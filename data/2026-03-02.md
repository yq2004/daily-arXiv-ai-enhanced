<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 34]
- [cs.IR](#cs.IR) [Total: 23]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Toward General Semantic Chunking: A Discriminative Framework for Ultra-Long Documents](https://arxiv.org/abs/2602.23370)
*Kaifeng Wu,Junyan Wu,Qiang Liu,Jiarui Zhang,Wen Xu*

Main category: cs.CL

TL;DR: 提出基于Qwen3-0.6B的判别式长文档主题分割模型，通过跨窗口上下文融合和重叠滑动窗口策略，支持13k tokens单次输入，相比生成式模型推理速度提升两个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有长文档主题分割方法存在明显不足：传统判别模型受限于固定窗口无法建模文档级语义；生成式大语言模型推理昂贵且难以支持长输入。需要一种更高效实用的解决方案。

Method: 基于Qwen3-0.6B骨干网络，添加跨窗口上下文融合层和边界分类头，结合重叠滑动窗口策略。提出向量融合方法（含标量校正）将超长片段压缩为单个向量而无语义损失。

Result: 在WIKI-727K数据集上，相比Jina发布的三个基于Qwen2-0.5B的生成模型，本方法取得更好的宏平均F1分数，推理速度快两个数量级，显著提升长文档处理的实用性和可扩展性。

Conclusion: 该判别式分割模型在保持高性能的同时大幅提升效率，为长文档主题分割提供了更实用的解决方案，支持单次输入13k tokens并可扩展至超长文档处理。

Abstract: Long-document topic segmentation plays an important role in information retrieval and document understanding, yet existing methods still show clear shortcomings in ultra-long text settings. Traditional discriminative models are constrained by fixed windows and cannot model document-level semantics; generative large language models can output paragraph boundaries, but inference is expensive and long inputs are difficult to support. To address these issues, we propose a discriminative segmentation model based on Qwen3-0.6B. On top of the backbone network, we add a cross-window context fusion layer and a boundary classification head, and combine them with an overlapping sliding-window strategy. Our model supports single-pass inputs of up to 13k tokens and can be extended to ultra-long documents for paragraph boundary detection. To further enhance downstream retrieval efficiency, we derive a vector fusion method with scalar correction, which compresses the representation of ultra-long segments into a single vector without semantic loss. Experiments on the Wikipedia long-document topic segmentation dataset WIKI-727K show that, compared with three generative models based on Qwen2-0.5B released by Jina, our method achieves a better macro-averaged F1 and delivers two orders of magnitude faster inference, substantially improving the practicality and scalability of long-document processing.

</details>


### [2] [Task-Lens: Cross-Task Utility Based Speech Dataset Profiling for Low-Resource Indian Languages](https://arxiv.org/abs/2602.23388)
*Swati Sharma,Divya V. Sharma,Anubha Gupta*

Main category: cs.CL

TL;DR: Task-Lens：对50个印度语言语音数据集进行跨任务调查，评估其在9个下游语音任务中的适用性，揭示未充分利用的元数据并提出任务对齐的增强方案。


<details>
  <summary>Details</summary>
Motivation: 印度等语言多样化国家中，低资源语言的任务特定资源意识有限，阻碍了包容性语音技术研究。现有调查通常只针对单一任务，缺乏跨任务的全面分析。

Method: 提出Task-Lens跨任务调查方法：1) 分析50个印度语音数据集（涵盖26种语言）的元数据和属性是否适合9个下游任务；2) 提出任务对齐的增强方案以释放数据集潜力；3) 识别当前资源严重不足的任务和语言。

Result: 发现许多印度语音数据集包含未充分利用的元数据，可支持多个下游任务。通过揭示跨任务关联和差距，为研究人员提供了探索现有数据集更广泛适用性的途径。

Conclusion: Task-Lens通过跨任务分析，能够帮助研究人员更有效地利用现有数据集，并优先为服务不足的任务和语言创建新数据集，从而缓解印度语言语音数据稀缺的挑战。

Abstract: The rising demand for inclusive speech technologies amplifies the need for multilingual datasets for Natural Language Processing (NLP) research. However, limited awareness of existing task-specific resources in low-resource languages hinders research. This challenge is especially acute in linguistically diverse countries, such as India. Cross-task profiling of existing Indian speech datasets can alleviate the data scarcity challenge. This involves investigating the utility of datasets across multiple downstream tasks rather than focusing on a single task. Prior surveys typically catalogue datasets for a single task, leaving comprehensive cross-task profiling as an open opportunity. Therefore, we propose Task-Lens, a cross-task survey that assesses the readiness of 50 Indian speech datasets spanning 26 languages for nine downstream speech tasks. First, we analyze which datasets contain metadata and properties suitable for specific tasks. Next, we propose task-aligned enhancements to unlock datasets to their full downstream potential. Finally, we identify tasks and Indian languages that are critically underserved by current resources. Our findings reveal that many Indian speech datasets contain untapped metadata that can support multiple downstream tasks. By uncovering cross-task linkages and gaps, Task-Lens enables researchers to explore the broader applicability of existing datasets and to prioritize dataset creation for underserved tasks and languages.

</details>


### [3] [Truncated Step-Level Sampling with Process Rewards for Retrieval-Augmented Reasoning](https://arxiv.org/abs/2602.23440)
*Chris Samarinas,Haw-Shiuan Chang,Hamed Zamani*

Main category: cs.CL

TL;DR: SLATE提出一种新的强化学习框架，结合截断步级采样和密集LLM-as-judge奖励，解决大语言模型搜索推理中的信用分配问题，降低梯度方差并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如Search-R1使用稀疏结果奖励，难以将成功或失败归因于单个推理和检索决策；而Process-reward方法如StepSearch虽然引入步级监督，但仍依赖启发式奖励（如TF-IDF重叠）并采样多个完整轨迹，梯度方差较高。

Method: 提出SLATE框架，包含两个核心思想：(1) 截断步级采样：生成k个共享共同前缀、仅在下一步有差异的轨迹；(2) 密集LLM-as-judge奖励：用能力强的LLM评估器替代启发式评分，评估每个推理步骤、搜索查询和答案的质量，提供更丰富可靠的监督。

Result: 理论上证明，在相同密集奖励结构下，截断采样将优势估计的方差降低了最多T倍（T步轨迹）；在七个QA基准测试中，SLATE持续优于稀疏奖励和过程奖励基线，在更难的多跳任务和较小模型上获得最大提升。

Conclusion: SLATE通过截断步级采样和密集LLM-as-judge奖励，有效解决了搜索推理中的信用分配问题，降低了梯度方差，在多个QA任务中取得了显著性能改进，特别适用于复杂推理场景和资源受限的模型。

Abstract: Training large language models to reason with search engines via reinforcement learning is hindered by a fundamental credit assignment problem: existing methods such as Search-R1 provide only a sparse outcome reward after an entire multi-step trajectory, making it infeasible to attribute success or failure to individual reasoning and retrieval decisions. Process-reward methods like StepSearch alleviate this by introducing step-level supervision, but rely on heuristic rewards such as TF-IDF overlap with gold documents, and still sample k complete trajectories per example, retaining high gradient variance. We propose SLATE, a framework built on two complementary ideas: (1) truncated step-level sampling, which generates k trajectories that share a common prefix and differ only at the next step, and (2) dense LLM-as-judge rewards, which replace heuristic scoring with a capable LLM evaluator that assesses the quality of each reasoning step, search query, and answer, providing richer and more reliable supervision. We theoretically prove that under the same dense reward structure, truncated sampling reduces the variance of advantage estimates by up to a factor of T compared to full-trajectory sampling for T-step trajectories, yielding lower-variance, better-targeted policy gradients. Experiments on seven QA benchmarks confirm that SLATE consistently outperforms both sparse-reward and process-reward baselines, with the largest gains on harder multi-hop tasks and smaller models.

</details>


### [4] [CiteAudit: You Cited It, But Did You Read It? A Benchmark for Verifying Scientific References in the LLM Era](https://arxiv.org/abs/2602.23452)
*Zhengqing Yuan,Kaiwen Shi,Zheyuan Zhang,Lichao Sun,Nitesh V. Chawla,Yanfang Ye*

Main category: cs.CL

TL;DR: 首个针对科学写作中幻觉引用的综合基准与检测框架，通过多智能体验证流程评估引用真实性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的幻觉引用在科学论文中已实际出现，但现有工具无法有效处理异构引用格式且缺乏标准化评估，需要可扩展的检测方案

Method: 提出多智能体验证流水线，将引用检查分解为声明提取、证据检索、段落匹配、推理和校准判断五个步骤，构建大规模人工验证数据集并定义统一评估指标

Result: 实验显示当前最先进LLM存在大量引用错误，该框架在准确性和可解释性上显著优于现有方法，为大规模引用审计提供基础设施

Conclusion: 该工作为LLM时代的科学引用审计提供了首个可扩展基础设施，并为提高科学参考文献的可信度提供实用工具

Abstract: Scientific research relies on accurate citation for attribution and integrity, yet large language models (LLMs) introduce a new risk: fabricated references that appear plausible but correspond to no real publications. Such hallucinated citations have already been observed in submissions and accepted papers at major machine learning venues, exposing vulnerabilities in peer review. Meanwhile, rapidly growing reference lists make manual verification impractical, and existing automated tools remain fragile to noisy and heterogeneous citation formats and lack standardized evaluation. We present the first comprehensive benchmark and detection framework for hallucinated citations in scientific writing. Our multi-agent verification pipeline decomposes citation checking into claim extraction, evidence retrieval, passage matching, reasoning, and calibrated judgment to assess whether a cited source truly supports its claim. We construct a large-scale human-validated dataset across domains and define unified metrics for citation faithfulness and evidence alignment. Experiments with state-of-the-art LLMs reveal substantial citation errors and show that our framework significantly outperforms prior methods in both accuracy and interpretability. This work provides the first scalable infrastructure for auditing citations in the LLM era and practical tools to improve the trustworthiness of scientific references.

</details>


### [5] [FHIRPath-QA: Executable Question Answering over FHIR Electronic Health Records](https://arxiv.org/abs/2602.23479)
*Michael Frew,Nishit Bheda,Bryan Tripp*

Main category: cs.CL

TL;DR: FHIRPath-QA：首个针对患者特定问答的开放数据集和基准，采用文本转FHIRPath查询范式，减少LLM使用，提升临床数据访问的安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有电子健康记录接口难以提供精确可信的患者特定问题答案，基于检索的LLM方法存在计算效率低、易产生幻觉、难以在实际EHR中部署等问题。

Method: 提出文本转FHIRPath问答范式，将推理从自由文本生成转向FHIRPath查询合成；构建基于MIMIC-IV on FHIR Demo的数据集，包含14k+自然语言问题与验证的FHIRPath查询和答案。

Result: 最先进的LLM在处理患者语言模糊性和FHIRPath查询合成方面表现不佳，但通过监督微调后显著改善；文本转FHIRPath合成有望成为安全、高效、可互操作的消费健康应用基础。

Conclusion: FHIRPath-QA数据集和基准为未来研究提供了起点，文本转FHIRPath范式在临床问答中具有实际应用潜力，能提高安全性和效率。

Abstract: Though patients are increasingly granted digital access to their electronic health records (EHRs), existing interfaces may not support precise, trustworthy answers to patient-specific questions. Large language models (LLM) show promise in clinical question answering (QA), but retrieval-based approaches are computationally inefficient, prone to hallucination, and difficult to deploy over real-life EHRs. In this work, we introduce FHIRPath-QA, the first open dataset and benchmark for patient-specific QA that includes open-standard FHIRPath queries over real-world clinical data. We propose a text-to-FHIRPath QA paradigm that shifts reasoning from free-text generation to FHIRPath query synthesis, significantly reducing LLM usage. Built on MIMIC-IV on FHIR Demo, the dataset pairs over 14k natural language questions in patient and clinician phrasing with validated FHIRPath queries and answers. Further, we demonstrate that state-of-the-art LLMs struggle to deal with ambiguity in patient language and perform poorly in FHIRPath query synthesis. However, they benefit strongly from supervised fine-tuning. Our results highlight that text-to-FHIRPath synthesis has the potential to serve as a practical foundation for safe, efficient, and interoperable consumer health applications, and our dataset and benchmark serve as a starting point for future research on the topic. The full dataset and generation code is available at: https://github.com/mooshifrew/fhirpath-qa.

</details>


### [6] [IDP Accelerator: Agentic Document Intelligence from Extraction to Compliance Validation](https://arxiv.org/abs/2602.23481)
*Md Mofijul Islam,Md Sirajus Salekin,Joe King,Priyashree Roy,Vamsi Thilak Gudi,Spencer Romo,Akhil Nooney,Boyi Xie,Bob Strahan,Diego A. Socolinsky*

Main category: cs.CL

TL;DR: IDP Accelerator是一个端到端文档智能处理框架，通过多模态LLM、智能代理和规则验证模块解决复杂文档包处理、合规性检查等工业NLP挑战。


<details>
  <summary>Details</summary>
Motivation: 工业NLP中从非结构化文档提取结构化信息面临三大挑战：传统流水线无法处理多文档包、复杂推理和严格合规要求，需要更智能的解决方案。

Method: 提出IDP Accelerator框架，包含四个核心组件：1) DocSplit多模态分类器分割文档包；2) 可配置提取模块使用多模态LLM转换非结构化数据；3) 基于MCP的代理分析模块提供安全代码执行；4) 基于LLM的规则验证模块替代确定性引擎。

Result: 在领先医疗机构的实际部署中，达到98%分类准确率，处理延迟降低80%，运营成本减少77%，框架已开源并提供在线演示。

Conclusion: IDP Accelerator通过智能代理和LLM驱动的方法，成功解决了工业文档处理的复杂挑战，为多行业提供了可扩展、合规的端到端解决方案。

Abstract: Understanding and extracting structured insights from unstructured documents remains a foundational challenge in industrial NLP. While Large Language Models (LLMs) enable zero-shot extraction, traditional pipelines often fail to handle multi-document packets, complex reasoning, and strict compliance requirements. We present IDP (Intelligent Document Processing) Accelerator, a framework enabling agentic AI for end-to-end document intelligence with four key components: (1) DocSplit, a novel benchmark dataset and multimodal classifier using BIO tagging to segment complex document packets; (2) configurable Extraction Module leveraging multimodal LLMs to transform unstructured content into structured data; (3) Agentic Analytics Module, compliant with the Model Context Protocol (MCP) providing data access through secure, sandboxed code execution; and (4) Rule Validation Module replacing deterministic engines with LLM-driven logic for complex compliance checks. The interactive demonstration enables users to upload document packets, visualize classification results, and explore extracted data through an intuitive web interface. We demonstrate effectiveness across industries, highlighting a production deployment at a leading healthcare provider achieving 98% classification accuracy, 80% reduced processing latency, and 77% lower operational costs over legacy baselines. IDP Accelerator is open-sourced with a live demonstration available to the community.

</details>


### [7] [Humans and LLMs Diverge on Probabilistic Inferences](https://arxiv.org/abs/2602.23546)
*Gaurav Kamath,Sreenath Madathil,Sebastian Schuster,Marie-Catherine de Marneffe,Siva Reddy*

Main category: cs.CL

TL;DR: 该论文介绍了ProbCOPA数据集，用于评估LLM在概率推理任务上的表现，发现LLM与人类在概率推理上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 人类推理常基于有限信息进行概率推断，而当前LLM在逻辑和数学任务上表现优秀，但在开放式、非确定性的概率推理任务上的表现尚未充分探索。

Method: 创建了包含210个手工制作的英语概率推理问题的ProbCOPA数据集，每个问题由25-30名人类参与者标注推理可能性，然后比较了8个最先进的推理LLM的表现。

Result: 人类反应呈现分级和多样化，而LLM无法产生类似人类的分布模式。通过分析LLM的推理链，发现它们使用了一种共同的推理模式来评估此类推理。

Conclusion: 人类与LLM在概率推理上存在持续差异，强调需要在非确定性设置下评估推理能力。

Abstract: Human reasoning often involves working over limited information to arrive at probabilistic conclusions. In its simplest form, this involves making an inference that is not strictly entailed by a premise, but rather only likely given the premise. While reasoning LLMs have demonstrated strong performance on logical and mathematical tasks, their behavior on such open-ended, non-deterministic inferences remains largely unexplored. We introduce ProbCOPA, a dataset of 210 handcrafted probabilistic inferences in English, each annotated for inference likelihood by 25--30 human participants. We find that human responses are graded and varied, revealing probabilistic judgments of the inferences in our dataset. Comparing these judgments with responses from eight state-of-the-art reasoning LLMs, we show that models consistently fail to produce human-like distributions. Finally, analyzing LLM reasoning chains, we find evidence of a common reasoning pattern used to evaluate such inferences. Our findings reveal persistent differences between humans and LLMs, and underscore the need to evaluate reasoning beyond deterministic settings.

</details>


### [8] [France or Spain or Germany or France: A Neural Account of Non-Redundant Redundant Disjunctions](https://arxiv.org/abs/2602.23547)
*Sasha Boguraev,Qing Yao,Kyle Mahowald*

Main category: cs.CL

TL;DR: 该论文通过人工神经网络机制解释了为什么某些看似冗余的句子在特定上下文中变得可接受，揭示了语言模型中避免冗余的两种交互机制。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解释为什么像"她将去法国或西班牙，或者可能去德国或法国"这样形式上冗余的句子，在特定上下文中（如"玛丽将去法国或西班牙的哲学项目，或德国或法国的数学项目"）变得可接受。虽然已有研究使用符号形式表示来分析这一现象，但本文旨在提供基于人工神经网络机制的补充解释。

Method: 方法包括：1）收集人类和大型语言模型的新行为证据，证明这种表面非冗余性在不同上下文中的鲁棒性；2）分析语言模型中避免冗余的机制，发现两种交互机制：模型学习将上下文相关信息绑定到重复的词汇项，Transformer的归纳头选择性地关注这些上下文许可的表示。

Result: 研究结果表明：1）人类和语言模型都表现出这种表面非冗余性的鲁棒性；2）在语言模型中，冗余避免源于两种交互机制：模型学习将上下文相关信息绑定到重复词汇项，Transformer归纳头选择性地关注这些上下文许可的表示。

Conclusion: 结论是这种神经机制解释揭示了上下文敏感语义解释的基础机制，补充了现有的符号分析，为理解语言处理中的冗余现象提供了新的视角。

Abstract: Sentences like "She will go to France or Spain, or perhaps to Germany or France." appear formally redundant, yet become acceptable in contexts such as "Mary will go to a philosophy program in France or Spain, or a mathematics program in Germany or France." While this phenomenon has typically been analyzed using symbolic formal representations, we aim to provide a complementary account grounded in artificial neural mechanisms. We first present new behavioral evidence from humans and large language models demonstrating the robustness of this apparent non-redundancy across contexts. We then show that, in language models, redundancy avoidance arises from two interacting mechanisms: models learn to bind contextually relevant information to repeated lexical items, and Transformer induction heads selectively attend to these context-licensed representations. We argue that this neural explanation sheds light on the mechanisms underlying context-sensitive semantic interpretation, and that it complements existing symbolic analyses.

</details>


### [9] [Multi-Agent Causal Reasoning for Suicide Ideation Detection Through Online Conversations](https://arxiv.org/abs/2602.23577)
*Jun Li,Xiangmeng Wang,Haoyang Li,Yifei Yan,Shijie Zhang,Hong Va Leong,Ling Feng,Nancy Xiaonan Yu,Qing Li*

Main category: cs.CL

TL;DR: 提出多智能体因果推理框架MACR，通过推理智能体扩展用户交互，偏置感知决策智能体减轻隐藏偏置，用于社交媒体自杀风险检测


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体自杀风险检测方法存在两个主要局限：1）依赖预定义规则（如引用或回复）仅捕捉狭窄的用户交互范围；2）忽视用户从众和自杀模仿行为等隐藏影响，这些因素显著影响在线社区中的自杀表达和传播。

Method: 提出多智能体因果推理框架MACR，包含两个协作智能体：推理智能体整合认知评价理论生成对帖子的反事实用户反应以扩展用户交互，通过认知、情感和行为模式三个维度分析反应；偏置感知决策智能体采用前门调整策略，利用推理智能体生成的反事实用户反应来减轻隐藏偏置。

Result: 在真实世界对话数据集上的大量实验表明，MACR在识别自杀风险方面具有有效性和鲁棒性。

Conclusion: MACR框架不仅减轻了隐藏偏置，还通过反事实知识丰富了用户交互的上下文信息，为社交媒体自杀风险检测提供了更全面的方法。

Abstract: Suicide remains a pressing global public health concern. While social media platforms offer opportunities for early risk detection through online conversation trees, existing approaches face two major limitations: (1) They rely on predefined rules (e.g., quotes or relies) to log conversations that capture only a narrow spectrum of user interactions, and (2) They overlook hidden influences such as user conformity and suicide copycat behavior, which can significantly affect suicidal expression and propagation in online communities. To address these limitations, we propose a Multi-Agent Causal Reasoning (MACR) framework that collaboratively employs a Reasoning Agent to scale user interactions and a Bias-aware Decision-Making Agent to mitigate harmful biases arising from hidden influences. The Reasoning Agent integrates cognitive appraisal theory to generate counterfactual user reactions to posts, thereby scaling user interactions. It analyses these reactions through structured dimensions, i.e., cognitive, emotional, and behavioral patterns, with a dedicated sub-agent responsible for each dimension. The Bias-aware Decision-Making Agent mitigates hidden biases through a front-door adjustment strategy, leveraging the counterfactual user reactions produced by the Reasoning Agent. Through the collaboration of reasoning and bias-aware decision making, the proposed MACR framework not only alleviates hidden biases, but also enriches contextual information of user interactions with counterfactual knowledge. Extensive experiments on real-world conversational datasets demonstrate the effectiveness and robustness of MACR in identifying suicide risk.

</details>


### [10] [BRIDGE the Gap: Mitigating Bias Amplification in Automated Scoring of English Language Learners via Inter-group Data Augmentation](https://arxiv.org/abs/2602.23580)
*Yun Wang,Xuansheng Wu,Jingyuan Huang,Lei Liu,Xiaoming Zhai,Ninghao Liu*

Main category: cs.CL

TL;DR: 提出BRIDGE框架，通过合成高质量少数群体样本减少自动评分系统中的偏见放大问题


<details>
  <summary>Details</summary>
Motivation: 在自动评分系统中，深度学习和大语言模型存在偏见放大风险，尤其对英语学习者等少数群体，模型倾向于低估使用不同语言模式但具备相当领域知识的学生，破坏评分公平性

Method: 提出BRIDGE框架，通过将高分的非ELL样本中的构念相关内容"粘贴"到真实的ELL语言模式中，合成高质量的ELL样本，并使用判别器模型确保合成样本质量

Result: 在加州科学测试数据集上的实验表明，BRIDGE有效减少了高分ELL学生的预测偏见，同时保持整体评分性能，其公平性提升效果与使用额外真实人类数据相当

Conclusion: BRIDGE为大规评估中的公平评分提供了一种经济有效的解决方案，通过合成高质量少数群体样本缓解偏见放大问题

Abstract: In the field of educational assessment, automated scoring systems increasingly rely on deep learning and large language models (LLMs). However, these systems face significant risks of bias amplification, where model prediction gaps between student groups become larger than those observed in training data. This issue is especially severe for underrepresented groups such as English Language Learners (ELLs), as models may inherit and further magnify existing disparities in the data. We identify that this issue is closely tied to representation bias: the scarcity of minority (high-scoring ELL) samples makes models trained with empirical risk minimization favor majority (non-ELL) linguistic patterns. Consequently, models tend to under-predict ELL students who even demonstrate comparable domain knowledge but use different linguistic patterns, thereby undermining the fairness of automated scoring outcomes. To mitigate this, we propose BRIDGE, a Bias-Reducing Inter-group Data GEneration framework designed for low-resource assessment settings. Instead of relying on the limited minority samples, BRIDGE synthesizes high-scoring ELL samples by "pasting" construct-relevant (i.e., rubric-aligned knowledge and evidence) content from abundant high-scoring non-ELL samples into authentic ELL linguistic patterns. We further introduce a discriminator model to ensure the quality of synthetic samples. Experiments on California Science Test (CAST) datasets demonstrate that BRIDGE effectively reduces prediction bias for high-scoring ELL students while maintaining overall scoring performance. Notably, our method achieves fairness gains comparable to using additional real human data, offering a cost-effective solution for ensuring equitable scoring in large-scale assessments.

</details>


### [11] [LFQA-HP-1M: A Large-Scale Human Preference Dataset for Long-Form Question Answering](https://arxiv.org/abs/2602.23603)
*Rafid Ishrak Jahan,Fahmid Shahriar Iqbal,Sagnik Ray Choudhury*

Main category: cs.CL

TL;DR: 提出了LFQA-HP-1M大规模数据集和基于九项标准的评估框架，线性模型性能媲美SOTA LLM评估器，并揭示了LLM评估器的各种偏差


<details>
  <summary>Details</summary>
Motivation: 长形式问答需要评估多句解释性回答，但现有指标往往无法反映人类判断，需要更可靠透明的评估方法

Method: 构建包含130万人类成对偏好标注的LFQA-HP-1M数据集，提出九个答案质量评估标准，使用基于这些特征的线性模型进行评估

Result: 基于九项标准的简单线性模型性能与最先进的LLM评估器相当，同时揭示了LLM评估器在传递一致性、位置偏差、冗长偏差方面的脆弱性

Conclusion: 该工作提供了最大的公开LFQA偏好数据集和基于标准的评估框架，为透明可靠的评估提供了重要资源

Abstract: Long-form question answering (LFQA) demands nuanced evaluation of multi-sentence explanatory responses, yet existing metrics often fail to reflect human judgment. We present LFQA-HP-1M, a large-scale dataset comprising 1.3M human pairwise preference annotations for LFQA. We propose nine rubrics for answer quality evaluation, and show that simple linear models based on these features perform comparably to state-of-the-art LLM evaluators. We further examine transitivity consistency, positional bias, and verbosity biases in LLM evaluators and demonstrate their vulnerability to adversarial perturbations. Overall, this work provides one of the largest public LFQA preference datasets and a rubric-driven framework for transparent and reliable evaluation.

</details>


### [12] [LLM-Driven Multi-Turn Task-Oriented Dialogue Synthesis for Realistic Reasoning](https://arxiv.org/abs/2602.23610)
*Yu Zhu,Kai Yang*

Main category: cs.CL

TL;DR: 提出LLM驱动的框架，通过三层优化合成基于现实场景的多轮任务导向对话，构建具有挑战性的推理基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有推理基准无法充分反映现实世界复杂性，数据集过于简化抽象，且存在数据污染问题，传统众包方法成本高难以扩展。

Method: 采用LLM驱动框架，通过三层优化合成基于真实任务场景的多轮对话，生成富含现实信息且上下文连贯的对话，并围绕对话精心设计推理任务。

Result: 构建的数据集为评估和提升LLMs的现实逻辑推理能力提供了有价值的基准，实验表明合成数据引入非平凡推理挑战，能有效支持LLMs推理能力提升。

Conclusion: 提出的LLM驱动框架能有效生成高质量的现实推理场景对话，为评估和增强LLMs在实际应用中的推理能力提供了可靠解决方案。

Abstract: The reasoning capability of large language models (LLMs), defined as their ability to analyze, infer, and make decisions based on input information, is essential for building intelligent task-oriented dialogue systems. However, existing benchmarks do not sufficiently reflect the complexity of real-world scenarios, which limits their effectiveness in evaluating and enhancing LLM reasoning in practical contexts. Many current reasoning datasets are overly simplistic and abstract, often disconnected from realistic task flows, domain constraints, and operational rules, making it difficult to effectively evaluate LLMs' logical reasoning ability. In addition, data contamination from pretraining corpora undermines the reliability of evaluation results, and traditional crowdsourcing methods for dataset construction are labor-intensive and difficult to scale. To address these challenges, we propose a LLM-driven framework for synthesizing multi-turn, task-oriented dialogues grounded in realistic reasoning scenarios, leveraging trilevel optimization to enhance dialogue quality. Our method generates dialogues grounded in authentic task scenarios, enriched with real-world information, and exhibiting strong contextual coherence. Corresponding reasoning tasks are carefully designed around these dialogues and iteratively refined to continuously improve the tasks' quality and challenge. The resulting dataset serves as a valuable benchmark for assessing and advancing the realistic logical reasoning capabilities of LLMs. Experimental results show that our synthetic data-based reasoning tasks introduce non-trivial reasoning challenges and provide meaningful support for improving the reasoning capabilities of LLMs.

</details>


### [13] [TRIZ-RAGNER: A Retrieval-Augmented Large Language Model for TRIZ-Aware Named Entity Recognition in Patent-Based Contradiction Mining](https://arxiv.org/abs/2602.23656)
*Zitong Xu,Yuqing Wu,Yue Zhao*

Main category: cs.CL

TL;DR: TRIZ-RAGNER：基于检索增强LLM的TRIZ矛盾挖掘框架，通过语义级NER任务和TRIZ知识库检索，提升专利矛盾参数提取的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有TRIZ矛盾挖掘方法主要依赖基于规则的系统或传统机器学习模型，在处理复杂专利语言时存在语义模糊、领域依赖和泛化能力有限的问题。LLM虽然具有强大的语义理解能力，但直接应用于TRIZ参数提取时存在幻觉问题，且缺乏结构化TRIZ知识的基础。

Method: 提出TRIZ-RAGNER框架，将矛盾挖掘重新定义为语义级命名实体识别任务。该框架整合了：1）基于TRIZ知识库的密集检索；2）用于上下文优化的交叉编码器重排序；3）结构化LLM提示，从专利句子中提取改善和恶化参数。通过将领域特定的TRIZ知识注入LLM推理过程，减少语义噪声并提高提取一致性。

Result: 在PaTRIZ数据集上的实验表明，TRIZ-RAGNER在TRIZ矛盾对识别方面达到85.6%的精确率、82.9%的召回率和84.2%的F1分数。相比使用提示增强GPT的最强基线，F1分数绝对提升了7.3个百分点。

Conclusion: TRIZ-RAGNER通过检索增强的TRIZ知识基础，显著提升了专利矛盾挖掘的鲁棒性和准确性，验证了将领域知识注入LLM推理过程的有效性。

Abstract: TRIZ-based contradiction mining is a fundamental task in patent analysis and systematic innovation, as it enables the identification of improving and worsening technical parameters that drive inventive problem solving. However, existing approaches largely rely on rule-based systems or traditional machine learning models, which struggle with semantic ambiguity, domain dependency, and limited generalization when processing complex patent language. Recently, large language models (LLMs) have shown strong semantic understanding capabilities, yet their direct application to TRIZ parameter extraction remains challenging due to hallucination and insufficient grounding in structured TRIZ knowledge. To address these limitations, this paper proposes TRIZ-RAGNER, a retrieval-augmented large language model framework for TRIZ-aware named entity recognition in patent-based contradiction mining. TRIZ-RAGNER reformulates contradiction mining as a semantic-level NER task and integrates dense retrieval over a TRIZ knowledge base, cross-encoder reranking for context refinement, and structured LLM prompting to extract improving and worsening parameters from patent sentences. By injecting domain-specific TRIZ knowledge into the LLM reasoning process, the proposed framework effectively reduces semantic noise and improves extraction consistency. Experiments on the PaTRIZ dataset demonstrate that TRIZ-RAGNER consistently outperforms traditional sequence labeling models and LLM-based baselines. The proposed framework achieves a precision of 85.6%, a recall of 82.9%, and an F1-score of 84.2% in TRIZ contradiction pair identification. Compared with the strongest baseline using prompt-enhanced GPT, TRIZ-RAGNER yields an absolute F1-score improvement of 7.3 percentage points, confirming the effectiveness of retrieval-augmented TRIZ knowledge grounding for robust and accurate patent-based contradiction mining.

</details>


### [14] [From Static Benchmarks to Dynamic Protocol: Agent-Centric Text Anomaly Detection for Evaluating LLM Reasoning](https://arxiv.org/abs/2602.23729)
*Seungdong Yoa,Sanghyu Yoon,Suhee Yoon,Dongmin Kim,Ye Seul Sim,Junhyun Lee,Woohyung Lim*

Main category: cs.CL

TL;DR: 提出基于智能体的动态基准测试范式，通过教师、协调员、学生智能体迭代生成、验证和解决问题，实现自动难度扩展，超越静态数据集限制


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要依赖静态数据集，但这种方法可扩展性有限，无法捕捉最新模型不断发展的推理能力。静态数据集难以跟上模型进步速度，且容易被模式匹配等方法绕过。

Method: 提出基于智能体的动态基准测试协议：1) 教师智能体生成候选问题；2) 协调员智能体严格验证问题有效性并防范对抗攻击；3) 学生智能体尝试解决验证通过的问题。如果问题无效，教师智能体修订直到通过验证；如果学生正确解决问题，协调员提示教师生成更具挑战性的变体。通过文本异常检测作为主要评估格式，要求跨句子逻辑推理，抵抗模式匹配捷径。

Result: 该协议能系统性地暴露传统基准测试无法揭示的边界情况推理错误。通过将更强大的智能体替换到任何角色，基准测试难度会自动扩展，实现无需人工标注数据集的渐进式评估。进一步提出沿多个互补维度评估系统，包括跨模型成对性能和初始问题与协调员最终问题之间的进展。

Conclusion: 通过将重点从固定数据集转向动态协议，该方法为评估不断发展的语言模型提供了可持续方向，并引入了以智能体基准测试共同进化为中心的研究议程。

Abstract: The evaluation of large language models (LLMs) has predominantly relied on static datasets, which offer limited scalability and fail to capture the evolving reasoning capabilities of recent models. To overcome these limitations, we propose an agent-centric benchmarking paradigm that moves beyond static datasets by introducing a dynamic protocol in which autonomous agents iteratively generate, validate, and solve problems. Within this protocol, a teacher agent generates candidate problems, an orchestrator agent rigorously verifies their validity and guards against adversarial attacks, and a student agent attempts to solve the validated problems. An invalid problem is revised by the teacher agent until it passes validation. If the student correctly solves the problem, the orchestrator prompts the teacher to generate more challenging variants. Consequently, the benchmark scales in difficulty automatically as more capable agents are substituted into any role, enabling progressive evaluation of large language models without manually curated datasets. Adopting text anomaly detection as our primary evaluation format, which demands cross-sentence logical inference and resists pattern-matching shortcuts, we demonstrate that this protocol systematically exposes corner-case reasoning errors that conventional benchmarks fail to reveal. We further advocate evaluating systems along several complementary axes including cross-model pairwise performance and progress between the initial and orchestrator-finalized problems. By shifting the focus from fixed datasets to dynamic protocols, our approach offers a sustainable direction for evaluating ever-evolving language models and introduces a research agenda centered on the co-evolution of agent-centric benchmarks.

</details>


### [15] [Structured Prompt Optimization for Few-Shot Text Classification via Semantic Alignment in Latent Space](https://arxiv.org/abs/2602.23753)
*Jiasen Zheng,Zijun Zhou,Huajun Zhang,Junjiang Lin,Jingyun Jia,Qi Wang*

Main category: cs.CL

TL;DR: 基于结构化提示的优化框架，通过多维度语义因子和跨空间对齐机制，解决少样本文本分类中的语义纠缠、标签结构不清晰和特征表示不足问题。


<details>
  <summary>Details</summary>
Motivation: 少样本文本分类中存在语义纠缠、标签结构不清晰和特征表示不足的问题，需要一种能够在低资源条件下增强语义理解和任务适应能力的方法。

Method: 提出基于结构化提示的优化框架：1) 使用预训练语言模型编码文本；2) 引入多维度语义因子构成的结构化提示，通过可学习组合机制与文本特征融合；3) 构建结构化标签嵌入矩阵，采用跨空间对齐机制匹配文本特征与标签属性；4) 应用提示正交性约束和联合优化目标保持语义因子独立性。

Result: 实验表明该框架有效缓解了少样本文本分类中的语义冲突和标签模糊性，在准确率、精确率、召回率和AUC等指标上显著提升，并展现出强大的跨任务适用性。通过三类敏感性实验验证了框架在不同条件下的稳定性和鲁棒性。

Conclusion: 结构化提示优化框架为少样本文本分类提供了一种透明可控的决策指导机制，能够有效解决语义纠缠和标签模糊问题，在低资源条件下显著提升分类性能并具备良好的泛化能力。

Abstract: This study addresses the issues of semantic entanglement, unclear label structure, and insufficient feature representation in few-shot text classification, and proposes an optimization framework based on structured prompts to enhance semantic understanding and task adaptation under low-resource conditions. The framework first uses a pretrained language model to encode the input text and obtain basic semantic representations. It then introduces structured prompts composed of multi-dimensional semantic factors and integrates them with text features through a learnable combination mechanism, which forms task-related representations with clear boundaries in the latent space. To further strengthen the consistency between text representations and label semantics, the method constructs a structured label embedding matrix and employs a cross-space alignment mechanism to ensure stable matching between textual features and label attributes. In addition, the model applies prompt orthogonality constraints and a joint optimization objective to maintain independence across different semantic factors in the prompts, allowing the structured prompts to provide transparent and controllable guidance for classification decisions. Three types of sensitivity experiments, including learning rate sensitivity, prompt length sensitivity, and data scale sensitivity, are designed to evaluate the stability and robustness of the framework under different conditions. Experimental results show that the proposed structured prompt optimization framework effectively alleviates semantic conflicts and label ambiguity in few-shot text classification. It significantly improves performance on accuracy, precision, recall, and AUC, and demonstrates strong cross-task applicability.

</details>


### [16] [Divide and Conquer: Accelerating Diffusion-Based Large Language Models via Adaptive Parallel Decoding](https://arxiv.org/abs/2602.23792)
*Xiangzhong Luo,Yilin An,Zhicheng Yu,Weichen Liu,Xu Yang*

Main category: cs.CL

TL;DR: DiCo提出了一种自适应并行解码方法，通过分治范式实现扩散大语言模型的理论并行潜力，在保持生成质量的同时显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 当前扩散大语言模型虽然理论上支持并行生成多个标记，但实践中仍采用逐标记生成，因为直接解码多个掩码标记会导致生成质量和稳定性下降。理论与实际性能之间存在显著差距。

Method: DiCo采用三阶段分治范式：1) Divide阶段：探索输入掩码序列，识别种子标记并扩展构建局部簇；2) Conquer阶段：在不同局部簇间并行解码；3) Finalize阶段：使用细粒度复合解码方案解码剩余少量掩码标记以完成生成。分治过程在Divide和Conquer阶段之间交替直至收敛。

Result: 大量实验表明，DiCo能够在保持竞争力的生成质量的同时，实现显著的推理加速。

Conclusion: DiCo成功弥补了扩散大语言模型理论并行性与实际性能之间的差距，为高效推理提供了有效解决方案。

Abstract: Diffusion-based large language models (dLLMs) have shown promising performance across various reasoning tasks, establishing themselves as an alternative to autoregressive large language models (LLMs). Unlike autoregressive LLMs that generate one token per step based on all previous tokens, dLLMs theoretically enable parallel generation of multiple tokens at each decoding step. However, recent dLLMs still favor one-token-per-step generation in practice, as directly decoding multiple masked tokens often leads to degraded generation quality and stability. This reveals a substantial gap between the theoretical parallelism and practical performance of dLLMs. To bridge this gap, we introduce an adaptive parallel decoding approach, namely DiCo, which features a three-phase divide-and-conquer paradigm to unleash the inherent parallelism of dLLMs. During the Divide phase, DiCo first explores the input masked sequence and identifies masked tokens as seed tokens, which are then expanded to construct a set of local clusters. During the Conquer phase, DiCo performs parallel decoding across different local clusters constructed in the Divide phase. The divide-and-conquer process repeatedly alternates between the Divide and Conquer phases until convergence. During the Finalize phase, DiCo decodes the remaining few masked tokens using an effective fine-grained compound decoding scheme to finalize the generation. Extensive experiments demonstrate that DiCo can achieve significant inference speedups while maintaining competitive generation quality.

</details>


### [17] [GLUScope: A Tool for Analyzing GLU Neurons in Transformer Language Models](https://arxiv.org/abs/2602.23826)
*Sebastian Gerstner,Hinrich Schütze*

Main category: cs.CL

TL;DR: GLUScope是一个用于分析Transformer语言模型中神经元的开源工具，特别针对使用门控激活函数（如SwiGLU）的现代模型，能可视化四种不同符号组合的神经元激活模式。


<details>
  <summary>Details</summary>
Motivation: 现有工具主要针对较旧的Transformer模型，而现代模型使用门控激活函数（如SwiGLU），这带来了新的分析挑战：仅理解正激活不够，需要考虑门和输入激活的正负符号组合。

Method: 开发GLUScope工具，为每个神经元展示四种符号组合（++、+-、-+、--）的文本示例，并统计每种组合出现的频率，帮助研究人员理解神经元的不同功能模式。

Result: GLUScope工具能够揭示使用门控激活函数的神经元具有不同的功能模式，通过展示四种符号组合的具体示例，帮助研究人员获得新的洞察。

Conclusion: GLUScope填补了现代Transformer模型分析工具的空白，特别适用于门控激活函数，为可解释性研究提供了重要工具，能帮助发现神经元功能的新模式。

Abstract: We present GLUScope, an open-source tool for analyzing neurons in Transformer-based language models, intended for interpretability researchers. We focus on more recent models than previous tools do; specifically we consider gated activation functions such as SwiGLU. This introduces a new challenge: understanding positive activations is not enough. Instead, both the gate and the in activation of a neuron can be positive or negative, leading to four different possible sign combinations that in some cases have quite different functionalities. Accordingly, for any neuron, our tool shows text examples for each of the four sign combinations, and indicates how often each combination occurs. We describe examples of how our tool can lead to novel insights. A demo is available at https: //sjgerstner.github.io/gluscope.

</details>


### [18] [CLFEC: A New Task for Unified Linguistic and Factual Error Correction in paragraph-level Chinese Professional Writing](https://arxiv.org/abs/2602.23845)
*Jian Kai,Zidong Zhang,Jiwen Chen,Zhengxiang Wu,Songtao Sun,Fuyang Li,Yang Cao,Qiang Liu*

Main category: cs.CL

TL;DR: 中文语言与事实错误联合纠错任务（CLFEC）的提出，构建了跨领域专业写作数据集，系统研究了LLM纠错范式，发现联合处理优于分离处理，智能体工作流在合适模型下有效。


<details>
  <summary>Details</summary>
Motivation: 传统中文纠错主要关注拼写和语法，事实错误通常单独处理。但在段落级中文专业写作中，语言错误（词汇/语法/标点）和事实错误经常同时出现并相互影响，因此需要统一的纠错方法，这既是必要的也是具有挑战性的。

Method: 提出了CLFEC任务，构建了涵盖时事、金融、法律、医学等多个领域的混合多领域中文专业写作数据集。系统研究了基于LLM的纠错范式，包括提示工程、检索增强生成（RAG）和智能体工作流。

Result: 研究发现：1）专业纠错模型泛化能力有限；2）事实修复需要证据支持；3）混合错误段落处理困难；4）对干净输入存在过度纠错问题。结果表明，在同一上下文中联合处理语言和事实错误优于分离处理流程，智能体工作流在合适的骨干模型下可以发挥有效作用。

Conclusion: 提出的数据集和实证研究为工业环境中构建可靠的全自动校对系统提供了指导。联合处理语言和事实错误在专业写作场景中具有实际价值，智能体工作流是有效的解决方案方向。

Abstract: Chinese text correction has traditionally focused on spelling and grammar, while factual error correction is usually treated separately. However, in paragraph-level Chinese professional writing, linguistic (word/grammar/punctuation) and factual errors frequently co-occur and interact, making unified correction both necessary and challenging. This paper introduces CLFEC (Chinese Linguistic & Factual Error Correction), a new task for joint linguistic and factual correction. We construct a mixed, multi-domain Chinese professional writing dataset spanning current affairs, finance, law, and medicine. We then conduct a systematic study of LLM-based correction paradigms, from prompting to retrieval-augmented generation (RAG) and agentic workflows. The analysis reveals practical challenges, including limited generalization of specialized correction models, the need for evidence grounding for factual repair, the difficulty of mixed-error paragraphs, and over-correction on clean inputs. Results further show that handling linguistic and factual Error within the same context outperform decoupled processes, and that agentic workflows can be effective with suitable backbone models. Overall, our dataset and empirical findings provide guidance for building reliable, fully automatic proofreading systems in industrial settings.

</details>


### [19] [The Astonishing Ability of Large Language Models to Parse Jabberwockified Language](https://arxiv.org/abs/2602.23928)
*Gary Lupyan,Senyi Yang*

Main category: cs.CL

TL;DR: LLMs能够从严重退化的英语文本中恢复语义，即使内容词被无意义字符串随机替换，也能翻译回接近原文的常规英语。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在理解严重退化文本方面的能力极限，研究结构线索（如形态句法、封闭类词）对词汇意义的约束程度，以及这对理解语言结构和高效语言处理的意义。

Method: 将英语文本中的内容词随机替换为无意义字符串（称为"Jabberwockified"英语），然后使用LLMs将这些退化文本翻译回常规英语。

Result: LLMs表现出惊人的能力，能够从严重退化的文本中恢复语义，在许多情况下翻译出的英语接近原始文本。这表明结构线索对词汇意义的约束程度远超想象。

Conclusion: LLMs理解"Jabberwockified"英语的能力远超人类，这对理解语言结构具有重要意义，表明高效的语言处理（无论是生物还是人工系统）很可能受益于句法、词汇语义和一般世界知识的紧密整合。

Abstract: We show that large language models (LLMs) have an astonishing ability to recover meaning from severely degraded English texts. Texts in which content words have been randomly substituted by nonsense strings, e.g., "At the ghybe of the swuint, we are haiveed to Wourge Phrear-gwurr, who sproles into an ghitch flount with his crurp", can be translated to conventional English that is, in many cases, close to the original text, e.g., "At the start of the story, we meet a man, Chow, who moves into an apartment building with his wife." These results show that structural cues (e.g., morphosyntax, closed-class words) constrain lexical meaning to a much larger degree than imagined. Although the abilities of LLMs to make sense of "Jabberwockified" English are clearly superhuman, they are highly relevant to understanding linguistic structure and suggest that efficient language processing either in biological or artificial systems likely benefits from very tight integration between syntax, lexical semantics, and general world knowledge.

</details>


### [20] [Benchmarking BERT-based Models for Sentence-level Topic Classification in Nepali Language](https://arxiv.org/abs/2602.23940)
*Nischal Karki,Bipesh Subedi,Prakash Poudyal,Rupak Raj Ghimire,Bal Krishna Bal*

Main category: cs.CL

TL;DR: 对多种BERT变体在尼泊尔语主题分类任务上的基准测试，发现印度语言模型表现最佳


<details>
  <summary>Details</summary>
Motivation: 尼泊尔语作为一种使用天城文书写但资源匮乏的语言，在自然语言处理领域相对缺乏研究，需要建立有效的分类基准

Method: 对10种预训练模型（包括mBERT、XLM-R、MuRIL、DevBERT、HindiBERT、IndicBERT和NepBERTa）进行微调，在包含25,006个句子、涵盖5个概念领域的平衡尼泊尔语数据集上进行测试，使用准确率、加权精确率、召回率、F1分数和AUROC等指标评估性能

Result: 印度语言模型表现最佳，特别是MuRIL-large达到90.60%的F1分数，优于多语言和单语言模型；NepBERTa也表现出色，F1分数为88.26%

Conclusion: 研究结果为未来的文档级分类和更广泛的尼泊尔语自然语言处理应用建立了稳健的基线

Abstract: Transformer-based models such as BERT have significantly advanced Natural Language Processing (NLP) across many languages. However, Nepali, a low-resource language written in Devanagari script, remains relatively underexplored. This study benchmarks multilingual, Indic, Hindi, and Nepali BERT variants to evaluate their effectiveness in Nepali topic classification. Ten pre-trained models, including mBERT, XLM-R, MuRIL, DevBERT, HindiBERT, IndicBERT, and NepBERTa, were fine-tuned and tested on the balanced Nepali dataset containing 25,006 sentences across five conceptual domains and the performance was evaluated using accuracy, weighted precision, recall, F1-score, and AUROC metrics. The results reveal that Indic models, particularly MuRIL-large, achieved the highest F1-score of 90.60%, outperforming multilingual and monolingual models. NepBERTa also performed competitively with an F1-score of 88.26%. Overall, these findings establish a robust baseline for future document-level classification and broader Nepali NLP applications.

</details>


### [21] [EDDA-Coordinata: An Annotated Dataset of Historical Geographic Coordinates](https://arxiv.org/abs/2602.23941)
*Ludovic Moncla,Pierre Nugues,Thierry Joliveau,Katherine McDonough*

Main category: cs.CL

TL;DR: 基于18世纪《百科全书》构建地理坐标数据集，开发两阶段模型自动提取和规范化历史文本中的坐标，在跨语言、跨领域测试中表现良好。


<details>
  <summary>Details</summary>
Motivation: 从历史文本中自动提取地理坐标具有挑战性，因为坐标表达方式多样且精度不一。为改进从早期现代数字化文本中提取坐标的能力，需要创建高质量数据集和有效模型。

Method: 1) 从《百科全书》74,000篇文章中筛选15,278个地理条目，人工标注4,798个含坐标条目和10,480个描述性条目；2) 基于标注数据训练transformer模型；3) 采用两阶段管道：分类器识别含坐标条目，第二个模型提取坐标；4) 测试多种编码器-解码器和解码器架构。

Result: 交叉验证获得86%的精确匹配分数；在跨领域测试中，18世纪法语词典获得61% EM分数，19世纪英语百科全书获得77% EM分数。模型展现出跨语言和跨领域的泛化能力。

Conclusion: 该研究创建的高质量数据集对训练坐标提取模型非常有效，两阶段方法在跨语言、跨领域场景中具有良好的泛化能力，为历史文本地理信息提取提供了实用工具。

Abstract: This paper introduces a dataset of enriched geographic coordinates retrieved from Diderot and d'Alembert's eighteenth-century Encyclopedie. Automatically recovering geographic coordinates from historical texts is a complex task, as they are expressed in a variety of ways and with varying levels of precision. To improve retrieval of coordinates from similar digitized early modern texts, we have created a gold standard dataset, trained models, published the resulting inferred and normalized coordinate data, and experimented applying these models to new texts. From 74,000 total articles in each of the digitized versions of the Encyclopedie from ARTFL and ENCCRE, we examined 15,278 geographical entries, manually identifying 4,798 containing coordinates, and 10,480 with descriptive but non-numerical references. Leveraging our gold standard annotations, we trained transformer-based models to retrieve and normalize coordinates. The pipeline presented here combines a classifier to identify coordinate-bearing entries and a second model for retrieval, tested across encoder-decoder and decoder architectures. Cross-validation yielded an 86% EM score. On an out-of-domain eighteenth-century Trevoux dictionary (also in French), our fine-tuned model had a 61% EM score, while for the nineteenth-century, 7th edition of the Encyclopaedia Britannica in English, the EM was 77%. These findings highlight the gold standard dataset's usefulness as training data, and our two-step method's cross-lingual, cross-domain generalizability.

</details>


### [22] [MemEmo: Evaluating Emotion in Memory Systems of Agents](https://arxiv.org/abs/2602.23944)
*Peng Liu,Zhen Tao,Jihao Zhao,Ding Chen,Yansong Zhang,Cuiping Li,Zhiyu Li,Hong Chen*

Main category: cs.CL

TL;DR: 提出情感增强记忆评估基准HLME，评估主流记忆系统处理情感信息的能力，发现现有系统在情感信息处理方面存在明显不足


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的记忆系统在处理长时间交互时存在上下文丢失问题，但与人类认知相比，这些系统处理情感相关信息的效果尚不明确，需要建立评估基准来填补这一研究空白

Method: 提出情感增强记忆评估基准，开发HLME数据集，从三个维度评估记忆系统：情感信息提取、情感记忆更新、情感记忆问答，对主流和SOTA记忆系统进行实验评估

Result: 实验结果表明，所有被评估的系统都无法在三个任务上实现稳健的性能，现有记忆系统在处理情感记忆方面存在明显缺陷

Conclusion: 研究为记忆系统处理情感记忆的当前不足提供了客观视角，为未来研究和系统优化指出了新的方向，强调需要改进记忆系统的情感信息处理能力

Abstract: Memory systems address the challenge of context loss in Large Language Model during prolonged interactions. However, compared to human cognition, the efficacy of these systems in processing emotion-related information remains inconclusive. To address this gap, we propose an emotion-enhanced memory evaluation benchmark to assess the performance of mainstream and state-of-the-art memory systems in handling affective information. We developed the \textbf{H}uman-\textbf{L}ike \textbf{M}emory \textbf{E}motion (\textbf{HLME}) dataset, which evaluates memory systems across three dimensions: emotional information extraction, emotional memory updating, and emotional memory question answering. Experimental results indicate that none of the evaluated systems achieve robust performance across all three tasks. Our findings provide an objective perspective on the current deficiencies of memory systems in processing emotional memories and suggest a new trajectory for future research and system optimization.

</details>


### [23] [The GRADIEND Python Package: An End-to-End System for Gradient-Based Feature Learning](https://arxiv.org/abs/2602.23993)
*Jonathan Drechsel,Steffen Herbold*

Main category: cs.CL

TL;DR: Gradiend是一个开源Python包，实现了从语言模型的事实-反事实梯度中学习特征方向的GRADIEND方法，提供特征相关数据处理、训练、评估、可视化、模型重写和多特征比较的统一工作流。


<details>
  <summary>Details</summary>
Motivation: 需要一种系统化的方法来从语言模型的梯度中学习特征方向，以支持特征相关研究、模型分析和可解释性工作，但目前缺乏统一的工作流程和工具。

Method: 基于GRADIEND方法，利用语言模型的事实-反事实MLM和CLM梯度来学习特征方向，通过Python包提供数据创建、训练、评估、可视化、模型重写和多特征比较的完整工作流。

Result: 开发了gradiend开源包，在英语代词范式和大规模特征比较中验证了GRADIEND方法，成功复现了先前的研究用例，展示了方法的有效性和工具的实用性。

Conclusion: gradiend包为语言模型特征方向学习提供了实用工具，支持特征分析、模型解释和干预研究，有助于推进语言模型可解释性和控制性研究。

Abstract: We present gradiend, an open-source Python package that operationalizes the GRADIEND method for learning feature directions from factual-counterfactual MLM and CLM gradients in language models. The package provides a unified workflow for feature-related data creation, training, evaluation, visualization, persistent model rewriting via controlled weight updates, and multi-feature comparison. We demonstrate GRADIEND on an English pronoun paradigm and on a large-scale feature comparison that reproduces prior use cases.

</details>


### [24] [Dialect and Gender Bias in YouTube's Spanish Captioning System](https://arxiv.org/abs/2602.24002)
*Iris Dania Jimenez,Christoph Kern*

Main category: cs.CL

TL;DR: YouTube的西班牙语自动字幕系统存在方言偏见，不同西班牙语方言的识别准确性存在系统性差异


<details>
  <summary>Details</summary>
Motivation: 西班牙语在21个国家有4.41亿使用者，存在多种方言变体，但YouTube仅提供单一的西班牙语自动字幕系统，这引发了该系统是否对某些方言存在偏见的疑问

Method: 通过分析YouTube自动字幕系统在不同西班牙语方言上的表现，比较来自不同地区的女性和男性说话者的字幕质量

Result: 研究发现系统性的差异可以归因于特定方言，表明YouTube的西班牙语自动字幕系统存在方言偏见

Conclusion: 数字平台部署的算法技术需要针对用户群体的多样化需求和体验进行校准，以确保公平性和包容性

Abstract: Spanish is the official language of twenty-one countries and is spoken by over 441 million people. Naturally, there are many variations in how Spanish is spoken across these countries. Media platforms such as YouTube rely on automatic speech recognition systems to make their content accessible to different groups of users. However, YouTube offers only one option for automatically generating captions in Spanish. This raises the question: could this captioning system be biased against certain Spanish dialects? This study examines the potential biases in YouTube's automatic captioning system by analyzing its performance across various Spanish dialects. By comparing the quality of captions for female and male speakers from different regions, we identify systematic disparities which can be attributed to specific dialects. Our study provides further evidence that algorithmic technologies deployed on digital platforms need to be calibrated to the diverse needs and experiences of their user populations.

</details>


### [25] [Task Complexity Matters: An Empirical Study of Reasoning in LLMs for Sentiment Analysis](https://arxiv.org/abs/2602.24060)
*Donghao Huang,Zhaoxia Wang*

Main category: cs.CL

TL;DR: 研究发现推理能力对语言任务性能的提升并非普遍适用，而是强烈依赖于任务复杂度：简单任务上推理反而会降低性能，复杂任务上推理才能带来显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前普遍认为大型语言模型的推理能力能够普遍提升各种语言任务的性能，但这一假设缺乏系统性验证。本研究旨在通过全面评估不同推理架构在各种复杂度任务上的表现，来检验这一假设的普遍性。

Method: 对7个模型家族的504种配置进行系统评估，包括自适应、条件和基于强化学习的推理架构。在情感分析数据集上进行测试，涵盖不同粒度：二分类、五分类和27类情感识别。采用零样本和少样本提示策略，并进行帕累托前沿分析以评估效率-性能权衡。

Result: 1. 推理效果与任务复杂度相关：二分类任务性能下降高达19.9个F1百分点，而27类情感识别任务提升高达16.0个百分点；2. 蒸馏推理变体在简单任务上比基础模型差3-18个百分点，但少样本提示可部分恢复性能；3. 少样本学习在大多数情况下优于零样本，但增益因架构和任务复杂度而异；4. 帕累托前沿分析显示基础模型在效率-性能权衡中占主导，推理仅在复杂情感识别任务中合理，尽管计算开销增加2.1-54倍。

Conclusion: 推理能力的有效性是任务依赖性的，挑战了"推理普遍提升性能"的流行假设。对于简单任务，推理反而会因系统性过度思考而导致性能下降。研究为推理机制提供了超越高层"过度思考假设"的机制性见解，并强调了在部署推理增强模型时需要考虑任务复杂度和计算效率的权衡。

Abstract: Large language models (LLMs) with reasoning capabilities have fueled a compelling narrative that reasoning universally improves performance across language tasks. We test this claim through a comprehensive evaluation of 504 configurations across seven model families--including adaptive, conditional, and reinforcement learning-based reasoning architectures--on sentiment analysis datasets of varying granularity (binary, five-class, and 27-class emotion). Our findings reveal that reasoning effectiveness is strongly task-dependent, challenging prevailing assumptions: (1) Reasoning shows task-complexity dependence--binary classification degrades up to -19.9 F1 percentage points (pp), while 27-class emotion recognition gains up to +16.0pp; (2) Distilled reasoning variants underperform base models by 3-18 pp on simpler tasks, though few-shot prompting enables partial recovery; (3) Few-shot learning improves over zero-shot in most cases regardless of model type, with gains varying by architecture and task complexity; (4) Pareto frontier analysis shows base models dominate efficiency-performance trade-offs, with reasoning justified only for complex emotion recognition despite 2.1x-54x computational overhead. We complement these quantitative findings with qualitative error analysis revealing that reasoning degrades simpler tasks through systematic over-deliberation, offering mechanistic insight beyond the high-level overthinking hypothesis.

</details>


### [26] [Preference Packing: Efficient Preference Optimization for Large Language Models](https://arxiv.org/abs/2602.24082)
*Jaekyung Cho*

Main category: cs.CL

TL;DR: 提出了一种称为preference packing的资源高效训练优化方法，用于处理具有相同输入提示但不同响应的数据，可显著减少训练时间和内存使用。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模不断扩大，资源高效的训练优化技术变得越来越重要。特别是在奖励模型或直接偏好优化等场景中，经常会出现相同输入提示对应不同响应的数据，现有方法在这些场景下的资源效率有待提升。

Method: 提出了preference packing方法，通过减少重复输入提示的注意力操作和降低KV缓存内存使用来提高资源效率。该方法可应用于纯文本和包含图像的数据集，并能与现有优化技术（如批排序）结合使用。

Result: 在文本数据集和图像数据集上的实验表明，该方法至少能减少37%的训练时间。与现有优化技术结合使用时，能实现3.22倍的加速效果。

Conclusion: preference packing是一种有效的资源效率优化方法，特别适用于处理具有相同输入提示但不同响应的训练场景，能够显著提升训练速度并降低内存消耗。

Abstract: Resource-efficient training optimization techniques are becoming increasingly important as the size of large language models (LLMs) continues to grow. In particular, batch packing is commonly used in pre-training and supervised fine-tuning to achieve resource-efficient training. We propose preference packing, a method to enhance resource efficiency in training techniques that use data with different responses for the same input prompt, such as reward models or Direct Preference Optimization (DPO). Preference packing improves resource efficiency by reducing the attention operations for duplicate input prompts and decreasing KV cache memory usage. We conducted experiments on text-only datasets and image-included datasets and achieved at least 37% reduction in training time. Notably, this method can be applied alongside existing optimization techniques such as batch sorting, resulting in a 3.22x speedup.

</details>


### [27] [ARGUS: Seeing the Influence of Narrative Features on Persuasion in Argumentative Texts](https://arxiv.org/abs/2602.24109)
*Sara Nabhani,Federico Pianzola,Khalid Al-Khatib,Malvina Nissim*

Main category: cs.CL

TL;DR: ARGUS框架研究叙事在在线论证中的说服作用，通过标注故事存在和六个关键叙事特征，结合理论框架和LLM技术分析叙事维度对说服成功的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管故事常被视为有力的说服工具，但它们在在线非结构化论证中的具体作用尚未得到充分探索。需要研究叙事特征如何影响在线论证的说服力。

Method: 提出ARGUS框架，创建新的ChangeMyView语料库，标注故事存在和六个关键叙事特征。结合两个成熟的理论框架，使用基于编码器的分类器和零样本大语言模型来识别故事和叙事特征，并大规模分析不同叙事维度对说服成功的影响。

Result: ARGUS框架能够系统识别和分析在线论证中的叙事元素，为研究叙事特征如何影响说服成功提供了可扩展的方法。

Conclusion: ARGUS框架填补了叙事在在线论证中作用的研究空白，为理解哪些叙事特征最影响说服力提供了系统化的分析工具。

Abstract: Can narratives make arguments more persuasive? And to this end, which narrative features matter most? Although stories are often seen as powerful tools for persuasion, their specific role in online, unstructured argumentation remains underexplored. To address this gap, we present ARGUS, a framework for studying the impact of narration on persuasion in argumentative discourse. ARGUS introduces a new ChangeMyView corpus annotated for story presence and six key narrative features, integrating insights from two established theoretical frameworks that capture both textual narrative features and their effects on recipients. Leveraging both encoder-based classifiers and zero-shot large language models (LLMs), ARGUS identifies stories and narrative features and applies them at scale to examine how different narrative dimensions influence persuasion success in online argumentation.

</details>


### [28] [Terminology Rarity Predicts Catastrophic Failure in LLM Translation of Low-Resource Ancient Languages: Evidence from Ancient Greek](https://arxiv.org/abs/2602.24119)
*James L. Zainaldin,Cameron Pattison,Manuela Marai,Jacob Wu,Mark J. Schiefsky*

Main category: cs.CL

TL;DR: 本研究对大型语言模型在古希腊技术散文翻译中的表现进行了首次系统性、无参考的人类评估，发现LLMs在已翻译文本上接近专家水平，在未翻译文本上质量较低但可接受，术语罕见性是翻译失败的主要预测因素。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在低资源古代语言（古希腊语）技术散文翻译中的表现，特别是针对已有翻译和从未翻译过的文本，为古典学术研究和古代语言自动评估流程设计提供依据。

Method: 使用三种商业LLM（Claude、Gemini、ChatGPT）翻译20段古希腊医学家盖伦的文本，包括已有英译的《论混合》和从未完整翻译的《按种类论药物组成》。采用标准自动评估指标（BLEU、chrF++等）和专家人类评估（修改版MQM框架）相结合的方法。

Result: 在已有翻译的说明性文本上，LLMs达到高质量翻译（平均MQM得分95.2/100），接近专家水平。在未翻译的药理学文本上，总体质量较低（79.9/100），但排除两个极端术语密集段落后，得分与已翻译文本仅差4分。术语罕见性（通过Diorisis语料库频率衡量）是翻译失败的强预测因素（r=-.97）。自动指标在质量差异大的文本上与人评估有中等相关性，但无法区分高质量翻译。

Conclusion: LLMs在古希腊技术散文翻译中表现出色，特别是在已有翻译参考的文本上接近专家水平。术语罕见性是翻译质量的主要制约因素。自动评估指标对低质量翻译有鉴别力但对高质量翻译区分度有限，这对古典学术中LLMs的应用和低资源古代语言的自动评估流程设计具有重要意义。

Abstract: This study presents the first systematic, reference-free human evaluation of large language model (LLM) machine translation (MT) for Ancient Greek (AG) technical prose. We evaluate translations by three commercial LLMs (Claude, Gemini, ChatGPT) of twenty paragraph-length passages from two works by the Greek physician Galen of Pergamum (ca. 129-216 CE): On Mixtures, which has two published English translations, and On the Composition of Drugs according to Kinds, which has never been fully translated into English. We assess translation quality using both standard automated evaluation metrics (BLEU, chrF++, METEOR, ROUGE-L, BERTScore, COMET, BLEURT) and expert human evaluation via a modified Multidimensional Quality Metrics (MQM) framework applied to all 60 translations by a team of domain specialists. On the previously translated expository text, LLMs achieved high translation quality (mean MQM score 95.2/100), with performance approaching expert level. On the untranslated pharmacological text, aggregate quality was lower (79.9/100) but with high variance driven by two passages presenting extreme terminological density; excluding these, scores converged to within 4 points of the translated text. Terminology rarity, operationalized via corpus frequency in the literary Diorisis Ancient Greek Corpus, emerged as a strong predictor of translation failure (r = -.97 for passage-level quality on the untranslated text). Automated metrics showed moderate correlation with human judgment overall on the text with a wide quality spread (Composition), but no metric discriminated among high-quality translations. We discuss implications for the use of LLMs in Classical scholarship and for the design of automated evaluation pipelines for low-resource ancient languages.

</details>


### [29] [CoME: Empowering Channel-of-Mobile-Experts with Informative Hybrid-Capabilities Reasoning](https://arxiv.org/abs/2602.24142)
*Yuxuan Liu,Weikai Xu,Kun Huang,Changyu Chen,Jiankun Zhao,Pengzhi Gao,Wei Liu,Jian Luan,Shuo Shang,Bo Du,Ji-Rong Wen,Rui Yan*

Main category: cs.CL

TL;DR: CoME：一种新型移动代理架构，通过四个专家模块分别处理不同推理阶段，采用渐进式训练策略和基于信息增益的DPO方法，显著提升移动代理的多能力推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有移动代理在混合能力推理（屏幕总结、子任务规划、行动决策、行动执行）方面存在两个主要问题：1）不同能力难以实现解耦增强；2）多种能力难以平衡整合。这导致代理在执行用户指令时表现不佳。

Method: 提出CoME架构，包含四个专家模块，每个专家对应特定推理阶段。采用渐进式训练策略：Expert-FT（专家微调）增强各专家能力；Router-FT（路由微调）对齐专家激活与推理阶段；CoT-FT（思维链微调）促进多能力协作。还提出Info-DPO方法，利用信息增益评估中间步骤贡献，指导更有效的推理。

Result: 在AITZ和AMEX数据集上的综合实验表明，CoME在性能上超越了密集移动代理和MoE方法，验证了其在混合能力推理方面的优越性。

Conclusion: CoME通过专家模块的专门化设计、渐进式训练策略和基于信息增益的优化方法，成功解决了移动代理在混合能力推理中的解耦增强与平衡整合问题，为移动代理的发展提供了新方向。

Abstract: Mobile Agents can autonomously execute user instructions, which requires hybrid-capabilities reasoning, including screen summary, subtask planning, action decision and action function. However, existing agents struggle to achieve both decoupled enhancement and balanced integration of these capabilities. To address these challenges, we propose Channel-of-Mobile-Experts (CoME), a novel agent architecture consisting of four distinct experts, each aligned with a specific reasoning stage, CoME activates the corresponding expert to generate output tokens in each reasoning stage via output-oriented activation. To empower CoME with hybrid-capabilities reasoning, we introduce a progressive training strategy: Expert-FT enables decoupling and enhancement of different experts' capability; Router-FT aligns expert activation with the different reasoning stage; CoT-FT facilitates seamless collaboration and balanced optimization across multiple capabilities. To mitigate error propagation in hybrid-capabilities reasoning, we propose InfoGain-Driven DPO (Info-DPO), which uses information gain to evaluate the contribution of each intermediate step, thereby guiding CoME toward more informative reasoning. Comprehensive experiments show that CoME outperforms dense mobile agents and MoE methods on both AITZ and AMEX datasets.

</details>


### [30] [ArgLLM-App: An Interactive System for Argumentative Reasoning with Large Language Models](https://arxiv.org/abs/2602.24172)
*Adam Dejl,Deniz Gorur,Francesca Toni*

Main category: cs.CL

TL;DR: ArgLLM-App：一个基于ArgLLM的Web系统，通过可视化解释和用户交互实现可解释、可争议的决策


<details>
  <summary>Details</summary>
Motivation: 现有ArgLLM方法虽然利用LLM和计算论证进行决策，但缺乏让人类用户理解、解释和质疑决策结果的实用系统。需要开发一个支持可视化解释和用户交互的平台，使AI决策过程更加透明和可争议。

Method: 1. 开发基于Web的系统ArgLLM-App，实现ArgLLM赋能的智能体处理二元决策任务
2. 系统高度模块化，支持从可信外部源获取信息
3. 提供决策过程的可视化展示
4. 允许人类用户与系统交互，识别和质疑推理中的错误

Result: 1. 成功开发了ArgLLM-App系统，公开可用（https://argllm.app）
2. 提供了视频演示（https://youtu.be/vzwlGOr0sPM）
3. 系统实现了ArgLLM决策过程的可视化解释
4. 支持用户与系统交互，质疑和纠正推理错误

Conclusion: ArgLLM-App是一个有效的工具，通过结合ArgLLM方法和用户交互界面，使AI决策更加透明、可解释和可争议，有助于建立人类对AI系统的信任。

Abstract: Argumentative LLMs (ArgLLMs) are an existing approach leveraging Large Language Models (LLMs) and computational argumentation for decision-making, with the aim of making the resulting decisions faithfully explainable to and contestable by humans. Here we propose a web-based system implementing ArgLLM-empowered agents for binary tasks. ArgLLM-App supports visualisation of the produced explanations and interaction with human users, allowing them to identify and contest any mistakes in the system's reasoning. It is highly modular and enables drawing information from trusted external sources. ArgLLM-App is publicly available at https://argllm.app, with a video demonstration at https://youtu.be/vzwlGOr0sPM.

</details>


### [31] [Task-Centric Acceleration of Small-Language Models](https://arxiv.org/abs/2602.24174)
*Dor Tsur,Sharon Adar,Ran Levy*

Main category: cs.CL

TL;DR: TASC框架通过两种方法加速小型语言模型：TASC-ft在微调时扩展词汇表包含高频输出n-gram，TASC-spec在推理时使用轻量级无训练推测解码构建n-gram草稿模型。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型常用于高吞吐量、低延迟场景，需要提高效率。现有方法在任务特定应用中存在效率瓶颈，需要更有效的加速方案。

Method: 提出TASC框架：1) TASC-ft：在模型微调时迭代扩展分词器词汇表，包含高频输出n-gram，然后微调模型使用扩展词汇表；2) TASC-spec：推理时轻量级无训练推测解码方法，从任务输出语料构建n-gram草稿模型，混合任务和上下文n-gram信息。

Result: 在多个低输出可变性生成任务上验证了两种方法的有效性，展示了推理效率的一致提升，同时保持了任务性能。

Conclusion: TASC框架为小型语言模型提供了有效的加速方案，TASC-ft通过词汇扩展优化微调，TASC-spec通过无训练推测解码提高推理效率，适用于高吞吐量、低延迟的任务特定应用。

Abstract: Small language models (SLMs) have emerged as efficient alternatives to large language models for task-specific applications. However, they are often employed in high-volume, low-latency settings, where efficiency is crucial. We propose TASC, Task-Adaptive Sequence Compression, a framework for SLM acceleration comprising two use-cases: When performing SLM fine-tuning, we propose TASC-ft, which iteratively enriches the tokenizer vocabulary with high-frequency output n-grams and then fine-tunes the model to utilize the expanded vocabulary. Next, we propose an inference-time method, termed TASC-spec. TASC-spec is a lightweight, training-free speculative decoding method that constructs an n-gram draft model from the task's output corpus, mixing task and context n-gram information.TASC-spec avoids any additional training, while bypassing draft-target vocabulary alignment constraints. We demonstrate the effectiveness of both methods across multiple low output-variability generation tasks. Our methods show consistent improvements in inference efficiency while maintaining task performance.

</details>


### [32] [MT-PingEval: Evaluating Multi-Turn Collaboration with Private Information Games](https://arxiv.org/abs/2602.24188)
*Jacob Eisenstein,Fantine Huot,Adam Fisch,Jonathan Berant,Mirella Lapata*

Main category: cs.CL

TL;DR: 开发了一个评估语言模型在多轮交互中协作能力的方法论，通过需要沟通私有信息的协作游戏进行测试，发现当前SOTA模型在多轮协作规划和执行方面存在显著弱点。


<details>
  <summary>Details</summary>
Motivation: 现实世界通信中主动管理私有信息是关键特征，但当前语言模型在多轮交互协作能力方面缺乏系统评估方法，需要开发相应工具来推动改进。

Method: 提出可扩展的方法论，使用需要沟通私有信息的协作游戏套件，进行交互式扩展分析，将固定token预算分配到可变轮次中。

Result: 在许多情况下，语言模型无法通过交互式协作超越非交互式基线（一个代理总结信息，另一个立即行动），尽管存在明显改进空间。人类在相同任务中能以更高的token效率获得可比的成功率。

Conclusion: 当前SOTA语言模型在多轮协作对话的规划和执行方面仍有显著弱点，没有单一的语言学解释，但人类对话更连贯高效。MT-PingEval工具将推动改进这一能力。

Abstract: We present a scalable methodology for evaluating language models in multi-turn interactions, using a suite of collaborative games that require effective communication about private information. This enables an interactive scaling analysis, in which a fixed token budget is divided over a variable number of turns. We find that in many cases, language models are unable to use interactive collaboration to improve over the non-interactive baseline scenario in which one agent attempts to summarize its information and the other agent immediately acts -- despite substantial headroom. This suggests that state-of-the-art models still suffer from significant weaknesses in planning and executing multi-turn collaborative conversations. We analyze the linguistic features of these dialogues, assessing the roles of sycophancy, information density, and discourse coherence. While there is no single linguistic explanation for the collaborative weaknesses of contemporary language models, we note that humans achieve comparable task success at superior token efficiency by producing dialogues that are more coherent than those produced by most language models. The proactive management of private information is a defining feature of real-world communication, and we hope that MT-PingEval will drive further work towards improving this capability.

</details>


### [33] [Controllable Reasoning Models Are Private Thinkers](https://arxiv.org/abs/2602.24210)
*Haritz Puerto,Haonan Li,Xudong Han,Timothy Baldwin,Iryna Gurevych*

Main category: cs.CL

TL;DR: 通过训练模型在推理过程中遵循指令来增强AI代理的隐私保护能力，在推理轨迹和最终答案中都实施约束，但会带来任务效用与隐私保护之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 基于推理模型的AI代理需要访问敏感用户数据，但其推理轨迹难以控制，可能导致隐私信息无意泄露给外部。需要改进模型在推理过程中的指令遵循能力以增强隐私保护。

Method: 1) 在带有明确推理轨迹限制的新指令遵循数据集上微调模型；2) 引入使用独立LoRA适配器分离推理和答案生成的生成策略；3) 在6个模型（1.7B到14B参数）上评估方法，涵盖两个指令遵循基准和两个隐私基准。

Result: 方法带来显著改进：指令遵循性能提升高达20.9分，隐私基准提升高达51.9个百分点。但改进可能以任务效用为代价，因为推理性能与指令遵循能力之间存在权衡。

Conclusion: 改进推理模型的指令遵循行为可以显著增强隐私保护，为未来隐私感知代理的开发提供了有前景的方向。需要在隐私保护和任务效用之间进行平衡。

Abstract: AI agents powered by reasoning models require access to sensitive user data. However, their reasoning traces are difficult to control, which can result in the unintended leakage of private information to external parties. We propose training models to follow instructions not only in the final answer, but also in reasoning traces, potentially under different constraints. We hypothesize that improving their instruction following abilities in the reasoning traces can improve their privacy-preservation skills. To demonstrate this, we fine-tune models on a new instruction-following dataset with explicit restrictions on reasoning traces. We further introduce a generation strategy that decouples reasoning and answer generation using separate LoRA adapters. We evaluate our approach on six models from two model families, ranging from 1.7B to 14B parameters, across two instruction-following benchmarks and two privacy benchmarks. Our method yields substantial improvements, achieving gains of up to 20.9 points in instruction-following performance and up to 51.9 percentage points on privacy benchmarks. These improvements, however, can come at the cost of task utility, due to the trade-off between reasoning performance and instruction-following abilities. Overall, our results show that improving instruction-following behavior in reasoning models can significantly enhance privacy, suggesting a promising direction for the development of future privacy-aware agents. Our code and data are available at https://github.com/UKPLab/arxiv2026-controllable-reasoning-models

</details>


### [34] [Do LLMs Benefit From Their Own Words?](https://arxiv.org/abs/2602.24287)
*Jenny Y. Huang,Leshem Choshen,Ramon Astudillo,Tamara Broderick,Jacob Andreas*

Main category: cs.CL

TL;DR: 研究发现在多轮对话中，大语言模型并不总是需要依赖自己之前的回答，移除助手侧历史响应可以显著减少上下文长度而不影响回答质量，甚至在某些情况下能提高质量。


<details>
  <summary>Details</summary>
Motivation: 重新审视多轮对话中让大语言模型依赖自己过去回答这一设计选择，探究模型是否真正受益于这种条件依赖。

Method: 使用真实多轮对话数据，对比标准（完整上下文）提示与仅包含用户轮次提示方法，分析三种开放推理模型和一个最先进模型的表现。设计上下文过滤方法，选择性省略助手侧历史。

Result: 移除助手历史响应不会影响大部分轮次的回答质量，可将累积上下文长度减少高达10倍。36.4%的提示是自包含的，许多后续提示仅需当前和先前用户轮次即可回答。当仅用户轮次提示显著优于完整上下文时，发现了上下文污染问题。

Conclusion: 选择性省略助手历史可以改善回答质量同时减少内存消耗，为优化多轮对话系统设计提供了新思路。

Abstract: Multi-turn interactions with large language models typically retain the assistant's own past responses in the conversation history. In this work, we revisit this design choice by asking whether large language models benefit from conditioning on their own prior responses. Using in-the-wild, multi-turn conversations, we compare standard (full-context) prompting with a user-turn-only prompting approach that omits all previous assistant responses, across three open reasoning models and one state-of-the-art model. To our surprise, we find that removing prior assistant responses does not affect response quality on a large fraction of turns. Omitting assistant-side history can reduce cumulative context lengths by up to 10x. To explain this result, we find that multi-turn conversations consist of a substantial proportion (36.4%) of self-contained prompts, and that many follow-up prompts provide sufficient instruction to be answered using only the current user turn and prior user turns. When analyzing cases where user-turn-only prompting substantially outperforms full context, we identify instances of context pollution, in which models over-condition on their previous responses, introducing errors, hallucinations, or stylistic artifacts that propagate across turns. Motivated by these findings, we design a context-filtering approach that selectively omits assistant-side context. Our findings suggest that selectively omitting assistant history can improve response quality while reducing memory consumption.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [35] [Keyword search is all you need: Achieving RAG-Level Performance without vector databases using agentic tool use](https://arxiv.org/abs/2602.23368)
*Shreyas Subramanian,Adewale Akinfaderin,Yanyan Zhang,Ishan Singh,Mani Khanuja,Sandeep Singh,Maira Ladeira Tanke*

Main category: cs.IR

TL;DR: 该研究比较了RAG系统与基于工具增强LLM代理的方法，发现仅使用关键词搜索工具的代理系统能达到传统RAG系统90%以上的性能，且实现更简单、成本更低


<details>
  <summary>Details</summary>
Motivation: 虽然RAG在生成基于知识库的准确响应方面有效，但存在检索质量依赖、集成复杂性和成本等挑战。研究者质疑向量数据库和语义搜索相比简单的代理关键词搜索能为问答任务带来多少额外价值

Method: 系统比较RAG系统与工具增强LLM代理，特别评估当代理只能访问基本关键词搜索工具时的检索机制和响应质量

Result: 实证分析表明，在代理框架中基于工具的关键词搜索实现能达到传统RAG系统90%以上的性能指标，且无需使用固定的向量数据库

Conclusion: 基于工具的关键词搜索方法实现简单、成本效益高，特别适用于需要频繁更新知识库的场景，为RAG提供了可行的替代方案

Abstract: While Retrieval-Augmented Generation (RAG) has proven effective for generating accurate, context-based responses based on existing knowledge bases, it presents several challenges including retrieval quality dependencies, integration complexity and cost. Recent advances in agentic-RAG and tool-augmented LLM architectures have introduced alternative approaches to information retrieval and processing. We question how much additional value vector databases and semantic search bring to RAG over simple, agentic keyword search in documents for question-answering. In this study, we conducted a systematic comparison between RAG-based systems and tool-augmented LLM agents, specifically evaluating their retrieval mechanisms and response quality when the agent only has access to basic keyword search tools. Our empirical analysis demonstrates that tool-based keyword search implementations within an agentic framework can attain over $90\%$ of the performance metrics compared to traditional RAG systems without using a standing vector database. Our approach is simple to implement, cost effective, and is particularly useful in scenarios requiring frequent updates to knowledge bases.

</details>


### [36] [Reason to Contrast: A Cascaded Multimodal Retrieval Framework](https://arxiv.org/abs/2602.23369)
*Xuanming Cui,Hong-You Chen,Hao Yu,Hao Yuan,Zihao Wang,Shlok Kumar Mishra,Hanchao Yu,Yonghuan Yang,Jun Xiao,Ser-Nam Lim,Jianpeng Cheng,Qi Guo,Xiangjun Fan*

Main category: cs.IR

TL;DR: TTE-v2是一个混合多模态检索框架，通过引入基于额外输入token预算的推理驱动性能扩展，在测试时通过重排序实现更丰富的查询-候选交互，显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 传统多模态检索系统主要依赖双编码器架构，性能与嵌入维度紧密相关。虽然TTE方法通过多模态推理生成额外信息token来改进检索，但仍需探索更有效的扩展范式。

Method: 提出TTE-v2混合多模态检索框架：1）在初始检索后引入额外的推理步骤进行重排序；2）重排序阶段提供细粒度监督用于硬负样本挖掘和假负样本过滤；3）创建反馈回路增强上游检索器；4）基于中间推理token扩展实现性能扩展。

Result: 在MMEB-V2基准测试中，TTE-v2-7B达到75.7%的最新SOTA准确率，TTE-v2-2B匹配或超越了使用更大外部数据训练的领先7B模型，证明了token级扩展作为多模态检索替代扩展范式的潜力。

Conclusion: TTE-v2通过推理驱动的性能扩展和级联设计，展示了基于token预算而非模型或嵌入尺寸扩展的新范式，为多模态检索系统提供了更高效的性能提升途径。

Abstract: Traditional multimodal retrieval systems rely primarily on bi-encoder architectures, where performance is closely tied to embedding dimensionality. Recent work, Think-Then-Embed (TTE), shows that incorporating multimodal reasoning to elicit additional informative tokens before embedding can further improve retrieval. In this paper, we extend this paradigm with TTE-v2, a hybrid multimodal retrieval framework that introduces reasoning-driven performance scaling based on additional input token budget rather than model or embedding size. Our approach augments the initial multimodal retrieval with additional reasoning steps for reranking, enabling more expressive query-candidate interactions at test time. The reranking stage further provides fine-grained supervision for hard negative mining and false negative filtering, creating a feedback loop that effectively strengthens the upstream retriever. This cascaded design delivers substantial test-time improvements based on intermediate reasoning token scaling. Experiments on the MMEB-V2 benchmark demonstrate that TTE-v2-7B achieves a new state-of-the-art accuracy of 75.7%, and that TTE-v2-2B matches or surpasses leading 7B models trained with significantly larger external data. Our results highlight the promise of token-wise scaling as an alternative scaling paradigm for multimodal retrieval.

</details>


### [37] [Domain-Partitioned Hybrid RAG for Legal Reasoning: Toward Modular and Explainable Legal AI for India](https://arxiv.org/abs/2602.23371)
*Rakshita Goel,S Pranav Kumar,Anmol Agrawal,Divyan Poddar,Pratik Narang,Dhruv Kumar*

Main category: cs.IR

TL;DR: 为印度法律研究设计的领域划分混合RAG与知识图谱架构，结合专门检索管道和结构化关系知识，显著提升法律问答性能


<details>
  <summary>Details</summary>
Motivation: 印度法律研究涉及冗长且异质的文档，包括法规、宪法条款、刑法典和司法判例。传统的基于关键词或嵌入的检索系统难以支持结构化法律推理，而现有的RAG方法在处理多跳推理、引用链和跨领域依赖方面存在不足。

Method: 提出领域划分的混合RAG与知识图谱架构：1）三个专门RAG管道分别处理最高法院判例法、法规宪法文本和印度刑法典；2）基于Neo4j构建法律知识图谱，捕获案例、法规、IPC条款、法官和引用之间的结构化关系；3）LLM驱动的智能编排器动态路由查询，融合证据生成基于引用的响应。

Result: 在40个问题的合成法律问答基准测试中，混合架构达到70%通过率，显著优于仅RAG基线的37.5%，在完整性和法律推理质量方面有明显改进。

Conclusion: 结合领域划分检索与结构化关系知识为印度司法环境中的高级法律AI系统提供了可扩展且可解释的基础，显著提升了法律问答的性能和质量。

Abstract: Legal research in India involves navigating long and heterogeneous documents spanning statutes, constitutional provisions, penal codes, and judicial precedents, where purely keyword-based or embedding-only retrieval systems often fail to support structured legal reasoning. Recent retrieval augmented generation (RAG) approaches improve grounding but struggle with multi-hop reasoning, citation chaining, and cross-domain dependencies inherent to legal texts.
  We propose a domain partitioned hybrid RAG and Knowledge Graph architecture designed specifically for Indian legal research. The system integrates three specialized RAG pipelines covering Supreme Court case law, statutory and constitutional texts, and the Indian Penal Code, each optimized for domain specific retrieval. To enable relational reasoning beyond semantic similarity, we construct a Neo4j based Legal Knowledge Graph capturing structured relationships among cases, statutes, IPC sections, judges, and citations. An LLM driven agentic orchestrator dynamically routes queries across retrieval modules and the knowledge graph, fusing evidence into grounded and citation aware responses.
  We evaluate the system using a 40 question synthetic legal question answer benchmark curated from authoritative Indian legal sources and assessed via an LLM as a Judge framework. Results show that the hybrid architecture achieves a 70 percent pass rate, substantially outperforming a RAG only baseline at 37.5 percent, with marked improvements in completeness and legal reasoning quality. These findings demonstrate that combining domain partitioned retrieval with structured relational knowledge provides a scalable and interpretable foundation for advanced legal AI systems in the Indian judicial context.

</details>


### [38] [Democratizing GraphRAG: Linear, CPU-Only Graph Retrieval for Multi-Hop QA](https://arxiv.org/abs/2602.23372)
*Qizhi Wang*

Main category: cs.IR

TL;DR: SPRIG是一个CPU友好的GraphRAG系统，使用NER驱动的共现图和个性化PageRank进行多跳检索，无需LLM构建图或GPU推理，在保持Recall@10不变的情况下将查询延迟降低28%。


<details>
  <summary>Details</summary>
Motivation: 现有的GraphRAG系统通常依赖昂贵的LLM构建图结构和GPU密集型推理，这限制了其实际应用和普及。需要一种更轻量、成本效益更高的方法来实现多跳检索。

Method: SPRIG使用轻量级的NER驱动共现图替代LLM图构建，然后采用个性化PageRank（PPR）进行检索。整个流程在CPU上运行，时间复杂度为线性，且无需token处理。

Result: SPRIG在保持Recall@10性能基本不变的情况下，将查询延迟降低了28%。研究还分析了CPU友好图检索何时有助于多跳召回，以及何时强词汇混合方法（RRF）就足够了。

Conclusion: SPRIG为GraphRAG的民主化提供了一条现实路径，无需token成本或GPU要求，能够在保持检索性能的同时显著降低计算开销。

Abstract: GraphRAG systems improve multi-hop retrieval by modeling structure, but many approaches rely on expensive LLM-based graph construction and GPU-heavy inference. We present SPRIG (Seeded Propagation for Retrieval In Graphs), a CPU-only, linear-time, token-free GraphRAG pipeline that replaces LLM graph building with lightweight NER-driven co-occurrence graphs and uses Personalized PageRank (PPR) for 28% with negligible Recall@10 changes. The results characterize when CPU-friendly graph retrieval helps multi-hop recall and when strong lexical hybrids (RRF) are sufficient, outlining a realistic path to democratizing GraphRAG without token costs or GPU requirements.

</details>


### [39] [Higress-RAG: A Holistic Optimization Framework for Enterprise Retrieval-Augmented Generation via Dual Hybrid Retrieval, Adaptive Routing, and CRAG](https://arxiv.org/abs/2602.23374)
*Weixi Lin*

Main category: cs.IR

TL;DR: Higress RAG MCP Server通过全链路优化解决企业级RAG系统三大挑战：复杂查询检索精度低、生成阶段幻觉率高、实时应用延迟高


<details>
  <summary>Details</summary>
Motivation: 虽然RAG范式将LLM集成到企业知识管理系统，但从概念验证到生产级系统面临三个主要挑战：复杂查询检索精度低、生成阶段幻觉率高、实时应用延迟高

Method: 基于Model Context Protocol构建分层架构，采用自适应路由、语义缓存、混合检索和校正RAG技术，具体包括Higress-Native Splitter进行结构感知数据摄取、使用RRF融合稠密和稀疏检索信号、50毫秒延迟的语义缓存机制

Result: 在Higress技术文档和博客上的实验验证了系统架构的鲁棒性，通过优化从预检索查询重写到后检索校正评估的整个检索生命周期，提供了可扩展、抗幻觉的企业AI部署方案

Conclusion: Higress RAG系统通过全链路优化策略，为企业级AI部署提供了可扩展、抗幻觉的解决方案，解决了从概念验证到生产级RAG系统的关键瓶颈

Abstract: The integration of Large Language Models (LLMs) into enterprise knowledge management systems has been catalyzed by the Retrieval-Augmented Generation (RAG) paradigm, which augments parametric memory with non-parametric external data. However, the transition from proof-of-concept to production-grade RAG systems is hindered by three persistent challenges: low retrieval precision for complex queries, high rates of hallucination in the generation phase, and unacceptable latency for real-time applications. This paper presents a comprehensive analysis of the Higress RAG MCP Server, a novel, enterprise-centric architecture designed to resolve these bottlenecks through a "Full-Link Optimization" strategy. Built upon the Model Context Protocol (MCP), the system introduces a layered architecture that orchestrates a sophisticated pipeline of Adaptive Routing, Semantic Caching, Hybrid Retrieval, and Corrective RAG (CRAG). We detail the technical implementation of key innovations, including the Higress-Native Splitter for structure-aware data ingestion, the application of Reciprocal Rank Fusion (RRF) for merging dense and sparse retrieval signals, and a 50ms-latency Semantic Caching mechanism with dynamic thresholding. Experimental evaluations on domain-specific Higress technical documentation and blogs verify the system's architectural robustness. The results demonstrate that by optimizing the entire retrieval lifecycle - from pre-retrieval query rewriting to post-retrieval corrective evaluation - the Higress RAG system offers a scalable, hallucination-resistant solution for enterprise AI deployment.

</details>


### [40] [Cross-Representation Knowledge Transfer for Improved Sequential Recommendations](https://arxiv.org/abs/2602.23471)
*Artur Gimranov,Viacheslav Yusupov,Elfat Sabitov,Tatyana Matveeva,Anton Lysenko,Ruslan Israfilov,Evgeny Frolov*

Main category: cs.IR

TL;DR: 结合Transformer和GNN的新框架，通过同时编码交互图的结构依赖和动态变化，在下一项预测任务中超越纯序列和纯图方法


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：Transformer虽然能捕捉序列依赖但将序列元素孤立处理，GNN能显式建模元素间关系但难以捕捉随时间的变化。需要结合两者优势来解决下一项预测任务

Method: 提出新框架，结合Transformer和GNN，对齐不同表示，同时编码交互图中的结构依赖并跟踪其动态变化

Result: 在多个公开数据集上的实验表明，该框架在推荐质量方面一致优于纯序列方法、纯图方法以及最近结合两种信号的方法

Conclusion: 结合Transformer和GNN的框架能够有效解决下一项预测任务，通过同时建模结构依赖和动态变化，显著提升推荐性能

Abstract: Transformer architectures, capable of capturing sequential dependencies in the history of user interactions, have become the dominant approach in sequential recommender systems. Despite their success, such models consider sequence elements in isolation, implicitly accounting for the complex relationships between them. Graph neural networks, in contrast, explicitly model these relationships through higher order interactions but are often unable to adequately capture their evolution over time, limiting their use for predicting the next interaction. To fill this gap, we present a new framework that combines transformers and graph neural networks and aligns different representations for solving next-item prediction task. Our solution simultaneously encodes structural dependencies in the interaction graph and tracks their dynamic change. Experimental results on a number of open datasets demonstrate that the proposed framework consistently outperforms both pure sequential and graph approaches in terms of recommendation quality, as well as recent methods that combine both types of signals.

</details>


### [41] [Unified Learning-to-Rank for Multi-Channel Retrieval in Large-Scale E-Commerce Search](https://arxiv.org/abs/2602.23530)
*Aditya Gaydhani,Guangyue Xu,Dhanush Kamath,Ankit Singh,Alex Li*

Main category: cs.IR

TL;DR: 提出一个统一的多通道检索融合模型，将异构检索通道的融合问题重新定义为查询相关的学习排序任务，显著提升电商搜索的用户转化率。


<details>
  <summary>Details</summary>
Motivation: 大规模电商搜索需要从海量商品中检索多样化商品（畅销品、新品、趋势品等），现有基于固定权重的排名融合方法（如RRF）无法考虑查询特定的通道效用和跨通道交互，限制了业务KPI优化。

Method: 将多通道融合重新定义为查询相关的学习排序问题，提出统一的通道感知学习排序模型，联合优化点击、加购、购买等指标并融入通道特定目标，同时引入近期用户行为信号捕捉短期意图变化。

Result: 在线A/B实验显示，该方法优于基于排名的融合方法，用户转化率提升+2.85%，满足生产延迟要求（p95延迟低于50ms），已在Target.com部署。

Conclusion: 将多通道检索融合重新定义为查询相关的学习排序问题，通过统一模型有效融合异构检索通道，显著提升电商搜索的转化性能，同时满足实际生产环境的延迟约束。

Abstract: Large-scale e-commerce search must surface a broad set of items from a vast catalog, ranging from bestselling products to new, trending, or seasonal items. Modern systems therefore rely on multiple specialized retrieval channels to surface products, each designed to satisfy a specific objective. A key challenge is how to effectively merge documents from these heterogeneous channels into a single ranked list under strict latency constraints while optimizing for business KPIs such as user conversion. Rank-based fusion methods such as Reciprocal Rank Fusion (RRF) and Weighted Interleaving rely on fixed global channel weights and treat channels independently, failing to account for query-specific channel utility and cross-channel interactions. We observe that multi-channel fusion can be reformulated as a query-dependent learning-to-rank problem over heterogeneous candidate sources. In this paper, we propose a unified ranking model that learns to merge and rank documents from multiple retrieval channels. We formulate the problem as a channel-aware learning-to-rank task that jointly optimizes clicks, add-to-carts, and purchases while incorporating channel-specific objectives. We further incorporate recent user behavioral signals to capture short-term intent shifts that are critical for improving conversion in multi-channel ranking. Our online A/B experiments show that the proposed approach outperforms rank-based fusion methods, leading to a +2.85\% improvement in user conversion. The model satisfies production latency requirements, achieving a p95 latency of under 50\,ms, and is deployed on Target.com.

</details>


### [42] [Synthetic Data Powers Product Retrieval for Long-tail Knowledge-Intensive Queries in E-commerce Search](https://arxiv.org/abs/2602.23620)
*Gui Ling,Weiyuan Li,Yue Jiang,Wenjun Peng,Xingxian Liu,Dongshuai Li,Fuyu Lv,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: 提出一个针对长尾知识密集型查询的高效数据合成框架，通过将强大离线查询重写模型的能力蒸馏到在线检索系统中来提升电商搜索效果


<details>
  <summary>Details</summary>
Motivation: 现有电商产品检索系统在处理主流查询时表现良好，但在处理长尾查询（特别是知识密集型查询）时面临挑战。这些查询具有多样化的语言模式，往往缺乏明确的购买意图，需要领域特定的知识推理来准确理解。同时，这些查询缺乏可靠的行为日志，使得检索优化成为持久难题。

Method: 提出一个高效的数据合成框架，核心思想是将强大的离线查询重写模型的能力隐式蒸馏到高效的在线检索系统中。利用LLM的强大语言理解能力，训练一个具有多重奖励信号的多候选查询重写模型，并通过强大的离线检索流程捕获其重写能力，生成精心策划的查询-产品对。这种设计减轻了重写查询的分布偏移问题。

Result: 实验表明，无需任何额外技巧，仅将这种合成数据纳入检索模型训练就能带来显著改进。在线Side-By-Side人工评估结果显示用户搜索体验有显著提升。

Conclusion: 该框架有效解决了长尾知识密集型查询的检索挑战，通过数据合成和模型能力蒸馏的方法，显著提升了电商搜索系统的整体性能，特别是针对传统方法难以处理的查询类型。

Abstract: Product retrieval is the backbone of e-commerce search: for each user query, it identifies a high-recall candidate set from billions of items, laying the foundation for high-quality ranking and user experience. Despite extensive optimization for mainstream queries, existing systems still struggle with long-tail queries, especially knowledge-intensive ones. These queries exhibit diverse linguistic patterns, often lack explicit purchase intent, and require domain-specific knowledge reasoning for accurate interpretation. They also suffer from a shortage of reliable behavioral logs, which makes such queries a persistent challenge for retrieval optimization. To address these issues, we propose an efficient data synthesis framework tailored to retrieval involving long-tail, knowledge-intensive queries. The key idea is to implicitly distill the capabilities of a powerful offline query-rewriting model into an efficient online retrieval system. Leveraging the strong language understanding of LLMs, we train a multi-candidate query rewriting model with multiple reward signals and capture its rewriting capability in well-curated query-product pairs through a powerful offline retrieval pipeline. This design mitigates distributional shift in rewritten queries, which might otherwise limit incremental recall or introduce irrelevant products. Experiments demonstrate that without any additional tricks, simply incorporating this synthetic data into retrieval model training leads to significant improvements. Online Side-By-Side (SBS) human evaluation results indicate a notable enhancement in user search experience.

</details>


### [43] [Learning to Reflect and Correct: Towards Better Decoding Trajectories for Large-Scale Generative Recommendation](https://arxiv.org/abs/2602.23639)
*Haibo Xing,Hao Deng,Lingyu Mu,Jinxin Hu,Yu Zhang,Xiaoyi Zeng,Jing Zhang*

Main category: cs.IR

TL;DR: GRC是一个生成式推荐的结构化反思-修正框架，通过将解码过程扩展为生成-反思-修正三阶段，结合强化学习和动态调度策略，显著提升推荐质量。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐模型通常采用单次解码，缺乏显式修正机制，导致早期偏差累积并最终降低推荐质量。

Method: 1. 提出结构化反思-修正框架，将解码分解为初始草稿生成、多粒度反思、反思引导修正三个阶段；2. 使用GRPO强化学习优化整个GRC轨迹；3. 提出基于熵的反思调度策略，在束搜索中动态分配修正预算。

Result: 在真实数据集上，GRC在六个SOTA基线中提升高达15.74%；在线A/B测试显示广告收入提升1.79%，仅带来适度延迟开销。

Conclusion: GRC通过结构化反思-修正机制有效解决了生成式推荐中的早期偏差累积问题，在大规模工业推荐中具有显著实用价值。

Abstract: Generative Recommendation (GR) has become a promising paradigm for large-scale recommendation systems. However, existing GR models typically perform single-pass decoding without explicit refinement, causing early deviations to accumulate and ultimately degrade recommendation quality. To tackle this problem, we propose GRC, which is, to our knowledge, the first structured reflection-correction framework for GR that extends standard decoding into a Generation-Reflection-Correction (GRC) process. Concretely, GRC introduces a supervised reflection-correction template that decomposes the decoding process into initial draft generation, multi-granular reflection, and reflection-guided correction, thereby enabling structured reflection and correction in the semantic token space. To further explore the enlarged refinement space introduced by the GRC process, we optimize the entire GRC trajectory with GRPO-based reinforcement learning, under a carefully designed reward function with token-level and trajectory-level signals. For efficient online serving, we propose an Entropy-Guided Reflection Scheduling (EGRS) strategy that dynamically allocates more correction budget to high-uncertainty decoding trajectories during beam search. Extensive experiments on real-world datasets show that GRC consistently outperforms six state-of-the-art baselines by up to 15.74%, and online A/B tests demonstrate its substantial practical value in large-scale industrial recommendation, delivering a 1.79% lift in advertising revenue with only modest latency overhead.

</details>


### [44] [Geodesic Semantic Search: Learning Local Riemannian Metrics for Citation Graph Retrieval](https://arxiv.org/abs/2602.23665)
*Brandon Yee,Lucas Wang,Kundana Kommini,Krishna Sharma*

Main category: cs.IR

TL;DR: GSS通过学习引文图上节点特定的黎曼度量，实现几何感知的语义检索，相比传统欧氏距离检索在Recall@20上提升23%，同时提供可解释的引用路径。


<details>
  <summary>Details</summary>
Motivation: 传统基于嵌入的检索使用固定的欧氏距离，无法捕捉引文图中复杂的语义关系。GSS旨在通过几何感知的检索方法，更好地理解学术文献之间的语义联系。

Method: 为每个节点学习低秩度量张量，构建局部半正定度量矩阵。使用多源Dijkstra算法计算测地距离，结合最大边际相关性重排序和路径一致性过滤。采用分层粗到细搜索和k-means池化降低计算成本。

Result: 在169K论文的引文预测基准测试中，Recall@20相对SPECTER+FAISS基线提升23%。分层搜索将计算成本降低4倍，同时保持97%的检索质量。提供可解释的引用路径。

Conclusion: GSS通过几何感知的检索方法显著提升了引文预测性能，在保持可解释性的同时降低了计算成本，为学术文献检索提供了新的有效方法。

Abstract: We present Geodesic Semantic Search (GSS), a retrieval system that learns node-specific Riemannian metrics on citation graphs to enable geometry-aware semantic search. Unlike standard embedding-based retrieval that relies on fixed Euclidean distances, \gss{} learns a low-rank metric tensor $\mL_i \in \R^{d \times r}$ at each node, inducing a local positive semi-definite metric $\mG_i = \mL_i \mL_i^\top + \eps \mI$. This parameterization guarantees valid metrics while keeping the model tractable. Retrieval proceeds via multi-source Dijkstra on the learned geodesic distances, followed by Maximal Marginal Relevance reranking and path coherence filtering. On citation prediction benchmarks with 169K papers, \gss{} achieves 23\% relative improvement in Recall@20 over SPECTER+FAISS baselines while providing interpretable citation paths. Our hierarchical coarse-to-fine search with k-means pooling reduces computational cost by 4$\times$ compared to flat geodesic search while maintaining 97\% retrieval quality. We provide theoretical analysis of when geodesic distances outperform direct similarity, characterize the approximation quality of low-rank metrics, and validate predictions empirically. Code and trained models are available at https://github.com/YCRG-Labs/geodesic-search.

</details>


### [45] [FuXi-Linear: Unleashing the Power of Linear Attention in Long-term Time-aware Sequential Recommendation](https://arxiv.org/abs/2602.23671)
*Yufei Ye,Wei Guo,Hao Wang,Luankang Zhang,Heng Chang,Hong Zhu,Yuyang Ye,Yong Liu,Defu Lian,Enhong Chen*

Main category: cs.IR

TL;DR: FuXi-Linear：一种用于长序列推荐的线性复杂度模型，通过独立处理时序信号和语义信号，在保持推荐质量的同时显著提升推理速度


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力机制的推荐系统存在二次复杂度问题，限制了处理长用户序列的能力并降低了推理速度。线性注意力虽然是一种有前景的替代方案，但面临三个关键挑战：1) 时序信号常被忽视或通过简单耦合集成，导致时序和语义信号相互干扰；2) 现有线性框架提供的位置信息不足；3) 主要关注短序列和浅层架构。

Method: 提出FuXi-Linear模型，包含两个关键组件：1) 时序保持通道：独立使用时序数据计算周期性注意力权重，防止时序和语义信号之间的串扰；2) 线性位置通道：在线性复杂度内通过可学习核集成位置信息。模型还展示了在千长度尺度上的强大幂律缩放特性。

Result: 在数千个token的序列上进行的广泛实验表明，FuXi-Linear在推荐质量上优于最先进的模型，同时在预填充阶段实现高达10倍的加速，在解码阶段实现高达21倍的加速，相比竞争基线。

Conclusion: FuXi-Linear通过独立处理时序和语义信号，解决了线性注意力在推荐系统中的关键挑战，实现了高效的长序列推荐，并在推荐质量和推理速度方面都取得了显著提升。

Abstract: Modern recommendation systems primarily rely on attention mechanisms with quadratic complexity, which limits their ability to handle long user sequences and slows down inference. While linear attention is a promising alternative, existing research faces three critical challenges: (1) temporal signals are often overlooked or integrated via naive coupling that causes mutual interference between temporal and semantic signals while neglecting behavioral periodicity; (2) insufficient positional information provided by existing linear frameworks; and (3) a primary focus on short sequences and shallow architectures. To address these issues, we propose FuXi-Linear, a linear-complexity model designed for efficient long-sequence recommendation. Our approach introduces two key components: (1) a Temporal Retention Channel that independently computes periodic attention weights using temporal data, preventing crosstalk between temporal and semantic signals; (2) a Linear Positional Channel that integrates positional information through learnable kernels within linear complexity. Moreover, we demonstrate that FuXi-Linear exhibits a robust power-law scaling property at a thousand-length scale, a characteristic largely unexplored in prior linear recommendation studies. Extensive experiments on sequences of several thousand tokens demonstrate that FuXi-Linear outperforms state-of-the-art models in recommendation quality, while achieving up to 10$\times$ speedup in the prefill stage and up to 21$\times$ speedup in the decode stage compared to competitive baselines. Our code has been released in a public repository https://github.com/USTC-StarTeam/fuxi-linear.

</details>


### [46] [Recommending Search Filters To Improve Conversions At Airbnb](https://arxiv.org/abs/2602.23717)
*Hao Li,Kedar Bellare,Siyu Yang,Sherry Chen,Liwei He,Stephanie Moyerman,Sanjeev Katariya*

Main category: cs.IR

TL;DR: Airbnb应用机器学习技术推荐搜索过滤器，直接针对预订转化率，成功部署并提升了预订转化


<details>
  <summary>Details</summary>
Motivation: 虽然搜索过滤器旨在促进在线市场转化，但其对转化的直接影响在现有文献中研究不足。Airbnb需要帮助客人从多样化的房源中找到理想住宿并完成预订。

Method: 提出了一个建模框架，直接针对下漏斗转化（预订），通过推荐中间工具（搜索过滤器）。设计了从零开始构建的过滤器推荐系统，解决了冷启动和严格服务要求等挑战。

Result: 开发的过滤器推荐系统已在Airbnb成功部署，支持多个用户界面，并通过在线A/B测试验证了预订转化率的提升。消融研究进一步验证了方法和关键设计选择的有效性。

Conclusion: 通过专注于以转化为导向的过滤器推荐，确保搜索过滤器在Airbnb实现其最终目的——帮助客人找到并预订理想住宿。

Abstract: Airbnb, a two-sided online marketplace connecting guests and hosts, offers a diverse and unique inventory of accommodations, experiences, and services. Search filters play an important role in helping guests navigate this variety by refining search results to align with their needs. Yet, while search filters are designed to facilitate conversions in online marketplaces, their direct impact on driving conversions remains underexplored in the existing literature.
  This paper bridges this gap by presenting a novel application of machine learning techniques to recommend search filters aimed at improving booking conversions. We introduce a modeling framework that directly targets lower-funnel conversions (bookings) by recommending intermediate tools, i.e. search filters. Leveraging the framework, we designed and built the filter recommendation system at Airbnb from the ground up, addressing challenges like cold start and stringent serving requirements.
  The filter recommendation system we developed has been successfully deployed at Airbnb, powering multiple user interfaces and driving incremental booking conversion lifts, as validated through online A/B testing. An ablation study further validates the effectiveness of our approach and key design choices. By focusing on conversion-oriented filter recommendations, our work ensures that search filters serve their ultimate purpose at Airbnb - helping guests find and book their ideal accommodations.

</details>


### [47] [UniFAR: A Unified Facet-Aware Retrieval Framework for Scientific Documents](https://arxiv.org/abs/2602.23766)
*Zheng Dou,Zhao Zhang,Deqing Wang,Yikun Ban,Fuzhen Zhuang*

Main category: cs.IR

TL;DR: 提出UniFAR框架，统一支持文档-文档和问题-文档的科学文献检索，通过多粒度聚合、可学习方面锚点和联合训练解决现有方法在问题驱动检索中的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现有科学文档检索方法主要基于文档中心表示，但LLM和RAG的兴起使检索转向问题驱动模式，导致文档中心模型与问题驱动检索之间存在系统性不匹配，包括输入粒度、语义焦点和训练信号等方面的差异。

Method: 提出UniFAR统一方面感知检索框架：1）通过自适应多粒度聚合协调粒度差异；2）通过可学习方面锚点对齐文档结构与问题意图；3）通过联合训练统一文档-文档和问题-文档的监督信号。

Result: 实验结果表明，UniFAR在多个检索任务和基础模型上持续优于先前方法，证实了其有效性和通用性。

Conclusion: UniFAR成功解决了文档中心模型与问题驱动检索之间的不匹配问题，为科学文档检索提供了统一的解决方案，在多个任务上表现出优越性能。

Abstract: Existing scientific document retrieval (SDR) methods primarily rely on document-centric representations learned from inter-document relationships for document-document (doc-doc) retrieval. However, the rise of LLMs and RAG has shifted SDR toward question-driven retrieval, where documents are retrieved in response to natural-language questions (q-doc). This change has led to systematic mismatches between document-centric models and question-driven retrieval, including (1) input granularity (long documents vs. short questions), (2) semantic focus (scientific discourse structure vs. specific question intent), and (3) training signals (citation-based similarity vs. question-oriented relevance). To this end, we propose UniFAR, a Unified Facet-Aware Retrieval framework to jointly support doc-doc and q-doc SDR within a single architecture. UniFAR reconciles granularity differences through adaptive multi-granularity aggregation, aligns document structure with question intent via learnable facet anchors, and unifies doc-doc and q-doc supervision through joint training. Experimental results show that UniFAR consistently outperforms prior methods across multiple retrieval tasks and base models, confirming its effectiveness and generality.

</details>


### [48] [HotelQuEST: Balancing Quality and Efficiency in Agentic Search](https://arxiv.org/abs/2602.23949)
*Guy Hadad,Shadi Iskander,Oren Kalinsky,Sofia Tolmach,Ran Levy,Haggai Roitman*

Main category: cs.IR

TL;DR: HotelQuEST 是一个包含214个酒店搜索查询的基准测试，涵盖从简单事实请求到复杂查询的完整难度范围，专门用于评估具有未明确偏好查询的智能搜索系统。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的智能搜索系统虽然性能优秀，但现有基准测试主要关注质量，忽视了实际部署中至关重要的效率因素。同时，真实世界用户查询常包含未明确的偏好，这一挑战在当前智能搜索评估中尚未充分探索。

Method: 提出 HotelQuEST 基准测试，包含214个酒店搜索查询，覆盖完整的查询难度范围。为了解决未明确偏好的评估挑战，收集了注释者隐式偏好的明确说明用于评估。

Result: 基于大语言模型的智能体比传统检索器获得更高准确率，但由于冗余工具调用和次优的路由决策（未能根据查询复杂度匹配模型能力），成本显著更高。

Conclusion: 分析揭示了当前智能搜索系统的效率低下问题，并展示了成本感知优化的巨大潜力。需要平衡质量和效率以实现实用的智能搜索系统。

Abstract: Agentic search has emerged as a promising paradigm for adaptive retrieval systems powered by large language models (LLMs). However, existing benchmarks primarily focus on quality, overlooking efficiency factors that are critical for real-world deployment. Moreover, real-world user queries often contain underspecified preferences, a challenge that remains largely underexplored in current agentic search evaluation. As a result, many agentic search systems remain impractical despite their impressive performance. In this work, we introduce HotelQuEST, a benchmark comprising 214 hotel search queries that range from simple factual requests to complex queries, enabling evaluation across the full spectrum of query difficulty. We further address the challenge of evaluating underspecified user preferences by collecting clarifications that make annotators' implicit preferences explicit for evaluation. We find that LLM-based agents achieve higher accuracy than traditional retrievers, but at substantially higher costs due to redundant tool calls and suboptimal routing that fails to match query complexity to model capability. Our analysis exposes inefficiencies in current agentic search systems and demonstrates substantial potential for cost-aware optimization.

</details>


### [49] [RAD-DPO: Robust Adaptive Denoising Direct Preference Optimization for Generative Retrieval in E-commerce](https://arxiv.org/abs/2602.23964)
*Zhiguo Chen,Guohao Sun,Yiming Qiu,Xingzhi Yao,Mingming Li,Huimu Wang,Yangqi Zhang,Songlin Wang,Sulong Xu*

Main category: cs.IR

TL;DR: RAD-DPO：一种针对生成式检索中语义ID对齐的改进方法，通过梯度分离、噪声鲁棒性优化和多标签对比学习解决DPO在结构化语义ID中的三个主要限制


<details>
  <summary>Details</summary>
Motivation: 生成式检索在电商搜索中通过自回归解码语义ID来检索商品，但难以对齐复杂用户偏好。直接偏好优化（DPO）虽然提供高效对齐方案，但应用于结构化语义ID时存在三个问题：1）惩罚共享层次前缀导致梯度冲突；2）对隐式反馈中的噪声伪负例敏感；3）多标签查询中对多个相关商品产生概率"挤压效应"

Method: 提出RAD-DPO方法，包含三个关键技术：1）令牌级梯度分离保护前缀结构；2）基于相似性的动态奖励加权减轻标签噪声；3）集成多标签全局对比目标与全局监督微调损失，显式扩展正例覆盖

Result: 在大规模电商平台上进行的大量离线实验和在线A/B测试表明，该方法在排序质量和训练效率方面均有显著提升

Conclusion: RAD-DPO有效解决了DPO在结构化语义ID对齐中的局限性，通过创新的梯度分离、噪声鲁棒性和多标签对比学习机制，显著提升了生成式检索在电商搜索中的性能

Abstract: Generative Retrieval (GR) has emerged as a powerful paradigm in e-commerce search, retrieving items via autoregressive decoding of Semantic IDs (SIDs). However, aligning GR with complex user preferences remains challenging. While Direct Preference Optimization (DPO) offers an efficient alignment solution, its direct application to structured SIDs suffers from three limitations: (i) it penalizes shared hierarchical prefixes, causing gradient conflicts; (ii) it is vulnerable to noisy pseudo-negatives from implicit feedback; and (iii) in multi-label queries with multiple relevant items, it exacerbates a probability "squeezing effect" among valid candidates. To address these issues, we propose RAD-DPO, which introduces token-level gradient detachment to protect prefix structures, similarity-based dynamic reward weighting to mitigate label noise, and a multi-label global contrastive objective integrated with global SFT loss to explicitly expand positive coverage. Extensive offline experiments and online A/B testing on a large-scale e-commerce platform demonstrate significant improvements in ranking quality and training efficiency.

</details>


### [50] [Towards Efficient and Generalizable Retrieval: Adaptive Semantic Quantization and Residual Knowledge Transfer](https://arxiv.org/abs/2602.23978)
*Huimu Wang,Xingzhi Yao,Yiming Qiu,Qinghong Zhang,Haotian Wang,Yufan Cui,Songlin Wang,Sulong Xu,Mingming Li*

Main category: cs.IR

TL;DR: 提出SA^2CRQ框架，通过自适应量化解决语义ID生成检索中头部项目ID冲突和尾部项目泛化不足的问题，在冷启动检索场景表现优异。


<details>
  <summary>Details</summary>
Motivation: 语义ID生成检索在工业应用中面临持续权衡：头部项目易受ID冲突影响下游任务，而数据稀疏的尾部项目（包括冷启动项目）泛化能力有限。需要同时解决这两个问题。

Method: 提出Anchored Curriculum with Sequential Adaptive Quantization (SA^2CRQ)框架：1) SARQ组件根据项目路径熵动态分配代码长度，为头部项目分配更长、更具区分性的ID，为尾部项目分配更短、更易泛化的ID；2) ACRQ组件利用从头部项目学习的冻结语义流形来正则化和加速尾部项目的表示学习。

Result: 在大型工业搜索系统和多个公共数据集上的实验结果表明，SA^2CRQ相比现有基线方法取得了一致的改进，特别是在冷启动检索场景中表现突出。

Conclusion: SA^2CRQ框架通过自适应量化和锚定课程学习，有效平衡了头部项目的ID冲突和尾部项目的泛化问题，为工业级语义ID生成检索提供了有效的解决方案。

Abstract: While semantic ID-based generative retrieval enables efficient end-to-end modeling in industrial applications, these methods face a persistent trade-off: head items are susceptible to ID collisions that negatively impact downstream tasks, whereas data-sparse tail items, including cold-start items, exhibit limited generalization. To address this issue, we propose the Anchored Curriculum with Sequential Adaptive Quantization (SA^2CRQ) framework. The framework introduces Sequential Adaptive Residual Quantization (SARQ) to dynamically allocate code lengths based on item path entropy, assigning longer, discriminative IDs to head items and shorter, generalizable IDs to tail items. To mitigate data sparsity, the Anchored Curriculum Residual Quantization (ACRQ) component utilizes a frozen semantic manifold learned from head items to regularize and accelerate the representation learning of tail items. Experimental results from a large-scale industrial search system and multiple public datasets indicate that SA^2CRQ yields consistent improvements over existing baselines, particularly in cold-start retrieval scenarios.

</details>


### [51] [Robust Aggregation for Federated Sequential Recommendation with Sparse and Poisoned Data](https://arxiv.org/abs/2602.23982)
*Minh Hieu Nguyen*

Main category: cs.IR

TL;DR: 针对联邦序列推荐中的稀疏数据和对抗攻击问题，提出了一种防御感知的聚合框架，通过识别不可靠客户端更新并稳定嵌入表示来提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 联邦序列推荐将模型训练分布在用户设备上以保护隐私，但面临两个交织的困难：1) 单个客户端通常只提供短且高度稀疏的交互序列，限制了学习用户表示的可靠性；2) 联邦优化过程容易受到恶意或损坏客户端更新的攻击，其中被污染的梯度会显著扭曲全局模型。这些挑战在序列推荐中尤为严重，因为时间动态进一步复杂化了信号聚合。

Method: 提出一个针对稀疏和对抗条件下联邦序列推荐的鲁棒聚合框架：1) 引入防御感知聚合机制，识别并降低不可靠客户端更新的权重，同时保留来自稀疏但良性参与者的信息信号；2) 融入表示级约束以稳定用户和物品嵌入，防止被污染或异常的贡献主导全局参数空间；3) 集成序列感知正则化，在有限的本地观察下保持用户建模的时间一致性。

Result: 未在摘要中明确说明具体实验结果，但论文提出了一个完整的鲁棒聚合框架来解决联邦序列推荐中的稀疏性和对抗性问题。

Conclusion: 该论文为联邦序列推荐在稀疏和对抗性条件下的鲁棒训练提供了一个有效的解决方案，通过防御感知聚合、表示级约束和序列感知正则化相结合，能够在保护隐私的同时提高推荐系统的可靠性和安全性。

Abstract: Federated sequential recommendation distributes model training across user devices so that behavioural data remains local, reducing privacy risks. Yet, this setting introduces two intertwined difficulties. On the one hand, individual clients typically contribute only short and highly sparse interaction sequences, limiting the reliability of learned user representations. On the other hand, the federated optimisation process is vulnerable to malicious or corrupted client updates, where poisoned gradients can significantly distort the global model. These challenges are particularly severe in sequential recommendation, where temporal dynamics further complicate signal aggregation. To address this problem, we propose a robust aggregation framework tailored for federated sequential recommendation under sparse and adversarial conditions. Instead of relying on standard averaging, our method introduces a defence-aware aggregation mechanism that identifies and down-weights unreliable client updates while preserving informative signals from sparse but benign participants. The framework incorporates representation-level constraints to stabilise user and item embeddings, preventing poisoned or anomalous contributions from dominating the global parameter space. In addition, we integrate sequence-aware regularisation to maintain temporal coherence in user modelling despite limited local observations.

</details>


### [52] [Colour Contrast on the Web: A WCAG 2.1 Level AA Compliance Audit of Common Crawl's Top 500 Domains](https://arxiv.org/abs/2602.24067)
*Thom Vaughan,Pedro Ortiz Suarez*

Main category: cs.IR

TL;DR: 对500个最常访问网站主页进行大规模自动化WCAG色彩对比度审计，发现40.9%的色彩配对未能达到4.5:1对比度标准，仅20.4%网站完全合规


<details>
  <summary>Details</summary>
Motivation: 评估主流网站的色彩对比度合规情况，了解WCAG 2.1/2.2 Level AA标准的实际实施状况，识别网站可访问性中的色彩对比度障碍

Method: 使用Common Crawl的CC-MAIN-2026-08存档数据，对500个最常访问的注册域名进行静态CSS分析，从WARC档案中提取页面内容而非实时爬取，分析240个主页的4,327个前景/背景色彩配对

Result: 1,771个色彩配对（40.9%）未能达到4.5:1对比度阈值；网站平均通过率为62.7%；仅20.4%的网站在所有检测到的色彩配对中完全合规；不同域名类别间存在显著差异

Conclusion: 色彩对比度仍然是主流网站中广泛存在的可访问性障碍，合规情况存在显著差异，需要持续关注和改进

Abstract: We present a large-scale automated audit of WCAG 2.1/2.2 Level AA colour contrast compliance across the 500 most frequently crawled registered domains in Common Crawl's CC-MAIN-2026-08 February 2026 crawl archive. Rather than conducting a live crawl, all page content was sourced from Common Crawl's open WARC archives, ensuring reproducibility and eliminating any load on target web servers. Our static CSS analysis of 240 homepages identified 4,327 unique foreground/background colour pairings, of which 1,771 (40.9%) failed to meet the 4.5:1 contrast ratio threshold for normal text. The median per-site pass rate was 62.7%, with 20.4% of sites achieving full compliance across all detected colour pairings. These findings suggest that colour contrast remains a widespread accessibility barrier on the most prominent websites, with significant variation across domain categories.

</details>


### [53] [Recommendation Algorithms: A Comparative Study in Movie Domain](https://arxiv.org/abs/2602.24125)
*Rohit Chivukula,T. Jaya Lakshmi,Hemlata Sharma,C. H. S. N. P. Sairam Rallabandi*

Main category: cs.IR

TL;DR: 该研究将电影推荐视为回归任务，使用Netflix数据集提取新特征，并比较多种推荐算法，发现基于矩阵分解的算法在RMSE指标上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 智能推荐系统能显著提升电商平台收入，电影推荐系统对用户观影体验至关重要。现有推荐方法众多，但本研究旨在探索将推荐作为回归任务，通过提取新颖特征来改进推荐性能。

Method: 1. 使用Netflix挑战数据集进行实验；2. 进行探索性数据分析以理解用户评分行为和电影特征；3. 提取多种特征：聚合特征、基于矩阵分解的特征、用户和电影相似性特征；4. 使用XGBoost回归算法，并结合Python Surprise库中的K近邻和矩阵分解算法进行推荐。

Result: 基于矩阵分解的算法在均方根误差（RMSE）指标上提供了最佳推荐结果，表明该方法在预测用户对电影的评分方面最准确。

Conclusion: 将推荐视为回归任务并提取新颖特征的方法是有效的，矩阵分解算法在电影推荐任务中表现最优，为改进推荐系统提供了有价值的见解。

Abstract: Intelligent recommendation systems have clearly increased the revenue of well-known e-commerce firms. Users receive product recommendations from recommendation systems. Cinematic recommendations are made to users by a movie recommendation system. There have been numerous approaches to the problem of recommendation in the literature. It is viewed as a regression task in this research. A regression model was built using novel properties extracted from the dataset and used as features in the model. For experimentation, the Netflix challenge dataset has been used. Video streaming service Netflix is a popular choice for many. Customers' prior viewing habits are taken into account when Netflix makes movie recommendations to them. An exploratory data analysis on the Netflix dataset was conducted to gain insights into user rating behaviour and movie characteristics. Various kinds of features, including aggregating, Matrix Factorization (MF) based, and user and movie similarity based, have been extracted in the subsequent stages. In addition to a feature in the XGBoost regression algorithm, the K-Nearest Neighbors and MF algorithms from Python's Surprise library are used for recommendations. Based on Root Mean Square Error (RMSE), MF-based algorithms have provided the best recommendations.

</details>


### [54] [Science Fiction and Fantasy in Wikipedia: Exploring Structural and Semantic Cues](https://arxiv.org/abs/2602.24229)
*Włodzimierz Lewoniewski,Milena Stróżyna,Izabela Czumałowska,Elżbieta Lewańska*

Main category: cs.IR

TL;DR: 利用维基百科的结构和语义特征识别科幻与奇幻相关文章


<details>
  <summary>Details</summary>
Motivation: 科幻与奇幻（SF/F）的边界模糊且经常重叠，难以在维基百科中准确识别相关文章。虽然维基百科提供了机器可读的结构信息（如分类、内部链接、Wikidata语句），但这些信号受社区惯例影响，可能存在偏见或不完整。

Method: 研究维基百科文章的结构和语义特征，包括分类、内部链接（wikilinks）以及对应的Wikidata陈述，用于识别与科幻和奇幻相关的内容。

Result: 未提供具体结果（摘要中未包含实验数据或发现）

Conclusion: 需要进一步研究如何利用维基百科的结构和语义特征来有效识别科幻与奇幻相关内容，以克服社区惯例带来的偏见和不完整性。

Abstract: Identifying which Wikipedia articles are related to science fiction, fantasy, or their hybrids is challenging because genre boundaries are porous and frequently overlap. Wikipedia nonetheless offers machine-readable structure beyond text, including categories, internal links (wikilinks), and statements if corresponding Wikidata items. However, each of these signals reflects community conventions and can be biased or incomplete. This study examines structural and semantic features of Wikipedia articles that can be used to identify content related to science fiction and fantasy (SF/F).

</details>


### [55] [UXSim: Towards a Hybrid User Search Simulation](https://arxiv.org/abs/2602.24241)
*Saber Zerhoudi,Michael Granitzer*

Main category: cs.IR

TL;DR: UXSim：结合传统模拟器与LLM代理的混合框架，用于更准确、动态地模拟复杂交互搜索系统中的用户体验


<details>
  <summary>Details</summary>
Motivation: 传统方法（静态用户代理）和现有LLM代理在模拟复杂交互搜索系统中的细微用户体验时存在局限：前者缺乏动态性，后者缺乏可验证的深层基础。真实人机交互的动性和个性化需要更集成的方法。

Method: 提出UXSim框架，整合传统模拟器的基于数据的基础与自适应LLM代理的推理能力。使用传统模拟器的数据来指导和约束LLM代理的推理，实现两者的协同。

Result: 该框架能够实现更准确、动态的用户行为模拟，同时为底层认知过程提供可解释的验证途径。

Conclusion: UXSim通过结合基于数据的模拟与LLM推理，为复杂交互系统的用户体验模拟提供了更有效、可解释的解决方案。

Abstract: Simulating nuanced user experiences within complex interactive search systems poses distinct challenge for traditional methodologies, which often rely on static user proxies or, more recently, on standalone large language model (LLM) agents that may lack deep, verifiable grounding. The true dynamism and personalization inherent in human-computer interaction demand a more integrated approach. This work introduces UXSim, a novel framework that integrates both approaches. It leverages grounded data from traditional simulators to inform and constrain the reasoning of an adaptive LLM agent. This synthesis enables more accurate and dynamic simulations of user behavior while also providing a pathway for the explainable validation of the underlying cognitive processes.

</details>


### [56] [Beyond the Click: A Framework for Inferring Cognitive Traces in Search](https://arxiv.org/abs/2602.24265)
*Saber Zerhoudi,Michael Granitzer*

Main category: cs.IR

TL;DR: 提出从用户行为日志推断认知轨迹的框架，以改善用户模拟器的真实性和检索系统评估


<details>
  <summary>Details</summary>
Motivation: 现有的用户模拟器主要复制用户行为而不理解其思考过程，因为大规模交互日志只记录用户行为而不包含其认知状态（如困惑或满意）

Method: 基于信息觅食理论(IFT)和人类专家判断的多智能体系统，从行为日志中推断认知轨迹

Result: 认知轨迹提升了模型在预测会话结果和用户挣扎恢复等任务上的性能，发布了AOL和Stack Overflow等公开数据集的标注集合以及开源工具

Conclusion: 该工作为构建更类人的用户模拟器和从用户导向维度评估检索系统提供了必要的工具和数据

Abstract: User simulators are essential for evaluating search systems, but they primarily copy user actions without understanding the underlying thought process. This gap exists since large-scale interaction logs record what users do, but not what they might be thinking or feeling, such as confusion or satisfaction. To solve this problem, we present a framework to infer cognitive traces from behavior logs. Our method uses a multi-agent system grounded in Information Foraging Theory (IFT) and human expert judgment. These traces improve model performance on tasks like forecasting session outcomes and user struggle recovery. We release a collection of annotations for several public datasets, including AOL and Stack Overflow, and an open-source tool that allows researchers to apply our method to their own data. This work provides the tools and data needed to build more human-like user simulators and to assess retrieval systems on user-oriented dimensions of performance.

</details>


### [57] [Resources for Automated Evaluation of Assistive RAG Systems that Help Readers with News Trustworthiness Assessment](https://arxiv.org/abs/2602.24277)
*Dake Zhang,Mark D. Smucker,Charles L. A. Clarke*

Main category: cs.IR

TL;DR: TREC 2025 DRAGUN赛道为评估辅助新闻可信度评估的RAG系统提供了资源，包括自动评估流程和人类评估基准。


<details>
  <summary>Details</summary>
Motivation: 当前读者难以评估在线新闻的可信度，因为可靠报道与错误信息并存。需要开发辅助系统来帮助读者进行新闻可信度评估。

Method: 创建DRAGUN赛道，包含两个任务：问题生成（生成10个排名调查问题）和报告生成（生成250字基于MS MARCO V2.1语料库的报告）。开发自动评估流程（AutoJudge）来评估系统表现。

Result: AutoJudge与TREC人工评估结果相关性良好（任务1 Kendall's τ=0.678，任务2 τ=0.872）。创建了可重复使用的任务框架和评估资源。

Conclusion: DRAGUN资源支持辅助新闻可信度评估RAG系统的评估，并以人类评估为基准，促进自动化RAG评估研究的改进。

Abstract: Many readers today struggle to assess the trustworthiness of online news because reliable reporting coexists with misinformation. The TREC 2025 DRAGUN (Detection, Retrieval, and Augmented Generation for Understanding News) Track provided a venue for researchers to develop and evaluate assistive RAG systems that support readers' news trustworthiness assessment by producing reader-oriented, well-attributed reports. As the organizers of the DRAGUN track, we describe the resources that we have newly developed to allow for the reuse of the track's tasks. The track had two tasks: (Task 1) Question Generation, producing 10 ranked investigative questions; and (Task 2, the main task) Report Generation, producing a 250-word report grounded in the MS MARCO V2.1 Segmented Corpus. As part of the track's evaluation, we had TREC assessors create importance-weighted rubrics of questions with expected short answers for 30 different news articles. These rubrics represent the information that assessors believe is important for readers to assess an article's trustworthiness. The assessors then used their rubrics to manually judge the participating teams' submitted runs. To make these tasks and their rubrics reusable, we have created an automated process to judge runs not part of the original assessing. We show that our AutoJudge ranks existing runs well compared to the TREC human-assessed evaluation (Kendall's $τ= 0.678$ for Task 1 and $τ= 0.872$ for Task 2). These resources enable both the evaluation of RAG systems for assistive news trustworthiness assessment and, with the human evaluation as a benchmark, research on improving automated RAG evaluation.

</details>
