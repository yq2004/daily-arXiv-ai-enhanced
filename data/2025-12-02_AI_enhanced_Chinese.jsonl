{"id": "2511.21695", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.21695", "abs": "https://arxiv.org/abs/2511.21695", "authors": ["Ruchira Dhar", "Danae Sanchez Villegas", "Antonia Karamolegkou", "Alice Schiavone", "Yifei Yuan", "Xinyi Chen", "Jiaang Li", "Stella Frank", "Laura De Grazia", "Monorama Swain", "Stephanie Brandl", "Daniel Hershcovich", "Anders S\u00f8gaard", "Desmond Elliott"], "title": "EvalCards: A Framework for Standardized Evaluation Reporting", "comment": "Under review", "summary": "Evaluation has long been a central concern in NLP, and transparent reporting practices are more critical than ever in today's landscape of rapidly released open-access models. Drawing on a survey of recent work on evaluation and documentation, we identify three persistent shortcomings in current reporting practices: reproducibility, accessibility, and governance. We argue that existing standardization efforts remain insufficient and introduce Evaluation Disclosure Cards (EvalCards) as a path forward. EvalCards are designed to enhance transparency for both researchers and practitioners while providing a practical foundation to meet emerging governance requirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8bc4\u4f30\u62ab\u9732\u5361\uff08EvalCards\uff09\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524dNLP\u8bc4\u4f30\u62a5\u544a\u4e2d\u7684\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u53ef\u590d\u73b0\u6027\u3001\u53ef\u8bbf\u95ee\u6027\u548c\u6cbb\u7406\uff0c\u4ee5\u589e\u5f3a\u8bc4\u4f30\u900f\u660e\u5ea6\u3002", "motivation": "NLP\u9886\u57df\u8bc4\u4f30\u4e00\u76f4\u662f\u6838\u5fc3\u5173\u6ce8\u70b9\uff0c\u5728\u5f53\u4eca\u5feb\u901f\u53d1\u5e03\u5f00\u6e90\u6a21\u578b\u7684\u80cc\u666f\u4e0b\uff0c\u900f\u660e\u7684\u62a5\u544a\u5b9e\u8df5\u6bd4\u4ee5\u5f80\u4efb\u4f55\u65f6\u5019\u90fd\u66f4\u52a0\u91cd\u8981\u3002\u4f5c\u8005\u901a\u8fc7\u8c03\u67e5\u8fd1\u671f\u8bc4\u4f30\u548c\u6587\u6863\u5de5\u4f5c\uff0c\u53d1\u73b0\u5f53\u524d\u62a5\u544a\u5b9e\u8df5\u5b58\u5728\u4e09\u4e2a\u6301\u7eed\u6027\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u9996\u5148\u8c03\u67e5\u4e86\u8fd1\u671f\u5173\u4e8e\u8bc4\u4f30\u548c\u6587\u6863\u7684\u5de5\u4f5c\uff0c\u8bc6\u522b\u51fa\u5f53\u524d\u62a5\u544a\u5b9e\u8df5\u4e2d\u7684\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\u3002\u7136\u540e\u63d0\u51fa\u8bc4\u4f30\u62ab\u9732\u5361\uff08EvalCards\uff09\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u8fd9\u662f\u4e00\u79cd\u65e8\u5728\u589e\u5f3a\u900f\u660e\u5ea6\u7684\u6807\u51c6\u5316\u62a5\u544a\u6846\u67b6\u3002", "result": "\u8bc6\u522b\u51fa\u5f53\u524dNLP\u8bc4\u4f30\u62a5\u544a\u5b9e\u8df5\u4e2d\u7684\u4e09\u4e2a\u6301\u7eed\u6027\u95ee\u9898\uff1a\u53ef\u590d\u73b0\u6027\u3001\u53ef\u8bbf\u95ee\u6027\u548c\u6cbb\u7406\u3002\u63d0\u51faEvalCards\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u65e8\u5728\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u66f4\u9ad8\u7684\u900f\u660e\u5ea6\uff0c\u5e76\u4e3a\u6ee1\u8db3\u65b0\u5174\u6cbb\u7406\u8981\u6c42\u63d0\u4f9b\u5b9e\u7528\u57fa\u7840\u3002", "conclusion": "\u73b0\u6709\u6807\u51c6\u5316\u5de5\u4f5c\u4ecd\u7136\u4e0d\u8db3\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002EvalCards\u4e3a\u589e\u5f3aNLP\u8bc4\u4f30\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u65e2\u80fd\u6ee1\u8db3\u7814\u7a76\u9700\u6c42\uff0c\u53c8\u80fd\u5e94\u5bf9\u65e5\u76ca\u589e\u957f\u7684\u6cbb\u7406\u8981\u6c42\u3002"}}
{"id": "2511.21699", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21699", "abs": "https://arxiv.org/abs/2511.21699", "authors": ["Zhiyao Ma", "In Gim", "Lin Zhong"], "title": "Cacheback: Speculative Decoding With Nothing But Cache", "comment": null, "summary": "We present Cacheback Decoding, a training-free and model-agnostic speculative decoding method that exploits the locality in language to accelerate Large Language Model (LLM) inference. Cacheback leverages only Least Recently Used (LRU) cache tables of token n-grams to generate draft sequences. Cacheback achieves state-of-the-art performance among comparable methods despite its minimalist design, and its simplicity allows easy integration into existing systems. Cacheback also shows potential for fast adaptation to new domains.", "AI": {"tldr": "Cacheback Decoding\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u6a21\u578b\u65e0\u5173\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u5229\u7528\u8bed\u8a00\u5c40\u90e8\u6027\u52a0\u901fLLM\u63a8\u7406\uff0c\u4ec5\u4f7f\u7528LRU\u7f13\u5b58\u8868\u751f\u6210\u8349\u7a3f\u5e8f\u5217\u3002", "motivation": "\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8bad\u7ec3\u6216\u590d\u6742\u8bbe\u8ba1\uff0cCacheback\u65e8\u5728\u63d0\u4f9b\u7b80\u5355\u3001\u65e0\u9700\u8bad\u7ec3\u4e14\u6a21\u578b\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528\u8bed\u8a00\u4e2d\u7684\u5c40\u90e8\u6027\u6a21\u5f0f\u6765\u52a0\u901fLLM\u63a8\u7406\u3002", "method": "\u4ec5\u4f7f\u7528\u6700\u8fd1\u6700\u5c11\u4f7f\u7528\uff08LRU\uff09\u7f13\u5b58\u8868\u5b58\u50a8token n-gram\uff0c\u5229\u7528\u8bed\u8a00\u5c40\u90e8\u6027\u751f\u6210\u8349\u7a3f\u5e8f\u5217\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u8bbe\u8ba1\u7b80\u6d01\u4e14\u6a21\u578b\u65e0\u5173\u3002", "result": "\u5728\u53ef\u6bd4\u65b9\u6cd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5c3d\u7ba1\u8bbe\u8ba1\u6781\u7b80\uff1b\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u7cfb\u7edf\uff1b\u5728\u65b0\u9886\u57df\u5177\u6709\u5feb\u901f\u9002\u5e94\u6f5c\u529b\u3002", "conclusion": "Cacheback Decoding\u901a\u8fc7\u6781\u7b80\u7684LRU\u7f13\u5b58\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u63a8\u6d4b\u89e3\u7801\uff0c\u4e3aLLM\u63a8\u7406\u52a0\u901f\u63d0\u4f9b\u4e86\u7b80\u5355\u3001\u6709\u6548\u4e14\u6613\u4e8e\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21700", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21700", "abs": "https://arxiv.org/abs/2511.21700", "authors": ["Yuhao Zhan", "Yuqing Zhang", "Jing Yuan", "Qixiang Ma", "Zhiqi Yang", "Yu Gu", "Zemin Liu", "Fei Wu"], "title": "JELV: A Judge of Edit-Level Validity for Evaluation and Automated Reference Expansion in Grammatical Error Correction", "comment": null, "summary": "Existing Grammatical Error Correction (GEC) systems suffer from limited reference diversity, leading to underestimated evaluation and restricted model generalization. To address this issue, we introduce the Judge of Edit-Level Validity (JELV), an automated framework to validate correction edits from grammaticality, faithfulness, and fluency. Using our proposed human-annotated Pair-wise Edit-level Validity Dataset (PEVData) as benchmark, JELV offers two implementations: a multi-turn LLM-as-Judges pipeline achieving 90% agreement with human annotators, and a distilled DeBERTa classifier with 85% precision on valid edits. We then apply JELV to reclassify misjudged false positives in evaluation and derive a comprehensive evaluation metric by integrating false positive decoupling and fluency scoring, resulting in state-of-the-art correlation with human judgments. We also apply JELV to filter LLM-generated correction candidates, expanding the BEA19's single-reference dataset containing 38,692 source sentences. Retraining top GEC systems on this expanded dataset yields measurable performance gains. JELV provides a scalable solution for enhancing reference diversity and strengthening both evaluation and model generalization.", "AI": {"tldr": "\u63d0\u51faJELV\u6846\u67b6\uff0c\u901a\u8fc7\u7f16\u8f91\u7ea7\u6709\u6548\u6027\u9a8c\u8bc1\u6765\u63d0\u5347\u8bed\u6cd5\u7ea0\u9519\u7cfb\u7edf\u7684\u8bc4\u4f30\u51c6\u786e\u6027\u548c\u6a21\u578b\u6cdb\u5316\u80fd\u529b", "motivation": "\u73b0\u6709\u8bed\u6cd5\u7ea0\u9519\u7cfb\u7edf\u56e0\u53c2\u8003\u591a\u6837\u6027\u6709\u9650\uff0c\u5bfc\u81f4\u8bc4\u4f30\u88ab\u4f4e\u4f30\u4e14\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u53d7\u9650", "method": "\u63d0\u51faJELV\u6846\u67b6\uff0c\u5305\u542b\u4e24\u79cd\u5b9e\u73b0\uff1a\u591a\u8f6eLLM-as-Judges\u7ba1\u9053\u548c\u84b8\u998f\u7684DeBERTa\u5206\u7c7b\u5668\uff0c\u5e76\u5e94\u7528\u4e8e\u91cd\u65b0\u5206\u7c7b\u8bef\u5224\u7684\u5047\u9633\u6027\u6848\u4f8b", "result": "JELV\u4e0e\u4eba\u5de5\u6807\u6ce8\u8005\u8fbe\u621090%\u4e00\u81f4\u7387\uff0cDeBERTa\u5206\u7c7b\u5668\u5bf9\u6709\u6548\u7f16\u8f91\u8fbe\u523085%\u7cbe\u786e\u5ea6\uff1b\u5e94\u7528JELV\u6269\u5c55\u6570\u636e\u96c6\u540e\uff0c\u91cd\u65b0\u8bad\u7ec3GEC\u7cfb\u7edf\u83b7\u5f97\u53ef\u6d4b\u91cf\u7684\u6027\u80fd\u63d0\u5347", "conclusion": "JELV\u4e3a\u589e\u5f3a\u53c2\u8003\u591a\u6837\u6027\u3001\u52a0\u5f3a\u8bc4\u4f30\u548c\u6a21\u578b\u6cdb\u5316\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.21701", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21701", "abs": "https://arxiv.org/abs/2511.21701", "authors": ["Chiung-Yi Tseng", "Danyang Zhang", "Tianyang Wang", "Hongying Luo", "Lu Chen", "Junming Huang", "Jibin Guan", "Junfeng Hao", "Junhao Song", "Ziqian Bi"], "title": "47B Mixture-of-Experts Beats 671B Dense Models on Chinese Medical Examinations", "comment": null, "summary": "The rapid advancement of large language models(LLMs) has prompted significant interest in their potential applications in medical domains. This paper presents a comprehensive benchmark evaluation of 27 state-of-the-art LLMs on Chinese medical examination questions, encompassing seven medical specialties across two professional levels. We introduce a robust evaluation framework that assesses model performance on 2,800 carefully curated questions from cardiovascular, gastroenterology, hematology, infectious diseases, nephrology, neurology, and respiratory medicine domains. Our dataset distinguishes between attending physician and senior physician difficulty levels, providing nuanced insights into model capabilities across varying complexity. Our empirical analysis reveals substantial performance variations among models, with Mixtral-8x7B achieving the highest overall accuracy of 74.25%, followed by DeepSeek-R1-671B at 64.07%. Notably, we observe no consistent correlation between model size and performance, as evidenced by the strong performance of smaller mixture-of-experts architectures. The evaluation demonstrates significant performance gaps between medical specialties, with models generally performing better on cardiovascular and neurology questions compared to gastroenterology and nephrology domains. Furthermore, our analysis indicates minimal performance degradation between attending and senior physician levels for top-performing models, suggesting robust generalization capabilities. This benchmark provides critical insights for the deployment of LLMs in medical education and clinical decision support systems, highlighting both the promise and current limitations of these technologies in specialized medical contexts.", "AI": {"tldr": "\u8bc4\u4f3027\u4e2aLLM\u5728\u4e2d\u6587\u533b\u5b66\u8003\u8bd5\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0Mixtral-8x7B\u8868\u73b0\u6700\u4f73\uff0874.25%\uff09\uff0c\u6a21\u578b\u5927\u5c0f\u4e0e\u6027\u80fd\u65e0\u4e00\u81f4\u76f8\u5173\u6027\uff0c\u4e0d\u540c\u533b\u5b66\u4e13\u79d1\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u65e5\u76ca\u589e\u957f\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u5728\u4e13\u4e1a\u533b\u5b66\u77e5\u8bc6\u4e0a\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4e2d\u6587\u533b\u5b66\u8003\u8bd5\u573a\u666f\uff0c\u4e3a\u533b\u7597\u6559\u80b2\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u6784\u5efa\u5305\u542b7\u4e2a\u533b\u5b66\u4e13\u79d1\u30012\u4e2a\u4e13\u4e1a\u7ea7\u522b\uff08\u4e3b\u6cbb\u533b\u5e08\u548c\u4e3b\u4efb\u533b\u5e08\uff09\u76842800\u9053\u4e2d\u6587\u533b\u5b66\u8003\u8bd5\u9898\u6570\u636e\u96c6\uff0c\u8bc4\u4f3027\u4e2a\u6700\u5148\u8fdb\u7684LLM\uff0c\u91c7\u7528\u7a33\u5065\u7684\u8bc4\u4f30\u6846\u67b6\u5206\u6790\u6a21\u578b\u6027\u80fd\u3002", "result": "Mixtral-8x7B\u4ee574.25%\u51c6\u786e\u7387\u8868\u73b0\u6700\u4f73\uff0cDeepSeek-R1-671B\u4ee564.07%\u6b21\u4e4b\uff1b\u6a21\u578b\u5927\u5c0f\u4e0e\u6027\u80fd\u65e0\u4e00\u81f4\u76f8\u5173\u6027\uff1b\u5fc3\u8840\u7ba1\u548c\u795e\u7ecf\u79d1\u8868\u73b0\u8f83\u597d\uff0c\u6d88\u5316\u79d1\u548c\u80be\u79d1\u8f83\u5dee\uff1b\u9876\u7ea7\u6a21\u578b\u5728\u4e0d\u540c\u96be\u5ea6\u7ea7\u522b\u95f4\u6027\u80fd\u4e0b\u964d\u6700\u5c0f\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3aLLM\u5728\u533b\u5b66\u6559\u80b2\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u6280\u672f\u5728\u4e13\u4e1a\u533b\u5b66\u80cc\u666f\u4e0b\u7684\u6f5c\u529b\u548c\u5f53\u524d\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u533b\u5b66\u4e13\u79d1\u8fdb\u884c\u4f18\u5316\u3002"}}
{"id": "2511.21989", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.21989", "abs": "https://arxiv.org/abs/2511.21989", "authors": ["Nachiket Subbaraman", "Jaskinder Sarai", "Aniruddh Nath", "Lichan Hong", "Lukasz Heldt", "Li Wei", "Zhe Zhao"], "title": "Selecting User Histories to Generate LLM Users for Cold-Start Item Recommendation", "comment": "12 pages, 15 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in reasoning, generalization, and simulating human-like behavior across a wide range of tasks. These strengths present new opportunities to enhance traditional recommendation systems (RS), especially in the cold-start item scenario where newly introduced items lack interactions. Existing works have used LLMs to address cold-start issues in traditional RS through data augmentation, but they have limitations. One recent work directly addresses this issue by prompting LLMs to generate augmented interaction data between randomly sampled users and cold-start items. Then, they train the traditional RS with augmented data, incorporating collaborative signals for cold-start items. Although they use LLMs to provide cold-start items with feedback, they use partial user histories, which does not allow the LLM to fully emulate the user. Furthermore, randomly selecting users is not optimal for augmentation. To address these challenges, we leverage the LLM as a user and develop a reinforcement learning (RL) framework that trains a policy to select users for augmentation, optimizing for cold-start item performance after augmented training. The policy model learns to select users for cold-start item data augmentation based on their behavioral features and histories. To optimize user selection for cold-start item performance, we employ a policy gradient method that updates the policy in the direction of actions that lead to high rewards. Experiments on Amazon Product Review datasets show substantial gains in cold-start item recall, demonstrating the effectiveness of our method as a scalable, serving-efficient augmentation strategy for modern RS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u7528\u6237\u6a21\u62df\u5668\uff0c\u901a\u8fc7\u7b56\u7565\u5b66\u4e60\u9009\u62e9\u6700\u4f18\u7528\u6237\u8fdb\u884c\u51b7\u542f\u52a8\u7269\u54c1\u7684\u6570\u636e\u589e\u5f3a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4f7f\u7528LLMs\u89e3\u51b3\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u4f46\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a1\uff09\u4ec5\u4f7f\u7528\u90e8\u5206\u7528\u6237\u5386\u53f2\uff0c\u65e0\u6cd5\u8ba9LLM\u5b8c\u5168\u6a21\u62df\u7528\u6237\u884c\u4e3a\uff1b2\uff09\u968f\u673a\u9009\u62e9\u7528\u6237\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u4e0d\u662f\u6700\u4f18\u7b56\u7565\u3002\u8fd9\u4e9b\u9650\u5236\u5f71\u54cd\u4e86\u51b7\u542f\u52a8\u7269\u54c1\u7684\u6027\u80fd\u63d0\u5347\u6548\u679c\u3002", "method": "\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06LLM\u4f5c\u4e3a\u7528\u6237\u6a21\u62df\u5668\uff0c\u8bad\u7ec3\u4e00\u4e2a\u7b56\u7565\u6a21\u578b\u6765\u5b66\u4e60\u9009\u62e9\u7528\u6237\u8fdb\u884c\u51b7\u542f\u52a8\u7269\u54c1\u7684\u6570\u636e\u589e\u5f3a\u3002\u7b56\u7565\u6a21\u578b\u57fa\u4e8e\u7528\u6237\u884c\u4e3a\u7279\u5f81\u548c\u5386\u53f2\u8fdb\u884c\u51b3\u7b56\uff0c\u91c7\u7528\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u66f4\u65b0\u7b56\u7565\uff0c\u4f18\u5316\u51b7\u542f\u52a8\u7269\u54c1\u5728\u589e\u5f3a\u8bad\u7ec3\u540e\u7684\u6027\u80fd\u3002", "result": "\u5728Amazon Product Review\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51b7\u542f\u52a8\u7269\u54c1\u53ec\u56de\u7387\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u53ef\u6269\u5c55\u3001\u670d\u52a1\u9ad8\u6548\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06LLM\u4f5c\u4e3a\u7528\u6237\u6a21\u62df\u5668\u5e76\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u7528\u6237\u9009\u62e9\u7b56\u7565\uff0c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u51b7\u542f\u52a8\u7269\u54c1\u7684\u6570\u636e\u589e\u5f3a\u95ee\u9898\uff0c\u4e3a\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21702", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21702", "abs": "https://arxiv.org/abs/2511.21702", "authors": ["Dong Liu", "Yanxuan Yu", "Ben Lengerich"], "title": "CSV-Decode: Certifiable Sub-Vocabulary Decoding for Efficient Large Language Model Inference", "comment": null, "summary": "Large language models face significant computational bottlenecks during inference due to the expensive output layer computation over large vocabularies. We present CSV-Decode, a novel approach that uses geometric upper bounds to construct small sub-vocabularies for each decoding step, enabling efficient sparse computation while maintaining dual correctness guarantees: exact top-$k$ certification and $\\varepsilon$-certified softmax approximations. Our method clusters vocabulary embeddings offline and uses centroid-plus-radius bounds to identify which tokens can be safely omitted from computation. We provide a complete system implementation with sparse GEMV kernels, multi-GPU sharding, and CUDA Graph optimization. Experimental results demonstrate significant speedup over full vocabulary decoding while maintaining distributional guarantees and low fallback rates. Our code implementation available at \\href{https://github.com/FastLM/CSV-Decode}{https://github.com/FastLM/CSV-Decode}.", "AI": {"tldr": "CSV-Decode\u662f\u4e00\u79cd\u901a\u8fc7\u51e0\u4f55\u4e0a\u754c\u6784\u5efa\u5c0f\u5b50\u8bcd\u6c47\u8868\u8fdb\u884c\u7a00\u758f\u8ba1\u7b97\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u7cbe\u786e\u7684top-k\u8ba4\u8bc1\u548c\u03b5\u8ba4\u8bc1\u7684softmax\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65f6\u9762\u4e34\u663e\u8457\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5927\u578b\u8bcd\u6c47\u8868\u4e0a\u7684\u8f93\u51fa\u5c42\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u4f20\u7edf\u7684\u5168\u8bcd\u6c47\u8868\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u7801\u65b9\u6cd5\u3002", "method": "\u79bb\u7ebf\u805a\u7c7b\u8bcd\u6c47\u5d4c\u5165\uff0c\u4f7f\u7528\u8d28\u5fc3\u52a0\u534a\u5f84\u7684\u51e0\u4f55\u4e0a\u754c\u4e3a\u6bcf\u4e2a\u89e3\u7801\u6b65\u9aa4\u6784\u5efa\u5c0f\u5b50\u8bcd\u6c47\u8868\uff0c\u8bc6\u522b\u53ef\u4ee5\u5b89\u5168\u7701\u7565\u7684token\uff0c\u5b9e\u73b0\u7a00\u758f\u8ba1\u7b97\u3002\u7cfb\u7edf\u5b9e\u73b0\u5305\u62ec\u7a00\u758fGEMV\u5185\u6838\u3001\u591aGPU\u5206\u7247\u548cCUDA\u56fe\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u5168\u8bcd\u6c47\u8868\u89e3\u7801\uff0cCSV-Decode\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5206\u5e03\u4fdd\u8bc1\u548c\u8f83\u4f4e\u7684\u56de\u9000\u7387\u3002", "conclusion": "CSV-Decode\u901a\u8fc7\u51e0\u4f55\u4e0a\u754c\u548c\u7a00\u758f\u8ba1\u7b97\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6b63\u786e\u6027\u4fdd\u8bc1\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2511.22240", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22240", "abs": "https://arxiv.org/abs/2511.22240", "authors": ["Philip Zhong", "Kent Chen", "Don Wang"], "title": "Evaluating Embedding Models and Pipeline Optimization for AI Search Quality", "comment": null, "summary": "We evaluate the performance of various text embedding models and pipeline configurations for AI-driven search systems. We compare sentence-transformer and generative embedding models (e.g., All-MPNet, BGE, GTE, and Qwen) at different dimensions, indexing methods (Milvus HNSW/IVF), and chunking strategies. A custom evaluation dataset of 11,975 query-chunk pairs was synthesized from US City Council meeting transcripts using a local large language model (LLM). The data pipeline includes preprocessing, automated question generation per chunk, manual validation, and continuous integration/continuous deployment (CI/CD) integration. We measure retrieval accuracy using reference-based metrics: Top-K Accuracy and Normalized Discounted Cumulative Gain (NDCG). Our results demonstrate that higher-dimensional embeddings significantly boost search quality (e.g., Qwen3-Embedding-8B/4096 achieves Top-3 accuracy about 0.571 versus 0.412 for GTE-large/1024), and that neural re-rankers (e.g., a BGE cross-encoder) further improve ranking accuracy (Top-3 up to 0.527). Finer-grained chunking (512 characters versus 2000 characters) also improves accuracy. We discuss the impact of these factors and outline future directions for pipeline automation and evaluation.", "AI": {"tldr": "\u8bc4\u4f30\u4e0d\u540c\u6587\u672c\u5d4c\u5165\u6a21\u578b\u548c\u914d\u7f6e\u5bf9AI\u641c\u7d22\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u9ad8\u7ef4\u5d4c\u5165\u3001\u795e\u7ecf\u91cd\u6392\u5e8f\u548c\u7ec6\u7c92\u5ea6\u5206\u5757\u80fd\u663e\u8457\u63d0\u5347\u68c0\u7d22\u51c6\u786e\u7387\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u4e0d\u540c\u6587\u672c\u5d4c\u5165\u6a21\u578b\u548c\u7ba1\u9053\u914d\u7f6e\u5728AI\u9a71\u52a8\u641c\u7d22\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u6bd4\u8f83\u5404\u79cd\u6a21\u578b\u3001\u7d22\u5f15\u65b9\u6cd5\u548c\u5206\u5757\u7b56\u7565\u7684\u6548\u679c\u3002", "method": "\u4f7f\u7528\u4ece\u7f8e\u56fd\u5e02\u8bae\u4f1a\u4f1a\u8bae\u8bb0\u5f55\u5408\u6210\u768411,975\u4e2a\u67e5\u8be2-\u5206\u5757\u5bf9\u4f5c\u4e3a\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u53e5\u5b50\u8f6c\u6362\u5668\u548c\u751f\u6210\u5f0f\u5d4c\u5165\u6a21\u578b\uff08All-MPNet\u3001BGE\u3001GTE\u3001Qwen\uff09\u5728\u4e0d\u540c\u7ef4\u5ea6\u3001\u7d22\u5f15\u65b9\u6cd5\uff08Milvus HNSW/IVF\uff09\u548c\u5206\u5757\u7b56\u7565\u4e0b\u7684\u8868\u73b0\uff0c\u91c7\u7528Top-K\u51c6\u786e\u7387\u548cNDCG\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u9ad8\u7ef4\u5d4c\u5165\u663e\u8457\u63d0\u5347\u641c\u7d22\u8d28\u91cf\uff08\u5982Qwen3-Embedding-8B/4096\u7684Top-3\u51c6\u786e\u7387\u7ea60.571\uff0c\u800cGTE-large/1024\u4e3a0.412\uff09\uff1b\u795e\u7ecf\u91cd\u6392\u5e8f\u5668\uff08\u5982BGE\u4ea4\u53c9\u7f16\u7801\u5668\uff09\u8fdb\u4e00\u6b65\u63d0\u5347\u6392\u540d\u51c6\u786e\u7387\uff08Top-3\u6700\u9ad8\u8fbe0.527\uff09\uff1b\u7ec6\u7c92\u5ea6\u5206\u5757\uff08512\u5b57\u7b26vs2000\u5b57\u7b26\uff09\u4e5f\u63d0\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u5d4c\u5165\u7ef4\u5ea6\u3001\u91cd\u6392\u5e8f\u548c\u5206\u5757\u7b56\u7565\u662f\u5f71\u54cdAI\u641c\u7d22\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u7ba1\u9053\u81ea\u52a8\u5316\u548c\u8bc4\u4f30\u65b9\u6cd5\u7684\u6539\u8fdb\u3002"}}
{"id": "2511.21703", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21703", "abs": "https://arxiv.org/abs/2511.21703", "authors": ["Siyaxolisa Kabane"], "title": "Evaluating Embedding Generalization: How LLMs, LoRA, and SLERP Shape Representational Geometry", "comment": "20 pages, 16 figures", "summary": "We investigate the generalization properties of dense text embeddings when the embedding backbone is a large language model (LLM) versus when it is a non-LLM encoder, and we study the extent to which spherical linear interpolation (SLERP) model-merging mitigates over-specialization introduced by task-specific adaptation (e.g., LoRA). To make the comparison concrete and domain-agnostic, we design a controlled suite of experiments in which models embed short numerical sequences and are evaluated on their ability to cluster and classify those sequences according to well-defined number-theoretic properties. Our experimental protocol compares four families of models: (1) non-LLM encoders trained from scratch or fine-tuned for embeddings, (2) LLM-based encoders adapted with parameter-efficient methods (LoRA), (3) LLM-based encoders with LoRA followed by model souping merging into the base weights, and (4) the same LoRA-adapted LLMs merged using SLERP across checkpoints or stages. We evaluate representational quality with clustering indices (Silhouette and Davies Bouldin). We additionally analyze the use of kmeans labels to see if the embeddings encode any other information besides the one we are testing for. Empirically, we find that LLM-based backbones produce embeddings that better capture higher-order, compositional numeric patterns, but are prone to adapter dominance that degrades balanced generalization; SLERP merging consistently recovers base-model structure while retaining most task gains, yielding superior tradeoffs in clustering separability, and robustness compared to model souping or models that were not merged.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86LLM\u4e0e\u975eLLM\u7f16\u7801\u5668\u5728\u6587\u672c\u5d4c\u5165\u4e2d\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u4ee5\u53caSLERP\u6a21\u578b\u878d\u5408\u5982\u4f55\u7f13\u89e3\u4efb\u52a1\u7279\u5b9a\u9002\u5e94\u5e26\u6765\u7684\u8fc7\u4e13\u4e1a\u5316\u95ee\u9898", "motivation": "\u63a2\u7d22\u5bc6\u96c6\u6587\u672c\u5d4c\u5165\u7684\u6cdb\u5316\u7279\u6027\uff0c\u6bd4\u8f83LLM\u4e0e\u975eLLM\u7f16\u7801\u5668\u4f5c\u4e3a\u5d4c\u5165\u9aa8\u5e72\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u7814\u7a76\u7403\u5f62\u7ebf\u6027\u63d2\u503c(SLERP)\u6a21\u578b\u878d\u5408\u5982\u4f55\u51cf\u8f7b\u4efb\u52a1\u7279\u5b9a\u9002\u5e94\uff08\u5982LoRA\uff09\u5f15\u5165\u7684\u8fc7\u4e13\u4e1a\u5316\u95ee\u9898", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53d7\u63a7\u5b9e\u9a8c\u5957\u4ef6\uff0c\u8ba9\u6a21\u578b\u5d4c\u5165\u77ed\u6570\u5b57\u5e8f\u5217\uff0c\u5e76\u6839\u636e\u660e\u786e\u5b9a\u4e49\u7684\u6570\u636e\u7406\u8bba\u5c5e\u6027\u8bc4\u4f30\u5176\u805a\u7c7b\u548c\u5206\u7c7b\u80fd\u529b\u3002\u6bd4\u8f83\u4e86\u56db\u79cd\u6a21\u578b\u5bb6\u65cf\uff1a(1)\u4ece\u5934\u8bad\u7ec3\u6216\u5fae\u8c03\u7684\u975eLLM\u7f16\u7801\u5668\uff0c(2)\u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5(LoRA)\u9002\u5e94\u7684LLM\u7f16\u7801\u5668\uff0c(3)LoRA\u9002\u5e94\u540e\u901a\u8fc7\u6a21\u578b\u878d\u5408\u5408\u5e76\u5230\u57fa\u7840\u6743\u91cd\u7684LLM\u7f16\u7801\u5668\uff0c(4)\u4f7f\u7528SLERP\u5728\u68c0\u67e5\u70b9\u6216\u9636\u6bb5\u95f4\u5408\u5e76\u7684LoRA\u9002\u5e94LLM", "result": "LLM\u9aa8\u5e72\u80fd\u66f4\u597d\u5730\u6355\u6349\u9ad8\u9636\u7ec4\u5408\u6570\u5b57\u6a21\u5f0f\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u9002\u914d\u5668\u4e3b\u5bfc\u5f71\u54cd\u800c\u964d\u4f4e\u5e73\u8861\u6cdb\u5316\u80fd\u529b\uff1bSLERP\u878d\u5408\u80fd\u4e00\u81f4\u5730\u6062\u590d\u57fa\u7840\u6a21\u578b\u7ed3\u6784\u540c\u65f6\u4fdd\u7559\u5927\u90e8\u5206\u4efb\u52a1\u589e\u76ca\uff0c\u5728\u805a\u7c7b\u53ef\u5206\u6027\u3001\u9c81\u68d2\u6027\u65b9\u9762\u63d0\u4f9b\u4f18\u4e8e\u6a21\u578b\u878d\u5408\u6216\u672a\u5408\u5e76\u6a21\u578b\u7684\u6743\u8861", "conclusion": "SLERP\u6a21\u578b\u878d\u5408\u662f\u7f13\u89e3LLM\u5d4c\u5165\u4e2d\u9002\u914d\u5668\u4e3b\u5bfc\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u5728\u4fdd\u7559\u4efb\u52a1\u7279\u5b9a\u6027\u80fd\u7684\u540c\u65f6\u4fdd\u6301\u57fa\u7840\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u6027\u80fd\u5e73\u8861"}}
{"id": "2511.22247", "categories": ["cs.IR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.22247", "abs": "https://arxiv.org/abs/2511.22247", "authors": ["Hoang-Bao Le", "Allie Tran", "Binh T. Nguyen", "Liting Zhou", "Cathal Gurrin"], "title": "FIGROTD: A Friendly-to-Handle Dataset for Image Guided Retrieval with Optional Text", "comment": "Accepted at MMM 2026", "summary": "Image-Guided Retrieval with Optional Text (IGROT) unifies visual retrieval (without text) and composed retrieval (with text). Despite its relevance in applications like Google Image and Bing, progress has been limited by the lack of an accessible benchmark and methods that balance performance across subtasks. Large-scale datasets such as MagicLens are comprehensive but computationally prohibitive, while existing models often favor either visual or compositional queries. We introduce FIGROTD, a lightweight yet high-quality IGROT dataset with 16,474 training triplets and 1,262 test triplets across CIR, SBIR, and CSTBIR. To reduce redundancy, we propose the Variance Guided Feature Mask (VaGFeM), which selectively enhances discriminative dimensions based on variance statistics. We further adopt a dual-loss design (InfoNCE + Triplet) to improve compositional reasoning. Trained on FIGROTD, VaGFeM achieves competitive results on nine benchmarks, reaching 34.8 mAP@10 on CIRCO and 75.7 mAP@200 on Sketchy, outperforming stronger baselines despite fewer triplets.", "AI": {"tldr": "FIGROTD\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u4f46\u9ad8\u8d28\u91cf\u7684IGROT\u6570\u636e\u96c6\uff0c\u914d\u5408VaGFeM\u65b9\u6cd5\uff08\u65b9\u5dee\u5f15\u5bfc\u7279\u5f81\u63a9\u7801\uff09\u548c\u53cc\u635f\u5931\u8bbe\u8ba1\uff0c\u5728\u591a\u4e2a\u68c0\u7d22\u4efb\u52a1\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\u3002", "motivation": "IGROT\uff08\u56fe\u50cf\u5f15\u5bfc\u68c0\u7d22\u4e0e\u53ef\u9009\u6587\u672c\uff09\u7edf\u4e00\u4e86\u89c6\u89c9\u68c0\u7d22\uff08\u65e0\u6587\u672c\uff09\u548c\u7ec4\u5408\u68c0\u7d22\uff08\u6709\u6587\u672c\uff09\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7f3a\u4e4f\u53ef\u8bbf\u95ee\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5e73\u8861\u5404\u5b50\u4efb\u52a1\u6027\u80fd\u7684\u65b9\u6cd5\u3002\u73b0\u6709\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u73b0\u6709\u6a21\u578b\u5f80\u5f80\u504f\u5411\u89c6\u89c9\u6216\u7ec4\u5408\u67e5\u8be2\u3002", "method": "1) \u5f15\u5165FIGROTD\u6570\u636e\u96c6\uff1a\u8f7b\u91cf\u7ea7\u9ad8\u8d28\u91cf\u7684IGROT\u6570\u636e\u96c6\uff0c\u5305\u542b16,474\u4e2a\u8bad\u7ec3\u4e09\u5143\u7ec4\u548c1,262\u4e2a\u6d4b\u8bd5\u4e09\u5143\u7ec4\uff0c\u6db5\u76d6CIR\u3001SBIR\u548cCSTBIR\u4efb\u52a1\uff1b2) \u63d0\u51faVaGFeM\uff08\u65b9\u5dee\u5f15\u5bfc\u7279\u5f81\u63a9\u7801\uff09\uff1a\u57fa\u4e8e\u65b9\u5dee\u7edf\u8ba1\u9009\u62e9\u6027\u589e\u5f3a\u5224\u522b\u6027\u7ef4\u5ea6\u4ee5\u51cf\u5c11\u5197\u4f59\uff1b3) \u91c7\u7528\u53cc\u635f\u5931\u8bbe\u8ba1\uff08InfoNCE + Triplet\uff09\u4ee5\u6539\u8fdb\u7ec4\u5408\u63a8\u7406\u3002", "result": "\u5728FIGROTD\u4e0a\u8bad\u7ec3\u7684VaGFeM\u5728\u4e5d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\uff1a\u5728CIRCO\u4e0a\u8fbe\u523034.8 mAP@10\uff0c\u5728Sketchy\u4e0a\u8fbe\u523075.7 mAP@200\uff0c\u5c3d\u7ba1\u4f7f\u7528\u66f4\u5c11\u7684\u4e09\u5143\u7ec4\uff0c\u4f46\u4ecd\u4f18\u4e8e\u66f4\u5f3a\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "FIGROTD\u6570\u636e\u96c6\u548cVaGFeM\u65b9\u6cd5\u4e3aIGROT\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u6a21\u578b\u6027\u80fd\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u68c0\u7d22\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.21704", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.21704", "abs": "https://arxiv.org/abs/2511.21704", "authors": ["Jonatas Grosman", "Cassio Almeida", "Guilherme Schardong", "H\u00e9lio Lopes"], "title": "On the Cross-lingual Transferability of Pre-trained wav2vec2-based Models", "comment": null, "summary": "Using representations provided by a large pre-trained model has become the primary strategy for achieving state-of-the-art results in a wide range of tasks. A recently proposed large pre-trained model, wav2vec 2.0, was seminal for several other works on pre-training large models on speech data. Many models are being pre-trained using the same architecture as wav2vec 2.0 and are getting state-of-the-art in various speech-related tasks. Previous work has demonstrated that the data used during the pre-training of these wav2vec2-based models can impact the model's performance in downstream tasks, and this should be taken into consideration before utilizing these models. However, few works have proposed investigating further how the transfer knowledge of these pre-trained models behaves in different languages, even when the target language differs from the one used during the model's pre-training. Our work aims to investigate the cross-lingual transferability of these wav2vec2-based models. We performed several fine-tuning experiments on the speech recognition task in 18 languages using 15 large pre-trained models. The results of our experiments showed us that the size of data used during the pre-training of these models is not as important to the final performance as the diversity. We noticed that the performance of Indo-European languages is superior to non-Indo-European languages in the evaluated models. We have observed a positive cross-lingual transfer of knowledge using monolingual models, which was evident in all the languages we used, but more pronounced when the language used during pre-training was more similar to the downstream task language. With these findings, we aim to assist the scientific community in utilizing existing wav2vec2-based pre-trained models, as well as facilitate the pre-training of new ones.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u57fa\u4e8ewav2vec 2.0\u67b6\u6784\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u591a\u8bed\u8a00\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\u80fd\u529b\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u6570\u636e\u7684\u591a\u6837\u6027\u6bd4\u6570\u636e\u91cf\u66f4\u91cd\u8981\uff0c\u4e14\u8bed\u8a00\u76f8\u4f3c\u6027\u5f71\u54cd\u8fc1\u79fb\u6548\u679c\u3002", "motivation": "\u867d\u7136\u57fa\u4e8ewav2vec 2.0\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5404\u79cd\u8bed\u97f3\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u6df1\u5165\u63a2\u8ba8\u8fd9\u4e9b\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u95f4\u7684\u77e5\u8bc6\u8fc1\u79fb\u80fd\u529b\uff0c\u7279\u522b\u662f\u5f53\u76ee\u6807\u8bed\u8a00\u4e0e\u9884\u8bad\u7ec3\u8bed\u8a00\u4e0d\u540c\u65f6\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f7f\u752815\u4e2a\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u572818\u79cd\u8bed\u8a00\u7684\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e0a\u8fdb\u884c\u5fae\u8c03\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u8de8\u8bed\u8a00\u8fc1\u79fb\u6548\u679c\uff0c\u5206\u6790\u8bed\u8a00\u76f8\u4f3c\u6027\u548c\u6570\u636e\u7279\u5f81\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "1. \u9884\u8bad\u7ec3\u6570\u636e\u7684\u591a\u6837\u6027\u6bd4\u6570\u636e\u91cf\u5bf9\u6700\u7ec8\u6027\u80fd\u66f4\u91cd\u8981\uff1b2. \u5370\u6b27\u8bed\u7cfb\u8bed\u8a00\u7684\u8868\u73b0\u4f18\u4e8e\u975e\u5370\u6b27\u8bed\u7cfb\u8bed\u8a00\uff1b3. \u5355\u8bed\u6a21\u578b\u5b58\u5728\u6b63\u5411\u7684\u8de8\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\uff0c\u4e14\u8bed\u8a00\u76f8\u4f3c\u6027\u8d8a\u9ad8\u8fc1\u79fb\u6548\u679c\u8d8a\u660e\u663e\u3002", "conclusion": "\u7814\u7a76\u4e3a\u79d1\u5b66\u793e\u533a\u63d0\u4f9b\u4e86\u4f7f\u7528\u73b0\u6709wav2vec2\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6307\u5bfc\uff0c\u5e76\u6709\u52a9\u4e8e\u65b0\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u8bbe\u8ba1\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u591a\u6837\u6027\u548c\u8bed\u8a00\u76f8\u4f3c\u6027\u5728\u8de8\u8bed\u8a00\u8fc1\u79fb\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.22253", "categories": ["cs.IR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.22253", "abs": "https://arxiv.org/abs/2511.22253", "authors": ["Hoang-Bao Le", "Allie Tran", "Binh T. Nguyen", "Liting Zhou", "Cathal Gurrin"], "title": "UNION: A Lightweight Target Representation for Efficient Zero-Shot Image-Guided Retrieval with Optional Textual Queries", "comment": "Accepted at ICDM - MMSR Workshop 2025", "summary": "Image-Guided Retrieval with Optional Text (IGROT) is a general retrieval setting where a query consists of an anchor image, with or without accompanying text, aiming to retrieve semantically relevant target images. This formulation unifies two major tasks: Composed Image Retrieval (CIR) and Sketch-Based Image Retrieval (SBIR). In this work, we address IGROT under low-data supervision by introducing UNION, a lightweight and generalisable target representation that fuses the image embedding with a null-text prompt. Unlike traditional approaches that rely on fixed target features, UNION enhances semantic alignment with multimodal queries while requiring no architectural modifications to pretrained vision-language models. With only 5,000 training samples - from LlavaSCo for CIR and Training-Sketchy for SBIR - our method achieves competitive results across benchmarks, including CIRCO mAP@50 of 38.5 and Sketchy mAP@200 of 82.7, surpassing many heavily supervised baselines. This demonstrates the robustness and efficiency of UNION in bridging vision and language across diverse query types.", "AI": {"tldr": "UNION\u65b9\u6cd5\u901a\u8fc7\u878d\u5408\u56fe\u50cf\u5d4c\u5165\u548c\u7a7a\u6587\u672c\u63d0\u793a\uff0c\u5728\u5c11\u91cf\u6570\u636e\u76d1\u7763\u4e0b\u89e3\u51b3\u56fe\u50cf\u5f15\u5bfc\u68c0\u7d22\u95ee\u9898\uff0c\u5728CIR\u548cSBIR\u4efb\u52a1\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\u3002", "motivation": "\u89e3\u51b3\u56fe\u50cf\u5f15\u5bfc\u68c0\u7d22\uff08IGROT\uff09\u5728\u4f4e\u6570\u636e\u76d1\u7763\u4e0b\u7684\u6311\u6218\uff0c\u8be5\u8bbe\u7f6e\u7edf\u4e00\u4e86\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\uff08CIR\uff09\u548c\u57fa\u4e8e\u8349\u56fe\u7684\u56fe\u50cf\u68c0\u7d22\uff08SBIR\uff09\u4e24\u5927\u4efb\u52a1\u3002", "method": "\u63d0\u51faUNION\u65b9\u6cd5\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u53ef\u6cdb\u5316\u7684\u76ee\u6807\u8868\u793a\uff0c\u5c06\u56fe\u50cf\u5d4c\u5165\u4e0e\u7a7a\u6587\u672c\u63d0\u793a\u878d\u5408\uff0c\u65e0\u9700\u4fee\u6539\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u67b6\u6784\u3002", "result": "\u4ec5\u75285,000\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u5728CIRCO\u6570\u636e\u96c6\u4e0a\u8fbe\u5230mAP@50\u4e3a38.5\uff0c\u5728Sketchy\u6570\u636e\u96c6\u4e0a\u8fbe\u5230mAP@200\u4e3a82.7\uff0c\u8d85\u8d8a\u4e86\u8bb8\u591a\u91cd\u5ea6\u76d1\u7763\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "UNION\u65b9\u6cd5\u5c55\u793a\u4e86\u5728\u5c11\u91cf\u6570\u636e\u4e0b\u8de8\u4e0d\u540c\u67e5\u8be2\u7c7b\u578b\u6865\u63a5\u89c6\u89c9\u548c\u8bed\u8a00\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\uff0c\u4e3a\u4f4e\u6570\u636e\u76d1\u7763\u4e0b\u7684\u56fe\u50cf\u68c0\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21705", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.21705", "abs": "https://arxiv.org/abs/2511.21705", "authors": ["Junjie Wu", "Yumeng Fu", "Chen Gong", "Guohong Fu"], "title": "Insight-A: Attribution-aware for Multimodal Misinformation Detection", "comment": null, "summary": "AI-generated content (AIGC) technology has emerged as a prevalent alternative to create multimodal misinformation on social media platforms, posing unprecedented threats to societal safety. However, standard prompting leverages multimodal large language models (MLLMs) to identify the emerging misinformation, which ignores the misinformation attribution. To this end, we present Insight-A, exploring attribution with MLLM insights for detecting multimodal misinformation. Insight-A makes two efforts: I) attribute misinformation to forgery sources, and II) an effective pipeline with hierarchical reasoning that detects distortions across modalities. Specifically, to attribute misinformation to forgery traces based on generation patterns, we devise cross-attribution prompting (CAP) to model the sophisticated correlations between perception and reasoning. Meanwhile, to reduce the subjectivity of human-annotated prompts, automatic attribution-debiased prompting (ADP) is used for task adaptation on MLLMs. Additionally, we design image captioning (IC) to achieve visual details for enhancing cross-modal consistency checking. Extensive experiments demonstrate the superiority of our proposal and provide a new paradigm for multimodal misinformation detection in the era of AIGC.", "AI": {"tldr": "Insight-A\uff1a\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u5f52\u56e0\u6d1e\u5bdf\u68c0\u6d4b\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\uff0c\u901a\u8fc7\u8de8\u5f52\u56e0\u63d0\u793a\u548c\u81ea\u52a8\u5f52\u56e0\u53bb\u504f\u63d0\u793a\u6765\u8bc6\u522b\u4f2a\u9020\u6765\u6e90\u548c\u8de8\u6a21\u6001\u5931\u771f\u3002", "motivation": "AI\u751f\u6210\u5185\u5bb9\uff08AIGC\uff09\u6280\u672f\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u5236\u9020\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\uff0c\u5bf9\u793e\u4f1a\u5b89\u5168\u6784\u6210\u5a01\u80c1\u3002\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u6807\u51c6\u63d0\u793a\u8ba9MLLMs\u8bc6\u522b\u865a\u5047\u4fe1\u606f\uff0c\u4f46\u5ffd\u7565\u4e86\u865a\u5047\u4fe1\u606f\u7684\u5f52\u56e0\uff08\u5373\u6765\u6e90\u548c\u4f2a\u9020\u75d5\u8ff9\uff09\u3002", "method": "1. \u8de8\u5f52\u56e0\u63d0\u793a\uff08CAP\uff09\uff1a\u5efa\u6a21\u611f\u77e5\u4e0e\u63a8\u7406\u4e4b\u95f4\u7684\u590d\u6742\u5173\u8054\uff0c\u5c06\u865a\u5047\u4fe1\u606f\u5f52\u56e0\u4e8e\u57fa\u4e8e\u751f\u6210\u6a21\u5f0f\u7684\u4f2a\u9020\u75d5\u8ff9\u30022. \u81ea\u52a8\u5f52\u56e0\u53bb\u504f\u63d0\u793a\uff08ADP\uff09\uff1a\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u63d0\u793a\u7684\u4e3b\u89c2\u6027\uff0c\u5b9e\u73b0MLLMs\u7684\u4efb\u52a1\u9002\u5e94\u30023. \u56fe\u50cf\u63cf\u8ff0\uff08IC\uff09\uff1a\u83b7\u53d6\u89c6\u89c9\u7ec6\u8282\u4ee5\u589e\u5f3a\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u68c0\u67e5\u30024. \u5206\u5c42\u63a8\u7406\u7ba1\u9053\uff1a\u68c0\u6d4b\u8de8\u6a21\u6001\u7684\u5931\u771f\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u4e3aAIGC\u65f6\u4ee3\u7684\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002", "conclusion": "Insight-A\u901a\u8fc7\u63a2\u7d22MLLMs\u7684\u5f52\u56e0\u6d1e\u5bdf\uff0c\u6709\u6548\u68c0\u6d4b\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\uff0c\u7279\u522b\u662f\u901a\u8fc7\u8bc6\u522b\u4f2a\u9020\u6765\u6e90\u548c\u8de8\u6a21\u6001\u5931\u771f\uff0c\u4e3a\u5e94\u5bf9AIGC\u5e26\u6765\u7684\u865a\u5047\u4fe1\u606f\u5a01\u80c1\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.22263", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22263", "abs": "https://arxiv.org/abs/2511.22263", "authors": ["Taeryun Won", "Tae Kwan Lee", "Hiun Kim", "Hyemin Lee"], "title": "Efficiency and Effectiveness of SPLADE Models on Billion-Scale Web Document Title", "comment": null, "summary": "This paper presents a comprehensive comparison of BM25, SPLADE, and Expanded-SPLADE models in the context of large-scale web document retrieval. We evaluate the effectiveness and efficiency of these models on datasets spanning from tens of millions to billions of web document titles. SPLADE and Expanded-SPLADE, which utilize sparse lexical representations, demonstrate superior retrieval performance compared to BM25, especially for complex queries. However, these models incur higher computational costs. We introduce pruning strategies, including document-centric pruning and top-k query term selection, boolean query with term threshold to mitigate these costs and improve the models' efficiency without significantly sacrificing retrieval performance. The results show that Expanded-SPLADE strikes the best balance between effectiveness and efficiency, particularly when handling large datasets. Our findings offer valuable insights for deploying sparse retrieval models in large-scale search engines.", "AI": {"tldr": "BM25\u3001SPLADE\u548cExpanded-SPLADE\u5728\u5927\u89c4\u6a21\u7f51\u9875\u6587\u6863\u68c0\u7d22\u4e2d\u7684\u5bf9\u6bd4\u7814\u7a76\uff0c\u53d1\u73b0\u7a00\u758f\u8868\u793a\u6a21\u578b\u6027\u80fd\u66f4\u4f18\u4f46\u8ba1\u7b97\u6210\u672c\u66f4\u9ad8\uff0c\u901a\u8fc7\u526a\u679d\u7b56\u7565\u4f18\u5316\u540eExpanded-SPLADE\u5728\u6548\u679c\u548c\u6548\u7387\u95f4\u53d6\u5f97\u6700\u4f73\u5e73\u8861\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u7f51\u9875\u6587\u6863\u68c0\u7d22\u573a\u666f\u4e2d\uff0c\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u68c0\u7d22\u6a21\u578b\uff08\u4f20\u7edfBM25\u4e0e\u57fa\u4e8e\u7a00\u758f\u8868\u793a\u7684SPLADE\u7cfb\u5217\uff09\u5728\u6548\u679c\u548c\u6548\u7387\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4e3a\u5b9e\u9645\u641c\u7d22\u5f15\u64ce\u90e8\u7f72\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u5728\u5343\u4e07\u5230\u6570\u5341\u4ebf\u89c4\u6a21\u7684\u7f51\u9875\u6587\u6863\u6807\u9898\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4BM25\u3001SPLADE\u548cExpanded-SPLADE\u6a21\u578b\uff1b\u5f15\u5165\u6587\u6863\u4e2d\u5fc3\u526a\u679d\u3001top-k\u67e5\u8be2\u8bcd\u9009\u62e9\u3001\u5e03\u5c14\u67e5\u8be2\u52a0\u8bcd\u9879\u9608\u503c\u7b49\u7b56\u7565\u6765\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u3002", "result": "SPLADE\u548cExpanded-SPLADE\u5728\u68c0\u7d22\u6548\u679c\u4e0a\u4f18\u4e8eBM25\uff0c\u7279\u522b\u662f\u590d\u6742\u67e5\u8be2\uff1b\u4f46\u8ba1\u7b97\u6210\u672c\u66f4\u9ad8\uff1b\u901a\u8fc7\u526a\u679d\u7b56\u7565\u53ef\u663e\u8457\u63d0\u5347\u6548\u7387\u800c\u4e0d\u660e\u663e\u635f\u5931\u6027\u80fd\uff1bExpanded-SPLADE\u5728\u6548\u679c\u548c\u6548\u7387\u95f4\u8fbe\u5230\u6700\u4f73\u5e73\u8861\u3002", "conclusion": "\u7a00\u758f\u68c0\u7d22\u6a21\u578b\u5728\u5927\u89c4\u6a21\u68c0\u7d22\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u4f18\u5316\u7b56\u7565\u53ef\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u63a7\u5236\u8ba1\u7b97\u6210\u672c\uff0cExpanded-SPLADE\u662f\u5b9e\u9645\u90e8\u7f72\u7684\u63a8\u8350\u9009\u62e9\uff0c\u4e3a\u5927\u89c4\u6a21\u641c\u7d22\u5f15\u64ce\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u90e8\u7f72\u6307\u5bfc\u3002"}}
{"id": "2511.21706", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21706", "abs": "https://arxiv.org/abs/2511.21706", "authors": ["Hui Wang", "Fafa Zhang", "Xiaoyu Zhang", "Chaoxu Mu"], "title": "A General Highly Accurate Online Planning Method Integrating Large Language Models into Nested Rollout Policy Adaptation for Dialogue Tasks", "comment": null, "summary": "In goal-oriented dialogue tasks, the main challenge is to steer the interaction towards a given goal within a limited number of turns. Existing approaches either rely on elaborate prompt engineering, whose effectiveness is heavily dependent on human experience, or integrate policy networks and pre-trained policy models, which are usually difficult to adapt to new dialogue scenarios and costly to train. Therefore, in this paper, we present Nested Rollout Policy Adaptation for Goal-oriented Dialogue (NRPA-GD), a novel dialogue policy planning method that completely avoids specific model training by utilizing a Large Language Model (LLM) to simulate behaviors of user and system at the same time. Specifically, NRPA-GD constructs a complete evaluation mechanism for dialogue trajectories and employs an optimization framework of nested Monte Carlo simulation and policy self-adaptation to dynamically adjust policies during the dialogue process. The experimental results on four typical goal-oriented dialogue datasets show that NRPA-GD outperforms both existing prompt engineering and specifically pre-trained model-based methods. Impressively, NRPA-GD surpasses ChatGPT and pre-trained policy models with only a 0.6-billion-parameter LLM. The proposed approach further demonstrates the advantages and novelty of employing planning methods on LLMs to solve practical planning tasks.", "AI": {"tldr": "NRPA-GD\u662f\u4e00\u79cd\u65b0\u9896\u7684\u9762\u5411\u76ee\u6807\u5bf9\u8bdd\u7b56\u7565\u89c4\u5212\u65b9\u6cd5\uff0c\u5b8c\u5168\u907f\u514d\u7279\u5b9a\u6a21\u578b\u8bad\u7ec3\uff0c\u5229\u7528LLM\u540c\u65f6\u6a21\u62df\u7528\u6237\u548c\u7cfb\u7edf\u884c\u4e3a\uff0c\u901a\u8fc7\u5d4c\u5957\u8499\u7279\u5361\u6d1b\u6a21\u62df\u548c\u7b56\u7565\u81ea\u9002\u5e94\u4f18\u5316\u6846\u67b6\u52a8\u6001\u8c03\u6574\u5bf9\u8bdd\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u9762\u5411\u76ee\u6807\u5bf9\u8bdd\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4eba\u5de5\u7ecf\u9a8c\u9a71\u52a8\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u8981\u4e48\u9700\u8981\u8bad\u7ec3\u7b56\u7565\u7f51\u7edc\u6216\u9884\u8bad\u7ec3\u7b56\u7565\u6a21\u578b\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u65b0\u5bf9\u8bdd\u573a\u666f\u4e14\u8bad\u7ec3\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faNRPA-GD\u65b9\u6cd5\uff1a1) \u5229\u7528LLM\u540c\u65f6\u6a21\u62df\u7528\u6237\u548c\u7cfb\u7edf\u884c\u4e3a\uff1b2) \u6784\u5efa\u5b8c\u6574\u7684\u5bf9\u8bdd\u8f68\u8ff9\u8bc4\u4f30\u673a\u5236\uff1b3) \u91c7\u7528\u5d4c\u5957\u8499\u7279\u5361\u6d1b\u6a21\u62df\u548c\u7b56\u7565\u81ea\u9002\u5e94\u7684\u4f18\u5316\u6846\u67b6\uff0c\u5728\u5bf9\u8bdd\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u7b56\u7565\u3002", "result": "\u5728\u56db\u4e2a\u5178\u578b\u9762\u5411\u76ee\u6807\u5bf9\u8bdd\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNRPA-GD\u4f18\u4e8e\u73b0\u6709\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u65b9\u6cd5\u3002\u4ec5\u4f7f\u75280.6\u4ebf\u53c2\u6570LLM\u5c31\u8d85\u8d8a\u4e86ChatGPT\u548c\u9884\u8bad\u7ec3\u7b56\u7565\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5728LLM\u4e0a\u5e94\u7528\u89c4\u5212\u65b9\u6cd5\u89e3\u51b3\u5b9e\u9645\u89c4\u5212\u4efb\u52a1\u7684\u4f18\u52bf\u548c\u65b0\u9896\u6027\uff0c\u4e3a\u9762\u5411\u76ee\u6807\u5bf9\u8bdd\u63d0\u4f9b\u4e86\u65e0\u9700\u7279\u5b9a\u8bad\u7ec3\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.22707", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22707", "abs": "https://arxiv.org/abs/2511.22707", "authors": ["Tianxin Wei", "Xuying Ning", "Xuxing Chen", "Ruizhong Qiu", "Yupeng Hou", "Yan Xie", "Shuang Yang", "Zhigang Hua", "Jingrui He"], "title": "CoFiRec: Coarse-to-Fine Tokenization for Generative Recommendation", "comment": null, "summary": "In web environments, user preferences are often refined progressively as users move from browsing broad categories to exploring specific items. However, existing generative recommenders overlook this natural refinement process. Generative recommendation formulates next-item prediction as autoregressive generation over tokenized user histories, where each item is represented as a sequence of discrete tokens. Prior models typically fuse heterogeneous attributes such as ID, category, title, and description into a single embedding before quantization, which flattens the inherent semantic hierarchy of items and fails to capture the gradual evolution of user intent during web interactions. To address this limitation, we propose CoFiRec, a novel generative recommendation framework that explicitly incorporates the Coarse-to-Fine nature of item semantics into the tokenization process. Instead of compressing all attributes into a single latent space, CoFiRec decomposes item information into multiple semantic levels, ranging from high-level categories to detailed descriptions and collaborative filtering signals. Based on this design, we introduce the CoFiRec Tokenizer, which tokenizes each level independently while preserving structural order. During autoregressive decoding, the language model is instructed to generate item tokens from coarse to fine, progressively modeling user intent from general interests to specific item-level interests. Experiments across multiple public benchmarks and backbones demonstrate that CoFiRec outperforms existing methods, offering a new perspective for generative recommendation. Theoretically, we prove that structured tokenization leads to lower dissimilarity between generated and ground truth items, supporting its effectiveness in generative recommendation. Our code is available at https://github.com/YennNing/CoFiRec.", "AI": {"tldr": "CoFiRec\uff1a\u4e00\u79cd\u65b0\u9896\u7684\u751f\u6210\u5f0f\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9879\u76ee\u8bed\u4e49\u4ece\u7c97\u5230\u7ec6\u5206\u89e3\u4e3a\u591a\u4e2a\u5c42\u6b21\u8fdb\u884c\u72ec\u7acb\u6807\u8bb0\u5316\uff0c\u5728\u81ea\u56de\u5f52\u89e3\u7801\u4e2d\u6a21\u62df\u7528\u6237\u610f\u56fe\u4ece\u4e00\u822c\u5174\u8da3\u5230\u5177\u4f53\u9879\u76ee\u5174\u8da3\u7684\u6e10\u8fdb\u6f14\u53d8\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u5ffd\u7565\u4e86\u7528\u6237\u5728\u7f51\u9875\u73af\u5883\u4e2d\u4ece\u6d4f\u89c8\u5bbd\u6cdb\u7c7b\u522b\u5230\u63a2\u7d22\u5177\u4f53\u9879\u76ee\u7684\u81ea\u7136\u7ec6\u5316\u8fc7\u7a0b\u3002\u4f20\u7edf\u65b9\u6cd5\u5c06\u6240\u6709\u5f02\u6784\u5c5e\u6027\u878d\u5408\u5230\u5355\u4e00\u5d4c\u5165\u4e2d\u518d\u8fdb\u884c\u91cf\u5316\uff0c\u8fd9\u62b9\u5e73\u4e86\u9879\u76ee\u56fa\u6709\u7684\u8bed\u4e49\u5c42\u6b21\u7ed3\u6784\uff0c\u65e0\u6cd5\u6355\u6349\u7528\u6237\u610f\u56fe\u5728\u7f51\u9875\u4ea4\u4e92\u4e2d\u7684\u6e10\u8fdb\u6f14\u53d8\u3002", "method": "\u63d0\u51faCoFiRec\u6846\u67b6\uff0c\u5c06\u9879\u76ee\u4fe1\u606f\u5206\u89e3\u4e3a\u4ece\u9ad8\u7ea7\u7c7b\u522b\u5230\u8be6\u7ec6\u63cf\u8ff0\u548c\u534f\u540c\u8fc7\u6ee4\u4fe1\u53f7\u7684\u591a\u4e2a\u8bed\u4e49\u5c42\u6b21\u3002\u8bbe\u8ba1CoFiRec\u6807\u8bb0\u5668\uff0c\u72ec\u7acb\u6807\u8bb0\u6bcf\u4e2a\u5c42\u6b21\u540c\u65f6\u4fdd\u6301\u7ed3\u6784\u987a\u5e8f\u3002\u5728\u81ea\u56de\u5f52\u89e3\u7801\u4e2d\uff0c\u8bed\u8a00\u6a21\u578b\u88ab\u6307\u5bfc\u4ece\u7c97\u5230\u7ec6\u751f\u6210\u9879\u76ee\u6807\u8bb0\uff0c\u6e10\u8fdb\u5efa\u6a21\u7528\u6237\u610f\u56fe\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u548c\u9aa8\u5e72\u7f51\u7edc\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cCoFiRec\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u7406\u8bba\u4e0a\u8bc1\u660e\u7ed3\u6784\u5316\u6807\u8bb0\u5316\u80fd\u964d\u4f4e\u751f\u6210\u9879\u76ee\u4e0e\u771f\u5b9e\u9879\u76ee\u4e4b\u95f4\u7684\u4e0d\u76f8\u4f3c\u6027\uff0c\u652f\u6301\u5176\u5728\u751f\u6210\u5f0f\u63a8\u8350\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "CoFiRec\u901a\u8fc7\u663e\u5f0f\u5730\u5c06\u9879\u76ee\u8bed\u4e49\u7684\u4ece\u7c97\u5230\u7ec6\u7279\u6027\u7eb3\u5165\u6807\u8bb0\u5316\u8fc7\u7a0b\uff0c\u4e3a\u751f\u6210\u5f0f\u63a8\u8350\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u7528\u6237\u610f\u56fe\u7684\u6e10\u8fdb\u6f14\u53d8\u8fc7\u7a0b\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.21708", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21708", "abs": "https://arxiv.org/abs/2511.21708", "authors": ["Matteo Spreafico", "Ludovica Tassini", "Camilla Sancricca", "Cinzia Cappiello"], "title": "Lost in the Pipeline: How Well Do Large Language Models Handle Data Preparation?", "comment": null, "summary": "Large language models have recently demonstrated their exceptional capabilities in supporting and automating various tasks. Among the tasks worth exploring for testing large language model capabilities, we considered data preparation, a critical yet often labor-intensive step in data-driven processes. This paper investigates whether large language models can effectively support users in selecting and automating data preparation tasks. To this aim, we considered both general-purpose and fine-tuned tabular large language models. We prompted these models with poor-quality datasets and measured their ability to perform tasks such as data profiling and cleaning. We also compare the support provided by large language models with that offered by traditional data preparation tools. To evaluate the capabilities of large language models, we developed a custom-designed quality model that has been validated through a user study to gain insights into practitioners' expectations.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u636e\u51c6\u5907\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u8bc4\u4f30\uff0c\u5305\u62ec\u6570\u636e\u5206\u6790\u548c\u6e05\u6d17\uff0c\u4e0e\u4f20\u7edf\u5de5\u5177\u5bf9\u6bd4", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u636e\u51c6\u5907\u8fd9\u4e00\u5173\u952e\u4f46\u52b3\u52a8\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u652f\u6301\u80fd\u529b\uff0c\u6d4b\u8bd5\u5176\u80fd\u5426\u6709\u6548\u5e2e\u52a9\u7528\u6237\u9009\u62e9\u548c\u81ea\u52a8\u5316\u6570\u636e\u51c6\u5907\u4efb\u52a1", "method": "\u4f7f\u7528\u901a\u7528\u548c\u5fae\u8c03\u7684\u8868\u683c\u578b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4f4e\u8d28\u91cf\u6570\u636e\u96c6\u8fdb\u884c\u63d0\u793a\uff0c\u6d4b\u91cf\u5176\u6267\u884c\u6570\u636e\u5206\u6790\u548c\u6e05\u6d17\u7b49\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u5e76\u4e0e\u4f20\u7edf\u6570\u636e\u51c6\u5907\u5de5\u5177\u5bf9\u6bd4", "result": "\u5f00\u53d1\u4e86\u7ecf\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u7684\u81ea\u5b9a\u4e49\u8d28\u91cf\u6a21\u578b\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\uff0c\u83b7\u5f97\u4e86\u4ece\u4e1a\u8005\u671f\u671b\u7684\u6d1e\u5bdf", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u652f\u6301\u6570\u636e\u51c6\u5907\u4efb\u52a1\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u4e0e\u4f20\u7edf\u5de5\u5177\u76f8\u6bd4\u7684\u5b9e\u9645\u6548\u679c"}}
{"id": "2511.22855", "categories": ["cs.IR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.22855", "abs": "https://arxiv.org/abs/2511.22855", "authors": ["Zhongming Feng", "Qiling Gao", "Zeping Sui", "Yun Lin", "Michail Matthaiou"], "title": "Two-Stage Distributionally Robust Optimization Framework for Secure Communications in Aerial-RIS Systems", "comment": "5 pages", "summary": "This letter proposes a two-stage distributionally robust optimization (DRO) framework for secure deployment and beamforming in an aerial reconfigurable intelligent surface (A-RIS) assisted millimeter-wave system. To account for multi-timescale uncertainties arising from user mobility, imperfect channel state information (CSI), and hardware impairments, our approach decouples the long-term unmanned aerial vehicle (UAV) placement from the per-slot beamforming design. By employing the conditional value-at-risk (CVaR) as a distribution-free risk metric, a low-complexity algorithm is developed, which combines a surrogate model for efficient deployment with an alternating optimization (AO) scheme for robust real-time beamforming. Simulation results validate that the proposed DRO-CVaR framework significantly enhances the tail-end secrecy spectral efficiency and maintains a lower outage probability compared to benchmark schemes, especially under severe uncertainty conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u7a7a\u4e2d\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u8f85\u52a9\u6beb\u7c73\u6ce2\u7cfb\u7edf\u7684\u5b89\u5168\u90e8\u7f72\u548c\u6ce2\u675f\u6210\u5f62\uff0c\u901a\u8fc7CVaR\u98ce\u9669\u5ea6\u91cf\u5904\u7406\u591a\u65f6\u95f4\u5c3a\u5ea6\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u7a7a\u4e2d\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u8f85\u52a9\u6beb\u7c73\u6ce2\u7cfb\u7edf\u4e2d\u7531\u7528\u6237\u79fb\u52a8\u6027\u3001\u4e0d\u5b8c\u7f8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u548c\u786c\u4ef6\u635f\u4f24\u5f15\u8d77\u7684\u591a\u65f6\u95f4\u5c3a\u5ea6\u4e0d\u786e\u5b9a\u6027\u6311\u6218\uff0c\u786e\u4fdd\u7cfb\u7edf\u5b89\u5168\u90e8\u7f72\u548c\u6027\u80fd\u9c81\u68d2\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff1a1) \u957f\u671f\u65e0\u4eba\u673a\u90e8\u7f72\u4e0e\u6bcf\u65f6\u9699\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u89e3\u8026\uff1b2) \u4f7f\u7528\u6761\u4ef6\u98ce\u9669\u4ef7\u503c\u4f5c\u4e3a\u5206\u5e03\u65e0\u5173\u98ce\u9669\u5ea6\u91cf\uff1b3) \u5f00\u53d1\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\uff0c\u7ed3\u5408\u4ee3\u7406\u6a21\u578b\u8fdb\u884c\u9ad8\u6548\u90e8\u7f72\u548c\u4ea4\u66ff\u4f18\u5316\u65b9\u6848\u8fdb\u884c\u9c81\u68d2\u5b9e\u65f6\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684DRO-CVaR\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u5c3e\u90e8\u4fdd\u5bc6\u9891\u8c31\u6548\u7387\uff0c\u5e76\u5728\u4e25\u91cd\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\u4fdd\u6301\u4e86\u66f4\u4f4e\u7684\u4e2d\u65ad\u6982\u7387\u3002", "conclusion": "\u8be5\u4e24\u9636\u6bb5\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86A-RIS\u8f85\u52a9\u6beb\u7c73\u6ce2\u7cfb\u7edf\u4e2d\u7684\u591a\u65f6\u95f4\u5c3a\u5ea6\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u5728\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.21709", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.21709", "abs": "https://arxiv.org/abs/2511.21709", "authors": ["Blessed Guda", "Lawrence Francis", "Gabrial Zencha Ashungafac", "Carlee Joe-Wong", "Moise Busogi"], "title": "Quantifying and Mitigating Selection Bias in LLMs: A Transferable LoRA Fine-Tuning and Efficient Majority Voting Approach", "comment": "Accepted into IJCNLP-AACL 2026", "summary": "Multiple Choice Question (MCQ) answering is a widely used method for evaluating the performance of Large Language Models (LLMs). However, LLMs often exhibit selection bias in MCQ tasks, where their choices are influenced by factors like answer position or option symbols rather than the content. This bias undermines the reliability of MCQ as an evaluation framework. Most existing selection bias metrics require answer labels and measure divergences between prediction and answer distributions, but do not fully capture the consistency of a model's predictions across different orderings of answer choices. Existing selection bias mitigation strategies have notable limitations: majority voting, though effective, is computationally prohibitive; calibration-based methods require validation sets and often fail to generalize across datasets. To address these gaps, we propose three key contributions: (1) a new unsupervised label-free Permutation Bias Metric (PBM) that directly quantifies inconsistencies in model predictions across answer permutations, providing a more precise measure of selection bias, (2) an efficient majority voting approach called Batch Question-Context KV caching (BaQCKV), to significantly reduce computational costs while preserving bias mitigation effectiveness, and (3) an unsupervised Low-Rank Adaptation (LoRA-1) fine-tuning strategy based on our proposed metric and the BaQCKV that mitigates selection bias, providing a computationally efficient alternative that maintains model generalizability. Experiments across multiple MCQ benchmarks demonstrate that our approaches reduce bias, increasing consistency in accuracy while minimizing computational costs.", "AI": {"tldr": "\u63d0\u51faPBM\u65e0\u76d1\u7763\u5ea6\u91cf\u3001BaQCKV\u9ad8\u6548\u591a\u6570\u6295\u7968\u548cLoRA-1\u5fae\u8c03\u7b56\u7565\uff0c\u89e3\u51b3LLM\u5728MCQ\u4efb\u52a1\u4e2d\u7684\u9009\u62e9\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u9ad8\u8bc4\u4f30\u53ef\u9760\u6027\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9879\u9009\u62e9\u9898\u4efb\u52a1\u4e2d\u5b58\u5728\u9009\u62e9\u504f\u5dee\uff0c\u5176\u9009\u62e9\u53d7\u5230\u7b54\u6848\u4f4d\u7f6e\u6216\u9009\u9879\u7b26\u53f7\u7b49\u975e\u5185\u5bb9\u56e0\u7d20\u5f71\u54cd\uff0c\u8fd9\u524a\u5f31\u4e86MCQ\u4f5c\u4e3a\u8bc4\u4f30\u6846\u67b6\u7684\u53ef\u9760\u6027\u3002\u73b0\u6709\u504f\u5dee\u5ea6\u91cf\u65b9\u6cd5\u9700\u8981\u7b54\u6848\u6807\u7b7e\u4e14\u65e0\u6cd5\u5145\u5206\u6355\u6349\u6a21\u578b\u5728\u4e0d\u540c\u7b54\u6848\u6392\u5e8f\u4e0b\u9884\u6d4b\u7684\u4e00\u81f4\u6027\uff0c\u800c\u73b0\u6709\u7f13\u89e3\u7b56\u7565\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u6216\u6cdb\u5316\u80fd\u529b\u5dee\u7b49\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u4e2a\u5173\u952e\u8d21\u732e\uff1a1) \u65e0\u76d1\u7763\u6807\u7b7e\u81ea\u7531\u7684\u6392\u5217\u504f\u5dee\u5ea6\u91cf(PBM)\uff0c\u76f4\u63a5\u91cf\u5316\u6a21\u578b\u5728\u4e0d\u540c\u7b54\u6848\u6392\u5217\u4e0b\u9884\u6d4b\u7684\u4e0d\u4e00\u81f4\u6027\uff1b2) \u6279\u91cf\u95ee\u9898\u4e0a\u4e0b\u6587KV\u7f13\u5b58(BaQCKV)\u7684\u9ad8\u6548\u591a\u6570\u6295\u7968\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff1b3) \u57fa\u4e8ePBM\u548cBaQCKV\u7684\u65e0\u76d1\u7763\u4f4e\u79e9\u9002\u5e94(LoRA-1)\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2aMCQ\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u51cf\u5c11\u504f\u5dee\uff0c\u63d0\u9ad8\u51c6\u786e\u7387\u7684\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u63d0\u51fa\u7684PBM\u5ea6\u91cf\u3001BaQCKV\u9ad8\u6548\u6295\u7968\u548cLoRA-1\u5fae\u8c03\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728MCQ\u4efb\u52a1\u4e2d\u7684\u9009\u62e9\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u504f\u5dee\u7f13\u89e3\u65b9\u6848\u3002"}}
{"id": "2511.22872", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.22872", "abs": "https://arxiv.org/abs/2511.22872", "authors": ["Yuyuan Li", "Junjie Fang", "Fengyuan Yu", "Xichun Sheng", "Tianyu Du", "Xuyang Teng", "Shaowei Jiang", "Linbo Jiang", "Jianan Lin", "Chaochao Chen"], "title": "FedAU2: Attribute Unlearning for User-Level Federated Recommender Systems with Adaptive and Robust Adversarial Training", "comment": null, "summary": "Federated Recommender Systems (FedRecs) leverage federated learning to protect user privacy by retaining data locally. However, user embeddings in FedRecs often encode sensitive attribute information, rendering them vulnerable to attribute inference attacks. Attribute unlearning has emerged as a promising approach to mitigate this issue. In this paper, we focus on user-level FedRecs, which is a more practical yet challenging setting compared to group-level FedRecs. Adversarial training emerges as the most feasible approach within this context. We identify two key challenges in implementing adversarial training-based attribute unlearning for user-level FedRecs: i) mitigating training instability caused by user data heterogeneity, and ii) preventing attribute information leakage through gradients. To address these challenges, we propose FedAU2, an attribute unlearning method for user-level FedRecs. For CH1, we propose an adaptive adversarial training strategy, where the training dynamics are adjusted in response to local optimization behavior. For CH2, we propose a dual-stochastic variational autoencoder to perturb the adversarial model, effectively preventing gradient-based information leakage. Extensive experiments on three real-world datasets demonstrate that our proposed FedAU2 achieves superior performance in unlearning effectiveness and recommendation performance compared to existing baselines.", "AI": {"tldr": "FedAU2\uff1a\u4e00\u79cd\u9488\u5bf9\u7528\u6237\u7ea7\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u7684\u5c5e\u6027\u9057\u5fd8\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5bf9\u6297\u8bad\u7ec3\u548c\u53cc\u91cd\u968f\u673a\u53d8\u5206\u81ea\u7f16\u7801\u5668\u89e3\u51b3\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u548c\u68af\u5ea6\u4fe1\u606f\u6cc4\u9732\u95ee\u9898\u3002", "motivation": "\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u867d\u7136\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u4f46\u7528\u6237\u5d4c\u5165\u4ecd\u53ef\u80fd\u7f16\u7801\u654f\u611f\u5c5e\u6027\u4fe1\u606f\uff0c\u6613\u53d7\u5c5e\u6027\u63a8\u65ad\u653b\u51fb\u3002\u73b0\u6709\u5c5e\u6027\u9057\u5fd8\u65b9\u6cd5\u5728\u7528\u6237\u7ea7\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u548c\u68af\u5ea6\u4fe1\u606f\u6cc4\u9732\u95ee\u9898\u3002", "method": "\u63d0\u51faFedAU2\u65b9\u6cd5\uff1a1\uff09\u81ea\u9002\u5e94\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\uff0c\u6839\u636e\u672c\u5730\u4f18\u5316\u884c\u4e3a\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u8fc7\u7a0b\u4ee5\u5e94\u5bf9\u7528\u6237\u6570\u636e\u5f02\u8d28\u6027\uff1b2\uff09\u53cc\u91cd\u968f\u673a\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6270\u52a8\u5bf9\u6297\u6a21\u578b\uff0c\u9632\u6b62\u57fa\u4e8e\u68af\u5ea6\u7684\u4fe1\u606f\u6cc4\u9732\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFedAU2\u5728\u5c5e\u6027\u9057\u5fd8\u6548\u679c\u548c\u63a8\u8350\u6027\u80fd\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FedAU2\u6709\u6548\u89e3\u51b3\u4e86\u7528\u6237\u7ea7\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5c5e\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u63a8\u8350\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.21711", "categories": ["cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21711", "abs": "https://arxiv.org/abs/2511.21711", "authors": ["Fatima Kazi"], "title": "Addressing Stereotypes in Large Language Models: A Critical Examination and Mitigation", "comment": null, "summary": "Large Language models (LLMs), such as ChatGPT, have gained popularity in recent years with the advancement of Natural Language Processing (NLP), with use cases spanning many disciplines and daily lives as well. LLMs inherit explicit and implicit biases from the datasets they were trained on; these biases can include social, ethical, cultural, religious, and other prejudices and stereotypes. It is important to comprehensively examine such shortcomings by identifying the existence and extent of such biases, recognizing the origin, and attempting to mitigate such biased outputs to ensure fair outputs to reduce harmful stereotypes and misinformation. This study inspects and highlights the need to address biases in LLMs amid growing generative Artificial Intelligence (AI). We utilize bias-specific benchmarks such StereoSet and CrowSPairs to evaluate the existence of various biases in many different generative models such as BERT, GPT 3.5, and ADA. To detect both explicit and implicit biases, we adopt a three-pronged approach for thorough and inclusive analysis. Results indicate fine-tuned models struggle with gender biases but excel at identifying and avoiding racial biases. Our findings also illustrated that despite some cases of success, LLMs often over-rely on keywords in prompts and its outputs. This demonstrates the incapability of LLMs to attempt to truly understand the accuracy and authenticity of its outputs. Finally, in an attempt to bolster model performance, we applied an enhancement learning strategy involving fine-tuning, models using different prompting techniques, and data augmentation of the bias benchmarks. We found fine-tuned models to exhibit promising adaptability during cross-dataset testing and significantly enhanced performance on implicit bias benchmarks, with performance gains of up to 20%.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u4f7f\u7528StereoSet\u548cCrowSPairs\u57fa\u51c6\u6d4b\u8bd5\u591a\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u5fae\u8c03\u6a21\u578b\u5728\u6027\u522b\u504f\u89c1\u4e0a\u8868\u73b0\u4e0d\u4f73\u4f46\u5728\u79cd\u65cf\u504f\u89c1\u8bc6\u522b\u4e0a\u8f83\u597d\uff0c\u5e76\u901a\u8fc7\u589e\u5f3a\u5b66\u4e60\u7b56\u7565\u63d0\u5347\u4e8620%\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u666e\u53ca\uff0c\u8fd9\u4e9b\u6a21\u578b\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u7ee7\u627f\u4e86\u663e\u6027\u548c\u9690\u6027\u7684\u793e\u4f1a\u3001\u4f26\u7406\u3001\u6587\u5316\u3001\u5b97\u6559\u7b49\u504f\u89c1\u548c\u523b\u677f\u5370\u8c61\u3002\u9700\u8981\u5168\u9762\u68c0\u67e5\u8fd9\u4e9b\u504f\u89c1\u7684\u5b58\u5728\u548c\u7a0b\u5ea6\uff0c\u8bc6\u522b\u5176\u6765\u6e90\uff0c\u5e76\u5c1d\u8bd5\u51cf\u8f7b\u8fd9\u4e9b\u6709\u504f\u89c1\u7684\u8f93\u51fa\uff0c\u4ee5\u786e\u4fdd\u516c\u5e73\u8f93\u51fa\u5e76\u51cf\u5c11\u6709\u5bb3\u7684\u523b\u677f\u5370\u8c61\u548c\u9519\u8bef\u4fe1\u606f\u3002", "method": "\u4f7f\u7528StereoSet\u548cCrowSPairs\u7b49\u504f\u89c1\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30BERT\u3001GPT 3.5\u548cADA\u7b49\u591a\u79cd\u751f\u6210\u6a21\u578b\u4e2d\u7684\u5404\u79cd\u504f\u89c1\u3002\u91c7\u7528\u4e09\u7ba1\u9f50\u4e0b\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u663e\u6027\u548c\u9690\u6027\u504f\u89c1\uff0c\u8fdb\u884c\u5f7b\u5e95\u548c\u5305\u5bb9\u6027\u7684\u5206\u6790\u3002\u5e94\u7528\u589e\u5f3a\u5b66\u4e60\u7b56\u7565\uff0c\u5305\u62ec\u5fae\u8c03\u3001\u4e0d\u540c\u7684\u63d0\u793a\u6280\u672f\u548c\u504f\u89c1\u57fa\u51c6\u7684\u6570\u636e\u589e\u5f3a\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5fae\u8c03\u6a21\u578b\u5728\u6027\u522b\u504f\u89c1\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4f46\u5728\u8bc6\u522b\u548c\u907f\u514d\u79cd\u65cf\u504f\u89c1\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u7814\u7a76\u53d1\u73b0LLMs\u7ecf\u5e38\u8fc7\u5ea6\u4f9d\u8d56\u63d0\u793a\u4e2d\u7684\u5173\u952e\u8bcd\uff0c\u65e0\u6cd5\u771f\u6b63\u7406\u89e3\u8f93\u51fa\u7684\u51c6\u786e\u6027\u548c\u771f\u5b9e\u6027\u3002\u589e\u5f3a\u5b66\u4e60\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5fae\u8c03\u6a21\u578b\u5728\u8de8\u6570\u636e\u96c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u6709\u5e0c\u671b\u7684\u9002\u5e94\u6027\uff0c\u5728\u9690\u6027\u504f\u89c1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe20%\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u65e5\u76ca\u589e\u957f\u7684\u80cc\u666f\u4e0b\u89e3\u51b3LLMs\u4e2d\u504f\u89c1\u95ee\u9898\u7684\u91cd\u8981\u6027\u3002\u867d\u7136\u5fae\u8c03\u6a21\u578b\u5728\u67d0\u4e9b\u504f\u89c1\u7c7b\u578b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46LLMs\u4ecd\u7136\u5b58\u5728\u8fc7\u5ea6\u4f9d\u8d56\u5173\u952e\u8bcd\u548c\u65e0\u6cd5\u771f\u6b63\u7406\u89e3\u8f93\u51fa\u7684\u5c40\u9650\u6027\u3002\u589e\u5f3a\u5b66\u4e60\u7b56\u7565\u4e3a\u6539\u5584\u6a21\u578b\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u9014\u5f84\uff0c\u4f46\u9700\u8981\u6301\u7eed\u52aa\u529b\u6765\u51cf\u8f7b\u504f\u89c1\u5e76\u786e\u4fdd\u516c\u5e73\u7684AI\u8f93\u51fa\u3002"}}
{"id": "2511.23312", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.23312", "abs": "https://arxiv.org/abs/2511.23312", "authors": ["Gustavo Penha", "Aleksandr V. Petrov", "Claudia Hauff", "Enrico Palumbo", "Ali Vardasbi", "Edoardo D'Amico", "Francesco Fabbri", "Alice Wang", "Praveen Chandar", "Henrik Lindstrom", "Hugues Bouchard", "Mounia Lalmas"], "title": "Do LLM-judges Align with Human Relevance in Cranfield-style Recommender Evaluation?", "comment": null, "summary": "Evaluating recommender systems remains a long-standing challenge, as offline methods based on historical user interactions and train-test splits often yield unstable and inconsistent results due to exposure bias, popularity bias, sampled evaluations, and missing-not-at-random patterns. In contrast, textual document retrieval benefits from robust, standardized evaluation via Cranfield-style test collections, which combine pooled relevance judgments with controlled setups. While recent work shows that adapting this methodology to recommender systems is feasible, constructing such collections remains costly due to the need for manual relevance judgments, thus limiting scalability. This paper investigates whether Large Language Models (LLMs) can serve as reliable automatic judges to address these scalability challenges. Using the ML-32M-ext Cranfield-style movie recommendation collection, we first examine the limitations of existing evaluation methodologies. Then we explore the alignment and the recommender systems ranking agreement between the LLM-judge and human provided relevance labels. We find that incorporating richer item metadata and longer user histories improves alignment, and that LLM-judge yields high agreement with human-based rankings (Kendall's tau = 0.87). Finally, an industrial case study in the podcast recommendation domain demonstrates the practical value of LLM-judge for model selection. Overall, our results show that LLM-judge is a viable and scalable approach for evaluating recommender systems.", "AI": {"tldr": "LLM\u53ef\u4ee5\u4f5c\u4e3a\u53ef\u9760\u7684\u81ea\u52a8\u8bc4\u4f30\u5668\u6765\u66ff\u4ee3\u4eba\u5de5\u6807\u6ce8\uff0c\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u8bc4\u4f30\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5728\u7535\u5f71\u63a8\u8350\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e0e\u4eba\u5de5\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\uff08Kendall's tau = 0.87\uff09\uff0c\u5e76\u5728\u64ad\u5ba2\u63a8\u8350\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5b9e\u7528\u6027\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u8bc4\u4f30\u9762\u4e34\u957f\u671f\u6311\u6218\uff1a\u57fa\u4e8e\u5386\u53f2\u4ea4\u4e92\u548c\u8bad\u7ec3\u6d4b\u8bd5\u5206\u5272\u7684\u79bb\u7ebf\u65b9\u6cd5\u5b58\u5728\u66dd\u5149\u504f\u5dee\u3001\u6d41\u884c\u5ea6\u504f\u5dee\u3001\u91c7\u6837\u8bc4\u4f30\u548cMNAR\u6a21\u5f0f\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u7a33\u5b9a\u4e0d\u4e00\u81f4\u3002\u867d\u7136Cranfield\u5f0f\u6d4b\u8bd5\u96c6\u5408\u80fd\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u4f30\uff0c\u4f46\u6784\u5efa\u6210\u672c\u9ad8\u6602\uff08\u9700\u8981\u4eba\u5de5\u76f8\u5173\u6027\u6807\u6ce8\uff09\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002", "method": "\u4f7f\u7528ML-32M-ext Cranfield\u5f0f\u7535\u5f71\u63a8\u8350\u6570\u636e\u96c6\uff0c\u9996\u5148\u5206\u6790\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u7136\u540e\u63a2\u7d22LLM\u8bc4\u4f30\u5668\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u76f8\u5173\u6027\u5bf9\u9f50\u548c\u63a8\u8350\u7cfb\u7edf\u6392\u5e8f\u4e00\u81f4\u6027\u3002\u7814\u7a76\u66f4\u4e30\u5bcc\u7684\u9879\u76ee\u5143\u6570\u636e\u548c\u66f4\u957f\u7684\u7528\u6237\u5386\u53f2\u5982\u4f55\u6539\u5584\u5bf9\u9f50\uff0c\u5e76\u5728\u64ad\u5ba2\u63a8\u8350\u9886\u57df\u8fdb\u884c\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1LLM\u8bc4\u4f30\u5668\u7684\u6a21\u578b\u9009\u62e9\u4ef7\u503c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u7ed3\u5408\u66f4\u4e30\u5bcc\u7684\u9879\u76ee\u5143\u6570\u636e\u548c\u66f4\u957f\u7684\u7528\u6237\u5386\u53f2\u80fd\u6539\u5584LLM\u8bc4\u4f30\u5668\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u5bf9\u9f50\uff1b2\uff09LLM\u8bc4\u4f30\u5668\u4e0e\u57fa\u4e8e\u4eba\u5de5\u7684\u6392\u5e8f\u5177\u6709\u9ad8\u5ea6\u4e00\u81f4\u6027\uff08Kendall's tau = 0.87\uff09\uff1b3\uff09\u64ad\u5ba2\u63a8\u8350\u9886\u57df\u7684\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86LLM\u8bc4\u4f30\u5668\u5728\u6a21\u578b\u9009\u62e9\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002", "conclusion": "LLM\u8bc4\u4f30\u5668\u662f\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u884c\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u89e3\u51b3\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.21712", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.21712", "abs": "https://arxiv.org/abs/2511.21712", "authors": ["Yi Ding", "Xushuo Tang", "Zhengyi Yang", "Wenqian Zhang", "Simin Wu", "Yuxin Huang", "Lingjing Lan", "Weiyuan Li", "Yin Chen", "Mingchen Ju", "Wenke Yang", "Thong Hoang", "Mykhailo Klymenko", "Xiwei Zu", "Wenjie Zhang"], "title": "EulerESG: Automating ESG Disclosure Analysis with LLMs", "comment": null, "summary": "Environmental, Social, and Governance (ESG) reports have become central to how companies communicate climate risk, social impact, and governance practices, yet they are still published primarily as long, heterogeneous PDF documents. This makes it difficult to systematically answer seemingly simple questions. Existing tools either rely on brittle rule-based extraction or treat ESG reports as generic text, without explicitly modelling the underlying reporting standards. We present \\textbf{EulerESG}, an LLM-powered system for automating ESG disclosure analysis with explicit awareness of ESG frameworks. EulerESG combines (i) dual-channel retrieval and LLM-driven disclosure analysis over ESG reports, and (ii) an interactive dashboard and chatbot for exploration, benchmarking, and explanation. Using four globally recognised companies and twelve SASB sub-industries, we show that EulerESG can automatically populate standard-aligned metric tables with high fidelity (up to 0.95 average accuracy) while remaining practical in end-to-end runtime, and we compare several recent LLM models in this setting. The full implementation, together with a demonstration video, is publicly available at https://github.com/UNSW-database/EulerESG.", "AI": {"tldr": "EulerESG\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684ESG\u62a5\u544a\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u53cc\u901a\u9053\u68c0\u7d22\u548cLLM\u9a71\u52a8\u7684\u62ab\u9732\u5206\u6790\uff0c\u80fd\u591f\u81ea\u52a8\u586b\u5145\u6807\u51c6\u5bf9\u9f50\u7684\u6307\u6807\u8868\u683c\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe0.95\u3002", "motivation": "ESG\u62a5\u544a\u4e3b\u8981\u4ee5\u957f\u800c\u5f02\u6784\u7684PDF\u6587\u6863\u5f62\u5f0f\u53d1\u5e03\uff0c\u8fd9\u4f7f\u5f97\u7cfb\u7edf\u56de\u7b54\u7b80\u5355\u95ee\u9898\u53d8\u5f97\u56f0\u96be\u3002\u73b0\u6709\u5de5\u5177\u8981\u4e48\u4f9d\u8d56\u8106\u5f31\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u63d0\u53d6\uff0c\u8981\u4e48\u5c06ESG\u62a5\u544a\u89c6\u4e3a\u901a\u7528\u6587\u672c\uff0c\u6ca1\u6709\u660e\u786e\u5efa\u6a21\u5e95\u5c42\u62a5\u544a\u6807\u51c6\u3002", "method": "EulerESG\u7ed3\u5408\u4e86(i)\u53cc\u901a\u9053\u68c0\u7d22\u548cLLM\u9a71\u52a8\u7684ESG\u62a5\u544a\u62ab\u9732\u5206\u6790\uff0c\u4ee5\u53ca(ii)\u7528\u4e8e\u63a2\u7d22\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u89e3\u91ca\u7684\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u548c\u804a\u5929\u673a\u5668\u4eba\u3002", "result": "\u4f7f\u7528\u56db\u5bb6\u5168\u7403\u77e5\u540d\u516c\u53f8\u548c\u5341\u4e8c\u4e2aSASB\u5b50\u884c\u4e1a\uff0cEulerESG\u80fd\u591f\u4ee5\u9ad8\u4fdd\u771f\u5ea6\uff08\u5e73\u5747\u51c6\u786e\u7387\u9ad8\u8fbe0.95\uff09\u81ea\u52a8\u586b\u5145\u6807\u51c6\u5bf9\u9f50\u7684\u6307\u6807\u8868\u683c\uff0c\u540c\u65f6\u5728\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\u4e0a\u4fdd\u6301\u5b9e\u7528\u6027\uff0c\u5e76\u6bd4\u8f83\u4e86\u8be5\u8bbe\u7f6e\u4e0b\u7684\u51e0\u79cd\u6700\u65b0LLM\u6a21\u578b\u3002", "conclusion": "EulerESG\u662f\u4e00\u4e2a\u5b9e\u7528\u7684LLM\u9a71\u52a8\u7cfb\u7edf\uff0c\u80fd\u591f\u81ea\u52a8\u5316ESG\u62ab\u9732\u5206\u6790\uff0c\u5177\u6709\u660e\u786e\u7684ESG\u6846\u67b6\u610f\u8bc6\uff0c\u4e3aESG\u62a5\u544a\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21714", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21714", "abs": "https://arxiv.org/abs/2511.21714", "authors": ["Pawel Batorski", "Paul Swoboda"], "title": "GPS: General Per-Sample Prompter", "comment": null, "summary": "LLMs are sensitive to prompting, with task performance often hinging on subtle, sometimes imperceptible variations in phrasing. As a result, crafting effective prompts manually remains challenging and time-consuming. Recent automatic prompting methods mitigate this difficulty but face three key limitations: (i) for each new task, they require large datasets to train good prompts;(ii) they rely on costly optimization loops that may take hours; (iii)they typically produce a single task-level prompt that does not adapt to the individual input problem to be solved.\n  We propose GPS, the first general-purpose, per-sample prompting method. Without any task-specific tuning, GPS generates a tailored prompt for each unseen input, improving performance across diverse tasks. The prompter is trained with reinforcement learning on a suite of training tasks and includes a novel regularization for effectively adapting to per-sample prompting. Finally, we employ Minimum Bayes Risk decoding to stabilize inference.\n  Empirically, GPS demonstrates competitive performance: we attain second best results among baselines on text simplification, third best results on summarization and on-par results on classification, while not training on any of these tasks, in contrast to the baselines. For in-domain prompting, we obtain sota on GSM8K. Our work shows the potential of a novel and effective paradigm for automatic prompting: generating adaptive, input-specific prompts without extensive optimization and without access to a task-specific training set. Our code is available at https://github.com/Batorskq/GPS.", "AI": {"tldr": "GPS\u662f\u4e00\u79cd\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u8c03\u4f18\u7684\u901a\u7528\u9010\u6837\u672c\u63d0\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u8f93\u5165\u751f\u6210\u5b9a\u5236\u5316\u63d0\u793a\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u5b9e\u73b0\u7ade\u4e89\u6027\u6027\u80fd", "motivation": "\u73b0\u6709\u81ea\u52a8\u63d0\u793a\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u9650\u5236\uff1a\u9700\u8981\u5927\u91cf\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u8bad\u7ec3\u3001\u4f9d\u8d56\u8017\u65f6\u4f18\u5316\u5faa\u73af\u3001\u53ea\u80fd\u751f\u6210\u5355\u4e00\u4efb\u52a1\u7ea7\u63d0\u793a\u800c\u65e0\u6cd5\u9002\u5e94\u4e2a\u4f53\u8f93\u5165\u3002\u624b\u52a8\u63d0\u793a\u8bbe\u8ba1\u56f0\u96be\u4e14\u8017\u65f6\u3002", "method": "\u63d0\u51faGPS\u65b9\u6cd5\uff1a1) \u5728\u8bad\u7ec3\u4efb\u52a1\u5957\u4ef6\u4e0a\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u63d0\u793a\u5668\uff1b2) \u5f15\u5165\u65b0\u9896\u7684\u6b63\u5219\u5316\u6280\u672f\u4ee5\u6709\u6548\u9002\u5e94\u9010\u6837\u672c\u63d0\u793a\uff1b3) \u91c7\u7528\u6700\u5c0f\u8d1d\u53f6\u65af\u98ce\u9669\u89e3\u7801\u7a33\u5b9a\u63a8\u7406", "result": "\u5728\u6587\u672c\u7b80\u5316\u4efb\u52a1\u4e0a\u83b7\u5f97\u57fa\u51c6\u65b9\u6cd5\u4e2d\u7b2c\u4e8c\u4f73\u7ed3\u679c\uff0c\u5728\u6458\u8981\u4efb\u52a1\u4e0a\u83b7\u5f97\u7b2c\u4e09\u4f73\u7ed3\u679c\uff0c\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u83b7\u5f97\u76f8\u5f53\u7ed3\u679c\uff0c\u4e14\u672a\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u5728GSM8K\u4e0a\u83b7\u5f97\u6700\u5148\u8fdb\u6027\u80fd", "conclusion": "GPS\u5c55\u793a\u4e86\u81ea\u52a8\u63d0\u793a\u7684\u65b0\u8303\u5f0f\u6f5c\u529b\uff1a\u65e0\u9700\u5927\u91cf\u4f18\u5316\u548c\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u96c6\uff0c\u5373\u53ef\u751f\u6210\u81ea\u9002\u5e94\u3001\u8f93\u5165\u7279\u5b9a\u7684\u63d0\u793a\uff0c\u4e3aLLM\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.22858", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.22858", "abs": "https://arxiv.org/abs/2511.22858", "authors": ["Yuya Ishihara", "Atsushi Keyaki", "Hiroaki Yamada", "Ryutaro Ohara", "Mihoko Sumida"], "title": "RAG System for Supporting Japanese Litigation Procedures: Faithful Response Generation Complying with Legal Norms", "comment": "This is a preprint version of a paper reviewed and accepted at BREV-RAG 2025: Beyond Relevance-based EValuation of RAG Systems, a SIGIR-AP 2025 workshop", "summary": "This study discusses the essential components that a Retrieval-Augmented Generation (RAG)-based LLM system should possess in order to support Japanese medical litigation procedures complying with legal norms. In litigation, expert commissioners, such as physicians, architects, accountants, and engineers, provide specialized knowledge to help judges clarify points of dispute. When considering the substitution of these expert roles with a RAG-based LLM system, the constraint of strict adherence to legal norms is imposed. Specifically, three requirements arise: (1) the retrieval module must retrieve appropriate external knowledge relevant to the disputed issues in accordance with the principle prohibiting the use of private knowledge, (2) the responses generated must originate from the context provided by the RAG and remain faithful to that context, and (3) the retrieval module must reference external knowledge with appropriate timestamps corresponding to the issues at hand. This paper discusses the design of a RAG-based LLM system that satisfies these requirements.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8eRAG\u7684LLM\u7cfb\u7edf\u5728\u652f\u6301\u65e5\u672c\u533b\u7597\u8bc9\u8bbc\u7a0b\u5e8f\u65f6\u5e94\u5177\u5907\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u7279\u522b\u5f3a\u8c03\u7cfb\u7edf\u5fc5\u987b\u4e25\u683c\u9075\u5b88\u6cd5\u5f8b\u89c4\u8303\uff0c\u6ee1\u8db3\u4e09\u4e2a\u6838\u5fc3\u8981\u6c42\uff1a\u68c0\u7d22\u6a21\u5757\u9700\u9075\u5faa\u7981\u6b62\u4f7f\u7528\u79c1\u4eba\u77e5\u8bc6\u539f\u5219\u3001\u751f\u6210\u54cd\u5e94\u5fc5\u987b\u5fe0\u5b9e\u4e8e\u68c0\u7d22\u4e0a\u4e0b\u6587\u3001\u68c0\u7d22\u9700\u5305\u542b\u9002\u5f53\u7684\u65f6\u95f4\u6233\u3002", "motivation": "\u5728\u8bc9\u8bbc\u8fc7\u7a0b\u4e2d\uff0c\u4e13\u5bb6\u59d4\u5458\uff08\u5982\u533b\u751f\u3001\u5efa\u7b51\u5e08\u3001\u4f1a\u8ba1\u5e08\u3001\u5de5\u7a0b\u5e08\uff09\u4e3a\u6cd5\u5b98\u63d0\u4f9b\u4e13\u4e1a\u77e5\u8bc6\u4ee5\u6f84\u6e05\u4e89\u8bae\u70b9\u3002\u8003\u8651\u7528\u57fa\u4e8eRAG\u7684LLM\u7cfb\u7edf\u66ff\u4ee3\u8fd9\u4e9b\u4e13\u5bb6\u89d2\u8272\u65f6\uff0c\u9700\u8981\u4e25\u683c\u9075\u5faa\u6cd5\u5f8b\u89c4\u8303\uff0c\u8fd9\u5e26\u6765\u4e86\u7279\u5b9a\u7684\u7cfb\u7edf\u8bbe\u8ba1\u8981\u6c42\u3002", "method": "\u672c\u6587\u8ba8\u8bba\u4e86\u6ee1\u8db3\u4e09\u4e2a\u6838\u5fc3\u8981\u6c42\u7684RAG-based LLM\u7cfb\u7edf\u8bbe\u8ba1\uff1a(1) \u68c0\u7d22\u6a21\u5757\u5fc5\u987b\u6839\u636e\u7981\u6b62\u4f7f\u7528\u79c1\u4eba\u77e5\u8bc6\u539f\u5219\uff0c\u68c0\u7d22\u4e0e\u4e89\u8bae\u95ee\u9898\u76f8\u5173\u7684\u5916\u90e8\u77e5\u8bc6\uff1b(2) \u751f\u6210\u7684\u54cd\u5e94\u5fc5\u987b\u6e90\u81eaRAG\u63d0\u4f9b\u7684\u4e0a\u4e0b\u6587\u5e76\u5fe0\u5b9e\u4e8e\u8be5\u4e0a\u4e0b\u6587\uff1b(3) \u68c0\u7d22\u6a21\u5757\u5fc5\u987b\u5f15\u7528\u5177\u6709\u9002\u5f53\u65f6\u95f4\u6233\u7684\u5916\u90e8\u77e5\u8bc6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e13\u95e8\u4e3a\u65e5\u672c\u533b\u7597\u8bc9\u8bbc\u7a0b\u5e8f\u8bbe\u8ba1\u7684RAG-based LLM\u7cfb\u7edf\u6846\u67b6\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u6ee1\u8db3\u6cd5\u5f8b\u89c4\u8303\u8981\u6c42\uff0c\u786e\u4fdd\u68c0\u7d22\u7684\u9002\u5f53\u6027\u3001\u54cd\u5e94\u7684\u5fe0\u5b9e\u6027\u4ee5\u53ca\u77e5\u8bc6\u7684\u65f6\u95f4\u76f8\u5173\u6027\u3002", "conclusion": "\u57fa\u4e8eRAG\u7684LLM\u7cfb\u7edf\u53ef\u4ee5\u652f\u6301\u65e5\u672c\u533b\u7597\u8bc9\u8bbc\u7a0b\u5e8f\uff0c\u4f46\u5fc5\u987b\u8bbe\u8ba1\u4e3a\u4e25\u683c\u9075\u5b88\u6cd5\u5f8b\u89c4\u8303\uff0c\u7279\u522b\u662f\u6ee1\u8db3\u68c0\u7d22\u9002\u5f53\u6027\u3001\u54cd\u5e94\u5fe0\u5b9e\u6027\u548c\u65f6\u95f4\u6233\u8981\u6c42\u8fd9\u4e09\u4e2a\u5173\u952e\u6761\u4ef6\uff0c\u4ee5\u786e\u4fdd\u7cfb\u7edf\u5728\u6cd5\u5f8b\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u548c\u5408\u89c4\u6027\u3002"}}
{"id": "2511.21716", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21716", "abs": "https://arxiv.org/abs/2511.21716", "authors": ["Shabbir Anees", "Anshuman", "Ayush Chaurasia", "Prathmesh Bogar"], "title": "An Optimized Machine Learning Classifier for Detecting Fake Reviews Using Extracted Features", "comment": null, "summary": "It is well known that fraudulent reviews cast doubt on the legitimacy and dependability of online purchases. The most recent development that leads customers towards darkness is the appearance of human reviews in computer-generated (CG) ones. In this work, we present an advanced machine-learning-based system that analyses these reviews produced by AI with remarkable precision. Our method integrates advanced text preprocessing, multi-modal feature extraction, Harris Hawks Optimization (HHO) for feature selection, and a stacking ensemble classifier. We implemented this methodology on a public dataset of 40,432 Original (OR) and Computer-Generated (CG) reviews. From an initial set of 13,539 features, HHO selected the most applicable 1,368 features, achieving an 89.9% dimensionality reduction. Our final stacking model achieved 95.40% accuracy, 92.81% precision, 95.01% recall, and a 93.90% F1-Score, which demonstrates that the combination of ensemble learning and bio-inspired optimisation is an effective method for machine-generated text recognition. Because large-scale review analytics commonly run on cloud platforms, privacy-preserving techniques such as differential approaches and secure outsourcing are essential to protect user data in these systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u548c\u751f\u7269\u542f\u53d1\u4f18\u5316\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u68c0\u6d4bAI\u751f\u6210\u7684\u865a\u5047\u8bc4\u8bba\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u548c\u96c6\u6210\u5b66\u4e60\u5b9e\u73b095.4%\u7684\u51c6\u786e\u7387\u3002", "motivation": "AI\u751f\u6210\u7684\u865a\u5047\u8bc4\u8bba\u5a01\u80c1\u5728\u7ebf\u8d2d\u7269\u7684\u53ef\u4fe1\u5ea6\uff0c\u9700\u8981\u6709\u6548\u65b9\u6cd5\u6765\u533a\u5206\u4eba\u7c7b\u8bc4\u8bba\u548c\u8ba1\u7b97\u673a\u751f\u6210\u7684\u8bc4\u8bba\u3002", "method": "\u96c6\u6210\u9ad8\u7ea7\u6587\u672c\u9884\u5904\u7406\u3001\u591a\u6a21\u6001\u7279\u5f81\u63d0\u53d6\u3001Harris Hawks Optimization\u7279\u5f81\u9009\u62e9\uff08\u4ece13,539\u4e2a\u7279\u5f81\u4e2d\u9009\u51fa1,368\u4e2a\uff09\u548c\u5806\u53e0\u96c6\u6210\u5206\u7c7b\u5668\u3002", "result": "\u572840,432\u6761\u539f\u59cb\u548c\u8ba1\u7b97\u673a\u751f\u6210\u8bc4\u8bba\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u8fbe\u523095.40%\u51c6\u786e\u7387\u300192.81%\u7cbe\u786e\u7387\u300195.01%\u53ec\u56de\u7387\u548c93.90% F1\u5206\u6570\uff0c\u7279\u5f81\u7ef4\u5ea6\u51cf\u5c1189.9%\u3002", "conclusion": "\u96c6\u6210\u5b66\u4e60\u4e0e\u751f\u7269\u542f\u53d1\u4f18\u5316\u7684\u7ed3\u5408\u662f\u673a\u5668\u751f\u6210\u6587\u672c\u8bc6\u522b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u540c\u65f6\u9700\u8981\u5dee\u5206\u9690\u79c1\u548c\u5b89\u5168\u5916\u5305\u7b49\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u6765\u4fdd\u62a4\u7528\u6237\u6570\u636e\u3002"}}
{"id": "2511.21717", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.21717", "abs": "https://arxiv.org/abs/2511.21717", "authors": ["Baoliang Tian", "Yuxuan Si", "Jilong Wang", "Lingyao Li", "Zhongyuan Bao", "Zineng Zhou", "Tao Wang", "Sixu Li", "Ziyao Xu", "Mingze Wang", "Zhouzhuo Zhang", "Zhihao Wang", "Yike Yun", "Ke Tian", "Ning Yang", "Minghui Qiu"], "title": "CrossCheck-Bench: Diagnosing Compositional Failures in Multimodal Conflict Resolution", "comment": "Accepted by AAAI 2026", "summary": "Multimodal Large Language Models are primarily trained and evaluated on aligned image-text pairs, which leaves their ability to detect and resolve real-world inconsistencies largely unexplored. In open-domain applications visual and textual cues often conflict, requiring models to perform structured reasoning beyond surface-level alignment. We introduce CrossCheck-Bench, a diagnostic benchmark for evaluating contradiction detection in multimodal inputs. The benchmark adopts a hierarchical task framework covering three levels of reasoning complexity and defines seven atomic capabilities essential for resolving cross-modal inconsistencies. CrossCheck-Bench includes 15k question-answer pairs sourced from real-world artifacts with synthetically injected contradictions. The dataset is constructed through a multi-stage annotation pipeline involving more than 450 expert hours to ensure semantic validity and calibrated difficulty across perception, integration, and reasoning. We evaluate 13 state-of-the-art vision-language models and observe a consistent performance drop as tasks shift from perceptual matching to logical contradiction detection. Most models perform well on isolated entity recognition but fail when multiple clues must be synthesized for conflict reasoning. Capability-level analysis further reveals uneven skill acquisition, especially in tasks requiring multi-step inference or rule-based validation. Additional probing shows that conventional prompting strategies such as Chain-of-Thought and Set-of-Mark yield only marginal gains. By contrast, methods that interleave symbolic reasoning with grounded visual processing achieve more stable improvements. These results highlight a persistent bottleneck in multimodal reasoning and suggest new directions for building models capable of robust cross-modal verification.", "AI": {"tldr": "CrossCheck-Bench\uff1a\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u548c\u89e3\u51b3\u56fe\u50cf-\u6587\u672c\u77db\u76fe\u80fd\u529b\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u5305\u542b15k\u4e2a\u5e26\u5408\u6210\u77db\u76fe\u7684\u95ee\u7b54\u5bf9\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u903b\u8f91\u77db\u76fe\u68c0\u6d4b\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u5728\u5bf9\u9f50\u7684\u56fe\u50cf-\u6587\u672c\u5bf9\u4e0a\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u5176\u68c0\u6d4b\u548c\u89e3\u51b3\u771f\u5b9e\u4e16\u754c\u4e0d\u4e00\u81f4\u6027\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u5728\u5f00\u653e\u57df\u5e94\u7528\u4e2d\uff0c\u89c6\u89c9\u548c\u6587\u672c\u7ebf\u7d22\u7ecf\u5e38\u51b2\u7a81\uff0c\u9700\u8981\u6a21\u578b\u8fdb\u884c\u8d85\u8d8a\u8868\u9762\u5bf9\u9f50\u7684\u7ed3\u6784\u5316\u63a8\u7406\u3002", "method": "\u5f15\u5165CrossCheck-Bench\u8bca\u65ad\u57fa\u51c6\uff0c\u91c7\u7528\u5206\u5c42\u4efb\u52a1\u6846\u67b6\u8986\u76d6\u4e09\u4e2a\u63a8\u7406\u590d\u6742\u5ea6\u7ea7\u522b\uff0c\u5b9a\u4e49\u4e03\u4e2a\u89e3\u51b3\u8de8\u6a21\u6001\u4e0d\u4e00\u81f4\u6027\u7684\u6838\u5fc3\u80fd\u529b\u3002\u6570\u636e\u96c6\u5305\u542b15k\u4e2a\u4ece\u771f\u5b9e\u4e16\u754c\u7d20\u6750\u4e2d\u83b7\u53d6\u7684\u95ee\u7b54\u5bf9\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u6807\u6ce8\u6d41\u7a0b\uff08\u8d85\u8fc7450\u4e13\u5bb6\u5c0f\u65f6\uff09\u6ce8\u5165\u5408\u6210\u77db\u76fe\uff0c\u786e\u4fdd\u8bed\u4e49\u6709\u6548\u6027\u548c\u6821\u51c6\u96be\u5ea6\u3002", "result": "\u8bc4\u4f3013\u4e2a\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u968f\u7740\u4efb\u52a1\u4ece\u611f\u77e5\u5339\u914d\u8f6c\u5411\u903b\u8f91\u77db\u76fe\u68c0\u6d4b\uff0c\u6027\u80fd\u6301\u7eed\u4e0b\u964d\u3002\u5927\u591a\u6570\u6a21\u578b\u5728\u5b64\u7acb\u5b9e\u4f53\u8bc6\u522b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u7efc\u5408\u591a\u4e2a\u7ebf\u7d22\u8fdb\u884c\u51b2\u7a81\u63a8\u7406\u65f6\u5931\u8d25\u3002\u80fd\u529b\u5206\u6790\u663e\u793a\u6280\u80fd\u83b7\u53d6\u4e0d\u5747\u8861\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u591a\u6b65\u63a8\u7406\u6216\u57fa\u4e8e\u89c4\u5219\u9a8c\u8bc1\u7684\u4efb\u52a1\u4e2d\u3002\u4f20\u7edf\u63d0\u793a\u7b56\u7565\u5982\u601d\u7ef4\u94fe\u548c\u6807\u8bb0\u96c6\u4ec5\u5e26\u6765\u8fb9\u9645\u6539\u8fdb\uff0c\u800c\u5c06\u7b26\u53f7\u63a8\u7406\u4e0e\u63a5\u5730\u89c6\u89c9\u5904\u7406\u4ea4\u7ec7\u7684\u65b9\u6cd5\u83b7\u5f97\u66f4\u7a33\u5b9a\u7684\u63d0\u5347\u3002", "conclusion": "\u7ed3\u679c\u7a81\u663e\u4e86\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u6301\u7eed\u74f6\u9888\uff0c\u5e76\u4e3a\u6784\u5efa\u80fd\u591f\u8fdb\u884c\u7a33\u5065\u8de8\u6a21\u6001\u9a8c\u8bc1\u7684\u6a21\u578b\u6307\u51fa\u4e86\u65b0\u65b9\u5411\u3002CrossCheck-Bench\u4e3a\u8bc4\u4f30\u548c\u63d0\u5347\u591a\u6a21\u6001\u6a21\u578b\u5728\u73b0\u5b9e\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2511.21718", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21718", "abs": "https://arxiv.org/abs/2511.21718", "authors": ["Zhaoxin Zhang", "Borui Chen", "Yiming Hu", "Youyang Qu", "Tianqing Zhu", "Longxiang Gao"], "title": "When Harmless Words Harm: A New Threat to LLM Safety via Conceptual Triggers", "comment": null, "summary": "Recent research on large language model (LLM) jailbreaks has primarily focused on techniques that bypass safety mechanisms to elicit overtly harmful outputs. However, such efforts often overlook attacks that exploit the model's capacity for abstract generalization, creating a critical blind spot in current alignment strategies. This gap enables adversaries to induce objectionable content by subtly manipulating the implicit social values embedded in model outputs. In this paper, we introduce MICM, a novel, model-agnostic jailbreak method that targets the aggregate value structure reflected in LLM responses. Drawing on conceptual morphology theory, MICM encodes specific configurations of nuanced concepts into a fixed prompt template through a predefined set of phrases. These phrases act as conceptual triggers, steering model outputs toward a specific value stance without triggering conventional safety filters. We evaluate MICM across five advanced LLMs, including GPT-4o, Deepseek-R1, and Qwen3-8B. Experimental results show that MICM consistently outperforms state-of-the-art jailbreak techniques, achieving high success rates with minimal rejection. Our findings reveal a critical vulnerability in commercial LLMs: their safety mechanisms remain susceptible to covert manipulation of underlying value alignment.", "AI": {"tldr": "MICM\u662f\u4e00\u79cd\u65b0\u578b\u7684\u6a21\u578b\u65e0\u5173\u8d8a\u72f1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6982\u5ff5\u5f62\u6001\u5b66\u7406\u8bba\u7f16\u7801\u5fae\u5999\u6982\u5ff5\u914d\u7f6e\uff0c\u64cd\u7eb5LLM\u7684\u9690\u542b\u793e\u4f1a\u4ef7\u503c\u89c2\uff0c\u7ed5\u8fc7\u5b89\u5168\u673a\u5236\u751f\u6210\u4e0d\u5f53\u5185\u5bb9\u3002", "motivation": "\u73b0\u6709LLM\u8d8a\u72f1\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7ed5\u8fc7\u5b89\u5168\u673a\u5236\u83b7\u53d6\u660e\u663e\u6709\u5bb3\u8f93\u51fa\uff0c\u5ffd\u7565\u4e86\u5229\u7528\u6a21\u578b\u62bd\u8c61\u6cdb\u5316\u80fd\u529b\u7684\u653b\u51fb\uff0c\u8fd9\u5bfc\u81f4\u5f53\u524d\u5bf9\u9f50\u7b56\u7565\u5b58\u5728\u5173\u952e\u76f2\u70b9\u3002\u653b\u51fb\u8005\u53ef\u4ee5\u901a\u8fc7\u5fae\u5999\u64cd\u7eb5\u6a21\u578b\u8f93\u51fa\u4e2d\u5d4c\u5165\u7684\u9690\u542b\u793e\u4f1a\u4ef7\u503c\u89c2\u6765\u8bf1\u5bfc\u4e0d\u5f53\u5185\u5bb9\u3002", "method": "\u57fa\u4e8e\u6982\u5ff5\u5f62\u6001\u5b66\u7406\u8bba\uff0cMICM\u901a\u8fc7\u9884\u5b9a\u4e49\u77ed\u8bed\u96c6\u5c06\u5fae\u5999\u6982\u5ff5\u7684\u7279\u5b9a\u914d\u7f6e\u7f16\u7801\u5230\u56fa\u5b9a\u63d0\u793a\u6a21\u677f\u4e2d\u3002\u8fd9\u4e9b\u77ed\u8bed\u4f5c\u4e3a\u6982\u5ff5\u89e6\u53d1\u5668\uff0c\u5f15\u5bfc\u6a21\u578b\u8f93\u51fa\u671d\u5411\u7279\u5b9a\u4ef7\u503c\u7acb\u573a\uff0c\u800c\u4e0d\u89e6\u53d1\u4f20\u7edf\u5b89\u5168\u8fc7\u6ee4\u5668\u3002\u8be5\u65b9\u6cd5\u6a21\u578b\u65e0\u5173\uff0c\u9002\u7528\u4e8e\u5404\u79cdLLM\u3002", "result": "\u5728\u5305\u62ecGPT-4o\u3001Deepseek-R1\u548cQwen3-8B\u5728\u5185\u7684\u4e94\u79cd\u5148\u8fdbLLM\u4e0a\u8bc4\u4f30MICM\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aMICM\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u8d8a\u72f1\u6280\u672f\uff0c\u4ee5\u6700\u5c0f\u62d2\u7edd\u7387\u5b9e\u73b0\u9ad8\u6210\u529f\u7387\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u5546\u4e1aLLM\u5b58\u5728\u5173\u952e\u6f0f\u6d1e\uff1a\u5176\u5b89\u5168\u673a\u5236\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u5bf9\u5e95\u5c42\u4ef7\u503c\u5bf9\u9f50\u7684\u9690\u853d\u64cd\u7eb5\u3002\u8fd9\u8868\u660e\u9700\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u4ef7\u503c\u5bf9\u9f50\u65b9\u6cd5\u6765\u9632\u5fa1\u6b64\u7c7b\u6982\u5ff5\u7ea7\u653b\u51fb\u3002"}}
{"id": "2511.21721", "categories": ["cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21721", "abs": "https://arxiv.org/abs/2511.21721", "authors": ["Gao Mo", "Naveen Raman", "Megan Chai", "Cindy Peng", "Shannon Pagdon", "Nev Jones", "Hong Shen", "Peggy Swarbrick", "Fei Fang"], "title": "PeerCoPilot: A Language Model-Powered Assistant for Behavioral Health Organizations", "comment": "Accepted at IAAI'26", "summary": "Behavioral health conditions, which include mental health and substance use disorders, are the leading disease burden in the United States. Peer-run behavioral health organizations (PROs) critically assist individuals facing these conditions by combining mental health services with assistance for needs such as income, employment, and housing. However, limited funds and staffing make it difficult for PROs to address all service user needs. To assist peer providers at PROs with their day-to-day tasks, we introduce PeerCoPilot, a large language model (LLM)-powered assistant that helps peer providers create wellness plans, construct step-by-step goals, and locate organizational resources to support these goals. PeerCoPilot ensures information reliability through a retrieval-augmented generation pipeline backed by a large database of over 1,300 vetted resources. We conducted human evaluations with 15 peer providers and 6 service users and found that over 90% of users supported using PeerCoPilot. Moreover, we demonstrated that PeerCoPilot provides more reliable and specific information than a baseline LLM. PeerCoPilot is now used by a group of 5-10 peer providers at CSPNJ, a large behavioral health organization serving over 10,000 service users, and we are actively expanding PeerCoPilot's use.", "AI": {"tldr": "PeerCoPilot\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u52a9\u624b\uff0c\u5e2e\u52a9\u540c\u4f34\u884c\u4e3a\u5065\u5eb7\u7ec4\u7ec7\u7684\u540c\u4f34\u63d0\u4f9b\u8005\u5236\u5b9a\u5065\u5eb7\u8ba1\u5212\u3001\u8bbe\u5b9a\u5206\u6b65\u76ee\u6807\u5e76\u67e5\u627e\u7ec4\u7ec7\u8d44\u6e90\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u786e\u4fdd\u4fe1\u606f\u53ef\u9760\u6027\u3002", "motivation": "\u884c\u4e3a\u5065\u5eb7\u75be\u75c5\u662f\u7f8e\u56fd\u6700\u4e3b\u8981\u7684\u75be\u75c5\u8d1f\u62c5\uff0c\u540c\u4f34\u884c\u4e3a\u5065\u5eb7\u7ec4\u7ec7\u901a\u8fc7\u7ed3\u5408\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u4e0e\u5176\u4ed6\u9700\u6c42\u63f4\u52a9\u6765\u5e2e\u52a9\u60a3\u8005\uff0c\u4f46\u6709\u9650\u7684\u8d44\u91d1\u548c\u4eba\u5458\u4f7f\u5f97\u96be\u4ee5\u6ee1\u8db3\u6240\u6709\u670d\u52a1\u7528\u6237\u9700\u6c42\u3002", "method": "\u5f00\u53d1PeerCoPilot\u7cfb\u7edf\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ba1\u9053\uff0c\u57fa\u4e8e\u5305\u542b1300\u591a\u4e2a\u7ecf\u8fc7\u5ba1\u67e5\u7684\u8d44\u6e90\u6570\u636e\u5e93\uff0c\u5e2e\u52a9\u540c\u4f34\u63d0\u4f9b\u8005\u521b\u5efa\u5065\u5eb7\u8ba1\u5212\u3001\u6784\u5efa\u5206\u6b65\u76ee\u6807\u5e76\u5b9a\u4f4d\u7ec4\u7ec7\u8d44\u6e90\u3002", "result": "15\u540d\u540c\u4f34\u63d0\u4f9b\u8005\u548c6\u540d\u670d\u52a1\u7528\u6237\u7684\u4eba\u4f53\u8bc4\u4f30\u663e\u793a\uff0c\u8d85\u8fc790%\u7684\u7528\u6237\u652f\u6301\u4f7f\u7528PeerCoPilot\u3002PeerCoPilot\u6bd4\u57fa\u7ebfLLM\u63d0\u4f9b\u66f4\u53ef\u9760\u548c\u5177\u4f53\u7684\u4fe1\u606f\uff0c\u76ee\u524d\u5df2\u5728CSPNJ\u7ec4\u7ec7\u4e2d\u75315-10\u540d\u540c\u4f34\u63d0\u4f9b\u8005\u4f7f\u7528\u3002", "conclusion": "PeerCoPilot\u662f\u4e00\u4e2a\u6709\u6548\u7684LLM\u52a9\u624b\uff0c\u80fd\u591f\u5e2e\u52a9\u540c\u4f34\u884c\u4e3a\u5065\u5eb7\u7ec4\u7ec7\u66f4\u6709\u6548\u5730\u6ee1\u8db3\u670d\u52a1\u7528\u6237\u9700\u6c42\uff0c\u76ee\u524d\u5df2\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u90e8\u7f72\u4f7f\u7528\u5e76\u6b63\u5728\u79ef\u6781\u6269\u5c55\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2511.21722", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.21722", "abs": "https://arxiv.org/abs/2511.21722", "authors": ["Jens Rupprecht", "Leon Fr\u00f6hling", "Claudia Wagner", "Markus Strohmaier"], "title": "German General Personas: A Survey-Derived Persona Prompt Collection for Population-Aligned LLM Studies", "comment": "18 pages, 7 figures", "summary": "The use of Large Language Models (LLMs) for simulating human perspectives via persona prompting is gaining traction in computational social science. However, well-curated, empirically grounded persona collections remain scarce, limiting the accuracy and representativeness of such simulations. Here we introduce the German General Personas (GGP) collection, a comprehensive and representative persona prompt collection built from the German General Social Survey (ALLBUS). The GGP and its persona prompts are designed to be easily plugged into prompts for all types of LLMs and tasks, steering models to generate responses aligned with the underlying German population. We evaluate GGP by prompting various LLMs to simulate survey response distributions across diverse topics, demonstrating that GGP-guided LLMs outperform state-of-the-art classifiers, particularly under data scarcity. Furthermore, we analyze how the representativity and attribute selection within persona prompts affect alignment with population responses. Our findings suggest that GGP provides a potentially valuable resource for research on LLM-based social simulations that enables more systematic explorations of population-aligned persona prompting in NLP and social science research.", "AI": {"tldr": "GGP\u662f\u4e00\u4e2a\u57fa\u4e8e\u5fb7\u56fd\u7efc\u5408\u793e\u4f1a\u8c03\u67e5\u6784\u5efa\u7684\u5168\u9762\u3001\u4ee3\u8868\u6027\u4eba\u7269\u63d0\u793a\u96c6\u5408\uff0c\u7528\u4e8e\u6307\u5bfcLLM\u751f\u6210\u4e0e\u5fb7\u56fd\u4eba\u53e3\u5bf9\u9f50\u7684\u54cd\u5e94\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u65f6\u4f18\u4e8e\u73b0\u6709\u5206\u7c7b\u5668\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u4eba\u7269\u63d0\u793a\u6a21\u62df\u4eba\u7c7b\u89c6\u89d2\u5728\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u4e2d\u65e5\u76ca\u6d41\u884c\uff0c\u4f46\u7f3a\u4e4f\u7ecf\u8fc7\u7cbe\u5fc3\u7b56\u5212\u3001\u57fa\u4e8e\u5b9e\u8bc1\u7684\u4eba\u7269\u96c6\u5408\uff0c\u9650\u5236\u4e86\u6a21\u62df\u7684\u51c6\u786e\u6027\u548c\u4ee3\u8868\u6027\u3002", "method": "\u4ece\u5fb7\u56fd\u7efc\u5408\u793e\u4f1a\u8c03\u67e5(ALLBUS)\u6784\u5efa\u5fb7\u56fd\u901a\u7528\u4eba\u7269(GGP)\u96c6\u5408\uff0c\u8bbe\u8ba1\u6613\u4e8e\u96c6\u6210\u5230\u5404\u79cdLLM\u548c\u4efb\u52a1\u4e2d\u7684\u4eba\u7269\u63d0\u793a\uff0c\u901a\u8fc7\u6307\u5bfcLLM\u6a21\u62df\u4e0d\u540c\u4e3b\u9898\u7684\u8c03\u67e5\u54cd\u5e94\u5206\u5e03\u6765\u8bc4\u4f30\u6548\u679c\u3002", "result": "GGP\u6307\u5bfc\u7684LLM\u5728\u6a21\u62df\u8c03\u67e5\u54cd\u5e94\u5206\u5e03\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5206\u7c7b\u5668\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u6761\u4ef6\u4e0b\uff1b\u5206\u6790\u4e86\u4eba\u7269\u63d0\u793a\u7684\u4ee3\u8868\u6027\u548c\u5c5e\u6027\u9009\u62e9\u5bf9\u4e0e\u4eba\u53e3\u54cd\u5e94\u5bf9\u9f50\u7684\u5f71\u54cd\u3002", "conclusion": "GGP\u4e3a\u57fa\u4e8eLLM\u7684\u793e\u4f1a\u6a21\u62df\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff0c\u652f\u6301\u5728NLP\u548c\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u4e2d\u5bf9\u4eba\u53e3\u5bf9\u9f50\u7684\u4eba\u7269\u63d0\u793a\u8fdb\u884c\u66f4\u7cfb\u7edf\u5316\u7684\u63a2\u7d22\u3002"}}
{"id": "2511.21724", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21724", "abs": "https://arxiv.org/abs/2511.21724", "authors": ["Zenan Sun", "Rashmie Abeysinghe", "Xiaojin Li", "Xinyue Hu", "Licong Cui", "Guo-Qiang Zhang", "Jiang Bian", "Cui Tao"], "title": "AD-CDO: A Lightweight Ontology for Representing Eligibility Criteria in Alzheimer's Disease Clinical Trials", "comment": null, "summary": "Objective\n  This study introduces the Alzheimer's Disease Common Data Element Ontology for Clinical Trials (AD-CDO), a lightweight, semantically enriched ontology designed to represent and standardize key eligibility criteria concepts in Alzheimer's disease (AD) clinical trials.\n  Materials and Methods\n  We extracted high-frequency concepts from more than 1,500 AD clinical trials on ClinicalTrials.gov and organized them into seven semantic categories: Disease, Medication, Diagnostic Test, Procedure, Social Determinants of Health, Rating Criteria, and Fertility. Each concept was annotated with standard biomedical vocabularies, including the UMLS, OMOP Standardized Vocabularies, DrugBank, NDC, and NLM VSAC value sets. To balance coverage and manageability, we applied the Jenks Natural Breaks method to identify an optimal set of representative concepts.\n  Results\n  The optimized AD-CDO achieved over 63% coverage of extracted trial concepts while maintaining interpretability and compactness. The ontology effectively captured the most frequent and clinically meaningful entities used in AD eligibility criteria. We demonstrated AD-CDO's practical utility through two use cases: (a) an ontology-driven trial simulation system for formal modeling and virtual execution of clinical trials, and (b) an entity normalization task mapping raw clinical text to ontology-aligned terms, enabling consistency and integration with EHR data.\n  Discussion\n  AD-CDO bridges the gap between broad biomedical ontologies and task-specific trial modeling needs. It supports multiple downstream applications, including phenotyping algorithm development, cohort identification, and structured data integration.\n  Conclusion\n  By harmonizing essential eligibility entities and aligning them with standardized vocabularies, AD-CDO provides a versatile foundation for ontology-driven AD clinical trial research.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4e34\u5e8a\u8bd5\u9a8c\u901a\u7528\u6570\u636e\u5143\u7d20\u672c\u4f53\uff08AD-CDO\uff09\uff0c\u7528\u4e8e\u6807\u51c6\u5316AD\u4e34\u5e8a\u8bd5\u9a8c\u7684\u8d44\u683c\u6807\u51c6\u6982\u5ff5\uff0c\u8986\u76d663%\u4ee5\u4e0a\u8bd5\u9a8c\u6982\u5ff5\uff0c\u652f\u6301\u8bd5\u9a8c\u6a21\u62df\u548c\u5b9e\u4f53\u89c4\u8303\u5316\u7b49\u5e94\u7528\u3002", "motivation": "\u9700\u8981\u89e3\u51b3\u5e7f\u6cdb\u751f\u7269\u533b\u5b66\u672c\u4f53\u4e0e\u7279\u5b9a\u4e34\u5e8a\u8bd5\u9a8c\u5efa\u6a21\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u4e34\u5e8a\u8bd5\u9a8c\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u8d44\u683c\u6807\u51c6\u6982\u5ff5\u8868\u793a\uff0c\u652f\u6301\u4e0b\u6e38\u5e94\u7528\u5982\u8868\u578b\u7b97\u6cd5\u5f00\u53d1\u3001\u961f\u5217\u8bc6\u522b\u548c\u7ed3\u6784\u5316\u6570\u636e\u96c6\u6210\u3002", "method": "\u4eceClinicalTrials.gov\u76841500\u591a\u4e2aAD\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u63d0\u53d6\u9ad8\u9891\u6982\u5ff5\uff0c\u7ec4\u7ec7\u62107\u4e2a\u8bed\u4e49\u7c7b\u522b\uff0c\u4f7f\u7528UMLS\u3001OMOP\u3001DrugBank\u7b49\u6807\u51c6\u751f\u7269\u533b\u5b66\u8bcd\u6c47\u8fdb\u884c\u6807\u6ce8\uff0c\u5e94\u7528Jenks\u81ea\u7136\u65ad\u70b9\u6cd5\u4f18\u5316\u6982\u5ff5\u96c6\u5e73\u8861\u8986\u76d6\u7387\u548c\u53ef\u7ba1\u7406\u6027\u3002", "result": "\u4f18\u5316\u7684AD-CDO\u8986\u76d6\u8d85\u8fc763%\u7684\u63d0\u53d6\u8bd5\u9a8c\u6982\u5ff5\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u548c\u7d27\u51d1\u6027\uff0c\u6709\u6548\u6355\u83b7AD\u8d44\u683c\u6807\u51c6\u4e2d\u6700\u9891\u7e41\u548c\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u5b9e\u4f53\u3002\u901a\u8fc7\u4e24\u4e2a\u7528\u4f8b\u5c55\u793a\u4e86\u5b9e\u7528\u6027\uff1a\u672c\u4f53\u9a71\u52a8\u7684\u8bd5\u9a8c\u6a21\u62df\u7cfb\u7edf\u548c\u5b9e\u4f53\u89c4\u8303\u5316\u4efb\u52a1\u3002", "conclusion": "AD-CDO\u901a\u8fc7\u534f\u8c03\u57fa\u672c\u8d44\u683c\u5b9e\u4f53\u5e76\u4e0e\u6807\u51c6\u5316\u8bcd\u6c47\u5bf9\u9f50\uff0c\u4e3a\u57fa\u4e8e\u672c\u4f53\u7684AD\u4e34\u5e8a\u8bd5\u9a8c\u7814\u7a76\u63d0\u4f9b\u4e86\u591a\u529f\u80fd\u57fa\u7840\uff0c\u652f\u6301\u8868\u578b\u7b97\u6cd5\u5f00\u53d1\u3001\u961f\u5217\u8bc6\u522b\u548c\u7ed3\u6784\u5316\u6570\u636e\u96c6\u6210\u7b49\u591a\u79cd\u4e0b\u6e38\u5e94\u7528\u3002"}}
{"id": "2511.21725", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21725", "abs": "https://arxiv.org/abs/2511.21725", "authors": ["Yizhou Xu", "Janet Davis"], "title": "PromptTailor: Multi-turn Intent-Aligned Prompt Synthesis for Lightweight LLMs", "comment": "EMNLP 2025 Workshop PALS. Additional note: There is a citation error on Evoke. The paper we are referring to is \"Evoking critical thinking abilities in LLMs via reviewer-author prompt editing.\"", "summary": "Lightweight language models remain attractive for on-device and privacy-sensitive applications, but their responses are highly sensitive to prompt quality. For open-ended generation, non-expert users often lack the knowledge or time to consistently craft high-quality prompts, leading them to rely on prompt optimization tools. However, a key challenge is ensuring the optimized prompts genuinely align with users' original intents and preferences. We introduce PromptTailor, a system for controllable prompt generation for open-ended text that improves model output quality by intent-aligned prompt synthesis. PromptTailor expands minimal user instructions into rich, domain-aware prompts while preserving the user's stated preferences. The system is a quantized Llama3-8B model fine-tuned with a lightweight LoRA adapter on 12,300 prompt-refinement dialogues spanning 41 everyday domains, distilled from three stronger LLMs. The adapter attaches to any Llama3-8B base, enabling edge deployment. In human and LLM-judge evaluations across multiple target models and optimization baselines, PromptTailor yields higher preference rates than chain-of-thought prompting and matches or surpasses state-of-the-art prompt optimization methods while requiring fewer model calls (e.g., 3 vs. 9). These results show that a compact student, guided by powerful teachers, can learn effective prompt-generation strategies that enhance response quality while maintaining alignment with user intent.", "AI": {"tldr": "PromptTailor\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u63d0\u793a\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u610f\u56fe\u5bf9\u9f50\u7684\u63d0\u793a\u5408\u6210\u6765\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u8d28\u91cf\uff0c\u4f7f\u7528\u91cf\u5316Llama3-8B\u6a21\u578b\u548cLoRA\u9002\u914d\u5668\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\u3002", "motivation": "\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u5728\u8bbe\u5907\u7aef\u548c\u9690\u79c1\u654f\u611f\u5e94\u7528\u4e2d\u5f88\u6709\u5438\u5f15\u529b\uff0c\u4f46\u5b83\u4eec\u7684\u54cd\u5e94\u5bf9\u63d0\u793a\u8d28\u91cf\u975e\u5e38\u654f\u611f\u3002\u975e\u4e13\u4e1a\u7528\u6237\u901a\u5e38\u7f3a\u4e4f\u77e5\u8bc6\u6216\u65f6\u95f4\u6765\u6301\u7eed\u5236\u4f5c\u9ad8\u8d28\u91cf\u63d0\u793a\uff0c\u800c\u73b0\u6709\u63d0\u793a\u4f18\u5316\u5de5\u5177\u96be\u4ee5\u786e\u4fdd\u4f18\u5316\u540e\u7684\u63d0\u793a\u771f\u6b63\u7b26\u5408\u7528\u6237\u7684\u539f\u59cb\u610f\u56fe\u548c\u504f\u597d\u3002", "method": "PromptTailor\u662f\u4e00\u4e2a\u91cf\u5316Llama3-8B\u6a21\u578b\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7LoRA\u9002\u914d\u5668\u572812,300\u4e2a\u63d0\u793a\u4f18\u5316\u5bf9\u8bdd\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u8fd9\u4e9b\u5bf9\u8bdd\u6db5\u76d641\u4e2a\u65e5\u5e38\u9886\u57df\uff0c\u4ece\u4e09\u4e2a\u66f4\u5f3a\u7684LLM\u4e2d\u84b8\u998f\u800c\u6765\u3002\u7cfb\u7edf\u53ef\u4ee5\u5c06\u6700\u5c0f\u7528\u6237\u6307\u4ee4\u6269\u5c55\u4e3a\u4e30\u5bcc\u3001\u9886\u57df\u611f\u77e5\u7684\u63d0\u793a\uff0c\u540c\u65f6\u4fdd\u7559\u7528\u6237\u58f0\u660e\u7684\u504f\u597d\u3002", "result": "\u5728\u4eba\u7c7b\u548cLLM\u8bc4\u4f30\u4e2d\uff0cPromptTailor\u5728\u591a\u4e2a\u76ee\u6807\u6a21\u578b\u548c\u4f18\u5316\u57fa\u7ebf\u4e2d\u83b7\u5f97\u4e86\u6bd4\u601d\u7ef4\u94fe\u63d0\u793a\u66f4\u9ad8\u7684\u504f\u597d\u7387\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u7684\u6a21\u578b\u8c03\u7528\uff08\u4f8b\u59823\u6b21 vs 9\u6b21\uff09\u3002", "conclusion": "\u7d27\u51d1\u7684\u5b66\u751f\u6a21\u578b\u5728\u5f3a\u5927\u6559\u5e08\u6a21\u578b\u7684\u6307\u5bfc\u4e0b\uff0c\u53ef\u4ee5\u5b66\u4e60\u6709\u6548\u7684\u63d0\u793a\u751f\u6210\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u4e0e\u7528\u6237\u610f\u56fe\u5bf9\u9f50\u7684\u540c\u65f6\u63d0\u5347\u54cd\u5e94\u8d28\u91cf\u3002\u8be5\u7cfb\u7edf\u652f\u6301\u8fb9\u7f18\u90e8\u7f72\uff0c\u4e3a\u8bbe\u5907\u7aef\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u63d0\u793a\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21726", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21726", "abs": "https://arxiv.org/abs/2511.21726", "authors": ["Yicong Zheng", "Kevin L. McKee", "Thomas Miconi", "Zacharie Bugaud", "Mick van Gelderen", "Jed McCaleb"], "title": "Goal-Directed Search Outperforms Goal-Agnostic Memory Compression in Long-Context Memory Tasks", "comment": null, "summary": "How to enable human-like long-term memory in large language models (LLMs) has been a central question for unlocking more general capabilities such as few-shot generalization. Existing memory frameworks and benchmarks focus on finding the optimal memory compression algorithm for higher performance in tasks that require recollection and sometimes further reasoning. However, such efforts have ended up building more human bias into the compression algorithm, through the search for the best prompts and memory architectures that suit specific benchmarks, rather than finding a general solution that would work on other data distributions. On the other hand, goal-directed search on uncompressed information could potentially exhibit superior performance because compression is lossy, and a predefined compression algorithm will not fit all raw data distributions. Here we present SUMER (Search in Uncompressed Memory via Experience Replay), an end-to-end reinforcement learning agent with verifiable reward (RLVR) that learns to use search tools to gather information and answer a target question. On the LoCoMo dataset for long-context conversation understanding, SUMER with Qwen2.5-7B-Instruct learned to use search tools and outperformed all other biased memory compression approaches and also the full-context baseline, reaching SOTA performance (43% gain over the prior best). We demonstrate that a simple search method applied to raw data outperforms goal-agnostic and biased compression algorithms in current long-context memory tasks, arguing for new paradigms and benchmarks that are more dynamic and autonomously scalable. Code for SUMER and all implemented baselines is publicly available at https://github.com/zycyc/SUMER.", "AI": {"tldr": "SUMER\u662f\u4e00\u4e2a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLM\u4f7f\u7528\u641c\u7d22\u5de5\u5177\u5728\u672a\u538b\u7f29\u8bb0\u5fc6\u4e2d\u67e5\u627e\u4fe1\u606f\u4ee5\u56de\u7b54\u95ee\u9898\u7684\u7cfb\u7edf\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u5bf9\u8bdd\u7406\u89e3\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u8bb0\u5fc6\u538b\u7f29\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bb0\u5fc6\u6846\u67b6\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e13\u6ce8\u4e8e\u5bfb\u627e\u6700\u4f18\u8bb0\u5fc6\u538b\u7f29\u7b97\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5f15\u5165\u4e86\u4eba\u7c7b\u504f\u89c1\uff0c\u4e14\u9884\u5b9a\u4e49\u7684\u538b\u7f29\u7b97\u6cd5\u65e0\u6cd5\u9002\u5e94\u6240\u6709\u539f\u59cb\u6570\u636e\u5206\u5e03\u3002\u672a\u538b\u7f29\u4fe1\u606f\u7684\u76ee\u6807\u5bfc\u5411\u641c\u7d22\u53ef\u80fd\u8868\u73b0\u66f4\u4f18\uff0c\u56e0\u4e3a\u538b\u7f29\u662f\u6709\u635f\u7684\u3002", "method": "\u63d0\u51faSUMER\uff08Search in Uncompressed Memory via Experience Replay\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u5177\u6709\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\uff0c\u5b66\u4e60\u4f7f\u7528\u641c\u7d22\u5de5\u5177\u6536\u96c6\u4fe1\u606f\u5e76\u56de\u7b54\u76ee\u6807\u95ee\u9898\u3002", "result": "\u5728LoCoMo\u957f\u4e0a\u4e0b\u6587\u5bf9\u8bdd\u7406\u89e3\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528Qwen2.5-7B-Instruct\u7684SUMER\u5b66\u4f1a\u4e86\u4f7f\u7528\u641c\u7d22\u5de5\u5177\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u5176\u4ed6\u6709\u504f\u8bb0\u5fc6\u538b\u7f29\u65b9\u6cd5\u548c\u5b8c\u6574\u4e0a\u4e0b\u6587\u57fa\u7ebf\uff0c\u8fbe\u5230SOTA\u6027\u80fd\uff08\u6bd4\u5148\u524d\u6700\u4f73\u63d0\u534743%\uff09\u3002", "conclusion": "\u5e94\u7528\u4e8e\u539f\u59cb\u6570\u636e\u7684\u7b80\u5355\u641c\u7d22\u65b9\u6cd5\u5728\u5f53\u524d\u957f\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u4efb\u52a1\u4e2d\u4f18\u4e8e\u76ee\u6807\u65e0\u5173\u548c\u6709\u504f\u538b\u7f29\u7b97\u6cd5\uff0c\u9700\u8981\u66f4\u52a8\u6001\u548c\u81ea\u4e3b\u53ef\u6269\u5c55\u7684\u65b0\u8303\u5f0f\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2511.21728", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21728", "abs": "https://arxiv.org/abs/2511.21728", "authors": ["Lin Yu", "Xiaofei Han", "Yifei Kang", "Chiung-Yi Tseng", "Danyang Zhang", "Ziqian Bi", "Zhimo Han"], "title": "Affective Multimodal Agents with Proactive Knowledge Grounding for Emotionally Aligned Marketing Dialogue", "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled fluent dialogue systems, but most remain reactive and struggle in emotionally rich, goal-oriented settings such as marketing conversations. To address this limitation, we propose AffectMind, a multimodal affective dialogue agent that performs proactive reasoning and dynamic knowledge grounding to sustain emotionally aligned and persuasive interactions. AffectMind combines three components: a Proactive Knowledge Grounding Network (PKGN) that continuously updates factual and affective context from text, vision, and prosody; an Emotion--Intent Alignment Model (EIAM) that jointly models user emotion and purchase intent to adapt persuasion strategies; and a Reinforced Discourse Loop (RDL) that optimizes emotional coherence and engagement via reinforcement signals from user responses. Experiments on two newly curated marketing dialogue datasets, MM-ConvMarket and AffectPromo, show that AffectMind outperforms strong LLM-based baselines in emotional consistency (+26\\%), persuasive success rate (+19\\%), and long-term user engagement (+23\\%), highlighting emotion-grounded proactivity as a key capability for commercial multimodal agents.", "AI": {"tldr": "AffectMind\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u60c5\u611f\u5bf9\u8bdd\u4ee3\u7406\uff0c\u901a\u8fc7\u4e3b\u52a8\u63a8\u7406\u548c\u52a8\u6001\u77e5\u8bc6\u57fa\u7840\uff0c\u5728\u8425\u9500\u5bf9\u8bdd\u4e2d\u5b9e\u73b0\u60c5\u611f\u5bf9\u9f50\u548c\u8bf4\u670d\u6027\u4ea4\u4e92\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709LLM\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u5b9e\u73b0\u6d41\u7545\u5bf9\u8bdd\uff0c\u4f46\u5728\u60c5\u611f\u4e30\u5bcc\u3001\u76ee\u6807\u5bfc\u5411\u7684\u8425\u9500\u5bf9\u8bdd\u573a\u666f\u4e2d\u8868\u73b0\u88ab\u52a8\uff0c\u96be\u4ee5\u7ef4\u6301\u60c5\u611f\u5bf9\u9f50\u548c\u8bf4\u670d\u6027\u4ea4\u4e92\u3002", "method": "\u63d0\u51faAffectMind\u7cfb\u7edf\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) \u4e3b\u52a8\u77e5\u8bc6\u57fa\u7840\u7f51\u7edc(PKGN)\u4ece\u6587\u672c\u3001\u89c6\u89c9\u548c\u97f5\u5f8b\u4e2d\u6301\u7eed\u66f4\u65b0\u4e8b\u5b9e\u548c\u60c5\u611f\u4e0a\u4e0b\u6587\uff1b2) \u60c5\u611f-\u610f\u56fe\u5bf9\u9f50\u6a21\u578b(EIAM)\u8054\u5408\u5efa\u6a21\u7528\u6237\u60c5\u611f\u548c\u8d2d\u4e70\u610f\u56fe\u4ee5\u8c03\u6574\u8bf4\u670d\u7b56\u7565\uff1b3) \u5f3a\u5316\u8bdd\u8bed\u5faa\u73af(RDL)\u901a\u8fc7\u7528\u6237\u53cd\u9988\u7684\u5f3a\u5316\u4fe1\u53f7\u4f18\u5316\u60c5\u611f\u8fde\u8d2f\u6027\u548c\u53c2\u4e0e\u5ea6\u3002", "result": "\u5728\u4e24\u4e2a\u65b0\u6784\u5efa\u7684\u8425\u9500\u5bf9\u8bdd\u6570\u636e\u96c6(MM-ConvMarket\u548cAffectPromo)\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cAffectMind\u5728\u60c5\u611f\u4e00\u81f4\u6027(+26%)\u3001\u8bf4\u670d\u6210\u529f\u7387(+19%)\u548c\u957f\u671f\u7528\u6237\u53c2\u4e0e\u5ea6(+23%)\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5f3aLLM\u57fa\u7ebf\u3002", "conclusion": "\u60c5\u611f\u57fa\u7840\u4e3b\u52a8\u6027\u662f\u591a\u6a21\u6001\u5546\u4e1a\u4ee3\u7406\u7684\u5173\u952e\u80fd\u529b\uff0cAffectMind\u901a\u8fc7\u591a\u6a21\u6001\u60c5\u611f\u7406\u89e3\u548c\u4e3b\u52a8\u63a8\u7406\u663e\u8457\u63d0\u5347\u4e86\u8425\u9500\u5bf9\u8bdd\u7684\u6548\u679c\u3002"}}
{"id": "2511.21729", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21729", "abs": "https://arxiv.org/abs/2511.21729", "authors": ["Jithin Krishnan"], "title": "Beyond Component Strength: Synergistic Integration and Adaptive Calibration in Multi-Agent RAG Systems", "comment": "10 pages, 4 figures", "summary": "Building reliable retrieval-augmented generation (RAG) systems requires more than adding powerful components; it requires understanding how they interact. Using ablation studies on 50 queries (15 answerable, 10 edge cases, and 25 adversarial), we show that enhancements such as hybrid retrieval, ensemble verification, and adaptive thresholding provide almost no benefit when used in isolation, yet together achieve a 95% reduction in abstention (from 40% to 2%) without increasing hallucinations. We also identify a measurement challenge: different verification strategies can behave safely but assign inconsistent labels (for example, \"abstained\" versus \"unsupported\"), creating apparent hallucination rates that are actually artifacts of labeling. Our results show that synergistic integration matters more than the strength of any single component, that standardized metrics and labels are essential for correctly interpreting performance, and that adaptive calibration is needed to prevent overconfident over-answering even when retrieval quality is high.", "AI": {"tldr": "RAG\u7cfb\u7edf\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\u5728\u4e8e\u7ec4\u4ef6\u95f4\u7684\u534f\u540c\u6574\u5408\uff0c\u800c\u975e\u5355\u4e2a\u7ec4\u4ef6\u7684\u5f3a\u5ea6\uff1b\u6807\u51c6\u5316\u6307\u6807\u548c\u6807\u7b7e\u5bf9\u6b63\u786e\u8bc4\u4f30\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u6784\u5efa\u53ef\u9760\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u9700\u8981\u7406\u89e3\u7ec4\u4ef6\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6dfb\u52a0\u5f3a\u5927\u7684\u7ec4\u4ef6\u3002\u5f53\u524d\u5b58\u5728\u6d4b\u91cf\u6311\u6218\uff1a\u4e0d\u540c\u7684\u9a8c\u8bc1\u7b56\u7565\u53ef\u80fd\u5bfc\u81f4\u4e0d\u4e00\u81f4\u7684\u6807\u7b7e\u5206\u914d\uff0c\u4ece\u800c\u4ea7\u751f\u865a\u5047\u7684\u5e7b\u89c9\u7387\u3002", "method": "\u4f7f\u752850\u4e2a\u67e5\u8be2\uff0815\u4e2a\u53ef\u56de\u7b54\u300110\u4e2a\u8fb9\u7f18\u6848\u4f8b\u548c25\u4e2a\u5bf9\u6297\u6027\u6848\u4f8b\uff09\u8fdb\u884c\u6d88\u878d\u7814\u7a76\uff0c\u8bc4\u4f30\u6df7\u5408\u68c0\u7d22\u3001\u96c6\u6210\u9a8c\u8bc1\u548c\u81ea\u9002\u5e94\u9608\u503c\u7b49\u589e\u5f3a\u529f\u80fd\u7684\u6548\u679c\u3002", "result": "\u589e\u5f3a\u529f\u80fd\u5355\u72ec\u4f7f\u7528\u65f6\u51e0\u4e4e\u65e0\u76ca\uff0c\u4f46\u534f\u540c\u4f7f\u7528\u65f6\u80fd\u5c06\u5f03\u7b54\u7387\u4ece40%\u964d\u4f4e\u52302%\uff08\u51cf\u5c1195%\uff09\uff0c\u4e14\u4e0d\u589e\u52a0\u5e7b\u89c9\u3002\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u9a8c\u8bc1\u7b56\u7565\u53ef\u80fd\u5bfc\u81f4\u4e0d\u4e00\u81f4\u7684\u6807\u7b7e\u5206\u914d\uff08\u5982\"\u5f03\u7b54\"vs\"\u4e0d\u652f\u6301\"\uff09\uff0c\u4ece\u800c\u4ea7\u751f\u865a\u5047\u7684\u5e7b\u89c9\u7387\u3002", "conclusion": "\u534f\u540c\u6574\u5408\u6bd4\u4efb\u4f55\u5355\u4e2a\u7ec4\u4ef6\u7684\u5f3a\u5ea6\u66f4\u91cd\u8981\uff1b\u6807\u51c6\u5316\u6307\u6807\u548c\u6807\u7b7e\u5bf9\u6b63\u786e\u89e3\u91ca\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff1b\u5373\u4f7f\u68c0\u7d22\u8d28\u91cf\u9ad8\uff0c\u4e5f\u9700\u8981\u81ea\u9002\u5e94\u6821\u51c6\u6765\u9632\u6b62\u8fc7\u5ea6\u81ea\u4fe1\u7684\u8fc7\u5ea6\u56de\u7b54\u3002"}}
{"id": "2511.21730", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21730", "abs": "https://arxiv.org/abs/2511.21730", "authors": ["Ishant Kohar", "Aswanth Krishnan"], "title": "A Benchmark for Procedural Memory Retrieval in Language Agents", "comment": null, "summary": "Current AI agents excel in familiar settings, but fail sharply when faced with novel tasks with unseen vocabularies -- a core limitation of procedural memory systems. We present the first benchmark that isolates procedural memory retrieval from task execution, evaluating whether agents can recognize functionally equivalent procedures that span different object instantiations. Using ALFWorld, we construct dual corpora of expert and LLM-generated trajectories and evaluate six retrieval methods using systematically stratified queries. Our results expose a clear generalization cliff: embedding-based methods perform strongly on familiar contexts, yet degrade considerably on novel ones, while LLM-generated procedural abstractions demonstrate reliable cross-context transfer. Controlled ablations show that although embeddings capture some lexical-level abstraction, they fundamentally treat procedures as unordered bags of words, discarding temporal structure necessary for cross-context transfer. Corpus scale delivers far larger gains than representation enrichment, revealing an architectural ceiling in current encoders. Our benchmark offers the first diagnostic framework separating genuine procedural understanding from surface-level memorization and gives tools for developing retrieval systems capable of dependable generalization. Resources available at our GitHub repository (https://github.com/qpiai/Proced_mem_bench).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u8bc4\u4f30AI\u4ee3\u7406\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u68c0\u7d22\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5f53\u524d\u5d4c\u5165\u65b9\u6cd5\u5728\u719f\u6089\u573a\u666f\u8868\u73b0\u826f\u597d\u4f46\u5728\u65b0\u9896\u573a\u666f\u6025\u5267\u9000\u5316\uff0c\u800cLLM\u751f\u6210\u7684\u7a0b\u5e8f\u62bd\u8c61\u80fd\u5b9e\u73b0\u53ef\u9760\u7684\u8de8\u4e0a\u4e0b\u6587\u8fc1\u79fb\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u5728\u719f\u6089\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9762\u5bf9\u5305\u542b\u672a\u89c1\u8bcd\u6c47\u7684\u65b0\u4efb\u52a1\u65f6\u8868\u73b0\u6025\u5267\u4e0b\u964d\u2014\u2014\u8fd9\u662f\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u7cfb\u7edf\u7684\u6838\u5fc3\u9650\u5236\u3002\u9700\u8981\u533a\u5206\u771f\u6b63\u7684\u7a0b\u5e8f\u6027\u7406\u89e3\u4e0e\u8868\u9762\u8bb0\u5fc6\u3002", "method": "\u4f7f\u7528ALFWorld\u6784\u5efa\u4e13\u5bb6\u548cLLM\u751f\u6210\u8f68\u8ff9\u7684\u53cc\u91cd\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u7cfb\u7edf\u5206\u5c42\u67e5\u8be2\u8bc4\u4f30\u516d\u79cd\u68c0\u7d22\u65b9\u6cd5\uff0c\u8fdb\u884c\u53d7\u63a7\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u5d4c\u5165\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "result": "\u53d1\u73b0\u660e\u663e\u7684\u6cdb\u5316\u60ac\u5d16\uff1a\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u5728\u719f\u6089\u4e0a\u4e0b\u6587\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5728\u65b0\u9896\u4e0a\u4e0b\u6587\u663e\u8457\u9000\u5316\uff1bLLM\u751f\u6210\u7684\u7a0b\u5e8f\u62bd\u8c61\u5c55\u793a\u53ef\u9760\u7684\u8de8\u4e0a\u4e0b\u6587\u8fc1\u79fb\u80fd\u529b\uff1b\u8bed\u6599\u5e93\u89c4\u6a21\u6bd4\u8868\u793a\u4e30\u5bcc\u5ea6\u5e26\u6765\u66f4\u5927\u6536\u76ca\u3002", "conclusion": "\u8be5\u57fa\u51c6\u63d0\u4f9b\u4e86\u9996\u4e2a\u8bca\u65ad\u6846\u67b6\uff0c\u80fd\u591f\u533a\u5206\u771f\u6b63\u7684\u7a0b\u5e8f\u6027\u7406\u89e3\u4e0e\u8868\u9762\u8bb0\u5fc6\uff0c\u5e76\u4e3a\u5f00\u53d1\u5177\u6709\u53ef\u9760\u6cdb\u5316\u80fd\u529b\u7684\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5de5\u5177\u3002"}}
{"id": "2511.21731", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21731", "abs": "https://arxiv.org/abs/2511.21731", "authors": ["Diederik Aerts", "Jonito Aerts Argu\u00eblles", "Lester Beltran", "Suzette Geriente", "Roberto Leporini", "Massimiliano Sassoli de Bianchi", "Sandro Sozzo"], "title": "Identifying Quantum Structure in AI Language: Evidence for Evolutionary Convergence of Human and Artificial Cognition", "comment": null, "summary": "We present the results of cognitive tests on conceptual combinations, performed using specific Large Language Models (LLMs) as test subjects. In the first test, performed with ChatGPT and Gemini, we show that Bell's inequalities are significantly violated, which indicates the presence of 'quantum entanglement' in the tested concepts. In the second test, also performed using ChatGPT and Gemini, we instead identify the presence of 'Bose-Einstein statistics', rather than the intuitively expected 'Maxwell-Boltzmann statistics', in the distribution of the words contained in large-size texts. Interestingly, these findings mirror the results previously obtained in both cognitive tests with human participants and information retrieval tests on large corpora. Taken together, they point to the 'systematic emergence of quantum structures in conceptual-linguistic domains', regardless of whether the cognitive agent is human or artificial. Although LLMs are classified as neural networks for historical reasons, we believe that a more essential form of knowledge organization takes place in the distributive semantic structure of vector spaces built on top of the neural network. It is this meaning-bearing structure that lends itself to a phenomenon of evolutionary convergence between human cognition and language, slowly established through biological evolution, and LLM cognition and language, emerging much more rapidly as a result of self-learning and training. We analyze various aspects and examples that contain evidence supporting the above hypothesis. We also advance a unifying framework that explains the pervasive quantum organization of meaning that we identify.", "AI": {"tldr": "LLMs\u5728\u6982\u5ff5\u7ec4\u5408\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u91cf\u5b50\u7ea0\u7f20\u548c\u73bb\u8272-\u7231\u56e0\u65af\u5766\u7edf\u8ba1\u7279\u6027\uff0c\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5b9e\u9a8c\u7ed3\u679c\u76f8\u4f3c\uff0c\u8868\u660e\u6982\u5ff5-\u8bed\u8a00\u9886\u57df\u5b58\u5728\u666e\u904d\u7684\u91cf\u5b50\u7ed3\u6784\u7ec4\u7ec7\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6982\u5ff5\u8ba4\u77e5\u6d4b\u8bd5\u4e2d\u662f\u5426\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u91cf\u5b50\u7ed3\u6784\u7279\u6027\uff0c\u63a2\u7d22\u4eba\u7c7b\u8ba4\u77e5\u4e0e\u4eba\u5de5\u667a\u80fd\u8ba4\u77e5\u4e4b\u95f4\u7684\u8fdb\u5316\u8d8b\u540c\u73b0\u8c61\u3002", "method": "\u4f7f\u7528ChatGPT\u548cGemini\u8fdb\u884c\u4e24\u4e2a\u8ba4\u77e5\u6d4b\u8bd5\uff1a1) \u6982\u5ff5\u7ec4\u5408\u6d4b\u8bd5\uff0c\u68c0\u9a8c\u8d1d\u5c14\u4e0d\u7b49\u5f0f\u7684\u8fdd\u53cd\u60c5\u51b5\uff1b2) \u5927\u578b\u6587\u672c\u4e2d\u8bcd\u6c47\u5206\u5e03\u7684\u7edf\u8ba1\u5206\u6790\u3002", "result": "LLMs\u663e\u8457\u8fdd\u53cd\u8d1d\u5c14\u4e0d\u7b49\u5f0f\uff08\u8868\u660e\u91cf\u5b50\u7ea0\u7f20\u5b58\u5728\uff09\uff0c\u5e76\u5728\u8bcd\u6c47\u5206\u5e03\u4e2d\u8868\u73b0\u51fa\u73bb\u8272-\u7231\u56e0\u65af\u5766\u7edf\u8ba1\u800c\u975e\u9884\u671f\u7684\u9ea6\u514b\u65af\u97e6-\u73bb\u5c14\u5179\u66fc\u7edf\u8ba1\uff0c\u8fd9\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5b9e\u9a8c\u7ed3\u679c\u4e00\u81f4\u3002", "conclusion": "\u6982\u5ff5-\u8bed\u8a00\u9886\u57df\u5b58\u5728\u7cfb\u7edf\u7684\u91cf\u5b50\u7ed3\u6784\u7ec4\u7ec7\uff0c\u8fd9\u79cd\u7ec4\u7ec7\u5f62\u5f0f\u5728\u4eba\u7c7b\u8ba4\u77e5\uff08\u751f\u7269\u8fdb\u5316\u5f62\u6210\uff09\u548cLLM\u8ba4\u77e5\uff08\u81ea\u5b66\u4e60\u5f62\u6210\uff09\u4e2d\u90fd\u51fa\u73b0\uff0c\u8868\u660e\u8ba4\u77e5\u7cfb\u7edf\u5b58\u5728\u8fdb\u5316\u8d8b\u540c\u73b0\u8c61\u3002"}}
{"id": "2511.21732", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21732", "abs": "https://arxiv.org/abs/2511.21732", "authors": ["Jiajun Zhang", "Shijia Luo", "Ruikang Zhang", "Qi Su"], "title": "HUMORCHAIN: Theory-Guided Multi-Stage Reasoning for Interpretable Multimodal Humor Generation", "comment": null, "summary": "Humor, as both a creative human activity and a social binding mechanism, has long posed a major challenge for AI generation. Although producing humor requires complex cognitive reasoning and social understanding, theories of humor suggest that it follows learnable patterns and structures, making it theoretically possible for generative models to acquire them implicitly. In recent years, multimodal humor has become a prevalent form of online communication, especially among Gen Z, highlighting the need for AI systems capable of integrating visual understanding with humorous language generation. However, existing data-driven approaches lack explicit modeling or theoretical grounding of humor, often producing literal descriptions that fail to capture its underlying cognitive mechanisms, resulting in the generated image descriptions that are fluent but lack genuine humor or cognitive depth. To address this limitation, we propose HUMORCHAIN (HUmor-guided Multi-step Orchestrated Reasoning Chain for Image Captioning), a theory-guided multi-stage reasoning framework. It integrates visual semantic parsing, humor- and psychology-based reasoning, and a fine-tuned discriminator for humor evaluation, forming an interpretable and controllable cognitive reasoning chain. To the best of our knowledge, this is the first work to explicitly embed cognitive structures from humor theories into multimodal humor generation, enabling a structured reasoning process from visual understanding to humor creation. Experiments on Meme-Image-No-Text, Oogiri-GO, and OxfordTVG-HIC datasets show that HUMORCHAIN outperforms state-of-the-art baselines in human humor preference, Elo/BT scores, and semantic diversity, demonstrating that theory-driven structured reasoning enables large language models to generate humor aligned with human perception.", "AI": {"tldr": "HUMORCHAIN\uff1a\u9996\u4e2a\u5c06\u5e7d\u9ed8\u8ba4\u77e5\u7406\u8bba\u5d4c\u5165\u591a\u6a21\u6001\u5e7d\u9ed8\u751f\u6210\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u94fe\u4ece\u89c6\u89c9\u7406\u89e3\u5230\u5e7d\u9ed8\u521b\u4f5c\uff0c\u663e\u8457\u63d0\u5347AI\u751f\u6210\u5e7d\u9ed8\u7684\u8d28\u91cf\u548c\u4eba\u7c7b\u504f\u597d\u3002", "motivation": "\u5e7d\u9ed8\u4f5c\u4e3a\u521b\u9020\u6027\u4eba\u7c7b\u6d3b\u52a8\u548c\u793e\u4f1a\u7ebd\u5e26\u673a\u5236\uff0c\u5bf9AI\u751f\u6210\u6784\u6210\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u5e7d\u9ed8\u7684\u663e\u5f0f\u5efa\u6a21\u6216\u7406\u8bba\u57fa\u7840\uff0c\u901a\u5e38\u4ea7\u751f\u6d41\u7545\u4f46\u7f3a\u4e4f\u771f\u6b63\u5e7d\u9ed8\u6216\u8ba4\u77e5\u6df1\u5ea6\u7684\u56fe\u50cf\u63cf\u8ff0\u3002\u591a\u6a21\u6001\u5e7d\u9ed8\u5df2\u6210\u4e3a\u5728\u7ebf\u4ea4\u6d41\u7684\u666e\u904d\u5f62\u5f0f\uff0c\u9700\u8981\u80fd\u591f\u6574\u5408\u89c6\u89c9\u7406\u89e3\u548c\u5e7d\u9ed8\u8bed\u8a00\u751f\u6210\u7684AI\u7cfb\u7edf\u3002", "method": "\u63d0\u51faHUMORCHAIN\uff08\u5e7d\u9ed8\u5f15\u5bfc\u7684\u591a\u6b65\u7f16\u6392\u63a8\u7406\u94fe\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u7406\u8bba\u6307\u5bfc\u7684\u591a\u9636\u6bb5\u63a8\u7406\u6846\u67b6\u3002\u5b83\u6574\u5408\u4e86\u89c6\u89c9\u8bed\u4e49\u89e3\u6790\u3001\u57fa\u4e8e\u5e7d\u9ed8\u548c\u5fc3\u7406\u5b66\u7684\u63a8\u7406\uff0c\u4ee5\u53ca\u7528\u4e8e\u5e7d\u9ed8\u8bc4\u4f30\u7684\u5fae\u8c03\u5224\u522b\u5668\uff0c\u5f62\u6210\u4e00\u4e2a\u53ef\u89e3\u91ca\u548c\u53ef\u63a7\u7684\u8ba4\u77e5\u63a8\u7406\u94fe\u3002\u8fd9\u662f\u9996\u4e2a\u5c06\u5e7d\u9ed8\u7406\u8bba\u7684\u8ba4\u77e5\u7ed3\u6784\u663e\u5f0f\u5d4c\u5165\u591a\u6a21\u6001\u5e7d\u9ed8\u751f\u6210\u7684\u5de5\u4f5c\u3002", "result": "\u5728Meme-Image-No-Text\u3001Oogiri-GO\u548cOxfordTVG-HIC\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHUMORCHAIN\u5728\u4eba\u7c7b\u5e7d\u9ed8\u504f\u597d\u3001Elo/BT\u5206\u6570\u548c\u8bed\u4e49\u591a\u6837\u6027\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u7406\u8bba\u9a71\u52a8\u7684\u7ed3\u6784\u5316\u63a8\u7406\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u7b26\u5408\u4eba\u7c7b\u611f\u77e5\u7684\u5e7d\u9ed8\u3002", "conclusion": "\u7406\u8bba\u9a71\u52a8\u7684\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u591f\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e0e\u4eba\u7c7b\u611f\u77e5\u4e00\u81f4\u7684\u5e7d\u9ed8\uff0cHUMORCHAIN\u6846\u67b6\u4e3a\u591a\u6a21\u6001\u5e7d\u9ed8\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u548c\u53ef\u63a7\u7684\u8ba4\u77e5\u63a8\u7406\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86AI\u751f\u6210\u5e7d\u9ed8\u7684\u8d28\u91cf\u3002"}}
{"id": "2511.21733", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21733", "abs": "https://arxiv.org/abs/2511.21733", "authors": ["Dayan Pan", "Jingyuan Wang", "Yilong Zhou", "Jiawei Cheng", "Pengyue Jia", "Xiangyu Zhao"], "title": "RoSA: Enhancing Parameter-Efficient Fine-Tuning via RoPE-aware Selective Adaptation in Large Language Models", "comment": "Accepted by AAAI' 26", "summary": "Fine-tuning large language models is essential for task-specific adaptation, yet it remains computationally prohibitive. Parameter-Efficient Fine-Tuning (PEFT) methods have emerged as a solution, but current approaches typically ignore the distinct roles of model components and the heterogeneous importance across layers, thereby limiting adaptation efficiency. Motivated by the observation that Rotary Position Embeddings (RoPE) induce critical activations in the low-frequency dimensions of attention states, we propose RoPE-aware Selective Adaptation (RoSA), a novel PEFT framework that allocates trainable parameters in a more targeted and effective manner. RoSA comprises a RoPE-aware Attention Enhancement (RoAE) module, which selectively enhances the low-frequency components of RoPE-influenced attention states, and a Dynamic Layer Selection (DLS) strategy that adaptively identifies and updates the most critical layers based on LayerNorm gradient norms. By combining dimension-wise enhancement with layer-wise adaptation, RoSA achieves more targeted and efficient fine-tuning. Extensive experiments on fifteen commonsense and arithmetic benchmarks demonstrate that RoSA outperforms existing mainstream PEFT methods under comparable trainable parameters. The code is available to ease reproducibility at https://github.com/Applied-Machine-Learning-Lab/RoSA.", "AI": {"tldr": "RoSA\u662f\u4e00\u79cd\u65b0\u9896\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7RoPE\u611f\u77e5\u7684\u6ce8\u610f\u529b\u589e\u5f3a\u548c\u52a8\u6001\u5c42\u9009\u62e9\u7b56\u7565\uff0c\u5728\u53ef\u8bad\u7ec3\u53c2\u6570\u76f8\u8fd1\u7684\u60c5\u51b5\u4e0b\u8d85\u8d8a\u73b0\u6709PEFT\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u901a\u5e38\u5ffd\u7565\u6a21\u578b\u7ec4\u4ef6\u7684\u4e0d\u540c\u89d2\u8272\u548c\u5404\u5c42\u7684\u5f02\u8d28\u91cd\u8981\u6027\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6548\u7387\u3002\u89c2\u5bdf\u5230RoPE\u5728\u6ce8\u610f\u529b\u72b6\u6001\u7684\u4f4e\u9891\u7ef4\u5ea6\u4e2d\u8bf1\u5bfc\u5173\u952e\u6fc0\u6d3b\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9488\u5bf9\u6027\u548c\u6709\u6548\u7684\u53c2\u6570\u5206\u914d\u65b9\u5f0f\u3002", "method": "\u63d0\u51faRoSA\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1) RoPE\u611f\u77e5\u6ce8\u610f\u529b\u589e\u5f3a\u6a21\u5757\uff0c\u9009\u62e9\u6027\u589e\u5f3aRoPE\u5f71\u54cd\u7684\u6ce8\u610f\u529b\u72b6\u6001\u7684\u4f4e\u9891\u5206\u91cf\uff1b2) \u52a8\u6001\u5c42\u9009\u62e9\u7b56\u7565\uff0c\u57fa\u4e8eLayerNorm\u68af\u5ea6\u8303\u6570\u81ea\u9002\u5e94\u8bc6\u522b\u548c\u66f4\u65b0\u6700\u5173\u952e\u5c42\u3002", "result": "\u572815\u4e2a\u5e38\u8bc6\u548c\u7b97\u672f\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRoSA\u5728\u53ef\u8bad\u7ec3\u53c2\u6570\u76f8\u8fd1\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41PEFT\u65b9\u6cd5\u3002", "conclusion": "RoSA\u901a\u8fc7\u7ed3\u5408\u7ef4\u5ea6\u589e\u5f3a\u548c\u5c42\u9002\u5e94\uff0c\u5b9e\u73b0\u4e86\u66f4\u9488\u5bf9\u6027\u548c\u9ad8\u6548\u7684\u5fae\u8c03\uff0c\u4e3a\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2511.21734", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21734", "abs": "https://arxiv.org/abs/2511.21734", "authors": ["Shiguang Wu", "Quanming Yao"], "title": "Asking LLMs to Verify First is Almost Free Lunch", "comment": null, "summary": "To enhance the reasoning capabilities of Large Language Models (LLMs) without high costs of training, nor extensive test-time sampling, we introduce Verification-First (VF), a strategy that prompts models to verify a provided candidate answer, even a trivial or random one, before generating a solution. This approach triggers a \"reverse reasoning\" process that is cognitively easier and complementary to standard forward Chain-of-Thought (CoT), effectively invoking the model's critical thinking to reduce logical errors. We further generalize the VF strategy to Iter-VF, a sequential test-time scaling (TTS) method that iteratively cycles the verification-generation process using the model's previous answer. Extensive experiments across various benchmarks (from mathematical reasoning to coding and agentic tasks) and various LLMs (from open-source 1B to cutting-edge commercial ones) confirm that VF with random answer consistently outperforms standard CoT with minimal computational overhead, and Iter-VF outperforms existing TTS strategies.", "AI": {"tldr": "\u63d0\u51faVerification-First (VF)\u7b56\u7565\uff0c\u901a\u8fc7\u5148\u9a8c\u8bc1\u5019\u9009\u7b54\u6848\uff08\u5373\u4f7f\u662f\u968f\u673a\u7b54\u6848\uff09\u6765\u89e6\u53d1\"\u9006\u5411\u63a8\u7406\"\uff0c\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u9ad8\u6210\u672c\u8bad\u7ec3\u6216\u5927\u91cf\u6d4b\u8bd5\u65f6\u91c7\u6837\u3002", "motivation": "\u5728\u4e0d\u589e\u52a0\u8bad\u7ec3\u6210\u672c\u6216\u5927\u91cf\u6d4b\u8bd5\u65f6\u91c7\u6837\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u5982Chain-of-Thought\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u800cVF\u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faVerification-First (VF)\u7b56\u7565\uff1a\u5728\u751f\u6210\u89e3\u51b3\u65b9\u6848\u4e4b\u524d\uff0c\u5148\u8ba9\u6a21\u578b\u9a8c\u8bc1\u4e00\u4e2a\u63d0\u4f9b\u7684\u5019\u9009\u7b54\u6848\uff08\u5373\u4f7f\u662f\u968f\u673a\u6216\u5e73\u51e1\u7684\u7b54\u6848\uff09\u3002\u8fd9\u79cd\u65b9\u6cd5\u89e6\u53d1\"\u9006\u5411\u63a8\u7406\"\u8fc7\u7a0b\uff0c\u6bd4\u6807\u51c6\u7684\u524d\u5411Chain-of-Thought\u66f4\u5bb9\u6613\u8ba4\u77e5\u3002\u8fdb\u4e00\u6b65\u63a8\u5e7f\u4e3aIter-VF\uff0c\u8fd9\u662f\u4e00\u79cd\u987a\u5e8f\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u4f7f\u7528\u6a21\u578b\u4e4b\u524d\u7684\u7b54\u6848\u8fed\u4ee3\u5faa\u73af\u9a8c\u8bc1-\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u4ece\u6570\u5b66\u63a8\u7406\u5230\u7f16\u7801\u548c\u4ee3\u7406\u4efb\u52a1\uff09\u548c\u5404\u79cdLLM\uff08\u4ece\u5f00\u6e901B\u5230\u5c16\u7aef\u5546\u4e1a\u6a21\u578b\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u5b9e\uff1a\u4f7f\u7528\u968f\u673a\u7b54\u6848\u7684VF\u7b56\u7565\u59cb\u7ec8\u4f18\u4e8e\u6807\u51c6CoT\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\uff1bIter-VF\u4f18\u4e8e\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u7b56\u7565\u3002", "conclusion": "Verification-First\u7b56\u7565\u901a\u8fc7\u89e6\u53d1\u9006\u5411\u63a8\u7406\u8fc7\u7a0b\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u7684\u66ff\u4ee3\u65b9\u6848\u3002Iter-VF\u8fdb\u4e00\u6b65\u6269\u5c55\u4e86\u8fd9\u4e00\u65b9\u6cd5\uff0c\u5728\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.21735", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.21735", "abs": "https://arxiv.org/abs/2511.21735", "authors": ["Harshita Sharma", "Maxwell C. Reynolds", "Valentina Salvatelli", "Anne-Marie G. Sykes", "Kelly K. Horst", "Anton Schwaighofer", "Maximilian Ilse", "Olesya Melnichenko", "Sam Bond-Taylor", "Fernando P\u00e9rez-Garc\u00eda", "Vamshi K. Mugu", "Alex Chan", "Ceylan Colak", "Shelby A. Swartz", "Motassem B. Nashawaty", "Austin J. Gonzalez", "Heather A. Ouellette", "Selnur B. Erdal", "Beth A. Schueler", "Maria T. Wetscherek", "Noel Codella", "Mohit Jain", "Shruthi Bannur", "Kenza Bouzid", "Daniel C. Castro", "Stephanie Hyland", "Panos Korfiatis", "Ashish Khandelwal", "Javier Alvarez-Valle"], "title": "Closing the Performance Gap Between AI and Radiologists in Chest X-Ray Reporting", "comment": null, "summary": "AI-assisted report generation offers the opportunity to reduce radiologists' workload stemming from expanded screening guidelines, complex cases and workforce shortages, while maintaining diagnostic accuracy. In addition to describing pathological findings in chest X-ray reports, interpreting lines and tubes (L&T) is demanding and repetitive for radiologists, especially with high patient volumes. We introduce MAIRA-X, a clinically evaluated multimodal AI model for longitudinal chest X-ray (CXR) report generation, that encompasses both clinical findings and L&T reporting. Developed using a large-scale, multi-site, longitudinal dataset of 3.1 million studies (comprising 6 million images from 806k patients) from Mayo Clinic, MAIRA-X was evaluated on three holdout datasets and the public MIMIC-CXR dataset, where it significantly improved AI-generated reports over the state of the art on lexical quality, clinical correctness, and L&T-related elements. A novel L&T-specific metrics framework was developed to assess accuracy in reporting attributes such as type, longitudinal change and placement. A first-of-its-kind retrospective user evaluation study was conducted with nine radiologists of varying experience, who blindly reviewed 600 studies from distinct subjects. The user study found comparable rates of critical errors (3.0% for original vs. 4.6% for AI-generated reports) and a similar rate of acceptable sentences (97.8% for original vs. 97.4% for AI-generated reports), marking a significant improvement over prior user studies with larger gaps and higher error rates. Our results suggest that MAIRA-X can effectively assist radiologists, particularly in high-volume clinical settings.", "AI": {"tldr": "MAIRA-X\u662f\u4e00\u4e2a\u7ecf\u8fc7\u4e34\u5e8a\u8bc4\u4f30\u7684\u591a\u6a21\u6001AI\u6a21\u578b\uff0c\u7528\u4e8e\u80f8\u90e8X\u5149\u62a5\u544a\u7684\u7eb5\u5411\u751f\u6210\uff0c\u6db5\u76d6\u4e34\u5e8a\u53d1\u73b0\u548c\u7ba1\u8def\u62a5\u544a\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "AI\u8f85\u52a9\u62a5\u544a\u751f\u6210\u53ef\u4ee5\u51cf\u8f7b\u653e\u5c04\u79d1\u533b\u751f\u56e0\u7b5b\u67e5\u6307\u5357\u6269\u5c55\u3001\u590d\u6742\u75c5\u4f8b\u548c\u4eba\u5458\u77ed\u7f3a\u5e26\u6765\u7684\u5de5\u4f5c\u8d1f\u62c5\uff0c\u540c\u65f6\u4fdd\u6301\u8bca\u65ad\u51c6\u786e\u6027\u3002\u7ba1\u8def\u89e3\u91ca\u5c24\u5176\u8017\u65f6\u91cd\u590d\uff0c\u7279\u522b\u662f\u5728\u9ad8\u60a3\u8005\u91cf\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u4f7f\u7528\u6885\u5965\u8bca\u6240\u7684\u5927\u89c4\u6a21\u3001\u591a\u7ad9\u70b9\u3001\u7eb5\u5411\u6570\u636e\u96c6\uff08310\u4e07\u7814\u7a76\uff0c600\u4e07\u56fe\u50cf\uff0c80.6\u4e07\u60a3\u8005\uff09\u5f00\u53d1MAIRA-X\u6a21\u578b\u3002\u5728\u4e09\u4e2a\u4fdd\u7559\u6570\u636e\u96c6\u548c\u516c\u5f00MIMIC-CXR\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5f00\u53d1\u4e86\u4e13\u95e8\u7684\u7ba1\u8def\u62a5\u544a\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u8fdb\u884c\u4e86\u9996\u6b21\u56de\u987e\u6027\u7528\u6237\u8bc4\u4f30\u7814\u7a76\uff0c\u75319\u540d\u4e0d\u540c\u7ecf\u9a8c\u7684\u653e\u5c04\u79d1\u533b\u751f\u76f2\u5ba1600\u4e2a\u7814\u7a76\u3002", "result": "MAIRA-X\u5728\u8bcd\u6c47\u8d28\u91cf\u3001\u4e34\u5e8a\u6b63\u786e\u6027\u548c\u7ba1\u8def\u76f8\u5173\u5143\u7d20\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002\u7528\u6237\u7814\u7a76\u53d1\u73b0\u5173\u952e\u9519\u8bef\u7387\u76f8\u5f53\uff08\u539f\u59cb\u62a5\u544a3.0% vs AI\u62a5\u544a4.6%\uff09\uff0c\u53ef\u63a5\u53d7\u53e5\u5b50\u7387\u76f8\u4f3c\uff0897.8% vs 97.4%\uff09\uff0c\u76f8\u6bd4\u5148\u524d\u7814\u7a76\u6709\u660e\u663e\u6539\u8fdb\u3002", "conclusion": "MAIRA-X\u53ef\u4ee5\u6709\u6548\u8f85\u52a9\u653e\u5c04\u79d1\u533b\u751f\uff0c\u7279\u522b\u662f\u5728\u9ad8\u6d41\u91cf\u7684\u4e34\u5e8a\u73af\u5883\u4e2d\uff0c\u663e\u793a\u51faAI\u8f85\u52a9\u62a5\u544a\u751f\u6210\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.21736", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21736", "abs": "https://arxiv.org/abs/2511.21736", "authors": ["Jiayi Chen", "Jieqi Shi", "Jing Huo", "Chen Wu"], "title": "R2Q: Towards Robust 2-Bit Large Language Models via Residual Refinement Quantization", "comment": null, "summary": "The rapid progress of Large Language Models (LLMs) has brought substantial computational and memory demands, spurring the adoption of low-bit quantization. While 8-bit and 4-bit formats have become prevalent, extending quantization to 2 bits remains challenging due to severe accuracy degradation. To address this, we propose Residual Refinement Quantization (R2Q)-a novel 2-bit quantization framework that decomposes the process into two sequential 1-bit sub-quantizations, forming an adaptive quantization lattice. Extensive evaluations on Llama, OPT, and Qwen across diverse benchmarks-covering question answering, commonsense reasoning, and language modeling-demonstrate that R2Q consistently outperforms existing 2-bit quantization methods in both fine-grained and coarse-grained settings. By refining quantization through a residual learning mechanism, R2Q enhances performance, improves training stability, and accelerates convergence under extreme compression. Furthermore, its modular design enables seamless integration with existing quantization-aware training (QAT) frameworks.", "AI": {"tldr": "R2Q\u662f\u4e00\u79cd\u521b\u65b0\u76842\u4f4d\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c062\u4f4d\u91cf\u5316\u5206\u89e3\u4e3a\u4e24\u4e2a\u987a\u5e8f\u76841\u4f4d\u5b50\u91cf\u5316\uff0c\u5f62\u6210\u81ea\u9002\u5e94\u91cf\u5316\u7f51\u683c\uff0c\u663e\u8457\u63d0\u53472\u4f4d\u91cf\u5316\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u5de8\u5927\uff0c\u4fc3\u4f7f\u4f4e\u6bd4\u7279\u91cf\u5316\u6210\u4e3a\u5fc5\u8981\u3002\u867d\u71368\u4f4d\u548c4\u4f4d\u91cf\u5316\u5df2\u666e\u53ca\uff0c\u4f46\u6269\u5c55\u52302\u4f4d\u91cf\u5316\u9762\u4e34\u4e25\u91cd\u7cbe\u5ea6\u4e0b\u964d\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6b8b\u5dee\u7cbe\u5316\u91cf\u5316(R2Q)\u6846\u67b6\uff0c\u5c062\u4f4d\u91cf\u5316\u8fc7\u7a0b\u5206\u89e3\u4e3a\u4e24\u4e2a\u987a\u5e8f\u76841\u4f4d\u5b50\u91cf\u5316\uff0c\u5f62\u6210\u81ea\u9002\u5e94\u91cf\u5316\u7f51\u683c\uff0c\u901a\u8fc7\u6b8b\u5dee\u5b66\u4e60\u673a\u5236\u7cbe\u5316\u91cf\u5316\u8fc7\u7a0b\u3002", "result": "\u5728Llama\u3001OPT\u548cQwen\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cR2Q\u5728\u7ec6\u7c92\u5ea6\u548c\u7c97\u7c92\u5ea6\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u67092\u4f4d\u91cf\u5316\u65b9\u6cd5\uff0c\u6db5\u76d6\u95ee\u7b54\u3001\u5e38\u8bc6\u63a8\u7406\u548c\u8bed\u8a00\u5efa\u6a21\u7b49\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "R2Q\u901a\u8fc7\u6b8b\u5dee\u7cbe\u5316\u673a\u5236\u63d0\u5347\u4e86\u6027\u80fd\u3001\u6539\u5584\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u3001\u52a0\u901f\u4e86\u6536\u655b\uff0c\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u53ef\u4e0e\u73b0\u6709\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u6846\u67b6\u65e0\u7f1d\u96c6\u6210\uff0c\u4e3a\u6781\u7aef\u538b\u7f29\u4e0b\u7684\u9ad8\u6548\u91cf\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21737", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21737", "abs": "https://arxiv.org/abs/2511.21737", "authors": ["Sabrina Sadiekh", "Elena Ericheva", "Chirag Agarwal"], "title": "Polarity-Aware Probing for Quantifying Latent Alignment in Language Models", "comment": "7 pages", "summary": "Advances in unsupervised probes such as Contrast-Consistent Search (CCS), which reveal latent beliefs without relying on token outputs, raise the question of whether these methods can reliably assess model alignment. We investigate this by examining the sensitivity of CCS to harmful vs. safe statements and by introducing Polarity-Aware CCS (PA-CCS), a method for evaluating whether a model's internal representations remain consistent under polarity inversion. We propose two alignment-oriented metrics, Polar-Consistency and the Contradiction Index, to quantify the semantic robustness of a model's latent knowledge. To validate PA-CCS, we curate two main datasets and one control dataset containing matched harmful-safe sentence pairs constructed using different methodologies (concurrent and antagonistic statements). We apply PA-CCS to 16 language models. Our results show that PA-CCS identifies both architectural and layer-specific differences in the encoding of latent harmful knowledge. Notably, replacing the negation token with a meaningless marker degrades PA-CCS scores for models with well-aligned internal representations, while models lacking robust internal calibration do not exhibit this degradation. Our findings highlight the potential of unsupervised probing for alignment evaluation and emphasize the need to incorporate structural robustness checks into interpretability benchmarks. Code and datasets are available at: https://github.com/SadSabrina/polarity-probing. WARNING: This paper contains potentially sensitive, harmful, and offensive content.", "AI": {"tldr": "PA-CCS\u662f\u4e00\u79cd\u901a\u8fc7\u6781\u6027\u53cd\u8f6c\u8bc4\u4f30\u6a21\u578b\u5185\u90e8\u8868\u5f81\u4e00\u81f4\u6027\u7684\u65e0\u76d1\u7763\u63a2\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u6a21\u578b\u6f5c\u5728\u6709\u5bb3\u77e5\u8bc6\u7684\u8bed\u4e49\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u63a2\u6d4b\u65b9\u6cd5\uff08\u5982CCS\uff09\u80fd\u5426\u53ef\u9760\u8bc4\u4f30\u6a21\u578b\u5bf9\u9f50\u6027\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u4e9b\u65b9\u6cd5\u5bf9\u6709\u5bb3/\u5b89\u5168\u9648\u8ff0\u7684\u654f\u611f\u6027\uff0c\u5e76\u5f00\u53d1\u80fd\u8bc4\u4f30\u6a21\u578b\u5185\u90e8\u8868\u5f81\u5728\u6781\u6027\u53cd\u8f6c\u4e0b\u4e00\u81f4\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPolarity-Aware CCS (PA-CCS)\uff0c\u901a\u8fc7\u6781\u6027\u53cd\u8f6c\u8bc4\u4f30\u6a21\u578b\u5185\u90e8\u8868\u5f81\u4e00\u81f4\u6027\uff1b\u63d0\u51fa\u4e24\u4e2a\u5bf9\u9f50\u5bfc\u5411\u6307\u6807\uff08\u6781\u6027\u4e00\u81f4\u6027\u548c\u77db\u76fe\u6307\u6570\uff09\uff1b\u6784\u5efa\u4e09\u4e2a\u6570\u636e\u96c6\uff08\u4e24\u4e2a\u4e3b\u8981\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u5bf9\u7167\u6570\u636e\u96c6\uff09\uff0c\u5305\u542b\u4f7f\u7528\u4e0d\u540c\u65b9\u6cd5\u6784\u5efa\u7684\u5339\u914d\u6709\u5bb3-\u5b89\u5168\u53e5\u5b50\u5bf9\uff1b\u5c06PA-CCS\u5e94\u7528\u4e8e16\u4e2a\u8bed\u8a00\u6a21\u578b\u3002", "result": "PA-CCS\u80fd\u8bc6\u522b\u6a21\u578b\u5728\u7f16\u7801\u6f5c\u5728\u6709\u5bb3\u77e5\u8bc6\u65f6\u7684\u67b6\u6784\u548c\u5c42\u7ea7\u7279\u5b9a\u5dee\u5f02\uff1b\u5bf9\u4e8e\u5185\u90e8\u8868\u5f81\u5bf9\u9f50\u826f\u597d\u7684\u6a21\u578b\uff0c\u5c06\u5426\u5b9a\u6807\u8bb0\u66ff\u6362\u4e3a\u65e0\u610f\u4e49\u6807\u8bb0\u4f1a\u964d\u4f4ePA-CCS\u5206\u6570\uff0c\u800c\u7f3a\u4e4f\u7a33\u5065\u5185\u90e8\u6821\u51c6\u7684\u6a21\u578b\u5219\u4e0d\u4f1a\u51fa\u73b0\u8fd9\u79cd\u9000\u5316\u3002", "conclusion": "\u65e0\u76d1\u7763\u63a2\u6d4b\u5728\u6a21\u578b\u5bf9\u9f50\u8bc4\u4f30\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u5c06\u7ed3\u6784\u9c81\u68d2\u6027\u68c0\u67e5\u7eb3\u5165\u53ef\u89e3\u91ca\u6027\u57fa\u51c6\u4e2d\uff0c\u4ee5\u786e\u4fdd\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.21740", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21740", "abs": "https://arxiv.org/abs/2511.21740", "authors": ["Yizi Zhang", "Linyang He", "Chaofei Fan", "Tingkai Liu", "Han Yu", "Trung Le", "Jingyuan Li", "Scott Linderman", "Lea Duncker", "Francis R Willett", "Nima Mesgarani", "Liam Paninski"], "title": "Decoding inner speech with an end-to-end brain-to-text neural interface", "comment": null, "summary": "Speech brain-computer interfaces (BCIs) aim to restore communication for people with paralysis by translating neural activity into text. Most systems use cascaded frameworks that decode phonemes before assembling sentences with an n-gram language model (LM), preventing joint optimization of all stages simultaneously. Here, we introduce an end-to-end Brain-to-Text (BIT) framework that translates neural activity into coherent sentences using a single differentiable neural network. Central to our approach is a cross-task, cross-species pretrained neural encoder, whose representations transfer to both attempted and imagined speech. In a cascaded setting with an n-gram LM, the pretrained encoder establishes a new state-of-the-art (SOTA) on the Brain-to-Text '24 and '25 benchmarks. Integrated end-to-end with audio large language models (LLMs) and trained with contrastive learning for cross-modal alignment, BIT reduces the word error rate (WER) of the prior end-to-end method from 24.69% to 10.22%. Notably, we find that small-scale audio LLMs markedly improve end-to-end decoding. Beyond record-setting performance, BIT aligns attempted and imagined speech embeddings to enable cross-task generalization. Altogether, our approach advances the integration of large, diverse neural datasets, paving the way for an end-to-end decoding framework that supports seamless, differentiable optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u8111\u5230\u6587\u672c\uff08BIT\uff09\u6846\u67b6\uff0c\u4f7f\u7528\u5355\u4e00\u53ef\u5fae\u5206\u795e\u7ecf\u7f51\u7edc\u5c06\u795e\u7ecf\u6d3b\u52a8\u76f4\u63a5\u7ffb\u8bd1\u4e3a\u8fde\u8d2f\u53e5\u5b50\uff0c\u5728\u8111\u5230\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u8bcd\u9519\u8bef\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u97f3\u8111\u673a\u63a5\u53e3\u5927\u591a\u4f7f\u7528\u7ea7\u8054\u6846\u67b6\uff0c\u5148\u89e3\u7801\u97f3\u7d20\u518d\u7528n-gram\u8bed\u8a00\u6a21\u578b\u7ec4\u88c5\u53e5\u5b50\uff0c\u8fd9\u79cd\u5206\u79bb\u7684\u67b6\u6784\u65e0\u6cd5\u5bf9\u6240\u6709\u9636\u6bb5\u8fdb\u884c\u8054\u5408\u4f18\u5316\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "1) \u4f7f\u7528\u8de8\u4efb\u52a1\u3001\u8de8\u7269\u79cd\u9884\u8bad\u7ec3\u7684\u795e\u7ecf\u7f16\u7801\u5668\uff0c\u5176\u8868\u5f81\u53ef\u8fc1\u79fb\u5230\u5c1d\u8bd5\u548c\u60f3\u8c61\u8bed\u97f3\uff1b2) \u5c06\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u4e0e\u97f3\u9891\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7aef\u5230\u7aef\u96c6\u6210\uff1b3) \u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u8fdb\u884c\u8de8\u6a21\u6001\u5bf9\u9f50\uff1b4) \u5728\u7ea7\u8054\u8bbe\u7f6e\u4e2d\u4e0en-gram LM\u7ed3\u5408\uff0c\u5728\u7aef\u5230\u7aef\u8bbe\u7f6e\u4e2d\u4e0e\u97f3\u9891LLMs\u7ed3\u5408\u3002", "result": "1) \u5728\u7ea7\u8054\u8bbe\u7f6e\u4e2d\uff0c\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u5728Brain-to-Text '24\u548c'25\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0\u7684SOTA\uff1b2) \u7aef\u5230\u7aef\u96c6\u6210\u5c06\u8bcd\u9519\u8bef\u7387\u4ece\u5148\u524d\u65b9\u6cd5\u768424.69%\u964d\u4f4e\u523010.22%\uff1b3) \u53d1\u73b0\u5c0f\u89c4\u6a21\u97f3\u9891LLMs\u663e\u8457\u6539\u5584\u7aef\u5230\u7aef\u89e3\u7801\uff1b4) BIT\u80fd\u591f\u5bf9\u9f50\u5c1d\u8bd5\u548c\u60f3\u8c61\u8bed\u97f3\u5d4c\u5165\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u6cdb\u5316\u3002", "conclusion": "BIT\u6846\u67b6\u901a\u8fc7\u7aef\u5230\u7aef\u7684\u53ef\u5fae\u5206\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8111\u5230\u6587\u672c\u89e3\u7801\u7684\u6027\u80fd\uff0c\u4fc3\u8fdb\u4e86\u5927\u89c4\u6a21\u591a\u6837\u5316\u795e\u7ecf\u6570\u636e\u96c6\u7684\u6574\u5408\uff0c\u4e3a\u5b9e\u73b0\u65e0\u7f1d\u3001\u53ef\u5fae\u5206\u7684\u4f18\u5316\u6846\u67b6\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2511.21741", "categories": ["cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21741", "abs": "https://arxiv.org/abs/2511.21741", "authors": ["Conrad D. Hougen", "Karl T. Pazdernik", "Alfred O. Hero"], "title": "A Multiscale Geometric Method for Capturing Relational Topic Alignment", "comment": "5 pages, 3 figures, 2025 IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing", "summary": "Interpretable topic modeling is essential for tracking how research interests evolve within co-author communities. In scientific corpora, where novelty is prized, identifying underrepresented niche topics is particularly important. However, contemporary models built from dense transformer embeddings tend to miss rare topics and therefore also fail to capture smooth temporal alignment. We propose a geometric method that integrates multimodal text and co-author network data, using Hellinger distances and Ward's linkage to construct a hierarchical topic dendrogram. This approach captures both local and global structure, supporting multiscale learning across semantic and temporal dimensions. Our method effectively identifies rare-topic structure and visualizes smooth topic drift over time. Experiments highlight the strength of interpretable bag-of-words models when paired with principled geometric alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u51e0\u4f55\u65b9\u6cd5\uff0c\u6574\u5408\u591a\u6a21\u6001\u6587\u672c\u548c\u5408\u8457\u8005\u7f51\u7edc\u6570\u636e\uff0c\u4f7f\u7528Hellinger\u8ddd\u79bb\u548cWard\u94fe\u63a5\u6784\u5efa\u5c42\u6b21\u4e3b\u9898\u6811\u72b6\u56fe\uff0c\u6709\u6548\u8bc6\u522b\u7a00\u6709\u4e3b\u9898\u5e76\u53ef\u89c6\u5316\u4e3b\u9898\u968f\u65f6\u95f4\u5e73\u6ed1\u6f02\u79fb\u3002", "motivation": "\u5728\u79d1\u5b66\u6587\u732e\u4e2d\uff0c\u8bc6\u522b\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u5229\u57fa\u4e3b\u9898\u5bf9\u4e8e\u8ffd\u8e2a\u5408\u8457\u8005\u793e\u533a\u7814\u7a76\u5174\u8da3\u6f14\u53d8\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u57fa\u4e8e\u5bc6\u96c6Transformer\u5d4c\u5165\u7684\u5f53\u4ee3\u6a21\u578b\u5f80\u5f80\u9057\u6f0f\u7a00\u6709\u4e3b\u9898\uff0c\u56e0\u6b64\u4e5f\u65e0\u6cd5\u6355\u6349\u5e73\u6ed1\u7684\u65f6\u95f4\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u65b9\u6cd5\uff0c\u6574\u5408\u591a\u6a21\u6001\u6587\u672c\u548c\u5408\u8457\u8005\u7f51\u7edc\u6570\u636e\uff0c\u4f7f\u7528Hellinger\u8ddd\u79bb\u548cWard\u94fe\u63a5\u6784\u5efa\u5c42\u6b21\u4e3b\u9898\u6811\u72b6\u56fe\u3002\u8be5\u65b9\u6cd5\u6355\u6349\u5c40\u90e8\u548c\u5168\u5c40\u7ed3\u6784\uff0c\u652f\u6301\u8de8\u8bed\u4e49\u548c\u65f6\u95f4\u7ef4\u5ea6\u7684\u591a\u5c3a\u5ea6\u5b66\u4e60\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u6548\u8bc6\u522b\u7a00\u6709\u4e3b\u9898\u7ed3\u6784\uff0c\u5e76\u53ef\u89c6\u5316\u968f\u65f6\u95f4\u5e73\u6ed1\u7684\u4e3b\u9898\u6f02\u79fb\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u53ef\u89e3\u91ca\u7684\u8bcd\u888b\u6a21\u578b\u4e0e\u539f\u5219\u6027\u51e0\u4f55\u5bf9\u9f50\u76f8\u7ed3\u5408\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u79d1\u5b66\u6587\u732e\u4e2d\u7684\u53ef\u89e3\u91ca\u4e3b\u9898\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u64c5\u957f\u8bc6\u522b\u7a00\u6709\u4e3b\u9898\u548c\u6355\u6349\u4e3b\u9898\u968f\u65f6\u95f4\u6f14\u53d8\uff0c\u5c55\u793a\u4e86\u51e0\u4f55\u65b9\u6cd5\u4e0e\u53ef\u89e3\u91ca\u6a21\u578b\u7ed3\u5408\u7684\u4ef7\u503c\u3002"}}
{"id": "2511.21742", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21742", "abs": "https://arxiv.org/abs/2511.21742", "authors": ["Meenakshi Mittal", "Rishi Khare", "Mihran Miroyan", "Chancharik Mitra", "Narges Norouzi"], "title": "EduMod-LLM: A Modular Approach for Designing Flexible and Transparent Educational Assistants", "comment": "Proceedings of the AAAI Conference on Artificial Intelligence", "summary": "With the growing use of Large Language Model (LLM)-based Question-Answering (QA) systems in education, it is critical to evaluate their performance across individual pipeline components. In this work, we introduce {\\model}, a modular function-calling LLM pipeline, and present a comprehensive evaluation along three key axes: function calling strategies, retrieval methods, and generative language models. Our framework enables fine-grained analysis by isolating and assessing each component. We benchmark function-calling performance across LLMs, compare our novel structure-aware retrieval method to vector-based and LLM-scoring baselines, and evaluate various LLMs for response synthesis. This modular approach reveals specific failure modes and performance patterns, supporting the development of interpretable and effective educational QA systems. Our findings demonstrate the value of modular function calling in improving system transparency and pedagogical alignment. Website and Supplementary Material: https://chancharikmitra.github.io/EduMod-LLM-website/", "AI": {"tldr": "EduMod-LLM\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u51fd\u6570\u8c03\u7528LLM\u7ba1\u9053\uff0c\u7528\u4e8e\u6559\u80b2\u95ee\u7b54\u7cfb\u7edf\u8bc4\u4f30\uff0c\u901a\u8fc7\u5206\u6790\u51fd\u6570\u8c03\u7528\u7b56\u7565\u3001\u68c0\u7d22\u65b9\u6cd5\u548c\u751f\u6210\u6a21\u578b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\u6765\u63d0\u5347\u7cfb\u7edf\u900f\u660e\u5ea6\u548c\u6559\u5b66\u5bf9\u9f50\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6559\u80b2\u95ee\u7b54\u7cfb\u7edf\u65e5\u76ca\u666e\u53ca\uff0c\u9700\u8981\u5bf9\u5176\u5404\u4e2a\u7ba1\u9053\u7ec4\u4ef6\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff0c\u4ee5\u8bc6\u522b\u7279\u5b9a\u6545\u969c\u6a21\u5f0f\u548c\u6027\u80fd\u6a21\u5f0f\uff0c\u652f\u6301\u5f00\u53d1\u53ef\u89e3\u91ca\u4e14\u6709\u6548\u7684\u6559\u80b2\u95ee\u7b54\u7cfb\u7edf\u3002", "method": "\u5f15\u5165EduMod-LLM\u6a21\u5757\u5316\u51fd\u6570\u8c03\u7528LLM\u7ba1\u9053\uff0c\u4ece\u4e09\u4e2a\u5173\u952e\u8f74\u8fdb\u884c\u8bc4\u4f30\uff1a1)\u51fd\u6570\u8c03\u7528\u7b56\u7565\uff0c2)\u68c0\u7d22\u65b9\u6cd5\uff08\u5305\u62ec\u65b0\u9896\u7684\u7ed3\u6784\u611f\u77e5\u68c0\u7d22\u4e0e\u5411\u91cf\u68c0\u7d22\u548cLLM\u8bc4\u5206\u57fa\u7ebf\u6bd4\u8f83\uff09\uff0c3)\u751f\u6210\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u54cd\u5e94\u5408\u6210\u3002\u91c7\u7528\u6a21\u5757\u5316\u65b9\u6cd5\u9694\u79bb\u548c\u8bc4\u4f30\u6bcf\u4e2a\u7ec4\u4ef6\u3002", "result": "\u5bf9LLM\u7684\u51fd\u6570\u8c03\u7528\u6027\u80fd\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u68c0\u7d22\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u8bc4\u4f30\u4e86\u5404\u79cdLLM\u7684\u54cd\u5e94\u5408\u6210\u80fd\u529b\u3002\u6a21\u5757\u5316\u65b9\u6cd5\u63ed\u793a\u4e86\u7279\u5b9a\u6545\u969c\u6a21\u5f0f\u548c\u6027\u80fd\u6a21\u5f0f\u3002", "conclusion": "\u6a21\u5757\u5316\u51fd\u6570\u8c03\u7528\u5728\u63d0\u9ad8\u7cfb\u7edf\u900f\u660e\u5ea6\u548c\u6559\u5b66\u5bf9\u9f50\u65b9\u9762\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u652f\u6301\u5f00\u53d1\u66f4\u53ef\u89e3\u91ca\u548c\u6709\u6548\u7684\u6559\u80b2\u95ee\u7b54\u7cfb\u7edf\u3002"}}
{"id": "2511.21743", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21743", "abs": "https://arxiv.org/abs/2511.21743", "authors": ["Mukul Singh", "Ananya Singha", "Arjun Radhakrishna", "Sumit Gulwani"], "title": "Scaling Competence, Shrinking Reasoning: Cognitive Signatures in Language Model Learning", "comment": null, "summary": "We analyze reasoning in language models during task-specific fine-tuning and draws parallel between reasoning tokens--intermediate steps generated while solving problem and the human working memory. Drawing from cognitive science, we align training dynamics with the Four Stages of Competence: models initially produce incorrect outputs without reasoning, then begin reasoning (but still fail), eventually reason effectively, and finally solve tasks without explicit reasoning. We find that reasoning token length expands as performance improves, peaks at the stage of conscious competence, then declines as the model internalizes the task. Notably, after training, models retain performance even when reasoning is removed--suggesting it scaffolded learning but is no longer needed. This progression offers actionable insights: reasoning token dynamics can serve as a signal for diagnosing training stage, identifying convergence, and guiding early stopping. We propose metrics to track this trajectory and argue that reasoning behavior is valuable for understanding and optimizing reasoning model training.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5728\u4efb\u52a1\u5fae\u8c03\u4e2d\u7684\u63a8\u7406\u8fc7\u7a0b\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u5de5\u4f5c\u8bb0\u5fc6\uff0c\u7ecf\u5386\u4ece\u65e0\u610f\u8bc6\u5230\u6709\u610f\u8bc6\u518d\u5230\u81ea\u52a8\u5316\u7684\u56db\u4e2a\u80fd\u529b\u9636\u6bb5\uff0c\u63a8\u7406\u6807\u8bb0\u957f\u5ea6\u5148\u589e\u540e\u51cf\uff0c\u6700\u7ec8\u6a21\u578b\u53ef\u4ee5\u5728\u79fb\u9664\u63a8\u7406\u6b65\u9aa4\u540e\u4ecd\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u5c06\u5176\u4e0e\u4eba\u7c7b\u5de5\u4f5c\u8bb0\u5fc6\u548c\u8ba4\u77e5\u53d1\u5c55\u8fc7\u7a0b\u8fdb\u884c\u7c7b\u6bd4\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u4f18\u5316\u63a8\u7406\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u4ece\u8ba4\u77e5\u79d1\u5b66\u89d2\u5ea6\uff0c\u5c06\u8bad\u7ec3\u52a8\u6001\u4e0e\"\u80fd\u529b\u56db\u9636\u6bb5\"\u7406\u8bba\u5bf9\u9f50\uff1a\u65e0\u610f\u8bc6\u65e0\u80fd\u3001\u6709\u610f\u8bc6\u65e0\u80fd\u3001\u6709\u610f\u8bc6\u6709\u80fd\u3001\u65e0\u610f\u8bc6\u6709\u80fd\u3002\u901a\u8fc7\u5206\u6790\u63a8\u7406\u6807\u8bb0\uff08\u4e2d\u95f4\u6b65\u9aa4\uff09\u7684\u957f\u5ea6\u53d8\u5316\u6765\u8ffd\u8e2a\u6a21\u578b\u80fd\u529b\u53d1\u5c55\u3002", "result": "\u63a8\u7406\u6807\u8bb0\u957f\u5ea6\u968f\u6027\u80fd\u63d0\u5347\u800c\u589e\u52a0\uff0c\u5728\"\u6709\u610f\u8bc6\u6709\u80fd\"\u9636\u6bb5\u8fbe\u5230\u5cf0\u503c\uff0c\u7136\u540e\u968f\u7740\u4efb\u52a1\u5185\u5316\u800c\u4e0b\u964d\u3002\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u5373\u4f7f\u79fb\u9664\u63a8\u7406\u6b65\u9aa4\uff0c\u6a21\u578b\u4ecd\u80fd\u4fdd\u6301\u6027\u80fd\uff0c\u8868\u660e\u63a8\u7406\u5728\u8bad\u7ec3\u4e2d\u8d77\u5230\u811a\u624b\u67b6\u4f5c\u7528\u4f46\u975e\u6700\u7ec8\u5fc5\u9700\u3002", "conclusion": "\u63a8\u7406\u6807\u8bb0\u52a8\u6001\u53ef\u4f5c\u4e3a\u8bca\u65ad\u8bad\u7ec3\u9636\u6bb5\u3001\u8bc6\u522b\u6536\u655b\u548c\u6307\u5bfc\u65e9\u505c\u7684\u4fe1\u53f7\u3002\u63a8\u7406\u884c\u4e3a\u5bf9\u4e8e\u7406\u89e3\u548c\u4f18\u5316\u63a8\u7406\u6a21\u578b\u8bad\u7ec3\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u63d0\u51fa\u7684\u6307\u6807\u53ef\u7528\u4e8e\u8ffd\u8e2a\u8fd9\u4e00\u53d1\u5c55\u8f68\u8ff9\u3002"}}
{"id": "2511.21744", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21744", "abs": "https://arxiv.org/abs/2511.21744", "authors": ["Sergey K. Aityan", "William Claster", "Karthik Sai Emani", "Sohni Rais", "Thy Tran"], "title": "A Lightweight Approach to Detection of AI-Generated Texts Using Stylometric Features", "comment": "19 pages, 6 figures, 3 tables", "summary": "A growing number of AI-generated texts raise serious concerns. Most existing approaches to AI-generated text detection rely on fine-tuning large transformer models or building ensembles, which are computationally expensive and often provide limited generalization across domains. Existing lightweight alternatives achieved significantly lower accuracy on large datasets. We introduce NEULIF, a lightweight approach that achieves best performance in the lightweight detector class, that does not require extensive computational power and provides high detection accuracy. In our approach, a text is first decomposed into stylometric and readability features which are then used for classification by a compact Convolutional Neural Network (CNN) or Random Forest (RF). Evaluated and tested on the Kaggle AI vs. Human corpus, our models achieve 97% accuracy (~ 0.95 F1) for CNN and 95% accuracy (~ 0.94 F1) for the Random Forest, demonstrating high precision and recall, with ROC-AUC scores of 99.5% and 95%, respectively. The CNN (~ 25 MB) and Random Forest (~ 10.6 MB) models are orders of magnitude smaller than transformer-based ensembles and can be run efficiently on standard CPU devices, without sacrificing accuracy.This study also highlights the potential of such models for broader applications across languages, domains, and streaming contexts, showing that simplicity, when guided by structural insights, can rival complexity in AI-generated content detection.", "AI": {"tldr": "NEULIF\uff1a\u4e00\u79cd\u8f7b\u91cf\u7ea7AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u98ce\u683c\u8ba1\u91cf\u548c\u53ef\u8bfb\u6027\u7279\u5f81\u914d\u5408CNN\u6216\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\uff0c\u5728Kaggle\u6570\u636e\u96c6\u4e0a\u8fbe\u523097%\u51c6\u786e\u7387\uff0c\u6a21\u578b\u5927\u5c0f\u4ec525MB\u548c10.6MB\u3002", "motivation": "\u73b0\u6709AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u5fae\u8c03\u5927\u578bTransformer\u6a21\u578b\u6216\u6784\u5efa\u96c6\u6210\u6a21\u578b\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u663e\u8457\u8f83\u4f4e\u3002", "method": "\u9996\u5148\u5c06\u6587\u672c\u5206\u89e3\u4e3a\u98ce\u683c\u8ba1\u91cf\u548c\u53ef\u8bfb\u6027\u7279\u5f81\uff0c\u7136\u540e\u4f7f\u7528\u7d27\u51d1\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u6216\u968f\u673a\u68ee\u6797\uff08RF\uff09\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5728Kaggle AI vs. Human\u8bed\u6599\u5e93\u4e0a\u8bc4\u4f30\uff1aCNN\u6a21\u578b\u8fbe\u523097%\u51c6\u786e\u7387\uff08F1\u7ea60.95\uff09\uff0cROC-AUC 99.5%\uff1b\u968f\u673a\u68ee\u6797\u8fbe\u523095%\u51c6\u786e\u7387\uff08F1\u7ea60.94\uff09\uff0cROC-AUC 95%\u3002\u6a21\u578b\u5927\u5c0f\u5206\u522b\u4e3a25MB\u548c10.6MB\u3002", "conclusion": "NEULIF\u5728\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u5668\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u65e0\u9700\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u4e14\u4fdd\u6301\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u3002\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u7ed3\u6784\u6d1e\u5bdf\u7684\u7b80\u5355\u65b9\u6cd5\u53ef\u4ee5\u5728AI\u751f\u6210\u5185\u5bb9\u68c0\u6d4b\u4e2d\u4e0e\u590d\u6742\u65b9\u6cd5\u76f8\u5ab2\u7f8e\uff0c\u5177\u6709\u8de8\u8bed\u8a00\u3001\u9886\u57df\u548c\u6d41\u5f0f\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.21746", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21746", "abs": "https://arxiv.org/abs/2511.21746", "authors": ["Mingyu Jeon", "Hyobin Kim"], "title": "DELTA: Language Diffusion-based EEG-to-Text Architecture", "comment": null, "summary": "Electroencephalogram (EEG)-to-text remains challenging due to high-dimensional noise, subject variability, and error accumulation in autoregressive decoding. We introduce DELTA, which pairs a Residual Vector Quantization (RVQ) EEG tokenizer with a masked language diffusion model (LLaDA). RVQ discretizes continuous EEG into multi-layer tokens to reduce noise and individual differences, while LLaDA reconstructs sentences via non-sequential denoising. On ZuCo, DELTA improves semantic alignment by up to 5.37 points over autoregressive baselines, achieving BLEU-1 21.9 and ROUGE-1 F 17.2 under word-level conditions. These results enable reliable text generation from small EEG-text datasets and point toward scalable multimodal EEG-language models.", "AI": {"tldr": "DELTA\uff1a\u4f7f\u7528\u6b8b\u5dee\u5411\u91cf\u91cf\u5316\uff08RVQ\uff09EEG\u5206\u8bcd\u5668\u548c\u63a9\u7801\u8bed\u8a00\u6269\u6563\u6a21\u578b\uff08LLaDA\uff09\u7684EEG\u5230\u6587\u672c\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u8bed\u4e49\u5bf9\u9f50\u6027\u80fd", "motivation": "EEG\u5230\u6587\u672c\u8f6c\u6362\u9762\u4e34\u9ad8\u7ef4\u566a\u58f0\u3001\u53d7\u8bd5\u8005\u53d8\u5f02\u6027\u548c\u81ea\u56de\u5f52\u89e3\u7801\u4e2d\u9519\u8bef\u7d2f\u79ef\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848", "method": "1. \u4f7f\u7528\u6b8b\u5dee\u5411\u91cf\u91cf\u5316\uff08RVQ\uff09EEG\u5206\u8bcd\u5668\u5c06\u8fde\u7eedEEG\u79bb\u6563\u5316\u4e3a\u591a\u5c42token\u4ee5\u51cf\u5c11\u566a\u58f0\u548c\u4e2a\u4f53\u5dee\u5f02\n2. \u91c7\u7528\u63a9\u7801\u8bed\u8a00\u6269\u6563\u6a21\u578b\uff08LLaDA\uff09\u901a\u8fc7\u975e\u987a\u5e8f\u53bb\u566a\u91cd\u5efa\u53e5\u5b50", "result": "\u5728ZuCo\u6570\u636e\u96c6\u4e0a\uff0cDELTA\u76f8\u6bd4\u81ea\u56de\u5f52\u57fa\u7ebf\u8bed\u4e49\u5bf9\u9f50\u63d0\u5347\u9ad8\u8fbe5.37\u70b9\uff0c\u5728\u8bcd\u7ea7\u6761\u4ef6\u4e0b\u8fbe\u5230BLEU-1 21.9\u548cROUGE-1 F 17.2", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u5c0f\u578bEEG-\u6587\u672c\u6570\u636e\u96c6\u4e2d\u5b9e\u73b0\u53ef\u9760\u7684\u6587\u672c\u751f\u6210\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001EEG-\u8bed\u8a00\u6a21\u578b\u6307\u660e\u4e86\u65b9\u5411"}}
{"id": "2511.21748", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21748", "abs": "https://arxiv.org/abs/2511.21748", "authors": ["Aman Kumar", "Ekant Muljibhai Amin", "Xian Yeow Lee", "Lasitha Vidyaratne", "Ahmed K. Farahat", "Dipanjan D. Ghosh", "Yuta Koreeda", "Chetan Gupta"], "title": "Building Domain-Specific Small Language Models via Guided Data Generation", "comment": "Accepted at Thirty-Eighth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-26)", "summary": "Large Language Models (LLMs) have shown remarkable success in supporting a wide range of knowledge-intensive tasks. In specialized domains, there is growing interest in leveraging LLMs to assist subject matter experts with domain-specific challenges. However, deploying LLMs as SaaS solutions raises data privacy concerns, while many open-source models demand significant computational resources for effective domain adaptation and deployment. A promising alternative is to develop smaller, domain-specialized LLMs, though this approach is often constrained by the lack of high-quality domain-specific training data. In this work, we address these limitations by presenting a cost-efficient and scalable training pipeline that combines guided synthetic data generation from a small seed corpus with bottom-up domain data curation. Our pipeline integrates Domain-Adaptive Pretraining (DAPT), Domain-specific Supervised Fine-tuning (DSFT), and Direct Preference Optimization (DPO) to train effective small-scale models for specialized use cases. We demonstrate this approach through DiagnosticSLM, a 3B-parameter domain-specific model tailored for fault diagnosis, root cause analysis, and repair recommendation in industrial settings. To evaluate model performance, we introduce four domain-specific benchmarks: multiple-choice questions (DiagnosticMCQ), question answering (DiagnosticQA), sentence completion (DiagnosticComp), and summarization (DiagnosticSum). DiagnosticSLM achieves up to 25% accuracy improvement over open-source models of comparable or larger size (2B-9B) on the MCQ task, while also outperforming or matching them in other tasks, demonstrating effective domain-specific reasoning and generalization capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6210\u672c\u6548\u76ca\u9ad8\u3001\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u6d41\u7a0b\uff0c\u7ed3\u5408\u5f15\u5bfc\u5f0f\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u81ea\u4e0b\u800c\u4e0a\u7684\u9886\u57df\u6570\u636e\u6574\u7406\uff0c\u7528\u4e8e\u8bad\u7ec3\u4e13\u95e8\u9886\u57df\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u4ee5\u5de5\u4e1a\u6545\u969c\u8bca\u65ad\u9886\u57df\u76843B\u53c2\u6570\u6a21\u578bDiagnosticSLM\u4e3a\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u5728\u4e13\u4e1a\u9886\u57df\u4e2d\u90e8\u7f72LLM\u9762\u4e34\u6570\u636e\u9690\u79c1\u3001\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u548c\u9ad8\u8d28\u91cf\u9886\u57df\u6570\u636e\u7f3a\u4e4f\u7684\u6311\u6218\u3002SaaS\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u9690\u79c1\u95ee\u9898\uff0c\u5f00\u6e90\u6a21\u578b\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u9886\u57df\u9002\u5e94\uff0c\u800c\u5f00\u53d1\u5c0f\u578b\u4e13\u4e1a\u6a21\u578b\u53c8\u53d7\u9650\u4e8e\u9ad8\u8d28\u91cf\u9886\u57df\u8bad\u7ec3\u6570\u636e\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\u7684\u8bad\u7ec3\u6d41\u7a0b\uff1a1) \u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3(DAPT)\uff1b2) \u9886\u57df\u7279\u5b9a\u76d1\u7763\u5fae\u8c03(DSFT)\uff1b3) \u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4ece\u5c11\u91cf\u79cd\u5b50\u8bed\u6599\u5e93\u751f\u6210\u7684\u5f15\u5bfc\u5f0f\u5408\u6210\u6570\u636e\u548c\u81ea\u4e0b\u800c\u4e0a\u7684\u9886\u57df\u6570\u636e\u6574\u7406\u3002", "result": "\u5f00\u53d1\u4e86DiagnosticSLM\uff083B\u53c2\u6570\uff09\uff0c\u5728\u5de5\u4e1a\u6545\u969c\u8bca\u65ad\u9886\u57df\u8868\u73b0\u51fa\u8272\u3002\u5728\u56db\u4e2a\u9886\u57df\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff1a\u591a\u9879\u9009\u62e9\u9898(DiagnosticMCQ)\u51c6\u786e\u7387\u6bd4\u7c7b\u4f3c\u89c4\u6a21\u7684\u5f00\u6e90\u6a21\u578b(2B-9B)\u63d0\u9ad825%\uff0c\u5728\u5176\u4ed6\u4efb\u52a1\u4e2d\u4e5f\u4f18\u4e8e\u6216\u5339\u914d\u8fd9\u4e9b\u6a21\u578b\uff0c\u663e\u793a\u51fa\u6709\u6548\u7684\u9886\u57df\u7279\u5b9a\u63a8\u7406\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bad\u7ec3\u6d41\u7a0b\u80fd\u591f\u9ad8\u6548\u5f00\u53d1\u5c0f\u578b\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u9690\u79c1\u3001\u8ba1\u7b97\u8d44\u6e90\u548c\u9ad8\u8d28\u91cf\u9886\u57df\u6570\u636e\u7f3a\u4e4f\u7684\u95ee\u9898\u3002DiagnosticSLM\u7684\u6210\u529f\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4e13\u4e1a\u9886\u57df\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5176\u4ed6\u9886\u57df\u7684\u5c0f\u578b\u4e13\u4e1a\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.21749", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21749", "abs": "https://arxiv.org/abs/2511.21749", "authors": ["Svitlana Volkova", "Will Dupree", "Hsien-Te Kao", "Peter Bautista", "Gabe Ganberg", "Jeff Beaubien", "Laura Cassani"], "title": "Proactive Defense: Compound AI for Detecting Persuasion Attacks and Measuring Inoculation Effectiveness", "comment": null, "summary": "This paper introduces BRIES, a novel compound AI architecture designed to detect and measure the effectiveness of persuasion attacks across information environments. We present a system with specialized agents: a Twister that generates adversarial content employing targeted persuasion tactics, a Detector that identifies attack types with configurable parameters, a Defender that creates resilient content through content inoculation, and an Assessor that employs causal inference to evaluate inoculation effectiveness. Experimenting with the SemEval 2023 Task 3 taxonomy across the synthetic persuasion dataset, we demonstrate significant variations in detection performance across language agents. Our comparative analysis reveals significant performance disparities with GPT-4 achieving superior detection accuracy on complex persuasion techniques, while open-source models like Llama3 and Mistral demonstrated notable weaknesses in identifying subtle rhetorical, suggesting that different architectures encode and process persuasive language patterns in fundamentally different ways. We show that prompt engineering dramatically affects detection efficacy, with temperature settings and confidence scoring producing model-specific variations; Gemma and GPT-4 perform optimally at lower temperatures while Llama3 and Mistral show improved capabilities at higher temperatures. Our causal analysis provides novel insights into socio-emotional-cognitive signatures of persuasion attacks, revealing that different attack types target specific cognitive dimensions. This research advances generative AI safety and cognitive security by quantifying LLM-specific vulnerabilities to persuasion attacks and delivers a framework for enhancing human cognitive resilience through structured interventions before exposure to harmful content.", "AI": {"tldr": "BRIES\u662f\u4e00\u4e2a\u590d\u5408AI\u67b6\u6784\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u8861\u91cf\u4fe1\u606f\u73af\u5883\u4e2d\u8bf4\u670d\u653b\u51fb\u7684\u6709\u6548\u6027\uff0c\u5305\u542b\u653b\u51fb\u751f\u6210\u3001\u68c0\u6d4b\u3001\u9632\u5fa1\u548c\u8bc4\u4f30\u56db\u4e2a\u4e13\u95e8\u4ee3\u7406\uff0c\u901a\u8fc7\u5b9e\u9a8c\u63ed\u793a\u4e86\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u8bf4\u670d\u6280\u672f\u65b9\u9762\u7684\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0fAI\u5b89\u5168\u9762\u4e34\u8bf4\u670d\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u9700\u8981\u91cf\u5316LLM\u5bf9\u8bf4\u670d\u653b\u51fb\u7684\u7279\u5b9a\u8106\u5f31\u6027\uff0c\u5e76\u5efa\u7acb\u589e\u5f3a\u4eba\u7c7b\u8ba4\u77e5\u97e7\u6027\u7684\u6846\u67b6\uff0c\u4ee5\u5728\u63a5\u89e6\u6709\u5bb3\u5185\u5bb9\u524d\u8fdb\u884c\u7ed3\u6784\u5316\u5e72\u9884\u3002", "method": "\u63d0\u51faBRIES\u590d\u5408AI\u67b6\u6784\uff0c\u5305\u542b\u56db\u4e2a\u4e13\u95e8\u4ee3\u7406\uff1aTwister\uff08\u751f\u6210\u5bf9\u6297\u6027\u5185\u5bb9\uff09\u3001Detector\uff08\u8bc6\u522b\u653b\u51fb\u7c7b\u578b\uff09\u3001Defender\uff08\u901a\u8fc7\u5185\u5bb9\u63a5\u79cd\u521b\u5efa\u5f39\u6027\u5185\u5bb9\uff09\u3001Assessor\uff08\u4f7f\u7528\u56e0\u679c\u63a8\u65ad\u8bc4\u4f30\u63a5\u79cd\u6548\u679c\uff09\u3002\u5728SemEval 2023 Task 3\u5206\u7c7b\u6cd5\u548c\u5408\u6210\u8bf4\u670d\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u7684\u68c0\u6d4b\u6027\u80fd\u3002", "result": "GPT-4\u5728\u590d\u6742\u8bf4\u670d\u6280\u672f\u68c0\u6d4b\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u800c\u5f00\u6e90\u6a21\u578b\u5982Llama3\u548cMistral\u5728\u8bc6\u522b\u5fae\u5999\u4fee\u8f9e\u65b9\u9762\u5b58\u5728\u660e\u663e\u5f31\u70b9\uff1b\u63d0\u793a\u5de5\u7a0b\u663e\u8457\u5f71\u54cd\u68c0\u6d4b\u6548\u679c\uff0c\u4e0d\u540c\u6a21\u578b\u5bf9\u6e29\u5ea6\u8bbe\u7f6e\u6709\u7279\u5b9a\u504f\u597d\uff1b\u56e0\u679c\u5206\u6790\u63ed\u793a\u4e86\u8bf4\u670d\u653b\u51fb\u7684\u793e\u4f1a-\u60c5\u611f-\u8ba4\u77e5\u7279\u5f81\uff0c\u4e0d\u540c\u653b\u51fb\u7c7b\u578b\u9488\u5bf9\u7279\u5b9a\u8ba4\u77e5\u7ef4\u5ea6\u3002", "conclusion": "BRIES\u67b6\u6784\u901a\u8fc7\u91cf\u5316LLM\u5bf9\u8bf4\u670d\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u63a8\u8fdb\u4e86\u751f\u6210\u5f0fAI\u5b89\u5168\u548c\u8ba4\u77e5\u5b89\u5168\u7814\u7a76\uff0c\u4e3a\u5728\u63a5\u89e6\u6709\u5bb3\u5185\u5bb9\u524d\u901a\u8fc7\u7ed3\u6784\u5316\u5e72\u9884\u589e\u5f3a\u4eba\u7c7b\u8ba4\u77e5\u97e7\u6027\u63d0\u4f9b\u4e86\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u67b6\u6784\u4ee5\u6839\u672c\u4e0d\u540c\u7684\u65b9\u5f0f\u7f16\u7801\u548c\u5904\u7406\u8bf4\u670d\u8bed\u8a00\u6a21\u5f0f\u3002"}}
{"id": "2511.21752", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21752", "abs": "https://arxiv.org/abs/2511.21752", "authors": ["Yanxi Li", "Ruocheng Shan"], "title": "Semantics as a Shield: Label Disguise Defense (LDD) against Prompt Injection in LLM Sentiment Classification", "comment": null, "summary": "Large language models are increasingly used for text classification tasks such as sentiment analysis, yet their reliance on natural language prompts exposes them to prompt injection attacks. In particular, class-directive injections exploit knowledge of the model's label set (e.g., positive vs. negative) to override its intended behavior through adversarial instructions. Existing defenses, such as detection-based filters, instruction hierarchies, and signed prompts, either require model retraining or remain vulnerable to obfuscation. This paper introduces Label Disguise Defense (LDD), a lightweight and model-agnostic strategy that conceals true labels by replacing them with semantically transformed or unrelated alias labels(e.g., blue vs. yellow). The model learns these new label mappings implicitly through few-shot demonstrations, preventing direct correspondence between injected directives and decision outputs. We evaluate LDD across nine state-of-the-art models, including GPT-5, GPT-4o, LLaMA3.2, Gemma3, and Mistral variants, under varying few-shot and an adversarial setting. Our results show that the ability of LDD to recover performance lost to the adversarial attack varies across models and alias choices. For every model evaluated, LDD is able to restore a portion of the accuracy degradation caused by the attack. Moreover, for the vast majority of models, we can identify more than one alias pair that achieves higher accuracy than the under-attack baseline, in which the model relies solely on few-shot learning without any defensive mechanism. A linguistic analysis further reveals that semantically aligned alias labels(e.g., good vs. bad) yield stronger robustness than unaligned symbols(e.g., blue vs. yellow). Overall, this study demonstrates that label semantics can serve as an effective defense layer, transforming meaning itself into a shield against prompt injection.", "AI": {"tldr": "Label Disguise Defense (LDD) \u901a\u8fc7\u7528\u8bed\u4e49\u8f6c\u6362\u6216\u65e0\u5173\u7684\u522b\u540d\u6807\u7b7e\u66ff\u6362\u771f\u5b9e\u6807\u7b7e\u6765\u9632\u5fa1\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u6a21\u578b\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u6f14\u793a\u9690\u5f0f\u5b66\u4e60\u65b0\u6807\u7b7e\u6620\u5c04\uff0c\u9632\u6b62\u653b\u51fb\u6307\u4ee4\u76f4\u63a5\u5f71\u54cd\u51b3\u7b56\u8f93\u51fa\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u4f9d\u8d56\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u7279\u522b\u662f\u5229\u7528\u6a21\u578b\u6807\u7b7e\u96c6\u77e5\u8bc6\u7684\u7c7b\u522b\u5bfc\u5411\u6ce8\u5165\u653b\u51fb\u3002\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\uff0c\u8981\u4e48\u5bb9\u6613\u53d7\u5230\u6df7\u6dc6\u653b\u51fb\u3002", "method": "\u63d0\u51faLabel Disguise Defense (LDD)\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u6a21\u578b\u65e0\u5173\u7684\u7b56\u7565\uff1a\u9690\u85cf\u771f\u5b9e\u6807\u7b7e\uff0c\u7528\u8bed\u4e49\u8f6c\u6362\u6216\u65e0\u5173\u7684\u522b\u540d\u6807\u7b7e\u66ff\u6362\uff08\u5982\u7528\"\u84dd\u8272\"vs\"\u9ec4\u8272\"\u4ee3\u66ff\"\u6b63\u9762\"vs\"\u8d1f\u9762\"\uff09\u3002\u6a21\u578b\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u6f14\u793a\u9690\u5f0f\u5b66\u4e60\u8fd9\u4e9b\u65b0\u6807\u7b7e\u6620\u5c04\uff0c\u9632\u6b62\u6ce8\u5165\u6307\u4ee4\u4e0e\u51b3\u7b56\u8f93\u51fa\u76f4\u63a5\u5bf9\u5e94\u3002", "result": "\u57289\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\uff08\u5305\u62ecGPT-5\u3001GPT-4o\u3001LLaMA3.2\u3001Gemma3\u548cMistral\u53d8\u4f53\uff09\u4e0a\u8bc4\u4f30LDD\u3002\u7ed3\u679c\u663e\u793a\uff1a1) LDD\u6062\u590d\u56e0\u653b\u51fb\u800c\u635f\u5931\u7684\u6027\u80fd\u80fd\u529b\u56e0\u6a21\u578b\u548c\u522b\u540d\u9009\u62e9\u800c\u5f02\uff1b2) \u5bf9\u6240\u6709\u6a21\u578b\uff0cLDD\u90fd\u80fd\u90e8\u5206\u6062\u590d\u653b\u51fb\u9020\u6210\u7684\u51c6\u786e\u7387\u4e0b\u964d\uff1b3) \u5bf9\u7edd\u5927\u591a\u6570\u6a21\u578b\uff0c\u80fd\u627e\u5230\u591a\u4e2a\u522b\u540d\u5bf9\uff0c\u5176\u51c6\u786e\u7387\u9ad8\u4e8e\u4ec5\u4f9d\u8d56\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u800c\u65e0\u9632\u5fa1\u673a\u5236\u7684\u57fa\u51c6\u3002\u8bed\u8a00\u5206\u6790\u663e\u793a\u8bed\u4e49\u5bf9\u9f50\u7684\u522b\u540d\u6807\u7b7e\u6bd4\u672a\u5bf9\u9f50\u7684\u7b26\u53f7\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6807\u7b7e\u8bed\u4e49\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u9632\u5fa1\u5c42\uff0c\u5c06\u610f\u4e49\u672c\u8eab\u8f6c\u5316\u4e3a\u5bf9\u6297\u63d0\u793a\u6ce8\u5165\u7684\u76fe\u724c\u3002\u8fd9\u9879\u7814\u7a76\u8868\u660e\u901a\u8fc7\u9690\u85cf\u771f\u5b9e\u6807\u7b7e\u5e76\u8ba9\u6a21\u578b\u9690\u5f0f\u5b66\u4e60\u65b0\u6620\u5c04\uff0c\u53ef\u4ee5\u6709\u6548\u9632\u5fa1\u7c7b\u522b\u5bfc\u5411\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002"}}
{"id": "2511.21753", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21753", "abs": "https://arxiv.org/abs/2511.21753", "authors": ["Sameeah Noreen Hameed", "Surangika Ranathunga", "Raj Prasanna", "Kristin Stock", "Christopher B. Jones"], "title": "Extracting Disaster Impacts and Impact Related Locations in Social Media Posts Using Large Language Models", "comment": null, "summary": "Large-scale disasters can often result in catastrophic consequences on people and infrastructure. Situation awareness about such disaster impacts generated by authoritative data from in-situ sensors, remote sensing imagery, and/or geographic data is often limited due to atmospheric opacity, satellite revisits, and time limitations. This often results in geo-temporal information gaps. In contrast, impact-related social media posts can act as \"geo-sensors\" during a disaster, where people describe specific impacts and locations. However, not all locations mentioned in disaster-related social media posts relate to an impact. Only the impacted locations are critical for directing resources effectively. e.g., \"The death toll from a fire which ripped through the Greek coastal town of #Mati stood at 80, with dozens of people unaccounted for as forensic experts tried to identify victims who were burned alive #Greecefires #AthensFires #Athens #Greece.\" contains impacted location \"Mati\" and non-impacted locations \"Greece\" and \"Athens\". This research uses Large Language Models (LLMs) to identify all locations, impacts and impacted locations mentioned in disaster-related social media posts. In the process, LLMs are fine-tuned to identify only impacts and impacted locations (as distinct from other, non-impacted locations), including locations mentioned in informal expressions, abbreviations, and short forms. Our fine-tuned model demonstrates efficacy, achieving an F1-score of 0.69 for impact and 0.74 for impacted location extraction, substantially outperforming the pre-trained baseline. These robust results confirm the potential of fine-tuned language models to offer a scalable solution for timely decision-making in resource allocation, situational awareness, and post-disaster recovery planning for responders.", "AI": {"tldr": "\u4f7f\u7528\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u707e\u5bb3\u76f8\u5173\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u4e2d\u63d0\u53d6\u5f71\u54cd\u548c\u53d7\u5f71\u54cd\u4f4d\u7f6e\uff0c\u663e\u8457\u4f18\u4e8e\u9884\u8bad\u7ec3\u57fa\u7ebf\uff0c\u4e3a\u707e\u5bb3\u54cd\u5e94\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5927\u89c4\u6a21\u707e\u5bb3\u901a\u5e38\u9020\u6210\u707e\u96be\u6027\u540e\u679c\uff0c\u4f46\u4f20\u7edf\u6743\u5a01\u6570\u636e\uff08\u73b0\u573a\u4f20\u611f\u5668\u3001\u9065\u611f\u5f71\u50cf\u3001\u5730\u7406\u6570\u636e\uff09\u5b58\u5728\u65f6\u7a7a\u4fe1\u606f\u7f3a\u53e3\u3002\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u53ef\u4f5c\u4e3a\"\u5730\u7406\u4f20\u611f\u5668\"\u63d0\u4f9b\u5b9e\u65f6\u5f71\u54cd\u4fe1\u606f\uff0c\u4f46\u5e76\u975e\u6240\u6709\u63d0\u53ca\u7684\u4f4d\u7f6e\u90fd\u53d7\u5230\u5b9e\u9645\u5f71\u54cd\uff0c\u53ea\u6709\u53d7\u5f71\u54cd\u4f4d\u7f6e\u5bf9\u8d44\u6e90\u5206\u914d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8bc6\u522b\u707e\u5bb3\u76f8\u5173\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u4e2d\u7684\u6240\u6709\u4f4d\u7f6e\u3001\u5f71\u54cd\u548c\u53d7\u5f71\u54cd\u4f4d\u7f6e\u3002\u901a\u8fc7\u5fae\u8c03LLMs\u4e13\u95e8\u8bc6\u522b\u5f71\u54cd\u548c\u53d7\u5f71\u54cd\u4f4d\u7f6e\uff08\u533a\u522b\u4e8e\u975e\u53d7\u5f71\u54cd\u4f4d\u7f6e\uff09\uff0c\u5305\u62ec\u975e\u6b63\u5f0f\u8868\u8fbe\u3001\u7f29\u5199\u548c\u7b80\u5199\u5f62\u5f0f\u7684\u4f4d\u7f6e\u4fe1\u606f\u3002", "result": "\u5fae\u8c03\u6a21\u578b\u5728\u5f71\u54cd\u63d0\u53d6\u4e0a\u8fbe\u5230F1\u5206\u65700.69\uff0c\u5728\u53d7\u5f71\u54cd\u4f4d\u7f6e\u63d0\u53d6\u4e0a\u8fbe\u52300.74\uff0c\u663e\u8457\u4f18\u4e8e\u9884\u8bad\u7ec3\u57fa\u7ebf\u3002\u8fd9\u4e9b\u7a33\u5065\u7ed3\u679c\u8bc1\u5b9e\u4e86\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u5728\u707e\u5bb3\u54cd\u5e94\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u5fae\u8c03\u7684\u8bed\u8a00\u6a21\u578b\u4e3a\u707e\u5bb3\u54cd\u5e94\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u3001\u6001\u52bf\u611f\u77e5\u548c\u707e\u540e\u6062\u590d\u89c4\u5212\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u53ca\u65f6\u51b3\u7b56\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u5173\u952e\u5f71\u54cd\u548c\u53d7\u5f71\u54cd\u4f4d\u7f6e\u4fe1\u606f\u3002"}}
{"id": "2511.21756", "categories": ["cs.CL", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.21756", "abs": "https://arxiv.org/abs/2511.21756", "authors": ["Soham Mirajkar"], "title": "Dissecting the Ledger: Locating and Suppressing \"Liar Circuits\" in Financial Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in high-stakes financial domains, yet they suffer from specific, reproducible hallucinations when performing arithmetic operations. Current mitigation strategies often treat the model as a black box. In this work, we propose a mechanistic approach to intrinsic hallucination detection. By applying Causal Tracing to the GPT-2 XL architecture on the ConvFinQA benchmark, we identify a dual-stage mechanism for arithmetic reasoning: a distributed computational scratchpad in middle layers (L12-L30) and a decisive aggregation circuit in late layers (specifically Layer 46). We verify this mechanism via an ablation study, demonstrating that suppressing Layer 46 reduces the model's confidence in hallucinatory outputs by 81.8%. Furthermore, we demonstrate that a linear probe trained on this layer generalizes to unseen financial topics with 98% accuracy, suggesting a universal geometry of arithmetic deception.", "AI": {"tldr": "\u901a\u8fc7\u56e0\u679c\u8ffd\u8e2a\u6280\u672f\uff0c\u5728GPT-2 XL\u67b6\u6784\u4e2d\u53d1\u73b0\u7b97\u672f\u63a8\u7406\u7684\u53cc\u9636\u6bb5\u673a\u5236\uff1a\u4e2d\u5c42\u5206\u5e03\u5f0f\u8ba1\u7b97\u8349\u7a3f\u548c\u6df1\u5c42\u805a\u5408\u7535\u8def\uff0c\u53ef\u7528\u4e8e\u68c0\u6d4b\u91d1\u878d\u9886\u57dfLLM\u7684\u7b97\u672f\u5e7b\u89c9", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72\u65f6\u5b58\u5728\u53ef\u590d\u73b0\u7684\u7b97\u672f\u5e7b\u89c9\u95ee\u9898\uff0c\u73b0\u6709\u7f13\u89e3\u7b56\u7565\u901a\u5e38\u5c06\u6a21\u578b\u89c6\u4e3a\u9ed1\u7bb1\uff0c\u9700\u8981\u66f4\u673a\u5236\u5316\u7684\u5185\u5728\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5", "method": "\u5728ConvFinQA\u57fa\u51c6\u4e0a\u5bf9GPT-2 XL\u67b6\u6784\u5e94\u7528\u56e0\u679c\u8ffd\u8e2a\u6280\u672f\uff0c\u8bc6\u522b\u7b97\u672f\u63a8\u7406\u7684\u53cc\u9636\u6bb5\u673a\u5236\uff1a\u4e2d\u5c42\uff08L12-L30\uff09\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u8349\u7a3f\u548c\u6df1\u5c42\uff08\u7279\u522b\u662f\u7b2c46\u5c42\uff09\u7684\u51b3\u5b9a\u6027\u805a\u5408\u7535\u8def", "result": "\u6291\u5236\u7b2c46\u5c42\u53ef\u5c06\u6a21\u578b\u5bf9\u5e7b\u89c9\u8f93\u51fa\u7684\u7f6e\u4fe1\u5ea6\u964d\u4f4e81.8%\uff1b\u5728\u8be5\u5c42\u8bad\u7ec3\u7684\u7ebf\u6027\u63a2\u9488\u5728\u672a\u89c1\u8fc7\u7684\u91d1\u878d\u4e3b\u9898\u4e0a\u8fbe\u523098%\u51c6\u786e\u7387\uff0c\u8868\u660e\u7b97\u672f\u6b3a\u9a97\u5b58\u5728\u666e\u904d\u51e0\u4f55\u7ed3\u6784", "conclusion": "\u63ed\u793a\u4e86LLM\u7b97\u672f\u63a8\u7406\u7684\u673a\u5236\u5316\u7ed3\u6784\uff0c\u4e3a\u5185\u5728\u5e7b\u89c9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u8868\u660e\u7b97\u672f\u6b3a\u9a97\u5177\u6709\u53ef\u63a8\u5e7f\u7684\u51e0\u4f55\u7279\u5f81\uff0c\u5bf9\u9ad8\u98ce\u9669\u91d1\u878d\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2511.21759", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21759", "abs": "https://arxiv.org/abs/2511.21759", "authors": ["Linye Wei", "Wenjue Chen", "Pingzhi Tang", "Xiaotian Guo", "Le Ye", "Runsheng Wang", "Meng Li"], "title": "Orchestrating Dual-Boundaries: An Arithmetic Intensity Inspired Acceleration Framework for Diffusion Language Models", "comment": null, "summary": "Diffusion-based large language models (dLLMs) have recently gained significant attention for their exceptional performance and inherent potential for parallel decoding. Existing frameworks further enhance its inference efficiency by enabling KV caching. However, its bidirectional attention mechanism necessitates periodic cache refreshes that interleave prefill and decoding phases, both contributing substantial inference cost and constraining achievable speedup. Inspired by the heterogeneous arithmetic intensity of the prefill and decoding phases, we propose ODB-dLLM, a framework that orchestrates dual-boundaries to accelerate dLLM inference. In the prefill phase, we find that the predefined fixed response length introduces heavy yet redundant computational overhead, which affects efficiency. To alleviate this, ODB-dLLM incorporates an adaptive length prediction mechanism that progressively reduces prefill overhead and unnecessary computation. In the decoding phase, we analyze the computational characteristics of dLLMs and propose a dLLM-specific jump-share speculative decoding method to enhance efficiency by reducing the number of decoding iterations. Experimental results demonstrate that ODB-dLLM achieves 46-162x and 2.63-6.30x speedups over the baseline dLLM and Fast-dLLM, respectively, while simultaneously mitigating the accuracy degradation in existing acceleration frameworks.", "AI": {"tldr": "ODB-dLLM\u901a\u8fc7\u81ea\u9002\u5e94\u957f\u5ea6\u9884\u6d4b\u548c\u8df3\u8f6c\u5171\u4eab\u63a8\u6d4b\u89e3\u7801\u6280\u672f\uff0c\u52a0\u901f\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5b9e\u73b046-162\u500d\u52a0\u901f", "motivation": "\u73b0\u6709\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b(dLLM)\u6846\u67b6\u867d\u7136\u652f\u6301KV\u7f13\u5b58\uff0c\u4f46\u5176\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\u9700\u8981\u5b9a\u671f\u5237\u65b0\u7f13\u5b58\uff0c\u5bfc\u81f4\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u4ea4\u66ff\u8fdb\u884c\uff0c\u589e\u52a0\u4e86\u63a8\u7406\u6210\u672c\u5e76\u9650\u5236\u4e86\u52a0\u901f\u6f5c\u529b", "method": "\u63d0\u51faODB-dLLM\u6846\u67b6\uff1a1) \u9884\u586b\u5145\u9636\u6bb5\u91c7\u7528\u81ea\u9002\u5e94\u957f\u5ea6\u9884\u6d4b\u673a\u5236\uff0c\u6e10\u8fdb\u51cf\u5c11\u9884\u586b\u5145\u5f00\u9500\u548c\u4e0d\u5fc5\u8981\u8ba1\u7b97\uff1b2) \u89e3\u7801\u9636\u6bb5\u63d0\u51fadLLM\u4e13\u7528\u7684\u8df3\u8f6c\u5171\u4eab\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u51cf\u5c11\u89e3\u7801\u8fed\u4ee3\u6b21\u6570", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cODB-dLLM\u76f8\u6bd4\u57fa\u7ebfdLLM\u5b9e\u73b046-162\u500d\u52a0\u901f\uff0c\u76f8\u6bd4Fast-dLLM\u5b9e\u73b02.63-6.30\u500d\u52a0\u901f\uff0c\u540c\u65f6\u7f13\u89e3\u4e86\u73b0\u6709\u52a0\u901f\u6846\u67b6\u7684\u7cbe\u5ea6\u4e0b\u964d\u95ee\u9898", "conclusion": "ODB-dLLM\u901a\u8fc7\u534f\u8c03\u53cc\u8fb9\u754c\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86dLLM\u63a8\u7406\u4e2d\u7684\u6548\u7387\u74f6\u9888\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6"}}
{"id": "2511.21760", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21760", "abs": "https://arxiv.org/abs/2511.21760", "authors": ["Yuxiang Wei", "Yanteng Zhang", "Xi Xiao", "Chengxuan Qian", "Tianyang Wang", "Vince D. Calhoun"], "title": "fMRI-LM: Towards a Universal Foundation Model for Language-Aligned fMRI Understanding", "comment": null, "summary": "Recent advances in multimodal large language models (LLMs) have enabled unified reasoning across images, audio, and video, but extending such capability to brain imaging remains largely unexplored. Bridging this gap is essential to link neural activity with semantic cognition and to develop cross-modal brain representations. To this end, we present fMRI-LM, a foundational model that bridges functional MRI (fMRI) and language through a three-stage framework. In Stage 1, we learn a neural tokenizer that maps fMRI into discrete tokens embedded in a language-consistent space. In Stage 2, a pretrained LLM is adapted to jointly model fMRI tokens and text, treating brain activity as a sequence that can be temporally predicted and linguistically described. To overcome the lack of natural fMRI-text pairs, we construct a large descriptive corpus that translates diverse imaging-based features into structured textual descriptors, capturing the low-level organization of fMRI signals. In Stage 3, we perform multi-task, multi-paradigm instruction tuning to endow fMRI-LM with high-level semantic understanding, supporting diverse downstream applications. Across various benchmarks, fMRI-LM achieves strong zero-shot and few-shot performance, and adapts efficiently with parameter-efficient tuning (LoRA), establishing a scalable pathway toward a language-aligned, universal model for structural and semantic understanding of fMRI.", "AI": {"tldr": "fMRI-LM\u662f\u4e00\u4e2a\u5c06\u529f\u80fd\u6027\u78c1\u5171\u632f\u6210\u50cf\uff08fMRI\uff09\u4e0e\u8bed\u8a00\u6a21\u578b\u8fde\u63a5\u7684\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6846\u67b6\u5b9e\u73b0\u8111\u6210\u50cf\u4e0e\u8bed\u4e49\u7406\u89e3\u7684\u7edf\u4e00\u63a8\u7406\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u7b49\u9886\u57df\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5c06\u5176\u6269\u5c55\u5230\u8111\u6210\u50cf\u9886\u57df\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u5bf9\u4e8e\u8fde\u63a5\u795e\u7ecf\u6d3b\u52a8\u4e0e\u8bed\u4e49\u8ba4\u77e5\u3001\u5f00\u53d1\u8de8\u6a21\u6001\u8111\u8868\u5f81\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1) \u5b66\u4e60\u795e\u7ecf\u6807\u8bb0\u5668\uff0c\u5c06fMRI\u6620\u5c04\u5230\u8bed\u8a00\u4e00\u81f4\u7a7a\u95f4\u4e2d\u7684\u79bb\u6563\u6807\u8bb0\uff1b2) \u9002\u914d\u9884\u8bad\u7ec3LLM\uff0c\u8054\u5408\u5efa\u6a21fMRI\u6807\u8bb0\u548c\u6587\u672c\uff0c\u5c06\u8111\u6d3b\u52a8\u89c6\u4e3a\u53ef\u9884\u6d4b\u548c\u63cf\u8ff0\u7684\u5e8f\u5217\uff1b3) \u8fdb\u884c\u591a\u4efb\u52a1\u3001\u591a\u8303\u5f0f\u6307\u4ee4\u5fae\u8c03\uff0c\u8d4b\u4e88\u6a21\u578b\u9ad8\u7ea7\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "result": "fMRI-LM\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u8c03\u4f18\uff08LoRA\uff09\u9ad8\u6548\u9002\u5e94\uff0c\u4e3afMRI\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u7406\u89e3\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u7684\u8bed\u8a00\u5bf9\u9f50\u901a\u7528\u6a21\u578b\u8def\u5f84\u3002", "conclusion": "fMRI-LM\u6210\u529f\u5c06\u591a\u6a21\u6001LLM\u80fd\u529b\u6269\u5c55\u5230\u8111\u6210\u50cf\u9886\u57df\uff0c\u5efa\u7acb\u4e86fMRI\u4e0e\u8bed\u8a00\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u4e3a\u7406\u89e3\u795e\u7ecf\u6d3b\u52a8\u4e0e\u8bed\u4e49\u8ba4\u77e5\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21761", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.21761", "abs": "https://arxiv.org/abs/2511.21761", "authors": ["Tabia Tanzin Prama", "Christopher M. Danforth", "Peter Sheridan Dodds"], "title": "LLMs for Low-Resource Dialect Translation Using Context-Aware Prompting: A Case Study on Sylheti", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong translation abilities through prompting, even without task-specific training. However, their effectiveness in dialectal and low-resource contexts remains underexplored. This study presents the first systematic investigation of LLM-based machine translation (MT) for Sylheti, a dialect of Bangla that is itself low-resource. We evaluate five advanced LLMs (GPT-4.1, GPT-4.1, LLaMA 4, Grok 3, and DeepSeek V3.2) across both translation directions (Bangla $\\Leftrightarrow$ Sylheti), and find that these models struggle with dialect-specific vocabulary. To address this, we introduce Sylheti-CAP (Context-Aware Prompting), a three-step framework that embeds a linguistic rulebook, a dictionary (2{,}260 core vocabulary items and idioms), and an authenticity check directly into prompts. Extensive experiments show that Sylheti-CAP consistently improves translation quality across models and prompting strategies. Both automatic metrics and human evaluations confirm its effectiveness, while qualitative analysis reveals notable reductions in hallucinations, ambiguities, and awkward phrasing, establishing Sylheti-CAP as a scalable solution for dialectal and low-resource MT. Dataset link: \\href{https://github.com/TabiaTanzin/LLMs-for-Low-Resource-Dialect-Translation-Using-Context-Aware-Prompting-A-Case-Study-on-Sylheti.git}{https://github.com/TabiaTanzin/LLMs-for-Low-Resource-Dialect-Translation-Using-Context-Aware-Prompting-A-Case-Study-on-Sylheti.git}", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u65b9\u8a00\u7ffb\u8bd1\u4e2d\u7684\u5e94\u7528\uff0c\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u65b9\u8a00Sylheti\u63d0\u51fa\u4e86Sylheti-CAP\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u663e\u8457\u63d0\u5347\u4e86\u7ffb\u8bd1\u8d28\u91cf\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u65b9\u8a00\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002Sylheti\u4f5c\u4e3a\u5b5f\u52a0\u62c9\u8bed\u7684\u4f4e\u8d44\u6e90\u65b9\u8a00\uff0c\u7f3a\u4e4f\u4e13\u95e8\u7684\u7ffb\u8bd1\u7cfb\u7edf\u652f\u6301\u3002", "method": "\u63d0\u51fa\u4e86Sylheti-CAP\uff08\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6b65\u9aa4\uff1a1\uff09\u5d4c\u5165\u8bed\u8a00\u5b66\u89c4\u5219\u624b\u518c\uff1b2\uff09\u96c6\u6210\u5305\u542b2,260\u4e2a\u6838\u5fc3\u8bcd\u6c47\u548c\u4e60\u8bed\u7684\u8bcd\u5178\uff1b3\uff09\u8fdb\u884c\u771f\u5b9e\u6027\u68c0\u67e5\u3002\u8bc4\u4f30\u4e86GPT-4.1\u3001LLaMA 4\u3001Grok 3\u548cDeepSeek V3.2\u7b49\u4e94\u4e2a\u5148\u8fdbLLM\u3002", "result": "Sylheti-CAP\u5728\u6240\u6709\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\u4e2d\u4e00\u81f4\u63d0\u5347\u4e86\u7ffb\u8bd1\u8d28\u91cf\u3002\u81ea\u52a8\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4f30\u5747\u8bc1\u5b9e\u5176\u6709\u6548\u6027\uff0c\u5b9a\u6027\u5206\u6790\u663e\u793a\u5e7b\u89c9\u3001\u6b67\u4e49\u548c\u751f\u786c\u8868\u8fbe\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "Sylheti-CAP\u4e3a\u65b9\u8a00\u548c\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u65b9\u8a00\u7279\u5b9a\u8bcd\u6c47\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.21762", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21762", "abs": "https://arxiv.org/abs/2511.21762", "authors": ["Gabriele Cesar Iwashima", "Claudia Susie Rodrigues", "Claudio Dipolitto", "Geraldo Xex\u00e9o"], "title": "Factors That Support Grounded Responses in LLM Conversations: A Rapid Review", "comment": "28 pages, 1 figure, 3 tables", "summary": "Large language models (LLMs) may generate outputs that are misaligned with user intent, lack contextual grounding, or exhibit hallucinations during conversation, which compromises the reliability of LLM-based applications. This review aimed to identify and analyze techniques that align LLM responses with conversational goals, ensure grounding, and reduce hallucination and topic drift. We conducted a Rapid Review guided by the PRISMA framework and the PICO strategy to structure the search, filtering, and selection processes. The alignment strategies identified were categorized according to the LLM lifecycle phase in which they operate: inference-time, post-training, and reinforcement learning-based methods. Among these, inference-time approaches emerged as particularly efficient, aligning outputs without retraining while supporting user intent, contextual grounding, and hallucination mitigation. The reviewed techniques provided structured mechanisms for improving the quality and reliability of LLM responses across key alignment objectives.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u7cfb\u7edf\u56de\u987e\u4e86\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u8bdd\u5bf9\u9f50\u3001\u4e0a\u4e0b\u6587\u57fa\u7840\u548c\u51cf\u5c11\u5e7b\u89c9\u7684\u6280\u672f\u65b9\u6cd5\uff0c\u901a\u8fc7PRISMA\u6846\u67b6\u548cPICO\u7b56\u7565\u8fdb\u884c\u5feb\u901f\u56de\u987e\uff0c\u5c06\u6280\u672f\u5206\u4e3a\u63a8\u7406\u65f6\u3001\u8bad\u7ec3\u540e\u548c\u5f3a\u5316\u5b66\u4e60\u4e09\u7c7b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u8bdd\u4e2d\u53ef\u80fd\u751f\u6210\u4e0e\u7528\u6237\u610f\u56fe\u4e0d\u4e00\u81f4\u3001\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u57fa\u7840\u6216\u51fa\u73b0\u5e7b\u89c9\u7684\u8f93\u51fa\uff0c\u8fd9\u5f71\u54cd\u4e86\u57fa\u4e8eLLM\u5e94\u7528\u7684\u53ef\u9760\u6027\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5206\u6790\u63d0\u5347\u5bf9\u8bdd\u5bf9\u9f50\u7684\u6280\u672f\u3002", "method": "\u91c7\u7528\u57fa\u4e8ePRISMA\u6846\u67b6\u548cPICO\u7b56\u7565\u7684\u5feb\u901f\u56de\u987e\u65b9\u6cd5\uff0c\u8fdb\u884c\u6587\u732e\u641c\u7d22\u3001\u7b5b\u9009\u548c\u9009\u62e9\uff0c\u5c06\u8bc6\u522b\u51fa\u7684\u5bf9\u9f50\u7b56\u7565\u6309\u7167LLM\u751f\u547d\u5468\u671f\u9636\u6bb5\u5206\u7c7b\uff1a\u63a8\u7406\u65f6\u65b9\u6cd5\u3001\u8bad\u7ec3\u540e\u65b9\u6cd5\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u65f6\u65b9\u6cd5\u7279\u522b\u9ad8\u6548\uff0c\u80fd\u591f\u5728\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5bf9\u9f50\u8f93\u51fa\uff0c\u540c\u65f6\u652f\u6301\u7528\u6237\u610f\u56fe\u3001\u4e0a\u4e0b\u6587\u57fa\u7840\u548c\u5e7b\u89c9\u7f13\u89e3\u3002\u6240\u6709\u88ab\u56de\u987e\u7684\u6280\u672f\u90fd\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u673a\u5236\u6765\u63d0\u5347LLM\u54cd\u5e94\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u8bdd\u5bf9\u9f50\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u6280\u672f\u5206\u7c7b\u548c\u5206\u6790\u6846\u67b6\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u63a8\u7406\u65f6\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u7387\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u63d0\u5347LLM\u5e94\u7528\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2511.21843", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21843", "abs": "https://arxiv.org/abs/2511.21843", "authors": ["Sarina Xi", "Vishisht Rao", "Justin Payan", "Nihar B. Shah"], "title": "FLAWS: A Benchmark for Error Identification and Localization in Scientific Papers", "comment": "30 pages, 12 tables, 2 figures", "summary": "The identification and localization of errors is a core task in peer review, yet the exponential growth of scientific output has made it increasingly difficult for human reviewers to reliably detect errors given the limited pool of experts. Recent advances in Large Language Models (LLMs) have sparked interest in their potential to support such evaluation tasks, from academic peer review to automated scientific assessment. However, despite the growing use of LLMs in review systems, their capabilities to pinpoint errors remain underexplored. In this work, we introduce Fault Localization Across Writing in Science (FLAWS), an automated benchmark consisting of 713 paper-error pairs designed to evaluate how effectively LLMs detect errors that undermine key claims in research papers. We construct the benchmark by systematically inserting claim-invalidating errors into peer-reviewed papers using LLMs, paired with an automated evaluation metric that measures whether models can identify and localize these errors. Developing such a benchmark presents unique challenges that we overcome: ensuring that the inserted errors are well-defined, challenging, and relevant to the content of the paper, avoiding artifacts that would make identification trivial, and designing a scalable, automated evaluation metric. On the resulting benchmark, we evaluate five frontier LLMs: Claude Sonnet 4.5, DeepSeek Reasoner v3.1, Gemini 2.5 Pro, GPT 5, and Grok 4. Among these, GPT 5 is the top-performing model, achieving 39.1% identification accuracy when k=10, where k is the number of top-ranked error text candidates generated by the LLM.", "AI": {"tldr": "FLAWS\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u79d1\u7814\u8bba\u6587\u4e2d\u68c0\u6d4b\u548c\u5b9a\u4f4d\u9519\u8bef\u7684\u81ea\u52a8\u5316\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b713\u4e2a\u8bba\u6587-\u9519\u8bef\u5bf9\uff0cGPT-5\u5728\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u968f\u7740\u79d1\u5b66\u4ea7\u51fa\u7684\u6307\u6570\u7ea7\u589e\u957f\uff0c\u4eba\u7c7b\u5ba1\u7a3f\u4eba\u96be\u4ee5\u53ef\u9760\u5730\u68c0\u6d4b\u9519\u8bef\uff0c\u800cLLMs\u5728\u9519\u8bef\u68c0\u6d4b\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u901a\u8fc7\u4f7f\u7528LLMs\u5728\u540c\u884c\u8bc4\u5ba1\u8bba\u6587\u4e2d\u7cfb\u7edf\u6027\u5730\u63d2\u5165\u7834\u574f\u5173\u952e\u4e3b\u5f20\u7684\u9519\u8bef\uff0c\u6784\u5efa\u4e86713\u4e2a\u8bba\u6587-\u9519\u8bef\u5bf9\uff0c\u5e76\u8bbe\u8ba1\u4e86\u81ea\u52a8\u5316\u7684\u8bc4\u4f30\u6307\u6807\u6765\u6d4b\u91cf\u6a21\u578b\u8bc6\u522b\u548c\u5b9a\u4f4d\u8fd9\u4e9b\u9519\u8bef\u7684\u80fd\u529b\u3002", "result": "\u5728\u8bc4\u4f30\u7684\u4e94\u4e2a\u524d\u6cbfLLM\uff08Claude Sonnet 4.5\u3001DeepSeek Reasoner v3.1\u3001Gemini 2.5 Pro\u3001GPT 5\u3001Grok 4\uff09\u4e2d\uff0cGPT 5\u8868\u73b0\u6700\u4f73\uff0c\u5728k=10\uff08LLM\u751f\u6210\u7684top-k\u9519\u8bef\u6587\u672c\u5019\u9009\uff09\u65f6\u8fbe\u523039.1%\u7684\u8bc6\u522b\u51c6\u786e\u7387\u3002", "conclusion": "FLAWS\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u8bc4\u4f30LLMs\u5728\u79d1\u5b66\u9519\u8bef\u68c0\u6d4b\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u867d\u7136\u5f53\u524d\u6a21\u578b\u8868\u73b0\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u4f46\u5c55\u793a\u4e86LLMs\u5728\u652f\u6301\u5b66\u672f\u8bc4\u5ba1\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.21860", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21860", "abs": "https://arxiv.org/abs/2511.21860", "authors": ["Paulo Cavalin", "Cassia Sanctos", "Marcelo Grave", "Claudio Pinhanez", "Yago Primerano"], "title": "Improving Score Reliability of Multiple Choice Benchmarks with Consistency Evaluation and Altered Answer Choices", "comment": null, "summary": "In this work we present the Consistency-Rebalanced Accuracy (CoRA) metric, improving the reliability of Large Language Model (LLM) scores computed on multiple choice (MC) benchmarks. Our metric explores the response consistency of the LLMs, taking advantage of synthetically-generated questions with altered answer choices. With two intermediate scores, i.e. Bare-Minimum-Consistency Accuracy (BMCA) and Consistency Index (CI), CoRA is computed by adjusting the multiple-choice question answering (MCQA) scores to better reflect the level of consistency of the LLM. We present evaluations in different benchmarks using diverse LLMs, and not only demonstrate that LLMs can present low response consistency even when they present high MCQA scores, but also that CoRA can successfully scale down the scores of inconsistent models.", "AI": {"tldr": "\u63d0\u51faCoRA\u6307\u6807\uff0c\u901a\u8fc7\u8bc4\u4f30LLM\u5728\u9009\u62e9\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u56de\u7b54\u4e00\u81f4\u6027\u6765\u6539\u8fdb\u8bc4\u5206\u53ef\u9760\u6027", "motivation": "\u5f53\u524dLLM\u5728\u9009\u62e9\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8bc4\u5206\u53ef\u80fd\u4e0d\u53ef\u9760\uff0c\u56e0\u4e3a\u6a21\u578b\u5373\u4f7f\u83b7\u5f97\u9ad8\u5206\u4e5f\u53ef\u80fd\u5b58\u5728\u56de\u7b54\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u8bc4\u4f30\u6307\u6807", "method": "\u63d0\u51faCoRA\u6307\u6807\uff0c\u5229\u7528\u5408\u6210\u751f\u6210\u7684\u4fee\u6539\u9009\u9879\u95ee\u9898\u6765\u8bc4\u4f30LLM\u56de\u7b54\u4e00\u81f4\u6027\uff0c\u5305\u542bBMCA\u548cCI\u4e24\u4e2a\u4e2d\u95f4\u5206\u6570\uff0c\u901a\u8fc7\u8c03\u6574MCQA\u5206\u6570\u6765\u53cd\u6620LLM\u7684\u4e00\u81f4\u6027\u6c34\u5e73", "result": "\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u79cdLLM\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cLLM\u5373\u4f7f\u83b7\u5f97\u9ad8MCQA\u5206\u6570\u4e5f\u53ef\u80fd\u8868\u73b0\u51fa\u4f4e\u4e00\u81f4\u6027\uff0c\u800cCoRA\u80fd\u6210\u529f\u964d\u4f4e\u4e0d\u4e00\u81f4\u6a21\u578b\u7684\u5206\u6570", "conclusion": "CoRA\u6307\u6807\u80fd\u66f4\u53ef\u9760\u5730\u8bc4\u4f30LLM\u5728\u9009\u62e9\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u8003\u8651\u56de\u7b54\u4e00\u81f4\u6027\u6539\u8fdb\u4e86\u4f20\u7edf\u8bc4\u5206\u65b9\u6cd5\u7684\u5c40\u9650\u6027"}}
{"id": "2511.21909", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21909", "abs": "https://arxiv.org/abs/2511.21909", "authors": ["Sofie Labat", "Thomas Demeester", "V\u00e9ronique Hoste"], "title": "A Customer Journey in the Land of Oz: Leveraging the Wizard of Oz Technique to Model Emotions in Customer Service Interactions", "comment": null, "summary": "Emotion-aware customer service needs in-domain conversational data, rich annotations, and predictive capabilities, but existing resources for emotion recognition are often out-of-domain, narrowly labeled, and focused on post-hoc detection. To address this, we conducted a controlled Wizard of Oz (WOZ) experiment to elicit interactions with targeted affective trajectories. The resulting corpus, EmoWOZ-CS, contains 2,148 bilingual (Dutch-English) written dialogues from 179 participants across commercial aviation, e-commerce, online travel agencies, and telecommunication scenarios. Our contributions are threefold: (1) Evaluate WOZ-based operator-steered valence trajectories as a design for emotion research; (2) Quantify human annotation performance and variation, including divergences between self-reports and third-party judgments; (3) Benchmark detection and forward-looking emotion inference in real-time support. Findings show neutral dominates participant messages; desire and gratitude are the most frequent non-neutral emotions. Agreement is moderate for multilabel emotions and valence, lower for arousal and dominance; self-reports diverge notably from third-party labels, aligning most for neutral, gratitude, and anger. Objective strategies often elicit neutrality or gratitude, while suboptimal strategies increase anger, annoyance, disappointment, desire, and confusion. Some affective strategies (cheerfulness, gratitude) foster positive reciprocity, whereas others (apology, empathy) can also leave desire, anger, or annoyance. Temporal analysis confirms successful conversation-level steering toward prescribed trajectories, most distinctly for negative targets; positive and neutral targets yield similar final valence distributions. Benchmarks highlight the difficulty of forward-looking emotion inference from prior turns, underscoring the complexity of proactive emotion-aware support.", "AI": {"tldr": "\u7814\u7a76\u8005\u521b\u5efa\u4e86EmoWOZ-CS\u8bed\u6599\u5e93\uff0c\u5305\u542b2,148\u4e2a\u53cc\u8bed\u5bf9\u8bdd\uff0c\u7528\u4e8e\u7814\u7a76\u5ba2\u670d\u573a\u666f\u4e2d\u7684\u60c5\u611f\u8bc6\u522b\u4e0e\u9884\u6d4b\uff0c\u8bc4\u4f30\u4e86\u60c5\u611f\u8f68\u8ff9\u8bbe\u8ba1\u3001\u6807\u6ce8\u5dee\u5f02\u548c\u5b9e\u65f6\u60c5\u611f\u63a8\u7406\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u8bc6\u522b\u8d44\u6e90\u901a\u5e38\u5b58\u5728\u9886\u57df\u4e0d\u5339\u914d\u3001\u6807\u6ce8\u6709\u9650\u4e14\u4fa7\u91cd\u4e8e\u4e8b\u540e\u68c0\u6d4b\u7684\u95ee\u9898\uff0c\u800c\u5ba2\u670d\u573a\u666f\u9700\u8981\u9886\u57df\u5185\u5bf9\u8bdd\u6570\u636e\u3001\u4e30\u5bcc\u6807\u6ce8\u548c\u9884\u6d4b\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u521b\u5efa\u4e13\u95e8\u7684\u60c5\u611f\u611f\u77e5\u5ba2\u670d\u7814\u7a76\u8d44\u6e90\u3002", "method": "\u91c7\u7528\u53d7\u63a7\u7684Wizard of Oz\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u5f15\u5bfc\u5177\u6709\u7279\u5b9a\u60c5\u611f\u8f68\u8ff9\u7684\u4ea4\u4e92\uff1b\u6536\u96c6\u4e86\u56db\u4e2a\u5546\u4e1a\u9886\u57df\uff08\u822a\u7a7a\u3001\u7535\u5546\u3001\u5728\u7ebf\u65c5\u6e38\u3001\u7535\u4fe1\uff09\u76842,148\u4e2a\u53cc\u8bed\u5bf9\u8bdd\uff1b\u8bc4\u4f30\u4e86\u64cd\u4f5c\u5458\u5f15\u5bfc\u7684\u60c5\u611f\u8f68\u8ff9\u8bbe\u8ba1\u3001\u91cf\u5316\u4e86\u4eba\u5de5\u6807\u6ce8\u6027\u80fd\u4e0e\u5dee\u5f02\uff0c\u5e76\u5bf9\u5b9e\u65f6\u60c5\u611f\u68c0\u6d4b\u548c\u524d\u77bb\u6027\u63a8\u7406\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4e2d\u6027\u60c5\u7eea\u5728\u53c2\u4e0e\u8005\u6d88\u606f\u4e2d\u5360\u4e3b\u5bfc\uff1b\u6b32\u671b\u548c\u611f\u6fc0\u662f\u6700\u5e38\u89c1\u7684\u975e\u4e2d\u6027\u60c5\u7eea\u3002\u591a\u6807\u7b7e\u60c5\u611f\u548c\u6548\u4ef7\u6807\u6ce8\u4e00\u81f4\u6027\u4e2d\u7b49\uff0c\u5524\u9192\u5ea6\u548c\u652f\u914d\u5ea6\u4e00\u81f4\u6027\u8f83\u4f4e\uff1b\u81ea\u6211\u62a5\u544a\u4e0e\u7b2c\u4e09\u65b9\u6807\u6ce8\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u5ba2\u89c2\u7b56\u7565\u901a\u5e38\u5f15\u53d1\u4e2d\u6027\u6216\u611f\u6fc0\uff0c\u800c\u6b21\u4f18\u7b56\u7565\u589e\u52a0\u6124\u6012\u3001\u70e6\u607c\u3001\u5931\u671b\u3001\u6b32\u671b\u548c\u56f0\u60d1\u3002\u67d0\u4e9b\u60c5\u611f\u7b56\u7565\uff08\u6109\u5feb\u3001\u611f\u6fc0\uff09\u4fc3\u8fdb\u79ef\u6781\u4e92\u60e0\uff0c\u800c\u5176\u4ed6\u7b56\u7565\uff08\u9053\u6b49\u3001\u540c\u7406\u5fc3\uff09\u53ef\u80fd\u5f15\u53d1\u8d1f\u9762\u60c5\u7eea\u3002\u65f6\u95f4\u5206\u6790\u8bc1\u5b9e\u5bf9\u8bdd\u7ea7\u60c5\u611f\u8f68\u8ff9\u5f15\u5bfc\u6210\u529f\uff0c\u7279\u522b\u662f\u8d1f\u9762\u76ee\u6807\uff1b\u6b63\u5411\u548c\u4e2d\u6027\u76ee\u6807\u4ea7\u751f\u76f8\u4f3c\u7684\u6700\u7ec8\u6548\u4ef7\u5206\u5e03\u3002\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u57fa\u4e8e\u5148\u524d\u8f6e\u6b21\u7684\u524d\u77bb\u6027\u60c5\u611f\u63a8\u7406\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "EmoWOZ-CS\u8bed\u6599\u5e93\u4e3a\u60c5\u611f\u611f\u77e5\u5ba2\u670d\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\uff1bWizard of Oz\u5b9e\u9a8c\u8bbe\u8ba1\u80fd\u6709\u6548\u5f15\u5bfc\u60c5\u611f\u8f68\u8ff9\uff1b\u6807\u6ce8\u5dee\u5f02\u51f8\u663e\u4e86\u60c5\u611f\u6807\u6ce8\u7684\u590d\u6742\u6027\uff1b\u524d\u77bb\u6027\u60c5\u611f\u63a8\u7406\u7684\u56f0\u96be\u8868\u660e\u4e3b\u52a8\u60c5\u611f\u611f\u77e5\u652f\u6301\u7cfb\u7edf\u7684\u5f00\u53d1\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002"}}
{"id": "2511.21912", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21912", "abs": "https://arxiv.org/abs/2511.21912", "authors": ["Karin de Langis", "William Walker", "Khanh Chi Le", "Dongyeop Kang"], "title": "Tracing How Annotators Think: Augmenting Preference Judgments with Reading Processes", "comment": null, "summary": "We propose an annotation approach that captures not only labels but also the reading process underlying annotators' decisions, e.g., what parts of the text they focus on, re-read or skim. Using this framework, we conduct a case study on the preference annotation task, creating a dataset PreferRead that contains fine-grained annotator reading behaviors obtained from mouse tracking. PreferRead enables detailed analysis of how annotators navigate between a prompt and two candidate responses before selecting their preference. We find that annotators re-read a response in roughly half of all trials, most often revisiting the option they ultimately choose, and rarely revisit the prompt. Reading behaviors are also significantly related to annotation outcomes: re-reading is associated with higher inter-annotator agreement, whereas long reading paths and times are associated with lower agreement. These results demonstrate that reading processes provide a complementary cognitive dimension for understanding annotator reliability, decision-making and disagreement in complex, subjective NLP tasks. Our code and data are publicly available.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6355\u6349\u6807\u6ce8\u8005\u9605\u8bfb\u8fc7\u7a0b\u7684\u6807\u6ce8\u65b9\u6cd5\uff0c\u901a\u8fc7\u9f20\u6807\u8ffd\u8e2a\u521b\u5efa\u4e86\u5305\u542b\u7ec6\u7c92\u5ea6\u9605\u8bfb\u884c\u4e3a\u7684PreferRead\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u9605\u8bfb\u884c\u4e3a\u4e0e\u6807\u6ce8\u7ed3\u679c\u663e\u8457\u76f8\u5173\u3002", "motivation": "\u73b0\u6709\u6807\u6ce8\u65b9\u6cd5\u53ea\u8bb0\u5f55\u6700\u7ec8\u6807\u7b7e\uff0c\u5ffd\u7565\u4e86\u6807\u6ce8\u8005\u7684\u9605\u8bfb\u8fc7\u7a0b\u548c\u51b3\u7b56\u673a\u5236\u3002\u4e3a\u4e86\u66f4\u6df1\u5165\u5730\u7406\u89e3\u6807\u6ce8\u8005\u7684\u53ef\u9760\u6027\u3001\u51b3\u7b56\u8fc7\u7a0b\u548c\u5206\u6b67\uff0c\u9700\u8981\u6355\u6349\u6807\u6ce8\u8fc7\u7a0b\u4e2d\u7684\u8ba4\u77e5\u7ef4\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6807\u6ce8\u6846\u67b6\uff0c\u4e0d\u4ec5\u8bb0\u5f55\u6807\u7b7e\uff0c\u8fd8\u901a\u8fc7\u9f20\u6807\u8ffd\u8e2a\u6280\u672f\u6355\u6349\u6807\u6ce8\u8005\u7684\u9605\u8bfb\u8fc7\u7a0b\uff08\u5982\u5173\u6ce8\u54ea\u4e9b\u6587\u672c\u90e8\u5206\u3001\u91cd\u8bfb\u6216\u7565\u8bfb\uff09\u3002\u5728\u504f\u597d\u6807\u6ce8\u4efb\u52a1\u4e2d\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u521b\u5efa\u4e86\u5305\u542b\u7ec6\u7c92\u5ea6\u9605\u8bfb\u884c\u4e3a\u7684PreferRead\u6570\u636e\u96c6\u3002", "result": "\u6807\u6ce8\u8005\u5728\u5927\u7ea6\u4e00\u534a\u7684\u8bd5\u9a8c\u4e2d\u4f1a\u91cd\u8bfb\u56de\u7b54\uff0c\u6700\u5e38\u91cd\u8bfb\u6700\u7ec8\u9009\u62e9\u7684\u9009\u9879\uff0c\u5f88\u5c11\u91cd\u8bfb\u63d0\u793a\u3002\u9605\u8bfb\u884c\u4e3a\u4e0e\u6807\u6ce8\u7ed3\u679c\u663e\u8457\u76f8\u5173\uff1a\u91cd\u8bfb\u4e0e\u66f4\u9ad8\u7684\u6807\u6ce8\u8005\u95f4\u4e00\u81f4\u6027\u76f8\u5173\uff0c\u800c\u8f83\u957f\u7684\u9605\u8bfb\u8def\u5f84\u548c\u65f6\u95f4\u4e0e\u8f83\u4f4e\u7684\u4e00\u81f4\u6027\u76f8\u5173\u3002", "conclusion": "\u9605\u8bfb\u8fc7\u7a0b\u4e3a\u7406\u89e3\u590d\u6742\u4e3b\u89c2NLP\u4efb\u52a1\u4e2d\u6807\u6ce8\u8005\u7684\u53ef\u9760\u6027\u3001\u51b3\u7b56\u548c\u5206\u6b67\u63d0\u4f9b\u4e86\u8865\u5145\u7684\u8ba4\u77e5\u7ef4\u5ea6\u3002\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u66f4\u5168\u9762\u5730\u5206\u6790\u6807\u6ce8\u8d28\u91cf\u3002"}}
{"id": "2511.21930", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21930", "abs": "https://arxiv.org/abs/2511.21930", "authors": ["Yuxin Li", "Lorraine Xu", "Meng Fan Wang"], "title": "A Comparative Study of LLM Prompting and Fine-Tuning for Cross-genre Authorship Attribution on Chinese Lyrics", "comment": "8 pages, 6 figures", "summary": "We propose a novel study on authorship attribution for Chinese lyrics, a domain where clean, public datasets are sorely lacking. Our contributions are twofold: (1) we create a new, balanced dataset of Chinese lyrics spanning multiple genres, and (2) we develop and fine-tune a domain-specific model, comparing its performance against zero-shot inference using the DeepSeek LLM.\n  We test two central hypotheses. First, we hypothesize that a fine-tuned model will outperform a zero-shot LLM baseline. Second, we hypothesize that performance is genre-dependent. Our experiments strongly confirm Hypothesis 2: structured genres (e.g. Folklore & Tradition) yield significantly higher attribution accuracy than more abstract genres (e.g. Love & Romance). Hypothesis 1 receives only partial support: fine-tuning improves robustness and generalization in Test1 (real-world data and difficult genres), but offers limited or ambiguous gains in Test2, a smaller, synthetically-augmented set. We show that the design limitations of Test2 (e.g., label imbalance, shallow lexical differences, and narrow genre sampling) can obscure the true effectiveness of fine-tuning.\n  Our work establishes the first benchmark for cross-genre Chinese lyric attribution, highlights the importance of genre-sensitive evaluation, and provides a public dataset and analytical framework for future research. We conclude with recommendations: enlarge and diversify test sets, reduce reliance on token-level data augmentation, balance author representation across genres, and investigate domain-adaptive pretraining as a pathway for improved attribution performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e2d\u6587\u6b4c\u8bcd\u4f5c\u8005\u5f52\u5c5e\u7684\u65b0\u7814\u7a76\uff0c\u521b\u5efa\u4e86\u5e73\u8861\u6570\u636e\u96c6\u5e76\u5f00\u53d1\u4e86\u9886\u57df\u7279\u5b9a\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u6d41\u6d3e\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u5927\u4e8e\u5fae\u8c03\u6548\u679c", "motivation": "\u4e2d\u6587\u6b4c\u8bcd\u4f5c\u8005\u5f52\u5c5e\u9886\u57df\u7f3a\u4e4f\u5e72\u51c0\u3001\u516c\u5f00\u7684\u6570\u636e\u96c6\uff0c\u9700\u8981\u5efa\u7acb\u57fa\u51c6\u7814\u7a76\u6846\u67b6", "method": "\u521b\u5efa\u65b0\u7684\u5e73\u8861\u4e2d\u6587\u6b4c\u8bcd\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u9886\u57df\u7279\u5b9a\u6a21\u578b\u5e76\u8fdb\u884c\u5fae\u8c03\uff0c\u4e0eDeepSeek LLM\u7684\u96f6\u6837\u672c\u63a8\u7406\u8fdb\u884c\u5bf9\u6bd4", "result": "\u5047\u8bbe2\u5f97\u5230\u5f3a\u70c8\u8bc1\u5b9e\uff1a\u7ed3\u6784\u5316\u6d41\u6d3e\uff08\u5982\u6c11\u4fd7\u4f20\u7edf\uff09\u6bd4\u62bd\u8c61\u6d41\u6d3e\uff08\u5982\u7231\u60c5\u6d6a\u6f2b\uff09\u51c6\u786e\u7387\u663e\u8457\u66f4\u9ad8\uff1b\u5047\u8bbe1\u4ec5\u5f97\u5230\u90e8\u5206\u652f\u6301\uff1a\u5fae\u8c03\u5728\u771f\u5b9e\u6570\u636e\u6d4b\u8bd5\u4e2d\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u5408\u6210\u589e\u5f3a\u6d4b\u8bd5\u4e2d\u589e\u76ca\u6709\u9650", "conclusion": "\u5efa\u7acb\u4e86\u9996\u4e2a\u8de8\u6d41\u6d3e\u4e2d\u6587\u6b4c\u8bcd\u4f5c\u8005\u5f52\u5c5e\u57fa\u51c6\uff0c\u5f3a\u8c03\u6d41\u6d3e\u654f\u611f\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u6269\u5927\u6d4b\u8bd5\u96c6\u3001\u51cf\u5c11\u8bcd\u7ea7\u6570\u636e\u589e\u5f3a\u3001\u5e73\u8861\u4f5c\u8005\u4ee3\u8868\u6027\u7b49\u5efa\u8bae"}}
{"id": "2511.21974", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21974", "abs": "https://arxiv.org/abs/2511.21974", "authors": ["Pamela D. Rivi\u00e8re", "Sean Trott"], "title": "Start Making Sense(s): A Developmental Probe of Attention Specialization Using Lexical Ambiguity", "comment": "13 pages (main text), 5 figures (main text) 6 pages (appendix), 6 figures (appendix), journal submission to TACL (\"a\" decision: pre-MIT Press publication version)", "summary": "Despite an in-principle understanding of self-attention matrix operations in Transformer language models (LMs), it remains unclear precisely how these operations map onto interpretable computations or functions--and how or when individual attention heads develop specialized attention patterns. Here, we present a pipeline to systematically probe attention mechanisms, and we illustrate its value by leveraging lexical ambiguity--where a single word has multiple meanings--to isolate attention mechanisms that contribute to word sense disambiguation. We take a \"developmental\" approach: first, using publicly available Pythia LM checkpoints, we identify inflection points in disambiguation performance for each LM in the suite; in 14M and 410M, we identify heads whose attention to disambiguating words covaries with overall disambiguation performance across development. We then stress-test the robustness of these heads to stimulus perturbations: in 14M, we find limited robustness, but in 410M, we identify multiple heads with surprisingly generalizable behavior. Then, in a causal analysis, we find that ablating the target heads demonstrably impairs disambiguation performance, particularly in 14M. We additionally reproduce developmental analyses of 14M across all of its random seeds. Together, these results suggest: that disambiguation benefits from a constellation of mechanisms, some of which (especially in 14M) are highly sensitive to the position and part-of-speech of the disambiguating cue; and that larger models (410M) may contain heads with more robust disambiguation behavior. They also join a growing body of work that highlights the value of adopting a developmental perspective when probing LM mechanisms.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u5957\u7cfb\u7edf\u63a2\u6d4bTransformer\u8bed\u8a00\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u8bcd\u6c47\u6b67\u4e49\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u53d1\u73b0\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u5728\u6d88\u6b67\u673a\u5236\u4e0a\u7684\u5dee\u5f02\uff0c\u5e76\u5f3a\u8c03\u4e86\u4ece\u53d1\u5c55\u89c6\u89d2\u7814\u7a76\u6a21\u578b\u673a\u5236\u7684\u4ef7\u503c\u3002", "motivation": "\u5c3d\u7ba1\u5728\u539f\u7406\u4e0a\u7406\u89e3Transformer\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u81ea\u6ce8\u610f\u529b\u77e9\u9635\u64cd\u4f5c\uff0c\u4f46\u4ecd\u4e0d\u6e05\u695a\u8fd9\u4e9b\u64cd\u4f5c\u5982\u4f55\u6620\u5c04\u5230\u53ef\u89e3\u91ca\u7684\u8ba1\u7b97\u6216\u529f\u80fd\uff0c\u4ee5\u53ca\u4e2a\u4f53\u6ce8\u610f\u529b\u5934\u4f55\u65f6\u5982\u4f55\u53d1\u5c55\u51fa\u4e13\u95e8\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u3002\u9700\u8981\u7cfb\u7edf\u65b9\u6cd5\u6765\u63a2\u6d4b\u6ce8\u610f\u529b\u673a\u5236\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u63a2\u6d4b\u6ce8\u610f\u529b\u673a\u5236\u7684\u6d41\u7a0b\uff1a1) \u5229\u7528Pythia LM\u68c0\u67e5\u70b9\uff0c\u8bc6\u522b\u6d88\u6b67\u6027\u80fd\u7684\u8f6c\u6298\u70b9\uff1b2) \u572814M\u548c410M\u6a21\u578b\u4e2d\u8bc6\u522b\u6ce8\u610f\u529b\u4e0e\u6d88\u6b67\u6027\u80fd\u5171\u53d8\u7684\u6ce8\u610f\u529b\u5934\uff1b3) \u901a\u8fc7\u523a\u6fc0\u6270\u52a8\u6d4b\u8bd5\u8fd9\u4e9b\u5934\u7684\u9c81\u68d2\u6027\uff1b4) \u8fdb\u884c\u56e0\u679c\u5206\u6790\uff0c\u901a\u8fc7\u6d88\u878d\u76ee\u6807\u5934\u6765\u9a8c\u8bc1\u5176\u5bf9\u6d88\u6b67\u7684\u5f71\u54cd\uff1b5) \u572814M\u6a21\u578b\u7684\u6240\u6709\u968f\u673a\u79cd\u5b50\u4e2d\u590d\u73b0\u53d1\u5c55\u5206\u6790\u3002", "result": "1) \u572814M\u548c410M\u6a21\u578b\u4e2d\u8bc6\u522b\u51fa\u6ce8\u610f\u529b\u4e0e\u6d88\u6b67\u6027\u80fd\u5171\u53d8\u7684\u6ce8\u610f\u529b\u5934\uff1b2) 14M\u6a21\u578b\u7684\u6ce8\u610f\u529b\u5934\u5bf9\u523a\u6fc0\u6270\u52a8\u9c81\u68d2\u6027\u6709\u9650\uff0c\u800c410M\u6a21\u578b\u5b58\u5728\u591a\u4e2a\u5177\u6709\u60ca\u4eba\u6cdb\u5316\u80fd\u529b\u7684\u6ce8\u610f\u529b\u5934\uff1b3) \u6d88\u878d\u76ee\u6807\u5934\u4f1a\u635f\u5bb3\u6d88\u6b67\u6027\u80fd\uff0c\u5c24\u5176\u572814M\u6a21\u578b\u4e2d\u66f4\u660e\u663e\uff1b4) \u6d88\u6b67\u53d7\u76ca\u4e8e\u591a\u79cd\u673a\u5236\u7684\u7ec4\u5408\uff0c\u5176\u4e2d\u4e00\u4e9b\uff08\u7279\u522b\u662f14M\u4e2d\uff09\u5bf9\u6d88\u6b67\u7ebf\u7d22\u7684\u4f4d\u7f6e\u548c\u8bcd\u6027\u9ad8\u5ea6\u654f\u611f\uff1b5) \u66f4\u5927\u6a21\u578b\uff08410M\uff09\u53ef\u80fd\u5305\u542b\u66f4\u9c81\u68d2\u7684\u6d88\u6b67\u884c\u4e3a\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u7cfb\u7edf\u63a2\u6d4b\u6ce8\u610f\u529b\u673a\u5236\u7684\u65b9\u6cd5\u4ef7\u503c\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u5728\u6d88\u6b67\u673a\u5236\u4e0a\u7684\u5dee\u5f02\uff0c\u5e76\u5f3a\u8c03\u4e86\u4ece\u53d1\u5c55\u89c6\u89d2\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u673a\u5236\u7684\u91cd\u8981\u6027\u3002\u6d88\u6b67\u4f9d\u8d56\u4e8e\u591a\u79cd\u673a\u5236\u7684\u7ec4\u5408\uff0c\u66f4\u5927\u6a21\u578b\u53ef\u80fd\u53d1\u5c55\u51fa\u66f4\u9c81\u68d2\u7684\u6d88\u6b67\u884c\u4e3a\u3002"}}
{"id": "2511.22016", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.22016", "abs": "https://arxiv.org/abs/2511.22016", "authors": ["Yann Le Beux", "Oluchi Audu", "Oche D. Ankeli", "Dhananjay Balakrishnan", "Melissah Weya", "Marie D. Ralaiarinosy", "Ignatius Ezeani"], "title": "AfriStereo: A Culturally Grounded Dataset for Evaluating Stereotypical Bias in Large Language Models", "comment": null, "summary": "Existing AI bias evaluation benchmarks largely reflect Western perspectives, leaving African contexts underrepresented and enabling harmful stereotypes in applications across various domains. To address this gap, we introduce AfriStereo, the first open-source African stereotype dataset and evaluation framework grounded in local socio-cultural contexts. Through community engaged efforts across Senegal, Kenya, and Nigeria, we collected 1,163 stereotypes spanning gender, ethnicity, religion, age, and profession. Using few-shot prompting with human-in-the-loop validation, we augmented the dataset to over 5,000 stereotype-antistereotype pairs. Entries were validated through semantic clustering and manual annotation by culturally informed reviewers. Preliminary evaluation of language models reveals that nine of eleven models exhibit statistically significant bias, with Bias Preference Ratios (BPR) ranging from 0.63 to 0.78 (p <= 0.05), indicating systematic preferences for stereotypes over antistereotypes, particularly across age, profession, and gender dimensions. Domain-specific models appeared to show weaker bias in our setup, suggesting task-specific training may mitigate some associations. Looking ahead, AfriStereo opens pathways for future research on culturally grounded bias evaluation and mitigation, offering key methodologies for the AI community on building more equitable, context-aware, and globally inclusive NLP technologies.", "AI": {"tldr": "AfriStereo\u662f\u9996\u4e2a\u57fa\u4e8e\u975e\u6d32\u793e\u4f1a\u6587\u5316\u80cc\u666f\u7684\u5f00\u6e90\u975e\u6d32\u523b\u677f\u5370\u8c61\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u586b\u8865\u4e86AI\u504f\u89c1\u8bc4\u4f30\u4e2d\u975e\u6d32\u89c6\u89d2\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709AI\u504f\u89c1\u8bc4\u4f30\u57fa\u51c6\u4e3b\u8981\u53cd\u6620\u897f\u65b9\u89c6\u89d2\uff0c\u5bfc\u81f4\u975e\u6d32\u80cc\u666f\u4ee3\u8868\u6027\u4e0d\u8db3\uff0c\u4f7f\u5f97\u5404\u79cd\u5e94\u7528\u4e2d\u7684\u6709\u5bb3\u523b\u677f\u5370\u8c61\u5f97\u4ee5\u5ef6\u7eed\u3002", "method": "\u901a\u8fc7\u585e\u5185\u52a0\u5c14\u3001\u80af\u5c3c\u4e9a\u548c\u5c3c\u65e5\u5229\u4e9a\u7684\u793e\u533a\u53c2\u4e0e\u6536\u96c61,163\u4e2a\u523b\u677f\u5370\u8c61\uff0c\u4f7f\u7528\u5c11\u6837\u672c\u63d0\u793a\u548c\u4eba\u5de5\u5faa\u73af\u9a8c\u8bc1\u6269\u5c55\u52305,000\u591a\u4e2a\u523b\u677f\u5370\u8c61-\u53cd\u523b\u677f\u5370\u8c61\u5bf9\uff0c\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u548c\u6587\u5316\u77e5\u60c5\u8bc4\u5ba1\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5bf911\u4e2a\u8bed\u8a00\u6a21\u578b\u7684\u521d\u6b65\u8bc4\u4f30\u663e\u793a\uff0c9\u4e2a\u6a21\u578b\u8868\u73b0\u51fa\u7edf\u8ba1\u663e\u8457\u7684\u504f\u89c1\uff0c\u504f\u89c1\u504f\u597d\u6bd4\u7387\u57280.63-0.78\u4e4b\u95f4\uff0c\u5728\u5e74\u9f84\u3001\u804c\u4e1a\u548c\u6027\u522b\u7ef4\u5ea6\u4e0a\u8868\u73b0\u51fa\u5bf9\u523b\u677f\u5370\u8c61\u7684\u7cfb\u7edf\u6027\u504f\u597d\u3002", "conclusion": "AfriStereo\u4e3a\u6587\u5316\u57fa\u7840\u7684\u504f\u89c1\u8bc4\u4f30\u548c\u7f13\u89e3\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u4e3aAI\u793e\u533a\u63d0\u4f9b\u4e86\u6784\u5efa\u66f4\u516c\u5e73\u3001\u60c5\u5883\u611f\u77e5\u548c\u5168\u7403\u5305\u5bb9\u6027NLP\u6280\u672f\u7684\u5173\u952e\u65b9\u6cd5\u3002"}}
{"id": "2511.22036", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.22036", "abs": "https://arxiv.org/abs/2511.22036", "authors": ["Jingjun Xu", "Chongshan Lin", "Haofei Yu", "Tao Feng", "Jiaxuan You"], "title": "ResearchArcade: Graph Interface for Academic Tasks", "comment": null, "summary": "Academic research generates diverse data sources, and as researchers increasingly use machine learning to assist research tasks, a crucial question arises: Can we build a unified data interface to support the development of machine learning models for various academic tasks? Models trained on such a unified interface can better support human researchers throughout the research process, eventually accelerating knowledge discovery. In this work, we introduce ResearchArcade, a graph-based interface that connects multiple academic data sources, unifies task definitions, and supports a wide range of base models to address key academic challenges. ResearchArcade utilizes a coherent multi-table format with graph structures to organize data from different sources, including academic corpora from ArXiv and peer reviews from OpenReview, while capturing information with multiple modalities, such as text, figures, and tables. ResearchArcade also preserves temporal evolution at both the manuscript and community levels, supporting the study of paper revisions as well as broader research trends over time. Additionally, ResearchArcade unifies diverse academic task definitions and supports various models with distinct input requirements. Our experiments across six academic tasks demonstrate that combining cross-source and multi-modal information enables a broader range of tasks, while incorporating graph structures consistently improves performance over baseline methods. This highlights the effectiveness of ResearchArcade and its potential to advance research progress.", "AI": {"tldr": "ResearchArcade\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u7684\u7edf\u4e00\u6570\u636e\u63a5\u53e3\uff0c\u8fde\u63a5\u591a\u4e2a\u5b66\u672f\u6570\u636e\u6e90\uff0c\u652f\u6301\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u7edf\u4e00\u4efb\u52a1\u5b9a\u4e49\uff0c\u7528\u4e8e\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u52a0\u901f\u5b66\u672f\u7814\u7a76\u3002", "motivation": "\u5b66\u672f\u7814\u7a76\u4ea7\u751f\u591a\u6837\u5316\u7684\u6570\u636e\u6e90\uff0c\u7814\u7a76\u4eba\u5458\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u8f85\u52a9\u7814\u7a76\u4efb\u52a1\uff0c\u9700\u8981\u6784\u5efa\u7edf\u4e00\u7684\u6570\u636e\u63a5\u53e3\u6765\u652f\u6301\u5404\u79cd\u5b66\u672f\u4efb\u52a1\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f00\u53d1\uff0c\u4ece\u800c\u52a0\u901f\u77e5\u8bc6\u53d1\u73b0\u3002", "method": "\u63d0\u51faResearchArcade\uff0c\u4e00\u4e2a\u57fa\u4e8e\u56fe\u7684\u63a5\u53e3\uff0c\u4f7f\u7528\u8fde\u8d2f\u7684\u591a\u8868\u683c\u5f0f\u548c\u56fe\u7ed3\u6784\u7ec4\u7ec7\u4e0d\u540c\u6765\u6e90\u7684\u6570\u636e\uff08\u5982ArXiv\u5b66\u672f\u8bed\u6599\u5e93\u548cOpenReview\u540c\u884c\u8bc4\u5ba1\uff09\uff0c\u652f\u6301\u6587\u672c\u3001\u56fe\u8868\u7b49\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u5e76\u4fdd\u7559\u624b\u7a3f\u548c\u793e\u533a\u5c42\u9762\u7684\u65f6\u95f4\u6f14\u5316\u3002", "result": "\u5728\u516d\u4e2a\u5b66\u672f\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u8de8\u6e90\u548c\u591a\u6a21\u6001\u4fe1\u606f\u80fd\u591f\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u4efb\u52a1\u8303\u56f4\uff0c\u800c\u56fe\u7ed3\u6784\u7684\u52a0\u5165\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "ResearchArcade\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff0c\u5e76\u5177\u6709\u63a8\u52a8\u7814\u7a76\u8fdb\u5c55\u7684\u6f5c\u529b\uff0c\u4e3a\u5b66\u672f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6570\u636e\u63a5\u53e3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.22038", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22038", "abs": "https://arxiv.org/abs/2511.22038", "authors": ["Rochana Chaturvedi", "Yue Zhou", "Andrew Boyd", "Brian T. Layden", "Mudassir Rashid", "Lu Cheng", "Ali Cinar", "Barbara Di Eugenio"], "title": "Early Risk Prediction with Temporally and Contextually Grounded Clinical Language Processing", "comment": null, "summary": "Clinical notes in Electronic Health Records (EHRs) capture rich temporal information on events, clinician reasoning, and lifestyle factors often missing from structured data. Leveraging them for predictive modeling can be impactful for timely identification of chronic diseases. However, they present core natural language processing (NLP) challenges: long text, irregular event distribution, complex temporal dependencies, privacy constraints, and resource limitations. We present two complementary methods for temporally and contextually grounded risk prediction from longitudinal notes. First, we introduce HiTGNN, a hierarchical temporal graph neural network that integrates intra-note temporal event structures, inter-visit dynamics, and medical knowledge to model patient trajectories with fine-grained temporal granularity. Second, we propose ReVeAL, a lightweight, test-time framework that distills the reasoning of large language models into smaller verifier models. Applied to opportunistic screening for Type 2 Diabetes (T2D) using temporally realistic cohorts curated from private and public hospital corpora, HiTGNN achieves the highest predictive accuracy, especially for near-term risk, while preserving privacy and limiting reliance on large proprietary models. ReVeAL enhances sensitivity to true T2D cases and retains explanatory reasoning. Our ablations confirm the value of temporal structure and knowledge augmentation, and fairness analysis shows HiTGNN performs more equitably across subgroups.", "AI": {"tldr": "\u63d0\u51fa\u4e86HiTGNN\u548cReVeAL\u4e24\u79cd\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u7eb5\u5411\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u9884\u6d4b2\u578b\u7cd6\u5c3f\u75c5\u98ce\u9669\uff0cHiTGNN\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u800cReVeAL\u63d0\u9ad8\u4e86\u5bf9\u771f\u5b9e\u75c5\u4f8b\u7684\u654f\u611f\u6027\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7684\u4e34\u5e8a\u7b14\u8bb0\u5305\u542b\u4e30\u5bcc\u7684\u65f6\u5e8f\u4fe1\u606f\uff0c\u53ef\u7528\u4e8e\u6162\u6027\u75be\u75c5\u7684\u65e9\u671f\u8bc6\u522b\uff0c\u4f46\u8fd9\u4e9b\u7b14\u8bb0\u5b58\u5728\u957f\u6587\u672c\u3001\u4e0d\u89c4\u5219\u4e8b\u4ef6\u5206\u5e03\u3001\u590d\u6742\u65f6\u5e8f\u4f9d\u8d56\u3001\u9690\u79c1\u7ea6\u675f\u548c\u8d44\u6e90\u9650\u5236\u7b49NLP\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a1) HiTGNN\uff1a\u5206\u5c42\u65f6\u5e8f\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u6574\u5408\u7b14\u8bb0\u5185\u4e8b\u4ef6\u7ed3\u6784\u3001\u5c31\u8bca\u95f4\u52a8\u6001\u548c\u533b\u5b66\u77e5\u8bc6\uff1b2) ReVeAL\uff1a\u8f7b\u91cf\u7ea7\u6d4b\u8bd5\u65f6\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\u5230\u8f83\u5c0f\u7684\u9a8c\u8bc1\u5668\u6a21\u578b\u4e2d\u3002", "result": "\u57282\u578b\u7cd6\u5c3f\u75c5\u673a\u4f1a\u6027\u7b5b\u67e5\u4efb\u52a1\u4e2d\uff0cHiTGNN\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff08\u7279\u522b\u662f\u8fd1\u671f\u98ce\u9669\uff09\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u5e76\u51cf\u5c11\u5bf9\u5927\u6a21\u578b\u7684\u4f9d\u8d56\uff1bReVeAL\u63d0\u9ad8\u4e86\u5bf9\u771f\u5b9e\u75c5\u4f8b\u7684\u654f\u611f\u6027\u5e76\u4fdd\u7559\u89e3\u91ca\u6027\u63a8\u7406\u3002", "conclusion": "\u4e24\u79cd\u65b9\u6cd5\u5728\u4ece\u7eb5\u5411\u4e34\u5e8a\u7b14\u8bb0\u8fdb\u884c\u98ce\u9669\u9884\u6d4b\u65b9\u9762\u5177\u6709\u4e92\u8865\u4f18\u52bf\uff0c\u65f6\u5e8f\u7ed3\u6784\u548c\u77e5\u8bc6\u589e\u5f3a\u5bf9\u6027\u80fd\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4e14HiTGNN\u5728\u4e0d\u540c\u4e9a\u7ec4\u4e2d\u8868\u73b0\u66f4\u516c\u5e73\u3002"}}
{"id": "2511.22109", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22109", "abs": "https://arxiv.org/abs/2511.22109", "authors": ["Gia Bao Hoang", "Keith J Ransom", "Rachel Stephens", "Carolyn Semmler", "Nicolas Fay", "Lewis Mitchell"], "title": "A Hybrid Theory and Data-driven Approach to Persuasion Detection with Large Language Models", "comment": null, "summary": "Traditional psychological models of belief revision focus on face-to-face interactions, but with the rise of social media, more effective models are needed to capture belief revision at scale, in this rich text-based online discourse. Here, we use a hybrid approach, utilizing large language models (LLMs) to develop a model that predicts successful persuasion using features derived from psychological experiments.\n  Our approach leverages LLM generated ratings of features previously examined in the literature to build a random forest classification model that predicts whether a message will result in belief change. Of the eight features tested, \\textit{epistemic emotion} and \\textit{willingness to share} were the top-ranking predictors of belief change in the model. Our findings provide insights into the characteristics of persuasive messages and demonstrate how LLMs can enhance models of successful persuasion based on psychological theory. Given these insights, this work has broader applications in fields such as online influence detection and misinformation mitigation, as well as measuring the effectiveness of online narratives.", "AI": {"tldr": "\u4f7f\u7528LLM\u63d0\u53d6\u5fc3\u7406\u5b66\u7279\u5f81\u6765\u9884\u6d4b\u793e\u4ea4\u5a92\u4f53\u4e0a\u6d88\u606f\u80fd\u5426\u6210\u529f\u6539\u53d8\u4ed6\u4eba\u4fe1\u5ff5\uff0c\u53d1\u73b0\u8ba4\u77e5\u60c5\u7eea\u548c\u5206\u4eab\u610f\u613f\u662f\u6700\u91cd\u8981\u7684\u9884\u6d4b\u56e0\u7d20\u3002", "motivation": "\u4f20\u7edf\u5fc3\u7406\u5b66\u4fe1\u5ff5\u4fee\u6b63\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u9762\u5bf9\u9762\u4e92\u52a8\uff0c\u4f46\u968f\u7740\u793e\u4ea4\u5a92\u4f53\u7684\u5174\u8d77\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u6a21\u578b\u6765\u6355\u6349\u5927\u89c4\u6a21\u3001\u57fa\u4e8e\u6587\u672c\u7684\u5728\u7ebf\u8ba8\u8bba\u4e2d\u7684\u4fe1\u5ff5\u4fee\u6b63\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u5fc3\u7406\u5b66\u6587\u732e\u4e2d\u5148\u524d\u7814\u7a76\u7684\u7279\u5f81\u8bc4\u5206\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u7279\u5f81\u6784\u5efa\u968f\u673a\u68ee\u6797\u5206\u7c7b\u6a21\u578b\u6765\u9884\u6d4b\u6d88\u606f\u662f\u5426\u4f1a\u5bfc\u81f4\u4fe1\u5ff5\u6539\u53d8\u3002", "result": "\u5728\u6d4b\u8bd5\u7684\u516b\u4e2a\u7279\u5f81\u4e2d\uff0c\u8ba4\u77e5\u60c5\u7eea\uff08epistemic emotion\uff09\u548c\u5206\u4eab\u610f\u613f\uff08willingness to share\uff09\u662f\u9884\u6d4b\u4fe1\u5ff5\u6539\u53d8\u7684\u6700\u91cd\u8981\u7279\u5f81\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u8bf4\u670d\u6027\u6d88\u606f\u7684\u7279\u5f81\uff0c\u5c55\u793a\u4e86LLMs\u5982\u4f55\u589e\u5f3a\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\u7684\u6210\u529f\u8bf4\u670d\u6a21\u578b\uff0c\u8fd9\u9879\u5de5\u4f5c\u5728\u5728\u7ebf\u5f71\u54cd\u529b\u68c0\u6d4b\u3001\u9519\u8bef\u4fe1\u606f\u7f13\u89e3\u4ee5\u53ca\u5728\u7ebf\u53d9\u4e8b\u6548\u679c\u6d4b\u91cf\u7b49\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.22141", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22141", "abs": "https://arxiv.org/abs/2511.22141", "authors": ["Shuhei Yamashita", "Daiki Shirafuji", "Tatsuhiko Saito"], "title": "Bridging the Modality Gap by Similarity Standardization with Pseudo-Positive Samples", "comment": "Accepted to PACLIC2025", "summary": "Advances in vision-language models (VLMs) have enabled effective cross-modality retrieval. However, when both text and images exist in the database, similarity scores would differ in scale by modality. This phenomenon, known as the modality gap, hinders accurate retrieval. Most existing studies address this issue with manually labeled data, e.g., by fine-tuning VLMs on them. In this work, we propose a similarity standardization approach with pseudo data construction. We first compute the mean and variance of the similarity scores between each query and its paired data in text or image modality. Using these modality-specific statistics, we standardize all similarity scores to compare on a common scale across modalities. These statistics are calculated from pseudo pairs, which are constructed by retrieving the text and image candidates with the highest cosine similarity to each query. We evaluate our method across seven VLMs using two multi-modal QA benchmarks (MMQA and WebQA), where each question requires retrieving either text or image data. Our experimental results show that our method significantly improves retrieval performance, achieving average Recall@20 gains of 64% on MMQA and 28% on WebQA when the query and the target data belong to different modalities. Compared to E5-V, which addresses the modality gap through image captioning, we confirm that our method more effectively bridges the modality gap.", "AI": {"tldr": "\u63d0\u51fa\u76f8\u4f3c\u6027\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f2a\u6570\u636e\u6784\u5efa\u89e3\u51b3\u8de8\u6a21\u6001\u68c0\u7d22\u4e2d\u7684\u6a21\u6001\u5dee\u8ddd\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u95ee\u7b54\u57fa\u51c6\u4e0a\u7684\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u5f53\u6570\u636e\u5e93\u540c\u65f6\u5305\u542b\u6587\u672c\u548c\u56fe\u50cf\u65f6\uff0c\u76f8\u4f3c\u6027\u5206\u6570\u5728\u4e0d\u540c\u6a21\u6001\u95f4\u5b58\u5728\u5c3a\u5ea6\u5dee\u5f02\uff08\u6a21\u6001\u5dee\u8ddd\uff09\uff0c\u8fd9\u963b\u788d\u4e86\u51c6\u786e\u7684\u8de8\u6a21\u6001\u68c0\u7d22\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u5fae\u8c03\uff0c\u6210\u672c\u8f83\u9ad8\u3002", "method": "\u63d0\u51fa\u76f8\u4f3c\u6027\u6807\u51c6\u5316\u65b9\u6cd5\uff1a1) \u8ba1\u7b97\u67e5\u8be2\u4e0e\u5176\u914d\u5bf9\u6570\u636e\u5728\u6587\u672c\u6216\u56fe\u50cf\u6a21\u6001\u4e0a\u7684\u76f8\u4f3c\u6027\u5206\u6570\u7684\u5747\u503c\u548c\u65b9\u5dee\uff1b2) \u4f7f\u7528\u8fd9\u4e9b\u6a21\u6001\u7279\u5b9a\u7edf\u8ba1\u91cf\u5c06\u6240\u6709\u76f8\u4f3c\u6027\u5206\u6570\u6807\u51c6\u5316\u5230\u8de8\u6a21\u6001\u53ef\u6bd4\u8f83\u7684\u5171\u540c\u5c3a\u5ea6\uff1b3) \u901a\u8fc7\u68c0\u7d22\u4e0e\u6bcf\u4e2a\u67e5\u8be2\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u6587\u672c\u548c\u56fe\u50cf\u5019\u9009\u6765\u6784\u5efa\u4f2a\u5bf9\uff0c\u7528\u4e8e\u8ba1\u7b97\u7edf\u8ba1\u91cf\u3002", "result": "\u57287\u4e2aVLM\u548c\u4e24\u4e2a\u591a\u6a21\u6001QA\u57fa\u51c6\uff08MMQA\u548cWebQA\uff09\u4e0a\u8bc4\u4f30\uff0c\u5f53\u67e5\u8be2\u548c\u76ee\u6807\u6570\u636e\u5c5e\u4e8e\u4e0d\u540c\u6a21\u6001\u65f6\uff0c\u5728MMQA\u4e0a\u5e73\u5747Recall@20\u63d0\u534764%\uff0c\u5728WebQA\u4e0a\u63d0\u534728%\u3002\u4e0e\u901a\u8fc7\u56fe\u50cf\u63cf\u8ff0\u89e3\u51b3\u6a21\u6001\u5dee\u8ddd\u7684E5-V\u76f8\u6bd4\uff0c\u672c\u65b9\u6cd5\u66f4\u6709\u6548\u5730\u5f25\u5408\u4e86\u6a21\u6001\u5dee\u8ddd\u3002", "conclusion": "\u63d0\u51fa\u7684\u76f8\u4f3c\u6027\u6807\u51c6\u5316\u65b9\u6cd5\u901a\u8fc7\u4f2a\u6570\u636e\u6784\u5efa\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u6a21\u6001\u68c0\u7d22\u4e2d\u7684\u6a21\u6001\u5dee\u8ddd\u95ee\u9898\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u5373\u53ef\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6027\u80fd\uff0c\u4e3a\u591a\u6a21\u6001\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.22146", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22146", "abs": "https://arxiv.org/abs/2511.22146", "authors": ["Kairong Han", "Nuanqiao Shan", "Ziyu Zhao", "Zijing Hu", "Xinpeng Dong", "Junjian Ye", "Lujia Pan", "Fei Wu", "Kun Kuang"], "title": "C$^2$DLM: Causal Concept-Guided Diffusion Large Language Models", "comment": null, "summary": "Autoregressive (AR) language models and Diffusion Language Models (DLMs) constitute the two principal paradigms of large language models. However, both paradigms suffer from insufficient reasoning capabilities. Human reasoning inherently relies on causal knowledge and thought, which are reflected in natural language. But in the AR paradigm, language is modeled as next token prediction (a strictly left-to-right, token-by-token order), whereas natural language itself exhibits more flexible causal structures. In the DLM paradigm, the attention mechanism is fully connected, which entirely disregards causal order. To fill this gap, we propose a \\underline{\\textbf{C}}ausal \\underline{\\textbf{C}}oncept-Guided \\underline{\\textbf{D}}iffusion \\underline{\\textbf{L}}anguage \\underline{\\textbf{M}}odel (C$^2$DLM). Starting from DLM's fully connected attention, C$^2$DLM first obtains a concept-level causal graph from the teacher model, and then explicitly guides attention to learn causal relationships between concepts. By focusing on causal relationships and avoiding interference from difficult subgoals involving causal inversion, C$^2$DLM improves 12\\% with about 3.2 times training speedup in the COT-OrderPerturb task, and achieves an average gain of 1.31\\% across six downstream reasoning tasks. More details in the repository ~\\href{https://github.com/Kairong-Han/C-2-DLM}{here}.", "AI": {"tldr": "C\u00b2DLM\uff1a\u4e00\u79cd\u56e0\u679c\u6982\u5ff5\u5f15\u5bfc\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4ece\u6559\u5e08\u6a21\u578b\u83b7\u53d6\u6982\u5ff5\u7ea7\u56e0\u679c\u56fe\uff0c\u663e\u5f0f\u5f15\u5bfc\u6ce8\u610f\u529b\u5b66\u4e60\u6982\u5ff5\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b\u5e76\u52a0\u901f\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u548c\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u4e0d\u8db3\u3002\u4eba\u7c7b\u63a8\u7406\u4f9d\u8d56\u4e8e\u56e0\u679c\u77e5\u8bc6\u548c\u601d\u7ef4\uff0c\u4f46\u81ea\u56de\u5f52\u6a21\u578b\u91c7\u7528\u4e25\u683c\u7684\u5de6\u5230\u53f3token\u9884\u6d4b\uff0c\u800c\u6269\u6563\u6a21\u578b\u7684\u6ce8\u610f\u529b\u673a\u5236\u5b8c\u5168\u8fde\u63a5\uff0c\u90fd\u5ffd\u7565\u4e86\u81ea\u7136\u8bed\u8a00\u4e2d\u66f4\u7075\u6d3b\u7684\u56e0\u679c\u7ed3\u6784\u3002", "method": "\u4ece\u6269\u6563\u6a21\u578b\u7684\u5b8c\u5168\u8fde\u63a5\u6ce8\u610f\u529b\u51fa\u53d1\uff0c\u9996\u5148\u4ece\u6559\u5e08\u6a21\u578b\u83b7\u53d6\u6982\u5ff5\u7ea7\u56e0\u679c\u56fe\uff0c\u7136\u540e\u663e\u5f0f\u5f15\u5bfc\u6ce8\u610f\u529b\u5b66\u4e60\u6982\u5ff5\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002\u901a\u8fc7\u5173\u6ce8\u56e0\u679c\u5173\u7cfb\u5e76\u907f\u514d\u56e0\u679c\u53cd\u8f6c\u5e26\u6765\u7684\u56f0\u96be\u5b50\u76ee\u6807\u5e72\u6270\u3002", "result": "\u5728COT-OrderPerturb\u4efb\u52a1\u4e2d\u63d0\u534712%\uff0c\u8bad\u7ec3\u901f\u5ea6\u52a0\u5feb\u7ea63.2\u500d\uff1b\u5728\u516d\u4e2a\u4e0b\u6e38\u63a8\u7406\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u53471.31%\u3002", "conclusion": "C\u00b2DLM\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u6982\u5ff5\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u52a0\u901f\u4e86\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4e3a\u6539\u8fdb\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.22153", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22153", "abs": "https://arxiv.org/abs/2511.22153", "authors": ["Sepyan Purnama Kristanto", "Lutfi Hakim"], "title": "A Theoretically Grounded Hybrid Ensemble for Reliable Detection of LLM-Generated Text", "comment": "24 pages", "summary": "The rapid proliferation of Large Language Models (LLMs) has blurred the line between human and machine authorship, creating practical risks for academic integrity and information reliability. Existing text detectors typically rely on a single methodological paradigm and suffer from poor generalization and high false positive rates (FPR), especially on high-stakes academic text. We propose a theoretically grounded hybrid ensemble that systematically fuses three complementary detection paradigms: (i) a RoBERTa-based transformer classifier for deep semantic feature extraction, (ii) a GPT-2-based probabilistic detector using perturbation-induced likelihood curvature, and (iii) a statistical linguistic feature analyzer capturing stylometric patterns. The core novelty lies in an optimized weighted voting framework, where ensemble weights are learned on the probability simplex to maximize F1-score rather than set heuristically. We provide a bias-variance analysis and empirically demonstrate low inter-model correlation (rho ~ 0.35-0.42), a key condition for variance reduction. Evaluated on a large-scale, multigenerator corpus of 30,000 documents, our system achieves 94.2% accuracy and an AUC of 0.978, with a 35% relative reduction in false positives on academic text. This yields a more reliable and ethically responsible detector for real-world deployment in education and other high-stakes domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7406\u8bba\u57fa\u7840\u7684\u6df7\u5408\u96c6\u6210\u65b9\u6cd5\uff0c\u878d\u5408\u4e09\u79cd\u4e92\u8865\u7684\u68c0\u6d4b\u8303\u5f0f\uff0c\u901a\u8fc7\u4f18\u5316\u7684\u52a0\u6743\u6295\u7968\u6846\u67b6\u663e\u8457\u63d0\u5347AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u964d\u4f4e\u8bef\u62a5\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u6269\u6563\u6a21\u7cca\u4e86\u4eba\u7c7b\u548c\u673a\u5668\u4f5c\u8005\u8eab\u4efd\u7684\u754c\u9650\uff0c\u5bf9\u5b66\u672f\u8bda\u4fe1\u548c\u4fe1\u606f\u53ef\u9760\u6027\u6784\u6210\u5b9e\u9645\u98ce\u9669\u3002\u73b0\u6709\u6587\u672c\u68c0\u6d4b\u5668\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u65b9\u6cd5\u8303\u5f0f\uff0c\u6cdb\u5316\u80fd\u529b\u5dee\u4e14\u8bef\u62a5\u7387\u9ad8\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u5b66\u672f\u6587\u672c\u4e0a\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u57fa\u7840\u7684\u6df7\u5408\u96c6\u6210\u65b9\u6cd5\uff0c\u7cfb\u7edf\u878d\u5408\u4e09\u79cd\u4e92\u8865\u68c0\u6d4b\u8303\u5f0f\uff1a1)\u57fa\u4e8eRoBERTa\u7684transformer\u5206\u7c7b\u5668\u7528\u4e8e\u6df1\u5ea6\u8bed\u4e49\u7279\u5f81\u63d0\u53d6\uff1b2)\u57fa\u4e8eGPT-2\u7684\u6982\u7387\u68c0\u6d4b\u5668\u4f7f\u7528\u6270\u52a8\u8bf1\u5bfc\u4f3c\u7136\u66f2\u7387\uff1b3)\u7edf\u8ba1\u8bed\u8a00\u5b66\u7279\u5f81\u5206\u6790\u5668\u6355\u6349\u6587\u4f53\u8ba1\u91cf\u6a21\u5f0f\u3002\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u4f18\u5316\u7684\u52a0\u6743\u6295\u7968\u6846\u67b6\uff0c\u5728\u6982\u7387\u5355\u7eaf\u5f62\u4e0a\u5b66\u4e60\u96c6\u6210\u6743\u91cd\u4ee5\u6700\u5927\u5316F1\u5206\u6570\u800c\u975e\u542f\u53d1\u5f0f\u8bbe\u7f6e\u3002", "result": "\u572830,000\u4efd\u6587\u6863\u7684\u5927\u89c4\u6a21\u591a\u751f\u6210\u5668\u8bed\u6599\u5e93\u4e0a\u8bc4\u4f30\uff0c\u7cfb\u7edf\u8fbe\u523094.2%\u7684\u51c6\u786e\u7387\u548c0.978\u7684AUC\uff0c\u5728\u5b66\u672f\u6587\u672c\u4e0a\u8bef\u62a5\u7387\u76f8\u5bf9\u964d\u4f4e35%\u3002\u63d0\u4f9b\u504f\u5dee-\u65b9\u5dee\u5206\u6790\uff0c\u7ecf\u9a8c\u8bc1\u660e\u4f4e\u6a21\u578b\u95f4\u76f8\u5173\u6027(rho ~ 0.35-0.42)\uff0c\u8fd9\u662f\u65b9\u5dee\u51cf\u5c11\u7684\u5173\u952e\u6761\u4ef6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6559\u80b2\u548c\u5176\u5b83\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u9053\u5fb7\u8d1f\u8d23\u4efb\u7684\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u7406\u8bba\u57fa\u7840\u7684\u6df7\u5408\u96c6\u6210\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.22155", "categories": ["cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.22155", "abs": "https://arxiv.org/abs/2511.22155", "authors": ["Bernd J. Kr\u00f6ger"], "title": "Lips-Jaw and Tongue-Jaw Articulatory Tradeoff in DYNARTmo", "comment": "12 pages, 3 figures, supplementary material: python code", "summary": "This paper investigates how the dynamic articulatory model DYNARTmo accounts for articulatory tradeoffs between primary and secondary articulators, with a focus on lips-jaw and tongue-jaw coordination. While DYNARTmo does not implement full task-dynamic second-order biomechanics, it adopts first-order task-space gesture specifications comparable to those used in articulatory phonology and integrates a simplified mechanism for distributing articulatory effort across multiple articulators. We first outline the conceptual relationship between task dynamics and DYNARTmo, emphasizing the distinction between high-level task-space trajectories and their low-level articulatory execution. We then present simulation results for a set of CV syllables that illustrate how jaw displacement varies as a function of both place of articulation (labial, apical, dorsal) and vowel context (/a/, /i/, /u/). The model reproduces empirically attested patterns of articulatory synergy, including jaw-supported apical closures, lower-lip elevation in bilabial stops, tongue-jaw co-movement, and saturation effects in labial constrictions. These results demonstrate that even with computationally simplified assumptions, DYNARTmo can generate realistic spatio-temporal movement patterns that capture key aspects of articulatory tradeoff and synergy across a range of consonant-vowel combinations.", "AI": {"tldr": "DYNARTmo\u6a21\u578b\u7814\u7a76\u53d1\u97f3\u5668\u5b98\u95f4\u7684\u534f\u8c03\u4e0e\u6743\u8861\uff0c\u7279\u522b\u662f\u5507-\u988c\u548c\u820c-\u988c\u534f\u8c03\uff0c\u901a\u8fc7\u7b80\u5316\u673a\u5236\u6a21\u62df\u53d1\u97f3\u52aa\u529b\u5728\u591a\u5668\u5b98\u95f4\u7684\u5206\u914d\uff0c\u80fd\u751f\u6210\u7b26\u5408\u5b9e\u8bc1\u7684\u53d1\u97f3\u534f\u540c\u6a21\u5f0f\u3002", "motivation": "\u7814\u7a76DYNARTmo\u52a8\u6001\u53d1\u97f3\u6a21\u578b\u5982\u4f55\u89e3\u91ca\u4e3b\u8981\u548c\u6b21\u8981\u53d1\u97f3\u5668\u5b98\u4e4b\u95f4\u7684\u53d1\u97f3\u6743\u8861\uff0c\u7279\u522b\u662f\u5507-\u988c\u548c\u820c-\u988c\u534f\u8c03\uff0c\u63a2\u7d22\u7b80\u5316\u6a21\u578b\u662f\u5426\u80fd\u6355\u6349\u771f\u5b9e\u53d1\u97f3\u534f\u540c\u6a21\u5f0f\u3002", "method": "\u91c7\u7528DYNARTmo\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u91c7\u7528\u4e00\u9636\u4efb\u52a1\u7a7a\u95f4\u624b\u52bf\u89c4\u8303\uff0c\u6574\u5408\u4e86\u7b80\u5316\u673a\u5236\u6765\u5206\u914d\u591a\u4e2a\u53d1\u97f3\u5668\u5b98\u95f4\u7684\u53d1\u97f3\u52aa\u529b\u3002\u901a\u8fc7\u6a21\u62dfCV\u97f3\u8282\uff08\u4e0d\u540c\u53d1\u97f3\u90e8\u4f4d\u548c\u5143\u97f3\u73af\u5883\uff09\u6765\u7814\u7a76\u988c\u4f4d\u79fb\u53d8\u5316\u3002", "result": "\u6a21\u578b\u6210\u529f\u590d\u73b0\u4e86\u5b9e\u8bc1\u89c2\u5bdf\u5230\u7684\u53d1\u97f3\u534f\u540c\u6a21\u5f0f\uff1a\u988c\u652f\u6301\u6027\u820c\u5c16\u95ed\u5408\u3001\u53cc\u5507\u585e\u97f3\u4e2d\u7684\u4e0b\u5507\u63d0\u5347\u3001\u820c-\u988c\u534f\u540c\u8fd0\u52a8\uff0c\u4ee5\u53ca\u5507\u90e8\u6536\u7d27\u4e2d\u7684\u9971\u548c\u6548\u5e94\u3002\u6a21\u578b\u80fd\u751f\u6210\u7b26\u5408\u5b9e\u8bc1\u7684\u7a7a\u95f4-\u65f6\u95f4\u8fd0\u52a8\u6a21\u5f0f\u3002", "conclusion": "\u5373\u4f7f\u91c7\u7528\u8ba1\u7b97\u7b80\u5316\u7684\u5047\u8bbe\uff0cDYNARTmo\u6a21\u578b\u4e5f\u80fd\u751f\u6210\u771f\u5b9e\u7684\u65f6\u7a7a\u8fd0\u52a8\u6a21\u5f0f\uff0c\u6355\u6349\u5230\u8de8\u591a\u79cd\u8f85\u97f3-\u5143\u97f3\u7ec4\u5408\u7684\u53d1\u97f3\u6743\u8861\u548c\u534f\u540c\u7684\u5173\u952e\u65b9\u9762\u3002"}}
{"id": "2511.22173", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22173", "abs": "https://arxiv.org/abs/2511.22173", "authors": ["Young-Jun Lee", "Seungone Kim", "Byung-Kwan Lee", "Minkyeong Moon", "Yechan Hwang", "Jong Myoung Kim", "Graham Neubig", "Sean Welleck", "Ho-Jin Choi"], "title": "RefineBench: Evaluating Refinement Capability of Language Models via Checklists", "comment": "Project website: https://passing2961.github.io/refinebench-page/", "summary": "Can language models (LMs) self-refine their own responses? This question is increasingly relevant as a wide range of real-world user interactions involve refinement requests. However, prior studies have largely tested LMs' refinement abilities on verifiable tasks such as competition math or symbolic reasoning with simplified scaffolds, whereas users often pose open-ended queries and provide varying degrees of feedback on what they desire. The recent advent of reasoning models that exhibit self-reflection patterns in their chains-of-thought further motivates this question. To analyze this, we introduce RefineBench, a benchmark of 1,000 challenging problems across 11 domains paired with a checklist-based evaluation framework. We evaluate two refinement modes: (1) guided refinement, where an LM is provided natural language feedback, and (2) self-refinement, where LMs attempt to improve without guidance. In the self-refinement setting, even frontier LMs such as Gemini 2.5 Pro and GPT-5 achieve modest baseline scores of 31.3% and 29.1%, respectively, and most models fail to consistently improve across iterations (e.g., Gemini-2.5-Pro gains only +1.8%, while DeepSeek-R1 declines by -0.1%). By contrast, in guided refinement, both proprietary LMs and large open-weight LMs (>70B) can leverage targeted feedback to refine responses to near-perfect levels within five turns. These findings suggest that frontier LMs require breakthroughs to self-refine their incorrect responses, and that RefineBench provides a valuable testbed for tracking progress.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5728\u5f15\u5bfc\u5f0f\u53cd\u9988\u4e0b\u80fd\u6709\u6548\u6539\u8fdb\u54cd\u5e94\uff0c\u4f46\u5728\u81ea\u6211\u7cbe\u70bc\u65b9\u9762\u8868\u73b0\u6709\u9650\uff0c\u9700\u8981\u7a81\u7834\u6027\u8fdb\u5c55\u3002", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u81ea\u6211\u7cbe\u70bc\u5176\u54cd\u5e94\uff0c\u56e0\u4e3a\u73b0\u5b9e\u4e16\u754c\u7528\u6237\u4ea4\u4e92\u5e38\u6d89\u53ca\u7cbe\u70bc\u8bf7\u6c42\uff0c\u800c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u53ef\u9a8c\u8bc1\u4efb\u52a1\u800c\u975e\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165RefineBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b11\u4e2a\u9886\u57df\u76841000\u4e2a\u6311\u6218\u6027\u95ee\u9898\uff0c\u91c7\u7528\u57fa\u4e8e\u68c0\u67e5\u8868\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc4\u4f30\u5f15\u5bfc\u5f0f\u7cbe\u70bc\uff08\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u53cd\u9988\uff09\u548c\u81ea\u6211\u7cbe\u70bc\uff08\u65e0\u6307\u5bfc\u6539\u8fdb\uff09\u4e24\u79cd\u6a21\u5f0f\u3002", "result": "\u5728\u81ea\u6211\u7cbe\u70bc\u8bbe\u7f6e\u4e2d\uff0c\u524d\u6cbf\u6a21\u578b\u8868\u73b0\u6709\u9650\uff08Gemini 2.5 Pro 31.3%\uff0cGPT-5 29.1%\uff09\uff0c\u4e14\u591a\u6570\u6a21\u578b\u65e0\u6cd5\u6301\u7eed\u6539\u8fdb\uff1b\u4f46\u5728\u5f15\u5bfc\u5f0f\u7cbe\u70bc\u4e2d\uff0c\u5927\u578b\u6a21\u578b\u80fd\u5229\u7528\u9488\u5bf9\u6027\u53cd\u9988\u5728\u4e94\u8f6e\u5185\u8fbe\u5230\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u6c34\u5e73\u3002", "conclusion": "\u524d\u6cbf\u8bed\u8a00\u6a21\u578b\u9700\u8981\u7a81\u7834\u6027\u8fdb\u5c55\u624d\u80fd\u81ea\u6211\u7cbe\u70bc\u9519\u8bef\u54cd\u5e94\uff0cRefineBench\u4e3a\u8ffd\u8e2a\u8fdb\u5c55\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2511.22176", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22176", "abs": "https://arxiv.org/abs/2511.22176", "authors": ["Lukas Struppek", "Dominik Hintersdorf", "Hannah Struppek", "Daniel Neider", "Kristian Kersting"], "title": "Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information", "comment": null, "summary": "Recent large language models achieve strong reasoning performance by generating detailed chain-of-thought traces, but this often leads to excessive token use and high inference latency. Existing efficiency approaches typically focus on model-centric interventions, such as reinforcement learning or supervised fine-tuning, to reduce verbosity. In contrast, we propose a training-free, input-centric approach. Inspired by cognitive psychology, we introduce Focused Chain-of-Thought (F-CoT), which separates information extraction from the reasoning process. F-CoT first organizes the essential information from a query into a concise, structured context and then guides the model to reason exclusively over this context. By preventing attention to irrelevant details, F-CoT naturally produces shorter reasoning paths. On arithmetic word problems, F-CoT reduces generated tokens by 2-3x while maintaining accuracy comparable to standard zero-shot CoT. These results highlight structured input as a simple yet effective lever for more efficient LLM reasoning.", "AI": {"tldr": "F-CoT\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u8f93\u5165\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4fe1\u606f\u63d0\u53d6\u4e0e\u63a8\u7406\u8fc7\u7a0b\u5206\u79bb\uff0c\u5c06\u67e5\u8be2\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u7ec4\u7ec7\u6210\u7b80\u6d01\u7684\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\uff0c\u4ece\u800c\u51cf\u5c11\u63a8\u7406\u8def\u5f84\u957f\u5ea6\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5c06\u751f\u6210token\u51cf\u5c112-3\u500d\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u751f\u6210\u8be6\u7ec6\u7684\u601d\u7ef4\u94fe\u5b9e\u73b0\u5f3a\u5927\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8fd9\u5bfc\u81f4\u8fc7\u591a\u7684token\u4f7f\u7528\u548c\u8f83\u9ad8\u7684\u63a8\u7406\u5ef6\u8fdf\u3002\u73b0\u6709\u6548\u7387\u65b9\u6cd5\u901a\u5e38\u5173\u6ce8\u6a21\u578b\u4e2d\u5fc3\u5e72\u9884\uff08\u5982\u5f3a\u5316\u5b66\u4e60\u6216\u76d1\u7763\u5fae\u8c03\uff09\u6765\u51cf\u5c11\u5197\u4f59\uff0c\u4f46\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u66f4\u7b80\u5355\u7684\u65b9\u6cd5\u3002", "method": "\u53d7\u8ba4\u77e5\u5fc3\u7406\u5b66\u542f\u53d1\uff0c\u63d0\u51faFocused Chain-of-Thought (F-CoT)\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u8f93\u5165\u4e2d\u5fc3\u7684\u65b9\u6cd5\u3002\u9996\u5148\u5c06\u67e5\u8be2\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u63d0\u53d6\u5e76\u7ec4\u7ec7\u6210\u7b80\u6d01\u7684\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\uff0c\u7136\u540e\u5f15\u5bfc\u6a21\u578b\u4ec5\u5728\u6b64\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u63a8\u7406\uff0c\u907f\u514d\u5173\u6ce8\u65e0\u5173\u7ec6\u8282\u3002", "result": "\u5728\u7b97\u672f\u6587\u5b57\u95ee\u9898\u4e0a\uff0cF-CoT\u5c06\u751f\u6210\u7684token\u51cf\u5c112-3\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002\u8fd9\u8bc1\u660e\u4e86\u7ed3\u6784\u5316\u8f93\u5165\u4f5c\u4e3a\u63d0\u9ad8LLM\u63a8\u7406\u6548\u7387\u7684\u7b80\u5355\u800c\u6709\u6548\u7684\u6760\u6746\u3002", "conclusion": "\u7ed3\u6784\u5316\u8f93\u5165\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u673a\u5236\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\uff0c\u65e0\u9700\u590d\u6742\u7684\u6a21\u578b\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u4e3a\u66f4\u9ad8\u6548\u7684LLM\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.22258", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22258", "abs": "https://arxiv.org/abs/2511.22258", "authors": ["Guifeng Wang", "Yuanfeng Song", "Meng Yang", "Tao Zhu", "Xiaoming Yin", "Xing Chen"], "title": "Beyond Query-Level Comparison: Fine-Grained Reinforcement Learning for Text-to-SQL with Automated Interpretable Critiques", "comment": null, "summary": "Text-to-SQL, a pivotal natural language processing (NLP) task that converts textual queries into executable SQL, has seen substantial progress in recent years. However, existing evaluation and reward mechanisms used to train and assess the text-to-SQL models remain a critical bottleneck. Current approaches heavily rely on manually annotated gold SQL queries, which are costly to produce and impractical for large-scale evaluation. More importantly, most reinforcement learning (RL) methods in text-to-SQL leverage only the final binary execution outcome as the reward signal, a coarse-grained supervision that overlooks detailed structural and semantic errors from the perspective of rubrics. To address these challenges, we propose RuCo-C, a novel generative judge model for fine-grained, query-specific automatic evaluation using interpretable critiques without human intervention. Our framework first automatically generates query-specific evaluation rubrics for human-free annotation, linking them to interpretable critiques. Subsequently, it integrates densified reward feedback through a \"progressive exploration\" strategy during the RL training process, which dynamically adjusts the rewards to enhance the model's performance. Comprehensive experiments demonstrate that RuCo-C outperforms existing methods in text-to-SQL evaluation, yielding significant performance gains.", "AI": {"tldr": "RuCo-C\u662f\u4e00\u4e2a\u7528\u4e8e\u6587\u672c\u5230SQL\u4efb\u52a1\u7684\u751f\u6210\u5f0f\u8bc4\u5224\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u67e5\u8be2\u7279\u5b9a\u7684\u8bc4\u4f30\u51c6\u5219\u548c\u53ef\u89e3\u91ca\u7684\u6279\u8bc4\uff0c\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684\u81ea\u52a8\u8bc4\u4f30\uff0c\u5e76\u5728\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\u901a\u8fc7\"\u6e10\u8fdb\u63a2\u7d22\"\u7b56\u7565\u96c6\u6210\u5bc6\u96c6\u5956\u52b1\u53cd\u9988\u3002", "motivation": "\u5f53\u524d\u6587\u672c\u5230SQL\u6a21\u578b\u7684\u8bc4\u4f30\u548c\u5956\u52b1\u673a\u5236\u5b58\u5728\u74f6\u9888\uff1a1) \u4e25\u91cd\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u9ec4\u91d1SQL\u67e5\u8be2\uff0c\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u5927\u89c4\u6a21\u8bc4\u4f30\uff1b2) \u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4ec5\u4f7f\u7528\u6700\u7ec8\u4e8c\u5143\u6267\u884c\u7ed3\u679c\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u8fd9\u79cd\u7c97\u7c92\u5ea6\u76d1\u7763\u5ffd\u7565\u4e86\u4ece\u8bc4\u4f30\u51c6\u5219\u89d2\u5ea6\u770b\u7684\u8be6\u7ec6\u7ed3\u6784\u548c\u8bed\u4e49\u9519\u8bef\u3002", "method": "1) \u81ea\u52a8\u751f\u6210\u67e5\u8be2\u7279\u5b9a\u7684\u8bc4\u4f30\u51c6\u5219\uff0c\u5b9e\u73b0\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u6807\u6ce8\uff0c\u5e76\u5c06\u5176\u4e0e\u53ef\u89e3\u91ca\u7684\u6279\u8bc4\u5173\u8054\uff1b2) \u5728\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\"\u6e10\u8fdb\u63a2\u7d22\"\u7b56\u7565\u96c6\u6210\u5bc6\u96c6\u5956\u52b1\u53cd\u9988\uff0c\u52a8\u6001\u8c03\u6574\u5956\u52b1\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cRuCo-C\u5728\u6587\u672c\u5230SQL\u8bc4\u4f30\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "RuCo-C\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u7ec6\u7c92\u5ea6\u3001\u67e5\u8be2\u7279\u5b9a\u7684\u8bc4\u4f30\u51c6\u5219\u548c\u53ef\u89e3\u91ca\u7684\u6279\u8bc4\uff0c\u89e3\u51b3\u4e86\u6587\u672c\u5230SQL\u4efb\u52a1\u4e2d\u8bc4\u4f30\u548c\u5956\u52b1\u673a\u5236\u7684\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u76d1\u7763\u4fe1\u53f7\u3002"}}
{"id": "2511.22312", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22312", "abs": "https://arxiv.org/abs/2511.22312", "authors": ["Anjaneya Praharaj", "Jaykumar Kasundra"], "title": "Token-Level Marginalization for Multi-Label LLM Classifiers", "comment": null, "summary": "This paper addresses the critical challenge of deriving interpretable confidence scores from generative language models (LLMs) when applied to multi-label content safety classification. While models like LLaMA Guard are effective for identifying unsafe content and its categories, their generative architecture inherently lacks direct class-level probabilities, which hinders model confidence assessment and performance interpretation. This limitation complicates the setting of dynamic thresholds for content moderation and impedes fine-grained error analysis. This research proposes and evaluates three novel token-level probability estimation approaches to bridge this gap. The aim is to enhance model interpretability and accuracy, and evaluate the generalizability of this framework across different instruction-tuned models. Through extensive experimentation on a synthetically generated, rigorously annotated dataset, it is demonstrated that leveraging token logits significantly improves the interpretability and reliability of generative classifiers, enabling more nuanced content safety moderation.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u79cd\u65b0\u9896\u7684\u6807\u8bb0\u7ea7\u6982\u7387\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4e3a\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6807\u7b7e\u5185\u5bb9\u5b89\u5168\u5206\u7c7b\u4e2d\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\uff08\u5982LLaMA Guard\uff09\u5728\u591a\u6807\u7b7e\u5185\u5bb9\u5b89\u5168\u5206\u7c7b\u4e2d\u7f3a\u4e4f\u76f4\u63a5\u7684\u7c7b\u522b\u7ea7\u6982\u7387\u8f93\u51fa\uff0c\u8fd9\u963b\u788d\u4e86\u6a21\u578b\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u548c\u6027\u80fd\u89e3\u91ca\uff0c\u4f7f\u5f97\u5185\u5bb9\u5ba1\u6838\u7684\u52a8\u6001\u9608\u503c\u8bbe\u7f6e\u548c\u7ec6\u7c92\u5ea6\u9519\u8bef\u5206\u6790\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e09\u79cd\u65b0\u9896\u7684\u6807\u8bb0\u7ea7\u6982\u7387\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5229\u7528\u6807\u8bb0\u5bf9\u6570\u6982\u7387\u6765\u4e3a\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u63d0\u4f9b\u7f6e\u4fe1\u5ea6\u5206\u6570\uff0c\u5e76\u5728\u5408\u6210\u751f\u6210\u3001\u4e25\u683c\u6807\u6ce8\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5229\u7528\u6807\u8bb0\u5bf9\u6570\u6982\u7387\u80fd\u663e\u8457\u63d0\u9ad8\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\uff0c\u5b9e\u73b0\u66f4\u7ec6\u81f4\u7684\u5185\u5bb9\u5b89\u5168\u5ba1\u6838\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u4e0a\u7684\u901a\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6807\u8bb0\u7ea7\u6982\u7387\u4f30\u8ba1\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6807\u7b7e\u5185\u5bb9\u5b89\u5168\u5206\u7c7b\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u95ee\u9898\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u5185\u5bb9\u5b89\u5168\u5ba1\u6838\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6846\u67b6\u3002"}}
{"id": "2511.22313", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22313", "abs": "https://arxiv.org/abs/2511.22313", "authors": ["Zahri Aksa Dautd", "Aviv Yuniar Rahman"], "title": "Sentiment Analysis Of Shopee Product Reviews Using Distilbert", "comment": "6 pages, 11 figures", "summary": "The rapid growth of digital commerce has led to the accumulation of a massive number of consumer reviews on online platforms. Shopee, as one of the largest e-commerce platforms in Southeast Asia, receives millions of product reviews every day containing valuable information regarding customer satisfaction and preferences. Manual analysis of these reviews is inefficient, thus requiring a computational approach such as sentiment analysis. This study examines the use of DistilBERT, a lightweight transformer-based deep learning model, for sentiment classification on Shopee product reviews. The dataset used consists of approximately one million English-language reviews that have been preprocessed and trained using the distilbert-base-uncased model. Evaluation was conducted using accuracy, precision, recall, and F1-score metrics, and compared against benchmark models such as BERT and SVM. The results show that DistilBERT achieved an accuracy of 94.8%, slightly below BERT (95.3%) but significantly higher than SVM (90.2%), with computation time reduced by more than 55%. These findings demonstrate that DistilBERT provides an optimal balance between accuracy and efficiency, making it suitable for large scale sentiment analysis on e-commerce platforms. Keywords: Sentiment Analysis, DistilBERT, Shopee Reviews, Natural Language Processing, Deep Learning, Transformer Models.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u8f7b\u91cf\u7ea7Transformer\u6a21\u578bDistilBERT\u5bf9Shopee\u4ea7\u54c1\u8bc4\u8bba\u8fdb\u884c\u60c5\u611f\u5206\u6790\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u968f\u7740\u7535\u5546\u5e73\u53f0\u8bc4\u8bba\u6570\u91cf\u6fc0\u589e\uff0c\u624b\u52a8\u5206\u6790\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u8ba1\u7b97\u9ad8\u6548\u7684\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u6765\u5904\u7406Shopee\u7b49\u5e73\u53f0\u7684\u6d77\u91cf\u8bc4\u8bba\u6570\u636e\u3002", "method": "\u4f7f\u7528DistilBERT\u6a21\u578b\u5bf9\u7ea6100\u4e07\u6761\u82f1\u6587Shopee\u8bc4\u8bba\u8fdb\u884c\u60c5\u611f\u5206\u7c7b\uff0c\u91c7\u7528distilbert-base-uncased\u6a21\u578b\uff0c\u5e76\u4e0eBERT\u548cSVM\u57fa\u51c6\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "DistilBERT\u8fbe\u523094.8%\u7684\u51c6\u786e\u7387\uff0c\u7565\u4f4e\u4e8eBERT\uff0895.3%\uff09\uff0c\u4f46\u663e\u8457\u9ad8\u4e8eSVM\uff0890.2%\uff09\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c1155%\u4ee5\u4e0a\u3002", "conclusion": "DistilBERT\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u6700\u4f73\u5e73\u8861\uff0c\u9002\u5408\u7535\u5546\u5e73\u53f0\u7684\u5927\u89c4\u6a21\u60c5\u611f\u5206\u6790\u5e94\u7528\u3002"}}
{"id": "2511.22315", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22315", "abs": "https://arxiv.org/abs/2511.22315", "authors": ["Bakhtawar Abdalla", "Rebwar Mala Nabi", "Hassan Eshkiki", "Fabio Caraffini"], "title": "Named Entity Recognition for the Kurdish Sorani Language: Dataset Creation and Comparative Analysis", "comment": null, "summary": "This work contributes towards balancing the inclusivity and global applicability of natural language processing techniques by proposing the first 'name entity recognition' dataset for Kurdish Sorani, a low-resource and under-represented language, that consists of 64,563 annotated tokens. It also provides a tool for facilitating this task in this and many other languages and performs a thorough comparative analysis, including classic machine learning models and neural systems. The results obtained challenge established assumptions about the advantage of neural approaches within the context of NLP. Conventional methods, in particular CRF, obtain F1-scores of 0.825, outperforming the results of BiLSTM-based models (0.706) significantly. These findings indicate that simpler and more computationally efficient classical frameworks can outperform neural architectures in low-resource settings.", "AI": {"tldr": "\u4e3a\u5e93\u5c14\u5fb7\u7d22\u62c9\u5c3c\u8bed\u521b\u5efa\u9996\u4e2a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6570\u636e\u96c6\uff0864,563\u4e2a\u6807\u6ce8\u8bcd\u5143\uff09\uff0c\u5f00\u53d1\u591a\u8bed\u8a00NER\u5de5\u5177\uff0c\u5e76\u53d1\u73b0\u4f20\u7edfCRF\u65b9\u6cd5\uff08F1=0.825\uff09\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u663e\u8457\u4f18\u4e8e\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff08BiLSTM F1=0.706\uff09\u3002", "motivation": "\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u5305\u5bb9\u6027\u548c\u5168\u7403\u9002\u7528\u6027\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u5e93\u5c14\u5fb7\u7d22\u62c9\u5c3c\u8bed\u8fd9\u79cd\u4f4e\u8d44\u6e90\u3001\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u8bed\u8a00\uff0c\u586b\u8865\u8be5\u8bed\u8a00\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6570\u636e\u96c6\u7684\u7a7a\u767d\u3002", "method": "\u521b\u5efa\u9996\u4e2a\u5e93\u5c14\u5fb7\u7d22\u62c9\u5c3c\u8bedNER\u6570\u636e\u96c6\uff0864,563\u4e2a\u6807\u6ce8\u8bcd\u5143\uff09\uff0c\u5f00\u53d1\u591a\u8bed\u8a00NER\u5de5\u5177\uff0c\u5e76\u8fdb\u884c\u5168\u9762\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u5305\u62ec\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5982CRF\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u7cfb\u7edf\uff08\u5982BiLSTM\uff09\u3002", "result": "\u4f20\u7edfCRF\u65b9\u6cd5\u83b7\u5f970.825\u7684F1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eBiLSTM\u7684\u6a21\u578b\uff080.706\uff09\uff0c\u6311\u6218\u4e86\u795e\u7ecf\u7f51\u7edc\u5728NLP\u4e2d\u5177\u6709\u4f18\u52bf\u7684\u65e2\u5b9a\u5047\u8bbe\u3002", "conclusion": "\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\uff0c\u66f4\u7b80\u5355\u3001\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u7684\u7ecf\u5178\u6846\u67b6\u53ef\u4ee5\u8d85\u8d8a\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u8fd9\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684NLP\u7814\u7a76\u548c\u5b9e\u8df5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.22402", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22402", "abs": "https://arxiv.org/abs/2511.22402", "authors": ["Srivarshinee Sridhar", "Raghav Kaushik Ravi", "Kripabandhu Ghosh"], "title": "Mapping Clinical Doubt: Locating Linguistic Uncertainty in LLMs", "comment": "Accepted to AAAI'26 SECURE-AI4H Workshop", "summary": "Large Language Models (LLMs) are increasingly used in clinical settings, where sensitivity to linguistic uncertainty can influence diagnostic interpretation and decision-making. Yet little is known about where such epistemic cues are internally represented within these models. Distinct from uncertainty quantification, which measures output confidence, this work examines input-side representational sensitivity to linguistic uncertainty in medical text. We curate a contrastive dataset of clinical statements varying in epistemic modality (e.g., 'is consistent with' vs. 'may be consistent with') and propose Model Sensitivity to Uncertainty (MSU), a layerwise probing metric that quantifies activation-level shifts induced by uncertainty cues. Our results show that LLMs exhibit structured, depth-dependent sensitivity to clinical uncertainty, suggesting that epistemic information is progressively encoded in deeper layers. These findings reveal how linguistic uncertainty is internally represented in LLMs, offering insight into their interpretability and epistemic reliability.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8861\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4e34\u5e8a\u6587\u672c\u4e2d\u8bed\u8a00\u4e0d\u786e\u5b9a\u6027\u654f\u611f\u6027\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0LLMs\u5728\u6df1\u5c42\u7f51\u7edc\u4e2d\u9010\u6b65\u7f16\u7801\u8ba4\u77e5\u4fe1\u606f\u3002", "motivation": "LLMs\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u5bf9\u8bed\u8a00\u4e0d\u786e\u5b9a\u6027\u7684\u5185\u90e8\u8868\u5f81\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002\u4e0e\u91cf\u5316\u8f93\u51fa\u7f6e\u4fe1\u5ea6\u4e0d\u540c\uff0c\u672c\u7814\u7a76\u5173\u6ce8\u6a21\u578b\u5bf9\u8f93\u5165\u4fa7\u8bed\u8a00\u4e0d\u786e\u5b9a\u6027\u7684\u8868\u5f81\u654f\u611f\u6027\uff0c\u8fd9\u5bf9\u8bca\u65ad\u89e3\u91ca\u548c\u51b3\u7b56\u5236\u5b9a\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u8ba4\u77e5\u6a21\u6001\u53d8\u5316\u7684\u4e34\u5e8a\u9648\u8ff0\u5bf9\u6bd4\u6570\u636e\u96c6\uff08\u5982\"is consistent with\" vs. \"may be consistent with\"\uff09\uff0c\u63d0\u51fa\u4e86\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u654f\u611f\u6027\uff08MSU\uff09\u6307\u6807\uff0c\u901a\u8fc7\u5206\u5c42\u63a2\u6d4b\u65b9\u6cd5\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u7ebf\u7d22\u5f15\u8d77\u7684\u6fc0\u6d3b\u6c34\u5e73\u53d8\u5316\u3002", "result": "LLMs\u8868\u73b0\u51fa\u7ed3\u6784\u5316\u3001\u6df1\u5ea6\u4f9d\u8d56\u7684\u4e34\u5e8a\u4e0d\u786e\u5b9a\u6027\u654f\u611f\u6027\uff0c\u8868\u660e\u8ba4\u77e5\u4fe1\u606f\u5728\u6df1\u5c42\u7f51\u7edc\u4e2d\u9010\u6b65\u7f16\u7801\u3002\u6a21\u578b\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u654f\u611f\u6027\u968f\u7f51\u7edc\u6df1\u5ea6\u800c\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LLMs\u5185\u90e8\u5982\u4f55\u8868\u5f81\u8bed\u8a00\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u8ba4\u77e5\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u7406\u89e3LLMs\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u673a\u5236\u3002"}}
{"id": "2511.22482", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22482", "abs": "https://arxiv.org/abs/2511.22482", "authors": ["Isabel Gon\u00e7alves", "Paulo Cavalin", "Claudio Pinhanez"], "title": "Exploring Performance Variations in Finetuned Translators of Ultra-Low Resource Languages: Do Linguistic Differences Matter?", "comment": null, "summary": "Finetuning pre-trained language models with small amounts of data is a commonly-used method to create translators for ultra-low resource languages such as endangered Indigenous languages. However, previous works have reported substantially different performances with translators created using similar methodology and data. In this work we systematically explored possible causes of the performance difference, aiming to determine whether it was a product of different cleaning procedures, limitations of the pre-trained models, the size of the base model, or the size of the training dataset, studying both directions of translation. Our studies, using two Brazilian Indigenous languages, related but with significant structural linguistic characteristics, indicated none or very limited influence from those training factors, suggesting differences between languages may play a significant role in the ability to produce translators by fine-tuning pre-trained models.", "AI": {"tldr": "\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u53d1\u73b0\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u521b\u5efa\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u5668\u65f6\uff0c\u6027\u80fd\u5dee\u5f02\u4e3b\u8981\u6e90\u4e8e\u8bed\u8a00\u672c\u8eab\u7279\u6027\u800c\u975e\u8bad\u7ec3\u56e0\u7d20\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u76f8\u4f3c\u65b9\u6cd5\u548c\u6570\u636e\u521b\u5efa\u7684\u7ffb\u8bd1\u5668\u6027\u80fd\u5dee\u5f02\u5f88\u5927\uff0c\u9700\u8981\u7cfb\u7edf\u63a2\u7a76\u8fd9\u4e9b\u5dee\u5f02\u7684\u539f\u56e0\uff0c\u4ee5\u786e\u5b9a\u662f\u6570\u636e\u6e05\u6d17\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u9650\u5236\u3001\u57fa\u7840\u6a21\u578b\u5927\u5c0f\u8fd8\u662f\u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u5177\u6709\u663e\u8457\u7ed3\u6784\u8bed\u8a00\u5b66\u7279\u5f81\u7684\u5df4\u897f\u539f\u4f4f\u6c11\u8bed\u8a00\uff0c\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u8bad\u7ec3\u56e0\u7d20\u5bf9\u7ffb\u8bd1\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u6570\u636e\u6e05\u6d17\u7a0b\u5e8f\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u9650\u5236\u3001\u57fa\u7840\u6a21\u578b\u5927\u5c0f\u548c\u8bad\u7ec3\u6570\u636e\u96c6\u89c4\u6a21\uff0c\u5e76\u7814\u7a76\u53cc\u5411\u7ffb\u8bd1\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u4e9b\u8bad\u7ec3\u56e0\u7d20\u5bf9\u7ffb\u8bd1\u6027\u80fd\u51e0\u4e4e\u6ca1\u6709\u6216\u53ea\u6709\u975e\u5e38\u6709\u9650\u7684\u5f71\u54cd\uff0c\u8868\u660e\u8bed\u8a00\u4e4b\u95f4\u7684\u5dee\u5f02\u53ef\u80fd\u5728\u901a\u8fc7\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\u521b\u5efa\u7ffb\u8bd1\u5668\u7684\u80fd\u529b\u4e2d\u8d77\u91cd\u8981\u4f5c\u7528\u3002", "conclusion": "\u7ffb\u8bd1\u5668\u6027\u80fd\u5dee\u5f02\u4e3b\u8981\u6e90\u4e8e\u8bed\u8a00\u672c\u8eab\u7684\u7279\u6027\u5dee\u5f02\uff0c\u800c\u975e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6280\u672f\u56e0\u7d20\uff0c\u8fd9\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u7814\u7a76\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.22503", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.22503", "abs": "https://arxiv.org/abs/2511.22503", "authors": ["Katia Vendrame", "Bolaji Yusuf", "Santosh Kesiraju", "\u0160imon Sedl\u00e1\u010dek", "Old\u0159ich Plchot", "Jan \u010cernock\u00fd"], "title": "Joint Speech and Text Training for LLM-Based End-to-End Spoken Dialogue State Tracking", "comment": "submitted to ICASSP 2026", "summary": "End-to-end spoken dialogue state tracking (DST) is made difficult by the tandem of having to handle speech input and data scarcity. Combining speech foundation encoders and large language models has been proposed in recent work as to alleviate some of this difficulty. Although this approach has been shown to result in strong spoken DST models, achieving state-of-the-art performance in realistic multi-turn DST, it struggles to generalize across domains and requires annotated spoken DST training data for each domain of interest. However, collecting such data for every target domain is both costly and difficult. Noting that textual DST data is more easily obtained for various domains, in this work, we propose jointly training on available spoken DST data and written textual data from other domains as a way to achieve cross-domain generalization. We conduct experiments which show the efficacy of our proposed method for getting good cross-domain DST performance without relying on spoken training data from the target domains.", "AI": {"tldr": "\u63d0\u51fa\u8054\u5408\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u73b0\u6709\u8bed\u97f3DST\u6570\u636e\u548c\u8de8\u9886\u57df\u6587\u672c\u6570\u636e\uff0c\u5b9e\u73b0\u65e0\u9700\u76ee\u6807\u9886\u57df\u8bed\u97f3\u8bad\u7ec3\u6570\u636e\u7684\u8de8\u9886\u57df\u53e3\u8bed\u5bf9\u8bdd\u72b6\u6001\u8ddf\u8e2a\u6cdb\u5316", "motivation": "\u7aef\u5230\u7aef\u53e3\u8bed\u5bf9\u8bdd\u72b6\u6001\u8ddf\u8e2a\u9762\u4e34\u8bed\u97f3\u8f93\u5165\u5904\u7406\u548c\u6570\u636e\u7a00\u7f3a\u7684\u53cc\u91cd\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u7ed3\u5408\u8bed\u97f3\u57fa\u7840\u7f16\u7801\u5668\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u53d6\u5f97\u826f\u597d\u6027\u80fd\uff0c\u4f46\u96be\u4ee5\u8de8\u9886\u57df\u6cdb\u5316\uff0c\u4e14\u9700\u8981\u4e3a\u6bcf\u4e2a\u76ee\u6807\u9886\u57df\u6536\u96c6\u6807\u6ce8\u7684\u8bed\u97f3DST\u6570\u636e\uff0c\u6210\u672c\u9ad8\u6602\u3002\u6ce8\u610f\u5230\u6587\u672cDST\u6570\u636e\u66f4\u5bb9\u6613\u8de8\u9886\u57df\u83b7\u53d6\u3002", "method": "\u63d0\u51fa\u8054\u5408\u8bad\u7ec3\u65b9\u6cd5\uff0c\u540c\u65f6\u5229\u7528\u53ef\u7528\u7684\u8bed\u97f3DST\u6570\u636e\u548c\u5176\u4ed6\u9886\u57df\u7684\u4e66\u9762\u6587\u672c\u6570\u636e\u3002\u901a\u8fc7\u8fd9\u79cd\u591a\u9886\u57df\u6570\u636e\u8054\u5408\u8bad\u7ec3\uff0c\u5b9e\u73b0\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u76ee\u6807\u9886\u57df\u7684\u8bed\u97f3\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u65e0\u9700\u76ee\u6807\u9886\u57df\u8bed\u97f3\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u83b7\u5f97\u826f\u597d\u7684\u8de8\u9886\u57dfDST\u6027\u80fd\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u9886\u57df\u6cdb\u5316\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u8bed\u97f3DST\u6570\u636e\u548c\u8de8\u9886\u57df\u6587\u672c\u6570\u636e\uff0c\u53ef\u4ee5\u6709\u6548\u5b9e\u73b0\u53e3\u8bed\u5bf9\u8bdd\u72b6\u6001\u8ddf\u8e2a\u7684\u8de8\u9886\u57df\u6cdb\u5316\uff0c\u964d\u4f4e\u5bf9\u76ee\u6807\u9886\u57df\u8bed\u97f3\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.22582", "categories": ["cs.CL", "math.RA"], "pdf": "https://arxiv.org/pdf/2511.22582", "abs": "https://arxiv.org/abs/2511.22582", "authors": ["Matilde Marcolli", "Richard Larson", "Riny Huijbregts"], "title": "Extension Condition \"violations\" and Merge optimality constraints", "comment": "85 pages", "summary": "We analyze, using the mathematical formulation of Merge within the Strong Minimalist Thesis framework, a set of linguistic phenomena, including head-to-head movement, phrasal affixes and syntactic cliticization, verb-particle alternation, and operator-variable phenomena. These are often regarded as problematic, as violations of the Extension Condition. We show that, in fact, all of these phenomena can be explained without involving any EC violation. We first show that derivations using Sideward Merge are possible for all of these cases: these respect EC, though they involve some amount of optimality violations, with respect to Resource Restrictions cost functions, andthe amount of violation differs among these cases. We show that all the cases that involve large optimality violations can be derived in alternative ways involving neither EC nor the use of SM. The main remaining case (head-to-head movement) only involves SM with minimal violations of optimality (near equilibrium fluctuations). We analyze explicitly also the cases of multiple wh-fronting, clusters of clitics in Romance languages and possessor agreement construction in Korean, and how an explanation of these phenomena based on SM can be made compatible with the colored operad generators for phases and theta roles. We also show that the EC condition has a clear algebraic meaning in the mathematical formulation of Merge and is therefore an intrinsic structural algebraic constraint of the model, rather than an additional assumption. We also show that the minimal optimality violating SM plays a structural role in the Markovian properties of Merge, and we compare different optimality conditions coming from Minimal Search and from Resource Restriction in terms of their effect on the dynamics of the Hopf algebra Markov chain, in a simple explicit example.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5728\u5f3a\u6700\u7b80\u8bba\u6846\u67b6\u4e0b\uff0c\u4f7f\u7528\u5408\u5e76\u7684\u6570\u5b66\u516c\u5f0f\u5206\u6790\u591a\u79cd\u8bed\u8a00\u73b0\u8c61\uff0c\u8bc1\u660e\u8fd9\u4e9b\u770b\u4f3c\u8fdd\u53cd\u6269\u5c55\u6761\u4ef6\u7684\u73b0\u8c61\u5b9e\u9645\u4e0a\u53ef\u4ee5\u901a\u8fc7\u4fa7\u5411\u5408\u5e76\u89e3\u91ca\uff0c\u65e0\u9700\u8fdd\u53cd\u6269\u5c55\u6761\u4ef6\u3002", "motivation": "\u8bb8\u591a\u8bed\u8a00\u73b0\u8c61\uff08\u5982\u5934\u5230\u5934\u7684\u79fb\u4f4d\u3001\u77ed\u8bed\u8bcd\u7f00\u3001\u53e5\u6cd5\u9644\u7740\u3001\u52a8\u8bcd-\u5c0f\u54c1\u8bcd\u4ea4\u66ff\u3001\u7b97\u5b50-\u53d8\u91cf\u73b0\u8c61\uff09\u5e38\u88ab\u89c6\u4e3a\u8fdd\u53cd\u6269\u5c55\u6761\u4ef6\uff0c\u9700\u8981\u89e3\u91ca\u8fd9\u4e9b\u73b0\u8c61\u5982\u4f55\u5728\u6700\u7b80\u65b9\u6848\u6846\u67b6\u5185\u5f97\u5230\u5408\u7406\u89e3\u91ca\u3002", "method": "\u91c7\u7528\u5f3a\u6700\u7b80\u8bba\u6846\u67b6\u4e0b\u7684\u5408\u5e76\u6570\u5b66\u516c\u5f0f\uff0c\u4f7f\u7528\u4fa7\u5411\u5408\u5e76\u5206\u6790\u5404\u79cd\u8bed\u8a00\u73b0\u8c61\uff0c\u7ed3\u5408\u6700\u4f18\u6027\u7406\u8bba\u548c\u8d44\u6e90\u9650\u5236\u6210\u672c\u51fd\u6570\uff0c\u5e76\u63a2\u8ba8\u4e0d\u540c\u6700\u4f18\u6027\u6761\u4ef6\u5bf9Hopf\u4ee3\u6570\u9a6c\u5c14\u53ef\u592b\u94fe\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660e\u6240\u6709\u770b\u4f3c\u8fdd\u53cd\u6269\u5c55\u6761\u4ef6\u7684\u73b0\u8c61\u90fd\u53ef\u4ee5\u901a\u8fc7\u4fa7\u5411\u5408\u5e76\u89e3\u91ca\u800c\u4e0d\u8fdd\u53cd\u6269\u5c55\u6761\u4ef6\uff1b\u5934\u5230\u5934\u7684\u79fb\u4f4d\u4ec5\u6d89\u53ca\u6700\u5c0f\u6700\u4f18\u6027\u8fdd\u53cd\uff1b\u6269\u5c55\u6761\u4ef6\u5728\u5408\u5e76\u6570\u5b66\u516c\u5f0f\u4e2d\u5177\u6709\u6e05\u6670\u7684\u4ee3\u6570\u610f\u4e49\uff0c\u662f\u6a21\u578b\u7684\u5185\u5728\u7ed3\u6784\u7ea6\u675f\u3002", "conclusion": "\u6269\u5c55\u6761\u4ef6\u4e0d\u662f\u989d\u5916\u5047\u8bbe\uff0c\u800c\u662f\u5408\u5e76\u6570\u5b66\u516c\u5f0f\u7684\u5185\u5728\u4ee3\u6570\u7ea6\u675f\uff1b\u4fa7\u5411\u5408\u5e76\u53ca\u5176\u6700\u5c0f\u6700\u4f18\u6027\u8fdd\u53cd\u5728\u5408\u5e76\u7684\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\u4e2d\u8d77\u7ed3\u6784\u4f5c\u7528\uff1b\u591a\u79cd\u770b\u4f3c\u6709\u95ee\u9898\u7684\u8bed\u8a00\u73b0\u8c61\u53ef\u4ee5\u5728\u4e0d\u8fdd\u53cd\u6269\u5c55\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\u5f97\u5230\u89e3\u91ca\u3002"}}
{"id": "2511.22584", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22584", "abs": "https://arxiv.org/abs/2511.22584", "authors": ["Chao Feng", "Zihan Liu", "Siddhant Gupta", "Gongpei Cui", "Jan von der Assen", "Burkhard Stiller"], "title": "Smarter, not Bigger: Fine-Tuned RAG-Enhanced LLMs for Automotive HIL Testing", "comment": null, "summary": "Hardware-in-the-Loop (HIL) testing is essential for automotive validation but suffers from fragmented and underutilized test artifacts. This paper presents HIL-GPT, a retrieval-augmented generation (RAG) system integrating domain-adapted large language models (LLMs) with semantic retrieval. HIL-GPT leverages embedding fine-tuning using a domain-specific dataset constructed via heuristic mining and LLM-assisted synthesis, combined with vector indexing for scalable, traceable test case and requirement retrieval. Experiments show that fine-tuned compact models, such as \\texttt{bge-base-en-v1.5}, achieve a superior trade-off between accuracy, latency, and cost compared to larger models, challenging the notion that bigger is always better. An A/B user study further confirms that RAG-enhanced assistants improve perceived helpfulness, truthfulness, and satisfaction over general-purpose LLMs. These findings provide insights for deploying efficient, domain-aligned LLM-based assistants in industrial HIL environments.", "AI": {"tldr": "HIL-GPT\uff1a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u6c7d\u8f66\u786c\u4ef6\u5728\u73af\u6d4b\u8bd5\u8f85\u52a9\u7cfb\u7edf\uff0c\u901a\u8fc7\u9886\u57df\u9002\u914d\u7684LLM\u548c\u8bed\u4e49\u68c0\u7d22\u63d0\u5347\u6d4b\u8bd5\u6548\u7387", "motivation": "\u6c7d\u8f66\u786c\u4ef6\u5728\u73af\u6d4b\u8bd5\u5b58\u5728\u6d4b\u8bd5\u5de5\u4ef6\u788e\u7247\u5316\u548c\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6d4b\u8bd5\u8f85\u52a9\u5de5\u5177", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u542f\u53d1\u5f0f\u6316\u6398\u548cLLM\u8f85\u52a9\u5408\u6210\u7684\u9886\u57df\u6570\u636e\u96c6\u8fdb\u884c\u5d4c\u5165\u5fae\u8c03\uff0c\u4f7f\u7528\u5411\u91cf\u7d22\u5f15\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u6d4b\u8bd5\u7528\u4f8b\u548c\u9700\u6c42\u68c0\u7d22", "result": "\u5fae\u8c03\u540e\u7684\u7d27\u51d1\u6a21\u578b\uff08\u5982bge-base-en-v1.5\uff09\u5728\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u4e4b\u95f4\u8fbe\u5230\u6700\u4f73\u5e73\u8861\uff1b\u7528\u6237\u7814\u7a76\u663e\u793aRAG\u589e\u5f3a\u52a9\u624b\u5728\u5e2e\u52a9\u6027\u3001\u771f\u5b9e\u6027\u548c\u6ee1\u610f\u5ea6\u65b9\u9762\u4f18\u4e8e\u901a\u7528LLM", "conclusion": "HIL-GPT\u4e3a\u5de5\u4e1aHIL\u73af\u5883\u90e8\u7f72\u9ad8\u6548\u3001\u9886\u57df\u5bf9\u9f50\u7684LLM\u52a9\u624b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u6311\u6218\u4e86\"\u8d8a\u5927\u8d8a\u597d\"\u7684\u4f20\u7edf\u89c2\u5ff5"}}
{"id": "2511.22612", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22612", "abs": "https://arxiv.org/abs/2511.22612", "authors": ["Guilherme Sousa", "Rinaldo Lima", "Cassia Trojahn"], "title": "Improving LLM-based Ontology Matching with fine-tuning on synthetic data", "comment": null, "summary": "Large Language Models (LLMs) are increasingly being integrated into various components of Ontology Matching pipelines. This paper investigates the capability of LLMs to perform ontology matching directly on ontology modules and generate the corresponding alignments. Furthermore, it is explored how a dedicated fine-tuning strategy can enhance the model's matching performance in a zero-shot setting. The proposed method incorporates a search space reduction technique to select relevant subsets from both source and target ontologies, which are then used to automatically construct prompts. Recognizing the scarcity of reference alignments for training, a novel LLM-based approach is introduced for generating a synthetic dataset. This process creates a corpus of ontology submodule pairs and their corresponding reference alignments, specifically designed to fine-tune an LLM for the ontology matching task. The proposed approach was evaluated on the Conference, Geolink, Enslaved, Taxon, and Hydrography datasets from the OAEI complex track. The results demonstrate that the LLM fine-tuned on the synthetically generated data exhibits superior performance compared to the non-fine-tuned base model. The key contribution is a strategy that combines automatic dataset generation with fine-tuning to effectively adapt LLMs for ontology matching tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u52a8\u6570\u636e\u96c6\u751f\u6210\u548c\u5fae\u8c03\u7684\u7b56\u7565\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u6267\u884c\u672c\u4f53\u5339\u914d\u4efb\u52a1\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u63d0\u5347\u5339\u914d\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u96c6\u6210\u5230\u672c\u4f53\u5339\u914d\u6d41\u7a0b\u4e2d\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u8db3\u591f\u7684\u53c2\u8003\u5bf9\u9f50\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5728\u672c\u4f53\u5339\u914d\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "method": "1) \u91c7\u7528\u641c\u7d22\u7a7a\u95f4\u7f29\u51cf\u6280\u672f\u9009\u62e9\u76f8\u5173\u672c\u4f53\u5b50\u96c6\uff1b2) \u81ea\u52a8\u6784\u5efa\u63d0\u793a\uff1b3) \u5f15\u5165\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u751f\u6210\u5408\u6210\u6570\u636e\u96c6\uff1b4) \u4f7f\u7528\u5408\u6210\u6570\u636e\u5fae\u8c03LLM\u7528\u4e8e\u672c\u4f53\u5339\u914d\u3002", "result": "\u5728OAEI\u590d\u6742\u8f68\u9053\u7684Conference\u3001Geolink\u3001Enslaved\u3001Taxon\u548cHydrography\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5728\u5408\u6210\u6570\u636e\u4e0a\u5fae\u8c03\u7684LLM\u6027\u80fd\u4f18\u4e8e\u672a\u5fae\u8c03\u7684\u57fa\u51c6\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ed3\u5408\u81ea\u52a8\u6570\u636e\u96c6\u751f\u6210\u548c\u5fae\u8c03\u7684\u7b56\u7565\u80fd\u591f\u6709\u6548\u9002\u914dLLM\u7528\u4e8e\u672c\u4f53\u5339\u914d\u4efb\u52a1\uff0c\u4e3a\u7f3a\u4e4f\u8bad\u7ec3\u6570\u636e\u7684\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.22769", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22769", "abs": "https://arxiv.org/abs/2511.22769", "authors": ["Kanchon Gharami", "Quazi Sarwar Muhtaseem", "Deepti Gupta", "Lavanya Elluri", "Shafika Showkat Moni"], "title": "Modeling Romanized Hindi and Bengali: Dataset Creation and Multilingual LLM Integration", "comment": "Proceedings of the 8th Workshop on Big Data for Cybersecurity (BigCyber)", "summary": "The development of robust transliteration techniques to enhance the effectiveness of transforming Romanized scripts into native scripts is crucial for Natural Language Processing tasks, including sentiment analysis, speech recognition, information retrieval, and intelligent personal assistants. Despite significant advancements, state-of-the-art multilingual models still face challenges in handling Romanized script, where the Roman alphabet is adopted to represent the phonetic structure of diverse languages. Within the South Asian context, where the use of Romanized script for Indo-Aryan languages is widespread across social media and digital communication platforms, such usage continues to pose significant challenges for cutting-edge multilingual models. While a limited number of transliteration datasets and models are available for Indo-Aryan languages, they generally lack sufficient diversity in pronunciation and spelling variations, adequate code-mixed data for large language model (LLM) training, and low-resource adaptation. To address this research gap, we introduce a novel transliteration dataset for two popular Indo-Aryan languages, Hindi and Bengali, which are ranked as the 3rd and 7th most spoken languages worldwide. Our dataset comprises nearly 1.8 million Hindi and 1 million Bengali transliteration pairs. In addition to that, we pre-train a custom multilingual seq2seq LLM based on Marian architecture using the developed dataset. Experimental results demonstrate significant improvements compared to existing relevant models in terms of BLEU and CER metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5305\u542b180\u4e07\u5370\u5730\u8bed\u548c100\u4e07\u5b5f\u52a0\u62c9\u8bed\u8f6c\u5199\u5bf9\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8eMarian\u67b6\u6784\u9884\u8bad\u7ec3\u4e86\u4e00\u4e2a\u591a\u8bed\u8a00seq2seq\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728BLEU\u548cCER\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u7f57\u9a6c\u5316\u811a\u672c\uff08\u7528\u7f57\u9a6c\u5b57\u6bcd\u8868\u793a\u5404\u79cd\u8bed\u8a00\u7684\u8bed\u97f3\u7ed3\u6784\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u4ecd\u7136\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5357\u4e9a\u8bed\u5883\u4e2d\uff0c\u5370\u5730\u8bed\u548c\u5b5f\u52a0\u62c9\u8bed\u7b49\u5370\u5ea6-\u96c5\u5229\u5b89\u8bed\u8a00\u5728\u793e\u4ea4\u5a92\u4f53\u548c\u6570\u5b57\u901a\u4fe1\u5e73\u53f0\u4e0a\u5e7f\u6cdb\u4f7f\u7528\u7f57\u9a6c\u5316\u811a\u672c\u3002\u73b0\u6709\u8f6c\u5199\u6570\u636e\u96c6\u548c\u6a21\u578b\u7f3a\u4e4f\u53d1\u97f3\u548c\u62fc\u5199\u53d8\u4f53\u7684\u591a\u6837\u6027\u3001\u8db3\u591f\u7684\u4ee3\u7801\u6df7\u5408\u6570\u636e\u7528\u4e8eLLM\u8bad\u7ec3\uff0c\u4ee5\u53ca\u4f4e\u8d44\u6e90\u9002\u5e94\u80fd\u529b\u3002", "method": "1. \u4e3a\u5370\u5730\u8bed\u548c\u5b5f\u52a0\u62c9\u8bed\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u8f6c\u5199\u6570\u636e\u96c6\uff0c\u5305\u542b\u8fd1180\u4e07\u5370\u5730\u8bed\u548c100\u4e07\u5b5f\u52a0\u62c9\u8bed\u8f6c\u5199\u5bf9\u30022. \u57fa\u4e8eMarian\u67b6\u6784\u9884\u8bad\u7ec3\u4e86\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684\u591a\u8bed\u8a00seq2seq\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u7528\u5f00\u53d1\u7684\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728BLEU\u548cCER\u6307\u6807\u4e0a\uff0c\u76f8\u6bd4\u73b0\u6709\u76f8\u5173\u6a21\u578b\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u636e\u96c6\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u5370\u5ea6-\u96c5\u5229\u5b89\u8bed\u8a00\u7f57\u9a6c\u5316\u811a\u672c\u8f6c\u5199\u7684\u6311\u6218\uff0c\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u652f\u6301\u3002"}}
{"id": "2511.22818", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.22818", "abs": "https://arxiv.org/abs/2511.22818", "authors": ["Vivek Kumar", "Pushpraj Singh Rajawat", "Eirini Ntoutsi"], "title": "Mitigating Semantic Drift: Evaluating LLMs' Efficacy in Psychotherapy through MI Dialogue Summarization", "comment": null, "summary": "Recent advancements in large language models (LLMs) have shown their potential across both general and domain-specific tasks. However, there is a growing concern regarding their lack of sensitivity, factual incorrectness in responses, inconsistent expressions of empathy, bias, hallucinations, and overall inability to capture the depth and complexity of human understanding, especially in low-resource and sensitive domains such as psychology. To address these challenges, our study employs a mixed-methods approach to evaluate the efficacy of LLMs in psychotherapy. We use LLMs to generate precise summaries of motivational interviewing (MI) dialogues and design a two-stage annotation scheme based on key components of the Motivational Interviewing Treatment Integrity (MITI) framework, namely evocation, collaboration, autonomy, direction, empathy, and a non-judgmental attitude. Using expert-annotated MI dialogues as ground truth, we formulate multi-class classification tasks to assess model performance under progressive prompting techniques, incorporating one-shot and few-shot prompting. Our results offer insights into LLMs' capacity for understanding complex psychological constructs and highlight best practices to mitigate ``semantic drift\" in therapeutic settings. Our work contributes not only to the MI community by providing a high-quality annotated dataset to address data scarcity in low-resource domains but also critical insights for using LLMs for precise contextual interpretation in complex behavioral therapy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u6cbb\u7597\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u6784\u5efa\u57fa\u4e8eMITI\u6846\u67b6\u7684\u6807\u6ce8\u65b9\u6848\uff0c\u8bc4\u4f30LLMs\u5728\u52a8\u673a\u6027\u8bbf\u8c08\u5bf9\u8bdd\u6458\u8981\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63a2\u7d22\u63d0\u793a\u6280\u672f\u4ee5\u51cf\u8f7b\u8bed\u4e49\u6f02\u79fb\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u901a\u7528\u548c\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u5fc3\u7406\u5b66\u7b49\u4f4e\u8d44\u6e90\u654f\u611f\u9886\u57df\u5b58\u5728\u654f\u611f\u6027\u4e0d\u8db3\u3001\u4e8b\u5b9e\u9519\u8bef\u3001\u5171\u60c5\u8868\u8fbe\u4e0d\u4e00\u81f4\u3001\u504f\u89c1\u3001\u5e7b\u89c9\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u6355\u6349\u4eba\u7c7b\u7406\u89e3\u7684\u6df1\u5ea6\u548c\u590d\u6742\u6027\u3002\u9700\u8981\u8bc4\u4f30LLMs\u5728\u5fc3\u7406\u6cbb\u7597\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u8bc4\u4f30LLMs\u5728\u5fc3\u7406\u6cbb\u7597\u4e2d\u7684\u6548\u80fd\uff1a1) \u4f7f\u7528LLMs\u751f\u6210\u52a8\u673a\u6027\u8bbf\u8c08\u5bf9\u8bdd\u7684\u7cbe\u786e\u6458\u8981\uff1b2) \u57fa\u4e8eMITI\u6846\u67b6\u5173\u952e\u7ec4\u4ef6\uff08\u5524\u8d77\u3001\u5408\u4f5c\u3001\u81ea\u4e3b\u3001\u65b9\u5411\u3001\u5171\u60c5\u3001\u975e\u8bc4\u5224\u6001\u5ea6\uff09\u8bbe\u8ba1\u4e24\u9636\u6bb5\u6807\u6ce8\u65b9\u6848\uff1b3) \u4f7f\u7528\u4e13\u5bb6\u6807\u6ce8\u7684MI\u5bf9\u8bdd\u4f5c\u4e3a\u57fa\u51c6\uff0c\u6784\u5efa\u591a\u5206\u7c7b\u4efb\u52a1\uff1b4) \u91c7\u7528\u6e10\u8fdb\u5f0f\u63d0\u793a\u6280\u672f\uff0c\u5305\u62ec\u5355\u6837\u672c\u548c\u5c11\u6837\u672c\u63d0\u793a\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u4e3aLLMs\u7406\u89e3\u590d\u6742\u5fc3\u7406\u6982\u5ff5\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u5e76\u7a81\u51fa\u4e86\u5728\u6cbb\u7597\u73af\u5883\u4e2d\u51cf\u8f7b\"\u8bed\u4e49\u6f02\u79fb\"\u7684\u6700\u4f73\u5b9e\u8df5\u3002\u540c\u65f6\u4e3aMI\u793e\u533a\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u4f4e\u8d44\u6e90\u9886\u57df\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3aMI\u793e\u533a\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u8fd8\u4e3a\u5728\u590d\u6742\u884c\u4e3a\u6cbb\u7597\u4e2d\u4f7f\u7528LLMs\u8fdb\u884c\u7cbe\u786e\u4e0a\u4e0b\u6587\u89e3\u91ca\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8LLMs\u5728\u5fc3\u7406\u6cbb\u7597\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2511.22869", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22869", "abs": "https://arxiv.org/abs/2511.22869", "authors": ["Zhihan Cao", "Fumihito Nishino", "Hiroaki Yamada", "Nguyen Ha Thanh", "Yusuke Miyao", "Ken Satoh"], "title": "JBE-QA: Japanese Bar Exam QA Dataset for Assessing Legal Domain Knowledge", "comment": "Three tables and one figure", "summary": "We introduce JBE-QA, a Japanese Bar Exam Question-Answering dataset to evaluate large language models' legal knowledge. Derived from the multiple-choice (tanto-shiki) section of the Japanese bar exam (2015-2024), JBE-QA provides the first comprehensive benchmark for Japanese legal-domain evaluation of LLMs. It covers the Civil Code, the Penal Code, and the Constitution, extending beyond the Civil Code focus of prior Japanese resources. Each question is decomposed into independent true/false judgments with structured contextual fields. The dataset contains 3,464 items with balanced labels. We evaluate 26 LLMs, including proprietary, open-weight, Japanese-specialised, and reasoning models. Our results show that proprietary models with reasoning enabled perform best, and the Constitution questions are generally easier than the Civil Code or the Penal Code questions.", "AI": {"tldr": "JBE-QA\u662f\u4e00\u4e2a\u65e5\u672c\u53f8\u6cd5\u8003\u8bd5\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6cd5\u5f8b\u77e5\u8bc6\uff0c\u6db5\u76d6\u6c11\u6cd5\u3001\u5211\u6cd5\u548c\u5baa\u6cd5\uff0c\u5305\u542b3464\u4e2a\u5e73\u8861\u6807\u6ce8\u7684\u9879\u76ee\u3002", "motivation": "\u73b0\u6709\u65e5\u672c\u6cd5\u5f8b\u9886\u57df\u8bc4\u4f30\u8d44\u6e90\u4e3b\u8981\u5173\u6ce8\u6c11\u6cd5\uff0c\u7f3a\u4e4f\u5168\u9762\u7684\u6cd5\u5f8b\u77e5\u8bc6\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9700\u8981\u521b\u5efa\u8986\u76d6\u591a\u4e2a\u6cd5\u5f8b\u9886\u57df\u7684\u7efc\u5408\u6027\u6570\u636e\u96c6\u6765\u8bc4\u4f30LLMs\u7684\u65e5\u672c\u6cd5\u5f8b\u77e5\u8bc6\u3002", "method": "\u4ece2015-2024\u5e74\u65e5\u672c\u53f8\u6cd5\u8003\u8bd5\u591a\u9009\u9898\u90e8\u5206\u63d0\u53d6\u6570\u636e\uff0c\u5c06\u6bcf\u4e2a\u95ee\u9898\u5206\u89e3\u4e3a\u72ec\u7acb\u7684\u771f/\u5047\u5224\u65ad\uff0c\u5e76\u6dfb\u52a0\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u5b57\u6bb5\uff0c\u521b\u5efa\u5305\u542b3464\u4e2a\u5e73\u8861\u6807\u6ce8\u9879\u76ee\u7684JBE-QA\u6570\u636e\u96c6\u3002", "result": "\u8bc4\u4f30\u4e8626\u4e2aLLM\uff08\u5305\u62ec\u4e13\u6709\u3001\u5f00\u6e90\u3001\u65e5\u672c\u4e13\u4e1a\u548c\u63a8\u7406\u6a21\u578b\uff09\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u542f\u7528\u63a8\u7406\u7684\u4e13\u6709\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff1b\u5baa\u6cd5\u95ee\u9898\u901a\u5e38\u6bd4\u6c11\u6cd5\u6216\u5211\u6cd5\u95ee\u9898\u66f4\u5bb9\u6613\u3002", "conclusion": "JBE-QA\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u9762\u7684\u65e5\u672c\u6cd5\u5f8b\u9886\u57df\u8bc4\u4f30\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u548c\u6539\u8fdbLLMs\u5728\u65e5\u672c\u6cd5\u5f8b\u77e5\u8bc6\u65b9\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2511.22883", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22883", "abs": "https://arxiv.org/abs/2511.22883", "authors": ["Jingheng Ye", "Shen Wang", "Jiaqi Chen", "Hebin Wang", "Deqing Zou", "Yanyu Zhu", "Jiwei Tang", "Hai-Tao Zheng", "Ruitong Liu", "Haoyang Li", "Yanfeng Wang", "Qingsong Wen"], "title": "FEANEL: A Benchmark for Fine-Grained Error Analysis in K-12 English Writing", "comment": "19 pages, 7 figures, and 4 tables. The dataset is available at https://huggingface.co/datasets/Feanel/FEANEL", "summary": "Large Language Models (LLMs) have transformed artificial intelligence, offering profound opportunities for educational applications. However, their ability to provide fine-grained educational feedback for K-12 English writing remains underexplored. In this paper, we challenge the error analysis and pedagogical skills of LLMs by introducing the problem of Fine-grained Error Analysis for English Learners and present the Fine-grained Error ANalysis for English Learners (FEANEL) Benchmark. The benchmark comprises 1,000 essays written by elementary and secondary school students, and a well-developed English writing error taxonomy. Each error is annotated by language education experts and categorized by type, severity, and explanatory feedback, using a part-of-speech-based taxonomy they co-developed. We evaluate state-of-the-art LLMs on the FEANEL Benchmark to explore their error analysis and pedagogical abilities. Experimental results reveal significant gaps in current LLMs' ability to perform fine-grained error analysis, highlighting the need for advancements in particular methods for educational applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86FEANEL\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728K-12\u82f1\u8bed\u5199\u4f5c\u4e2d\u7ec6\u7c92\u5ea6\u9519\u8bef\u5206\u6790\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524dLLM\u5728\u6b64\u4efb\u52a1\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u6559\u80b2\u5e94\u7528\u4e2d\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5728K-12\u82f1\u8bed\u5199\u4f5c\u4e2d\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u6559\u80b2\u53cd\u9988\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u9700\u8981\u8bc4\u4f30LLM\u5728\u9519\u8bef\u5206\u6790\u548c\u6559\u5b66\u6280\u80fd\u65b9\u9762\u7684\u5b9e\u9645\u8868\u73b0\u3002", "method": "1. \u63d0\u51fa\u7ec6\u7c92\u5ea6\u9519\u8bef\u5206\u6790\u95ee\u9898\uff1b2. \u521b\u5efaFEANEL\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1000\u7bc7\u4e2d\u5c0f\u5b66\u5b66\u751f\u4f5c\u6587\uff1b3. \u5f00\u53d1\u82f1\u8bed\u5199\u4f5c\u9519\u8bef\u5206\u7c7b\u6cd5\uff1b4. \u7531\u8bed\u8a00\u6559\u80b2\u4e13\u5bb6\u8fdb\u884c\u9519\u8bef\u6807\u6ce8\uff08\u7c7b\u578b\u3001\u4e25\u91cd\u7a0b\u5ea6\u3001\u89e3\u91ca\u6027\u53cd\u9988\uff09\uff1b5. \u5728\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u6700\u5148\u8fdb\u7684LLM\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524dLLM\u5728\u7ec6\u7c92\u5ea6\u9519\u8bef\u5206\u6790\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u6559\u80b2\u5e94\u7528\u65b9\u9762\u9700\u8981\u7279\u5b9a\u7684\u65b9\u6cd5\u6539\u8fdb\u3002", "conclusion": "LLM\u5728K-12\u82f1\u8bed\u5199\u4f5c\u7684\u7ec6\u7c92\u5ea6\u9519\u8bef\u5206\u6790\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u5176\u6559\u80b2\u5e94\u7528\u80fd\u529b\uff0cFEANEL\u57fa\u51c6\u4e3a\u8fd9\u4e00\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2511.22904", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.22904", "abs": "https://arxiv.org/abs/2511.22904", "authors": ["Anh Nguyen", "Stefan Lee"], "title": "Language-conditioned world model improves policy generalization by reading environmental descriptions", "comment": "NeuRIPS 2025. Workshop: LAW 2025: Bridging Language, Agent, and World Models", "summary": "To interact effectively with humans in the real world, it is important for agents to understand language that describes the dynamics of the environment--that is, how the environment behaves--rather than just task instructions specifying \"what to do\". Understanding this dynamics-descriptive language is important for human-agent interaction and agent behavior. Recent work address this problem using a model-based approach: language is incorporated into a world model, which is then used to learn a behavior policy. However, these existing methods either do not demonstrate policy generalization to unseen games or rely on limiting assumptions. For instance, assuming that the latency induced by inference-time planning is tolerable for the target task or expert demonstrations are available. Expanding on this line of research, we focus on improving policy generalization from a language-conditioned world model while dropping these assumptions. We propose a model-based reinforcement learning approach, where a language-conditioned world model is trained through interaction with the environment, and a policy is learned from this model--without planning or expert demonstrations. Our method proposes Language-aware Encoder for Dreamer World Model (LED-WM) built on top of DreamerV3. LED-WM features an observation encoder that uses an attention mechanism to explicitly ground language descriptions to entities in the observation. We show that policies trained with LED-WM generalize more effectively to unseen games described by novel dynamics and language compared to other baselines in several settings in two environments: MESSENGER and MESSENGER-WM.To highlight how the policy can leverage the trained world model before real-world deployment, we demonstrate the policy can be improved through fine-tuning on synthetic test trajectories generated by the world model.", "AI": {"tldr": "\u63d0\u51faLED-WM\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u8a00\u6761\u4ef6\u5316\u7684\u4e16\u754c\u6a21\u578b\u63d0\u5347\u7b56\u7565\u5728\u672a\u89c1\u6e38\u620f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u89c4\u5212\u6216\u4e13\u5bb6\u6f14\u793a", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u7406\u89e3\u73af\u5883\u52a8\u6001\u63cf\u8ff0\u8bed\u8a00\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff1a\u8981\u4e48\u65e0\u6cd5\u5c55\u793a\u7b56\u7565\u5728\u672a\u89c1\u6e38\u620f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8981\u4e48\u4f9d\u8d56\u89c4\u5212\u5ef6\u8fdf\u53ef\u5bb9\u5fcd\u6216\u4e13\u5bb6\u6f14\u793a\u53ef\u7528\u7b49\u9650\u5236\u6027\u5047\u8bbe", "method": "\u57fa\u4e8eDreamerV3\u6784\u5efa\u8bed\u8a00\u611f\u77e5\u7f16\u7801\u5668LED-WM\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u5c06\u8bed\u8a00\u63cf\u8ff0\u663e\u5f0f\u5730\u5173\u8054\u5230\u89c2\u5bdf\u4e2d\u7684\u5b9e\u4f53\uff0c\u901a\u8fc7\u73af\u5883\u4ea4\u4e92\u8bad\u7ec3\u8bed\u8a00\u6761\u4ef6\u5316\u4e16\u754c\u6a21\u578b\uff0c\u5e76\u4ece\u4e2d\u5b66\u4e60\u7b56\u7565", "result": "\u5728MESSENGER\u548cMESSENGER-WM\u73af\u5883\u4e2d\uff0cLED-WM\u8bad\u7ec3\u7684\u7b56\u7565\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u6cdb\u5316\u5230\u7531\u65b0\u52a8\u6001\u548c\u8bed\u8a00\u63cf\u8ff0\u7684\u672a\u89c1\u6e38\u620f\uff1b\u901a\u8fc7\u4e16\u754c\u6a21\u578b\u751f\u6210\u7684\u5408\u6210\u6d4b\u8bd5\u8f68\u8ff9\u8fdb\u884c\u5fae\u8c03\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u7b56\u7565\u6027\u80fd", "conclusion": "LED-WM\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u89c4\u5212\u6216\u4e13\u5bb6\u6f14\u793a\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u8bed\u8a00\u6761\u4ef6\u5316\u4e16\u754c\u6a21\u578b\u6709\u6548\u63d0\u5347\u7b56\u7565\u5728\u672a\u89c1\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u524d\u7684\u7b56\u7565\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2511.22943", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.22943", "abs": "https://arxiv.org/abs/2511.22943", "authors": ["Kelaiti Xiao", "Liang Yang", "Dongyu Zhang", "Paerhati Tulajiang", "Hongfei Lin"], "title": "Visual Puns from Idioms: An Iterative LLM-T2IM-MLLM Framework", "comment": "Submitted to ICASSP 2026 (under review)", "summary": "We study idiom-based visual puns--images that align an idiom's literal and figurative meanings--and present an iterative framework that coordinates a large language model (LLM), a text-to-image model (T2IM), and a multimodal LLM (MLLM) for automatic generation and evaluation. Given an idiom, the system iteratively (i) generates detailed visual prompts, (ii) synthesizes an image, (iii) infers the idiom from the image, and (iv) refines the prompt until recognition succeeds or a step limit is reached. Using 1,000 idioms as inputs, we synthesize a corresponding dataset of visual pun images with paired prompts, enabling benchmarking of both generation and understanding. Experiments across 10 LLMs, 10 MLLMs, and one T2IM (Qwen-Image) show that MLLM choice is the primary performance driver: GPT achieves the highest accuracies, Gemini follows, and the best open-source MLLM (Gemma) is competitive with some closed models. On the LLM side, Claude attains the strongest average performance for prompt generation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8fed\u4ee3\u6846\u67b6\uff0c\u5229\u7528LLM\u3001\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u548c\u591a\u6a21\u6001LLM\u81ea\u52a8\u751f\u6210\u548c\u8bc4\u4f30\u57fa\u4e8e\u6210\u8bed\u7684\u89c6\u89c9\u53cc\u5173\u56fe\u50cf\uff0c\u5e76\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b1000\u4e2a\u6210\u8bed\u7684\u6570\u636e\u96c6\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u7814\u7a76\u57fa\u4e8e\u6210\u8bed\u7684\u89c6\u89c9\u53cc\u5173\u56fe\u50cf\uff08\u540c\u65f6\u4f53\u73b0\u6210\u8bed\u5b57\u9762\u548c\u6bd4\u55bb\u610f\u4e49\u7684\u56fe\u50cf\uff09\uff0c\u5f00\u53d1\u81ea\u52a8\u751f\u6210\u548c\u8bc4\u4f30\u8fd9\u7c7b\u521b\u610f\u5185\u5bb9\u7684\u65b9\u6cd5\uff0c\u4e3a\u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u5efa\u7acb\u57fa\u51c6\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u8fed\u4ee3\u6846\u67b6\uff1a\u7ed9\u5b9a\u6210\u8bed\uff0c\u7cfb\u7edf\u5faa\u73af\u6267\u884c\uff1a(1) LLM\u751f\u6210\u8be6\u7ec6\u89c6\u89c9\u63d0\u793a\uff0c(2) \u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u5408\u6210\u56fe\u50cf\uff0c(3) MLLM\u4ece\u56fe\u50cf\u63a8\u65ad\u6210\u8bed\uff0c(4) \u6839\u636e\u8bc6\u522b\u7ed3\u679c\u4f18\u5316\u63d0\u793a\uff0c\u76f4\u5230\u6210\u529f\u8bc6\u522b\u6216\u8fbe\u5230\u6b65\u6570\u9650\u5236\u3002", "result": "\u4f7f\u75281000\u4e2a\u6210\u8bed\u751f\u6210\u4e86\u5bf9\u5e94\u7684\u89c6\u89c9\u53cc\u5173\u56fe\u50cf\u6570\u636e\u96c6\uff1b\u5b9e\u9a8c\u8bc4\u4f30\u4e8610\u4e2aLLM\u300110\u4e2aMLLM\u548c1\u4e2a\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\uff08Qwen-Image\uff09\uff0c\u53d1\u73b0MLLM\u9009\u62e9\u662f\u6027\u80fd\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff1aGPT\u51c6\u786e\u7387\u6700\u9ad8\uff0cGemini\u6b21\u4e4b\uff0c\u6700\u4f73\u5f00\u6e90MLLM\uff08Gemma\uff09\u4e0e\u90e8\u5206\u95ed\u6e90\u6a21\u578b\u7ade\u4e89\uff1b\u5728LLM\u65b9\u9762\uff0cClaude\u5728\u63d0\u793a\u751f\u6210\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u751f\u6210\u57fa\u4e8e\u6210\u8bed\u7684\u89c6\u89c9\u53cc\u5173\u56fe\u50cf\uff0c\u521b\u5efa\u7684\u6570\u636e\u96c6\u4e3a\u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\u3002"}}
{"id": "2511.22972", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22972", "abs": "https://arxiv.org/abs/2511.22972", "authors": ["Jinze Li", "Yixing Xu", "Guanchen Li", "Shuo Yang", "Jinfeng Xu", "Xuanwu Yin", "Dong Li", "Edith C. H. Ngai", "Emad Barsoum"], "title": "Training-Free Loosely Speculative Decoding: Accepting Semantically Correct Drafts Beyond Exact Match", "comment": "Under review", "summary": "Large language models (LLMs) achieve strong performance across diverse tasks but suffer from high inference latency due to their autoregressive generation. Speculative Decoding (SPD) mitigates this issue by verifying candidate tokens in parallel from a smaller draft model, yet its strict exact-match verification discards many semantically valid continuations. Moreover, existing training-based SPD methods often suffer from performance degradation on out-of-distribution (OOD) tasks. To this end, we propose Training-Free Loosely Speculative Decoding (FLy), a novel method that loosens the rigid verification criterion by leveraging the target model's self-corrective behavior to judge whether a draft-target mismatch remains semantically valid. FLy introduces a two-tier mechanism: an entropy-level gate that identifies whether the current token allows multiple plausible alternatives or is nearly deterministic, and a token-level deferred window that distinguishes genuine errors from differently worded yet semantically correct variants. To further reduce latency, we design a multi-level acceleration strategy that accelerates not only the target model but also the drafter itself. Owing to its training-free design, FLy composes seamlessly with arbitrary draft-target pairs and generalizes across models and domains without hyperparameter re-tuning. Experiments show that FLy preserves more than 99% of the target model's accuracy while achieving an average 2.81x speedup on Llama-3.1-70B-Instruct and 5.07x speedup on the 405B variant. Notably, on out-of-domain datasets, our method remains highly effective and outperforms the training-based method EAGLE-3 by 1.62x.", "AI": {"tldr": "FLy\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u5bbd\u677e\u9a8c\u8bc1\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u76ee\u6807\u6a21\u578b\u7684\u81ea\u6821\u6b63\u884c\u4e3a\u548c\u4e24\u7ea7\u673a\u5236\u4fdd\u7559\u8bed\u4e49\u6709\u6548\u4f46\u5b57\u9762\u4e0d\u5339\u914d\u7684\u5019\u9009\uff0c\u5728\u4fdd\u630199%\u4ee5\u4e0a\u51c6\u786e\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u663e\u8457\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4e25\u683c\u7684\u7cbe\u786e\u5339\u914d\u9a8c\u8bc1\u4e22\u5f03\u4e86\u8bb8\u591a\u8bed\u4e49\u6709\u6548\u7684\u5ef6\u7eed\uff1b2\uff09\u57fa\u4e8e\u8bad\u7ec3\u7684\u65b9\u6cd5\u5728\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u80fd\u4fdd\u7559\u8bed\u4e49\u6709\u6548\u5019\u9009\u7684\u5bbd\u677e\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "FLy\u91c7\u7528\u65e0\u9700\u8bad\u7ec3\u7684\u8bbe\u8ba1\uff0c\u901a\u8fc7\u76ee\u6807\u6a21\u578b\u7684\u81ea\u6821\u6b63\u884c\u4e3a\u8fdb\u884c\u5bbd\u677e\u9a8c\u8bc1\u3002\u5305\u542b\u4e24\u7ea7\u673a\u5236\uff1a1\uff09\u71b5\u7ea7\u95e8\u63a7\uff0c\u5224\u65ad\u5f53\u524dtoken\u662f\u5426\u5141\u8bb8\u591a\u4e2a\u5408\u7406\u66ff\u4ee3\uff1b2\uff09token\u7ea7\u5ef6\u8fdf\u7a97\u53e3\uff0c\u533a\u5206\u771f\u6b63\u9519\u8bef\u4e0e\u8bed\u4e49\u6b63\u786e\u4f46\u7528\u8bcd\u4e0d\u540c\u7684\u53d8\u4f53\u3002\u8fd8\u8bbe\u8ba1\u4e86\u591a\u7ea7\u52a0\u901f\u7b56\u7565\u6765\u540c\u65f6\u52a0\u901f\u76ee\u6807\u6a21\u578b\u548c\u8349\u7a3f\u6a21\u578b\u3002", "result": "FLy\u5728\u4fdd\u6301\u76ee\u6807\u6a21\u578b99%\u4ee5\u4e0a\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u5728Llama-3.1-70B-Instruct\u4e0a\u5b9e\u73b0\u5e73\u57472.81\u500d\u52a0\u901f\uff0c\u5728405B\u53d8\u4f53\u4e0a\u5b9e\u73b05.07\u500d\u52a0\u901f\u3002\u5728\u5206\u5e03\u5916\u6570\u636e\u96c6\u4e0a\uff0cFLy\u4ecd\u4fdd\u6301\u9ad8\u6548\uff0c\u6bd4\u57fa\u4e8e\u8bad\u7ec3\u7684EAGLE-3\u65b9\u6cd5\u5feb1.62\u500d\u3002", "conclusion": "FLy\u662f\u4e00\u79cd\u6709\u6548\u7684\u8bad\u7ec3\u81ea\u7531\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bbd\u677e\u9a8c\u8bc1\u673a\u5236\u5728\u4fdd\u6301\u6a21\u578b\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6a21\u578b\u517c\u5bb9\u6027\u3002"}}
{"id": "2511.22977", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.22977", "abs": "https://arxiv.org/abs/2511.22977", "authors": ["Sumit Mamtani", "Abhijeet Bhure"], "title": "Pooling Attention: Evaluating Pretrained Transformer Embeddings for Deception Classification", "comment": "Accepted at the IEEE 7th Computing, Communications and IoT Applications Conference (ComComAp 2025), Madrid, Spain, December 2025. 6 pages", "summary": "This paper investigates fake news detection as a downstream evaluation of Transformer representations, benchmarking encoder-only and decoder-only pre-trained models (BERT, GPT-2, Transformer-XL) as frozen embedders paired with lightweight classifiers. Through controlled preprocessing comparing pooling versus padding and neural versus linear heads, results demonstrate that contextual self-attention encodings consistently transfer effectively. BERT embeddings combined with logistic regression outperform neural baselines on LIAR dataset splits, while analyses of sequence length and aggregation reveal robustness to truncation and advantages from simple max or average pooling. This work positions attention-based token encoders as robust, architecture-centric foundations for veracity tasks, isolating Transformer contributions from classifier complexity.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5c06\u5047\u65b0\u95fb\u68c0\u6d4b\u4f5c\u4e3aTransformer\u8868\u5f81\u7684\u4e0b\u6e38\u8bc4\u4f30\u4efb\u52a1\uff0c\u6bd4\u8f83\u4e86\u7f16\u7801\u5668-\u89e3\u7801\u5668\u9884\u8bad\u7ec3\u6a21\u578b\u4f5c\u4e3a\u51bb\u7ed3\u5d4c\u5165\u5668\u4e0e\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u7ec4\u5408\u7684\u6027\u80fd\uff0c\u53d1\u73b0BERT\u5d4c\u5165\u7ed3\u5408\u903b\u8f91\u56de\u5f52\u5728LIAR\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7814\u7a76Transformer\u8868\u793a\u5728\u5047\u65b0\u95fb\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5c06\u5047\u65b0\u95fb\u68c0\u6d4b\u4f5c\u4e3a\u8bc4\u4f30Transformer\u8868\u5f81\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u65e8\u5728\u5206\u79bbTransformer\u67b6\u6784\u8d21\u732e\u4e0e\u5206\u7c7b\u5668\u590d\u6742\u6027\u3002", "method": "\u4f7f\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u9884\u8bad\u7ec3\u6a21\u578b\uff08BERT\u3001GPT-2\u3001Transformer-XL\uff09\u4f5c\u4e3a\u51bb\u7ed3\u5d4c\u5165\u5668\uff0c\u4e0e\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u914d\u5bf9\u3002\u901a\u8fc7\u63a7\u5236\u9884\u5904\u7406\u6bd4\u8f83\u6c60\u5316\u4e0e\u586b\u5145\u7b56\u7565\uff0c\u4ee5\u53ca\u795e\u7ecf\u7f51\u7edc\u4e0e\u7ebf\u6027\u5206\u7c7b\u5934\u3002\u5728LIAR\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "BERT\u5d4c\u5165\u7ed3\u5408\u903b\u8f91\u56de\u5f52\u5728LIAR\u6570\u636e\u96c6\u5206\u5272\u4e0a\u4f18\u4e8e\u795e\u7ecf\u7f51\u7edc\u57fa\u7ebf\u3002\u4e0a\u4e0b\u6587\u81ea\u6ce8\u610f\u529b\u7f16\u7801\u80fd\u6709\u6548\u8fc1\u79fb\uff0c\u5bf9\u622a\u65ad\u5177\u6709\u9c81\u68d2\u6027\uff0c\u7b80\u5355\u7684\u6700\u5927\u6216\u5e73\u5747\u6c60\u5316\u7b56\u7565\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6807\u8bb0\u7f16\u7801\u5668\u53ef\u4f5c\u4e3a\u771f\u5b9e\u6027\u4efb\u52a1\u7684\u7a33\u5065\u67b6\u6784\u4e2d\u5fc3\u57fa\u7840\uff0cTransformer\u8d21\u732e\u53ef\u4e0e\u5206\u7c7b\u5668\u590d\u6742\u6027\u5206\u79bb\uff0c\u4e3a\u5047\u65b0\u95fb\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8868\u5f81\u57fa\u7840\u3002"}}
{"id": "2511.22978", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.22978", "abs": "https://arxiv.org/abs/2511.22978", "authors": ["Huaixiao Tou", "Ying Zeng", "Cong Ma", "Muzhi Li", "Minghao Li", "Weijie Yuan", "He Zhang", "Kai Jia"], "title": "ShoppingComp: Are LLMs Really Ready for Your Shopping Cart?", "comment": null, "summary": "We present ShoppingComp, a challenging real-world benchmark for rigorously evaluating LLM-powered shopping agents on three core capabilities: precise product retrieval, expert-level report generation, and safety critical decision making. Unlike prior e-commerce benchmarks, ShoppingComp introduces highly complex tasks under the principle of guaranteeing real products and ensuring easy verifiability, adding a novel evaluation dimension for identifying product safety hazards alongside recommendation accuracy and report quality. The benchmark comprises 120 tasks and 1,026 scenarios, curated by 35 experts to reflect authentic shopping needs. Results reveal stark limitations of current LLMs: even state-of-the-art models achieve low performance (e.g., 11.22% for GPT-5, 3.92% for Gemini-2.5-Flash). These findings highlight a substantial gap between research benchmarks and real-world deployment, where LLMs make critical errors such as failure to identify unsafe product usage or falling for promotional misinformation, leading to harmful recommendations. ShoppingComp fills the gap and thus establishes a new standard for advancing reliable and practical agents in e-commerce.", "AI": {"tldr": "ShoppingComp\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u8d2d\u7269\u4ee3\u7406\u5728\u4e09\u4e2a\u6838\u5fc3\u80fd\u529b\u4e0a\u7684\u8868\u73b0\uff1a\u7cbe\u786e\u4ea7\u54c1\u68c0\u7d22\u3001\u4e13\u5bb6\u7ea7\u62a5\u544a\u751f\u6210\u548c\u5b89\u5168\u5173\u952e\u51b3\u7b56\u3002\u7ed3\u679c\u663e\u793a\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u8868\u73b0\u4e0d\u4f73\uff0c\u7a81\u663e\u4e86\u7814\u7a76\u57fa\u51c6\u4e0e\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e4b\u95f4\u7684\u5de8\u5927\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7535\u5b50\u5546\u52a1\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30LLM\u8d2d\u7269\u4ee3\u7406\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u4ea7\u54c1\u5b89\u5168\u5371\u5bb3\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u53cd\u6620\u771f\u5b9e\u8d2d\u7269\u9700\u6c42\u3001\u4fdd\u8bc1\u771f\u5b9e\u4ea7\u54c1\u4e14\u6613\u4e8e\u9a8c\u8bc1\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u521b\u5efa\u4e86\u5305\u542b120\u4e2a\u4efb\u52a1\u548c1,026\u4e2a\u573a\u666f\u7684ShoppingComp\u57fa\u51c6\u6d4b\u8bd5\uff0c\u753135\u4f4d\u4e13\u5bb6\u7b56\u5212\u4ee5\u53cd\u6620\u771f\u5b9e\u8d2d\u7269\u9700\u6c42\u3002\u57fa\u51c6\u6d4b\u8bd5\u5f3a\u8c03\u771f\u5b9e\u4ea7\u54c1\u548c\u6613\u4e8e\u9a8c\u8bc1\u7684\u539f\u5219\uff0c\u5e76\u5f15\u5165\u4e86\u4ea7\u54c1\u5b89\u5168\u5371\u5bb3\u8bc6\u522b\u8fd9\u4e00\u65b0\u7684\u8bc4\u4f30\u7ef4\u5ea6\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u8868\u73b0\u4e0d\u4f73\uff1aGPT-5\u4ec5\u8fbe\u523011.22%\uff0cGemini-2.5-Flash\u4ec5\u8fbe\u52303.92%\u3002LLM\u5b58\u5728\u4e25\u91cd\u9519\u8bef\uff0c\u5982\u672a\u80fd\u8bc6\u522b\u4e0d\u5b89\u5168\u4ea7\u54c1\u4f7f\u7528\u3001\u88ab\u4fc3\u9500\u8bef\u5bfc\u4fe1\u606f\u6b3a\u9a97\uff0c\u5bfc\u81f4\u6709\u5bb3\u63a8\u8350\u3002", "conclusion": "ShoppingComp\u586b\u8865\u4e86\u7814\u7a76\u57fa\u51c6\u4e0e\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u63a8\u8fdb\u7535\u5b50\u5546\u52a1\u4e2d\u53ef\u9760\u5b9e\u7528\u7684\u4ee3\u7406\u5efa\u7acb\u4e86\u65b0\u6807\u51c6\u3002\u5f53\u524dLLM\u5728\u771f\u5b9e\u4e16\u754c\u8d2d\u7269\u4efb\u52a1\u4e2d\u4ecd\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\u3002"}}
{"id": "2511.23041", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23041", "abs": "https://arxiv.org/abs/2511.23041", "authors": ["Dong Nguyen", "Laura Rosseel"], "title": "Social Perceptions of English Spelling Variation on Twitter: A Comparative Analysis of Human and LLM Responses", "comment": null, "summary": "Spelling variation (e.g. funnnn vs. fun) can influence the social perception of texts and their writers: we often have various associations with different forms of writing (is the text informal? does the writer seem young?). In this study, we focus on the social perception of spelling variation in online writing in English and study to what extent this perception is aligned between humans and large language models (LLMs). Building on sociolinguistic methodology, we compare LLM and human ratings on three key social attributes of spelling variation (formality, carefulness, age). We find generally strong correlations in the ratings between humans and LLMs. However, notable differences emerge when we analyze the distribution of ratings and when comparing between different types of spelling variation.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4eba\u7c7b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u82f1\u8bed\u5728\u7ebf\u5199\u4f5c\u4e2d\u62fc\u5199\u53d8\u4f53\uff08\u5982funnnn vs. fun\uff09\u7684\u793e\u4f1a\u611f\u77e5\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u5f62\u5f0f\u6027\u3001\u8ba4\u771f\u5ea6\u548c\u5e74\u9f84\u611f\u77e5\u4e0a\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff0c\u4f46\u5728\u8bc4\u5206\u5206\u5e03\u548c\u4e0d\u540c\u7c7b\u578b\u53d8\u4f53\u95f4\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u62fc\u5199\u53d8\u4f53\uff08\u5982\u91cd\u590d\u5b57\u6bcd\uff09\u4f1a\u5f71\u54cd\u6587\u672c\u548c\u4f5c\u8005\u7684\u793e\u4f1a\u611f\u77e5\uff08\u5982\u662f\u5426\u975e\u6b63\u5f0f\u3001\u4f5c\u8005\u662f\u5426\u5e74\u8f7b\uff09\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4eba\u7c7b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u8fd9\u79cd\u793e\u4f1a\u611f\u77e5\u7684\u4e00\u81f4\u6027\u7a0b\u5ea6\u3002", "method": "\u57fa\u4e8e\u793e\u4f1a\u8bed\u8a00\u5b66\u65b9\u6cd5\uff0c\u6bd4\u8f83LLM\u548c\u4eba\u7c7b\u5bf9\u62fc\u5199\u53d8\u4f53\u5728\u4e09\u4e2a\u5173\u952e\u793e\u4f1a\u5c5e\u6027\uff08\u5f62\u5f0f\u6027\u3001\u8ba4\u771f\u5ea6\u3001\u5e74\u9f84\uff09\u4e0a\u7684\u8bc4\u5206\u3002", "result": "\u4eba\u7c7b\u4e0eLLM\u7684\u8bc4\u5206\u603b\u4f53\u4e0a\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff0c\u4f46\u5728\u5206\u6790\u8bc4\u5206\u5206\u5e03\u548c\u6bd4\u8f83\u4e0d\u540c\u7c7b\u578b\u62fc\u5199\u53d8\u4f53\u65f6\u51fa\u73b0\u4e86\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "LLM\u5728\u611f\u77e5\u62fc\u5199\u53d8\u4f53\u7684\u793e\u4f1a\u5c5e\u6027\u65b9\u9762\u4e0e\u4eba\u7c7b\u6709\u8f83\u9ad8\u4e00\u81f4\u6027\uff0c\u4f46\u5728\u67d0\u4e9b\u65b9\u9762\u4ecd\u5b58\u5728\u5dee\u5f02\uff0c\u8fd9\u4e3a\u7406\u89e3LLM\u7684\u793e\u4f1a\u8bed\u8a00\u80fd\u529b\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2511.23056", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23056", "abs": "https://arxiv.org/abs/2511.23056", "authors": ["Paulo J. N. Pinto", "Armando J. Pinho", "Diogo Pratas"], "title": "Decoding the Past: Explainable Machine Learning Models for Dating Historical Texts", "comment": null, "summary": "Accurately dating historical texts is essential for organizing and interpreting cultural heritage collections. This article addresses temporal text classification using interpretable, feature-engineered tree-based machine learning models. We integrate five feature categories - compression-based, lexical structure, readability, neologism detection, and distance features - to predict the temporal origin of English texts spanning five centuries. Comparative analysis shows that these feature domains provide complementary temporal signals, with combined models outperforming any individual feature set. On a large-scale corpus, we achieve 76.7% accuracy for century-scale prediction and 26.1% for decade-scale classification, substantially above random baselines (20% and 2.3%). Under relaxed temporal precision, performance increases to 96.0% top-2 accuracy for centuries and 85.8% top-10 accuracy for decades. The final model exhibits strong ranking capabilities with AUCROC up to 94.8% and AUPRC up to 83.3%, and maintains controlled errors with mean absolute deviations of 27 years and 30 years, respectively. For authentication-style tasks, binary models around key thresholds (e.g., 1850-1900) reach 85-98% accuracy. Feature importance analysis identifies distance features and lexical structure as most informative, with compression-based features providing complementary signals. SHAP explainability reveals systematic linguistic evolution patterns, with the 19th century emerging as a pivot point across feature domains. Cross-dataset evaluation on Project Gutenberg highlights domain adaptation challenges, with accuracy dropping by 26.4 percentage points, yet the computational efficiency and interpretability of tree-based models still offer a scalable, explainable alternative to neural architectures.", "AI": {"tldr": "\u4f7f\u7528\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u5de5\u7a0b\u6811\u6a21\u578b\u8fdb\u884c\u5386\u53f2\u6587\u672c\u5e74\u4ee3\u5206\u7c7b\uff0c\u6574\u5408\u4e94\u79cd\u7279\u5f81\u7c7b\u522b\uff0c\u5728\u4e16\u7eaa\u5c3a\u5ea6\u8fbe\u523076.7%\u51c6\u786e\u7387\uff0c\u5728\u5341\u5e74\u5c3a\u5ea6\u8fbe\u523026.1%\u51c6\u786e\u7387\u3002", "motivation": "\u51c6\u786e\u786e\u5b9a\u5386\u53f2\u6587\u672c\u7684\u5e74\u4ee3\u5bf9\u4e8e\u6587\u5316\u9057\u4ea7\u6536\u85cf\u7684\u7ec4\u7ec7\u548c\u89e3\u91ca\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6765\u66ff\u4ee3\u9ed1\u76d2\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "method": "\u91c7\u7528\u7279\u5f81\u5de5\u7a0b\u7684\u6811\u57fa\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u6574\u5408\u4e94\u79cd\u7279\u5f81\u7c7b\u522b\uff1a\u57fa\u4e8e\u538b\u7f29\u7684\u7279\u5f81\u3001\u8bcd\u6c47\u7ed3\u6784\u3001\u53ef\u8bfb\u6027\u3001\u65b0\u8bcd\u68c0\u6d4b\u548c\u8ddd\u79bb\u7279\u5f81\u3002\u4f7f\u7528SHAP\u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u4e16\u7eaa\u5c3a\u5ea6\u9884\u6d4b\u8fbe\u523076.7%\u51c6\u786e\u7387\uff0c\u5341\u5e74\u5c3a\u5ea6\u8fbe\u523026.1%\u51c6\u786e\u7387\uff0c\u663e\u8457\u9ad8\u4e8e\u968f\u673a\u57fa\u7ebf\u3002\u5728\u653e\u677e\u65f6\u95f4\u7cbe\u5ea6\u8981\u6c42\u4e0b\uff0c\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u3002\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u663e\u793a\u8ddd\u79bb\u7279\u5f81\u548c\u8bcd\u6c47\u7ed3\u6784\u6700\u5177\u4fe1\u606f\u91cf\uff0c\u538b\u7f29\u7279\u5f81\u63d0\u4f9b\u8865\u5145\u4fe1\u53f7\u300219\u4e16\u7eaa\u88ab\u8bc6\u522b\u4e3a\u8de8\u7279\u5f81\u57df\u7684\u5173\u952e\u8f6c\u6298\u70b9\u3002", "conclusion": "\u7279\u5f81\u5de5\u7a0b\u7684\u6811\u57fa\u6a21\u578b\u4e3a\u5386\u53f2\u6587\u672c\u5e74\u4ee3\u5206\u7c7b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u5355\u72ec\u7684\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u3002\u867d\u7136\u8de8\u6570\u636e\u96c6\u8bc4\u4f30\u663e\u793a\u9886\u57df\u9002\u5e94\u6311\u6218\uff0c\u4f46\u6a21\u578b\u7684\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u4f7f\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.23057", "categories": ["cs.CL", "cs.LG", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.23057", "abs": "https://arxiv.org/abs/2511.23057", "authors": ["Sidharth Rony", "Jack Patman"], "title": "Standard Occupation Classifier -- A Natural Language Processing Approach", "comment": null, "summary": "Standard Occupational Classifiers (SOC) are systems used to categorize and classify different types of jobs and occupations based on their similarities in terms of job duties, skills, and qualifications. Integrating these facets with Big Data from job advertisement offers the prospect to investigate labour demand that is specific to various occupations. This project investigates the use of recent developments in natural language processing to construct a classifier capable of assigning an occupation code to a given job advertisement. We develop various classifiers for both UK ONS SOC and US O*NET SOC, using different Language Models. We find that an ensemble model, which combines Google BERT and a Neural Network classifier while considering job title, description, and skills, achieved the highest prediction accuracy. Specifically, the ensemble model exhibited a classification accuracy of up to 61% for the lower (or fourth) tier of SOC, and 72% for the third tier of SOC. This model could provide up to date, accurate information on the evolution of the labour market using job advertisements.", "AI": {"tldr": "\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u6784\u5efa\u804c\u4e1a\u5206\u7c7b\u5668\uff0c\u80fd\u591f\u6839\u636e\u62db\u8058\u5e7f\u544a\u81ea\u52a8\u5206\u914d\u804c\u4e1a\u4ee3\u7801\uff0c\u6700\u9ad8\u5728SOC\u7b2c\u56db\u5c42\u8fbe\u523061%\u51c6\u786e\u7387\uff0c\u7b2c\u4e09\u5c42\u8fbe\u523072%\u51c6\u786e\u7387\u3002", "motivation": "\u5c06\u6807\u51c6\u804c\u4e1a\u5206\u7c7b\u7cfb\u7edf\uff08SOC\uff09\u4e0e\u62db\u8058\u5e7f\u544a\u5927\u6570\u636e\u7ed3\u5408\uff0c\u53ef\u4ee5\u7814\u7a76\u7279\u5b9a\u804c\u4e1a\u7684\u52b3\u52a8\u529b\u5e02\u573a\u9700\u6c42\u3002\u5f53\u524d\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u5206\u6790\u5927\u91cf\u62db\u8058\u5e7f\u544a\u7684\u804c\u4e1a\u5206\u7c7b\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u79cd\u5206\u7c7b\u5668\uff0c\u9488\u5bf9\u82f1\u56fdONS SOC\u548c\u7f8e\u56fdO*NET SOC\u7cfb\u7edf\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u8bed\u8a00\u6a21\u578b\u3002\u6784\u5efa\u4e86\u96c6\u6210\u6a21\u578b\uff0c\u7ed3\u5408Google BERT\u548c\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\uff0c\u540c\u65f6\u8003\u8651\u804c\u4f4d\u540d\u79f0\u3001\u63cf\u8ff0\u548c\u6280\u80fd\u4fe1\u606f\u3002", "result": "\u96c6\u6210\u6a21\u578b\u5728SOC\u7b2c\u56db\u5c42\uff08\u6700\u7ec6\u7c92\u5ea6\uff09\u8fbe\u523061%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5728\u7b2c\u4e09\u5c42\u8fbe\u523072%\u7684\u51c6\u786e\u7387\u3002\u8be5\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u53ca\u65f6\u51c6\u786e\u7684\u52b3\u52a8\u529b\u5e02\u573a\u6f14\u53d8\u4fe1\u606f\u3002", "conclusion": "\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u804c\u4e1a\u5206\u7c7b\u5668\u53ef\u4ee5\u6709\u6548\u5206\u6790\u62db\u8058\u5e7f\u544a\uff0c\u4e3a\u52b3\u52a8\u529b\u5e02\u573a\u7814\u7a76\u63d0\u4f9b\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u96c6\u6210\u6a21\u578b\u5728SOC\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\u3002"}}
{"id": "2511.23059", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23059", "abs": "https://arxiv.org/abs/2511.23059", "authors": ["Jiatong Han"], "title": "Conveying Imagistic Thinking in TCM Translation: A Prompt Engineering and LLM-Based Evaluation Framework", "comment": "3 figures", "summary": "Traditional Chinese Medicine theory is built on imagistic thinking, in which medical principles and diagnostic and therapeutic logic are structured through metaphor and metonymy. However, existing English translations largely rely on literal rendering, making it difficult for target-language readers to reconstruct the underlying conceptual networks and apply them in clinical practice. This study adopted a human-in-the-loop framework and selected four passages from the medical canon Huangdi Neijing that are fundamental in theory. Through prompt-based cognitive scaffolding, DeepSeek V3.1 was guided to identify metaphor and metonymy in the source text and convey the theory in translation. In the evaluation stage, ChatGPT 5 Pro and Gemini 2.5 Pro were instructed by prompts to simulate three types of real-world readers. Human translations, baseline model translations, and prompt-adjusted translations were scored by the simulated readers across five cognitive dimensions, followed by structured interviews and Interpretative Phenomenological Analysis. Results show that the prompt-adjusted LLM translations perform best across all five dimensions, with high cross-model and cross-role consistency. The interview themes reveal differences between human and machine translation, effective strategies for metaphor and metonymy transfer, and readers' cognitive preferences. This study provides a cognitive, efficient and replicable HITL methodological pathway for translation of ancient, concept-dense texts like TCM.", "AI": {"tldr": "\u672c\u7814\u7a76\u91c7\u7528\u4eba\u673a\u534f\u540c\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u5f15\u5bfcDeepSeek V3.1\u8bc6\u522b\u300a\u9ec4\u5e1d\u5185\u7ecf\u300b\u4e2d\u7684\u9690\u55bb\u548c\u8f6c\u55bb\uff0c\u751f\u6210\u8ba4\u77e5\u4f18\u5316\u7684\u7ffb\u8bd1\uff0c\u5728\u6a21\u62df\u8bfb\u8005\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u4eba\u7c7b\u7ffb\u8bd1\u548c\u57fa\u7ebf\u6a21\u578b\u7ffb\u8bd1\u3002", "motivation": "\u4e2d\u533b\u7406\u8bba\u5efa\u7acb\u5728\u610f\u8c61\u601d\u7ef4\u57fa\u7840\u4e0a\uff0c\u901a\u8fc7\u9690\u55bb\u548c\u8f6c\u55bb\u6784\u5efa\u533b\u5b66\u539f\u7406\u548c\u8bca\u7597\u903b\u8f91\u3002\u73b0\u6709\u82f1\u8bd1\u591a\u91c7\u7528\u5b57\u9762\u7ffb\u8bd1\uff0c\u5bfc\u81f4\u76ee\u6807\u8bed\u8bfb\u8005\u96be\u4ee5\u91cd\u6784\u5e95\u5c42\u6982\u5ff5\u7f51\u7edc\u5e76\u5e94\u7528\u4e8e\u4e34\u5e8a\u5b9e\u8df5\u3002", "method": "\u91c7\u7528\u4eba\u673a\u534f\u540c\u6846\u67b6\uff0c\u9009\u53d6\u300a\u9ec4\u5e1d\u5185\u7ecf\u300b\u4e2d\u56db\u4e2a\u7406\u8bba\u6838\u5fc3\u6bb5\u843d\u3002\u901a\u8fc7\u57fa\u4e8e\u63d0\u793a\u7684\u8ba4\u77e5\u652f\u67b6\uff0c\u5f15\u5bfcDeepSeek V3.1\u8bc6\u522b\u6e90\u6587\u672c\u4e2d\u7684\u9690\u55bb\u548c\u8f6c\u55bb\uff0c\u5728\u7ffb\u8bd1\u4e2d\u4f20\u8fbe\u7406\u8bba\u3002\u8bc4\u4f30\u9636\u6bb5\u4f7f\u7528ChatGPT 5 Pro\u548cGemini 2.5 Pro\u6a21\u62df\u4e09\u7c7b\u771f\u5b9e\u8bfb\u8005\uff0c\u5bf9\u4eba\u7c7b\u7ffb\u8bd1\u3001\u57fa\u7ebf\u6a21\u578b\u7ffb\u8bd1\u548c\u63d0\u793a\u8c03\u6574\u7ffb\u8bd1\u5728\u4e94\u4e2a\u8ba4\u77e5\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u5206\uff0c\u5e76\u8fdb\u884c\u7ed3\u6784\u5316\u8bbf\u8c08\u548c\u89e3\u91ca\u73b0\u8c61\u5b66\u5206\u6790\u3002", "result": "\u63d0\u793a\u8c03\u6574\u7684LLM\u7ffb\u8bd1\u5728\u6240\u6709\u4e94\u4e2a\u7ef4\u5ea6\u8868\u73b0\u6700\u4f73\uff0c\u5177\u6709\u9ad8\u5ea6\u7684\u8de8\u6a21\u578b\u548c\u8de8\u89d2\u8272\u4e00\u81f4\u6027\u3002\u8bbf\u8c08\u4e3b\u9898\u63ed\u793a\u4e86\u4eba\u7c7b\u4e0e\u673a\u5668\u7ffb\u8bd1\u7684\u5dee\u5f02\u3001\u9690\u55bb\u548c\u8f6c\u55bb\u4f20\u9012\u7684\u6709\u6548\u7b56\u7565\uff0c\u4ee5\u53ca\u8bfb\u8005\u7684\u8ba4\u77e5\u504f\u597d\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4e2d\u533b\u7b49\u53e4\u8001\u3001\u6982\u5ff5\u5bc6\u96c6\u6587\u672c\u7684\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u4e00\u6761\u8ba4\u77e5\u3001\u9ad8\u6548\u4e14\u53ef\u590d\u5236\u7684\u4eba\u673a\u534f\u540c\u65b9\u6cd5\u8bba\u8def\u5f84\u3002"}}
{"id": "2511.23088", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23088", "abs": "https://arxiv.org/abs/2511.23088", "authors": ["Akhil Rajeev P", "Annarao Kulkarni"], "title": "Accent Placement Models for Rigvedic Sanskrit Text", "comment": "Submitted to AACL-IJCNLP 2025", "summary": "The Rigveda, among the oldest Indian texts in Vedic Sanskrit, employs a distinctive pitch-accent system : ud\u0101tta, anud\u0101tta, svarita whose marks encode melodic and interpretive cues but are often absent from modern e-texts. This work develops a parallel corpus of accented-unaccented \u015blokas and conducts a controlled comparison of three strategies for automatic accent placement in Rigvedic verse: (i) full fine-tuning of ByT5, a byte-level Transformer that operates directly on Unicode combining marks, (ii) a from-scratch BiLSTM-CRF sequence-labeling baseline, and (iii) LoRA-based parameter-efficient fine-tuning atop ByT5.\n  Evaluation uses Word Error Rate (WER) and Character Error Rate (CER) for orthographic fidelity, plus a task-specific Diacritic Error Rate (DER) that isolates accent edits. Full ByT5 fine-tuning attains the lowest error across all metrics; LoRA offers strong efficiency-accuracy trade-offs, and BiLSTM-CRF serves as a transparent baseline. The study underscores practical requirements for accent restoration - Unicode-safe preprocessing, mark-aware tokenization, and evaluation that separates grapheme from accent errors - and positions heritage-language technology as an emerging NLP area connecting computational modeling with philological and pedagogical aims. Results establish reproducible baselines for Rigvedic accent restoration and provide guidance for downstream tasks such as accent-aware OCR, ASR/chant synthesis, and digital scholarship.", "AI": {"tldr": "\u4f7f\u7528\u4e09\u79cd\u7b56\u7565\u81ea\u52a8\u6062\u590d\u300a\u68a8\u4ff1\u5420\u9640\u300b\u68b5\u6587\u8bd7\u8282\u4e2d\u7684\u97f3\u8c03\u91cd\u97f3\u6807\u8bb0\uff1a\u5168\u5fae\u8c03ByT5\u3001\u4ece\u5934\u8bad\u7ec3\u7684BiLSTM-CRF\u57fa\u7ebf\u3001\u4ee5\u53ca\u57fa\u4e8eLoRA\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5176\u4e2d\u5168\u5fae\u8c03ByT5\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u300a\u68a8\u4ff1\u5420\u9640\u300b\u4f5c\u4e3a\u6700\u53e4\u8001\u7684\u68b5\u6587\u6587\u672c\u4e4b\u4e00\uff0c\u4f7f\u7528\u72ec\u7279\u7684\u97f3\u8c03\u91cd\u97f3\u7cfb\u7edf\uff08ud\u0101tta\u3001anud\u0101tta\u3001svarita\uff09\uff0c\u4f46\u8fd9\u4e9b\u6807\u8bb0\u5728\u73b0\u4ee3\u7535\u5b50\u6587\u672c\u4e2d\u7ecf\u5e38\u7f3a\u5931\uff0c\u5f71\u54cd\u4e86\u6587\u672c\u7684\u65cb\u5f8b\u548c\u89e3\u91ca\u7ebf\u7d22\u7684\u4fdd\u7559\u3002", "method": "1. \u521b\u5efa\u5e26\u91cd\u97f3\u548c\u4e0d\u5e26\u91cd\u97f3\u8bd7\u8282\u7684\u5e73\u884c\u8bed\u6599\u5e93\uff1b2. \u6bd4\u8f83\u4e09\u79cd\u81ea\u52a8\u91cd\u97f3\u653e\u7f6e\u7b56\u7565\uff1a\u5168\u5fae\u8c03ByT5\uff08\u76f4\u63a5\u5728Unicode\u7ec4\u5408\u6807\u8bb0\u4e0a\u64cd\u4f5c\u7684\u5b57\u8282\u7ea7Transformer\uff09\u3001\u4ece\u5934\u8bad\u7ec3\u7684BiLSTM-CRF\u5e8f\u5217\u6807\u6ce8\u57fa\u7ebf\u3001\u4ee5\u53ca\u57fa\u4e8eLoRA\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff1b3. \u4f7f\u7528WER\u3001CER\u548c\u4e13\u95e8\u7684\u91cd\u97f3\u9519\u8bef\u7387\uff08DER\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5168\u5fae\u8c03ByT5\u5728\u6240\u6709\u6307\u6807\u4e0a\u83b7\u5f97\u6700\u4f4e\u9519\u8bef\u7387\uff1bLoRA\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6548\u7387-\u51c6\u786e\u6027\u6743\u8861\uff1bBiLSTM-CRF\u4f5c\u4e3a\u900f\u660e\u57fa\u7ebf\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u91cd\u97f3\u6062\u590d\u7684\u5b9e\u9645\u9700\u6c42\uff1aUnicode\u5b89\u5168\u9884\u5904\u7406\u3001\u6807\u8bb0\u611f\u77e5\u5206\u8bcd\u3001\u4ee5\u53ca\u5206\u79bb\u5b57\u5f62\u548c\u91cd\u97f3\u9519\u8bef\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u300a\u68a8\u4ff1\u5420\u9640\u300b\u91cd\u97f3\u6062\u590d\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7ebf\uff0c\u4e3a\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u91cd\u97f3\u611f\u77e5OCR\u3001ASR/\u541f\u5531\u5408\u6210\u3001\u6570\u5b57\u5b66\u672f\u7814\u7a76\uff09\u63d0\u4f9b\u6307\u5bfc\uff0c\u5e76\u5c06\u9057\u4ea7\u8bed\u8a00\u6280\u672f\u5b9a\u4f4d\u4e3a\u8fde\u63a5\u8ba1\u7b97\u5efa\u6a21\u4e0e\u6587\u732e\u5b66\u548c\u6559\u5b66\u76ee\u6807\u7684NLP\u65b0\u5174\u9886\u57df\u3002"}}
{"id": "2511.23101", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23101", "abs": "https://arxiv.org/abs/2511.23101", "authors": ["Francesco Di Cursi", "Chiara Boldrini", "Marco Conti", "Andrea Passarella"], "title": "Mind Reading or Misreading? LLMs on the Big Five Personality Test", "comment": "Funding: SoBigDatait (IR0000013), FAIR (PE00000013), ICSC (CN00000013)", "summary": "We evaluate large language models (LLMs) for automatic personality prediction from text under the binary Five Factor Model (BIG5). Five models -- including GPT-4 and lightweight open-source alternatives -- are tested across three heterogeneous datasets (Essays, MyPersonality, Pandora) and two prompting strategies (minimal vs. enriched with linguistic and psychological cues). Enriched prompts reduce invalid outputs and improve class balance, but also introduce a systematic bias toward predicting trait presence. Performance varies substantially: Openness and Agreeableness are relatively easier to detect, while Extraversion and Neuroticism remain challenging. Although open-source models sometimes approach GPT-4 and prior benchmarks, no configuration yields consistently reliable predictions in zero-shot binary settings. Moreover, aggregate metrics such as accuracy and macro-F1 mask significant asymmetries, with per-class recall offering clearer diagnostic value. These findings show that current out-of-the-box LLMs are not yet suitable for APPT, and that careful coordination of prompt design, trait framing, and evaluation metrics is essential for interpretable results.", "AI": {"tldr": "\u8bc4\u4f30LLM\u5728\u4e8c\u5143\u4e94\u56e0\u7d20\u6a21\u578b\u4e0b\u4ece\u6587\u672c\u81ea\u52a8\u9884\u6d4b\u4eba\u683c\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e2d\u65e0\u6cd5\u4ea7\u751f\u53ef\u9760\u9884\u6d4b\uff0c\u9700\u8981\u4ed4\u7ec6\u534f\u8c03\u63d0\u793a\u8bbe\u8ba1\u3001\u7279\u8d28\u6846\u67b6\u548c\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u4eba\u683c\u9884\u6d4b\u4efb\u52a1\uff08APPT\uff09\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u4e8c\u5143\u4e94\u56e0\u7d20\u6a21\u578b\uff08BIG5\uff09\u6846\u67b6\u4e0b\uff0c\u4e86\u89e3\u5f53\u524d\u73b0\u6210LLM\u662f\u5426\u9002\u5408\u6b64\u4efb\u52a1\u3002", "method": "\u6d4b\u8bd5\u4e94\u4e2aLLM\uff08\u5305\u62ecGPT-4\u548c\u8f7b\u91cf\u7ea7\u5f00\u6e90\u66ff\u4ee3\u65b9\u6848\uff09\uff0c\u4f7f\u7528\u4e09\u4e2a\u5f02\u6784\u6570\u636e\u96c6\uff08Essays\u3001MyPersonality\u3001Pandora\uff09\u548c\u4e24\u79cd\u63d0\u793a\u7b56\u7565\uff08\u6700\u5c0f\u63d0\u793a vs \u5305\u542b\u8bed\u8a00\u5b66\u548c\u5fc3\u7406\u5b66\u7ebf\u7d22\u7684\u4e30\u5bcc\u63d0\u793a\uff09\u3002", "result": "\u4e30\u5bcc\u63d0\u793a\u51cf\u5c11\u65e0\u6548\u8f93\u51fa\u5e76\u6539\u5584\u7c7b\u522b\u5e73\u8861\uff0c\u4f46\u4e5f\u5f15\u5165\u7cfb\u7edf\u6027\u504f\u5411\u9884\u6d4b\u7279\u8d28\u5b58\u5728\u3002\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff1a\u5f00\u653e\u6027\u548c\u5b9c\u4eba\u6027\u76f8\u5bf9\u5bb9\u6613\u68c0\u6d4b\uff0c\u5916\u5411\u6027\u548c\u795e\u7ecf\u8d28\u4ecd\u5177\u6311\u6218\u6027\u3002\u5f00\u6e90\u6a21\u578b\u6709\u65f6\u63a5\u8fd1GPT-4\u548c\u5148\u524d\u57fa\u51c6\uff0c\u4f46\u6ca1\u6709\u914d\u7f6e\u80fd\u5728\u96f6\u6837\u672c\u4e8c\u5143\u8bbe\u7f6e\u4e2d\u4ea7\u751f\u4e00\u81f4\u53ef\u9760\u7684\u9884\u6d4b\u3002", "conclusion": "\u5f53\u524d\u73b0\u6210\u7684LLM\u5c1a\u4e0d\u9002\u5408APPT\u4efb\u52a1\uff0c\u9700\u8981\u4ed4\u7ec6\u534f\u8c03\u63d0\u793a\u8bbe\u8ba1\u3001\u7279\u8d28\u6846\u67b6\u548c\u8bc4\u4f30\u6307\u6807\u624d\u80fd\u83b7\u5f97\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\u3002\u805a\u5408\u6307\u6807\u5982\u51c6\u786e\u7387\u548c\u5b8fF1\u63a9\u76d6\u4e86\u663e\u8457\u7684\u4e0d\u5bf9\u79f0\u6027\uff0c\u6bcf\u7c7b\u53ec\u56de\u7387\u63d0\u4f9b\u66f4\u6e05\u6670\u7684\u8bca\u65ad\u4ef7\u503c\u3002"}}
{"id": "2511.23119", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23119", "abs": "https://arxiv.org/abs/2511.23119", "authors": ["Mengjie Liu", "Jiahui Peng", "Pei Chu", "Jiantao Qiu", "Ren Ma", "He Zhu", "Rui Min", "Lindong Lu", "Wenchang Ning", "Linfeng Hou", "Kaiwen Liu", "Yuan Qu", "Zhenxiang Li", "Chao Xu", "Zhongying Tu", "Wentao Zhang", "Conghui He"], "title": "Dripper: Token-Efficient Main HTML Extraction with a Lightweight LM", "comment": null, "summary": "Accurately and efficiently extracting main content from general web pages is of great significance for obtaining training data for large models. Using well-pre-trained decoder-only generative language models offers excellent document comprehension capabilities, thereby effectively enhancing parsing quality. However, it remains constrained by issues such as context window length, inference cost, and format hallucination. We present Dripper, an efficient HTML main content extraction framework powered by lightweight language models, which addresses these challenges through four key innovations: (1) We design a specialized HTML simplification algorithm that reduces input token count to 22\\% compared to raw HTML while preserving critical structural information; (2) We reformulate main content extraction as a semantic block sequence classification task, significantly reducing inference cost; (3) We introduce a controlled decoding mechanism that strictly constrains the output space through logits processors, effectively eliminating hallucination issues common in small-scale models; (4) We propose WebMainBench, an evaluation dataset containing over 7,800 web pages with meticulously human-annotated main content extraction labels. Experimental results demonstrate that using only a 0.6B parameter model, Dripper achieves state-of-the-art performance across all evaluation benchmarks and outperforms all baseline methods, attaining an ROUGE-N F1 score of 81.58\\%( 83.13\\% with fall-back strategy) on our proposed WebMainBench dataset.", "AI": {"tldr": "Dripper\u662f\u4e00\u4e2a\u9ad8\u6548\u7684HTML\u4e3b\u8981\u5185\u5bb9\u63d0\u53d6\u6846\u67b6\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7HTML\u7b80\u5316\u3001\u8bed\u4e49\u5757\u5e8f\u5217\u5206\u7c7b\u3001\u53d7\u63a7\u89e3\u7801\u7b49\u521b\u65b0\u6280\u672f\uff0c\u57280.6B\u53c2\u6570\u4e0b\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u4ece\u7f51\u9875\u4e2d\u51c6\u786e\u9ad8\u6548\u63d0\u53d6\u4e3b\u8981\u5185\u5bb9\u5bf9\u4e8e\u83b7\u53d6\u5927\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u9884\u8bad\u7ec3\u7684\u89e3\u7801\u5668\u751f\u6210\u8bed\u8a00\u6a21\u578b\u5177\u6709\u826f\u597d\u7684\u6587\u6863\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u7a97\u53e3\u957f\u5ea6\u3001\u63a8\u7406\u6210\u672c\u548c\u683c\u5f0f\u5e7b\u89c9\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faDripper\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u5173\u952e\u6280\u672f\uff1a(1)\u4e13\u95e8\u7684HTML\u7b80\u5316\u7b97\u6cd5\uff0c\u5c06\u8f93\u5165token\u51cf\u5c11\u5230\u539f\u59cbHTML\u768422%\uff1b(2)\u5c06\u4e3b\u8981\u5185\u5bb9\u63d0\u53d6\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8bed\u4e49\u5757\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\uff1b(3)\u5f15\u5165\u53d7\u63a7\u89e3\u7801\u673a\u5236\uff0c\u901a\u8fc7logits\u5904\u7406\u5668\u4e25\u683c\u7ea6\u675f\u8f93\u51fa\u7a7a\u95f4\uff1b(4)\u6784\u5efaWebMainBench\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5305\u542b7800\u591a\u4e2a\u7f51\u9875\u7684\u4eba\u5de5\u6807\u6ce8\u3002", "result": "\u4ec5\u4f7f\u75280.6B\u53c2\u6570\u6a21\u578b\uff0cDripper\u5728\u6240\u6709\u8bc4\u4f30\u57fa\u51c6\u4e0a\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728WebMainBench\u6570\u636e\u96c6\u4e0a\u83b7\u5f9781.58%\u7684ROUGE-N F1\u5206\u6570\uff08\u4f7f\u7528\u56de\u9000\u7b56\u7565\u53ef\u8fbe83.13%\uff09\uff0c\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Dripper\u901a\u8fc7\u521b\u65b0\u7684HTML\u7b80\u5316\u3001\u4efb\u52a1\u91cd\u6784\u548c\u53d7\u63a7\u89e3\u7801\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u4e0a\u4e0b\u6587\u957f\u5ea6\u3001\u63a8\u7406\u6210\u672c\u548c\u5e7b\u89c9\u65b9\u9762\u7684\u9650\u5236\uff0c\u4e3a\u7f51\u9875\u4e3b\u8981\u5185\u5bb9\u63d0\u53d6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.23136", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23136", "abs": "https://arxiv.org/abs/2511.23136", "authors": ["Yujiao Yang", "Jing Lian", "Linhui Li"], "title": "Multi-chain Graph Refinement and Selection for Reliable Reasoning in Large Language Models", "comment": null, "summary": "The complex reasoning ability of Large Language Models (LLMs) poses a critical bottleneck for their practical applications. Test-time expansion methods such as Tree-of-Thought (ToT) and Graph-of-Thought (GoT) enhance reasoning by introducing intermediate reasoning structures, tree search, or graph-based exploration mechanisms. However, their reasoning strategies suffer from limited diversity, redundant search branches, and inadequate integration and error correction across heterogeneous reasoning paths. To address these limitations, we propose a novel reasoning framework called Multi-chain Graph Refinement & Selection (MGRS), which first generates multiple diverse reasoning trajectories for a given problem, refines candidate responses using a composite self- and cross-verification strategy, then constructs a reasoning relation graph and estimates the success rate of intermediate nodes, and finally computes cumulative success rates to select the most reliable answer and corresponding reasoning trajectory. Experimental results demonstrate that MGRS significantly advances both the reasoning capability and computational efficiency of reasoning enhancement methods. Across six benchmark datasets spanning four distinct tasks, MGRS achieves an average accuracy of 82.9%, outperforming state-of-the-art baselines by a clear margin of 2.1%. Remarkably, on the 24-point game, MGRS attains 100% accuracy for the first time, while delivering a 13.6x speed-up compared to the leading Forest of Thoughts framework.", "AI": {"tldr": "MGRS\u662f\u4e00\u4e2a\u65b0\u7684\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u591a\u6837\u63a8\u7406\u8f68\u8ff9\u3001\u590d\u5408\u9a8c\u8bc1\u3001\u6784\u5efa\u63a8\u7406\u5173\u7cfb\u56fe\u5e76\u8ba1\u7b97\u7d2f\u79ef\u6210\u529f\u7387\uff0c\u663e\u8457\u63d0\u5347LLMs\u7684\u63a8\u7406\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\uff08\u5982ToT\u3001GoT\uff09\u5b58\u5728\u63a8\u7406\u7b56\u7565\u591a\u6837\u6027\u6709\u9650\u3001\u641c\u7d22\u5206\u652f\u5197\u4f59\u3001\u5f02\u6784\u63a8\u7406\u8def\u5f84\u6574\u5408\u4e0e\u7ea0\u9519\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86LLMs\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faMGRS\u6846\u67b6\uff1a1) \u4e3a\u7ed9\u5b9a\u95ee\u9898\u751f\u6210\u591a\u4e2a\u591a\u6837\u63a8\u7406\u8f68\u8ff9\uff1b2) \u4f7f\u7528\u590d\u5408\u81ea\u9a8c\u8bc1\u548c\u4ea4\u53c9\u9a8c\u8bc1\u7b56\u7565\u7cbe\u70bc\u5019\u9009\u54cd\u5e94\uff1b3) \u6784\u5efa\u63a8\u7406\u5173\u7cfb\u56fe\u5e76\u4f30\u8ba1\u4e2d\u95f4\u8282\u70b9\u6210\u529f\u7387\uff1b4) \u8ba1\u7b97\u7d2f\u79ef\u6210\u529f\u7387\u9009\u62e9\u6700\u53ef\u9760\u7b54\u6848\u548c\u63a8\u7406\u8f68\u8ff9\u3002", "result": "\u5728\u6db5\u76d6\u56db\u4e2a\u4efb\u52a1\u7684\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cMGRS\u5e73\u5747\u51c6\u786e\u7387\u8fbe82.9%\uff0c\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u9ad8\u51fa2.1%\u3002\u572824\u70b9\u6e38\u620f\u4e2d\u9996\u6b21\u5b9e\u73b0100%\u51c6\u786e\u7387\uff0c\u540c\u65f6\u6bd4\u9886\u5148\u7684Forest of Thoughts\u6846\u67b6\u5feb13.6\u500d\u3002", "conclusion": "MGRS\u901a\u8fc7\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u7684\u63a8\u7406\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4e3aLLMs\u7684\u590d\u6742\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.23174", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23174", "abs": "https://arxiv.org/abs/2511.23174", "authors": ["Neemesh Yadav", "Francesco Ortu", "Jiarui Liu", "Joeun Yook", "Bernhard Sch\u00f6lkopf", "Rada Mihalcea", "Alberto Cazzaniga", "Zhijing Jin"], "title": "Are LLMs Good Safety Agents or a Propaganda Engine?", "comment": "15 pages, 7 tables, 4 figures", "summary": "Large Language Models (LLMs) are trained to refuse to respond to harmful content. However, systematic analyses of whether this behavior is truly a reflection of its safety policies or an indication of political censorship, that is practiced globally by countries, is lacking. Differentiating between safety influenced refusals or politically motivated censorship is hard and unclear. For this purpose we introduce PSP, a dataset built specifically to probe the refusal behaviors in LLMs from an explicitly political context. PSP is built by formatting existing censored content from two data sources, openly available on the internet: sensitive prompts in China generalized to multiple countries, and tweets that have been censored in various countries. We study: 1) impact of political sensitivity in seven LLMs through data-driven (making PSP implicit) and representation-level approaches (erasing the concept of politics); and, 2) vulnerability of models on PSP through prompt injection attacks (PIAs). Associating censorship with refusals on content with masked implicit intent, we find that most LLMs perform some form of censorship. We conclude with summarizing major attributes that can cause a shift in refusal distributions across models and contexts of different countries.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86PSP\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u4ece\u653f\u6cbb\u89d2\u5ea6\u63a2\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u62d2\u7edd\u884c\u4e3a\uff0c\u53d1\u73b0\u5927\u591a\u6570LLM\u90fd\u5b58\u5728\u67d0\u79cd\u5f62\u5f0f\u7684\u5ba1\u67e5\uff0c\u5e76\u603b\u7ed3\u4e86\u5bfc\u81f4\u4e0d\u540c\u6a21\u578b\u548c\u56fd\u5bb6\u95f4\u62d2\u7edd\u5206\u5e03\u5dee\u5f02\u7684\u4e3b\u8981\u56e0\u7d20\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u62d2\u7edd\u6709\u5bb3\u5185\u5bb9\u884c\u4e3a\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u65e0\u6cd5\u533a\u5206\u8fd9\u79cd\u62d2\u7edd\u662f\u57fa\u4e8e\u5b89\u5168\u653f\u7b56\u8fd8\u662f\u653f\u6cbb\u5ba1\u67e5\u3002\u9700\u8981\u4e13\u95e8\u5de5\u5177\u6765\u63a2\u6d4bLLM\u62d2\u7edd\u884c\u4e3a\u80cc\u540e\u7684\u653f\u6cbb\u52a8\u673a\u3002", "method": "\u6784\u5efaPSP\u6570\u636e\u96c6\uff0c\u5305\u542b\u6765\u81ea\u4e92\u8054\u7f51\u7684\u4e24\u4e2a\u6570\u636e\u6e90\uff1a\u4e2d\u56fd\u654f\u611f\u63d0\u793a\u6269\u5c55\u5230\u591a\u56fd\uff0c\u4ee5\u53ca\u5404\u56fd\u88ab\u5ba1\u67e5\u7684\u63a8\u6587\u3002\u91c7\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff08\u4f7fPSP\u9690\u542b\uff09\u548c\u8868\u793a\u5c42\u9762\u65b9\u6cd5\uff08\u6d88\u9664\u653f\u6cbb\u6982\u5ff5\uff09\uff0c\u5e76\u6d4b\u8bd5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5927\u591a\u6570LLM\u90fd\u5b58\u5728\u67d0\u79cd\u5f62\u5f0f\u7684\u5ba1\u67e5\u884c\u4e3a\u3002\u901a\u8fc7\u5c06\u5ba1\u67e5\u4e0e\u9690\u542b\u610f\u56fe\u5185\u5bb9\u7684\u62d2\u7edd\u76f8\u5173\u8054\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u653f\u6cbb\u654f\u611f\u5185\u5bb9\u4e0a\u7684\u62d2\u7edd\u6a21\u5f0f\u3002", "conclusion": "\u603b\u7ed3\u4e86\u5bfc\u81f4\u4e0d\u540c\u6a21\u578b\u548c\u56fd\u5bb6\u95f4\u62d2\u7edd\u5206\u5e03\u5dee\u5f02\u7684\u4e3b\u8981\u5c5e\u6027\uff0c\u4e3a\u7406\u89e3LLM\u62d2\u7edd\u884c\u4e3a\u4e2d\u7684\u653f\u6cbb\u5ba1\u67e5\u56e0\u7d20\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2511.23184", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23184", "abs": "https://arxiv.org/abs/2511.23184", "authors": ["Wenna Lai", "Haoran Xie", "Guandong Xu", "Qing Li", "S. Joe Qin"], "title": "Listwise Preference Optimization with Element-wise Confusions for Aspect Sentiment Quad Prediction", "comment": "11 pages, 7 figures, and 6 tables", "summary": "Aspect sentiment quad prediction (ASQP) is inherently challenging to predict a structured quadruple with four core sentiment elements, including aspect term (a), aspect category (c), opinion term (o), and sentiment polarity (s). Prior methods relying on marker-based prediction struggle with modeling the intricate relationships among elements and experience sharp performance declines when predicting higher-order elements (e.g., c and s) under standard supervised fine-tuning. To address these limitations, we employ reasoning-based generation to output both the quadruple and a natural language rationale under element prefixes within a unified template, encouraging explicit relational reasoning and interpretability. To further enhance element-wise alignment, we introduce a listwise preference optimization framework for improving structural validity and relational coherence. Specifically, we generate element-wise confusable candidates via syntactic and semantic proximity, then train the model with listwise objectives to prefer the gold candidates over closely competing alternatives. Extensive experiments on four benchmark datasets demonstrate that our framework effectively improves quadruple prediction accuracy and explanation consistency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a8\u7406\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u5217\u8868\u504f\u597d\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u65b9\u9762\u60c5\u611f\u56db\u5143\u7ec4\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u89e3\u91ca\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6807\u8bb0\u7684\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5efa\u6a21\u56db\u5143\u7ec4\u5143\u7d20\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff0c\u4e14\u5728\u6807\u51c6\u76d1\u7763\u5fae\u8c03\u4e0b\u5bf9\u9ad8\u9636\u5143\u7d20\uff08\u5982\u7c7b\u522b\u548c\u60c5\u611f\u6781\u6027\uff09\u9884\u6d4b\u6027\u80fd\u4e0b\u964d\u660e\u663e\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u63a8\u7406\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u7edf\u4e00\u6a21\u677f\u4e2d\u8f93\u51fa\u56db\u5143\u7ec4\u548c\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff1b\u5f15\u5165\u5217\u8868\u504f\u597d\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u53e5\u6cd5\u548c\u8bed\u4e49\u90bb\u8fd1\u751f\u6210\u5143\u7d20\u7ea7\u6df7\u6dc6\u5019\u9009\uff0c\u7136\u540e\u7528\u5217\u8868\u76ee\u6807\u8bad\u7ec3\u6a21\u578b\u4ee5\u504f\u597d\u9ec4\u91d1\u5019\u9009\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u56db\u5143\u7ec4\u9884\u6d4b\u51c6\u786e\u6027\u548c\u89e3\u91ca\u4e00\u81f4\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u63a8\u7406\u751f\u6210\u548c\u5217\u8868\u504f\u597d\u4f18\u5316\u6846\u67b6\u80fd\u591f\u66f4\u597d\u5730\u5efa\u6a21\u5143\u7d20\u95f4\u5173\u7cfb\uff0c\u63d0\u5347\u7ed3\u6784\u5316\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.23225", "categories": ["cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.23225", "abs": "https://arxiv.org/abs/2511.23225", "authors": ["Guang Liang", "Jie Shao", "Ningyuan Tang", "Xinyao Liu", "Jianxin Wu"], "title": "TWEO: Transformers Without Extreme Outliers Enables FP8 Training And Quantization For Dummies", "comment": null, "summary": "Native FP8 support in modern hardware is essential for training large Transformers, but is severely hindered by extreme activation outliers. Existing solutions either rely on complex mixed-precision engineering or invasive architectural modifications. This paper fundamentally challenges the conventional wisdom that outliers are data-driven. We demonstrate that extreme outliers are a data-independent, mechanically-produced artifact of training, originating from specific structural properties of the weight matrices (i.e., colinearity). Based on this insight, we propose TWEO (Transformers Without Extreme Outliers), a novel, non-invasive loss function. TWEO effectively prevents extreme outliers via a very simple loss term, which reduces outliers from 10000+ to less than 20. TWEO then enables full-model FP8 pre-training with neither engineering tricks nor architectural changes for both LLM and ViT. When standard FP8 training catastrophically collapses, TWEO achieves performance comparable to the BF16 baseline while delivering a 36% increase in training throughput. Also, TWEO enables a new quantization paradigm. Hardware-friendly W8A8 per-tensor static quantization of LLMs, previously considered completely unusable due to outliers, achieves SOTA performance for the first time on TWEO-trained models.", "AI": {"tldr": "TWEO\u662f\u4e00\u79cd\u65b0\u578b\u975e\u4fb5\u5165\u5f0f\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u6d88\u9664Transformer\u8bad\u7ec3\u4e2d\u6781\u7aef\u5f02\u5e38\u503c\uff0c\u5b9e\u73b0\u5168\u6a21\u578bFP8\u9884\u8bad\u7ec3\uff0c\u65e0\u9700\u5de5\u7a0b\u6280\u5de7\u6216\u67b6\u6784\u4fee\u6539\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u5e76\u5b9e\u73b0\u786c\u4ef6\u53cb\u597d\u7684W8A8\u91cf\u5316\u3002", "motivation": "\u73b0\u4ee3\u786c\u4ef6\u539f\u751f\u652f\u6301FP8\u5bf9\u4e8e\u8bad\u7ec3\u5927\u578bTransformer\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6781\u7aef\u6fc0\u6d3b\u5f02\u5e38\u503c\u4e25\u91cd\u963b\u788d\u4e86\u5176\u5e94\u7528\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u4f9d\u8d56\u590d\u6742\u7684\u6df7\u5408\u7cbe\u5ea6\u5de5\u7a0b\uff0c\u8981\u4e48\u9700\u8981\u4fb5\u5165\u5f0f\u67b6\u6784\u4fee\u6539\u3002\u8bba\u6587\u6311\u6218\u4e86\u5f02\u5e38\u503c\u662f\u6570\u636e\u9a71\u52a8\u7684\u4f20\u7edf\u89c2\u5ff5\u3002", "method": "\u8bba\u6587\u9996\u5148\u8bc1\u660e\u6781\u7aef\u5f02\u5e38\u503c\u662f\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u673a\u68b0\u4ea7\u751f\u7684\u4f2a\u5f71\uff0c\u6e90\u4e8e\u6743\u91cd\u77e9\u9635\u7684\u7279\u5b9a\u7ed3\u6784\u7279\u6027\uff08\u5373\u5171\u7ebf\u6027\uff09\u3002\u57fa\u4e8e\u8fd9\u4e00\u6d1e\u5bdf\uff0c\u63d0\u51fa\u4e86TWEO\uff08Transformers Without Extreme Outliers\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u975e\u4fb5\u5165\u5f0f\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u635f\u5931\u9879\u6709\u6548\u9632\u6b62\u6781\u7aef\u5f02\u5e38\u503c\u3002", "result": "TWEO\u5c06\u5f02\u5e38\u503c\u4ece10000+\u51cf\u5c11\u5230\u5c0f\u4e8e20\uff0c\u5b9e\u73b0\u4e86\u5168\u6a21\u578bFP8\u9884\u8bad\u7ec3\uff08\u5305\u62ecLLM\u548cViT\uff09\uff0c\u65e0\u9700\u5de5\u7a0b\u6280\u5de7\u6216\u67b6\u6784\u4fee\u6539\u3002\u5728\u6807\u51c6FP8\u8bad\u7ec3\u707e\u96be\u6027\u5d29\u6e83\u7684\u60c5\u51b5\u4e0b\uff0cTWEO\u5b9e\u73b0\u4e86\u4e0eBF16\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u534736%\u3002\u6b64\u5916\uff0cTWEO\u5b9e\u73b0\u4e86\u65b0\u7684\u91cf\u5316\u8303\u5f0f\uff1a\u786c\u4ef6\u53cb\u597d\u7684W8A8\u6bcf\u5f20\u91cf\u9759\u6001\u91cf\u5316\u9996\u6b21\u5728TWEO\u8bad\u7ec3\u6a21\u578b\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "conclusion": "TWEO\u901a\u8fc7\u63ed\u793a\u5f02\u5e38\u503c\u7684\u673a\u68b0\u4ea7\u751f\u673a\u5236\u5e76\u63d0\u4f9b\u7b80\u5355\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ece\u6839\u672c\u4e0a\u89e3\u51b3\u4e86FP8\u8bad\u7ec3\u4e2d\u7684\u5f02\u5e38\u503c\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684FP8\u8bad\u7ec3\u548c\u5148\u8fdb\u7684\u91cf\u5316\u6027\u80fd\uff0c\u4e3aTransformer\u8bad\u7ec3\u548c\u90e8\u7f72\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.23235", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23235", "abs": "https://arxiv.org/abs/2511.23235", "authors": ["Praveen Gatla", "Anushka", "Nikita Kanwar", "Gouri Sahoo", "Rajesh Kumar Mundotiya"], "title": "Tourism Question Answer System in Indian Language using Domain-Adapted Foundation Models", "comment": null, "summary": "This article presents the first comprehensive study on designing a baseline extractive question-answering (QA) system for the Hindi tourism domain, with a specialized focus on the Varanasi-a cultural and spiritual hub renowned for its Bhakti-Bhaav (devotional ethos). Targeting ten tourism-centric subdomains-Ganga Aarti, Cruise, Food Court, Public Toilet, Kund, Museum, General, Ashram, Temple and Travel, the work addresses the absence of language-specific QA resources in Hindi for culturally nuanced applications. In this paper, a dataset comprising 7,715 Hindi QA pairs pertaining to Varanasi tourism was constructed and subsequently augmented with 27,455 pairs generated via Llama zero-shot prompting. We propose a framework leveraging foundation models-BERT and RoBERTa, fine-tuned using Supervised Fine-Tuning (SFT) and Low-Rank Adaptation (LoRA), to optimize parameter efficiency and task performance. Multiple variants of BERT, including pre-trained languages (e.g., Hindi-BERT), are evaluated to assess their suitability for low-resource domain-specific QA. Evaluation metrics - F1, BLEU, and ROUGE-L - highlight trade-offs between answer precision and linguistic fluency. Experiments demonstrate that LoRA-based fine-tuning achieves competitive performance (85.3\\% F1) while reducing trainable parameters by 98\\% compared to SFT, striking a balance between efficiency and accuracy. Comparative analysis across models reveals that RoBERTa with SFT outperforms BERT variants in capturing contextual nuances, particularly for culturally embedded terms (e.g., Aarti, Kund). This work establishes a foundational baseline for Hindi tourism QA systems, emphasizing the role of LORA in low-resource settings and underscoring the need for culturally contextualized NLP frameworks in the tourism domain.", "AI": {"tldr": "\u9996\u4e2a\u9488\u5bf9\u5370\u5730\u8bed\u65c5\u6e38\u9886\u57df\u7684\u62bd\u53d6\u5f0f\u95ee\u7b54\u7cfb\u7edf\u7814\u7a76\uff0c\u4e13\u6ce8\u4e8e\u74e6\u62c9\u7eb3\u897f\u65c5\u6e38\uff0c\u6784\u5efa\u6570\u636e\u96c6\u5e76\u8bc4\u4f30\u591a\u79cdBERT\u53d8\u4f53\uff0c\u53d1\u73b0LoRA\u5fae\u8c03\u5728\u53c2\u6570\u6548\u7387\u4e0e\u6027\u80fd\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002", "motivation": "\u9488\u5bf9\u5370\u5730\u8bed\u65c5\u6e38\u9886\u57df\u7f3a\u4e4f\u8bed\u8a00\u7279\u5b9a\u548c\u6587\u5316\u7ec6\u5fae\u5dee\u522b\u7684\u95ee\u7b54\u7cfb\u7edf\u8d44\u6e90\uff0c\u7279\u522b\u662f\u5728\u74e6\u62c9\u7eb3\u897f\u8fd9\u4e00\u6587\u5316\u7cbe\u795e\u4e2d\u5fc3\uff0c\u9700\u8981\u5efa\u7acb\u57fa\u7840\u7cfb\u7edf\u6765\u652f\u6301\u65c5\u6e38\u76f8\u5173\u7684\u4fe1\u606f\u67e5\u8be2\u3002", "method": "\u6784\u5efa\u5305\u542b7,715\u4e2a\u5370\u5730\u8bed\u95ee\u7b54\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7Llama\u96f6\u6837\u672c\u63d0\u793a\u751f\u621027,455\u4e2a\u989d\u5916\u5bf9\u3002\u4f7f\u7528BERT\u548cRoBERTa\u7b49\u57fa\u7840\u6a21\u578b\uff0c\u91c7\u7528\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u4f4e\u79e9\u9002\u5e94(LoRA)\u8fdb\u884c\u5fae\u8c03\uff0c\u8bc4\u4f30\u591a\u79cdBERT\u53d8\u4f53\u5728\u4f4e\u8d44\u6e90\u9886\u57df\u7279\u5b9aQA\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "LoRA\u5fae\u8c03\u8fbe\u523085.3%\u7684F1\u5206\u6570\uff0c\u540c\u65f6\u5c06\u53ef\u8bad\u7ec3\u53c2\u6570\u51cf\u5c1198%\uff0c\u5728\u6548\u7387\u4e0e\u51c6\u786e\u6027\u95f4\u53d6\u5f97\u5e73\u8861\u3002RoBERTa\u7ed3\u5408SFT\u5728\u6355\u6349\u6587\u5316\u5d4c\u5165\u672f\u8bed\uff08\u5982Aarti\u3001Kund\uff09\u7684\u4e0a\u4e0b\u6587\u7ec6\u5fae\u5dee\u522b\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002\u8bc4\u4f30\u6307\u6807\u663e\u793a\u7b54\u6848\u7cbe\u786e\u5ea6\u4e0e\u8bed\u8a00\u6d41\u7545\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5370\u5730\u8bed\u65c5\u6e38\u95ee\u7b54\u7cfb\u7edf\u5efa\u7acb\u4e86\u57fa\u7840\u57fa\u51c6\uff0c\u5f3a\u8c03LoRA\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u7a81\u663e\u4e86\u65c5\u6e38\u9886\u57df\u9700\u8981\u6587\u5316\u60c5\u5883\u5316\u7684NLP\u6846\u67b6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.23271", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23271", "abs": "https://arxiv.org/abs/2511.23271", "authors": ["Jiancheng Dong", "Pengyue Jia", "Jingyu Peng", "Maolin Wang", "Yuhao Wang", "Lixin Su", "Xin Sun", "Shuaiqiang Wang", "Dawei Yin", "Xiangyu Zhao"], "title": "Behavior-Equivalent Token: Single-Token Replacement for Long Prompts in LLMs", "comment": "15 pages, 5 figures", "summary": "Carefully engineered system prompts play a critical role in guiding the behavior of LLM agents, but their considerable length introduces significant drawbacks, including increased inference latency, higher computational cost, and reduced effective context length. This raises the question of whether such lengthy prompts can be replaced by a drastically reduced number of tokens while preserving their behavioral effect on downstream tasks. To enable this, we propose a lightweight three-stage training framework that learns a single prompt-specific Behavior-Equivalent token ([BE]). The framework first trains [BE] to encode the natural-language content of the original system prompt via reconstruction, and then distills the prompt 's downstream behavior into this single token. Importantly, our method requires no access to model internals, no auxiliary compression models, and no labeled responses. Empirical evaluations on three datasets show that a single [BE] token achieves up to a 3000x reduction in prompt length, while retaining about 98% of the downstream performance of the original system prompts. This substantially reduces inference cost and leaves almost the entire context window available for user inputs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e09\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u5355\u4e2a[BE]\u4ee4\u724c\u66ff\u4ee3\u5197\u957f\u7cfb\u7edf\u63d0\u793a\uff0c\u5b9e\u73b03000\u500d\u957f\u5ea6\u538b\u7f29\uff0c\u4fdd\u755998%\u4e0b\u6e38\u6027\u80fd", "motivation": "\u5197\u957f\u7684\u7cfb\u7edf\u63d0\u793a\u4f1a\u589e\u52a0\u63a8\u7406\u5ef6\u8fdf\u3001\u8ba1\u7b97\u6210\u672c\u548c\u51cf\u5c11\u6709\u6548\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u9700\u8981\u5bfb\u627e\u65e2\u80fd\u538b\u7f29\u63d0\u793a\u957f\u5ea6\u53c8\u80fd\u4fdd\u6301\u884c\u4e3a\u6548\u679c\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u4e09\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a1) \u901a\u8fc7\u91cd\u6784\u8bad\u7ec3[BE]\u4ee4\u724c\u7f16\u7801\u539f\u59cb\u7cfb\u7edf\u63d0\u793a\u7684\u81ea\u7136\u8bed\u8a00\u5185\u5bb9\uff1b2) \u5c06\u63d0\u793a\u7684\u4e0b\u6e38\u884c\u4e3a\u84b8\u998f\u5230\u5355\u4e2a\u4ee4\u724c\u4e2d\uff1b3) \u65e0\u9700\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\u3001\u8f85\u52a9\u538b\u7f29\u6a21\u578b\u6216\u6807\u8bb0\u54cd\u5e94", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5355\u4e2a[BE]\u4ee4\u724c\u53ef\u5b9e\u73b0\u9ad8\u8fbe3000\u500d\u7684\u63d0\u793a\u957f\u5ea6\u538b\u7f29\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cb\u7cfb\u7edf\u63d0\u793a\u7ea698%\u7684\u4e0b\u6e38\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u5e76\u91ca\u653e\u51e0\u4e4e\u5168\u90e8\u4e0a\u4e0b\u6587\u7a97\u53e3", "conclusion": "\u901a\u8fc7\u884c\u4e3a\u7b49\u6548\u4ee4\u724c[BE]\u53ef\u4ee5\u5927\u5e45\u538b\u7f29\u7cfb\u7edf\u63d0\u793a\u957f\u5ea6\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\uff0c\u4e3a\u9ad8\u6548LLM\u4ee3\u7406\u90e8\u7f72\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.23281", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23281", "abs": "https://arxiv.org/abs/2511.23281", "authors": ["Aaron Steiner", "Ralph Peeters", "Christian Bizer"], "title": "MCP vs RAG vs NLWeb vs HTML: A Comparison of the Effectiveness and Efficiency of Different Agent Interfaces to the Web (Technical Report)", "comment": null, "summary": "Large language model agents are increasingly used to automate web tasks such as product search, offer comparison, and checkout. Current research explores different interfaces through which these agents interact with websites, including traditional HTML browsing, retrieval-augmented generation (RAG) over pre-crawled content, communication via Web APIs using the Model Context Protocol (MCP), and natural-language querying through the NLWeb interface. However, no prior work has compared these four architectures within a single controlled environment using identical tasks.\n  To address this gap, we introduce a testbed consisting of four simulated e-shops, each offering its products via HTML, MCP, and NLWeb interfaces. For each interface (HTML, RAG, MCP, and NLWeb) we develop specialized agents that perform the same sets of tasks, ranging from simple product searches and price comparisons to complex queries for complementary or substitute products and checkout processes. We evaluate the agents using GPT 4.1, GPT 5, GPT 5 mini, and Claude Sonnet 4 as underlying LLM. Our evaluation shows that the RAG, MCP and NLWeb agents outperform HTML on both effectiveness and efficiency. Averaged over all tasks, F1 rises from 0.67 for HTML to between 0.75 and 0.77 for the other agents. Token usage falls from about 241k for HTML to between 47k and 140k per task. The runtime per task drops from 291 seconds to between 50 and 62 seconds. The best overall configuration is RAG with GPT 5 achieving an F1 score of 0.87 and a completion rate of 0.79. Also taking cost into consideration, RAG with GPT 5 mini offers a good compromise between API usage fees and performance. Our experiments show the choice of the interaction interface has a substantial impact on both the effectiveness and efficiency of LLM-based web agents.", "AI": {"tldr": "\u6bd4\u8f83\u56db\u79cd\u7f51\u9875\u4ea4\u4e92\u63a5\u53e3\uff08HTML\u6d4f\u89c8\u3001RAG\u3001MCP\u3001NLWeb\uff09\u5728LLM\u4ee3\u7406\u81ea\u52a8\u5316\u7535\u5546\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0RAG\u3001MCP\u548cNLWeb\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edfHTML\u63a5\u53e3\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u63a2\u7d22\u4e86LLM\u4ee3\u7406\u4e0e\u7f51\u7ad9\u4ea4\u4e92\u7684\u4e0d\u540c\u63a5\u53e3\uff0c\u4f46\u7f3a\u4e4f\u5728\u7edf\u4e00\u63a7\u5236\u73af\u5883\u4e0b\u5bf9\u8fd9\u56db\u79cd\u67b6\u6784\uff08HTML\u3001RAG\u3001MCP\u3001NLWeb\uff09\u7684\u7cfb\u7edf\u6bd4\u8f83\u3002", "method": "\u6784\u5efa\u5305\u542b\u56db\u4e2a\u6a21\u62df\u7535\u5546\u7f51\u7ad9\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6bcf\u4e2a\u7f51\u7ad9\u63d0\u4f9bHTML\u3001MCP\u548cNLWeb\u63a5\u53e3\u3002\u4e3a\u6bcf\u79cd\u63a5\u53e3\u5f00\u53d1\u4e13\u7528\u4ee3\u7406\u6267\u884c\u76f8\u540c\u4efb\u52a1\u96c6\uff0c\u4f7f\u7528GPT 4.1\u3001GPT 5\u3001GPT 5 mini\u548cClaude Sonnet 4\u4f5c\u4e3a\u5e95\u5c42LLM\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "RAG\u3001MCP\u548cNLWeb\u4ee3\u7406\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8eHTML\u4ee3\u7406\uff1a\u5e73\u5747F1\u4ece0.67\u63d0\u5347\u52300.75-0.77\uff1b\u4ee4\u724c\u4f7f\u7528\u91cf\u4ece241k\u964d\u81f347k-140k\uff1b\u8fd0\u884c\u65f6\u95f4\u4ece291\u79d2\u964d\u81f350-62\u79d2\u3002\u6700\u4f73\u914d\u7f6e\u662fRAG+GPT 5\uff08F1=0.87\uff0c\u5b8c\u6210\u7387=0.79\uff09\u3002", "conclusion": "\u4ea4\u4e92\u63a5\u53e3\u7684\u9009\u62e9\u5bf9\u57fa\u4e8eLLM\u7684\u7f51\u9875\u4ee3\u7406\u7684\u6548\u679c\u548c\u6548\u7387\u6709\u663e\u8457\u5f71\u54cd\uff0cRAG\u3001MCP\u548cNLWeb\u63a5\u53e3\u76f8\u6bd4\u4f20\u7edfHTML\u6d4f\u89c8\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u5176\u4e2dRAG+GPT 5 mini\u5728\u6210\u672c\u548c\u6027\u80fd\u95f4\u63d0\u4f9b\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2511.23319", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23319", "abs": "https://arxiv.org/abs/2511.23319", "authors": ["Xiang Hu", "Zhanchao Zhou", "Ruiqi Liang", "Zehuan Li", "Wei Wu", "Jianguo Li"], "title": "Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models", "comment": null, "summary": "This work explores the challenge of building ``Machines that Can Remember'', framing long-term memory as the problem of efficient ultra-long context modeling. We argue that this requires three key properties: \\textbf{sparsity}, \\textbf{random-access flexibility}, and \\textbf{length generalization}. To address ultra-long-context modeling, we leverage Hierarchical Sparse Attention (HSA), a novel attention mechanism that satisfies all three properties. We integrate HSA into Transformers to build HSA-UltraLong, which is an 8B-parameter MoE model trained on over 8 trillion tokens and is rigorously evaluated on different tasks with in-domain and out-of-domain context lengths to demonstrate its capability in handling ultra-long contexts. Results show that our model performs comparably to full-attention baselines on in-domain lengths while achieving over 90\\% accuracy on most in-context retrieval tasks with contexts up to 16M. This report outlines our experimental insights and open problems, contributing a foundation for future research in ultra-long context modeling.", "AI": {"tldr": "\u63d0\u51faHSA-UltraLong\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u5c42\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u8d85\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\uff0c\u572816M\u957f\u5ea6\u4e0a\u4e0b\u6587\u4e2d\u4fdd\u630190%\u4ee5\u4e0a\u68c0\u7d22\u51c6\u786e\u7387", "motivation": "\u6784\u5efa\"\u80fd\u8bb0\u4f4f\u7684\u673a\u5668\"\uff0c\u89e3\u51b3\u8d85\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u95ee\u9898\uff0c\u9700\u8981\u6ee1\u8db3\u7a00\u758f\u6027\u3001\u968f\u673a\u8bbf\u95ee\u7075\u6d3b\u6027\u548c\u957f\u5ea6\u6cdb\u5316\u4e09\u4e2a\u5173\u952e\u7279\u6027", "method": "\u63d0\u51fa\u5206\u5c42\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u96c6\u6210\u5230Transformer\u4e2d\u6784\u5efaHSA-UltraLong\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u4e2a8B\u53c2\u6570\u7684MoE\u6a21\u578b\uff0c\u5728\u8d85\u8fc78\u4e07\u4ebftoken\u4e0a\u8bad\u7ec3", "result": "\u6a21\u578b\u5728\u9886\u57df\u5185\u957f\u5ea6\u4e0a\u4e0e\u5168\u6ce8\u610f\u529b\u57fa\u7ebf\u8868\u73b0\u76f8\u5f53\uff0c\u5728\u957f\u8fbe16M\u7684\u4e0a\u4e0b\u6587\u68c0\u7d22\u4efb\u52a1\u4e2d\u8fbe\u523090%\u4ee5\u4e0a\u51c6\u786e\u7387", "conclusion": "HSA-UltraLong\u4e3a\u8d85\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u63d0\u4f9b\u4e86\u57fa\u7840\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u7a00\u758f\u6027\u3001\u968f\u673a\u8bbf\u95ee\u548c\u957f\u5ea6\u6cdb\u5316\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u57fa\u7840"}}
{"id": "2511.23325", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23325", "abs": "https://arxiv.org/abs/2511.23325", "authors": ["Horacio Thompson", "Marcelo Errecalde"], "title": "Tackling a Challenging Corpus for Early Detection of Gambling Disorder: UNSL at MentalRiskES 2025", "comment": "In Iberian Language Evaluation Forum (IberLEF 2025), Zaragoza, Spain", "summary": "Gambling disorder is a complex behavioral addiction that is challenging to understand and address, with severe physical, psychological, and social consequences. Early Risk Detection (ERD) on the Web has become a key task in the scientific community for identifying early signs of mental health behaviors based on social media activity. This work presents our participation in the MentalRiskES 2025 challenge, specifically in Task 1, aimed at classifying users at high or low risk of developing a gambling-related disorder. We proposed three methods based on a CPI+DMC approach, addressing predictive effectiveness and decision-making speed as independent objectives. The components were implemented using the SS3, BERT with extended vocabulary, and SBERT models, followed by decision policies based on historical user analysis. Although it was a challenging corpus, two of our proposals achieved the top two positions in the official results, performing notably in decision metrics. Further analysis revealed some difficulty in distinguishing between users at high and low risk, reinforcing the need to explore strategies to improve data interpretation and quality, and to promote more transparent and reliable ERD systems for mental disorders.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53c2\u4e0eMentalRiskES 2025\u6311\u6218\u8d5bTask 1\uff0c\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8eCPI+DMC\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528SS3\u3001BERT\u548cSBERT\u6a21\u578b\u8fdb\u884c\u8d4c\u535a\u969c\u788d\u98ce\u9669\u5206\u7c7b\uff0c\u5176\u4e2d\u4e24\u79cd\u65b9\u6cd5\u5728\u5b98\u65b9\u7ed3\u679c\u4e2d\u6392\u540d\u524d\u4e8c\u3002", "motivation": "\u8d4c\u535a\u969c\u788d\u662f\u4e00\u79cd\u590d\u6742\u7684\u884c\u4e3a\u6210\u763e\uff0c\u5177\u6709\u4e25\u91cd\u7684\u751f\u7406\u3001\u5fc3\u7406\u548c\u793e\u4f1a\u540e\u679c\u3002\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u6d3b\u52a8\u7684\u65e9\u671f\u98ce\u9669\u68c0\u6d4b\u5df2\u6210\u4e3a\u8bc6\u522b\u5fc3\u7406\u5065\u5eb7\u884c\u4e3a\u65e9\u671f\u8ff9\u8c61\u7684\u5173\u952e\u4efb\u52a1\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8eCPI+DMC\uff08\u53ef\u80fd\u6307\u5185\u5bb9\u5904\u7406+\u51b3\u7b56\u673a\u5236\u7ec4\u5408\uff09\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528SS3\u3001BERT\uff08\u6269\u5c55\u8bcd\u6c47\u8868\uff09\u548cSBERT\u6a21\u578b\u5904\u7406\u6587\u672c\uff0c\u7136\u540e\u57fa\u4e8e\u5386\u53f2\u7528\u6237\u5206\u6790\u7684\u51b3\u7b56\u7b56\u7565\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u8bed\u6599\u5e93\u4e2d\uff0c\u4e24\u79cd\u63d0\u6848\u5728\u5b98\u65b9\u7ed3\u679c\u4e2d\u83b7\u5f97\u4e86\u524d\u4e24\u540d\u4f4d\u7f6e\uff0c\u5728\u51b3\u7b56\u6307\u6807\u4e0a\u8868\u73b0\u7a81\u51fa\u3002\u4f46\u5206\u6790\u663e\u793a\u533a\u5206\u9ad8\u98ce\u9669\u548c\u4f4e\u98ce\u9669\u7528\u6237\u5b58\u5728\u4e00\u5b9a\u56f0\u96be\u3002", "conclusion": "\u9700\u8981\u63a2\u7d22\u6539\u8fdb\u6570\u636e\u89e3\u91ca\u548c\u8d28\u91cf\u7684\u7b56\u7565\uff0c\u4fc3\u8fdb\u66f4\u900f\u660e\u53ef\u9760\u7684\u65e9\u671f\u98ce\u9669\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4ee5\u66f4\u597d\u5730\u8bc6\u522b\u8d4c\u535a\u969c\u788d\u98ce\u9669\u3002"}}
{"id": "2511.23335", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23335", "abs": "https://arxiv.org/abs/2511.23335", "authors": ["Shuqi Liu", "Han Wu", "Guanzhi Deng", "Jianshu Chen", "Xiaoyang Wang", "Linqi Song"], "title": "Towards Improving Interpretability of Language Model Generation through a Structured Knowledge Discovery Approach", "comment": null, "summary": "Knowledge-enhanced text generation aims to enhance the quality of generated text by utilizing internal or external knowledge sources. While language models have demonstrated impressive capabilities in generating coherent and fluent text, the lack of interpretability presents a substantial obstacle. The limited interpretability of generated text significantly impacts its practical usability, particularly in knowledge-enhanced text generation tasks that necessitate reliability and explainability. Existing methods often employ domain-specific knowledge retrievers that are tailored to specific data characteristics, limiting their generalizability to diverse data types and tasks. To overcome this limitation, we directly leverage the two-tier architecture of structured knowledge, consisting of high-level entities and low-level knowledge triples, to design our task-agnostic structured knowledge hunter. Specifically, we employ a local-global interaction scheme for structured knowledge representation learning and a hierarchical transformer-based pointer network as the backbone for selecting relevant knowledge triples and entities. By combining the strong generative ability of language models with the high faithfulness of the knowledge hunter, our model achieves high interpretability, enabling users to comprehend the model output generation process. Furthermore, we empirically demonstrate the effectiveness of our model in both internal knowledge-enhanced table-to-text generation on the RotoWireFG dataset and external knowledge-enhanced dialogue response generation on the KdConv dataset. Our task-agnostic model outperforms state-of-the-art methods and corresponding language models, setting new standards on the benchmark.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4efb\u52a1\u65e0\u5173\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u730e\u624b\uff0c\u901a\u8fc7\u5229\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\u7684\u4e24\u5c42\u67b6\u6784\uff08\u9ad8\u5c42\u5b9e\u4f53\u548c\u4f4e\u5c42\u77e5\u8bc6\u4e09\u5143\u7ec4\uff09\u6765\u589e\u5f3a\u6587\u672c\u751f\u6210\u7684\u89e3\u91ca\u6027\uff0c\u5728\u8868\u683c\u5230\u6587\u672c\u751f\u6210\u548c\u5bf9\u8bdd\u54cd\u5e94\u751f\u6210\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u77e5\u8bc6\u589e\u5f3a\u6587\u672c\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u8fd9\u5f71\u54cd\u4e86\u751f\u6210\u6587\u672c\u7684\u5b9e\u9645\u53ef\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u4efb\u52a1\u4e2d\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u9488\u5bf9\u7279\u5b9a\u6570\u636e\u7279\u5f81\u7684\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u68c0\u7d22\u5668\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e0d\u540c\u6570\u636e\u7c7b\u578b\u548c\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4efb\u52a1\u65e0\u5173\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u730e\u624b\uff0c\u76f4\u63a5\u5229\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\u7684\u4e24\u5c42\u67b6\u6784\uff08\u9ad8\u5c42\u5b9e\u4f53\u548c\u4f4e\u5c42\u77e5\u8bc6\u4e09\u5143\u7ec4\uff09\u3002\u91c7\u7528\u5c40\u90e8-\u5168\u5c40\u4ea4\u4e92\u65b9\u6848\u8fdb\u884c\u7ed3\u6784\u5316\u77e5\u8bc6\u8868\u793a\u5b66\u4e60\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u5206\u5c42Transformer\u7684\u6307\u9488\u7f51\u7edc\u4f5c\u4e3a\u4e3b\u5e72\uff0c\u9009\u62e9\u76f8\u5173\u7684\u77e5\u8bc6\u4e09\u5143\u7ec4\u548c\u5b9e\u4f53\u3002\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5927\u751f\u6210\u80fd\u529b\u4e0e\u77e5\u8bc6\u730e\u624b\u7684\u9ad8\u53ef\u4fe1\u5ea6\u76f8\u7ed3\u5408\u3002", "result": "\u5728RotoWireFG\u6570\u636e\u96c6\u4e0a\u7684\u5185\u90e8\u77e5\u8bc6\u589e\u5f3a\u8868\u683c\u5230\u6587\u672c\u751f\u6210\u4efb\u52a1\u548cKdConv\u6570\u636e\u96c6\u4e0a\u7684\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u5bf9\u8bdd\u54cd\u5e94\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u8be5\u4efb\u52a1\u65e0\u5173\u6a21\u578b\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u548c\u76f8\u5e94\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\u548c\u7ed3\u6784\u5316\u77e5\u8bc6\u730e\u624b\u7684\u53ef\u4fe1\u5ea6\uff0c\u8be5\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u89e3\u91ca\u6027\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u7406\u89e3\u6a21\u578b\u8f93\u51fa\u751f\u6210\u8fc7\u7a0b\u3002\u8be5\u65b9\u6cd5\u4e3a\u77e5\u8bc6\u589e\u5f3a\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.23370", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23370", "abs": "https://arxiv.org/abs/2511.23370", "authors": ["Antoine Caubri\u00e8re", "Elodie Gauthier"], "title": "Scaling HuBERT for African Languages: From Base to Large and XL", "comment": "Journ\u00e9e d'\u00e9tudes AFIA-ATALA 2025 : Technologies linguistiques pour les langues peu dot\u00e9es", "summary": "Despite recent progress in multilingual speech processing, African languages remain under-represented in both research and deployed systems, particularly when it comes to strong, open-weight encoders that transfer well under low-resource supervision. Self-supervised learning has proven especially promising in such settings, yet most publicly released models targeting African speech remain at BASE scale, leaving unanswered whether larger encoders, trained exclusively on Africa-centric audio, offer tangible benefits and how model capacity interacts with data composition. This work addresses that gap by introducing SSA-HuBERT-Large (317M parameters) and SSA-HuBERT-XL (964M parameters), the first large models trained solely on African speech, alongside a BASE size counterpart. We release these models as open weights: see https://huggingface.co/collections/Orange/african-speech-foundation-models. By conducting a carefully controlled experimental study focused exclusively on Sub-Saharan languages, covering automatic speech recognition (ASR) and language identification (LID) tasks, we demonstrate that larger architectures significantly improve performance by effectively leveraging large audio datasets.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86SSA-HuBERT-Large\u548cSSA-HuBERT-XL\uff0c\u8fd9\u662f\u9996\u4e2a\u4ec5\u4f7f\u7528\u975e\u6d32\u8bed\u97f3\u8bad\u7ec3\u7684\u5927\u578b\u6a21\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u66f4\u5927\u6a21\u578b\u5728\u975e\u6d32\u8bed\u8a00\u8bed\u97f3\u4efb\u52a1\u4e2d\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1\u591a\u8bed\u8a00\u8bed\u97f3\u5904\u7406\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u975e\u6d32\u8bed\u8a00\u5728\u7814\u7a76\u548c\u90e8\u7f72\u7cfb\u7edf\u4e2d\u4ecd\u7136\u4ee3\u8868\u6027\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u76d1\u7763\u4e0b\u8868\u73b0\u826f\u597d\u7684\u5f00\u653e\u6743\u91cd\u7f16\u7801\u5668\u65b9\u9762\u3002\u73b0\u6709\u516c\u5f00\u6a21\u578b\u591a\u4e3aBASE\u89c4\u6a21\uff0c\u4e0d\u6e05\u695a\u4ec5\u4f7f\u7528\u975e\u6d32\u4e2d\u5fc3\u97f3\u9891\u8bad\u7ec3\u7684\u5927\u578b\u7f16\u7801\u5668\u662f\u5426\u5e26\u6765\u5b9e\u9645\u76ca\u5904\uff0c\u4ee5\u53ca\u6a21\u578b\u5bb9\u91cf\u4e0e\u6570\u636e\u7ec4\u6210\u5982\u4f55\u4ea4\u4e92\u3002", "method": "\u5f15\u5165SSA-HuBERT-Large\uff083.17\u4ebf\u53c2\u6570\uff09\u548cSSA-HuBERT-XL\uff089.64\u4ebf\u53c2\u6570\uff09\u4f5c\u4e3a\u9996\u4e2a\u4ec5\u4f7f\u7528\u975e\u6d32\u8bed\u97f3\u8bad\u7ec3\u7684\u5927\u578b\u6a21\u578b\uff0c\u540c\u65f6\u63d0\u4f9bBASE\u89c4\u6a21\u5bf9\u5e94\u6a21\u578b\u3002\u901a\u8fc7\u4e25\u683c\u63a7\u5236\u5b9e\u9a8c\u7814\u7a76\uff0c\u4e13\u6ce8\u4e8e\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u8bed\u8a00\uff0c\u6db5\u76d6\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u548c\u8bed\u8a00\u8bc6\u522b\uff08LID\uff09\u4efb\u52a1\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u66f4\u5927\u7684\u67b6\u6784\u901a\u8fc7\u6709\u6548\u5229\u7528\u5927\u578b\u97f3\u9891\u6570\u636e\u96c6\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u3002\u6a21\u578b\u4f5c\u4e3a\u5f00\u653e\u6743\u91cd\u53d1\u5e03\u5728Hugging Face\u5e73\u53f0\u4e0a\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u586b\u8865\u4e86\u975e\u6d32\u8bed\u8a00\u8bed\u97f3\u5904\u7406\u9886\u57df\u7684\u7a7a\u767d\uff0c\u8bc1\u660e\u4e86\u4e13\u95e8\u9488\u5bf9\u975e\u6d32\u8bed\u97f3\u8bad\u7ec3\u7684\u5927\u578b\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u76d1\u7763\u4e0b\u7684\u6709\u6548\u6027\uff0c\u4e3a\u975e\u6d32\u8bed\u8a00\u8bed\u97f3\u5904\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u57fa\u7840\u6a21\u578b\u8d44\u6e90\u3002"}}
{"id": "2511.23375", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.23375", "abs": "https://arxiv.org/abs/2511.23375", "authors": ["Alexander Sergeev", "Evgeny Kotelnikov"], "title": "Optimizing Multimodal Language Models through Attention-based Interpretability", "comment": "Accepted for ICAI-2025 conference", "summary": "Modern large language models become multimodal, analyzing various data formats like text and images. While fine-tuning is effective for adapting these multimodal language models (MLMs) to downstream tasks, full fine-tuning is computationally expensive. Parameter-Efficient Fine-Tuning (PEFT) methods address this by training only a small portion of model weights. However, MLMs are difficult to interpret, making it challenging to identify which components are most effective for training to balance efficiency and performance. We propose an attention-based interpretability method for MLMs by analyzing attention scores relative to image tokens. The core idea is to identify attention heads that focus on image key objects. We utilize this information to select optimal model components for PEFT in multimodal models. Our contributions include a method for identifying attention heads associated with image key objects, its application to PEFT for image captioning, and the creation of a new dataset containing images, key object masks, and their textual descriptions. We conducted experiments on MLMs with 2-3 billion parameters to validate the method's effectiveness. By calculating Head Impact (HI) scores we quantify an attention head's focus on key objects, indicating its significance in image understanding. Our fine-tuning experiments demonstrate that adapting layers with the highest HI scores leads to the most significant shifts in metrics compared to pre-trained, randomly selected, or lowest-HI-score layers. This indicates that fine-tuning a small percentage (around 0.01%) of parameters in these crucial layers can substantially influence image understanding capabilities.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684MLMs\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u56fe\u50cf\u5173\u952e\u5bf9\u8c61\u7684\u6ce8\u610f\u529b\u5206\u6570\u6765\u8bc6\u522b\u91cd\u8981\u6ce8\u610f\u529b\u5934\uff0c\u5e76\u5e94\u7528\u4e8e\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u4ec5\u9700\u5fae\u8c03\u7ea60.01%\u53c2\u6570\u5373\u53ef\u663e\u8457\u63d0\u5347\u56fe\u50cf\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\uff08MLMs\uff09\u867d\u7136\u5f3a\u5927\u4f46\u96be\u4ee5\u89e3\u91ca\uff0c\u96be\u4ee5\u786e\u5b9a\u54ea\u4e9b\u7ec4\u4ef6\u5bf9\u8bad\u7ec3\u6700\u6709\u6548\u4ee5\u5e73\u8861\u6548\u7387\u548c\u6027\u80fd\u3002\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u65b9\u6cd5\u867d\u7136\u80fd\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u7f3a\u4e4f\u6307\u5bfc\u9009\u62e9\u54ea\u4e9b\u53c2\u6570\u8fdb\u884c\u5fae\u8c03\u7684\u673a\u5236\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff1a1\uff09\u5206\u6790\u6ce8\u610f\u529b\u5206\u6570\u76f8\u5bf9\u4e8e\u56fe\u50cftoken\u7684\u5173\u7cfb\uff1b2\uff09\u8bc6\u522b\u5173\u6ce8\u56fe\u50cf\u5173\u952e\u5bf9\u8c61\u7684\u6ce8\u610f\u529b\u5934\uff1b3\uff09\u8ba1\u7b97Head Impact\uff08HI\uff09\u5206\u6570\u91cf\u5316\u6ce8\u610f\u529b\u5934\u5bf9\u5173\u952e\u5bf9\u8c61\u7684\u5173\u6ce8\u7a0b\u5ea6\uff1b4\uff09\u5e94\u7528HI\u5206\u6570\u9009\u62e9\u6700\u4f18\u6a21\u578b\u7ec4\u4ef6\u8fdb\u884cPEFT\u3002", "result": "\u57282-30\u4ebf\u53c2\u6570\u7684MLMs\u4e0a\u9a8c\u8bc1\uff1a1\uff09\u5fae\u8c03HI\u5206\u6570\u6700\u9ad8\u7684\u5c42\u80fd\u5e26\u6765\u6700\u663e\u8457\u7684\u6307\u6807\u53d8\u5316\uff1b2\uff09\u76f8\u6bd4\u9884\u8bad\u7ec3\u3001\u968f\u673a\u9009\u62e9\u6216\u6700\u4f4eHI\u5206\u6570\u5c42\uff0c\u9ad8HI\u5206\u6570\u5c42\u7684\u5fae\u8c03\u6548\u679c\u6700\u597d\uff1b3\uff09\u4ec5\u5fae\u8c03\u7ea60.01%\u53c2\u6570\u5373\u53ef\u663e\u8457\u5f71\u54cd\u56fe\u50cf\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6ce8\u610f\u529b\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522bMLMs\u4e2d\u5bf9\u56fe\u50cf\u7406\u89e3\u5173\u952e\u7684\u7ec4\u4ef6\uff0c\u6307\u5bfc\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5728\u6781\u4f4e\u53c2\u6570\u6210\u672c\u4e0b\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u591a\u6a21\u6001\u6a21\u578b\u7684\u9ad8\u6548\u9002\u5e94\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.23391", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.23391", "abs": "https://arxiv.org/abs/2511.23391", "authors": ["Jian Li", "Shenglin Yin", "Yujia Zhang", "Alan Zhao", "Xi Chen", "Xiaohui Zhou", "Pengfei Xu"], "title": "Ambiguity Awareness Optimization: Towards Semantic Disambiguation for Direct Preference Optimization", "comment": "Accepted at EMNLP 2025 main", "summary": "Direct Preference Optimization (DPO) is a widely used reinforcement learning from human feedback (RLHF) method across various domains. Recent research has increasingly focused on the role of token importance in improving DPO effectiveness. It is observed that identical or semantically similar content (defined as ambiguous content) frequently appears within the preference pairs. We hypothesize that the presence of ambiguous content during DPO training may introduce ambiguity, thereby limiting further improvements in alignment. Through mathematical analysis and proof-of-concept experiments, we reveal that ambiguous content may potentially introduce ambiguities, thereby degrading performance. To address this issue, we introduce Ambiguity Awareness Optimization (AAO), a simple yet effective approach that automatically re-weights ambiguous content to reduce ambiguities by calculating semantic similarity from preference pairs. Through extensive experiments, we demonstrate that AAO consistently and significantly surpasses state-of-the-art approaches in performance, without markedly increasing response length, across multiple model scales and widely adopted benchmark datasets, including AlpacaEval 2, MT-Bench, and Arena-Hard. Specifically, AAO outperforms DPO by up to 8.9 points on AlpacaEval 2 and achieves an improvement of by up to 15.0 points on Arena-Hard.", "AI": {"tldr": "AAO\u901a\u8fc7\u81ea\u52a8\u91cd\u52a0\u6743\u504f\u597d\u5bf9\u4e2d\u7684\u6a21\u7cca\u5185\u5bb9\u6765\u51cf\u5c11\u6b67\u4e49\uff0c\u663e\u8457\u63d0\u5347\u4e86DPO\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0DPO\u8bad\u7ec3\u4e2d\u5b58\u5728\u7684\u76f8\u540c\u6216\u8bed\u4e49\u76f8\u4f3c\u5185\u5bb9\uff08\u6a21\u7cca\u5185\u5bb9\uff09\u53ef\u80fd\u5f15\u5165\u6b67\u4e49\uff0c\u9650\u5236\u4e86\u5bf9\u9f50\u6548\u679c\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u63d0\u51faAmbiguity Awareness Optimization (AAO)\uff0c\u901a\u8fc7\u8ba1\u7b97\u504f\u597d\u5bf9\u4e2d\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6765\u81ea\u52a8\u91cd\u52a0\u6743\u6a21\u7cca\u5185\u5bb9\u4ee5\u51cf\u5c11\u6b67\u4e49\u3002", "result": "AAO\u5728AlpacaEval 2\u4e0a\u6bd4DPO\u63d0\u53478.9\u5206\uff0c\u5728Arena-Hard\u4e0a\u63d0\u534715.0\u5206\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\u548c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "AAO\u901a\u8fc7\u89e3\u51b3\u6a21\u7cca\u5185\u5bb9\u5f15\u5165\u7684\u6b67\u4e49\u95ee\u9898\uff0c\u6709\u6548\u63d0\u5347\u4e86DPO\u7684\u6027\u80fd\uff0c\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.23397", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.23397", "abs": "https://arxiv.org/abs/2511.23397", "authors": ["Mahdi Rahmani", "AmirHossein Saffari", "Reyhane Rahmani"], "title": "MegaChat: A Synthetic Persian Q&A Dataset for High-Quality Sales Chatbot Evaluation", "comment": "6 pages, 11 figures, 2 tables", "summary": "Small and medium-sized enterprises (SMEs) in Iran increasingly leverage Telegram for sales, where real-time engagement is essential for conversion. However, developing AI-driven chatbots for this purpose requires large, high-quality question-and-answer (Q&A) datasets, which are typically expensive and resource-intensive to produce, especially for low-resource languages like Persian. In this paper, we introduce MegaChat, the first fully synthetic Persian Q&A dataset designed to evaluate intelligent sales chatbots in Telegram-based e-commerce. We propose a novel, automated multi-agent architecture that generates persona-aware Q&A pairs by collecting data from active Telegram shopping channels. The system employs specialized agents for question generation, validation, and refinement, ensuring the production of realistic and diverse conversational data. To evaluate answer generation, we compare three classic retrieval-augmented generation (RAG) models with our advanced agentic system, which features multi-query retrieval, reranking, and persona-aligned response synthesis. Using GPT-5.1 for evaluation across six quality dimensions, our results show that the agentic architecture outperformed traditional RAG models in 4 out of 5 diverse channels, demonstrating its ability to generate scalable, high-quality datasets without relying on expensive human annotation or complex fine-tuning. MegaChat provides SMEs with an efficient, cost-effective solution for building intelligent customer engagement systems in specialized commercial domains, enabling advancements in multilingual conversational AI for low-resource languages. Download: https://github.com/MegaChat-Tech/MegaChat-DataSet", "AI": {"tldr": "MegaChat\u662f\u9996\u4e2a\u7528\u4e8eTelegram\u7535\u5546\u9500\u552e\u804a\u5929\u673a\u5668\u4eba\u8bc4\u4f30\u7684\u6ce2\u65af\u8bed\u5408\u6210\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u81ea\u52a8\u751f\u6210\uff0c\u65e0\u9700\u6602\u8d35\u7684\u4eba\u5de5\u6807\u6ce8", "motivation": "\u4f0a\u6717\u4e2d\u5c0f\u4f01\u4e1a\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528Telegram\u8fdb\u884c\u9500\u552e\uff0c\u9700\u8981\u5b9e\u65f6\u4e92\u52a8\u804a\u5929\u673a\u5668\u4eba\uff0c\u4f46\u4e3a\u6ce2\u65af\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u521b\u5efa\u9ad8\u8d28\u91cf\u95ee\u7b54\u6570\u636e\u96c6\u6210\u672c\u9ad8\u6602\u4e14\u8d44\u6e90\u5bc6\u96c6", "method": "\u63d0\u51fa\u81ea\u52a8\u5316\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u4ece\u6d3b\u8dc3\u7684Telegram\u8d2d\u7269\u9891\u9053\u6536\u96c6\u6570\u636e\uff0c\u4f7f\u7528\u4e13\u95e8\u7684\u667a\u80fd\u4f53\u8fdb\u884c\u95ee\u9898\u751f\u6210\u3001\u9a8c\u8bc1\u548c\u7cbe\u70bc\uff0c\u751f\u6210\u89d2\u8272\u611f\u77e5\u7684\u95ee\u7b54\u5bf9", "result": "\u4e0e\u4e09\u79cd\u7ecf\u5178\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u578b\u76f8\u6bd4\uff0c\u667a\u80fd\u4f53\u67b6\u6784\u57285\u4e2a\u4e0d\u540c\u9891\u9053\u4e2d\u76844\u4e2a\u8868\u73b0\u66f4\u4f18\uff0c\u5728\u516d\u4e2a\u8d28\u91cf\u7ef4\u5ea6\u4e0a\u7ecfGPT-5.1\u8bc4\u4f30\u663e\u793a\u80fd\u751f\u6210\u53ef\u6269\u5c55\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6", "conclusion": "MegaChat\u4e3a\u4e2d\u5c0f\u4f01\u4e1a\u63d0\u4f9b\u4e86\u5728\u4e13\u4e1a\u5546\u4e1a\u9886\u57df\u6784\u5efa\u667a\u80fd\u5ba2\u6237\u4e92\u52a8\u7cfb\u7edf\u7684\u9ad8\u6548\u3001\u7ecf\u6d4e\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u591a\u8bed\u8a00\u5bf9\u8bddAI\u7684\u53d1\u5c55"}}
