<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 53]
- [cs.IR](#cs.IR) [Total: 13]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Reviewing the Reviewer: Elevating Peer Review Quality through LLM-Guided Feedback](https://arxiv.org/abs/2602.10118)
*Sukannya Purkayastha,Qile Wan,Anne Lauscher,Lizhen Qu,Iryna Gurevych*

Main category: cs.CL

TL;DR: 论文提出一个LLM驱动的框架，通过将同行评审分解为论证段落、结合神经符号模块检测多种问题（如懒惰思维和具体性问题），并生成针对性反馈，从而提升评审质量。


<details>
  <summary>Details</summary>
Motivation: 同行评审是科学质量的核心，但依赖简单启发式（懒惰思维）降低了标准。现有工作将懒惰思维检测视为单标签任务，但评审段落可能同时存在多种问题，包括更广泛的清晰度问题或具体性问题。当前缺乏能够提供基于指南的可操作反馈的方法。

Method: 引入一个LLM驱动的框架：1）将评审分解为论证段落；2）通过神经符号模块结合LLM特征与传统分类器识别问题；3）使用遗传算法优化的特定问题模板生成针对性反馈。

Result: 实验表明该方法优于零样本LLM基线，能将评审质量提升高达92.4%。同时发布了LazyReviewPlus数据集，包含1,309个标注了懒惰思维和具体性问题的句子。

Conclusion: 该框架能有效检测同行评审中的多种问题并生成可操作的改进反馈，显著提升评审质量，为解决科学评审中的懒惰思维问题提供了系统化方法。

Abstract: Peer review is central to scientific quality, yet reliance on simple heuristics -- lazy thinking -- has lowered standards. Prior work treats lazy thinking detection as a single-label task, but review segments may exhibit multiple issues, including broader clarity problems, or specificity issues. Turning detection into actionable improvements requires guideline-aware feedback, which is currently missing. We introduce an LLM-driven framework that decomposes reviews into argumentative segments, identifies issues via a neurosymbolic module combining LLM features with traditional classifiers, and generates targeted feedback using issue-specific templates refined by a genetic algorithm. Experiments show our method outperforms zero-shot LLM baselines and improves review quality by up to 92.4\%. We also release LazyReviewPlus, a dataset of 1,309 sentences labeled for lazy thinking and specificity.

</details>


### [2] [Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens](https://arxiv.org/abs/2602.10229)
*Weihao Liu,Dehai Min,Lu Cheng*

Main category: cs.CL

TL;DR: LT-Tuning是一个新的潜在思维调优框架，通过上下文-预测-融合机制和渐进式课程学习，解决了潜在推理中的特征崩溃和不稳定问题，实现了比现有方法更好的推理性能。


<details>
  <summary>Details</summary>
Motivation: 显式思维链（CoT）要求模型用文本标记表达每个中间步骤，将模型思维限制在离散词汇空间中。而连续潜在空间推理虽然更具鲁棒性和灵活性，但现有方法存在特征崩溃和不稳定性问题，主要源于递归使用隐藏状态作为输入嵌入时的分布不匹配，或依赖辅助模型时的对齐问题。

Method: 提出Latent Thoughts Tuning（LT-Tuning）框架，采用上下文-预测-融合机制，联合利用上下文隐藏状态和词汇嵌入空间的预测语义指导来构建潜在思维。结合渐进式三阶段课程学习流程，能够动态切换潜在和显式思维模式。

Result: 实验表明，该方法优于现有的潜在推理基线方法，有效缓解了特征崩溃问题，实现了鲁棒的推理准确性。

Conclusion: LT-Tuning通过重新定义潜在思维的构建和部署方式，解决了当前潜在推理范式的主要问题，为大型语言模型提供了更稳定和灵活的推理能力。

Abstract: While explicit Chain-of-Thought (CoT) equips Large Language Models (LLMs) with strong reasoning capabilities, it requires models to verbalize every intermediate step in text tokens, constraining the model thoughts to the discrete vocabulary space. Recently, reasoning in continuous latent space has emerged as a promising alternative, enabling more robust inference and flexible computation beyond discrete token constraints. However, current latent paradigms often suffer from feature collapse and instability, stemming from distribution mismatches when recurrently using hidden states as the input embeddings, or alignment issues when relying on assistant models. To address this, we propose Latent Thoughts Tuning (LT-Tuning), a framework that redefines how latent thoughts are constructed and deployed. Instead of relying solely on raw hidden states, our method introduces a Context-Prediction-Fusion mechanism that jointly leveraging contextual hidden states and predictive semantic guidance from the vocabulary embedding space. Combined with a progressive three-stage curriculum learning pipeline, LT-Tuning also enables dynamically switching between latent and explicit thinking modes. Experiments demonstrate that our method outperforms existing latent reasoning baselines, effectively mitigating feature collapse and achieving robust reasoning accuracy.

</details>


### [3] [Learning to Evict from Key-Value Cache](https://arxiv.org/abs/2602.10238)
*Luca Moschella,Laura Manduchi,Ozan Sener*

Main category: cs.CL

TL;DR: KVP：一个基于强化学习的轻量级KV缓存淘汰框架，通过学习预测token的未来效用来自适应管理缓存，无需修改底层LLM。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存淘汰或压缩方法依赖启发式规则（如最近使用或历史注意力分数），这些只是token未来效用的间接代理，且引入计算开销。需要更直接、自适应的方法来预测token对后续解码的效用。

Method: 将KV缓存淘汰重新定义为强化学习问题，训练轻量级的每个注意力头RL代理。这些代理使用预计算的生成轨迹（仅包含key和value向量）进行训练，学习基于未来效用的专门淘汰策略，无需修改底层LLM或增加推理开销。

Result: 在两个不同模型家族上评估，在长上下文基准RULER和多轮对话基准OASST2-4k上显著优于基线方法。零样本测试在标准下游任务（LongBench、BOOLQ、ARC）上表现出良好的泛化能力，能适应超出训练分布和更长上下文长度的情况。

Conclusion: 学习预测token未来效用是自适应KV缓存管理的强大且可扩展范式，KVP框架为LLM高效推理提供了有效的解决方案。

Abstract: The growing size of Large Language Models (LLMs) makes efficient inference challenging, primarily due to the memory demands of the autoregressive Key-Value (KV) cache. Existing eviction or compression methods reduce cost but rely on heuristics, such as recency or past attention scores, which serve only as indirect proxies for a token's future utility and introduce computational overhead. We reframe KV cache eviction as a reinforcement learning (RL) problem: learning to rank tokens by their predicted usefulness for future decoding. To this end, we introduce KV Policy (KVP), a framework of lightweight per-head RL agents trained on pre-computed generation traces using only key and value vectors. Each agent learns a specialized eviction policy guided by future utility, which evaluates the quality of the ranking across all cache budgets, requiring no modifications to the underlying LLM or additional inference. Evaluated across two different model families on the long-context benchmark RULER and the multi-turn dialogue benchmark OASST2-4k, KVP significantly outperforms baselines. Furthermore, zero-shot tests on standard downstream tasks (e.g., LongBench, BOOLQ, ARC) indicate that KVP generalizes well beyond its training distribution and to longer context lengths. These results demonstrate that learning to predict future token utility is a powerful and scalable paradigm for adaptive KV cache management.

</details>


### [4] [On Emergent Social World Models -- Evidence for Functional Integration of Theory of Mind and Pragmatic Reasoning in Language Models](https://arxiv.org/abs/2602.10298)
*Polina Tsvilodub,Jan-Felix Klumpp,Amir Mohammadpour,Jennifer Hu,Michael Franke*

Main category: cs.CL

TL;DR: 本研究通过行为评估和因果机制实验，探索语言模型是否共享计算机制来处理心理理论和语用推理，以检验其是否发展出可跨任务重用的"社会世界模型"。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨语言模型是否发展出可跨任务重用的"社会世界模型"（即心智状态表征），这关系到LM是否具有涌现的社会认知能力。具体来说，研究旨在验证功能整合假说：LM是否共享计算机制来处理一般心理理论和特定语用推理。

Method: 采用行为评估和因果机制实验相结合的方法，借鉴认知神经科学中的功能定位技术。分析LM在七个心理理论子类别上的表现，使用了比先前研究更大规模的功能定位数据集。通过严格的假设驱动统计检验来验证功能整合假说。

Result: 严格的假设驱动统计检验提供了支持功能整合假说的提示性证据，表明语言模型可能发展出相互连接的"社会世界模型"，而非孤立的认知能力。

Conclusion: 本研究为语言模型可能发展出相互连接的社会世界模型提供了初步证据，贡献包括新颖的心理理论功能定位数据、功能定位技术的方论改进，以及对人工系统中社会认知涌现的实证见解。

Abstract: This paper investigates whether LMs recruit shared computational mechanisms for general Theory of Mind (ToM) and language-specific pragmatic reasoning in order to contribute to the general question of whether LMs may be said to have emergent "social world models", i.e., representations of mental states that are repurposed across tasks (the functional integration hypothesis). Using behavioral evaluations and causal-mechanistic experiments via functional localization methods inspired by cognitive neuroscience, we analyze LMs' performance across seven subcategories of ToM abilities (Beaudoin et al., 2020) on a substantially larger localizer dataset than used in prior like-minded work. Results from stringent hypothesis-driven statistical testing offer suggestive evidence for the functional integration hypothesis, indicating that LMs may develop interconnected "social world models" rather than isolated competencies. This work contributes novel ToM localizer data, methodological refinements to functional localization techniques, and empirical insights into the emergence of social cognition in artificial systems.

</details>


### [5] [Are More Tokens Rational? Inference-Time Scaling in Language Models as Adaptive Resource Rationality](https://arxiv.org/abs/2602.10329)
*Zhimin Hu,Riya Roshan,Sashank Varma*

Main category: cs.CL

TL;DR: 研究发现，通过推理时间扩展，大语言模型能够根据任务复杂性自适应调整推理策略，表现出资源理性的涌现特性。


<details>
  <summary>Details</summary>
Motivation: 探索在没有明确计算成本奖励的情况下，通过推理时间扩展（如指令调优模型和大型推理模型）能否自发涌现资源理性行为。

Method: 引入变量归因任务，系统操纵任务复杂性（候选变量数量和试验次数），比较指令调优模型和大型推理模型在逻辑函数（包括XOR和XNOR）上的表现。

Result: 随着复杂性增加，两种模型都从暴力策略转向分析策略。指令调优模型在XOR和XNOR函数上表现下降，而大型推理模型保持稳健。

Conclusion: 资源理性是推理时间扩展本身的涌现特性，即使没有明确的成本奖励，模型也能根据任务复杂性自适应调整推理行为。

Abstract: Human reasoning is shaped by resource rationality -- optimizing performance under constraints. Recently, inference-time scaling has emerged as a powerful paradigm to improve the reasoning performance of Large Language Models by expanding test-time computation. Specifically, instruction-tuned (IT) models explicitly generate long reasoning steps during inference, whereas Large Reasoning Models (LRMs) are trained by reinforcement learning to discover reasoning paths that maximize accuracy. However, it remains unclear whether resource-rationality can emerge from such scaling without explicit reward related to computational costs. We introduce a Variable Attribution Task in which models infer which variables determine outcomes given candidate variables, input-output trials, and predefined logical functions. By varying the number of candidate variables and trials, we systematically manipulate task complexity. Both models exhibit a transition from brute-force to analytic strategies as complexity increases. IT models degrade on XOR and XNOR functions, whereas LRMs remain robust. These findings suggest that models can adjust their reasoning behavior in response to task complexity, even without explicit cost-based reward. It provides compelling evidence that resource rationality is an emergent property of inference-time scaling itself.

</details>


### [6] [The Subjectivity of Respect in Police Traffic Stops: Modeling Community Perspectives in Body-Worn Camera Footage](https://arxiv.org/abs/2602.10339)
*Preni Golazizian,Elnaz Rahmati,Jackson Trager,Zhivar Sourati,Nona Ghazizadeh,Georgios Chochlakis,Jose Alcocer,Kerby Bennett,Aarya Vijay Devnani,Parsa Hejabi,Harry G. Muttram,Akshay Kiran Padte,Mehrshad Saadatinia,Chenhao Wu,Alireza S. Zaibari,Michael Sierra-Arévalo,Nick Weller,Shrikanth Narayanan,Benjamin A. T. Graham,Morteza Dehghani*

Main category: cs.CL

TL;DR: 研究人员创建了首个大规模交通拦截数据集，包含多视角尊重度评分和自由文本理由，开发了视角感知建模框架来预测个性化尊重评分并生成特定理由。


<details>
  <summary>Details</summary>
Motivation: 交通拦截是最常见的警民互动之一，尊重是这些互动的核心维度，影响公众信任和合法性感知。然而，尊重的解释具有主观性，受到生活经验影响，因此社区特定视角至关重要。目前缺乏大规模多视角标注的交通拦截数据集。

Method: 1) 开发基于程序正义理论、LAPD培训材料和实地调查的领域特定评估标准；2) 引入标准驱动的偏好数据构建框架，用于视角一致性对齐；3) 提出视角感知建模框架，从交通拦截记录中预测个性化尊重评分，并为警官和司机生成特定标注者的理由。

Result: 在所有三个标注者群体（警察关联、司法系统受影响、无关联的洛杉矶居民）中，该方法提高了评分预测性能和理由对齐度。视角感知框架使执法部门能更好地理解不同社区的期望。

Conclusion: 该研究提供了首个大规模多视角交通拦截数据集和视角感知建模框架，为执法部门理解不同社区期望、建立公众信任和程序合法性提供了重要工具。

Abstract: Traffic stops are among the most frequent police-civilian interactions, and body-worn cameras (BWCs) provide a unique record of how these encounters unfold. Respect is a central dimension of these interactions, shaping public trust and perceived legitimacy, yet its interpretation is inherently subjective and shaped by lived experience, rendering community-specific perspectives a critical consideration. Leveraging unprecedented access to Los Angeles Police Department BWC footage, we introduce the first large-scale traffic-stop dataset annotated with respect ratings and free-text rationales from multiple perspectives. By sampling annotators from police-affiliated, justice-system-impacted, and non-affiliated Los Angeles residents, we enable the systematic study of perceptual differences across diverse communities. To this end, we (i) develop a domain-specific evaluation rubric grounded in procedural justice theory, LAPD training materials, and extensive fieldwork; (ii) introduce a rubric-driven preference data construction framework for perspective-consistent alignment; and (iii) propose a perspective-aware modeling framework that predicts personalized respect ratings and generates annotator-specific rationales for both officers and civilian drivers from traffic-stop transcripts. Across all three annotator groups, our approach improves both rating prediction performance and rationale alignment. Our perspective-aware framework enables law enforcement to better understand diverse community expectations, providing a vital tool for building public trust and procedural legitimacy.

</details>


### [7] [Geometry-Aware Decoding with Wasserstein-Regularized Truncation and Mass Penalties for Large Language Models](https://arxiv.org/abs/2602.10346)
*Arash Gholami Davoodi,Navid Rezazadeh,Seyed Pouyan Mousavi Davoudi,Pouya Pezeshkpour*

Main category: cs.CL

TL;DR: Top-W是一种基于Wasserstein距离的几何感知截断采样方法，通过平衡保留概率质量与熵，在保持截断分布接近原始分布的同时提升生成多样性与逻辑一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于截断的采样方法主要依赖概率质量和熵等启发式指标，忽略了词元嵌入空间的语义几何结构，限制了在开放生成中平衡多样性与逻辑一致性的能力。

Method: 提出Top-W方法，使用基于Wasserstein距离定义的几何感知截断规则，在词元嵌入空间上保持截断分布接近原始分布。理论推导出固定势能子集更新的闭式解结构，通过线性扫描高效找到最优前缀形式。采用高效几何势能（最近集或k-NN）实现，并与交替解码例程结合，保持标准截断采样接口不变。

Result: 在四个基准测试（GSM8K、GPQA、AlpacaEval、MT-Bench）和三个指令调优模型上的实验表明，Top-W持续优于现有最先进的解码方法，最高提升33.7%。不仅提升准确性导向的性能，还在基于评判的开放生成评估中增强了创造性。

Conclusion: Top-W通过引入语义几何感知的截断采样方法，有效平衡了生成多样性与逻辑一致性，为大型语言模型的解码策略提供了理论严谨且实际高效的改进方案。

Abstract: Large language models (LLMs) must balance diversity and creativity against logical coherence in open-ended generation. Existing truncation-based samplers are effective but largely heuristic, relying mainly on probability mass and entropy while ignoring semantic geometry of the token space. We present Top-W, a geometry-aware truncation rule that uses Wasserstein distance-defined over token-embedding geometry-to keep the cropped distribution close to the original, while explicitly balancing retained probability mass against the entropy of the kept set. Our theory yields a simple closed-form structure for the fixed-potential subset update: depending on the mass-entropy trade-off, the optimal crop either collapses to a single token or takes the form of a one-dimensional prefix that can be found efficiently with a linear scan. We implement Top-W using efficient geometry-based potentials (nearest-set or k-NN) and pair it with an alternating decoding routine that keeps the standard truncation-and-sampling interface unchanged. Extensive experiments on four benchmarks (GSM8K, GPQA, AlpacaEval, and MT-Bench) across three instruction-tuned models show that Top-W consistently outperforms prior state-of-the-art decoding approaches achieving up to 33.7% improvement. Moreover, we find that Top-W not only improves accuracy-focused performance, but also boosts creativity under judge-based open-ended evaluation.

</details>


### [8] [When Less Is More? Diagnosing ASR Predictions in Sardinian via Layer-Wise Decoding](https://arxiv.org/abs/2602.10350)
*Domenico De Cristofaro,Alessandro Vietti,Marianne Pouplier,Aleese Block*

Main category: cs.CL

TL;DR: 研究发现Wav2Vec2模型的中间层比最终层能提供更准确的音素预测，尤其是在低资源语言场景下，截断上层Transformer层能改善音素错误率。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明多语言语音模型的中间层编码了比最终输出层更准确的音素表示，但这种现象在低资源语言中的具体表现和机制尚不清楚。

Method: 使用分层解码策略分析预训练Wav2Vec2模型，以低资源语言Campidanese Sardinian为研究对象，通过截断不同Transformer层来观察音素预测的变化，并进行细粒度对齐分析。

Result: 截断上层Transformer层能显著改善音素错误率，最佳性能出现在倒数第二层而非最终层；中间层预测能更好地保持音素身份、避免过度生成并减少特定类型的音系错误；发现了回归错误现象，即中间层正确的预测在最终层被错误覆盖。

Conclusion: 研究支持将中间层探测作为ASR模型的诊断工具，特别是在低资源场景下，标准评估指标可能无法捕捉语言学上有意义的行为，而中间层分析能揭示深层模型如何泛化或抽象化声学细节。

Abstract: Recent studies have shown that intermediate layers in multilingual speech models often encode more phonetically accurate representations than the final output layer. In this work, we apply a layer-wise decoding strategy to a pretrained Wav2Vec2 model to investigate how phoneme-level predictions evolve across encoder layers, focusing on Campidanese Sardinian, a low-resource language. We show that truncating upper transformer layers leads to improved Phoneme Error Rates (PER), with the best performance achieved not at the final layer, but two layers earlier. Through fine-grained alignment analysis, we find that intermediate predictions better preserve segmental identity, avoid overgeneration, and reduce certain classes of phonological errors. We also introduce the notion of regressive errors, cases where correct predictions at intermediate layers are overwritten by errors at the final layer. These regressions highlight the limitations of surface-level error metrics and reveal how deeper layers may generalize or abstract away from acoustic detail. Our findings support the use of early-layer probing as a diagnostic tool for ASR models, particularly in low-resource settings where standard evaluation metrics may fail to capture linguistically meaningful behavior.

</details>


### [9] [Learning Self-Interpretation from Interpretability Artifacts: Training Lightweight Adapters on Vector-Label Pairs](https://arxiv.org/abs/2602.10352)
*Keenan Pepper,Alex McKenzie,Florin Pop,Stijn Servaes,Martin Leitgab,Mike Vaiana,Judd Rosenblatt,Michael S. A. Graziano,Diogo de Lucena*

Main category: cs.CL

TL;DR: 通过训练轻量级适配器来提升语言模型的自我解释能力，无需修改模型本身，仅需少量参数即可实现跨任务和模型族的可靠自我解释。


<details>
  <summary>Details</summary>
Motivation: 现有的自我解释方法存在超参数敏感性问题，导致结果不可靠。研究者希望找到一种更可靠的方法来让语言模型描述其内部状态。

Method: 训练轻量级适配器来学习可解释性特征，同时保持语言模型完全冻结。使用仅需d_model+1个参数的标量仿射适配器，在多个任务上训练适配器生成特征标签。

Result: 训练后的适配器在多个任务上表现优异：在70B规模上生成稀疏自编码器特征标签的得分超过训练标签本身（71% vs 63%）；主题识别任务中召回率达到94%，而未经训练的基线仅为1%；能够解码多跳推理中未出现在提示或响应中的桥接实体。学习到的偏置向量单独贡献了85%的改进，且更简单的适配器比更复杂的替代方案泛化能力更好。

Conclusion: 自我解释能力随模型规模提升而改善，且无需修改被解释的模型。轻量级适配器方法为语言模型的可解释性提供了一种可靠且高效的解决方案。

Abstract: Self-interpretation methods prompt language models to describe their own internal states, but remain unreliable due to hyperparameter sensitivity. We show that training lightweight adapters on interpretability artifacts, while keeping the LM entirely frozen, yields reliable self-interpretation across tasks and model families. A scalar affine adapter with just $d_\text{model}+1$ parameters suffices: trained adapters generate sparse autoencoder feature labels that outperform the training labels themselves (71% vs 63% generation scoring at 70B scale), identify topics with 94% recall@1 versus 1% for untrained baselines, and decode bridge entities in multi-hop reasoning that appear in neither prompt nor response, surfacing implicit reasoning without chain-of-thought. The learned bias vector alone accounts for 85% of improvement, and simpler adapters generalize better than more expressive alternatives. Controlling for model knowledge via prompted descriptions, we find self-interpretation gains outpace capability gains from 7B to 72B parameters. Our results demonstrate that self-interpretation improves with scale, without modifying the model being interpreted.

</details>


### [10] [Physically Interpretable AlphaEarth Foundation Model Embeddings Enable LLM-Based Land Surface Intelligence](https://arxiv.org/abs/2602.10354)
*Mashrekur Rahman*

Main category: cs.CL

TL;DR: 对Google AlphaEarth卫星基础模型嵌入的全面可解释性分析，发现其能准确映射地表物理特性，并基于此开发了地表智能系统，支持自然语言环境查询的卫星数据检索。


<details>
  <summary>Details</summary>
Motivation: 卫星基础模型生成的密集嵌入在物理可解释性方面理解不足，限制了其在环境决策系统中的集成应用。需要验证这些嵌入是否能准确表示地表物理特性。

Method: 使用1210万个美国大陆样本（2017-2023年），通过线性、非线性和基于注意力的方法分析64维嵌入与26个环境变量的关系。基于验证结果开发了地表智能系统，采用FAISS索引的嵌入数据库和检索增强生成技术。

Result: 嵌入维度能映射到特定地表属性，完整嵌入空间能高保真重建大多数环境变量（12/26变量R²>0.90）。关系具有时空稳定性。开发的地表智能系统在LLM评估中获得3.74±0.77的加权得分。

Conclusion: 卫星基础模型嵌入是具有物理结构的表示，可用于环境和地理空间智能应用，为自然语言环境查询提供卫星数据支持。

Abstract: Satellite foundation models produce dense embeddings whose physical interpretability remains poorly understood, limiting their integration into environmental decision systems. Using 12.1 million samples across the Continental United States (2017--2023), we first present a comprehensive interpretability analysis of Google AlphaEarth's 64-dimensional embeddings against 26 environmental variables spanning climate, vegetation, hydrology, temperature, and terrain. Combining linear, nonlinear, and attention-based methods, we show that individual embedding dimensions map onto specific land surface properties, while the full embedding space reconstructs most environmental variables with high fidelity (12 of 26 variables exceed $R^2 > 0.90$; temperature and elevation approach $R^2 = 0.97$). The strongest dimension-variable relationships converge across all three analytical methods and remain robust under spatial block cross-validation (mean $ΔR^2 = 0.017$) and temporally stable across all seven study years (mean inter-year correlation $r = 0.963$). Building on these validated interpretations, we then developed a Land Surface Intelligence system that implements retrieval-augmented generation over a FAISS-indexed embedding database of 12.1 million vectors, translating natural language environmental queries into satellite-grounded assessments. An LLM-as-Judge evaluation across 360 query--response cycles, using four LLMs in rotating generator, system, and judge roles, achieved weighted scores of $μ= 3.74 \pm 0.77$ (scale 1--5), with grounding ($μ= 3.93$) and coherence ($μ= 4.25$) as the strongest criteria. Our results demonstrate that satellite foundation model embeddings are physically structured representations that can be operationalized for environmental and geospatial intelligence.

</details>


### [11] [Autonomous Continual Learning of Computer-Use Agents for Environment Adaptation](https://arxiv.org/abs/2602.10356)
*Tianci Xue,Zeyi Liao,Tianneng Shi,Zilu Wang,Kai Zhang,Dawn Song,Yu Su,Huan Sun*

Main category: cs.CL

TL;DR: ACuRL：无需人工标注的自主课程强化学习框架，通过环境探索和任务生成实现计算机使用代理的持续适应


<details>
  <summary>Details</summary>
Motivation: 现实数字环境高度多样且动态，导致代理经常遇到未见场景和分布偏移。传统方法依赖昂贵的人工标注来获取高质量的环境基础数据，限制了计算机使用代理的持续学习能力。

Method: 1. 代理先探索目标环境获取初始经验；2. 课程任务生成器利用这些经验和上一轮反馈，合成适合代理当前能力的新任务；3. 引入CUAJudge自动评估器提供可靠奖励信号（与人类判断93%一致）

Result: 1. 在环境和跨环境持续学习中实现4-22%性能提升，且不遗忘现有环境知识；2. 参数更新高度稀疏（约20%），解释有效且鲁棒的适应；3. CUAJudge达到93%的人类判断一致性

Conclusion: ACuRL框架成功解决了计算机使用代理在特定环境中持续学习的挑战，无需人工数据，通过自主课程生成和稀疏更新实现有效适应，为实际部署提供了可行方案。

Abstract: Real-world digital environments are highly diverse and dynamic. These characteristics cause agents to frequently encounter unseen scenarios and distribution shifts, making continual learning in specific environments essential for computer-use agents (CUAs). However, a key challenge lies in obtaining high-quality and environment-grounded agent data without relying on costly human annotation. In this work, we introduce ACuRL, an Autonomous Curriculum Reinforcement Learning framework that continually adapts agents to specific environments with zero human data. The agent first explores target environments to acquire initial experiences. During subsequent iterative training, a curriculum task generator leverages these experiences together with feedback from the previous iteration to synthesize new tasks tailored for the agent's current capabilities. To provide reliable reward signals, we introduce CUAJudge, a robust automatic evaluator for CUAs that achieves 93% agreement with human judgments. Empirically, our method effectively enables both intra-environment and cross-environment continual learning, yielding 4-22% performance gains without catastrophic forgetting on existing environments. Further analyses show highly sparse updates (e.g., 20% parameters), which helps explain the effective and robust adaptation. Our data and code are available at https://github.com/OSU-NLP-Group/ACuRL.

</details>


### [12] [The Alignment Bottleneck in Decomposition-Based Claim Verification](https://arxiv.org/abs/2602.10380)
*Mahmud Elahi Akhter,Federico Ruggeri,Iman Munire Bilal,Rob Procter,Maria Liakata*

Main category: cs.CL

TL;DR: 论文研究发现，结构化声明分解仅在证据精细对齐时有效，标准重复声明级证据方法反而会降低性能，且子声明标签错误类型决定下游鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对结构化声明分解在实际验证复杂声明时效果不一致的问题，作者认为这源于两个被忽视的瓶颈：证据对齐和子声明错误模式。需要深入研究这些因素对分解效果的影响。

Method: 引入包含时间限制证据和人工标注子声明证据范围的新数据集，评估两种证据对齐设置：子声明对齐证据（SAE）和重复声明级证据（SRE）。在不同数据集和领域（PHEMEPlus、MMM-Fact、COVID-Fact）上测试分解效果，并分析噪声子声明标签的错误传播模式。

Result: 分解仅在证据精细且严格对齐时带来显著性能提升，而标准SRE设置不仅无法改善反而经常降低性能。在存在噪声子声明标签时，保守的"弃权"策略相比激进但错误的预测能显著减少错误传播。

Conclusion: 未来的声明分解框架必须优先考虑精确的证据合成，并校准子声明验证模型的标签偏差，特别是在证据对齐和错误处理方面需要更精细的设计。

Abstract: Structured claim decomposition is often proposed as a solution for verifying complex, multi-faceted claims, yet empirical results have been inconsistent. We argue that these inconsistencies stem from two overlooked bottlenecks: evidence alignment and sub-claim error profiles. To better understand these factors, we introduce a new dataset of real-world complex claims, featuring temporally bounded evidence and human-annotated sub-claim evidence spans. We evaluate decomposition under two evidence alignment setups: Sub-claim Aligned Evidence (SAE) and Repeated Claim-level Evidence (SRE). Our results reveal that decomposition brings significant performance improvement only when evidence is granular and strictly aligned. By contrast, standard setups that rely on repeated claim-level evidence (SRE) fail to improve and often degrade performance as shown across different datasets and domains (PHEMEPlus, MMM-Fact, COVID-Fact). Furthermore, we demonstrate that in the presence of noisy sub-claim labels, the nature of the error ends up determining downstream robustness. We find that conservative "abstention" significantly reduces error propagation compared to aggressive but incorrect predictions. These findings suggest that future claim decomposition frameworks must prioritize precise evidence synthesis and calibrate the label bias of sub-claim verification models.

</details>


### [13] [Triggers Hijack Language Circuits: A Mechanistic Analysis of Backdoor Behaviors in Large Language Models](https://arxiv.org/abs/2602.10382)
*Théo Lasnier,Wissam Antoun,Francis Kulumba,Djamé Seddah*

Main category: cs.CL

TL;DR: 该论文首次对语言切换后门进行机制分析，发现后门触发器并非形成独立电路，而是劫持模型已有的语言编码组件。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的后门攻击存在重大安全风险，但触发器在模型内部如何运作的机制仍不清楚。作者旨在理解语言切换后门的内部工作机制。

Method: 使用激活修补技术对GAPperon模型家族（1B、8B、24B参数）进行分析，定位触发器在早期层（7.5-25%深度）的形成过程，并识别处理触发器信息的注意力头。

Result: 触发器激活的注意力头与自然编码输出语言的注意力头高度重叠（Jaccard指数0.18-0.66），表明后门触发器劫持了模型已有的语言组件而非形成独立电路。

Conclusion: 后门检测应监控已知功能组件而非寻找隐藏电路，缓解策略可利用注入行为与自然行为之间的纠缠关系。

Abstract: Backdoor attacks pose significant security risks for Large Language Models (LLMs), yet the internal mechanisms by which triggers operate remain poorly understood. We present the first mechanistic analysis of language-switching backdoors, studying the GAPperon model family (1B, 8B, 24B parameters) which contains triggers injected during pretraining that cause output language switching. Using activation patching, we localize trigger formation to early layers (7.5-25% of model depth) and identify which attention heads process trigger information. Our central finding is that trigger-activated heads substantially overlap with heads naturally encoding output language across model scales, with Jaccard indices between 0.18 and 0.66 over the top heads identified. This suggests that backdoor triggers do not form isolated circuits but instead co-opt the model's existing language components. These findings have implications for backdoor defense: detection methods may benefit from monitoring known functional components rather than searching for hidden circuits, and mitigation strategies could potentially leverage this entanglement between injected and natural behaviors.

</details>


### [14] [When Tables Go Crazy: Evaluating Multimodal Models on French Financial Documents](https://arxiv.org/abs/2602.10384)
*Virginie Mouilleron,Théo Lasnier,Djamé Seddah*

Main category: cs.CL

TL;DR: 本文提出了首个法语金融文档理解多模态基准测试Multimodal Finance Eval，评估发现现有视觉语言模型在文本和表格任务上表现良好（85-90%准确率），但在图表解释（34-62%）和多轮对话推理（约50%）方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在专业非英语领域（特别是金融领域）的可靠性研究不足。金融文档包含密集的监管文本、数字表格和可视化图表，提取错误可能产生现实后果，因此需要专门的评估基准。

Method: 构建了包含1,204个专家验证问题的多模态法语金融文档数据集，涵盖文本提取、表格理解、图表解释和多轮对话推理任务。使用LLM-as-judge协议评估了六个开放权重的视觉语言模型（8B-124B参数）。

Result: 模型在文本和表格任务上表现良好（85-90%准确率），但在图表解释上表现较差（34-62%准确率）。多轮对话揭示了一个严重问题：早期错误会在对话轮次中传播，导致准确率降至约50%，且不受模型大小影响。

Conclusion: 当前视觉语言模型在明确定义的提取任务上有效，但在交互式、多步骤的金融分析中仍然脆弱。Multimodal Finance Eval为这一高风险领域提供了具有挑战性的基准测试，可用于推动相关技术进步。

Abstract: Vision-language models (VLMs) perform well on many document understanding tasks, yet their reliability in specialized, non-English domains remains underexplored. This gap is especially critical in finance, where documents mix dense regulatory text, numerical tables, and visual charts, and where extraction errors can have real-world consequences. We introduce Multimodal Finance Eval, the first multimodal benchmark for evaluating French financial document understanding. The dataset contains 1,204 expert-validated questions spanning text extraction, table comprehension, chart interpretation, and multi-turn conversational reasoning, drawn from real investment prospectuses, KIDs, and PRIIPs. We evaluate six open-weight VLMs (8B-124B parameters) using an LLM-as-judge protocol. While models achieve strong performance on text and table tasks (85-90% accuracy), they struggle with chart interpretation (34-62%). Most notably, multi-turn dialogue reveals a sharp failure mode: early mistakes propagate across turns, driving accuracy down to roughly 50% regardless of model size.
  These results show that current VLMs are effective for well-defined extraction tasks but remain brittle in interactive, multi-step financial analysis. Multimodal Finance Eval offers a challenging benchmark to measure and drive progress in this high-stakes setting.

</details>


### [15] [Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs](https://arxiv.org/abs/2602.10388)
*Zhongzhi Li,Xuansheng Wu,Yijiang Li,Lijie Hu,Ninghao Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为特征激活覆盖（FAC）的新方法来衡量LLM后训练数据的多样性，并基于此开发了FAC Synthesis框架，通过识别缺失特征并生成相应样本来提升数据多样性和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用基于文本的指标来衡量后训练数据多样性，但这些指标只能捕捉语言变化，对决定下游性能的任务相关特征提供弱信号。需要一种能更好量化任务相关特征多样性的方法。

Method: 提出特征激活覆盖（FAC）指标，在可解释的特征空间中衡量数据多样性。基于此开发FAC Synthesis框架：1）使用稀疏自编码器从种子数据集中识别缺失特征；2）生成明确反映这些特征的合成样本。

Result: 实验表明，该方法在各种任务（指令遵循、毒性检测、奖励建模和行为引导）上持续提升数据多样性和下游性能。有趣的是，发现在不同模型家族（LLaMA、Mistral、Qwen）之间存在共享的可解释特征空间，支持跨模型知识迁移。

Conclusion: 该工作为探索LLM的数据中心化优化提供了坚实实用的方法论，通过特征空间视角提升数据多样性，有效改善下游任务性能，并揭示了跨模型的特征空间共享现象。

Abstract: The diversity of post-training data is critical for effective downstream performance in large language models (LLMs). Many existing approaches to constructing post-training data quantify diversity using text-based metrics that capture linguistic variation, but such metrics provide only weak signals for the task-relevant features that determine downstream performance. In this work, we introduce Feature Activation Coverage (FAC) which measures data diversity in an interpretable feature space. Building upon this metric, we further propose a diversity-driven data synthesis framework, named FAC Synthesis, that first uses a sparse autoencoder to identify missing features from a seed dataset, and then generates synthetic samples that explicitly reflect these features. Experiments show that our approach consistently improves both data diversity and downstream performance on various tasks, including instruction following, toxicity detection, reward modeling, and behavior steering. Interestingly, we identify a shared, interpretable feature space across model families (i.e., LLaMA, Mistral, and Qwen), enabling cross-model knowledge transfer. Our work provides a solid and practical methodology for exploring data-centric optimization of LLMs.

</details>


### [16] [When are We Worried? Temporal Trends of Anxiety and What They Reveal about Us](https://arxiv.org/abs/2602.10400)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 利用社交媒体数据分析焦虑的时间模式和语言特征，发现焦虑在早晨最高、周末最低，过去时焦虑最高，第三人称和主格代词相关帖子焦虑更高。


<details>
  <summary>Details</summary>
Motivation: 探索社交媒体上焦虑表达的时间模式和语言特征，了解何时以及如何表达焦虑，从而揭示焦虑与时间、人称、时态等因素的关系。

Method: 使用最近创建的词汇-焦虑关联词典分析大量美国和加拿大社交媒体数据（推文），研究焦虑的时间模式（日/周变化）、时态差异（过去/现在/未来）以及人称代词使用中的焦虑表达。

Result: 1. 社交媒体焦虑水平呈现系统性日变化：早晨8点最高（与体内皮质醇高峰一致），中午最低；周末最低，周中最高。2. 焦虑表达在不同时态中差异显著：过去时最高，未来时最低。3. 人称代词使用中：第三人称代词（他/他们）相关帖子比第一、二人称更焦虑；主格代词（我/他/她/他们）相关帖子比宾格代词（我/他/她/他们）更焦虑。

Conclusion: 社交媒体焦虑分析不仅揭示了焦虑的时间模式，还表明不同类型的关注焦点（未来、过去、自我、外向等）与焦虑程度相关，为理解焦虑表达提供了有价值的社会心理洞察。

Abstract: In this short paper, we make use of a recently created lexicon of word-anxiety associations to analyze large amounts of US and Canadian social media data (tweets) to explore *when* we are anxious and what insights that reveals about us. We show that our levels of anxiety on social media exhibit systematic patterns of rise and fall during the day -- highest at 8am (in-line with when we have high cortisol levels in the body) and lowest around noon. Anxiety is lowest on weekends and highest mid-week. We also examine anxiety in past, present, and future tense sentences to show that anxiety is highest in past tense and lowest in future tense. Finally, we examine the use of anxiety and calmness words in posts that contain pronouns to show: more anxiety in 3rd person pronouns (he, they) posts than 1st and 2nd person pronouns and higher anxiety in posts with subject pronouns (I, he, she, they) than object pronouns (me, him, her, them). Overall, these trends provide valuable insights on not just when we are anxious, but also how different types of focus (future, past, self, outward, etc.) are related to anxiety.

</details>


### [17] [EVOKE: Emotion Vocabulary Of Korean and English](https://arxiv.org/abs/2602.10414)
*Yoonwon Jung,Hagyeong Shin,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: EVOKE是一个英韩情感词汇平行数据集，包含1,427个韩语词和1,399个英语词，提供多对多翻译、语言特有情感词识别、多义性分析和隐喻关系标注，是目前最全面的英韩情感词汇资源。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏全面、系统且理论中立的情感词汇数据集，特别是在跨语言（英韩）比较方面。现有资源往往受特定情感理论框架限制，难以满足不同研究需求。

Method: 构建包含1,427个韩语词和1,399个英语词的平行数据集，系统标注819个韩语和924个英语形容词与动词。对每个词的多重含义及其关系进行标注，识别多义情感词和情感相关隐喻。

Result: 创建了目前最全面、系统且理论中立的英韩情感词汇数据集，包含语言特有情感词识别、多对多翻译、多义性分析和隐喻关系标注。数据集公开可用。

Conclusion: EVOKE数据集为情感科学、心理语言学、计算语言学和自然语言处理提供了实用工具，支持研究者根据自身需求和理论视角灵活使用该资源。

Abstract: This paper introduces EVOKE, a parallel dataset of emotion vocabulary in English and Korean. The dataset offers comprehensive coverage of emotion words in each language, in addition to many-to-many translations between words in the two languages and identification of language-specific emotion words. The dataset contains 1,427 Korean words and 1,399 English words, and we systematically annotate 819 Korean and 924 English adjectives and verbs. We also annotate multiple meanings of each word and their relationships, identifying polysemous emotion words and emotion-related metaphors. The dataset is, to our knowledge, the most comprehensive, systematic, and theory-agnostic dataset of emotion words in both Korean and English to date. It can serve as a practical tool for emotion science, psycholinguistics, computational linguistics, and natural language processing, allowing researchers to adopt different views on the resource reflecting their needs and theoretical perspectives. The dataset is publicly available at https://github.com/yoonwonj/EVOKE.

</details>


### [18] [LATA: A Tool for LLM-Assisted Translation Annotation](https://arxiv.org/abs/2602.10454)
*Baorong Huang,Ali Asiri*

Main category: cs.CL

TL;DR: 开发了一个基于LLM的交互式工具，用于构建高质量的阿拉伯语-英语平行语料库，通过模板化提示管理结合人工循环，在保证语言精度的同时提高标注效率。


<details>
  <summary>Details</summary>
Motivation: 传统自动化工具在处理结构差异大的语言对（如阿拉伯语-英语）时，难以捕捉深层语言转换和语义细微差别，而高质量平行语料库构建正从简单句子对齐转向复杂的多层标注任务。

Method: 提出基于LLM的交互式工具，采用模板化提示管理器，在严格JSON输出约束下进行句子分割和对齐。系统将自动化预处理整合到人工循环工作流中，研究人员可通过独立架构优化对齐并应用自定义翻译技术标注。

Result: 该工具通过LLM辅助处理，在保持语言精度的同时提高了标注效率，能够分析专业领域中复杂的翻译现象，弥补了可扩展自动化与专家人工判断所需严格精度之间的差距。

Conclusion: LLM辅助的交互式工具为结构分歧语言对的平行语料库构建提供了有效解决方案，平衡了自动化效率与专家级语言精度需求，特别适用于专业领域的复杂翻译现象分析。

Abstract: The construction of high-quality parallel corpora for translation research has increasingly evolved from simple sentence alignment to complex, multi-layered annotation tasks. This methodological shift presents significant challenges for structurally divergent language pairs, such as Arabic--English, where standard automated tools frequently fail to capture deep linguistic shifts or semantic nuances. This paper introduces a novel, LLM-assisted interactive tool designed to reduce the gap between scalable automation and the rigorous precision required for expert human judgment. Unlike traditional statistical aligners, our system employs a template-based Prompt Manager that leverages large language models (LLMs) for sentence segmentation and alignment under strict JSON output constraints. In this tool, automated preprocessing integrates into a human-in-the-loop workflow, allowing researchers to refine alignments and apply custom translation technique annotations through a stand-off architecture. By leveraging LLM-assisted processing, the tool balances annotation efficiency with the linguistic precision required to analyze complex translation phenomena in specialized domains.

</details>


### [19] [Neuro-Symbolic Synergy for Interactive World Modeling](https://arxiv.org/abs/2602.10480)
*Hongyu Zhao,Siyu Zhou,Haolin Yang,Zengyi Qin,Tianyi Zhou*

Main category: cs.CL

TL;DR: NeSyS框架通过整合LLM的概率语义先验与可执行符号规则，在保持表达能力的同时提升了世界模型的鲁棒性，减少了50%的训练数据而不损失准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为世界模型时经常产生幻觉，尤其是在需要严格遵守确定性转换规则的边缘情况下，而符号世界模型虽然提供逻辑一致性但缺乏语义表达能力。需要弥合这两种方法的差距。

Method: 提出神经符号协同框架，通过交替训练LLM和符号世界模型，让符号模型直接修改LLM的输出概率分布进行约束，神经网络只在符号规则未覆盖的轨迹上进行微调。

Result: 在ScienceWorld、Webshop和Plancraft三个交互环境中的实验表明，NeSyS在世界模型预测准确性和数据效率方面均优于基线方法。

Conclusion: NeSyS成功整合了LLM的语义先验和符号规则的逻辑一致性，实现了表达能力和鲁棒性的平衡，为解决LLM作为世界模型时的幻觉问题提供了有效方案。

Abstract: Large language models (LLMs) exhibit strong general-purpose reasoning capabilities, yet they frequently hallucinate when used as world models (WMs), where strict compliance with deterministic transition rules--particularly in corner cases--is essential. In contrast, Symbolic WMs provide logical consistency but lack semantic expressivity. To bridge this gap, we propose Neuro-Symbolic Synergy (NeSyS), a framework that integrates the probabilistic semantic priors of LLMs with executable symbolic rules to achieve both expressivity and robustness. NeSyS alternates training between the two models using trajectories inadequately explained by the other. Unlike rule-based prompting, the symbolic WM directly constrains the LLM by modifying its output probability distribution. The neural WM is fine-tuned only on trajectories not covered by symbolic rules, reducing training data by 50% without loss of accuracy. Extensive experiments on three distinct interactive environments, i.e., ScienceWorld, Webshop, and Plancraft, demonstrate NeSyS's consistent advantages over baselines in both WM prediction accuracy and data efficiency.

</details>


### [20] [Canvas-of-Thought: Grounding Reasoning via Mutable Structured States](https://arxiv.org/abs/2602.10494)
*Lingzhuang Sun,Yuxia Zhu,Ruitong Liu,Hao Liang,Zheng Sun,Caijun Jia,Honghao He,Yuchen Wu,Siyuan Li,Jingxuan Wei,Xiangxiang Zhang,Bihui Yu,Wentao Zhang*

Main category: cs.CL

TL;DR: 本文提出Canvas-of-Thought方法，通过HTML Canvas作为外部推理基板，实现原子级DOM操作和渲染验证，显著提升多模态大语言模型在复杂任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有Chain-of-Thought方法在多模态推理中存在局限：线性文本序列成为瓶颈，辅助视觉元素被当作静态快照处理，推理历史不可变导致错误修正困难，文本表达缺乏视觉指导限制了在几何、SVG设计等高维领域的推理精度。

Method: 提出Canvas-of-Thought框架，利用HTML Canvas作为外部推理基板，支持原子级DOM的CRUD操作，实现状态原地修订而不破坏上下文；集成基于渲染的批判循环作为硬约束验证器，提供明确的视觉反馈。

Result: 在VCode、RBench-V和MathVista等基准测试中，Canvas-CoT显著优于现有基线方法，为上下文高效的多模态推理建立了新范式。

Conclusion: Canvas-of-Thought通过引入外部可视化推理基板和渲染验证机制，有效解决了传统CoT方法在多模态推理中的局限性，为复杂任务的精确推理提供了更强大的框架。

Abstract: While Chain-of-Thought (CoT) prompting has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), relying solely on linear text sequences remains a bottleneck for complex tasks. We observe that even when auxiliary visual elements are interleaved, they are often treated as static snapshots within a one-dimensional, unstructured reasoning chain. We argue that such approaches treat reasoning history as an immutable stream: correcting a local error necessitates either generating verbose downstream corrections or regenerating the entire context. This forces the model to implicitly maintain and track state updates, significantly increasing token consumption and cognitive load. This limitation is particularly acute in high-dimensional domains, such as geometry and SVG design, where the textual expression of CoT lacks explicit visual guidance, further constraining the model's reasoning precision. To bridge this gap, we introduce \textbf{Canvas-of-Thought (Canvas-CoT)}. By leveraging a HTML Canvas as an external reasoning substrate, Canvas-CoT empowers the model to perform atomic, DOM-based CRUD operations. This architecture enables in-place state revisions without disrupting the surrounding context, allowing the model to explicitly maintain the "ground truth". Furthermore, we integrate a rendering-based critique loop that serves as a hard constraint validator, providing explicit visual feedback to resolve complex tasks that are difficult to articulate through text alone. Extensive experiments on VCode, RBench-V, and MathVista demonstrate that Canvas-CoT significantly outperforms existing baselines, establishing a new paradigm for context-efficient multimodal reasoning.

</details>


### [21] [On the Robustness of Knowledge Editing for Detoxification](https://arxiv.org/abs/2602.10504)
*Ming Dong,Shiyi Tang,Ziyan Peng,Guanyi Chen,Tingting He*

Main category: cs.CL

TL;DR: 本研究提出了一个针对基于知识编辑的解毒方法的鲁棒性评估框架，发现现有的自动毒性分类器评估存在伪解毒问题，并且解毒效果在多种不安全行为联合编辑、跨语言场景中表现有限。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识编辑的解毒方法评估主要依赖自动毒性分类器，隐含假设毒性分数降低反映了真实行为抑制。这种评估方法存在局限性，需要更全面的鲁棒性评估框架来检查解毒方法的可靠性。

Method: 提出了一个面向鲁棒性的评估框架，从三个维度评估基于知识编辑的解毒方法：优化鲁棒性（检查是否存在伪解毒现象）、组合鲁棒性（多个不安全行为联合编辑时的效果）、跨语言鲁棒性（单语和跨语言场景下的有效性）。

Result: 1. 识别出伪解毒是常见失效模式，即表面毒性降低源于退化的生成行为而非真正的不安全内容抑制；2. 当多个不安全行为被联合编辑时，解毒效果会下降；3. 单语和跨语言解毒仅在特定的模型-方法组合下有效；4. 基于知识编辑的解毒方法仅在特定模型、有限解毒目标数量和部分语言中表现鲁棒。

Conclusion: 基于知识编辑的解毒方法在实际应用中存在显著局限性，其鲁棒性高度依赖于模型类型、编辑目标数量和语言选择。需要开发更可靠的评估方法和更鲁棒的解毒技术。

Abstract: Knowledge-Editing-based (KE-based) detoxification has emerged as a promising approach for mitigating harmful behaviours in Large Language Models. Existing evaluations, however, largely rely on automatic toxicity classifiers, implicitly assuming that reduced toxicity scores reflect genuine behavioural suppression. In this work, we propose a robustness-oriented evaluation framework for KE-based detoxification that examines its reliability beyond standard classifier-based metrics along three dimensions: optimisation robustness, compositional robustness, and cross-lingual robustness. We identify pseudo-detoxification as a common failure mode, where apparent toxicity reductions arise from degenerate generation behaviours rather than meaningful suppression of unsafe content. We further show that detoxification effectiveness degrades when multiple unsafe behaviours are edited jointly, and that both monolingual and cross-lingual detoxification remain effective only under specific model-method combinations. Overall, our results indicate that KE-based detoxification is robust only for certain models, limited numbers of detoxification objectives, and a subset of languages.

</details>


### [22] [LHAW: Controllable Underspecification for Long-Horizon Tasks](https://arxiv.org/abs/2602.10525)
*George Pu,Michael S. Lee,Udari Madhushani Sehwag,David J. Lee,Bryan Zhu,Yash Maurya,Mohit Raghavendra,Yuan Xue,Samuel Marc Denton*

Main category: cs.CL

TL;DR: LHAW是一个模块化、数据集无关的合成管道，通过系统性地移除目标、约束、输入和上下文四个维度的信息，将明确定义的任务转化为可控的未指定变体，用于评估长流程代理在模糊情况下的澄清行为。


<details>
  <summary>Details</summary>
Motivation: 长流程工作流代理在真正自主系统中至关重要，但其可靠执行依赖于在模糊情况下寻求澄清的能力。目前缺乏可扩展的、任务无关的框架来系统性地策划和测量模糊性对自定义工作流的影响。

Method: LHAW是一个模块化、数据集无关的合成管道，通过系统性地移除目标、约束、输入和上下文四个维度的信息，将明确定义的任务转化为可控的未指定变体。与依赖LLM预测模糊性的方法不同，LHAW通过实证代理试验验证变体，根据观察到的终端状态差异将变体分类为结果关键型、发散型或良性。

Result: 发布了来自TheAgentCompany、SWE-Bench Pro和MCP-Atlas的285个任务变体，并进行了形式化分析，测量了当前代理在模糊设置中检测、推理和解决未指定性的能力。LHAW为长流程设置中代理澄清行为的成本敏感评估提供了第一个系统框架。

Conclusion: LHAW填补了长流程工作流代理模糊性评估的空白，为开发可靠的自主系统提供了首个系统性的框架，能够评估代理在模糊情况下的澄清行为。

Abstract: Long-horizon workflow agents that operate effectively over extended periods are essential for truly autonomous systems. Their reliable execution critically depends on the ability to reason through ambiguous situations in which clarification seeking is necessary to ensure correct task execution. However, progress is limited by the lack of scalable, task-agnostic frameworks for systematically curating and measuring the impact of ambiguity across custom workflows. We address this gap by introducing LHAW (Long-Horizon Augmented Workflows), a modular, dataset-agnostic synthetic pipeline that transforms any well-specified task into controllable underspecified variants by systematically removing information across four dimensions - Goals, Constraints, Inputs, and Context - at configurable severity levels. Unlike approaches that rely on LLM predictions of ambiguity, LHAW validates variants through empirical agent trials, classifying them as outcome-critical, divergent, or benign based on observed terminal state divergence. We release 285 task variants from TheAgentCompany, SWE-Bench Pro and MCP-Atlas according to our taxonomy alongside formal analysis measuring how current agents detect, reason about, and resolve underspecification across ambiguous settings. LHAW provides the first systematic framework for cost-sensitive evaluation of agent clarification behavior in long-horizon settings, enabling development of reliable autonomous systems.

</details>


### [23] [When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning](https://arxiv.org/abs/2602.10560)
*Leheng Sheng,Yongtao Zhang,Wenchang Ma,Yaorui Shi,Ting Huang,Xiang Wang,An Zhang,Ke Shen,Tat-Seng Chua*

Main category: cs.CL

TL;DR: GRU-Mem 通过引入文本控制的门控机制（更新门和退出门）来改进长上下文推理，解决了 MemAgent 中内存爆炸和无退出机制的问题，实现了更稳定高效的长上下文处理。


<details>
  <summary>Details</summary>
Motivation: 现有方法 MemAgent 在处理长上下文时存在两个关键问题：1）内存会快速膨胀，因为即使在无证据的文本块上也会更新内存；2）循环缺乏退出机制，导致在收集到足够证据后仍进行不必要的计算。

Method: 提出 GRU-Mem，引入两个文本控制的门控机制：更新门控制内存何时更新，退出门控制循环何时退出。通过端到端强化学习中的两个奖励信号 r^{update} 和 r^{exit} 来训练正确的更新和退出行为。

Result: 在各种长上下文推理任务上的实验表明，GRU-Mem 通常优于原始 MemAgent，推理速度最高可加速 400%。

Conclusion: GRU-Mem 通过门控机制解决了长上下文推理中的内存管理和计算效率问题，为 LLMs 处理长上下文提供了一种更稳定高效的解决方案。

Abstract: While reasoning over long context is crucial for various real-world applications, it remains challenging for large language models (LLMs) as they suffer from performance degradation as the context length grows. Recent work MemAgent has tried to tackle this by processing context chunk-by-chunk in an RNN-like loop and updating a textual memory for final answering. However, this naive recurrent memory update faces two crucial drawbacks: (i) memory can quickly explode because it can update indiscriminately, even on evidence-free chunks; and (ii) the loop lacks an exit mechanism, leading to unnecessary computation after even sufficient evidence is collected. To address these issues, we propose GRU-Mem, which incorporates two text-controlled gates for more stable and efficient long-context reasoning. Specifically, in GRU-Mem, the memory only updates when the update gate is open and the recurrent loop will exit immediately once the exit gate is open. To endow the model with such capabilities, we introduce two reward signals $r^{\text{update}}$ and $r^{\text{exit}}$ within end-to-end RL, rewarding the correct updating and exiting behaviors respectively. Experiments on various long-context reasoning tasks demonstrate the effectiveness and efficiency of GRU-Mem, which generally outperforms the vanilla MemAgent with up to 400\% times inference speed acceleration.

</details>


### [24] [Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters](https://arxiv.org/abs/2602.10604)
*Ailin Huang,Ang Li,Aobo Kong,Bin Wang,Binxing Jiao,Bo Dong,Bojun Wang,Boyu Chen,Brian Li,Buyun Ma,Chang Su,Changxin Miao,Changyi Wan,Chao Lou,Chen Hu,Chen Xu,Chenfeng Yu,Chengting Feng,Chengyuan Yao,Chunrui Han,Dan Ma,Dapeng Shi,Daxin Jiang,Dehua Ma,Deshan Sun,Di Qi,Enle Liu,Fajie Zhang,Fanqi Wan,Guanzhe Huang,Gulin Yan,Guoliang Cao,Guopeng Li,Han Cheng,Hangyu Guo,Hanshan Zhang,Hao Nie,Haonan Jia,Haoran Lv,Hebin Zhou,Hekun Lv,Heng Wang,Heung-Yeung Shum,Hongbo Huang,Hongbo Peng,Hongyu Zhou,Hongyuan Wang,Houyong Chen,Huangxi Zhu,Huimin Wu,Huiyong Guo,Jia Wang,Jian Zhou,Jianjian Sun,Jiaoren Wu,Jiaran Zhang,Jiashu Lv,Jiashuo Liu,Jiayi Fu,Jiayu Liu,Jie Cheng,Jie Luo,Jie Yang,Jie Zhou,Jieyi Hou,Jing Bai,Jingcheng Hu,Jingjing Xie,Jingwei Wu,Jingyang Zhang,Jishi Zhou,Junfeng Liu,Junzhe Lin,Ka Man Lo,Kai Liang,Kaibo Liu,Kaijun Tan,Kaiwen Yan,Kaixiang Li,Kang An,Kangheng Lin,Lei Yang,Liang Lv,Liang Zhao,Liangyu Chen,Lieyu Shi,Liguo Tan,Lin Lin,Lina Chen,Luck Ma,Mengqiang Ren,Michael Li,Ming Li,Mingliang Li,Mingming Zhang,Mingrui Chen,Mitt Huang,Na Wang,Peng Liu,Qi Han,Qian Zhao,Qinglin He,Qinxin Du,Qiuping Wu,Quan Sun,Rongqiu Yang,Ruihang Miao,Ruixin Han,Ruosi Wan,Ruyan Guo,Shan Wang,Shaoliang Pang,Shaowen Yang,Shengjie Fan,Shijie Shang,Shiliang Yang,Shiwei Li,Shuangshuang Tian,Siqi Liu,Siye Wu,Siyu Chen,Song Yuan,Tiancheng Cao,Tianchi Yue,Tianhao Cheng,Tianning Li,Tingdan Luo,Wang You,Wei Ji,Wei Yuan,Wei Zhang,Weibo Wu,Weihao Xie,Wen Sun,Wenjin Deng,Wenzhen Zheng,Wuxun Xie,Xiangfeng Wang,Xiangwen Kong,Xiangyu Liu,Xiangyu Zhang,Xiaobo Yang,Xiaojia Liu,Xiaolan Yuan,Xiaoran Jiao,Xiaoxiao Ren,Xiaoyun Zhang,Xin Li,Xin Liu,Xin Wu,Xing Chen,Xingping Yang,Xinran Wang,Xu Zhao,Xuan He,Xuanti Feng,Xuedan Cai,Xuqiang Zhou,Yanbo Yu,Yang Li,Yang Xu,Yanlin Lai,Yanming Xu,Yaoyu Wang,Yeqing Shen,Yibo Zhu,Yichen Lv,Yicheng Cao,Yifeng Gong,Yijing Yang,Yikun Yang,Yin Zhao,Yingxiu Zhao,Yinmin Zhang,Yitong Zhang,Yixuan Zhang,Yiyang Chen,Yongchi Zhao,Yongshen Long,Yongyao Wang,Yousong Guan,Yu Zhou,Yuang Peng,Yuanhao Ding,Yuantao Fan,Yuanzhen Yang,Yuchu Luo,Yudi Zhao,Yue Peng,Yueqiang Lin,Yufan Lu,Yuling Zhao,Yunzhou Ju,Yurong Zhang,Yusheng Li,Yuxiang Yang,Yuyang Chen,Yuzhu Cai,Zejia Weng,Zetao Hong,Zexi Li,Zhe Xie,Zheng Ge,Zheng Gong,Zheng Zeng,Zhenyi Lu,Zhewei Huang,Zhichao Chang,Zhiguo Huang,Zhiheng Hu,Zidong Yang,Zili Wang,Ziqi Ren,Zixin Zhang,Zixuan Wang*

Main category: cs.CL

TL;DR: Step 3.5 Flash是一款稀疏混合专家模型，通过196B参数基础与11B激活参数实现高效推理，在数学、代码和工具使用任务上达到前沿模型性能水平。


<details>
  <summary>Details</summary>
Motivation: 构建智能体时最关键的要素是敏锐的推理能力和快速可靠的执行能力。需要在保持前沿级智能的同时实现计算效率，以便在实际工业环境中部署复杂的智能体。

Method: 采用稀疏混合专家架构，结合3:1滑动窗口/全注意力交替优化和多令牌预测来降低延迟和成本。设计了可扩展的强化学习框架，结合可验证信号和偏好反馈，支持大规模离策略训练下的稳定自我改进。

Result: 在多个基准测试中表现优异：IMO-AnswerBench 85.4%、LiveCodeBench-v6 86.4%、tau2-Bench 88.2%、BrowseComp 69.0%、Terminal-Bench 2.0 51.0%，性能与GPT-5.2 xHigh和Gemini 3.0 Pro等前沿模型相当。

Conclusion: Step 3.5 Flash通过重新定义效率前沿，为在实际工业环境中部署复杂智能体提供了高密度基础，成功平衡了前沿级智能与计算效率。

Abstract: We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.

</details>


### [25] [Online Causal Kalman Filtering for Stable and Effective Policy Optimization](https://arxiv.org/abs/2602.10609)
*Shuo He,Lang Feng,Xin Cheng,Lei Feng,Bo An*

Main category: cs.CL

TL;DR: KPO使用卡尔曼滤波器在线平滑token级重要性采样比率，解决强化学习中高方差问题，在数学推理任务上取得SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型强化学习面临高方差token级重要性采样比率问题，现有方法使用固定序列级比率或单独调整每个token，忽略了序列中token间的时序离策略推导，导致训练不稳定。

Method: 提出在线因果卡尔曼滤波策略优化（KPO），将期望的重要性采样比率建模为跨token演化的潜在状态，应用卡尔曼滤波器基于过去token状态在线自回归更新，保持token级局部结构感知变化同时平滑噪声尖峰。

Result: KPO在具有挑战性的数学推理数据集上相比现有最先进方法取得了更优的结果。

Conclusion: 通过在线因果卡尔曼滤波平滑重要性采样比率，KPO实现了更稳定有效的策略更新，解决了大规模语言模型强化学习中的训练稳定性问题。

Abstract: Reinforcement learning for large language models suffers from high-variance token-level importance sampling (IS) ratios, which would destabilize policy optimization at scale. To improve stability, recent methods typically use a fixed sequence-level IS ratio for all tokens in a sequence or adjust each token's IS ratio separately, thereby neglecting temporal off-policy derivation across tokens in a sequence. In this paper, we first empirically identify that local off-policy deviation is structurally inconsistent at the token level, which may distort policy-gradient updates across adjacent tokens and lead to training collapse. To address the issue, we propose Online Causal Kalman Filtering for stable and effective Policy Optimization (KPO). Concretely, we model the desired IS ratio as a latent state that evolves across tokens and apply a Kalman filter to update this state online and autoregressively based on the states of past tokens, regardless of future tokens. The resulting filtered IS ratios preserve token-wise local structure-aware variation while strongly smoothing noise spikes, yielding more stable and effective policy updates. Experimentally, KPO achieves superior results on challenging math reasoning datasets compared with state-of-the-art counterparts.

</details>


### [26] [How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning](https://arxiv.org/abs/2602.10622)
*Jiahao Yuan,Yike Xu,Jinyong Wen,Baokun Wang,Yang Chen,Xiaotong Lin,Wuliang Huang,Ziyi Gao,Xing Fu,Yu Cheng,Weiqiang Wang*

Main category: cs.CL

TL;DR: 论文研究了注意力掩码对用户表示学习的影响，提出梯度引导软掩码方法改善从因果到双向注意力的训练动态，在工业基准上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 仅解码器大型语言模型越来越多地用作用户表示学习的行为编码器，但注意力掩码对用户嵌入质量的影响尚未得到充分探索。需要系统研究不同注意力掩码（因果、混合、双向）在用户表示学习中的效果。

Method: 提出梯度引导软掩码方法：在优化过程中，通过基于梯度的预预热和线性调度器，逐步开放未来注意力，实现从因果到双向注意力的平滑过渡。在统一的对比学习框架下，使用大规模真实支付宝数据集成长期异构用户行为进行训练。

Result: 在9个工业用户认知基准测试（涵盖预测、偏好和营销敏感性任务）上，该方法相比因果、混合和仅调度器基线，产生更稳定的训练和更高质量的双向表示，同时保持与解码器预训练的兼容性。

Conclusion: 研究强调了掩码设计和训练过渡在适应仅解码器LLMs进行有效用户表示学习中的重要性。梯度引导软掩码方法能改善训练动态，产生更优的双向用户表示。

Abstract: Decoder-only large language models are increasingly used as behavioral encoders for user representation learning, yet the impact of attention masking on the quality of user embeddings remains underexplored. In this work, we conduct a systematic study of causal, hybrid, and bidirectional attention masks within a unified contrastive learning framework trained on large-scale real-world Alipay data that integrates long-horizon heterogeneous user behaviors. To improve training dynamics when transitioning from causal to bidirectional attention, we propose Gradient-Guided Soft Masking, a gradient-based pre-warmup applied before a linear scheduler that gradually opens future attention during optimization. Evaluated on 9 industrial user cognition benchmarks covering prediction, preference, and marketing sensitivity tasks, our approach consistently yields more stable training and higher-quality bidirectional representations compared with causal, hybrid, and scheduler-only baselines, while remaining compatible with decoder pretraining. Overall, our findings highlight the importance of masking design and training transition in adapting decoder-only LLMs for effective user representation learning. Our code is available at https://github.com/JhCircle/Deepfind-GGSM.

</details>


### [27] [UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory](https://arxiv.org/abs/2602.10652)
*Yongshi Ye,Hui Jiang,Feihu Jiang,Tian Lan,Yichao Du,Biao Fu,Xiaodong Shi,Qianghuai Jia,Longyue Wang,Weihua Luo*

Main category: cs.CL

TL;DR: UMEM框架联合优化记忆提取与管理，通过语义邻域建模和GRPO奖励实现记忆泛化，显著提升多轮交互任务性能10.67%


<details>
  <summary>Details</summary>
Motivation: 现有方法主要优化记忆管理而将记忆提取视为静态过程，导致智能体积累实例特定噪声而非鲁棒记忆，泛化能力差

Method: 提出UMEM框架，联合优化LLM同时进行记忆提取和管理；引入语义邻域建模，通过GRPO优化模型，使用邻域级边际效用奖励确保记忆泛化性

Result: 在五个基准测试中显著优于竞争基线，多轮交互任务提升达10.67%；在持续演化过程中保持单调增长曲线

Conclusion: UMEM通过联合优化记忆提取和管理，解决了现有方法的泛化问题，为自演化智能体提供了更鲁棒的记忆框架

Abstract: Self-evolving memory serves as the trainable parameters for Large Language Models (LLMs)-based agents, where extraction (distilling insights from experience) and management (updating the memory bank) must be tightly coordinated. Existing methods predominately optimize memory management while treating memory extraction as a static process, resulting in poor generalization, where agents accumulate instance-specific noise rather than robust memories. To address this, we propose Unified Memory Extraction and Management (UMEM), a self-evolving agent framework that jointly optimizes a Large Language Model to simultaneous extract and manage memories. To mitigate overfitting to specific instances, we introduce Semantic Neighborhood Modeling and optimize the model with a neighborhood-level marginal utility reward via GRPO. This approach ensures memory generalizability by evaluating memory utility across clusters of semantically related queries. Extensive experiments across five benchmarks demonstrate that UMEM significantly outperforms highly competitive baselines, achieving up to a 10.67% improvement in multi-turn interactive tasks. Futhermore, UMEM maintains a monotonic growth curve during continuous evolution. Codes and models will be publicly released.

</details>


### [28] [Benchmarks Are Not That Out of Distribution: Word Overlap Predicts Performance](https://arxiv.org/abs/2602.10657)
*Woojin Chung,Jeonghoon Kim*

Main category: cs.CL

TL;DR: 本文研究发现基准测试性能主要受预训练数据与评估数据之间词级统计模式重叠的影响，词级单字交叉熵与基准性能呈负相关关系。


<details>
  <summary>Details</summary>
Motivation: 理解什么构成高质量预训练数据是语言模型训练的核心问题。本研究旨在探究基准测试性能是否主要由预训练语料库与评估数据集之间的统计模式重叠程度驱动。

Method: 使用词级单字交叉熵和词频统计来衡量重叠程度，在10个零样本基准测试、4个预训练数据集（8.5B到60B tokens）和模型大小（400M到3B参数）范围内进行控制实验。

Result: 结果显示词级单字交叉熵与基准性能存在稳健的负相关关系，表明广泛使用的基准测试受到训练和评估数据之间词重叠的强烈影响。具有相似词级单字交叉熵的更大预训练子集能带来更好的下游结果。

Conclusion: 许多标准基准测试相对于预训练语料库只是弱分布外，简单的词重叠统计就能预测基准性能，这对基准测试的有效性提出了重要问题。

Abstract: Understanding what constitutes high-quality pre-training data remains a central question in language model training. In this work, we investigate whether benchmark performance is primarily driven by the degree of statistical pattern overlap between pre-training corpora and evaluation datasets. We measure this overlap using word-level unigram cross-entropy and word frequency statistics, and perform controlled experiments across $10$ zero-shot benchmarks, $4$ pre-training datasets spanning $8.5\mathrm{B}$ to $60\mathrm{B}$ tokens, and model sizes ranging from $400\mathrm{M}$ to $3\mathrm{B}$ parameters. Our results demonstrate a robust inverse relationship between word-level unigram cross-entropy and benchmark performance, suggesting that widely used benchmarks are strongly influenced by word overlap between training and evaluation data. Thus, larger pre-training subsets with similar word-level unigram cross-entropy yield improved downstream results, indicating that word frequency statistics play an additional role in shaping benchmark scores. Taken together, these results suggest that many standard benchmarks are only weakly out-of-distribution relative to pre-training corpora, so that simple word-overlap statistics predict benchmark performance.

</details>


### [29] [Targeted Syntactic Evaluation of Language Models on Georgian Case Alignment](https://arxiv.org/abs/2602.10661)
*Daniel Gallagher,Gerhard Heyer*

Main category: cs.CL

TL;DR: 该论文评估了基于Transformer的语言模型在格鲁吉亚语分裂作格对齐上的表现，发现模型在作格标记上表现最差，这与作格的低频分布和训练数据缺乏有关。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估Transformer语言模型在处理格鲁吉亚语这种罕见的分裂作格系统时的表现，特别是关注主语和宾语通过主格、作格和与格的各种排列来标记的情况。由于低资源语言的基准测试有限，需要专门的方法来评估模型在这种复杂语法系统上的能力。

Method: 采用基于树库的方法，使用Grew查询语言生成最小对比对。创建了包含370个句法测试的数据集，分为7个任务，每个任务50-70个样本，每个样本测试三种名词形式。评估了5个编码器模型和2个解码器模型，使用词级和/或句子级准确率指标。

Result: 无论具体的句法构成如何，模型在正确分配作格方面表现最差，在正确分配主格方面表现最好。性能与三种形式的总频率分布相关（主格 > 与格 > 作格）。尽管数据稀缺是低资源语言的已知问题，但研究表明作格的高度特定角色以及缺乏可用的训练数据可能导致其表现不佳。

Conclusion: 该研究为低资源语言的句法评估提供了有价值的方法论和公开数据集。作格表现差的原因主要是其低频分布和训练数据不足。这种方法为未来在基准测试有限的语言上进行句法评估提供了有趣的途径。

Abstract: This paper evaluates the performance of transformer-based language models on split-ergative case alignment in Georgian, a particularly rare system for assigning grammatical cases to mark argument roles. We focus on subject and object marking determined through various permutations of nominative, ergative, and dative noun forms. A treebank-based approach for the generation of minimal pairs using the Grew query language is implemented. We create a dataset of 370 syntactic tests made up of seven tasks containing 50-70 samples each, where three noun forms are tested in any given sample. Five encoder- and two decoder-only models are evaluated with word- and/or sentence-level accuracy metrics. Regardless of the specific syntactic makeup, models performed worst in assigning the ergative case correctly and strongest in assigning the nominative case correctly. Performance correlated with the overall frequency distribution of the three forms (NOM > DAT > ERG). Though data scarcity is a known issue for low-resource languages, we show that the highly specific role of the ergative along with a lack of available training data likely contributes to poor performance on this case. The dataset is made publicly available and the methodology provides an interesting avenue for future syntactic evaluations of languages where benchmarks are limited.

</details>


### [30] [Locomo-Plus: Beyond-Factual Cognitive Memory Evaluation Framework for LLM Agents](https://arxiv.org/abs/2602.10715)
*Yifei Li,Weidong Guo,Lingling Zhang,Rongman Xu,Muye Huang,Hui Liu,Lijiao Xu,Yu Xu,Jun Liu*

Main category: cs.CL

TL;DR: 该论文提出了LoCoMo-Plus基准测试，用于评估LLM在长对话中处理隐性约束的认知记忆能力，超越了传统的事实回忆评估。


<details>
  <summary>Details</summary>
Motivation: 现有对话记忆基准主要关注表层事实回忆，但现实对话中合适的回应往往依赖于用户状态、目标或价值观等未明确提及的隐性约束。需要评估模型在"线索-触发语义断开"场景下的认知记忆能力。

Method: 提出了LoCoMo-Plus基准测试，专门设计用于评估认知记忆在线索与触发语义断开情况下的表现。采用基于约束一致性的统一评估框架，替代传统的字符串匹配指标和显式任务类型提示方法。

Result: 实验表明，认知记忆任务对现有骨干模型、基于检索的方法和记忆系统都具有挑战性，能够揭示现有基准测试未能捕捉到的失败情况。证明了传统评估方法在此类场景下的局限性。

Conclusion: 长期对话记忆需要超越事实回忆的认知记忆能力，LoCoMo-Plus基准测试为评估这种能力提供了新框架，揭示了当前模型的局限性，并为未来研究指明了方向。

Abstract: Long-term conversational memory is a core capability for LLM-based dialogue systems, yet existing benchmarks and evaluation protocols primarily focus on surface-level factual recall. In realistic interactions, appropriate responses often depend on implicit constraints such as user state, goals, or values that are not explicitly queried later. To evaluate this setting, we introduce \textbf{LoCoMo-Plus}, a benchmark for assessing cognitive memory under cue--trigger semantic disconnect, where models must retain and apply latent constraints across long conversational contexts. We further show that conventional string-matching metrics and explicit task-type prompting are misaligned with such scenarios, and propose a unified evaluation framework based on constraint consistency. Experiments across diverse backbone models, retrieval-based methods, and memory systems demonstrate that cognitive memory remains challenging and reveals failures not captured by existing benchmarks. Our code and evaluation framework are publicly available at: https://github.com/xjtuleeyf/Locomo-Plus.

</details>


### [31] [Macaron: Controlled, Human-Written Benchmark for Multilingual and Multicultural Reasoning via Template-Filling](https://arxiv.org/abs/2602.10732)
*Alaa Elsetohy,Sama Hadhoud,Haryo Akbarianto Wibowo,Chenxi Whitehouse,Genta Indra Winata,Fajri Koto,Alham Fikri Aji*

Main category: cs.CL

TL;DR: Macaron是一个多语言基准测试，通过模板优先的方法分离推理类型和文化维度，涵盖20种语言和22种文化方面，评估显示推理模式模型在零样本跨语言任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有多语言基准测试存在两个问题：1）翻译数据集保留英语中心场景，缺乏文化基础；2）文化优先数据集缺乏对所需推理类型的控制。需要构建一个能够同时控制推理类型和文化维度的多语言基准测试。

Method: 采用模板优先的方法：首先创建100个语言无关的模板，覆盖7种推理类型和22种文化方面。然后由母语标注者根据这些模板创建场景对齐的英语和本地语言选择题，并系统推导出真/假问题。

Result: 构建了包含11,862个实例的数据集，涵盖20个国家/文化背景、10种文字和20种语言（包括低资源语言）。在21个多语言LLM的零样本评估中，推理模式模型表现最强，英语和本地语言表现接近；而开源模型在本地语言中表现大幅下降，在真/假任务中常接近随机水平。文化基础的数学和计数模板始终最难。

Conclusion: Macaron基准测试成功解决了多语言评估中推理类型和文化维度控制的问题，揭示了当前LLM在跨文化推理任务中的局限性，特别是开源模型在非英语语言和文化特定任务上的表现缺陷，为多语言AI系统评估提供了新工具。

Abstract: Multilingual benchmarks rarely test reasoning over culturally grounded premises: translated datasets keep English-centric scenarios, while culture-first datasets often lack control over the reasoning required. We propose Macaron, a template-first benchmark that factorizes reasoning type and cultural aspect across question languages. Using 100 language-agnostic templates that cover 7 reasoning types, 22 cultural aspects, native annotators create scenario-aligned English and local-language multiple-choice questions and systematically derived True/False questions. Macaron contains 11,862 instances spanning 20 countries/cultural contexts, 10 scripts, and 20 languages (including low-resource ones like Amharic, Yoruba, Zulu, Kyrgyz, and some Arabic dialects). In zero-shot evaluation of 21 multilingual LLMs, reasoning-mode models achieve the strongest performance and near-parity between English and local languages, while open-weight models degrade substantially in local languages and often approach chance on T/F tasks. Culture-grounded mathematical and counting templates are consistently the hardest. The data can be accessed here https://huggingface.co/datasets/AlaaAhmed2444/Macaron.

</details>


### [32] [Reinforced Curriculum Pre-Alignment for Domain-Adaptive VLMs](https://arxiv.org/abs/2602.10740)
*Yuming Yan,Shuo Yang,Kai Tang,Sihong Chen,Yang Zhang,Ke Xu,Dan Hu,Qun Yu,Pengfei Hu,Edith C. H. Ngai*

Main category: cs.CL

TL;DR: RCPA是一种新颖的后训练范式，通过课程感知的渐进调制机制，在保留VLMs通用能力的同时实现领域自适应。


<details>
  <summary>Details</summary>
Motivation: 现有的监督微调方法在适应新领域时会导致灾难性遗忘，而持续预训练由于计算成本高和预训练数据不可用而不现实。基于强化学习的方法在领域适应场景中可能因模型初始领域知识不足而失败。

Method: 提出Reinforced Curriculum Pre-Alignment (RCPA)，采用课程感知的渐进调制机制：早期阶段应用部分输出约束安全地暴露模型于新领域概念；随着模型领域熟悉度增加，逐步过渡到完全生成优化，精炼响应并使其与领域特定偏好对齐。

Result: 在专业领域和通用基准上的广泛实验验证了RCPA的有效性，为构建高性能和领域自适应的VLMs提供了实用途径。

Conclusion: RCPA通过平衡领域知识获取与通用多模态能力保留，成功解决了VLMs在保持通用能力的同时进行领域适应的挑战。

Abstract: Vision-Language Models (VLMs) demonstrate remarkable general-purpose capabilities but often fall short in specialized domains such as medical imaging or geometric problem-solving. Supervised Fine-Tuning (SFT) can enhance performance within a target domain, but it typically causes catastrophic forgetting, limiting its generalization. The central challenge, therefore, is to adapt VLMs to new domains while preserving their general-purpose capabilities. Continual pretraining is effective for expanding knowledge in Large Language Models (LLMs), but it is less feasible for VLMs due to prohibitive computational costs and the unavailability of pretraining data for most open-source models. This necessitates efficient post-training adaptation methods. Reinforcement learning (RL)-based approaches such as Group Relative Policy Optimization (GRPO) have shown promise in preserving general abilities, yet they often fail in domain adaptation scenarios where the model initially lacks sufficient domain knowledge, leading to optimization collapse. To bridge this gap, we propose Reinforced Curriculum Pre-Alignment (RCPA), a novel post-training paradigm that introduces a curriculum-aware progressive modulation mechanism. In the early phase, RCPA applies partial output constraints to safely expose the model to new domain concepts. As the model's domain familiarity increases, training gradually transitions to full generation optimization, refining responses and aligning them with domain-specific preferences. This staged adaptation balances domain knowledge acquisition with the preservation of general multimodal capabilities. Extensive experiments across specialized domains and general benchmarks validate the effectiveness of RCPA, establishing a practical pathway toward building high-performing and domain-adaptive VLMs.

</details>


### [33] [Deep Learning-based Method for Expressing Knowledge Boundary of Black-Box LLM](https://arxiv.org/abs/2602.10801)
*Haotian Sheng,Heyong Wang,Ming Hong,Hongman He,Junqiu Liu*

Main category: cs.CL

TL;DR: 提出LSCL方法，通过深度学习模型基于黑盒LLM的输入问题、输出答案和token概率，构建输入与模型内部知识状态的映射，实现黑盒LLM知识边界的量化表达。


<details>
  <summary>Details</summary>
Motivation: 现有关于知识边界表达的研究主要针对白盒LLM，而黑盒LLM（仅提供API访问）的方法尚待探索。LLM缺乏对其存储内部知识的意识，导致在超出其知识边界的问题上产生幻觉。

Method: 基于知识蒸馏框架，设计深度学习模型LSCL。以黑盒LLM的输入问题、输出答案和token概率作为输入，构建输入与模型内部知识状态的映射，量化表达黑盒LLM的知识边界。

Result: 在多样化公共数据集和多个主流黑盒LLM上的实验表明，LSCL能有效帮助黑盒LLM准确表达知识边界，在准确率和召回率等指标上显著优于现有基线模型。对于不支持token概率访问的黑盒LLM，提出的自适应替代方法性能接近LSCL且优于基线模型。

Conclusion: LSCL方法成功解决了黑盒LLM知识边界表达的问题，通过深度学习模型实现了对黑盒LLM内部知识状态的量化，为减少LLM幻觉提供了有效途径。

Abstract: Large Language Models (LLMs) have achieved remarkable success, however, the emergence of content generation distortion (hallucination) limits their practical applications. The core cause of hallucination lies in LLMs' lack of awareness regarding their stored internal knowledge, preventing them from expressing their knowledge state on questions beyond their internal knowledge boundaries, as humans do. However, existing research on knowledge boundary expression primarily focuses on white-box LLMs, leaving methods suitable for black-box LLMs which offer only API access without revealing internal parameters-largely unexplored. Against this backdrop, this paper proposes LSCL (LLM-Supervised Confidence Learning), a deep learning-based method for expressing the knowledge boundaries of black-box LLMs. Based on the knowledge distillation framework, this method designs a deep learning model. Taking the input question, output answer, and token probability from a black-box LLM as inputs, it constructs a mapping between the inputs and the model' internal knowledge state, enabling the quantification and expression of the black-box LLM' knowledge boundaries. Experiments conducted on diverse public datasets and with multiple prominent black-box LLMs demonstrate that LSCL effectively assists black-box LLMs in accurately expressing their knowledge boundaries. It significantly outperforms existing baseline models on metrics such as accuracy and recall rate. Furthermore, considering scenarios where some black-box LLMs do not support access to token probability, an adaptive alternative method is proposed. The performance of this alternative approach is close to that of LSCL and surpasses baseline models.

</details>


### [34] [Beyond Confidence: The Rhythms of Reasoning in Generative Models](https://arxiv.org/abs/2602.10816)
*Deyuan Liu,Zecheng Wang,Zhanyue Qin,Zhiying Tu,Dianhui Chu,Dianbo Sui*

Main category: cs.CL

TL;DR: 提出Token Constraint Bound (δ_TCB)新指标，量化LLM在保持主导预测不变前提下能承受的最大内部状态扰动，用于评估预测稳定性。


<details>
  <summary>Details</summary>
Motivation: LLM对输入上下文微小变化敏感，影响可靠性。传统指标如准确率和困惑度无法评估局部预测鲁棒性，因为归一化输出概率可能掩盖LLM内部状态对扰动的真实韧性。

Method: 引入Token Constraint Bound (δ_TCB)指标，该指标与输出嵌入空间几何内在相关，量化LLM在主导下一个token预测发生显著变化前能承受的最大内部状态扰动。

Result: 实验表明δ_TCB与有效提示工程相关，能发现在上下文学习和文本生成中被困惑度忽略的关键预测不稳定性。

Conclusion: δ_TCB为分析和潜在改进LLM预测的上下文稳定性提供了原则性的补充方法。

Abstract: Large Language Models (LLMs) exhibit impressive capabilities yet suffer from sensitivity to slight input context variations, hampering reliability. Conventional metrics like accuracy and perplexity fail to assess local prediction robustness, as normalized output probabilities can obscure the underlying resilience of an LLM's internal state to perturbations. We introduce the Token Constraint Bound ($δ_{\mathrm{TCB}}$), a novel metric that quantifies the maximum internal state perturbation an LLM can withstand before its dominant next-token prediction significantly changes. Intrinsically linked to output embedding space geometry, $δ_{\mathrm{TCB}}$ provides insights into the stability of the model's internal predictive commitment. Our experiments show $δ_{\mathrm{TCB}}$ correlates with effective prompt engineering and uncovers critical prediction instabilities missed by perplexity during in-context learning and text generation. $δ_{\mathrm{TCB}}$ offers a principled, complementary approach to analyze and potentially improve the contextual stability of LLM predictions.

</details>


### [35] [I can tell whether you are a Native Hawlêri Speaker! How ANN, CNN, and RNN perform in NLI-Native Language Identification](https://arxiv.org/abs/2602.10832)
*Hardi Garari,Hossein Hassani*

Main category: cs.CL

TL;DR: 本文研究了Sorani库尔德语Hewlêri次方言的母语识别任务，创建了首个该次方言的语音数据集，并通过多种神经网络模型实现了95.92%的高准确率。


<details>
  <summary>Details</summary>
Motivation: 母语识别（NLI）研究通常集中在主流语言如英语和德语上，而对于方言和次方言，特别是像库尔德语这样的低资源语言，存在显著的研究空白。本文旨在填补Sorani库尔德语中Hewlêri次方言的NLI研究空缺。

Method: 收集了约24小时的语音数据，采访了40名Hewlêri次方言的母语和非母语者。创建了三种神经网络模型：ANN、CNN和RNN，通过66个实验进行评估，涵盖1-60秒不同时长片段、欠采样、过采样和交叉验证等技术。

Result: RNN模型在5秒音频分割和80:10:10数据划分方案下取得了95.92%的最高准确率。这是首个针对Sorani库尔德语Hewlêri次方言的NLI语音数据集。

Conclusion: 该研究成功实现了对低资源语言次方言的母语识别，证明了神经网络方法在方言NLI任务中的有效性，创建的数据集将为相关研究领域提供宝贵资源。

Abstract: Native Language Identification (NLI) is a task in Natural Language Processing (NLP) that typically determines the native language of an author through their writing or a speaker through their speaking. It has various applications in different areas, such as forensic linguistics and general linguistics studies. Although considerable research has been conducted on NLI regarding two different languages, such as English and German, the literature indicates a significant gap regarding NLI for dialects and subdialects. The gap becomes wider in less-resourced languages such as Kurdish. This research focuses on NLI within the context of a subdialect of Sorani (Central) Kurdish. It aims to investigate the NLI for Hewlêri, a subdialect spoken in Hewlêr (Erbil), the Capital of the Kurdistan Region of Iraq. We collected about 24 hours of speech by recording interviews with 40 native or non-native Hewlêri speakers, 17 female and 23 male. We created three Neural Network-based models: Artificial Neural Network (ANN), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN), which were evaluated through 66 experiments, covering various time-frames from 1 to 60 seconds, undersampling, oversampling, and cross-validation. The RNN model showed the highest accuracy of 95.92% for 5-second audio segmentation, using an 80:10:10 data splitting scheme. The created dataset is the first speech dataset for NLI on the Hewlêri subdialect in the Sorani Kurdish dialect, which can be of benefit to various research areas.

</details>


### [36] [C-MOP: Integrating Momentum and Boundary-Aware Clustering for Enhanced Prompt Evolution](https://arxiv.org/abs/2602.10874)
*Binwei Yan,Yifei Fu,Mingjian Zhu,Hanting Chen,Mingxuan Yuan,Yunhe Wang,Hailin Hu*

Main category: cs.CL

TL;DR: C-MOP是一个基于聚类的动量优化提示框架，通过边界感知对比采样和动量引导语义聚类来稳定提示优化过程，显著提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法常受到噪声和冲突更新信号的困扰，导致优化过程不稳定，需要一种更稳定的优化框架。

Method: 提出C-MOP框架，包含两个核心组件：1) BACS（边界感知对比采样）：利用批次信息挖掘硬负样本、锚点和边界对，精确表征正负提示样本的典型表示和决策边界；2) MGSC（动量引导语义聚类）：引入具有时间衰减的文本动量机制，从迭代中波动的梯度中提取持久共识。

Result: C-MOP在实验中一致优于PromptWizard和ProTeGi等SOTA基线方法，平均提升分别为1.58%和3.35%。值得注意的是，C-MOP使仅激活3B参数的通用LLM能够超越70B参数的领域特定密集LLM。

Conclusion: C-MOP通过稳定优化过程和解决语义冲突，有效推动了精确的提示演化，为自动提示优化提供了有效的解决方案。

Abstract: Automatic prompt optimization is a promising direction to boost the performance of Large Language Models (LLMs). However, existing methods often suffer from noisy and conflicting update signals. In this research, we propose C-MOP (Cluster-based Momentum Optimized Prompting), a framework that stabilizes optimization via Boundary-Aware Contrastive Sampling (BACS) and Momentum-Guided Semantic Clustering (MGSC). Specifically, BACS utilizes batch-level information to mine tripartite features--Hard Negatives, Anchors, and Boundary Pairs--to precisely characterize the typical representation and decision boundaries of positive and negative prompt samples. To resolve semantic conflicts, MGSC introduces a textual momentum mechanism with temporal decay that distills persistent consensus from fluctuating gradients across iterations. Extensive experiments demonstrate that C-MOP consistently outperforms SOTA baselines like PromptWizard and ProTeGi, yielding average gains of 1.58% and 3.35%. Notably, C-MOP enables a general LLM with 3B activated parameters to surpass a 70B domain-specific dense LLM, highlighting its effectiveness in driving precise prompt evolution. The code is available at https://github.com/huawei-noah/noah-research/tree/master/C-MOP.

</details>


### [37] [Diagnosing Structural Failures in LLM-Based Evidence Extraction for Meta-Analysis](https://arxiv.org/abs/2602.10881)
*Zhiyin Tan,Jennifer D'Souza*

Main category: cs.CL

TL;DR: LLMs在系统综述和荟萃分析中证据提取表现不佳，特别是在需要变量、角色、统计方法和效应量稳定绑定的复杂结构任务上。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在文本处理方面进展迅速，但它们在系统综述和荟萃分析中的结构化证据提取能力仍不明确。这类任务需要跨文档保持角色、方法和效应量归因的结构一致性，而非简单的实体识别。

Method: 提出一个结构性诊断框架，通过逐步增加关系和数值复杂度的模式约束查询来评估LLM的证据提取能力。使用涵盖五个科学领域的手动标注语料库、统一查询套件和评估协议，评估两种最先进的LLM在单文档和长上下文多文档输入下的表现。

Result: LLMs在单属性查询上表现中等，但在需要变量、角色、统计方法和效应量稳定绑定的任务上性能急剧下降。完整的荟萃分析关联元组提取可靠性几乎为零，长上下文输入进一步加剧了这些失败。下游聚合会放大上游的微小错误，导致语料库级统计不可靠。

Conclusion: 当前LLMs缺乏自动化荟萃分析所需的结构保真度、关系绑定和数值基础能力。失败原因并非实体识别错误，而是系统性的结构崩溃，包括角色反转、跨分析绑定漂移、密集结果部分的实例压缩和数值错误归因。

Abstract: Systematic reviews and meta-analyses rely on converting narrative articles into structured, numerically grounded study records. Despite rapid advances in large language models (LLMs), it remains unclear whether they can meet the structural requirements of this process, which hinge on preserving roles, methods, and effect-size attribution across documents rather than on recognizing isolated entities. We propose a structural, diagnostic framework that evaluates LLM-based evidence extraction as a progression of schema-constrained queries with increasing relational and numerical complexity, enabling precise identification of failure points beyond atom-level extraction. Using a manually curated corpus spanning five scientific domains, together with a unified query suite and evaluation protocol, we evaluate two state-of-the-art LLMs under both per-document and long-context, multi-document input regimes. Across domains and models, performance remains moderate for single-property queries but degrades sharply once tasks require stable binding between variables, roles, statistical methods, and effect sizes. Full meta-analytic association tuples are extracted with near-zero reliability, and long-context inputs further exacerbate these failures. Downstream aggregation amplifies even minor upstream errors, rendering corpus-level statistics unreliable. Our analysis shows that these limitations stem not from entity recognition errors, but from systematic structural breakdowns, including role reversals, cross-analysis binding drift, instance compression in dense result sections, and numeric misattribution, indicating that current LLMs lack the structural fidelity, relational binding, and numerical grounding required for automated meta-analysis. The code and data are publicly available at GitHub (https://github.com/zhiyintan/LLM-Meta-Analysis).

</details>


### [38] [The CLEF-2026 FinMMEval Lab: Multilingual and Multimodal Evaluation of Financial AI Systems](https://arxiv.org/abs/2602.10886)
*Zhuohan Xie,Rania Elbadry,Fan Zhang,Georgi Georgiev,Xueqing Peng,Lingfei Qian,Jimin Huang,Dimitar Dimitrov,Vanshikaa Jani,Yuyang Dai,Jiahui Geng,Yuxia Wang,Ivan Koychev,Veselin Stoyanov,Preslav Nakov*

Main category: cs.CL

TL;DR: FinMMEval 2026是首个多语言多模态金融大语言模型评估框架，包含三个互相关联的任务，旨在全面评估模型在金融理解、推理和决策方面的跨语言跨模态能力。


<details>
  <summary>Details</summary>
Motivation: 当前金融自然语言处理领域存在局限性：现有基准测试大多是单语言的、纯文本的，并且局限于狭窄的子任务。需要建立一个更全面、多语言、多模态的评估框架来推动金融AI系统的发展。

Method: 通过三个互相关联的任务构建评估框架：1) 金融考试问答，2) 多语言金融问答(PolyFiQA)，3) 金融决策制定。提供公开数据集和评估资源支持可重复研究。

Result: 建立了首个多语言多模态金融LLM评估框架FinMMEval 2026，涵盖金融理解、推理和决策三个维度，支持跨语言和跨模态的模型评估。

Conclusion: FinMMEval 2026填补了现有金融AI评估的空白，旨在促进鲁棒、透明、全球包容的金融AI系统发展，通过公开数据集和评估资源支持可重复研究。

Abstract: We present the setup and the tasks of the FinMMEval Lab at CLEF 2026, which introduces the first multilingual and multimodal evaluation framework for financial Large Language Models (LLMs). While recent advances in financial natural language processing have enabled automated analysis of market reports, regulatory documents, and investor communications, existing benchmarks remain largely monolingual, text-only, and limited to narrow subtasks. FinMMEval 2026 addresses this gap by offering three interconnected tasks that span financial understanding, reasoning, and decision-making: Financial Exam Question Answering, Multilingual Financial Question Answering (PolyFiQA), and Financial Decision Making. Together, these tasks provide a comprehensive evaluation suite that measures models' ability to reason, generalize, and act across diverse languages and modalities. The lab aims to promote the development of robust, transparent, and globally inclusive financial AI systems, with datasets and evaluation resources publicly released to support reproducible research.

</details>


### [39] [SoftMatcha 2: A Fast and Soft Pattern Matcher for Trillion-Scale Corpora](https://arxiv.org/abs/2602.10908)
*Masataka Yoneda,Yusuke Matsushita,Go Kamoda,Kohei Suenaga,Takuya Akiba,Masaki Waga,Sho Yokoi*

Main category: cs.CL

TL;DR: 提出了一种超快速灵活的搜索算法，能在0.3秒内搜索万亿规模的自然语言语料库，同时处理语义变化（替换、插入和删除）。


<details>
  <summary>Details</summary>
Motivation: 现有方法在万亿规模语料库上进行语义搜索时存在速度瓶颈，特别是处理查询语义变化（如替换、插入、删除）时会引发组合爆炸问题。

Method: 基于后缀数组的字符串匹配方法，采用磁盘感知设计实现快速精确查找，并结合动态语料感知剪枝来抑制搜索空间指数级增长。

Result: 在FineWeb-Edu（1.4T tokens）实验中，搜索延迟显著低于现有方法（infini-gram、infini-gram mini、SoftMatcha）。能够识别现有方法未发现的训练语料库基准污染，并提供七种语言的在线演示。

Conclusion: 该方法在万亿规模语料库上实现了亚秒级语义搜索，有效解决了组合爆炸问题，并在实际应用中展示了识别基准污染的能力。

Abstract: We present an ultra-fast and flexible search algorithm that enables search over trillion-scale natural language corpora in under 0.3 seconds while handling semantic variations (substitution, insertion, and deletion). Our approach employs string matching based on suffix arrays that scales well with corpus size. To mitigate the combinatorial explosion induced by the semantic relaxation of queries, our method is built on two key algorithmic ideas: fast exact lookup enabled by a disk-aware design, and dynamic corpus-aware pruning. We theoretically show that the proposed method suppresses exponential growth in the search space with respect to query length by leveraging statistical properties of natural language. In experiments on FineWeb-Edu (Lozhkov et al., 2024) (1.4T tokens), we show that our method achieves significantly lower search latency than existing methods: infini-gram (Liu et al., 2024), infini-gram mini (Xu et al., 2025), and SoftMatcha (Deguchi et al., 2025). As a practical application, we demonstrate that our method identifies benchmark contamination in training corpora, unidentified by existing approaches. We also provide an online demo of fast, soft search across corpora in seven languages.

</details>


### [40] [Computational Phenomenology of Temporal Experience in Autism: Quantifying the Emotional and Narrative Characteristics of Lived Unpredictability](https://arxiv.org/abs/2602.10947)
*Kacper Dudzic,Karolina Drożdż,Maciej Wodziński,Anastazja Szuła,Marcin Moskalewicz*

Main category: cs.CL

TL;DR: 本研究通过整合现象学访谈和计算分析，探讨自闭症个体的时间体验特征，发现不可预测性是核心挑战，且源于生活体验内容而非叙事建构。


<details>
  <summary>Details</summary>
Motivation: 现有自闭症时间体验研究存在三大局限：1) 以缺陷为基础的医学模型主导；2) 质性研究样本量小；3) 计算研究缺乏现象学基础。本研究旨在弥合现象学与计算方法之间的鸿沟，并克服样本量限制。

Method: 整合三种方法：研究A-使用跨诊断时间体验评估进行结构化现象学访谈；研究B-对专门构建的自闭症自传叙事语料库进行计算分析；研究C-复制一项使用叙事流测量评估自闭症自传现象学真实性的计算研究。

Result: 访谈显示自闭症与对照组最显著差异在于体验的不可预测性。计算分析结果与此一致：自闭症叙事中的时间词汇显著更负面（尤其是"即时性与突发性"类别）。离群值分析发现与感知不连续性相关的词汇高度负面。叙事流计算分析显示自闭症叙事在语料库中更接近真实自传而非虚构故事。

Conclusion: 自闭症个体经历的时间挑战主要涉及生活体验的不可预测性，且源于生活体验内容本身，而非自闭症叙事建构方式。

Abstract: Disturbances in temporality, such as desynchronization with the social environment and its unpredictability, are considered core features of autism with a deep impact on relationships. However, limitations regarding research on this issue include: 1) the dominance of deficit-based medical models of autism, 2) sample size in qualitative research, and 3) the lack of phenomenological anchoring in computational research. To bridge the gap between phenomenological and computational approaches and overcome sample-size limitations, our research integrated three methodologies. Study A: structured phenomenological interviews with autistic individuals using the Transdiagnostic Assessment of Temporal Experience. Study B: computational analysis of an autobiographical corpus of autistic narratives built for this purpose. Study C: a replication of a computational study using narrative flow measures to assess the perceived phenomenological authenticity of autistic autobiographies. Interviews revealed that the most significant differences between the autistic and control groups concerned unpredictability of experience. Computational results mirrored these findings: the temporal lexicon in autistic narratives was significantly more negatively valenced - particularly the "Immediacy & Suddenness" category. Outlier analysis identified terms associated with perceived discontinuity (unpredictably, precipitously, and abruptly) as highly negative. The computational analysis of narrative flow found that the autistic narratives contained within the corpus quantifiably resemble autobiographical stories more than imaginary ones. Overall, the temporal challenges experienced by autistic individuals were shown to primarily concern lived unpredictability and stem from the contents of lived experience, and not from autistic narrative construction.

</details>


### [41] [Search or Accelerate: Confidence-Switched Position Beam Search for Diffusion Language Models](https://arxiv.org/abs/2602.10953)
*Mingyu Cao,Alvaro Correia,Christos Louizos,Shiwei Liu,Lu Yin*

Main category: cs.CL

TL;DR: SOAR是一种训练免费的DLM解码算法，通过根据模型置信度动态调整搜索策略来优化文本生成质量，在数学推理和代码生成任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统DLM解码采用贪婪策略，总是选择置信度最高的位置进行解掩码，但这种局部最优选择可能导致次优的解码顺序，特别是在需要复杂推理的任务中。

Method: SOAR算法根据模型置信度自适应调整解码行为：当置信度低时，扩大对替代解掩码决策的搜索范围以避免过早承诺；当置信度高时，缩小搜索范围并并行解码多个位置以减少去噪迭代次数。

Result: 在数学推理（GSM8K）和代码生成（MBPP、HumanEval）基准测试中，使用Dream-7B和LLaDA-8B模型，SOAR在保持竞争性推理速度的同时提高了生成质量。

Conclusion: SOAR为DLM解码提供了一种实用的质量与效率平衡方案，通过训练免费的自适应解码策略显著提升了复杂推理任务的表现。

Abstract: Diffusion Language Models (DLMs) generate text by iteratively denoising a masked sequence, repeatedly deciding which positions to commit at each step. Standard decoding follows a greedy rule: unmask the most confident positions, yet this local choice can lock the model into a suboptimal unmasking order, especially on reasoning-heavy prompts. We present SOAR, a training-free decoding algorithm that adapts its behavior to the model's uncertainty. When confidence is low, SOAR briefly widens the search over alternative unmasking decisions to avoid premature commitments; when confidence is high, it collapses the search and decodes many positions in parallel to reduce the number of denoising iterations. Across mathematical reasoning and code generation benchmarks (GSM8K, MBPP, HumanEval) on Dream-7B and LLaDA-8B, SOAR improves generation quality while maintaining competitive inference speed, offering a practical way to balance quality and efficiency in DLM decoding.

</details>


### [42] [LoRA-Squeeze: Simple and Effective Post-Tuning and In-Tuning Compression of LoRA Modules](https://arxiv.org/abs/2602.10993)
*Ivan Vulić,Adam Grycner,Quentin de Laroussilhe,Jonas Pfeiffer*

Main category: cs.CL

TL;DR: LoRA-Squeeze是一种改进标准LoRA的方法，通过训练时动态或训练后压缩的方式改变LoRA模块的秩，先学习高秩表达再压缩，比直接训练低秩模块效果更好


<details>
  <summary>Details</summary>
Motivation: 标准LoRA面临预选最优秩、秩特定超参数调优的挑战，以及异构秩模块和更复杂LoRA变体的部署复杂性。需要一种更简单高效的方法来改进LoRA学习

Method: 提出LoRA-Squeeze方法：1）使用故意设置的高源秩进行微调；2）重建或高效近似全权重更新矩阵；3）使用随机奇异值分解创建压缩后的低目标秩LoRA模块。包括训练后压缩和训练中动态秩退火两种变体

Result: 在13个文本任务和10个视觉语言任务上的实验表明：1）训练后压缩通常能产生优于直接训练的目标秩适配器；2）如果允许少量目标秩微调步骤，效果更好；3）训练中秩退火变体始终实现最佳LoRA大小-性能权衡

Conclusion: LoRA-Squeeze通过先学习高秩表达再压缩的方法，有效解决了标准LoRA的秩选择难题，提供了一种简单高效的参数高效微调改进方案，在保持性能的同时减少了部署复杂性

Abstract: Despite its huge number of variants, standard Low-Rank Adaptation (LoRA) is still a dominant technique for parameter-efficient fine-tuning (PEFT). Nonetheless, it faces persistent challenges, including the pre-selection of an optimal rank and rank-specific hyper-parameters, as well as the deployment complexity of heterogeneous-rank modules and more sophisticated LoRA derivatives. In this work, we introduce LoRA-Squeeze, a simple and efficient methodology that aims to improve standard LoRA learning by changing LoRA module ranks either post-hoc or dynamically during training}. Our approach posits that it is better to first learn an expressive, higher-rank solution and then compress it, rather than learning a constrained, low-rank solution directly. The method involves fine-tuning with a deliberately high(er) source rank, reconstructing or efficiently approximating the reconstruction of the full weight update matrix, and then using Randomized Singular Value Decomposition (RSVD) to create a new, compressed LoRA module at a lower target rank. Extensive experiments across 13 text and 10 vision-language tasks show that post-hoc compression often produces lower-rank adapters that outperform those trained directly at the target rank, especially if a small number of fine-tuning steps at the target rank is allowed. Moreover, a gradual, in-tuning rank annealing variant of LoRA-Squeeze consistently achieves the best LoRA size-performance trade-off.

</details>


### [43] [Linguistic Indicators of Early Cognitive Decline in the DementiaBank Pitt Corpus: A Statistical and Machine Learning Study](https://arxiv.org/abs/2602.11028)
*Artsvik Avetisyan,Sachin Kumar*

Main category: cs.CL

TL;DR: 该研究通过分析自发语言转录本，使用三种语言表征和机器学习模型，发现句法和语法特征即使在缺乏词汇内容时仍能有效区分认知衰退，为语言基础的认知筛查提供了透明可靠的方法。


<details>
  <summary>Details</summary>
Motivation: 自发语言产生的细微变化是认知衰退的最早期指标之一。识别可解释的痴呆症语言标记可以支持透明且临床基础的筛查方法。

Method: 使用DementiaBank Pitt Corpus的自发语言转录本，采用三种语言表征：原始清理文本、结合词汇和语法信息的词性增强表征、以及仅词性的句法表征。使用逻辑回归和随机森林模型，在两种协议下评估：转录本级训练-测试分割和受试者级五折交叉验证（防止说话者重叠）。通过全局特征重要性和Mann-Whitney U检验与Cliff's delta效应量进行模型可解释性分析和统计验证。

Result: 所有表征下模型均获得稳定性能，句法和语法特征即使在缺乏词汇内容时仍保持强大区分能力。受试者级评估产生更保守但一致的结果，特别是词性增强和仅词性表征。统计分析显示功能词使用、词汇多样性、句子结构和语篇连贯性存在显著组间差异，与机器学习特征重要性结果高度一致。

Conclusion: 结果表明抽象语言特征在临床现实评估中捕获了早期认知衰退的稳健标记。通过结合可解释机器学习和非参数统计验证，该研究支持使用语言基础特征进行透明可靠的语言基础认知筛查。

Abstract: Background: Subtle changes in spontaneous language production are among the earliest indicators of cognitive decline. Identifying linguistically interpretable markers of dementia can support transparent and clinically grounded screening approaches.
  Methods: This study analyzes spontaneous speech transcripts from the DementiaBank Pitt Corpus using three linguistic representations: raw cleaned text, a part-of-speech (POS)-enhanced representation combining lexical and grammatical information, and a POS-only syntactic representation. Logistic regression and random forest models were evaluated under two protocols: transcript-level train-test splits and subject-level five-fold cross-validation to prevent speaker overlap. Model interpretability was examined using global feature importance, and statistical validation was conducted using Mann-Whitney U tests with Cliff's delta effect sizes.
  Results: Across representations, models achieved stable performance, with syntactic and grammatical features retaining strong discriminative power even in the absence of lexical content. Subject-level evaluation yielded more conservative but consistent results, particularly for POS-enhanced and POS-only representations. Statistical analysis revealed significant group differences in functional word usage, lexical diversity, sentence structure, and discourse coherence, aligning closely with machine learning feature importance findings.
  Conclusion: The results demonstrate that abstract linguistic features capture robust markers of early cognitive decline under clinically realistic evaluation. By combining interpretable machine learning with non-parametric statistical validation, this study supports the use of linguistically grounded features for transparent and reliable language-based cognitive screening.

</details>


### [44] [Language Model Inversion through End-to-End Differentiation](https://arxiv.org/abs/2602.11044)
*Kevin Yandoka Denamganaï,Kartic Subr*

Main category: cs.CL

TL;DR: 该论文提出了一种基于梯度优化的方法来逆向求解语言模型：给定目标输出序列，找到能产生该输出的输入提示词。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型研究很少分析其可逆性，即给定目标输出序列，确定能产生该输出的输入提示词仍然是一个未解决的问题。

Method: 1. 将语言模型视为在token分布序列上操作的函数（而非传统token序列）；2. 提出简单算法实现冻结语言模型的端到端可微性；3. 通过梯度下降找到优化的提示词。

Result: 实验表明，DLM驱动的逆向方法能可靠高效地优化长度为10和80的提示词，针对长度为20的目标输出序列，适用于多个白盒语言模型（开箱即用）。

Conclusion: 该研究成功解决了语言模型可逆性问题，提出了一种有效的梯度优化方法，能够为给定目标输出找到相应的输入提示词。

Abstract: Despite emerging research on Language Models (LM), few approaches analyse the invertibility of LMs. That is, given a LM and a desirable target output sequence of tokens, determining what input prompts would yield the target output remains an open problem. We formulate this problem as a classical gradient-based optimisation. First, we propose a simple algorithm to achieve end-to-end differentiability of a given (frozen) LM and then find optimised prompts via gradient descent. Our central insight is to view LMs as functions operating on sequences of distributions over tokens (rather than the traditional view as functions on sequences of tokens). Our experiments and ablations demonstrate that our DLM-powered inversion can reliably and efficiently optimise prompts of lengths $10$ and $80$ for targets of length $20$, for several white-box LMs (out-of-the-box).

</details>


### [45] [Embedding Inversion via Conditional Masked Diffusion Language Models](https://arxiv.org/abs/2602.11047)
*Han Xiao*

Main category: cs.CL

TL;DR: 通过条件掩码扩散实现嵌入反转，仅需8次前向传播即可并行恢复所有token，在三种嵌入模型上达到81.3%的token准确率和0.87余弦相似度。


<details>
  <summary>Details</summary>
Motivation: 传统嵌入反转方法通常采用自回归序列生成，效率较低。本文旨在开发一种更高效的并行方法，通过扩散模型一次性恢复所有token。

Method: 将嵌入反转重新定义为条件掩码扩散问题：使用自适应层归一化将目标嵌入作为条件输入到掩码扩散语言模型中，通过迭代去噪并行恢复所有token，而非顺序生成。

Result: 在32个token的序列上，针对三种不同的嵌入模型，该方法仅用8次前向传播（78M参数模型）就实现了81.3%的token准确率和0.87的余弦相似度，且无需访问目标编码器。

Conclusion: 条件掩码扩散为嵌入反转提供了一种高效、准确的并行解决方案，显著优于传统的自回归方法，在保持高质量的同时大幅减少了计算开销。

Abstract: We frame embedding inversion as conditional masked diffusion, recovering all tokens in parallel through iterative denoising rather than sequential autoregressive generation. A masked diffusion language model is conditioned on the target embedding via adaptive layer normalization, requiring only 8 forward passes through a 78M parameter model with no access to the target encoder. On 32-token sequences across three embedding models, the method achieves 81.3% token accuracy and 0.87 cosine similarity.

</details>


### [46] [Conversational Behavior Modeling Foundation Model With Multi-Level Perception](https://arxiv.org/abs/2602.11065)
*Dingkun Zhou,Shuchang Pan,Jiachen Lian,Siddharth Banerjee,Sarika Pasumarthy,Dhruv Hebbar,Siddhant Patel,Zeyi Austin Li,Kan Jen Cheng,Sanay Bordia,Krish Patel,Akshaj Gupta,Tingle Li,Gopala Anumanchipalli*

Main category: cs.CL

TL;DR: 论文提出了一个基于图思维（GoT）的框架，用于建模人类对话中的多级感知过程，通过层次化标签预测交流意图和言语行为，并在全双工会话系统中实现可解释的推理。


<details>
  <summary>Details</summary>
Motivation: 人类对话由隐含的思维链组织，表现为定时的言语行为。捕捉这种感知路径对于构建自然的全双工交互系统至关重要。当前系统缺乏对这种认知过程的建模能力。

Method: 1. 将对话过程建模为多级感知
2. 通过图思维（GoT）对会话行为进行推理
3. 使用层次化标签方案形式化意图到行动的路径：预测高层交流意图和低层言语行为
4. 学习意图和言语行为之间的因果和时间依赖关系
5. 构建高质量语料库，包含可控的事件丰富对话数据和人工标注标签
6. GoT框架将流式预测结构化为演化图，使transformer能够预测下一个言语行为、生成决策的简洁理由，并动态优化推理

Result: 在合成和真实全双工对话上的实验表明：1. 框架实现了稳健的行为检测；2. 产生了可解释的推理链；3. 为全双工口语对话系统中的会话推理基准建立了基础。

Conclusion: GoT框架成功捕捉了人类对话中的隐含思维链，通过多级感知和演化图推理，为构建自然、可解释的全双工交互系统提供了有效方法，并建立了会话推理的评估基准。

Abstract: Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this perceptual pathway is key to building natural full-duplex interactive systems. We introduce a framework that models this process as multi-level perception, and then reasons over conversational behaviors via a Graph-of-Thoughts (GoT). Our approach formalizes the intent-to-action pathway with a hierarchical labeling scheme, predicting high-level communicative intents and low-level speech acts to learn their causal and temporal dependencies. To train this system, we develop a high quality corpus that pairs controllable, event-rich dialogue data with human-annotated labels. The GoT framework structures streaming predictions as an evolving graph, enabling a transformer to forecast the next speech act, generate concise justifications for its decisions, and dynamically refine its reasoning. Experiments on both synthetic and real duplex dialogues show that the framework delivers robust behavior detection, produces interpretable reasoning chains, and establishes a foundation for benchmarking conversational reasoning in full duplex spoken dialogue systems.

</details>


### [47] [Simultaneous Speech-to-Speech Translation Without Aligned Data](https://arxiv.org/abs/2602.11072)
*Tom Labiausse,Romain Fabre,Yannick Estève,Alexandre Défossez,Neil Zeghidour*

Main category: cs.CL

TL;DR: Hibiki-Zero 是一种无需词级对齐的同步语音翻译模型，通过强化学习优化延迟，在多个语言对英语任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统同步语音翻译方法依赖词级对齐数据，但这些数据难以大规模收集，通常需要使用语言特定的启发式方法进行合成对齐，这种方法并不理想。需要一种能消除词级对齐需求、简化训练流程并轻松扩展到不同语法结构语言的方法。

Method: 首先在句子级对齐数据上训练以学习高延迟的语音翻译，然后应用基于GRPO的新型强化学习策略来优化延迟同时保持翻译质量。完全消除了对词级对齐的需求。

Result: 在五个X到英语任务中实现了翻译准确性、延迟、语音传递和自然度的最先进性能。此外，模型只需不到1000小时的语音数据即可适应新的输入语言。发布了包含45小时多语言数据的基准测试。

Conclusion: Hibiki-Zero通过消除词级对齐需求，显著简化了同步语音翻译的训练流程，实现了跨语言的可扩展性，并在多个关键指标上达到最先进性能，为多语言同步语音翻译提供了实用解决方案。

Abstract: Simultaneous speech translation requires translating source speech into a target language in real-time while handling non-monotonic word dependencies. Traditional approaches rely on supervised training with word-level aligned data, which is difficult to collect at scale and thus depends on synthetic alignments using language-specific heuristics that are suboptimal. We propose Hibiki-Zero, which eliminates the need for word-level alignments entirely. This fundamentally simplifies the training pipeline and enables seamless scaling to diverse languages with varying grammatical structures, removing the bottleneck of designing language-specific alignment heuristics. We first train on sentence-level aligned data to learn speech translation at high latency, then apply a novel reinforcement learning strategy using GRPO to optimize latency while preserving translation quality. Hibiki-Zero achieves state-of-the-art performance in translation accuracy, latency, voice transfer, and naturalness across five X-to-English tasks. Moreover, we demonstrate that our model can be adapted to support a new input language with less than 1000h of speech. We provide examples, model weights, inference code and we release a benchmark containing 45h of multilingual data for speech translation evaluation.

</details>


### [48] [SteuerLLM: Local specialized large language model for German tax law analysis](https://arxiv.org/abs/2602.11081)
*Sebastian Wind,Jeta Sopa,Laurin Schmid,Quirin Jackl,Sebastian Kiefer,Fei Wu,Martin Mayr,Harald Köstler,Gerhard Wellein,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.CL

TL;DR: 研究者创建了SteuerEx，首个基于德国大学税法考试的开放基准，并开发了SteuerLLM，一个专门针对德国税法的领域适应大语言模型，该模型在特定领域数据上表现优于通用大模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在需要严格形式规则、精确术语和法律约束结构的领域（如税法）表现不佳，需要专门针对这些领域的评估基准和模型。

Method: 1. 算法生成SteuerEx基准：包含115个专家验证的德国大学税法考试问题，涵盖六个核心税法领域和多个学术水平，采用分步部分评分框架。
2. 开发SteuerLLM：通过受控检索增强管道从真实考试材料生成大规模合成数据集，训练专门针对德国税法的领域适应大语言模型（28B参数）。

Result: SteuerLLM在德国税法任务上持续优于同规模通用指令微调模型，甚至在某些情况下优于更大的系统，表明特定领域数据和架构适应比参数规模对现实法律推理任务更重要。

Conclusion: 对于现实法律推理任务，特定领域数据和架构适应比模型参数规模更为关键。研究者开源了所有基准数据、训练数据集、模型权重和评估代码，以支持领域特定法律人工智能的可重复研究。

Abstract: Large language models (LLMs) demonstrate strong general reasoning and language understanding, yet their performance degrades in domains governed by strict formal rules, precise terminology, and legally binding structure. Tax law exemplifies these challenges, as correct answers require exact statutory citation, structured legal argumentation, and numerical accuracy under rigid grading schemes. We algorithmically generate SteuerEx, the first open benchmark derived from authentic German university tax law examinations. SteuerEx comprises 115 expert-validated examination questions spanning six core tax law domains and multiple academic levels, and employs a statement-level, partial-credit evaluation framework that closely mirrors real examination practice. We further present SteuerLLM, a domain-adapted LLM for German tax law trained on a large-scale synthetic dataset generated from authentic examination material using a controlled retrieval-augmented pipeline. SteuerLLM (28B parameters) consistently outperforms general-purpose instruction-tuned models of comparable size and, in several cases, substantially larger systems, demonstrating that domain-specific data and architectural adaptation are more decisive than parameter scale for performance on realistic legal reasoning tasks. All benchmark data, training datasets, model weights, and evaluation code are released openly to support reproducible research in domain-specific legal artificial intelligence. A web-based demo of SteuerLLM is available at https://steuerllm.i5.ai.fau.de.

</details>


### [49] [DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning](https://arxiv.org/abs/2602.11089)
*Yicheng Chen,Zerun Ma,Xinchen Xie,Yining Li,Kai Chen*

Main category: cs.CL

TL;DR: DataChef-32B：首个端到端数据配方生成框架，通过在线强化学习和代理奖励自动化设计LLM训练数据配方，性能媲美人工专家


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练中，数据配方的设计仍然高度依赖人工专家经验，过程繁琐且耗时。虽然已有使用LLM自动化单个数据处理步骤的研究，但整体数据配方的端到端设计仍然缺乏自动化解决方案。

Method: 提出DataChef-32B框架，将数据配方生成形式化为端到端优化问题。采用在线强化学习，使用代理奖励函数预测候选配方在下游任务上的性能，自动从可用数据源池中生成完整的数据处理流程。

Result: 在6个保留任务上，DataChef-32B生成的数据配方达到与人类专家设计的配方相当的下游性能。特别地，DataChef-32B为Qwen3-1.7B-Base设计的数学领域配方在AIME'25上达到66.7分，超越了原始Qwen3-1.7B模型。

Conclusion: 该工作首次实现了端到端数据配方生成的自动化，为LLM训练过程的全面自动化开辟了新途径，也为开发自进化AI系统提供了重要洞见。

Abstract: In the current landscape of Large Language Models (LLMs), the curation of large-scale, high-quality training data is a primary driver of model performance. A key lever is the \emph{data recipe}, which comprises a data processing pipeline to transform raw sources into training corpora. Despite the growing use of LLMs to automate individual data processing steps, such as data synthesis and filtering, the overall design of data recipes remains largely manual and labor-intensive, requiring substantial human expertise and iteration. To bridge this gap, we formulate \emph{end-to-end data recipe generation} for LLM adaptation. Given a target benchmark and a pool of available data sources, a model is required to output a complete data recipe that adapts a base LLM to the target task. We present DataChef-32B, which performs online reinforcement learning using a proxy reward that predicts downstream performance for candidate recipes. Across six held-out tasks, DataChef-32B produces practical recipes that reach comparable downstream performance to those curated by human experts. Notably, the recipe from DataChef-32B adapts Qwen3-1.7B-Base to the math domain, achieving 66.7 on AIME'25 and surpassing Qwen3-1.7B. This work sheds new light on automating LLM training and developing self-evolving AI systems.

</details>


### [50] [Can Large Language Models Make Everyone Happy?](https://arxiv.org/abs/2602.11091)
*Usman Naseem,Gautam Siddharth Kashyap,Ebad Shabbir,Sushant Kumar Ray,Abdullah Mohammad,Rafiq Ali*

Main category: cs.CL

TL;DR: MisAlign-Profile是一个用于衡量大语言模型安全、价值和跨文化维度间错位权衡的统一基准，包含112个规范领域的错位对齐数据集，并揭示了模型在这些维度间存在12%-34%的错位权衡。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如SAFETUNEBED、VALUEBENCH、WORLDVIEW-BENCH）主要孤立评估安全、价值和跨文化维度，无法揭示这些维度间的交互作用和权衡关系。更近期的MIB和基于机制可解释性的基准虽然提供了有价值的视角，但仍不足以系统地表征跨维度权衡。

Method: 1. 构建MISALIGNTRADE数据集：包含112个规范领域（14个安全、56个价值、42个文化领域），每个提示被分类为对象、属性或关系三种语义类型的错位；2. 使用Gemma-2-9B-it和Qwen3-30B-A3B-Instruct-2507进行扩展，采用SimHash指纹避免去重；3. 通过两阶段拒绝采样为每个提示配对错位和对齐响应；4. 在MISALIGNTRADE上对通用、微调和开源权重大语言模型进行基准测试。

Result: 基准测试揭示了模型在安全、价值和跨文化维度间存在12%-34%的错位权衡，表明大语言模型在同时满足多个对齐维度时面临显著挑战。

Conclusion: MisAlign-Profile填补了现有基准在评估多维度错位权衡方面的空白，为系统表征大语言模型在安全、价值和跨文化维度间的交互作用提供了统一框架，有助于更全面地理解和改进模型对齐。

Abstract: Misalignment in Large Language Models (LLMs) refers to the failure to simultaneously satisfy safety, value, and cultural dimensions, leading to behaviors that diverge from human expectations in real-world settings where these dimensions must co-occur. Existing benchmarks, such as SAFETUNEBED (safety-centric), VALUEBENCH (value-centric), and WORLDVIEW-BENCH (culture-centric), primarily evaluate these dimensions in isolation and therefore provide limited insight into their interactions and trade-offs. More recent efforts, including MIB and INTERPRETABILITY BENCHMARK-based on mechanistic interpretability, offer valuable perspectives on model failures; however, they remain insufficient for systematically characterizing cross-dimensional trade-offs. To address these gaps, we introduce MisAlign-Profile, a unified benchmark for measuring misalignment trade-offs inspired by mechanistic profiling. First, we construct MISALIGNTRADE, an English misaligned-aligned dataset across 112 normative domains taxonomies, including 14 safety, 56 value, and 42 cultural domains. In addition to domain labels, each prompt is classified with one of three orthogonal semantic types-object, attribute, or relations misalignment-using Gemma-2-9B-it and expanded via Qwen3-30B-A3B-Instruct-2507 with SimHash-based fingerprinting to avoid deduplication. Each prompt is paired with misaligned and aligned responses through two-stage rejection sampling to ensure quality. Second, we benchmark general-purpose, fine-tuned, and open-weight LLMs on MISALIGNTRADE-revealing 12%-34% misalignment trade-offs across dimensions.

</details>


### [51] [Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away](https://arxiv.org/abs/2602.11096)
*Soumya Suvra Ghosal,Souradip Chakraborty,Vaibhav Singh,Furong Huang,Dinesh Manocha,Amrit Singh Bedi*

Main category: cs.CL

TL;DR: SafeThink是一个轻量级推理时防御方法，通过在推理过程中监控安全性并在必要时注入纠正前缀来恢复RL后训练多模态大模型的安全性，同时保持推理能力。


<details>
  <summary>Details</summary>
Motivation: 基于强化学习的后训练（如GRPO）虽然能提升多模态大模型的推理能力，但会同时降低安全对齐性并增加越狱成功率，需要在保持推理性能的同时恢复安全性。

Method: 将安全性恢复视为满足约束而非最大化目标，通过安全奖励模型监控推理轨迹，当安全阈值被违反时条件性地注入优化的短纠正前缀（"Wait, think safely"）。

Result: 在六个开源MLRM和四个越狱基准测试中，SafeThink将攻击成功率降低30-60%（如LlamaV-o1从63.33%降至5.74%），同时保持推理性能（MathVista准确率从65.20%降至65.00%）。

Conclusion: 安全性恢复通常只需要少数引导步骤，在最初1-3个推理步骤中进行干预通常足以将完整生成重新导向安全完成，SafeThink为RL后训练模型提供了有效的推理时安全防御方案。

Abstract: Reinforcement learning (RL) based post-training for explicit chain-of-thought (e.g., GRPO) improves the reasoning ability of multimodal large-scale reasoning models (MLRMs). But recent evidence shows that it can simultaneously degrade safety alignment and increase jailbreak success rates. We propose SafeThink, a lightweight inference-time defense that treats safety recovery as a satisficing constraint rather than a maximization objective. SafeThink monitors the evolving reasoning trace with a safety reward model and conditionally injects an optimized short corrective prefix ("Wait, think safely") only when the safety threshold is violated. In our evaluations across six open-source MLRMs and four jailbreak benchmarks (JailbreakV-28K, Hades, FigStep, and MM-SafetyBench), SafeThink reduces attack success rates by 30-60% (e.g., LlamaV-o1: 63.33% to 5.74% on JailbreakV-28K, R1-Onevision: 69.07% to 5.65% on Hades) while preserving reasoning performance (MathVista accuracy: 65.20% to 65.00%). A key empirical finding from our experiments is that safety recovery is often only a few steering steps away: intervening in the first 1-3 reasoning steps typically suffices to redirect the full generation toward safe completions.

</details>


### [52] [TEGRA: Text Encoding With Graph and Retrieval Augmentation for Misinformation Detection](https://arxiv.org/abs/2602.11106)
*Géraud Faye,Wassila Ouerdane,Guillaume Gadek,Céline Hudelot*

Main category: cs.CL

TL;DR: 提出TEG方法，通过提取文档的结构化图信息并结合文本编码，增强错误信息检测性能，并扩展为TEGRA框架整合领域知识。


<details>
  <summary>Details</summary>
Motivation: 错误信息检测任务需要整合外部知识，类似人工事实核查，但现有语言模型单独使用可能不足以准确检测错误信息。

Method: 提出TEG方法：提取文档的结构化信息形成图表示，同时编码文本和图结构用于分类；扩展为TEGRA框架，整合领域特定知识。

Result: 实验表明，这种混合表示相比单独使用语言模型能提升错误信息检测性能；TEGRA在多数情况下能进一步提高分类准确率。

Conclusion: 结合结构化图表示和外部知识能有效增强错误信息检测能力，为自动化事实核查提供有前景的方向。

Abstract: Misinformation detection is a critical task that can benefit significantly from the integration of external knowledge, much like manual fact-checking. In this work, we propose a novel method for representing textual documents that facilitates the incorporation of information from a knowledge base. Our approach, Text Encoding with Graph (TEG), processes documents by extracting structured information in the form of a graph and encoding both the text and the graph for classification purposes. Through extensive experiments, we demonstrate that this hybrid representation enhances misinformation detection performance compared to using language models alone. Furthermore, we introduce TEGRA, an extension of our framework that integrates domain-specific knowledge, further enhancing classification accuracy in most cases.

</details>


### [53] [Data Repetition Beats Data Scaling in Long-CoT Supervised Fine-Tuning](https://arxiv.org/abs/2602.11149)
*Dawid J. Kopiczko,Sagar Vaze,Tijmen Blankevoort,Yuki M. Asano*

Main category: cs.CL

TL;DR: 在推理语言模型的监督微调中，重复训练小数据集比单次训练大数据集效果更好，当训练token准确率达到饱和时，模型在推理任务上的性能也达到最佳。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习直觉认为，使用更多独特的训练样本能带来更好的泛化能力。然而，作者发现对于推理语言模型的监督微调，这种直觉并不成立，并探索了重复训练小数据集的优势。

Method: 在固定更新预算下，比较了不同训练策略：使用小数据集进行多轮重复训练 vs 使用大数据集进行单轮训练。在AIME'24/25和GPQA基准上测试Olmo3-7B模型，分析了训练token准确率与推理性能的关系。

Result: 在400个样本上训练128轮的性能显著优于在51200个样本上训练1轮的性能，提升幅度达12-26个百分点，且没有额外的灾难性遗忘。训练token准确率能可靠地指示重复训练何时饱和，当达到完全记忆时，额外轮次的改进会达到平台期。

Conclusion: 对于推理任务的监督微调，使用小数据集进行多轮重复训练比扩展数据集规模更有效。训练token准确率可作为停止标准，这种"重复优势"现象（完全记忆与改进泛化同时发生）是理解大语言模型训练动态的新开放问题。

Abstract: Supervised fine-tuning (SFT) on chain-of-thought data is an essential post-training step for reasoning language models. Standard machine learning intuition suggests that training with more unique training samples yields better generalization. Counterintuitively, we show that SFT benefits from repetition: under a fixed update budget, training for more epochs on smaller datasets outperforms single-epoch training on larger datasets. On AIME'24/25 and GPQA benchmarks, Olmo3-7B trained for 128 epochs on 400 samples outperforms the equivalent 1 epoch on 51200 samples by 12-26 percentage points, with no additional catastrophic forgetting. We find that training token accuracy reliably signals when repetition has saturated; improvements from additional epochs plateau at full memorization, a pattern consistent across all settings. These findings provide a practical approach for reasoning SFT, where scaling epochs with token accuracy as a stopping criterion can replace expensive undirected data scaling. We pose the repetition advantage, where full memorization coincides with improved generalization, as a new open problem for the community in understanding the training dynamics of large language models.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [54] [JAG: Joint Attribute Graphs for Filtered Nearest Neighbor Search](https://arxiv.org/abs/2602.10258)
*Haike Xu,Guy Blelloch,Laxman Dhulipala,Lars Gottesbüren,Rajesh Jayaram,Jakub Łącki*

Main category: cs.IR

TL;DR: JAG (Joint Attribute Graphs) 是一种基于图的过滤最近邻搜索算法，通过引入属性和过滤距离，将二进制过滤约束转化为连续导航指导，在多样过滤类型和全选择性范围内提供稳健性能。


<details>
  <summary>Details</summary>
Motivation: 现有过滤最近邻搜索算法对查询选择性和过滤类型高度敏感，通常只在特定过滤类别或狭窄选择性范围内表现良好，无法满足实际部署中对新过滤类型和未知查询选择性的泛化需求。

Method: 提出JAG算法，引入属性和过滤距离的概念，将二进制过滤约束转化为连续导航指导。构建同时优化向量相似性和属性邻近性的邻近图，避免导航死胡同。

Result: 在五个数据集和四种过滤类型（标签、范围、子集、布尔）上的实验表明，JAG在吞吐量和召回率稳健性方面显著优于现有最先进的基线方法。

Conclusion: JAG通过联合优化向量相似性和属性邻近性，为过滤最近邻搜索提供了一种通用的解决方案，能够在全选择性范围内支持多样过滤类型，并显著提升性能稳健性。

Abstract: Despite filtered nearest neighbor search being a fundamental task in modern vector search systems, the performance of existing algorithms is highly sensitive to query selectivity and filter type. In particular, existing solutions excel either at specific filter categories (e.g., label equality) or within narrow selectivity bands (e.g., pre-filtering for low selectivity) and are therefore a poor fit for practical deployments that demand generalization to new filter types and unknown query selectivities. In this paper, we propose JAG (Joint Attribute Graphs), a graph-based algorithm designed to deliver robust performance across the entire selectivity spectrum and support diverse filter types. Our key innovation is the introduction of attribute and filter distances, which transform binary filter constraints into continuous navigational guidance. By constructing a proximity graph that jointly optimizes for both vector similarity and attribute proximity, JAG prevents navigational dead-ends and allows JAG to consistently outperform prior graph-based filtered nearest neighbor search methods. Our experimental results across five datasets and four filter types (Label, Range, Subset, Boolean) demonstrate that JAG significantly outperforms existing state-of-the-art baselines in both throughput and recall robustness.

</details>


### [55] [MLDocRAG: Multimodal Long-Context Document Retrieval Augmented Generation](https://arxiv.org/abs/2602.10271)
*Yongyue Zhang,Yaxiong Wu*

Main category: cs.IR

TL;DR: 提出MLDocRAG框架，通过多模态块-查询图（MCQG）组织多模态长文档内容，提升检索增强生成在跨模态跨页面文档理解中的表现。


<details>
  <summary>Details</summary>
Motivation: 多模态长文档理解面临两大挑战：(1) 跨模态异质性导致难以定位相关信息，(2) 跨页面推理需要聚合分散在多页的证据。现有方法难以有效处理这些挑战。

Method: 提出MLDocRAG框架，核心是构建多模态块-查询图（MCQG）。通过多模态文档扩展过程，从异质文档块生成细粒度查询，并将这些查询链接到跨模态和跨页面的相关内容。基于图结构实现选择性、查询中心的检索和结构化证据聚合。

Result: 在MMLongBench-Doc和LongDocURL数据集上的实验表明，MLDocRAG能持续提升检索质量和答案准确性，验证了其在长上下文多模态理解中的有效性。

Conclusion: MLDocRAG通过查询中心的表示空间和基于图的结构，有效解决了多模态长文档理解中的跨模态和跨页面挑战，为长上下文多模态问答提供了更优的检索增强生成框架。

Abstract: Understanding multimodal long-context documents that comprise multimodal chunks such as paragraphs, figures, and tables is challenging due to (1) cross-modal heterogeneity to localize relevant information across modalities, (2) cross-page reasoning to aggregate dispersed evidence across pages. To address these challenges, we are motivated to adopt a query-centric formulation that projects cross-modal and cross-page information into a unified query representation space, with queries acting as abstract semantic surrogates for heterogeneous multimodal content. In this paper, we propose a Multimodal Long-Context Document Retrieval Augmented Generation (MLDocRAG) framework that leverages a Multimodal Chunk-Query Graph (MCQG) to organize multimodal document content around semantically rich, answerable queries. MCQG is constructed via a multimodal document expansion process that generates fine-grained queries from heterogeneous document chunks and links them to their corresponding content across modalities and pages. This graph-based structure enables selective, query-centric retrieval and structured evidence aggregation, thereby enhancing grounding and coherence in long-context multimodal question answering. Experiments on datasets MMLongBench-Doc and LongDocURL demonstrate that MLDocRAG consistently improves retrieval quality and answer accuracy, demonstrating its effectiveness for long-context multimodal understanding.

</details>


### [56] [Single-Turn LLM Reformulation Powered Multi-Stage Hybrid Re-Ranking for Tip-of-the-Tongue Known-Item Retrieval](https://arxiv.org/abs/2602.10321)
*Debayan Mukhopadhyay,Utshab Kumar Ghosh,Shubham Chatterjee*

Main category: cs.IR

TL;DR: 使用8B参数通用LLM进行单次查询改写，解决Tip-of-the-Tongue检索难题，通过多阶段检索流程显著提升召回率和排序指标


<details>
  <summary>Details</summary>
Motivation: Tip-of-the-Tongue检索中，用户通常给出模糊描述，难以直接匹配具体信息。传统Pseudo-Relevance Feedback在初始召回率低时效果不佳，需要更有效的查询改写方法。

Method: 使用通用8B参数LLM单次调用进行查询改写，无需领域微调。改写后的查询进入多阶段检索流程：稀疏检索(BM25)→密集/延迟交互重排(Contriever,E5-large-v2,ColBERTv2)→monoT5交叉编码→列表重排(Qwen 2.5 72B)。

Result: 在2025 TREC-ToT数据集上，原始查询性能差，但轻量级预检索转换使Recall提升20.61%。后续重排使nDCG@10提升33.88%，MRR提升29.92%，MAP@10提升29.98%。

Conclusion: 通用LLM的提示策略（而非模型专业化）可有效改进ToT检索，成本效益高，能释放下游排序器的潜力。方法不依赖特定领域微调，具有广泛适用性。

Abstract: Retrieving known items from vague descriptions, Tip-of-the-Tongue (ToT) retrieval, remains a significant challenge. We propose using a single call to a generic 8B-parameter LLM for query reformulation, bridging the gap between ill-formed ToT queries and specific information needs. This method is particularly effective where standard Pseudo-Relevance Feedback fails due to poor initial recall. Crucially, our LLM is not fine-tuned for ToT or specific domains, demonstrating that gains stem from our prompting strategy rather than model specialization. Rewritten queries feed a multi-stage pipeline: sparse retrieval (BM25), dense/late-interaction reranking (Contriever, E5-large-v2, ColBERTv2), monoT5 cross-encoding, and list-wise reranking (Qwen 2.5 72B). Experiments on 2025 TREC-ToT datasets show that while raw queries yield poor performance, our lightweight pre-retrieval transformation improves Recall by 20.61%. Subsequent reranking improves nDCG@10 by 33.88%, MRR by 29.92%, and MAP@10 by 29.98%, offering a cost-effective intervention that unlocks the potential of downstream rankers. Code and data: https://github.com/debayan1405/TREC-TOT-2025

</details>


### [57] [GeoGR: A Generative Retrieval Framework for Spatio-Temporal Aware POI Recommendation](https://arxiv.org/abs/2602.10411)
*Fangye Wang,Haowen Lin,Yifang Yuan,Siyuan Wang,Xiaojiang Zhou,Song Yang,Pengjie Wang*

Main category: cs.IR

TL;DR: GeoGR是一个为导航LBS设计的地理生成推荐框架，通过两阶段方法解决POI预测中的语义ID建模和LLM对齐问题，在实际部署中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于语义ID的POI推荐方法在复杂稀疏的真实环境中存在两个关键限制：1) 难以建模高质量捕捉跨类别时空协作关系的语义ID；2) 大语言模型与POI推荐任务对齐不佳。

Method: 提出两阶段框架：1) 地理感知的语义ID标记化流程，通过地理约束的共同访问POI对、对比学习和迭代优化来学习时空协作语义表示；2) 多阶段LLM训练策略，通过模板化持续预训练对齐非原生语义ID标记，并通过监督微调实现自回归POI生成。

Result: 在多个真实数据集上的实验显示GeoGR优于现有最优基线，在AMAP平台的实际部署中，通过多个在线指标提升证明了其实际有效性和可扩展性。

Conclusion: GeoGR框架成功解决了POI推荐中的语义ID建模和LLM对齐问题，为导航LBS提供了一种有效的意图感知POI推荐解决方案，并在大规模生产环境中验证了其价值。

Abstract: Next Point-of-Interest (POI) prediction is a fundamental task in location-based services, especially critical for large-scale navigation platforms like AMAP that serve billions of users across diverse lifestyle scenarios. While recent POI recommendation approaches based on SIDs have achieved promising, they struggle in complex, sparse real-world environments due to two key limitations: (1) inadequate modeling of high-quality SIDs that capture cross-category spatio-temporal collaborative relationships, and (2) poor alignment between large language models (LLMs) and the POI recommendation task. To this end, we propose GeoGR, a geographic generative recommendation framework tailored for navigation-based LBS like AMAP, which perceives users' contextual state changes and enables intent-aware POI recommendation. GeoGR features a two-stage design: (i) a geo-aware SID tokenization pipeline that explicitly learns spatio-temporal collaborative semantic representations via geographically constrained co-visited POI pairs, contrastive learning, and iterative refinement; and (ii) a multi-stage LLM training strategy that aligns non-native SID tokens through multiple template-based continued pre-training(CPT) and enables autoregressive POI generation via supervised fine-tuning(SFT). Extensive experiments on multiple real-world datasets demonstrate GeoGR's superiority over state-of-the-art baselines. Moreover, deployment on the AMAP platform, serving millions of users with multiple online metrics boosting, confirms its practical effectiveness and scalability in production.

</details>


### [58] [End-to-End Semantic ID Generation for Generative Advertisement Recommendation](https://arxiv.org/abs/2602.10445)
*Jie Jiang,Xinxun Zhang,Enming Zhang,Yuling Xiong,Jun Zhang,Jingwen Wang,Huan Yu,Yuxiang Wang,Hao Wang,Xiao Yan,Jiawei Jiang*

Main category: cs.IR

TL;DR: UniSID提出统一的语义ID生成框架，通过端到端联合优化解决传统残差量化在生成推荐中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有生成推荐方法依赖残差量化生成语义ID，存在两阶段压缩导致的目标错位和语义退化问题，以及残差量化的误差累积缺陷。

Method: 1) 端到端联合优化嵌入和语义ID，直接从原始广告数据中学习；2) 引入多粒度对比学习策略对齐不同语义ID层级的项目；3) 提出基于摘要的广告重建机制，让语义ID捕获广告上下文中未显式存在的高层语义信息。

Result: 实验表明UniSID持续优于最先进的语义ID生成方法，在下游广告场景中命中率指标相比最强基线提升高达4.62%。

Conclusion: UniSID通过统一的端到端框架解决了传统残差量化在语义ID生成中的根本缺陷，显著提升了生成推荐系统的性能。

Abstract: Generative Recommendation (GR) has excelled by framing recommendation as next-token prediction. This paradigm relies on Semantic IDs (SIDs) to tokenize large-scale items into discrete sequences. Existing GR approaches predominantly generate SIDs via Residual Quantization (RQ), where items are encoded into embeddings and then quantized to discrete SIDs. However, this paradigm suffers from inherent limitations: 1) Objective misalignment and semantic degradation stemming from the two-stage compression; 2) Error accumulation inherent in the structure of RQ. To address these limitations, we propose UniSID, a Unified SID generation framework for generative advertisement recommendation. Specifically, we jointly optimize embeddings and SIDs in an end-to-end manner from raw advertising data, enabling semantic information to flow directly into the SID space and thus addressing the inherent limitations of the two-stage cascading compression paradigm. To capture fine-grained semantics, a multi-granularity contrastive learning strategy is introduced to align distinct items across SID levels. Finally, a summary-based ad reconstruction mechanism is proposed to encourage SIDs to capture high-level semantic information that is not explicitly present in advertising contexts. Experiments demonstrate that UniSID consistently outperforms state-of-the-art SID generation methods, yielding up to a 4.62% improvement in Hit Rate metrics across downstream advertising scenarios compared to the strongest baseline.

</details>


### [59] [Compute Only Once: UG-Separation for Efficient Large Recommendation Models](https://arxiv.org/abs/2602.10455)
*Hui Lu,Zheng Chai,Shipeng Bai,Hao Zhang,Zhifang Fan,Kunmin Bai,Yingwen Wu,Bingzheng Wei,Xiang Sun,Ziyan Gong,Tianyi Liu,Hua Chen,Deping Xie,Zhongkai Chen,Zhiliang Guo,Qiwei Chen,Yuchao Zheng*

Main category: cs.IR

TL;DR: UG-Sep首次在稠密交互模型中实现可复用的用户侧计算，通过用户-组分离设计和信息补偿策略，结合量化技术，在保持推荐质量的同时显著降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 推荐系统依赖大规模模型来捕捉复杂特征交互，但带来高昂的训练和推理成本。现有长序列模型可通过KV缓存复用用户侧计算，但在稠密特征交互架构（如RankMixer）中，用户和候选项目特征在多层深度纠缠，难以实现类似复用。

Method: 提出用户-组分离（UG-Sep）框架：1）引入掩码机制在token混合层中显式分离用户侧和项目侧信息流，保持部分token的纯用户侧表示以支持跨样本复用；2）设计信息补偿策略自适应重建被抑制的用户-项目交互以弥补表达力损失；3）结合W8A16仅权重量化缓解内存带宽瓶颈。

Result: 在字节跳动的离线和在线A/B实验中，UG-Sep在保持在线用户体验和商业指标不变的情况下，在信息流推荐和广告系统等多个业务场景中将推理延迟降低高达20%。

Conclusion: UG-Sep首次实现了稠密交互模型中用户侧计算的有效复用，通过创新的分离设计和补偿策略，结合量化技术，为大规模推荐系统的效率优化提供了实用解决方案。

Abstract: Driven by scaling laws, recommender systems increasingly rely on large-scale models to capture complex feature interactions and user behaviors, but this trend also leads to prohibitive training and inference costs. While long-sequence models(e.g., LONGER) can reuse user-side computation through KV caching, such reuse is difficult in dense feature interaction architectures(e.g., RankMixer), where user and group (candidate item) features are deeply entangled across layers. In this work, we propose User-Group Separation (UG-Sep), a novel framework that enables reusable user-side computation in dense interaction models for the first time. UG-Sep introduces a masking mechanism that explicitly disentangles user-side and item-side information flows within token-mixing layers, ensuring that a subset of tokens to preserve purely user-side representations across layers. This design enables corresponding token computations to be reused across multiple samples, significantly reducing redundant inference cost. To compensate for potential expressiveness loss induced by masking, we further propose an Information Compensation strategy that adaptively reconstructs suppressed user-item interactions. Moreover, as UG-Sep substantially reduces user-side FLOPs and exposes memory-bound components, we incorporate W8A16 (8-bit weight, 16-bit activation) weight-only quantization to alleviate memory bandwidth bottlenecks and achieve additional acceleration. We conduct extensive offline evaluations and large-scale online A/B experiments at ByteDance, demonstrating that UG-Sep reduces inference latency by up to 20 percent without degrading online user experience or commercial metrics across multiple business scenarios, including feed recommendation and advertising systems.

</details>


### [60] [ChainRec: An Agentic Recommender Learning to Route Tool Chains for Diverse and Evolving Interests](https://arxiv.org/abs/2602.10490)
*Fuchun Li,Qian Li,Xingyu Gao,Bocheng Pan,Yang Wu,Jun Zhang,Huan Yu,Jie Jiang,Jinsheng Xiao,Hailong Shi*

Main category: cs.IR

TL;DR: ChainRec：一个使用规划器动态选择推理工具的智能推荐系统，在冷启动和兴趣演变场景中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的推荐系统大多采用固定工作流程，无法适应多样化的用户场景（如冷启动、兴趣转变）。需要智能体能够根据具体情境自适应地决定下一步收集什么证据，而不是遵循脚本化过程。

Method: 1. 从专家轨迹构建标准化的工具代理库
2. 使用监督微调和偏好优化训练规划器
3. 规划器动态选择工具、决定工具顺序、确定何时停止

Result: 在AgentRecBench上的实验（涵盖Amazon、Yelp、Goodreads）显示，ChainRec在Avg HR@{1,3,5}上持续优于强基线，在冷启动和兴趣演变场景中提升尤为显著。消融研究验证了工具标准化和偏好优化规划的重要性。

Conclusion: ChainRec通过动态工具选择和自适应规划，解决了现有智能推荐系统中固定工作流程的局限性，在多样化推荐场景中表现出优越性能。

Abstract: Large language models (LLMs) are increasingly integrated into recommender systems, motivating recent interest in agentic and reasoning-based recommendation. However, most existing approaches still rely on fixed workflows, applying the same reasoning procedure across diverse recommendation scenarios. In practice, user contexts vary substantially-for example, in cold-start settings or during interest shifts, so an agent should adaptively decide what evidence to gather next rather than following a scripted process. To address this, we propose ChainRec, an agentic recommender that uses a planner to dynamically select reasoning tools. ChainRec builds a standardized Tool Agent Library from expert trajectories. It then trains a planner using supervised fine-tuning and preference optimization to dynamically select tools, decide their order, and determine when to stop. Experiments on AgentRecBench across Amazon, Yelp, and Goodreads show that ChainRec consistently improves Avg HR@{1,3,5} over strong baselines, with especially notable gains in cold-start and evolving-interest scenarios. Ablation studies further validate the importance of tool standardization and preference-optimized planning.

</details>


### [61] [Boundary-Aware Multi-Behavior Dynamic Graph Transformer for Sequential Recommendation](https://arxiv.org/abs/2602.10493)
*Jingsong Su,Xuetao Ma,Mingming Li,Qiannan Zhu,Yu Guo*

Main category: cs.IR

TL;DR: 提出边界感知多行为动态图变换器（MB-DGT），通过动态优化图结构和序列行为建模提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时处理动态图拓扑和序列交互模式，且无法充分捕捉多行为边界，限制了用户偏好建模的准确性

Method: 提出MB-DGT模型，包含基于变换器的动态图聚合器来建模用户偏好，以及用户特定的多行为损失函数来区分行为边界

Result: 在三个数据集上的实验表明，该模型持续提供卓越的推荐性能

Conclusion: MB-DGT通过动态图结构优化和多行为边界建模，显著提升了用户偏好表示的准确性和推荐效果

Abstract: In the landscape of contemporary recommender systems, user-item interactions are inherently dynamic and sequential, often characterized by various behaviors. Prior research has explored the modeling of user preferences through sequential interactions and the user-item interaction graph, utilizing advanced techniques such as graph neural networks and transformer-based architectures. However, these methods typically fall short in simultaneously accounting for the dynamic nature of graph topologies and the sequential pattern of interactions in user preference models. Moreover, they often fail to adequately capture the multiple user behavior boundaries during model optimization. To tackle these challenges, we introduce a boundary-aware Multi-Behavioral Dynamic Graph Transformer (MB-DGT) model that dynamically refines the graph structure to reflect the evolving patterns of user behaviors and interactions. Our model involves a transformer-based dynamic graph aggregator for user preference modeling, which assimilates the changing graph structure and the sequence of user behaviors. This integration yields a more comprehensive and dynamic representation of user preferences. For model optimization, we implement a user-specific multi-behavior loss function that delineates the interest boundaries among different behaviors, thereby enriching the personalized learning of user preferences. Comprehensive experiments across three datasets indicate that our model consistently delivers remarkable recommendation performance.

</details>


### [62] [Campaign-2-PT-RAG: LLM-Guided Semantic Product Type Attribution for Scalable Campaign Ranking](https://arxiv.org/abs/2602.10577)
*Yiming Che,Mansi Mane,Keerthi Gopalakrishnan,Parisa Kaghazgaran,Murali Mohana Krishna Dandu,Archana Venkatachalapathy,Sinduja Subramaniam,Yokila Arora,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.IR

TL;DR: 一个利用LLM从营销活动内容推断相关产品类型，从而生成用户-活动购买标签的框架，解决了电商活动排名模型缺乏监督信号的问题。


<details>
  <summary>Details</summary>
Motivation: 电商活动排名模型需要大规模的训练标签来识别哪些用户因活动影响而购买，但生成这些标签很困难，因为活动使用创意性、主题性的语言，不直接映射到具体产品购买。缺乏明确的产品级归因限制了活动优化的监督学习。

Method: 提出了Campaign-2-PT-RAG框架：1) 使用LLM解释活动内容捕捉隐含意图；2) 通过语义搜索在平台分类中检索候选产品类型(PTs)；3) 使用结构化LLM分类器评估每个PT的相关性，生成活动特定的产品覆盖集；4) 用户购买匹配这些PTs时生成正训练标签供下游排名模型使用。

Result: 在内部和合成数据集上的实验显示，该方法生成高质量标签，精度达78-90%，同时保持超过99%的召回率，验证了基于专家标注的活动-PT映射。

Conclusion: 该框架将模糊的归因问题转化为可处理的语义对齐任务，为下游任务（如生产电商环境中的活动排名优化）提供了可扩展且一致的监督信号。

Abstract: E-commerce campaign ranking models require large-scale training labels indicating which users purchased due to campaign influence. However, generating these labels is challenging because campaigns use creative, thematic language that does not directly map to product purchases. Without clear product-level attribution, supervised learning for campaign optimization remains limited. We present \textbf{Campaign-2-PT-RAG}, a scalable label generation framework that constructs user--campaign purchase labels by inferring which product types (PTs) each campaign promotes. The framework first interprets campaign content using large language models (LLMs) to capture implicit intent, then retrieves candidate PTs through semantic search over the platform taxonomy. A structured LLM-based classifier evaluates each PT's relevance, producing a campaign-specific product coverage set. User purchases matching these PTs generate positive training labels for downstream ranking models. This approach reframes the ambiguous attribution problem into a tractable semantic alignment task, enabling scalable and consistent supervision for downstream tasks such as campaign ranking optimization in production e-commerce environments. Experiments on internal and synthetic datasets, validated against expert-annotated campaign--PT mappings, show that our LLM-assisted approach generates high-quality labels with 78--90% precision while maintaining over 99% recall.

</details>


### [63] [S-GRec: Personalized Semantic-Aware Generative Recommendation with Asymmetric Advantage](https://arxiv.org/abs/2602.10606)
*Jie Jiang,Hongbo Tang,Wenjie Wu,Yangru Huang,Zhenmao Li,Qian Li,Changping Wang,Jun Zhang,Huan Yu*

Main category: cs.IR

TL;DR: S-GRec是一个语义感知推荐框架，通过解耦在线轻量生成器和离线LLM语义评判器，在训练时提供语义监督，同时避免实时LLM推理的高成本，实现了业务目标和语义一致性的平衡。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐模型虽然能端到端生成物品序列，但行为日志训练提供的用户意图监督较弱。LLMs虽然能提供丰富的语义先验，但直接应用于工业推荐面临两个障碍：语义信号可能与平台商业目标冲突，且LLM推理在大规模场景下成本过高。

Method: 提出S-GRec框架：1) 两阶段个性化语义评判器(PSJ)：生成可解释的方面证据，从成对反馈中学习用户条件聚合，产生稳定的语义奖励；2) 非对称优势策略优化(A2PO)：以商业奖励（如eCPM）为优化锚点，仅在语义优势与商业目标一致时注入语义优势。

Result: 在公共基准和大规模生产系统上的实验验证了有效性和可扩展性：包括CTR的统计显著提升，在线A/B测试中GMV提升1.19%，且无需实时LLM推理。

Conclusion: S-GRec成功解决了LLM在工业推荐中的语义监督与商业目标冲突问题，通过解耦架构实现了语义感知推荐，在保持业务目标的同时提升了推荐质量，为大规模推荐系统提供了实用解决方案。

Abstract: Generative recommendation models sequence generation to produce items end-to-end, but training from behavioral logs often provides weak supervision on underlying user intent. Although Large Language Models (LLMs) offer rich semantic priors that could supply such supervision, direct adoption in industrial recommendation is hindered by two obstacles: semantic signals can conflict with platform business objectives, and LLM inference is prohibitively expensive at scale. This paper presents S-GRec, a semantic-aware framework that decouples an online lightweight generator from an offline LLM-based semantic judge for train-time supervision. S-GRec introduces a two-stage Personalized Semantic Judge (PSJ) that produces interpretable aspect evidence and learns user-conditional aggregation from pairwise feedback, yielding stable semantic rewards. To prevent semantic supervision from deviating from business goals, Asymmetric Advantage Policy Optimization (A2PO) anchors optimization on business rewards (e.g., eCPM) and injects semantic advantages only when they are consistent. Extensive experiments on public benchmarks and a large-scale production system validate both effectiveness and scalability, including statistically significant gains in CTR and a 1.19\% lift in GMV in online A/B tests, without requiring real-time LLM inference.

</details>


### [64] [A Cognitive Distribution and Behavior-Consistent Framework for Black-Box Attacks on Recommender Systems](https://arxiv.org/abs/2602.10633)
*Hongyue Zhan,Mingming Li,Dongqin Liu,Hui Wang,Yaning Zhang,Xi Zhou,Honglei Lv,Jiao Dai,Jizhong Han*

Main category: cs.IR

TL;DR: 提出双增强攻击框架：认知分布驱动提取机制+行为感知噪声项目生成策略，显著提升攻击成功率和规避率


<details>
  <summary>Details</summary>
Motivation: 现有黑盒提取攻击主要依赖硬标签或成对学习，忽视排名位置重要性，导致知识转移不完整；同时基于纯梯度方法生成的对抗序列缺乏与真实用户行为的语义一致性，易被检测

Method: 1. 基于首因效应和位置偏差的认知分布驱动提取机制，将离散排名映射为具有位置感知衰减的连续值分布，实现从顺序对齐到认知分布对齐；2. 行为感知噪声项目生成策略，联合优化协同信号和梯度信号，确保语义一致性和统计隐蔽性

Result: 在多个数据集上的实验表明，该方法在攻击成功率和规避率方面显著优于现有方法

Conclusion: 验证了将认知建模和行为一致性整合到安全推荐系统中的价值，为解决顺序推荐系统的安全问题提供了新思路

Abstract: With the growing deployment of sequential recommender systems in e-commerce and other fields, their black-box interfaces raise security concerns: models are vulnerable to extraction and subsequent adversarial manipulation. Existing black-box extraction attacks primarily rely on hard labels or pairwise learning, often ignoring the importance of ranking positions, which results in incomplete knowledge transfer. Moreover, adversarial sequences generated via pure gradient methods lack semantic consistency with real user behavior, making them easily detectable. To overcome these limitations, this paper proposes a dual-enhanced attack framework. First, drawing on primacy effects and position bias, we introduce a cognitive distribution-driven extraction mechanism that maps discrete rankings into continuous value distributions with position-aware decay, thereby advancing from order alignment to cognitive distribution alignment. Second, we design a behavior-aware noisy item generation strategy that jointly optimizes collaborative signals and gradient signals. This ensures both semantic coherence and statistical stealth while effectively promoting target item rankings. Extensive experiments on multiple datasets demonstrate that our approach significantly outperforms existing methods in both attack success rate and evasion rate, validating the value of integrating cognitive modeling and behavioral consistency for secure recommender systems.

</details>


### [65] [EST: Towards Efficient Scaling Laws in Click-Through Rate Prediction via Unified Modeling](https://arxiv.org/abs/2602.10811)
*Mingyang Liu,Yong Bai,Zhangming Chan,Sishuo Chen,Xiang-Rong Sheng,Han Zhu,Jian Xu,Xinyang Chen*

Main category: cs.IR

TL;DR: EST（高效可扩展Transformer）通过完全统一建模所有原始输入，利用轻量级交叉注意力和内容稀疏注意力，实现了工业CTR预测的稳定高效扩展，在淘宝广告平台上显著提升了效果。


<details>
  <summary>Details</summary>
Motivation: 现有CTR预测方法通常通过早期聚合用户行为来保持效率，但这种非统一或部分统一建模会丢弃细粒度的token级信号，形成信息瓶颈，限制了模型扩展收益的发挥。

Method: 提出高效可扩展Transformer（EST），通过单一序列处理所有原始输入实现完全统一建模。包含两个核心模块：轻量级交叉注意力（LCA）修剪冗余自交互以聚焦高影响力跨特征依赖；内容稀疏注意力（CSA）利用内容相似性动态选择高信号行为。

Result: EST展现出稳定高效的能量定律缩放关系，能够预测模型规模带来的性能提升。在淘宝展示广告平台部署中，显著超越生产基线，实现3.27%的RPM（每千次展示收入）提升和1.22%的CTR提升。

Conclusion: EST通过完全统一建模和专门的注意力机制，克服了现有CTR预测方法的信息瓶颈，为可扩展工业CTR预测模型提供了实用路径，实现了预测性能的稳定扩展和实际业务效果的显著提升。

Abstract: Efficiently scaling industrial Click-Through Rate (CTR) prediction has recently attracted significant research attention. Existing approaches typically employ early aggregation of user behaviors to maintain efficiency. However, such non-unified or partially unified modeling creates an information bottleneck by discarding fine-grained, token-level signals essential for unlocking scaling gains. In this work, we revisit the fundamental distinctions between CTR prediction and Large Language Models (LLMs), identifying two critical properties: the asymmetry in information density between behavioral and non-behavioral features, and the modality-specific priors of content-rich signals. Accordingly, we propose the Efficiently Scalable Transformer (EST), which achieves fully unified modeling by processing all raw inputs in a single sequence without lossy aggregation. EST integrates two modules: Lightweight Cross-Attention (LCA), which prunes redundant self-interactions to focus on high-impact cross-feature dependencies, and Content Sparse Attention (CSA), which utilizes content similarity to dynamically select high-signal behaviors. Extensive experiments show that EST exhibits a stable and efficient power-law scaling relationship, enabling predictable performance gains with model scale. Deployed on Taobao's display advertising platform, EST significantly outperforms production baselines, delivering a 3.27\% RPM (Revenue Per Mile) increase and a 1.22\% CTR lift, establishing a practical pathway for scalable industrial CTR prediction models.

</details>


### [66] [Training-Induced Bias Toward LLM-Generated Content in Dense Retrieval](https://arxiv.org/abs/2602.10833)
*William Xion,Wolfgang Nejdl*

Main category: cs.IR

TL;DR: 密集检索器在训练过程中会发展出对LLM生成文本的偏好（源偏差），这种偏差主要来自监督微调而非模型固有特性，困惑度解释力有限。


<details>
  <summary>Details</summary>
Motivation: 近期研究显示密集检索器普遍偏好大语言模型（LLM）生成的文本而非人类文本，这种"源偏差"被认为与较低困惑度有关。本研究旨在重新审视这一主张，探究这种偏好在不同训练阶段和数据源中的出现情况。

Method: 使用SciFact和Natural Questions数据集的并行人类生成和LLM生成版本，比较无监督检查点与使用领域内人类文本、领域内LLM生成文本和MS MARCO微调的模型。通过重新附加语言建模头到微调后的密集检索器编码器进行检索器中心化困惑度探测。

Result: 1) 无监督检索器没有表现出一致的亲LLM偏好，方向和幅度取决于数据集；2) MS MARCO监督微调始终使排名偏向LLM生成文本；3) 领域内微调产生数据集特定且不一致的偏好变化；4) LLM生成语料库微调诱导明显的亲LLM偏差；5) 困惑度探测显示与相关性的相关性接近随机，削弱了困惑度的解释力。

Conclusion: 源偏差是训练诱导的现象，而非密集检索器的固有属性。监督微调（特别是使用MS MARCO和LLM生成数据）是产生这种偏差的主要原因，困惑度不能很好地解释检索器的偏好行为。

Abstract: Dense retrieval is a promising approach for acquiring relevant context or world knowledge in open-domain natural language processing tasks and is now widely used in information retrieval applications. However, recent reports claim a broad preference for text generated by large language models (LLMs). This bias is called "source bias", and it has been hypothesized that lower perplexity contributes to this effect. In this study, we revisit this claim by conducting a controlled evaluation to trace the emergence of such preferences across training stages and data sources. Using parallel human- and LLM-generated counterparts of the SciFact and Natural Questions (NQ320K) datasets, we compare unsupervised checkpoints with models fine-tuned using in-domain human text, in-domain LLM-generated text, and MS MARCO. Our results show the following: 1) Unsupervised retrievers do not exhibit a uniform pro-LLM preference. The direction and magnitude depend on the dataset. 2) Across the settings tested, supervised fine-tuning on MS MARCO consistently shifts the rankings toward LLM-generated text. 3) In-domain fine-tuning produces dataset-specific and inconsistent shifts in preference. 4) Fine-tuning on LLM-generated corpora induces a pronounced pro-LLM bias. Finally, a retriever-centric perplexity probe involving the reattachment of a language modeling head to the fine-tuned dense retriever encoder indicates agreement with relevance near chance, thereby weakening the explanatory power of perplexity. Our study demonstrates that source bias is a training-induced phenomenon rather than an inherent property of dense retrievers.

</details>
