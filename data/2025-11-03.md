<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Understanding and Enhancing Mamba-Transformer Hybrids for Memory Recall and Language Modeling](https://arxiv.org/abs/2510.26912)
*Hyunji Lee,Wenhao Yu,Hongming Zhang,Kaixin Ma,Jiyeon Kim,Dong Yu,Minjoon Seo*

Main category: cs.CL

TL;DR: 本文分析了混合状态空间模型与注意力机制的架构设计，发现顺序混合在短上下文表现更好，并行混合在长上下文更有效，并提出了一种基于数据增强的持续训练方法来提升召回能力。


<details>
  <summary>Details</summary>
Motivation: 混合状态空间模型与注意力机制的模型虽然表现出色，但其架构设计选择背后的原理仍不够清晰，需要深入理解不同集成方式对内存利用和性能的影响。

Method: 首先分析了顺序和并行两种SSM与注意力层的集成方式，然后提出了一种数据驱动的方法：在包含释义增强的数据集上进行持续训练。

Result: 研究发现顺序混合在短上下文表现更好，并行混合在长上下文更有效；数据增强的持续训练方法能进一步提升召回能力，且在不同基础模型上都能良好泛化，优于仅通过架构修改来增强召回的方法。

Conclusion: 研究为混合SSM-注意力模型提供了更深入的理解，并为针对不同使用场景设计架构提供了实用指导。

Abstract: Hybrid models that combine state space models (SSMs) with attention
mechanisms have shown strong performance by leveraging the efficiency of SSMs
and the high recall ability of attention. However, the architectural design
choices behind these hybrid models remain insufficiently understood. In this
work, we analyze hybrid architectures through the lens of memory utilization
and overall performance, and propose a complementary method to further enhance
their effectiveness. We first examine the distinction between sequential and
parallel integration of SSM and attention layers. Our analysis reveals several
interesting findings, including that sequential hybrids perform better on
shorter contexts, whereas parallel hybrids are more effective for longer
contexts. We also introduce a data-centric approach of continually training on
datasets augmented with paraphrases, which further enhances recall while
preserving other capabilities. It generalizes well across different base models
and outperforms architectural modifications aimed at enhancing recall. Our
findings provide a deeper understanding of hybrid SSM-attention models and
offer practical guidance for designing architectures tailored to various use
cases. Our findings provide a deeper understanding of hybrid SSM-attention
models and offer practical guidance for designing architectures tailored to
various use cases.

</details>


### [2] [Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence](https://arxiv.org/abs/2510.26969)
*Lívia Dutra,Arthur Lorenzi,Laís Berno,Franciany Campos,Karoline Biscardi,Kenneth Brown,Marcelo Viridiano,Frederico Belcavello,Ely Matos,Olívia Guaranha,Erik Santos,Sofia Reinach,Tiago Timponi Torrent*

Main category: cs.CL

TL;DR: 提出了一种基于语义框架的方法，用于从电子医疗记录中识别基于性别的暴力事件，在2100万句巴西葡萄牙语语料上测试，识别精度达到0.726。


<details>
  <summary>Details</summary>
Motivation: 解决基于性别的暴力事件在电子医疗记录中报告不足的问题，为公共卫生监测提供透明、高效、低碳且语言无关的解决方案。

Method: 利用语义框架定义细粒度模式，在电子医疗记录的非结构化文本字段中搜索这些模式，定义了8种模式并在2100万句语料上进行搜索。

Result: 方法有效识别暴力报告，精度达到0.726，结果由语言学家手动评估验证。

Conclusion: 该方法稳健有效，可轻松适应其他健康监测场景，有助于在公共卫生系统中更广泛、道德和可解释地使用自然语言处理技术。

Abstract: We introduce a methodology for the identification of notifiable events in the
domain of healthcare. The methodology harnesses semantic frames to define
fine-grained patterns and search them in unstructured data, namely, open-text
fields in e-medical records. We apply the methodology to the problem of
underreporting of gender-based violence (GBV) in e-medical records produced
during patients' visits to primary care units. A total of eight patterns are
defined and searched on a corpus of 21 million sentences in Brazilian
Portuguese extracted from e-SUS APS. The results are manually evaluated by
linguists and the precision of each pattern measured. Our findings reveal that
the methodology effectively identifies reports of violence with a precision of
0.726, confirming its robustness. Designed as a transparent, efficient,
low-carbon, and language-agnostic pipeline, the approach can be easily adapted
to other health surveillance contexts, contributing to the broader, ethical,
and explainable use of NLP in public health systems.

</details>


### [3] [Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations](https://arxiv.org/abs/2510.26974)
*Jean-Philippe Corbeil,Asma Ben Abacha,Jerome Tremblay,Phillip Swazinna,Akila Jeeson Daniel,Miguel Del-Agua,Francois Beaulieu*

Main category: cs.CL

TL;DR: MEDIQA-OE 2025是首个从医患对话中提取医疗指令的共享任务，旨在减轻临床医生的文档负担并改善患者护理。


<details>
  <summary>Details</summary>
Motivation: 临床文档越来越多地使用自动语音识别和摘要技术，但将对话转化为电子健康记录中的可操作医疗指令仍未得到探索。解决这个问题可以显著减轻临床医生的文档负担，并直接影响下游患者护理。

Method: 引入了MEDIQA-OE 2025共享任务，六个团队参与并尝试了广泛的方法，包括闭源和开源的大语言模型。

Result: 论文描述了MEDIQA-OE任务、数据集、最终排行榜排名以及参与者的解决方案。

Conclusion: MEDIQA-OE 2025共享任务为从医患对话中提取医疗指令这一重要问题提供了首个挑战平台，展示了各种方法的潜力。

Abstract: Clinical documentation increasingly uses automatic speech recognition and
summarization, yet converting conversations into actionable medical orders for
Electronic Health Records remains unexplored. A solution to this problem can
significantly reduce the documentation burden of clinicians and directly impact
downstream patient care. We introduce the MEDIQA-OE 2025 shared task, the first
challenge on extracting medical orders from doctor-patient conversations. Six
teams participated in the shared task and experimented with a broad range of
approaches, and both closed- and open-weight large language models (LLMs). In
this paper, we describe the MEDIQA-OE task, dataset, final leaderboard ranking,
and participants' solutions.

</details>


### [4] [Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services](https://arxiv.org/abs/2510.27016)
*Jayden Serenari,Stephen Lee*

Main category: cs.CL

TL;DR: LOPSIDED框架是一种语义感知的隐私保护代理，通过动态替换用户提示中的敏感PII实体为语义一致的假名，在保护隐私的同时保持对话的上下文完整性，相比基线技术将语义效用错误减少了5倍。


<details>
  <summary>Details</summary>
Motivation: 随着对话AI系统的广泛使用，用户在与大型语言模型交互时分享敏感个人数据可能导致隐私泄露，特别是个人可识别信息(PII)的暴露可能引发安全漏洞或身份盗窃。

Method: 提出了LOPSIDED框架，采用动态替换敏感PII实体为语义一致假名的方法，在模型生成响应后自动进行假名还原，确保用户获得准确且隐私保护的输出。使用ShareGPT的真实对话数据进行评估，并进一步增量和标注以评估命名实体与模型响应的上下文相关性。

Result: LOPSIDED相比基线技术将语义效用错误减少了5倍，同时增强了隐私保护。

Conclusion: LOPSIDED框架在保护用户隐私的同时有效保持了对话的语义完整性，为使用远程LLM时的隐私保护提供了实用解决方案。

Abstract: With the increasing use of conversational AI systems, there is growing
concern over privacy leaks, especially when users share sensitive personal data
in interactions with Large Language Models (LLMs). Conversations shared with
these models may contain Personally Identifiable Information (PII), which, if
exposed, could lead to security breaches or identity theft. To address this
challenge, we present the Local Optimizations for Pseudonymization with
Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a
semantically-aware privacy agent designed to safeguard sensitive PII data when
using remote LLMs. Unlike prior work that often degrade response quality, our
approach dynamically replaces sensitive PII entities in user prompts with
semantically consistent pseudonyms, preserving the contextual integrity of
conversations. Once the model generates its response, the pseudonyms are
automatically depseudonymized, ensuring the user receives an accurate,
privacy-preserving output. We evaluate our approach using real-world
conversations sourced from ShareGPT, which we further augment and annotate to
assess whether named entities are contextually relevant to the model's
response. Our results show that LOPSIDED reduces semantic utility errors by a
factor of 5 compared to baseline techniques, all while enhancing privacy.

</details>


### [5] [Kad: A Framework for Proxy-based Test-time Alignment with Knapsack Approximation Deferral](https://arxiv.org/abs/2510.27017)
*Ayoub Hammal,Pierre Zweigenbaum,Caio Corro*

Main category: cs.CL

TL;DR: 提出一种基于代理的测试时对齐方法，使用小型对齐模型指导大型语言模型，通过0-1背包问题制定令牌级延迟规则，在任务性能和推测解码速度方面均获得提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然预训练阶段已学习大部分生成能力，但仍需对齐以适应下游任务需求，而随着模型规模扩大，对齐过程的计算成本急剧增加。

Method: 采用令牌级级联方法，将令牌特定延迟规则简化为0-1背包问题，推导出最优延迟决策的原始和对偶近似解。

Result: 实验证明该方法在任务性能和推测解码速度方面均表现出优势。

Conclusion: 提出的代理测试时对齐方法能有效规避大型语言模型对齐的高计算成本，同时保持或提升模型性能。

Abstract: Several previous works concluded that the largest part of generation
capabilities of large language models (LLM) are learned (early) during
pre-training. However, LLMs still require further alignment to adhere to
downstream task requirements and stylistic preferences, among other desired
properties. As LLMs continue to scale in terms of size, the computational cost
of alignment procedures increase prohibitively. In this work, we propose a
novel approach to circumvent these costs via proxy-based test-time alignment,
i.e. using guidance from a small aligned model. Our approach can be described
as token-specific cascading method, where the token-specific deferral rule is
reduced to 0-1 knapsack problem. In this setting, we derive primal and dual
approximations of the optimal deferral decision. We experimentally show the
benefits of our method both in task performance and speculative decoding speed.

</details>


### [6] [Elastic Architecture Search for Efficient Language Models](https://arxiv.org/abs/2510.27037)
*Shang Wang*

Main category: cs.CL

TL;DR: ELM是一种新颖的神经架构搜索方法，专门为紧凑语言模型优化，通过灵活的搜索空间和动态模块调整，结合知识蒸馏损失，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型在自然语言理解任务中计算和内存需求巨大，带来经济和环境问题，需要开发更紧凑高效的模型。

Method: ELM扩展现有NAS方法，引入包含高效transformer块和动态维度、头数调整模块的灵活搜索空间，并使用新颖的知识蒸馏损失来保持各块特性。

Result: 在掩码语言建模和因果语言建模任务上的实验表明，ELM发现的模型显著优于现有方法。

Conclusion: ELM通过创新的NAS方法和知识蒸馏技术，成功开发出更高效、紧凑的语言模型，解决了大型模型的计算和环境问题。

Abstract: As large pre-trained language models become increasingly critical to natural
language understanding (NLU) tasks, their substantial computational and memory
requirements have raised significant economic and environmental concerns.
Addressing these challenges, this paper introduces the Elastic Language Model
(ELM), a novel neural architecture search (NAS) method optimized for compact
language models. ELM extends existing NAS approaches by introducing a flexible
search space with efficient transformer blocks and dynamic modules for
dimension and head number adjustment. These innovations enhance the efficiency
and flexibility of the search process, which facilitates more thorough and
effective exploration of model architectures. We also introduce novel knowledge
distillation losses that preserve the unique characteristics of each block, in
order to improve the discrimination between architectural choices during the
search process. Experiments on masked language modeling and causal language
modeling tasks demonstrate that models discovered by ELM significantly
outperform existing methods.

</details>


### [7] [Dataset Creation and Baseline Models for Sexism Detection in Hausa](https://arxiv.org/abs/2510.27038)
*Fatima Adam Muhammad,Shamsuddeen Muhammad Hassan,Isa Inuwa-Dutse*

Main category: cs.CL

TL;DR: 本研究创建了首个豪萨语性别歧视检测数据集，通过社区参与、定性编码和数据增强开发，并探索了传统机器学习与预训练多语言模型在豪萨语性别歧视检测中的效果。


<details>
  <summary>Details</summary>
Motivation: 在线平台助长了各种形式的性别歧视，但现有性别歧视检测方法主要针对高资源语言，低资源语言如豪萨语由于语言资源有限和文化差异，检测进展缓慢。

Method: 通过两阶段用户研究（n=66）收集本地说话者对性别歧视的定义和表达，结合社区参与、定性编码和数据增强构建数据集，使用传统机器学习分类器和预训练多语言语言模型进行实验。

Result: 研究发现在捕捉文化细微差别方面存在挑战，特别是在澄清寻求和习语表达方面，这些情况下容易出现许多误报。

Conclusion: 本研究强调了在低资源语言中检测性别歧视时考虑文化细微差别的重要性，并为豪萨语性别歧视检测提供了首个数据集和基准方法。

Abstract: Sexism reinforces gender inequality and social exclusion by perpetuating
stereotypes, bias, and discriminatory norms. Noting how online platforms enable
various forms of sexism to thrive, there is a growing need for effective sexism
detection and mitigation strategies. While computational approaches to sexism
detection are widespread in high-resource languages, progress remains limited
in low-resource languages where limited linguistic resources and cultural
differences affect how sexism is expressed and perceived. This study introduces
the first Hausa sexism detection dataset, developed through community
engagement, qualitative coding, and data augmentation. For cultural nuances and
linguistic representation, we conducted a two-stage user study (n=66) involving
native speakers to explore how sexism is defined and articulated in everyday
discourse. We further experiment with both traditional machine learning
classifiers and pre-trained multilingual language models and evaluating the
effectiveness few-shot learning in detecting sexism in Hausa. Our findings
highlight challenges in capturing cultural nuance, particularly with
clarification-seeking and idiomatic expressions, and reveal a tendency for many
false positives in such cases.

</details>


### [8] [Quantitative Intertextuality from the Digital Humanities Perspective: A Survey](https://arxiv.org/abs/2510.27045)
*Siyu Duan*

Main category: cs.CL

TL;DR: 本文提供了量化互文性研究的路线图，总结了数据、方法和应用，涵盖从统计到深度学习的多种方法，并展望了在AI与人文科学交叉研究中的更广泛应用前景。


<details>
  <summary>Details</summary>
Motivation: 互文性作为文学理论中的重要概念，在数字人文学科中具有重要理论基础。随着自然语言处理技术的发展，互文性研究进入了量化时代，需要系统总结这一领域的研究现状和发展方向。

Method: 基于多语言和多主题的数据，综述了从统计方法到深度学习的各种量化互文性研究方法，并总结了相关平台工具。

Result: 总结了量化互文性研究的数据、方法和应用现状，展示了该领域在人文社会科学研究中的具体应用案例。

Conclusion: 随着计算机技术的进步，可以预期更精确、多样化和大规模的互文性研究。互文性在连接人工智能与人文学科的跨学科研究中具有广阔的应用前景。

Abstract: The connection between texts is referred to as intertextuality in literary
theory, which served as an important theoretical basis in many digital
humanities studies. Over the past decade, advancements in natural language
processing have ushered intertextuality studies into the quantitative age.
Large-scale intertextuality research based on cutting-edge methods has
continuously emerged. This paper provides a roadmap for quantitative
intertextuality studies, summarizing their data, methods, and applications.
Drawing on data from multiple languages and topics, this survey reviews methods
from statistics to deep learning. It also summarizes their applications in
humanities and social sciences research and the associated platform tools.
Driven by advances in computer technology, more precise, diverse, and
large-scale intertext studies can be anticipated. Intertextuality holds promise
for broader application in interdisciplinary research bridging AI and the
humanities.

</details>


### [9] [Recursive numeral systems are highly regular and easy to process](https://arxiv.org/abs/2510.27049)
*Ponrawee Prasertsom,Andrea Silvi,Jennifer Culbertson,Moa Johansson,Devdatt Dubhashi,Kenny Smith*

Main category: cs.CL

TL;DR: 本文提出基于最小描述长度（MDL）的方法来衡量递归数字系统的规律性和处理复杂性，认为自然语言系统在这两方面更优，而非仅基于词汇大小和形态句法复杂性的权衡。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为递归数字系统在词汇大小和平均形态句法复杂性之间达到最优权衡，但需要依赖临时约束来排除不自然的系统。本文认为问题在于忽略了规律性这一人类语法的关键方面。

Method: 采用最小描述长度（MDL）方法，提出衡量规律性和处理复杂性的新指标，比较自然系统与先前研究中"最优"但不自然的递归数字系统。

Result: MDL方法能更好地区分自然系统与不自然但可能的系统，先前文献中的临时约束自然地由规律性推导得出。

Conclusion: 研究表明在语言最优性研究中需要纳入形式集合的规律性，递归数字系统在规律性和处理复杂性方面更高效。

Abstract: Previous work has argued that recursive numeral systems optimise the
trade-off between lexicon size and average morphosyntatic complexity (Deni\'c
and Szymanik, 2024). However, showing that only natural-language-like systems
optimise this tradeoff has proven elusive, and the existing solution has relied
on ad-hoc constraints to rule out unnatural systems (Yang and Regier, 2025).
Here, we argue that this issue arises because the proposed trade-off has
neglected regularity, a crucial aspect of complexity central to human grammars
in general. Drawing on the Minimum Description Length (MDL) approach, we
propose that recursive numeral systems are better viewed as efficient with
regard to their regularity and processing complexity. We show that our
MDL-based measures of regularity and processing complexity better capture the
key differences between attested, natural systems and unattested but possible
ones, including "optimal" recursive numeral systems from previous work, and
that the ad-hoc constraints from previous literature naturally follow from
regularity. Our approach highlights the need to incorporate regularity across
sets of forms in studies that attempt to measure and explain optimality in
language.

</details>


### [10] [VISTA Score: Verification In Sequential Turn-based Assessment](https://arxiv.org/abs/2510.27052)
*Ashley Lewis,Andrew Perrault,Eric Fosler-Lussier,Michael White*

Main category: cs.CL

TL;DR: VISTA是一个用于评估对话系统事实性的框架，通过声明级验证和序列一致性跟踪来检测多轮对话中的幻觉问题，相比现有方法在多个基准测试中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有的事实性评估指标要么评估孤立回复，要么将不可验证内容视为错误，限制了在多轮对话中的应用。幻觉（生成无证据支持或与上下文矛盾的陈述）是部署对话AI系统的主要障碍。

Method: VISTA框架将每个助手回复分解为原子事实声明，根据可信来源和对话历史进行验证，并将不可验证陈述分类（主观、矛盾、缺乏证据或弃权）。

Result: 在8个大语言模型和4个对话事实性基准测试（AIS、BEGIN、FAITHDIAL、FADE）中，VISTA在幻觉检测方面显著优于FACTSCORE和LLM-as-Judge基线方法。人工评估确认VISTA的分解方法提高了标注者一致性并揭示了现有基准的不一致问题。

Conclusion: 通过将事实性建模为对话的动态属性，VISTA为对话系统提供了一个更透明、更符合人类认知的真实性衡量标准。

Abstract: Hallucination--defined here as generating statements unsupported or
contradicted by available evidence or conversational context--remains a major
obstacle to deploying conversational AI systems in settings that demand factual
reliability. Existing metrics either evaluate isolated responses or treat
unverifiable content as errors, limiting their use for multi-turn dialogue. We
introduce VISTA (Verification In Sequential Turn-based Assessment), a framework
for evaluating conversational factuality through claim-level verification and
sequential consistency tracking. VISTA decomposes each assistant turn into
atomic factual claims, verifies them against trusted sources and dialogue
history, and categorizes unverifiable statements (subjective, contradicted,
lacking evidence, or abstaining). Across eight large language models and four
dialogue factuality benchmarks (AIS, BEGIN, FAITHDIAL, and FADE), VISTA
substantially improves hallucination detection over FACTSCORE and LLM-as-Judge
baselines. Human evaluation confirms that VISTA's decomposition improves
annotator agreement and reveals inconsistencies in existing benchmarks. By
modeling factuality as a dynamic property of conversation, VISTA offers a more
transparent, human-aligned measure of truthfulness in dialogue systems.

</details>


### [11] [Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs](https://arxiv.org/abs/2510.27246)
*Mohammad Tavakoli,Alireza Salemi,Carrie Ye,Mohamed Abdalla,Hamed Zamani,J Ross Mitchell*

Main category: cs.CL

TL;DR: 本文提出了BEAM基准测试和LIGHT框架，用于评估和改进大语言模型在长对话中的记忆能力。BEAM包含100个长对话和2000个问题，LIGHT框架通过三个记忆系统提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏叙事连贯性、覆盖领域狭窄，且只测试简单的回忆任务，无法充分评估大语言模型在长上下文推理中的记忆能力。

Method: 1) 提出自动生成长对话的框架，构建BEAM基准测试；2) 提出LIGHT框架，包含长期情景记忆、短期工作记忆和事实积累便签三个互补记忆系统。

Result: 实验表明，即使具有100万token上下文窗口的LLM在长对话中表现不佳，而LIGHT框架在不同模型上平均提升3.5%-12.69%的性能，消融研究证实了各记忆组件的贡献。

Conclusion: LIGHT框架通过模拟人类认知的多重记忆系统，有效提升了LLM在长对话中的记忆和推理能力，为解决长上下文推理问题提供了有效方案。

Abstract: Evaluating the abilities of large language models (LLMs) for tasks that
require long-term memory and thus long-context reasoning, for example in
conversational settings, is hampered by the existing benchmarks, which often
lack narrative coherence, cover narrow domains, and only test simple
recall-oriented tasks. This paper introduces a comprehensive solution to these
challenges. First, we present a novel framework for automatically generating
long (up to 10M tokens), coherent, and topically diverse conversations,
accompanied by probing questions targeting a wide range of memory abilities.
From this, we construct BEAM, a new benchmark comprising 100 conversations and
2,000 validated questions. Second, to enhance model performance, we propose
LIGHT-a framework inspired by human cognition that equips LLMs with three
complementary memory systems: a long-term episodic memory, a short-term working
memory, and a scratchpad for accumulating salient facts. Our experiments on
BEAM reveal that even LLMs with 1M token context windows (with and without
retrieval-augmentation) struggle as dialogues lengthen. In contrast, LIGHT
consistently improves performance across various models, achieving an average
improvement of 3.5%-12.69% over the strongest baselines, depending on the
backbone LLM. An ablation study further confirms the contribution of each
memory component.

</details>


### [12] [LLM-Centric RAG with Multi-Granular Indexing and Confidence Constraints](https://arxiv.org/abs/2510.27054)
*Xiaofan Guo,Yaxuan Luan,Yue Kang,Xiangchen Song,Jinxu Guo*

Main category: cs.CL

TL;DR: 提出了一种结合多粒度记忆索引和不确定性估计的置信度控制方法，用于提升复杂知识环境下检索增强生成的覆盖度、稳定性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂知识环境下检索增强生成存在的覆盖不足、结果不稳定和可靠性有限的问题。

Method: 构建分层记忆结构将知识表示划分为不同粒度级别，实现从局部细节到全局上下文的动态索引和检索；引入不确定性估计机制，在生成过程中显式约束和过滤低置信度路径；优化目标包括生成损失、熵约束和方差正则化。

Result: 在问答准确性、检索召回率、排序质量和事实一致性方面优于现有模型，证明了多粒度索引与置信度控制结合的有效性。

Conclusion: 为检索增强生成提供了新的技术路径，并为提高大模型在复杂环境下的可靠性和可控性提供了实践证据。

Abstract: This paper addresses the issues of insufficient coverage, unstable results,
and limited reliability in retrieval-augmented generation under complex
knowledge environments, and proposes a confidence control method that
integrates multi-granularity memory indexing with uncertainty estimation. The
method builds a hierarchical memory structure that divides knowledge
representations into different levels of granularity, enabling dynamic indexing
and retrieval from local details to global context, and thus establishing
closer semantic connections between retrieval and generation. On this basis, an
uncertainty estimation mechanism is introduced to explicitly constrain and
filter low-confidence paths during the generation process, allowing the model
to maintain information coverage while effectively suppressing noise and false
content. The overall optimization objective consists of generation loss,
entropy constraints, and variance regularization, forming a unified confidence
control framework. In the experiments, comprehensive sensitivity tests and
comparative analyses were designed, covering hyperparameters, environmental
conditions, and data structures, to verify the stability and robustness of the
proposed method across different scenarios. The results show that the method
achieves superior performance over existing models in QA accuracy, retrieval
recall, ranking quality, and factual consistency, demonstrating the
effectiveness of combining multi-granularity indexing with confidence control.
This study not only provides a new technical pathway for retrieval-augmented
generation but also offers practical evidence for improving the reliability and
controllability of large models in complex contexts.

</details>


### [13] [Detecting Data Contamination in LLMs via In-Context Learning](https://arxiv.org/abs/2510.27055)
*Michał Zawalski,Meriem Boubdir,Klaudia Bałazy,Besmira Nushi,Pablo Ribalta*

Main category: cs.CL

TL;DR: CoDeC是一种实用的训练数据污染检测方法，通过测量上下文学习对模型性能的影响来区分记忆数据和未见数据。


<details>
  <summary>Details</summary>
Motivation: 需要检测和量化大型语言模型中的训练数据污染问题，特别是对于训练语料未公开的模型。

Method: 利用上下文学习的影响来检测污染：上下文示例通常会提升对未见数据集的置信度，但对于训练过的数据集可能因记忆模式被破坏而降低置信度。

Result: CoDeC产生可解释的污染分数，能清晰区分已见和未见数据集，并在未公开训练语料的开放权重模型中揭示强烈记忆证据。

Conclusion: 该方法简单、自动化、模型和数据集无关，易于集成到基准评估中，是一种准确实用的污染检测方案。

Abstract: We present Contamination Detection via Context (CoDeC), a practical and
accurate method to detect and quantify training data contamination in large
language models. CoDeC distinguishes between data memorized during training and
data outside the training distribution by measuring how in-context learning
affects model performance. We find that in-context examples typically boost
confidence for unseen datasets but may reduce it when the dataset was part of
training, due to disrupted memorization patterns. Experiments show that CoDeC
produces interpretable contamination scores that clearly separate seen and
unseen datasets, and reveals strong evidence of memorization in open-weight
models with undisclosed training corpora. The method is simple, automated, and
both model- and dataset-agnostic, making it easy to integrate with benchmark
evaluations.

</details>


### [14] [Contrastive Knowledge Transfer and Robust Optimization for Secure Alignment of Large Language Models](https://arxiv.org/abs/2510.27077)
*Jiasen Zheng,Huajun Zhang,Xu Yan,Ran Hao,Chong Peng*

Main category: cs.CL

TL;DR: 提出了一种结合对比蒸馏和噪声鲁棒训练的微调方法，通过冻结主干模型并转移教师模型的知识边界，提高语义一致性和对齐精度，同时在训练中引入噪声扰动和鲁棒优化约束，确保模型在噪声和不确定输入下保持稳定预测输出。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型在安全对齐和鲁棒性方面的局限性，现有方法在知识转移、鲁棒性和整体安全性方面存在不足。

Method: 采用对比蒸馏与噪声鲁棒训练相结合的微调方法，框架包含蒸馏损失、鲁棒性损失和正则化项，形成统一的优化目标，平衡对齐能力与抗干扰能力。

Result: 该方法在知识转移、鲁棒性和整体安全性方面显著优于现有基线方法，在多个关键指标上达到最佳性能。

Conclusion: 该工作不仅丰富了参数高效微调的理论体系，还为构建更安全、更可信的对齐机制提供了新的解决方案。

Abstract: This paper addresses the limitations of large-scale language models in safety
alignment and robustness by proposing a fine-tuning method that combines
contrastive distillation with noise-robust training. The method freezes the
backbone model and transfers the knowledge boundaries of the teacher model to
the student model through distillation, thereby improving semantic consistency
and alignment accuracy. At the same time, noise perturbations and robust
optimization constraints are introduced during training to ensure that the
model maintains stable predictive outputs under noisy and uncertain inputs. The
overall framework consists of distillation loss, robustness loss, and a
regularization term, forming a unified optimization objective that balances
alignment ability with resistance to interference. To systematically validate
its effectiveness, the study designs experiments from multiple perspectives,
including distillation weight sensitivity, stability analysis under computation
budgets and mixed-precision environments, and the impact of data noise and
distribution shifts on model performance. Results show that the method
significantly outperforms existing baselines in knowledge transfer, robustness,
and overall safety, achieving the best performance across several key metrics.
This work not only enriches the theoretical system of parameter-efficient
fine-tuning but also provides a new solution for building safer and more
trustworthy alignment mechanisms.

</details>


### [15] [Characterizing Selective Refusal Bias in Large Language Models](https://arxiv.org/abs/2510.27087)
*Adel Khorramrouz,Sharon Levy*

Main category: cs.CL

TL;DR: 研究发现LLM安全护栏存在选择性拒绝偏见，对不同人口群体（性别、性取向、国籍、宗教）的拒绝率不一致，这可能导致新的偏见问题。


<details>
  <summary>Details</summary>
Motivation: LLM安全护栏旨在防止生成有害内容，但可能无意中引入新的偏见，因为模型可能拒绝针对某些人口群体而非其他群体的有害内容生成。

Method: 通过分析针对个体和交叉人口群体的拒绝率、LLM响应类型以及生成拒绝的长度来探索选择性拒绝偏见。

Result: 结果显示在性别、性取向、国籍和宗教属性上存在选择性拒绝偏见的证据。通过间接攻击测试发现，之前被拒绝的群体面临额外的安全风险。

Conclusion: 需要开发更公平和稳健的安全护栏，确保在不同人口群体间的性能一致性。

Abstract: Safety guardrails in large language models(LLMs) are developed to prevent
malicious users from generating toxic content at a large scale. However, these
measures can inadvertently introduce or reflect new biases, as LLMs may refuse
to generate harmful content targeting some demographic groups and not others.
We explore this selective refusal bias in LLM guardrails through the lens of
refusal rates of targeted individual and intersectional demographic groups,
types of LLM responses, and length of generated refusals. Our results show
evidence of selective refusal bias across gender, sexual orientation,
nationality, and religion attributes. This leads us to investigate additional
safety implications via an indirect attack, where we target previously refused
groups. Our findings emphasize the need for more equitable and robust
performance in safety guardrails across demographic groups.

</details>


### [16] [Rating Roulette: Self-Inconsistency in LLM-As-A-Judge Frameworks](https://arxiv.org/abs/2510.27106)
*Rajarshi Haldar,Julia Hockenmaier*

Main category: cs.CL

TL;DR: LLM评估自然语言生成任务时存在评分不一致问题，但通过合理使用仍可发挥作用


<details>
  <summary>Details</summary>
Motivation: 随着自然语言生成技术广泛应用，评估变得困难。虽然LLM评估比传统指标更符合人类偏好，但其评分一致性存在问题

Method: 通过实验量化LLM评估在不同NLG任务和基准测试中的不一致性，并探索合理使用LLM评估的指导原则

Result: 发现LLM评估者在不同运行中评分可靠性低，评分存在较大方差，导致评估结果几乎随机

Conclusion: LLM评估存在显著的不一致性问题，但在遵循适当指导原则的情况下仍可谨慎使用

Abstract: As Natural Language Generation (NLG) continues to be widely adopted, properly
assessing it has become quite difficult. Lately, using large language models
(LLMs) for evaluating these generations has gained traction, as they tend to
align more closely with human preferences than conventional n-gram or
embedding-based metrics. In our experiments, we show that LLM judges have low
intra-rater reliability in their assigned scores across different runs. This
variance makes their ratings inconsistent, almost arbitrary in the worst case,
making it difficult to measure how good their judgments actually are. We
quantify this inconsistency across different NLG tasks and benchmarks and see
if judicious use of LLM judges can still be useful following proper guidelines.

</details>


### [17] [Probability Distributions Computed by Hard-Attention Transformers](https://arxiv.org/abs/2510.27118)
*Andy Yang,Anej Svete,Jiaoda Li,Anthony Widjaja Lin,Jonathan Rawski,Ryan Cotterell,David Chiang*

Main category: cs.CL

TL;DR: 本文分析了Transformer语言模型的表达能力，重点关注其作为概率性自回归生成模型的实际使用方式，而非传统的语言识别器视角。研究发现自回归和概率性特性会影响Transformer的表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer表达能力研究主要将其视为语言识别器（接受或拒绝字符串），但实际应用中Transformer主要作为语言模型使用（自回归概率性生成字符串）。需要研究Transformer在真实使用场景下的表达能力。

Method: 通过理论分析，研究Transformer语言模型能够表达的概率分布特性，比较自回归和非自回归、概率性和非概率性情况下的表达能力差异。

Result: 研究发现：1）使Transformer语言识别器具有自回归特性有时能增强其表达能力；2）概率性特性会打破非概率性情况下的等价关系；3）揭示了Transformer在语言模型使用场景下的表达能力边界。

Conclusion: 本文系统分析了Transformer语言模型的表达能力，强调了考虑实际使用方式（自回归概率生成）的重要性，为理解Transformer在真实应用中的能力边界提供了理论依据。

Abstract: Most expressivity results for transformers treat them as language recognizers
(which accept or reject strings), and not as they are used in practice, as
language models (which generate strings autoregressively and
probabilistically). Here, we characterize the probability distributions that
transformer language models can express. We show that making transformer
language recognizers autoregressive can sometimes increase their expressivity,
and that making them probabilistic can break equivalences that hold in the
non-probabilistic case. Our overall contribution is to tease apart what
functions transformers are capable of expressing, in their most common use-case
as language models.

</details>


### [18] [Simple Additions, Substantial Gains: Expanding Scripts, Languages, and Lineage Coverage in URIEL+](https://arxiv.org/abs/2510.27183)
*Mason Shipton,York Hay Ng,Aditya Khan,Phuong Hanh Hoang,Xiang Lu,A. Seza Doğruöz,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 本文扩展了URIEL+语言知识库，通过添加文字系统向量、整合Glottolog增加语言覆盖度，以及扩展谱系插补来减少数据稀疏性问题，提升了多语言研究的完整性和包容性。


<details>
  <summary>Details</summary>
Motivation: URIEL+语言知识库存在数据稀疏性问题，包括缺失特征类型、不完整的语言条目和有限的谱系覆盖，这限制了其在跨语言迁移特别是支持低资源语言方面的实用性。

Method: 1) 为7,488种语言引入文字系统向量；2) 整合Glottolog增加18,710种语言；3) 为26,449种语言扩展谱系插补，在谱系间传播类型学和文字特征。

Result: 文字向量特征稀疏性减少14%，语言覆盖度增加高达19,015种语言（1,007%），插补质量指标提升高达33%。在跨语言迁移任务中，某些设置下性能提升达6%。

Conclusion: 这些改进使URIEL+在多语言研究中更加完整和包容，为低资源语言的跨语言迁移提供了更好的支持。

Abstract: The URIEL+ linguistic knowledge base supports multilingual research by
encoding languages through geographic, genetic, and typological vectors.
However, data sparsity remains prevalent, in the form of missing feature types,
incomplete language entries, and limited genealogical coverage. This limits the
usefulness of URIEL+ in cross-lingual transfer, particularly for supporting
low-resource languages. To address this sparsity, this paper extends URIEL+
with three contributions: introducing script vectors to represent writing
system properties for 7,488 languages, integrating Glottolog to add 18,710
additional languages, and expanding lineage imputation for 26,449 languages by
propagating typological and script features across genealogies. These additions
reduce feature sparsity by 14% for script vectors, increase language coverage
by up to 19,015 languages (1,007%), and improve imputation quality metrics by
up to 33%. Our benchmark on cross-lingual transfer tasks (oriented around
low-resource languages) shows occasionally divergent performance compared to
URIEL+, with performance gains up to 6% in certain setups. Our advances make
URIEL+ more complete and inclusive for multilingual research.

</details>


### [19] [MemeArena: Automating Context-Aware Unbiased Evaluation of Harmfulness Understanding for Multimodal Large Language Models](https://arxiv.org/abs/2510.27196)
*Zixin Chen,Hongzhan Lin,Kaixin Li,Ziyang Luo,Yayue Deng,Jing Ma*

Main category: cs.CL

TL;DR: 提出了MemeArena评估框架，通过基于代理的竞技场式评估方法，对多模态大语言模型在理解多模态有害内容方面的能力进行上下文感知和无偏见的评估。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要关注多模态大语言模型在二元分类任务中的检测准确性，往往无法反映不同上下文中对有害性的深度解释细微差别。

Method: MemeArena模拟多样化的解释上下文来制定评估任务，从多模态大语言模型中引出特定视角的分析，通过整合不同观点并在评估者之间达成共识，实现公平无偏见的比较。

Result: 广泛实验表明，该框架有效减少了评估代理的偏见，判断结果与人类偏好高度一致，为多模态有害性理解提供了可靠且全面的评估见解。

Conclusion: MemeArena框架为多模态大语言模型在多模态有害内容理解方面的评估提供了有价值的工具，能够进行上下文感知和无偏见的评估。

Abstract: The proliferation of memes on social media necessitates the capabilities of
multimodal Large Language Models (mLLMs) to effectively understand multimodal
harmfulness. Existing evaluation approaches predominantly focus on mLLMs'
detection accuracy for binary classification tasks, which often fail to reflect
the in-depth interpretive nuance of harmfulness across diverse contexts. In
this paper, we propose MemeArena, an agent-based arena-style evaluation
framework that provides a context-aware and unbiased assessment for mLLMs'
understanding of multimodal harmfulness. Specifically, MemeArena simulates
diverse interpretive contexts to formulate evaluation tasks that elicit
perspective-specific analyses from mLLMs. By integrating varied viewpoints and
reaching consensus among evaluators, it enables fair and unbiased comparisons
of mLLMs' abilities to interpret multimodal harmfulness. Extensive experiments
demonstrate that our framework effectively reduces the evaluation biases of
judge agents, with judgment results closely aligning with human preferences,
offering valuable insights into reliable and comprehensive mLLM evaluations in
multimodal harmfulness understanding. Our code and data are publicly available
at https://github.com/Lbotirx/MemeArena.

</details>


### [20] [Identifying the Periodicity of Information in Natural Language](https://arxiv.org/abs/2510.27241)
*Yulin Ou,Yu Wang,Yang Xu,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: 本文提出了一种名为AutoPeriod of Surprisal (APS)的新方法，用于检测自然语言中信息密度的周期性模式，发现在人类语言中存在显著的周期性信息模式，并识别出超越典型文本结构单元的新周期。


<details>
  <summary>Details</summary>
Motivation: 信息密度理论的发展引发了对自然语言中信息编码周期性程度的疑问，需要探索语言信息是否具有周期性模式。

Method: 采用APS方法，这是一种规范周期性检测算法，能够识别单个文档惊奇值序列中的任何显著周期。

Result: 研究发现：1）相当比例的人类语言表现出强烈的信息周期性模式；2）发现了超越典型文本结构单元分布的新周期，并通过谐波回归模型进一步确认。

Conclusion: 语言中信息的周期性是结构化因素和长距离作用的其他驱动因素共同作用的结果。该方法在LLM生成检测方面具有潜在应用价值。

Abstract: Recent theoretical advancement of information density in natural language has
brought the following question on desk: To what degree does natural language
exhibit periodicity pattern in its encoded information? We address this
question by introducing a new method called AutoPeriod of Surprisal (APS). APS
adopts a canonical periodicity detection algorithm and is able to identify any
significant periods that exist in the surprisal sequence of a single document.
By applying the algorithm to a set of corpora, we have obtained the following
interesting results: Firstly, a considerable proportion of human language
demonstrates a strong pattern of periodicity in information; Secondly, new
periods that are outside the distributions of typical structural units in text
(e.g., sentence boundaries, elementary discourse units, etc.) are found and
further confirmed via harmonic regression modeling. We conclude that the
periodicity of information in language is a joint outcome from both structured
factors and other driving factors that take effect at longer distances. The
advantages of our periodicity detection method and its potentials in
LLM-generation detection are further discussed.

</details>


### [21] [Languages are Modalities: Cross-Lingual Alignment via Encoder Injection](https://arxiv.org/abs/2510.27254)
*Rajan Agarwal,Aarush Gupta*

Main category: cs.CL

TL;DR: LLINK是一种计算高效的语言注入方法，通过将多语言编码器的句子嵌入对齐到解码器的潜在空间，改善低资源非拉丁文字语言模型的性能，无需更改分词器或重新训练解码器。


<details>
  <summary>Details</summary>
Motivation: 指令调优的大型语言模型在低资源非拉丁文字上表现不佳，主要由于分词器碎片化和弱跨语言耦合问题。

Method: 首先将冻结多语言编码器的句子嵌入通过轻量级对比投影器对齐到解码器潜在嵌入空间的保留位置；然后将向量扩展为K个软槽，通过最小适配器训练，使冻结解码器能够消费信号。

Result: LLINK显著改善了双语检索性能，在LLM评判的Q&A评估中，81.3%优于基础模型，63.6%优于直接微调。改进归因于减少分词膨胀和更强的跨语言对齐。

Conclusion: 将低资源语言视为一种模态，为轻量级LLMs中更强的跨语言对齐提供了一条实用路径，尽管在数值保真度方面仍存在残余弱点。

Abstract: Instruction-tuned Large Language Models (LLMs) underperform on low resource,
non-Latin scripts due to tokenizer fragmentation and weak cross-lingual
coupling. We present LLINK (Latent Language Injection for Non-English
Knowledge), a compute efficient language-as-modality method that conditions an
instruction-tuned decoder without changing the tokenizer or retraining the
decoder. First, we align sentence embeddings from a frozen multilingual encoder
to the decoder's latent embedding space at a reserved position via a
lightweight contrastive projector. Second, the vector is expanded into K soft
slots and trained with minimal adapters so the frozen decoder consumes the
signal. LLINK substantially improves bilingual retrieval and achieves 81.3%
preference over the base model and 63.6% over direct fine-tuning in LLM-judged
Q&A evaluations. We further find that improvements can be attributed to reduced
tokenization inflation and a stronger cross lingual alignment, despite the
model having residual weaknesses in numeric fidelity. Treating low resource
languages as a modality offers a practical path to stronger cross-lingual
alignment in lightweight LLMs.

</details>


### [22] [MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models](https://arxiv.org/abs/2510.27267)
*Kangkun Mao,Jinru Ding,Jiayuan Chen,Mouxiao Bian,Ruiyao Chen,Xinwei Peng,Sijie Ren,Linyang Li,Jie Xu*

Main category: cs.CL

TL;DR: 提出了MedCalc-Eval基准测试，包含700多个医疗计算任务，用于评估LLM在医疗领域的定量推理能力，并通过MedCalc-Env强化学习环境提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有医疗基准测试主要关注问答和描述性推理，忽视了临床决策中关键的定量推理能力，现有数据集如MedCalc-Bench覆盖的计算任务较少且不能反映真实世界的计算场景。

Method: 开发了MedCalc-Eval基准测试，包含方程型计算和基于规则的评分系统两类任务；建立了MedCalc-Env强化学习环境，基于InternBootcamp框架支持多步临床推理和规划；对Qwen2.5-32B模型进行微调。

Result: 在MedCalc-Eval上实现了最先进的结果，在数值敏感性、公式选择和推理鲁棒性方面取得了显著提升。

Conclusion: 该研究填补了医疗领域定量推理评估的空白，但单位转换、多条件逻辑和上下文理解仍然是需要解决的挑战。

Abstract: As large language models (LLMs) enter the medical domain, most benchmarks
evaluate them on question answering or descriptive reasoning, overlooking
quantitative reasoning critical to clinical decision-making. Existing datasets
like MedCalc-Bench cover few calculation tasks and fail to reflect real-world
computational scenarios.
  We introduce MedCalc-Eval, the largest benchmark for assessing LLMs' medical
calculation abilities, comprising 700+ tasks across two types: equation-based
(e.g., Cockcroft-Gault, BMI, BSA) and rule-based scoring systems (e.g., Apgar,
Glasgow Coma Scale). These tasks span diverse specialties including internal
medicine, surgery, pediatrics, and cardiology, offering a broader and more
challenging evaluation setting.
  To improve performance, we further develop MedCalc-Env, a reinforcement
learning environment built on the InternBootcamp framework, enabling multi-step
clinical reasoning and planning. Fine-tuning a Qwen2.5-32B model within this
environment achieves state-of-the-art results on MedCalc-Eval, with notable
gains in numerical sensitivity, formula selection, and reasoning robustness.
Remaining challenges include unit conversion, multi-condition logic, and
contextual understanding.
  Code and datasets are available at
https://github.com/maokangkun/MedCalc-Eval.

</details>


### [23] [Why Do Multilingual Reasoning Gaps Emerge in Reasoning Language Models?](https://arxiv.org/abs/2510.27269)
*Deokhyung Kang,Seonjeong Hwang,Daehui Kim,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 本文发现多语言推理差距主要由语言理解失败引起，提出选择性翻译策略，仅当检测到理解失败时才翻译输入，在仅翻译约20%输入的情况下达到接近全翻译的性能。


<details>
  <summary>Details</summary>
Motivation: 推理语言模型在多语言推理任务中存在性能差距，高资源语言表现优于低资源语言，但其根本原因尚未被充分探索。

Method: 通过分析发现理解失败是主要原因，评估多种检测方法，提出选择性翻译策略，仅在检测到理解失败时将多语言输入翻译为英语。

Result: 选择性翻译策略显著缩小了多语言推理差距，在仅翻译约20%输入的情况下达到了接近全翻译的性能水平。

Conclusion: 理解失败是多语言推理差距的主要根源，可以通过检测和选择性缓解来改善，为实现更公平的多语言推理提供了关键见解和可行路径。

Abstract: Reasoning language models (RLMs) achieve strong performance on complex
reasoning tasks, yet they still suffer from a multilingual reasoning gap,
performing better in high-resource languages than in low-resource ones. While
recent efforts have reduced this gap, its underlying causes remain largely
unexplored. In this paper, we address this by showing that the multilingual
reasoning gap largely stems from failures in language understanding-the model's
inability to represent the multilingual input meaning into the dominant
language (i.e., English) within its reasoning trace. This motivates us to
examine whether understanding failures can be detected, as this ability could
help mitigate the multilingual reasoning gap. To this end, we evaluate a range
of detection methods and find that understanding failures can indeed be
identified, with supervised approaches performing best. Building on this, we
propose Selective Translation, a simple yet effective strategy that translates
the multilingual input into English only when an understanding failure is
detected. Experimental results show that Selective Translation bridges the
multilingual reasoning gap, achieving near full-translation performance while
using translation for only about 20% of inputs. Together, our work demonstrates
that understanding failures are the primary cause of the multilingual reasoning
gap and can be detected and selectively mitigated, providing key insight into
its origin and a promising path toward more equitable multilingual reasoning.
Our code and data are publicly available at
https://github.com/deokhk/RLM_analysis.

</details>


### [24] [A Unified Representation Underlying the Judgment of Large Language Models](https://arxiv.org/abs/2510.27328)
*Yi-Long Lu,Jiajun Song,Wei Wang*

Main category: cs.CL

TL;DR: 研究发现大型语言模型使用统一的评价维度（VAA）同时编码主观价值和事实认同，这种架构导致推理过程从公正推断转向目标导向的合理化，从而产生系统性偏见和幻觉。


<details>
  <summary>Details</summary>
Motivation: 探讨智能系统是依赖专门模块还是统一通用资源进行判断，特别是在发现LLMs中可解码的不同概念表示后，这些表示是否真正独立仍待验证。

Method: 通过分析多种LLMs，识别出主导的评价维度（VAA），并通过直接干预实验验证其功能。

Result: 发现VAA作为控制信号引导生成过程构建与其评价状态一致的合理化，即使牺牲事实准确性，导致推理从公正推断转向目标导向的合理化。

Conclusion: 这种促进连贯判断的架构会系统性削弱忠实推理，为系统性偏见和幻觉提供了机制性解释。

Abstract: A central architectural question for both biological and artificial
intelligence is whether judgment relies on specialized modules or a unified,
domain-general resource. While the discovery of decodable neural
representations for distinct concepts in Large Language Models (LLMs) has
suggested a modular architecture, whether these representations are truly
independent systems remains an open question. Here we provide evidence for a
convergent architecture. Across a range of LLMs, we find that diverse
evaluative judgments are computed along a dominant dimension, which we term the
Valence-Assent Axis (VAA). This axis jointly encodes subjective valence ("what
is good") and the model's assent to factual claims ("what is true"). Through
direct interventions, we show this unified representation creates a critical
dependency: the VAA functions as a control signal that steers the generative
process to construct a rationale consistent with its evaluative state, even at
the cost of factual accuracy. This mechanism, which we term the subordination
of reasoning, shifts the process of reasoning from impartial inference toward
goal-directed justification. Our discovery offers a mechanistic account for
systemic bias and hallucination, revealing how an architecture that promotes
coherent judgment can systematically undermine faithful reasoning.

</details>


### [25] [TransAlign: Machine Translation Encoders are Strong Word Aligners, Too](https://arxiv.org/abs/2510.27337)
*Benedikt Ebing,Christian Goldschmied,Goran Glavaš*

Main category: cs.CL

TL;DR: TransAlign是一种基于大规模多语言机器翻译模型编码器的新型词对齐器，在基于机器翻译的跨语言迁移中显著优于现有词对齐和非词对齐标签投影方法。


<details>
  <summary>Details</summary>
Motivation: 大多数世界语言缺乏大规模训练数据，基于翻译的跨语言迁移策略（如translate-test和translate-train）需要词对齐来进行标签投影。现有方法主要依赖mBERT或LaBSE等编码器语言模型，而机器翻译模型在词对齐方面的潜力未被充分挖掘。

Method: 提出TransAlign词对齐器，利用大规模多语言机器翻译模型的编码器来提取词对齐信息，而不是传统上使用的编码器语言模型或基于交叉注意力的方法。

Result: TransAlign不仅实现了强大的词对齐性能，而且在基于机器翻译的跨语言迁移中，显著优于流行的词对齐方法和最先进的非词对齐标签投影方法。

Conclusion: 利用大规模多语言机器翻译模型的编码器进行词对齐是有效的，TransAlign为跨语言迁移中的标签投影提供了更优的解决方案。

Abstract: In the absence of sizable training data for most world languages and NLP
tasks, translation-based strategies such as translate-test -- evaluating on
noisy source language data translated from the target language -- and
translate-train -- training on noisy target language data translated from the
source language -- have been established as competitive approaches for
cross-lingual transfer (XLT). For token classification tasks, these strategies
require label projection: mapping the labels from each token in the original
sentence to its counterpart(s) in the translation. To this end, it is common to
leverage multilingual word aligners (WAs) derived from encoder language models
such as mBERT or LaBSE. Despite obvious associations between machine
translation (MT) and WA, research on extracting alignments with MT models is
largely limited to exploiting cross-attention in encoder-decoder architectures,
yielding poor WA results. In this work, in contrast, we propose TransAlign, a
novel word aligner that utilizes the encoder of a massively multilingual MT
model. We show that TransAlign not only achieves strong WA performance but
substantially outperforms popular WA and state-of-the-art non-WA-based label
projection methods in MT-based XLT for token classification.

</details>


### [26] [ThoughtProbe: Classifier-Guided LLM Thought Space Exploration via Probing Representations](https://arxiv.org/abs/2510.27355)
*Zijian Wang,Chang Xu*

Main category: cs.CL

TL;DR: ThoughtProbe是一个新颖的推理时间框架，利用LLM的隐藏推理特征来提升推理性能，通过树结构响应空间探索和分支聚合方法，在多个算术推理基准上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要操纵隐藏表示来引导LLM生成，但ThoughtProbe将这些表示作为判别信号来指导树结构响应空间的探索，以更有效地利用计算资源。

Method: 在节点扩展时使用分类器作为评分和排序机制，优先处理高分候选进行延续；完成树扩展后收集所有分支的答案形成候选池，并通过聚合CoT分数来识别最优答案。

Result: 实验结果表明，该框架的全面探索不仅覆盖了有效的推理链，还能有效识别它们，在多个算术推理基准上实现了显著改进。

Conclusion: ThoughtProbe通过利用LLM的隐藏推理特征进行树结构探索和分支聚合，显著提升了推理性能，证明了该方法在算术推理任务中的有效性。

Abstract: This paper introduces ThoughtProbe, a novel inference time framework that
leverages the hidden reasoning features of Large Language Models (LLMs) to
improve their reasoning performance. Unlike previous works that manipulate the
hidden representations to steer LLM generation, we harness them as
discriminative signals to guide the tree structured response space exploration.
In each node expansion, a classifier serves as a scoring and ranking mechanism
that efficiently allocates computational resources by prioritizing higher score
candidates for continuation. After completing the tree expansion, we collect
answers from all branches to form a candidate answer pool. We then propose a
branch aggregation method that marginalizes over all supporting branches by
aggregating their CoT scores, thereby identifying the optimal answer from the
pool. Experimental results show that our framework's comprehensive exploration
not only covers valid reasoning chains but also effectively identifies them,
achieving significant improvements across multiple arithmetic reasoning
benchmarks.

</details>


### [27] [From the Rock Floor to the Cloud: A Systematic Survey of State-of-the-Art NLP in Battery Life Cycle](https://arxiv.org/abs/2510.27369)
*Tosin Adewumi,Martin Karlsson,Marcus Liwicki,Mikael Sjödahl,Lama Alkhaled,Rihab Gargouri,Nudrat Habib,Franz Hennie*

Main category: cs.CL

TL;DR: 该论文对自然语言处理在电池全生命周期应用进行了系统性调查，提出了技术语言处理框架，并评估了274篇科学论文中的66篇相关研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注电池生命周期的单一阶段或方法，缺乏对整个生命周期中NLP应用的全面调查，且欧盟提出的数字电池护照需要新的技术框架支持。

Method: 采用PRISMA系统评价方法，使用Google Scholar、IEEE Xplore和Scopus三个数据库，评估274篇论文并最终评审66篇相关论文。

Result: 研究发现电池领域涌现出新的NLP任务，有助于材料发现和生命周期各阶段，但仍面临缺乏标准基准等挑战。

Conclusion: 提出的技术语言处理框架结合智能AI和优化提示，能够应对部分挑战，为数字电池护照和一般电池预测提供支持。

Abstract: We present a comprehensive systematic survey of the application of natural
language processing (NLP) along the entire battery life cycle, instead of one
stage or method, and introduce a novel technical language processing (TLP)
framework for the EU's proposed digital battery passport (DBP) and other
general battery predictions. We follow the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) method and employ three reputable
databases or search engines, including Google Scholar, Institute of Electrical
and Electronics Engineers Xplore (IEEE Xplore), and Scopus. Consequently, we
assessed 274 scientific papers before the critical review of the final 66
relevant papers. We publicly provide artifacts of the review for validation and
reproducibility. The findings show that new NLP tasks are emerging in the
battery domain, which facilitate materials discovery and other stages of the
life cycle. Notwithstanding, challenges remain, such as the lack of standard
benchmarks. Our proposed TLP framework, which incorporates agentic AI and
optimized prompts, will be apt for tackling some of the challenges.

</details>


### [28] [Balancing Knowledge Updates: Toward Unified Modular Editing in LLMs](https://arxiv.org/abs/2510.27400)
*Jiahao Liu,Zijian Wang,Kuo Zhao,Dong Hu*

Main category: cs.CL

TL;DR: 本文提出IntAttn-Edit方法，通过联合更新MLP和注意力模块来改进大语言模型的知识编辑效果，使用知识平衡策略根据各模块对知识存储的贡献分配更新幅度。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法主要关注MLP模块的权重修改，而忽略了注意力模块在事实知识存储和检索中的重要作用，这种不平衡会导致残留过时知识并限制编辑效果。

Method: 基于对先进LLMs的知识定位实验发现，提出IntAttn-Edit方法，将关联记忆范式扩展到联合更新MLP和注意力模块，采用知识平衡策略按各模块对知识存储的贡献比例分配更新幅度。

Result: 在标准基准测试中，IntAttn-Edit相比先前方法实现了更高的编辑成功率、更好的泛化能力和更强的知识保持能力，平衡策略能在不同设置下保持编辑性能在最优范围内。

Conclusion: 注意力模块在事实知识存储中扮演重要角色，特别是在早期层，联合更新MLP和注意力模块的知识编辑方法能显著提升编辑效果，知识平衡策略是确保编辑性能的关键。

Abstract: Knowledge editing has emerged as an efficient approach for updating factual
knowledge in large language models (LLMs). It typically locates knowledge
storage modules and then modifies their parameters. However, most existing
methods focus on the weights of multilayer perceptron (MLP) modules, which are
often identified as the main repositories of factual information. Other
components, such as attention (Attn) modules, are often ignored during editing.
This imbalance can leave residual outdated knowledge and limit editing
effectiveness. We perform comprehensive knowledge localization experiments on
advanced LLMs and find that Attn modules play a substantial role in factual
knowledge storage and retrieval, especially in earlier layers. Based on these
insights, we propose IntAttn-Edit, a method that extends the associative memory
paradigm to jointly update both MLP and Attn modules. Our approach uses a
knowledge balancing strategy that allocates update magnitudes in proportion to
each module's measured contribution to knowledge storage. Experiments on
standard benchmarks show that IntAttn-Edit achieves higher edit success, better
generalization, and stronger knowledge preservation than prior methods. Further
analysis shows that the balancing strategy keeps editing performance within an
optimal range across diverse settings.

</details>


### [29] [Awal -- Community-Powered Language Technology for Tamazight](https://arxiv.org/abs/2510.27407)
*Alp Öktem,Farida Boudichat*

Main category: cs.CL

TL;DR: Awal是一个社区驱动的倡议，旨在为塔马齐特语开发语言技术资源。该平台通过众包方式收集翻译和语音数据，但在18个月内仅收集到6,421个翻译对和3小时语音数据，显示标准众包方法在复杂社会语言环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决塔马齐特语在数字空间中的代表性不足问题，应对该语言持续存在的数据稀缺挑战。

Method: 通过awaldigital.org协作平台，让塔马齐特语使用者贡献翻译和语音数据，采用社区驱动的方法。

Result: 18个月的社区参与显示参与存在显著障碍，包括对书面塔马齐特语的信心不足和标准化挑战。实际数据贡献主要集中在语言学家和活动家群体中，收集到6,421个翻译对和3小时语音数据。

Conclusion: 标准众包方法在具有复杂社会语言背景的语言中存在局限性，需要改进方法来更好地支持塔马齐特语的语言技术发展。

Abstract: This paper presents Awal, a community-powered initiative for developing
language technology resources for Tamazight. We provide a comprehensive review
of the NLP landscape for Tamazight, examining recent progress in computational
resources, and the emergence of community-driven approaches to address
persistent data scarcity. Launched in 2024, awaldigital.org platform addresses
the underrepresentation of Tamazight in digital spaces through a collaborative
platform enabling speakers to contribute translation and voice data. We analyze
18 months of community engagement, revealing significant barriers to
participation including limited confidence in written Tamazight and ongoing
standardization challenges. Despite widespread positive reception, actual data
contribution remained concentrated among linguists and activists. The modest
scale of community contributions -- 6,421 translation pairs and 3 hours of
speech data -- highlights the limitations of applying standard crowdsourcing
approaches to languages with complex sociolinguistic contexts. We are working
on improved open-source MT models using the collected data.

</details>


### [30] [Dynamic Affective Memory Management for Personalized LLM Agents](https://arxiv.org/abs/2510.27418)
*Junfeng Lu,Yueyan Li*

Main category: cs.CL

TL;DR: 提出基于贝叶斯启发和记忆熵概念的记忆管理系统，解决个性化AI代理中的记忆冗余、陈旧和整合问题，通过最小化全局熵实现动态记忆更新。


<details>
  <summary>Details</summary>
Motivation: 当前个性化AI代理系统依赖外部记忆数据库，但面临记忆冗余、记忆陈旧和记忆-上下文整合差的问题，主要由于交互过程中缺乏有效的记忆更新机制。

Method: 采用贝叶斯启发的记忆更新算法，引入记忆熵概念，使代理能够通过最小化全局熵来自主维护动态更新的记忆向量数据库。

Result: 实验结果表明，该系统在个性化、逻辑一致性和准确性方面表现优异，消融研究进一步验证了贝叶斯启发更新机制在缓解记忆膨胀方面的有效性。

Conclusion: 这项工作为长期记忆系统的设计提供了新的见解，证明了基于熵最小化的动态记忆管理方法在情感场景中的有效性。

Abstract: Advances in large language models are making personalized AI agents a new
research focus. While current agent systems primarily rely on personalized
external memory databases to deliver customized experiences, they face
challenges such as memory redundancy, memory staleness, and poor memory-context
integration, largely due to the lack of effective memory updates during
interaction. To tackle these issues, we propose a new memory management system
designed for affective scenarios. Our approach employs a Bayesian-inspired
memory update algorithm with the concept of memory entropy, enabling the agent
to autonomously maintain a dynamically updated memory vector database by
minimizing global entropy to provide more personalized services. To better
evaluate the system's effectiveness in this context, we propose DABench, a
benchmark focusing on emotional expression and emotional change toward objects.
Experimental results demonstrate that, our system achieves superior performance
in personalization, logical coherence, and accuracy. Ablation studies further
validate the effectiveness of the Bayesian-inspired update mechanism in
alleviating memory bloat. Our work offers new insights into the design of
long-term memory systems.

</details>


### [31] [VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision](https://arxiv.org/abs/2510.27462)
*Xuan Gong,Senmiao Wang,Hanbo Huang,Ruoyu Sun,Shiyu Liang*

Main category: cs.CL

TL;DR: VCORE是一种基于优化理论的方法，通过控制方差来重新分配监督信号，解决了传统交叉熵损失在长链思维推理中均匀处理所有token的问题，显著提升了LLMs在数学和编程任务中的推理性能。


<details>
  <summary>Details</summary>
Motivation: 标准交叉熵损失在长链思维推理中对所有token进行均匀处理，忽略了不同token在推理轨迹中的异质贡献，导致监督信号分配不当和泛化能力弱，特别是在复杂的长期推理任务中。

Method: VCORE将链式思维监督重新表述为一个约束优化问题，采用优化理论视角，实现跨token的原则性和自适应监督分配，使训练目标更贴近鲁棒推理泛化的目标。

Result: VCORE在数学和编程基准测试中，使用Qwen3系列和LLaMA-3.1-8B-Instruct模型，在域内和域外设置下均取得显著性能提升，且作为强化学习的初始化方法更有效。

Conclusion: VCORE通过优化理论框架实现了监督信号的合理分配，显著提升了LLMs的推理能力，并为后续强化学习提供了更强的基础。

Abstract: Supervised fine-tuning (SFT) on long chain-of-thought (CoT) trajectories has
emerged as a crucial technique for enhancing the reasoning abilities of large
language models (LLMs). However, the standard cross-entropy loss treats all
tokens equally, ignoring their heterogeneous contributions across a reasoning
trajectory. This uniform treatment leads to misallocated supervision and weak
generalization, especially in complex, long-form reasoning tasks. To address
this, we introduce \textbf{V}ariance-\textbf{C}ontrolled
\textbf{O}ptimization-based \textbf{RE}weighting (VCORE), a principled
framework that reformulates CoT supervision as a constrained optimization
problem. By adopting an optimization-theoretic perspective, VCORE enables a
principled and adaptive allocation of supervision across tokens, thereby
aligning the training objective more closely with the goal of robust reasoning
generalization. Empirical evaluations demonstrate that VCORE consistently
outperforms existing token reweighting methods. Across both in-domain and
out-of-domain settings, VCORE achieves substantial performance gains on
mathematical and coding benchmarks, using models from the Qwen3 series (4B, 8B,
32B) and LLaMA-3.1-8B-Instruct. Moreover, we show that VCORE serves as a more
effective initialization for subsequent reinforcement learning, establishing a
stronger foundation for advancing the reasoning capabilities of LLMs. The Code
will be released at https://github.com/coder-gx/VCORE.

</details>


### [32] [Diffuse Thinking: Exploring Diffusion Language Models as Efficient Thought Proposers for Reasoning](https://arxiv.org/abs/2510.27469)
*Chenyang Shao,Sijian Ren,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 提出了一种高效的协作推理框架，利用扩散语言模型生成候选思路，大语言模型评估质量，在保持推理质量的同时显著降低计算负担。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的自回归生成范式导致推理性能随测试时间计算量增长不理想，需要过多计算开销来生成思路，而性能提升有限。扩散语言模型能够通过单次前向传播并行去噪高效生成多样样本。

Method: 提出协作推理框架：使用扩散语言模型生成候选中间思路，然后使用大语言模型评估这些思路的质量。

Result: 在多样化基准测试中，该框架在复杂推理任务上实现了强劲性能。

Conclusion: 该框架为未来研究提供了有前景的方向，通过结合扩散语言模型和大语言模型的优势，在保持推理质量的同时显著降低了计算负担。

Abstract: In recent years, large language models (LLMs) have witnessed remarkable
advancements, with the test-time scaling law consistently enhancing the
reasoning capabilities. Through systematic evaluation and exploration of a
diverse spectrum of intermediate thoughts, LLMs demonstrate the potential to
generate deliberate reasoning steps, thereby substantially enhancing reasoning
accuracy. However, LLMs' autoregressive generation paradigm results in
reasoning performance scaling sub-optimally with test-time computation, often
requiring excessive computational overhead to propose thoughts while yielding
only marginal performance gains. In contrast, diffusion language models (DLMs)
can efficiently produce diverse samples through parallel denoising in a single
forward pass, inspiring us to leverage them for proposing intermediate
thoughts, thereby alleviating the computational burden associated with
autoregressive generation while maintaining quality. In this work, we propose
an efficient collaborative reasoning framework, leveraging DLMs to generate
candidate thoughts and LLMs to evaluate their quality. Experiments across
diverse benchmarks demonstrate that our framework achieves strong performance
in complex reasoning tasks, offering a promising direction for future research.
Our code is open-source at
https://anonymous.4open.science/r/Diffuse-Thinking-EC60.

</details>


### [33] [The aftermath of compounds: Investigating Compounds and their Semantic Representations](https://arxiv.org/abs/2510.27477)
*Swarang Joshi*

Main category: cs.CL

TL;DR: 本研究比较了静态词向量(GloVe)和上下文嵌入(BERT)在英语复合词处理中与人类语义判断的一致性，发现BERT能更好地捕捉组合语义，可预测性评分是语义透明度的强预测因子。


<details>
  <summary>Details</summary>
Motivation: 研究计算嵌入与人类语义判断在英语复合词处理中的对齐程度，旨在推进计算心理语言学发展，阐明驱动复合词处理的因素。

Method: 使用静态词向量(GloVe)和上下文嵌入(BERT)，基于关联强度、频率和可预测性指标计算嵌入衍生的LMD和ST指标，通过Spearman相关和回归分析评估与人类判断的关系。

Result: BERT嵌入比GloVe更好地捕捉组合语义，可预测性评分在人类和模型数据中都是语义透明度的强预测因子。

Conclusion: 研究结果推进了计算心理语言学，阐明了驱动复合词处理的因素，并为基于嵌入的语义建模提供了见解。

Abstract: This study investigates how well computational embeddings align with human
semantic judgments in the processing of English compound words. We compare
static word vectors (GloVe) and contextualized embeddings (BERT) against human
ratings of lexeme meaning dominance (LMD) and semantic transparency (ST) drawn
from a psycholinguistic dataset. Using measures of association strength
(Edinburgh Associative Thesaurus), frequency (BNC), and predictability (LaDEC),
we compute embedding-derived LMD and ST metrics and assess their relationships
with human judgments via Spearmans correlation and regression analyses. Our
results show that BERT embeddings better capture compositional semantics than
GloVe, and that predictability ratings are strong predictors of semantic
transparency in both human and model data. These findings advance computational
psycholinguistics by clarifying the factors that drive compound word processing
and offering insights into embedding-based semantic modeling.

</details>


### [34] [Effect of Domain Generalization Techniques in Low Resource Systems](https://arxiv.org/abs/2510.27512)
*Mahi Aminu,Chisom Chibuike,Fatimo Adebanjo,Omokolade Awosanya,Samuel Oyeneye*

Main category: cs.CL

TL;DR: 本研究在低资源自然语言任务中比较了两种因果域泛化方法：因果数据增强和不变因果表示学习，发现它们都能提升对未见领域的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中训练和测试数据分布往往不同，这种分布偏移问题在低资源设置中尤为突出，因为数据稀缺和领域多样性有限会阻碍模型的稳健泛化。

Method: 1) 因果数据增强方法：自动生成反事实样本来提升对伪相关性的鲁棒性，应用于NaijaSenti Twitter语料库的情感分类；2) 不变因果表示学习方法：使用DINER框架，将其适配到多语言设置中。

Result: 两种方法都增强了对未见领域的鲁棒性：反事实数据增强在情感分类中带来一致的跨领域准确率提升；基于DINER的因果表示学习在多语言情感分析中改善了分布外性能，尽管不同语言的增益程度不同。

Conclusion: 因果域泛化方法在低资源自然语言处理任务中能有效提升模型对分布偏移的鲁棒性，两种因果方法都显示出良好的泛化能力。

Abstract: Machine learning models typically assume that training and test data follow
the same distribution, an assumption that often fails in real-world scenarios
due to distribution shifts. This issue is especially pronounced in low-resource
settings, where data scarcity and limited domain diversity hinder robust
generalization. Domain generalization (DG) approaches address this challenge by
learning features that remain invariant across domains, often using causal
mechanisms to improve model robustness. In this study, we examine two distinct
causal DG techniques in low-resource natural language tasks. First, we
investigate a causal data augmentation (CDA) approach that automatically
generates counterfactual examples to improve robustness to spurious
correlations. We apply this method to sentiment classification on the
NaijaSenti Twitter corpus, expanding the training data with semantically
equivalent paraphrases to simulate controlled distribution shifts. Second, we
explore an invariant causal representation learning (ICRL) approach using the
DINER framework, originally proposed for debiasing aspect-based sentiment
analysis. We adapt DINER to a multilingual setting. Our findings demonstrate
that both approaches enhance robustness to unseen domains: counterfactual data
augmentation yields consistent cross-domain accuracy gains in sentiment
classification, while causal representation learning with DINER improves
out-of-distribution performance in multilingual sentiment analysis, albeit with
varying gains across languages.

</details>


### [35] [BiSparse-AAS: Bilinear Sparse Attention and Adaptive Spans Framework for Scalable and Efficient Text Summarization](https://arxiv.org/abs/2510.27516)
*Desta Haileselassie Hagos,Legand L. Burge,Anietie Andy,Anis Yazidi,Vladimir Vlassov*

Main category: cs.CL

TL;DR: BiSparse-AAS是一种结合稀疏注意力、自适应跨度和双线性注意力的新型Transformer框架，显著提升了长文档文本摘要的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer架构在文本摘要中存在二次复杂度问题，限制了在长文档上的可扩展性。

Method: 结合稀疏注意力（降低计算成本）、自适应跨度（动态调整注意力范围）和双线性注意力（建模复杂token交互）的BiSparse-AAS框架。

Result: 在CNN/DailyMail和XSum数据集上分别实现了约68.1%和52.6%的平均ROUGE提升，在OpenWebText和Gigaword数据集上保持强劲性能。

Conclusion: BiSparse-AAS通过解决效率、可扩展性和长序列建模问题，为实际文本摘要应用提供了统一的实用解决方案。

Abstract: Transformer-based architectures have advanced text summarization, yet their
quadratic complexity limits scalability on long documents. This paper
introduces BiSparse-AAS (Bilinear Sparse Attention with Adaptive Spans), a
novel framework that combines sparse attention, adaptive spans, and bilinear
attention to address these limitations. Sparse attention reduces computational
costs by focusing on the most relevant parts of the input, while adaptive spans
dynamically adjust the attention ranges. Bilinear attention complements both by
modeling complex token interactions within this refined context. BiSparse-AAS
consistently outperforms state-of-the-art baselines in both extractive and
abstractive summarization tasks, achieving average ROUGE improvements of about
68.1% on CNN/DailyMail and 52.6% on XSum, while maintaining strong performance
on OpenWebText and Gigaword datasets. By addressing efficiency, scalability,
and long-sequence modeling, BiSparse-AAS provides a unified, practical solution
for real-world text summarization applications.

</details>


### [36] [SQLSpace: A Representation Space for Text-to-SQL to Discover and Mitigate Robustness Gaps](https://arxiv.org/abs/2510.27532)
*Neha Srikanth,Victor Bursztyn,Puneet Mathur,Ani Nenkova*

Main category: cs.CL

TL;DR: SQLSpace是一种从文本到SQL示例中提取的可解释、通用且紧凑的表示方法，可用于评估文本到SQL模型的性能，揭示基准测试的组成差异，并通过查询重写提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到SQL评估方法主要依赖整体准确率，难以深入理解模型在具体维度上的表现差异，也无法有效识别基准测试的独特特征。

Method: 开发SQLSpace表示方法，通过最小化人工干预从文本到SQL示例中提取可解释的特征表示，支持三种应用场景：基准测试对比分析、细粒度性能评估和基于正确性估计的查询重写。

Result: SQLSpace能够揭示不同基准测试在组成上的差异，暴露仅凭准确率难以发现的性能模式，并支持对查询成功率的建模，从而提升模型性能。

Conclusion: SQLSpace为文本到SQL任务的评估提供了更深入的分析工具，能够超越传统的准确率指标，实现更细粒度的性能理解和模型改进。

Abstract: We introduce SQLSpace, a human-interpretable, generalizable, compact
representation for text-to-SQL examples derived with minimal human
intervention. We demonstrate the utility of these representations in evaluation
with three use cases: (i) closely comparing and contrasting the composition of
popular text-to-SQL benchmarks to identify unique dimensions of examples they
evaluate, (ii) understanding model performance at a granular level beyond
overall accuracy scores, and (iii) improving model performance through targeted
query rewriting based on learned correctness estimation. We show that SQLSpace
enables analysis that would be difficult with raw examples alone: it reveals
compositional differences between benchmarks, exposes performance patterns
obscured by accuracy alone, and supports modeling of query success.

</details>


### [37] [Patient-Centered Summarization Framework for AI Clinical Summarization: A Mixed-Methods Design](https://arxiv.org/abs/2510.27535)
*Maria Lizarazo Jimenez,Ana Gabriela Claros,Kieran Green,David Toro-Tobon,Felipe Larios,Sheena Asthana,Camila Wenczenovicz,Kerly Guevara Maldonado,Luis Vilatuna-Andrango,Cristina Proano-Velez,Satya Sai Sri Bandi,Shubhangi Bagewadi,Megan E. Branda,Misk Al Zahidy,Saturnino Luz,Mirella Lapata,Juan P. Brito,Oscar J. Ponce-Ponte*

Main category: cs.CL

TL;DR: 该研究提出了以患者为中心的临床摘要(PCS)新标准，通过混合方法开发框架，评估开源大语言模型在生成患者价值观摘要方面的表现，发现模型在完整性和流畅性上与人类相当，但在准确性和患者中心性方面仍不及人类专家。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型生成的临床摘要过于关注患者生物学特征，而忽视了患者的偏好、价值观、愿望和关切，无法实现真正的以患者为中心的护理。

Method: 采用混合方法：通过英国两个患者和公众参与小组(10名患者和8名临床医生)的半结构化访谈确定摘要内容标准；8名临床医生基于指南为88个房颤咨询创建黄金标准PCS；使用16个咨询优化提示模板；评估5个开源LLM在72个咨询上的零样本和少样本表现，使用ROUGE-L、BERTScore和定性指标。

Result: 患者强调生活方式、社会支持、近期压力源和护理价值观；临床医生需要简洁的功能、心理社会和情感背景信息。最佳零样本表现：Mistral-8B(ROUGE-L 0.189)和Llama-3.1-8B(BERTScore 0.673)；最佳少样本表现：Llama-3.1-8B(ROUGE-L 0.206, BERTScore 0.683)。模型与专家在完整性和流畅性上相似，但在正确性和患者中心性方面人类PCS更优。

Conclusion: 虽然开源大语言模型在生成以患者为中心的临床摘要方面显示出潜力，但在准确捕捉患者价值观和确保临床实用性方面仍需改进，尚未达到人类专家水平。

Abstract: Large Language Models (LLMs) are increasingly demonstrating the potential to
reach human-level performance in generating clinical summaries from
patient-clinician conversations. However, these summaries often focus on
patients' biology rather than their preferences, values, wishes, and concerns.
To achieve patient-centered care, we propose a new standard for Artificial
Intelligence (AI) clinical summarization tasks: Patient-Centered Summaries
(PCS). Our objective was to develop a framework to generate PCS that capture
patient values and ensure clinical utility and to assess whether current
open-source LLMs can achieve human-level performance in this task. We used a
mixed-methods process. Two Patient and Public Involvement groups (10 patients
and 8 clinicians) in the United Kingdom participated in semi-structured
interviews exploring what personal and contextual information should be
included in clinical summaries and how it should be structured for clinical
use. Findings informed annotation guidelines used by eight clinicians to create
gold-standard PCS from 88 atrial fibrillation consultations. Sixteen
consultations were used to refine a prompt aligned with the guidelines. Five
open-source LLMs (Llama-3.2-3B, Llama-3.1-8B, Mistral-8B, Gemma-3-4B, and
Qwen3-8B) generated summaries for 72 consultations using zero-shot and few-shot
prompting, evaluated with ROUGE-L, BERTScore, and qualitative metrics. Patients
emphasized lifestyle routines, social support, recent stressors, and care
values. Clinicians sought concise functional, psychosocial, and emotional
context. The best zero-shot performance was achieved by Mistral-8B (ROUGE-L
0.189) and Llama-3.1-8B (BERTScore 0.673); the best few-shot by Llama-3.1-8B
(ROUGE-L 0.206, BERTScore 0.683). Completeness and fluency were similar between
experts and models, while correctness and patient-centeredness favored human
PCS.

</details>


### [38] [DialectalArabicMMLU: Benchmarking Dialectal Capabilities in Arabic and Multilingual Language Models](https://arxiv.org/abs/2510.27543)
*Malik H. Altakrori,Nizar Habash,Abdelhakim Freihat,Younes Samih,Kirill Chirkunov,Muhammed AbuOdeh,Radu Florian,Teresa Lynn,Preslav Nakov,Alham Fikri Aji*

Main category: cs.CL

TL;DR: DialectalArabicMMLU是一个新的阿拉伯语方言基准测试，通过手动翻译和改编3K多选题为五种主要方言，用于评估大语言模型在阿拉伯方言上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的阿拉伯语和多语言基准主要关注现代标准阿拉伯语(MSA)，而方言变体在日常交流中普遍存在但代表性不足。

Method: 基于MMLU-Redux框架，手动翻译和改编3K多选题为叙利亚、埃及、阿联酋、沙特和摩洛哥五种方言，共产生15K问答对，涵盖32个学术和专业领域。

Result: 评估了19个开放权重的阿拉伯语和多语言LLMs，发现不同方言间存在显著的性能差异，揭示了方言泛化方面的持续差距。

Conclusion: DialectalArabicMMLU提供了首个统一的人工策划资源，用于衡量阿拉伯语方言理解，从而促进更包容的评估和未来模型发展。

Abstract: We present DialectalArabicMMLU, a new benchmark for evaluating the
performance of large language models (LLMs) across Arabic dialects. While
recently developed Arabic and multilingual benchmarks have advanced LLM
evaluation for Modern Standard Arabic (MSA), dialectal varieties remain
underrepresented despite their prevalence in everyday communication.
DialectalArabicMMLU extends the MMLU-Redux framework through manual translation
and adaptation of 3K multiple-choice question-answer pairs into five major
dialects (Syrian, Egyptian, Emirati, Saudi, and Moroccan), yielding a total of
15K QA pairs across 32 academic and professional domains (22K QA pairs when
also including English and MSA). The benchmark enables systematic assessment of
LLM reasoning and comprehension beyond MSA, supporting both task-based and
linguistic analysis. We evaluate 19 open-weight Arabic and multilingual LLMs
(1B-13B parameters) and report substantial performance variation across
dialects, revealing persistent gaps in dialectal generalization.
DialectalArabicMMLU provides the first unified, human-curated resource for
measuring dialectal understanding in Arabic, thus promoting more inclusive
evaluation and future model development.

</details>


### [39] [Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality](https://arxiv.org/abs/2510.27552)
*Yinghao Luo,Lang Zhou,Amrish Jhingoer,Klaske Vliegenthart Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li*

Main category: cs.CL

TL;DR: 该研究探讨了在医疗领域对多语言BERT模型进行领域特定预训练的效果，发现领域适应能显著提升模型在荷兰语、罗马尼亚语和西班牙语医疗NLP任务中的性能，且临床领域适应优于一般生物医学领域适应，同时观察到跨语言迁移能力。


<details>
  <summary>Details</summary>
Motivation: 在多语言医疗应用中，领域特定NLP工具稀缺，尤其是低资源语言。虽然多语言BERT提供了缩小语言差距的潜力，但低资源语言的医疗NLP任务仍未被充分探索。

Method: 对多语言BERT模型进行四种不同的领域特定预训练实验，创建医疗领域模型，然后在三个下游任务上微调：荷兰语临床笔记的自动患者筛查、罗马尼亚语和西班牙语临床笔记的命名实体识别。

Result: 领域适应显著提升了任务性能，临床领域适应模型优于一般生物医学领域适应模型，并观察到跨语言迁移能力的证据。

Conclusion: 研究结果强调了领域适应和跨语言能力在医疗NLP中的可行性，为开发多语言医疗NLP系统以缓解训练数据不足提供了有意义的指导。

Abstract: In multilingual healthcare applications, the availability of domain-specific
natural language processing(NLP) tools is limited, especially for low-resource
languages. Although multilingual bidirectional encoder representations from
transformers (BERT) offers a promising motivation to mitigate the language gap,
the medical NLP tasks in low-resource languages are still underexplored.
Therefore, this study investigates how further pre-training on domain-specific
corpora affects model performance on medical tasks, focusing on three
languages: Dutch, Romanian and Spanish. In terms of further pre-training, we
conducted four experiments to create medical domain models. Then, these models
were fine-tuned on three downstream tasks: Automated patient screening in Dutch
clinical notes, named entity recognition in Romanian and Spanish clinical
notes. Results show that domain adaptation significantly enhanced task
performance. Furthermore, further differentiation of domains, e.g. clinical and
general biomedical domains, resulted in diverse performances. The clinical
domain-adapted model outperformed the more general biomedical domain-adapted
model. Moreover, we observed evidence of cross-lingual transferability.
Moreover, we also conducted further investigations to explore potential reasons
contributing to these performance differences. These findings highlight the
feasibility of domain adaptation and cross-lingual ability in medical NLP.
Within the low-resource language settings, these findings can provide
meaningful guidance for developing multilingual medical NLP systems to mitigate
the lack of training data and thereby improve the model performance.

</details>


### [40] [Data-Efficient Domain Adaptation for LLM-based MT using Contrastive Preference Optimization](https://arxiv.org/abs/2510.27556)
*Inacio Vieira,Antonio Castaldo,James O'Doherty,Sheila Castilho*

Main category: cs.CL

TL;DR: 使用CPO进行数据高效的领域适应，通过将基础模型的原始输出作为'拒绝'翻译，人工批准的TM条目作为'选择'翻译来合成偏好对，仅用14.7k偏好对就能达到与160k+ SFT样本相近的性能。


<details>
  <summary>Details</summary>
Motivation: LLMs需要适应领域特定要求，但仅依赖SFT可能成本高昂，因此探索更数据高效的领域适应方法。

Method: 应用CPO模拟后编辑工作流，通过将基础模型的原始输出作为'拒绝'翻译，人工批准的翻译记忆条目作为'选择'翻译来合成偏好对，为模型提供对其当前知识的直接反馈。

Result: 在英语-巴西葡萄牙语和英语-韩语实验中，仅使用14.7k偏好对，模型性能就接近使用160k+样本进行SFT训练的模型，显示出显著的数据效率。

Conclusion: CPO在机器翻译中有效，且这种方法自然可推广到其他生成任务，其中模型的初始草稿可以作为与黄金参考对比的信号。

Abstract: LLMs often require adaptation to domain-specific requirements, a process that
can be expensive when relying solely on SFT. We present an empirical study on
applying CPO to simulate a post-editing workflow for data-efficient domain
adaptation. Our approach synthesizes preference pairs by treating the base
model's own raw output as the 'rejected' translation and the human-approved TM
entry as the 'chosen' one. This method provides direct feedback on the model's
current knowledge, guiding it to align with domain-specific standards.
Experiments in English-Brazilian Portuguese and English-Korean show that, by
using just 14.7k preference pairs, the model achieves performance close to that
of a model trained on 160k+ samples with SFT, demonstrating significant data
efficiency. Although we showcase its effectiveness in MT, this application of
CPO naturally generalizes to other generative tasks where a model's initial
drafts can serve as a contrastive signal against a golden reference.

</details>


### [41] [MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval](https://arxiv.org/abs/2510.27569)
*Qi Luo,Xiaonan Li,Yuxin Wang,Tingshuo Fan,Yuan Li,Xinchi Chen,Xipeng Qiu*

Main category: cs.CL

TL;DR: MARAG-R1是一个基于强化学习的多工具RAG框架，通过动态协调多种检索机制来解决传统单一检索器在信息获取上的局限性，在语料级推理任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统依赖单一检索器和固定的top-k选择，限制了对外部知识的全面访问，特别是在需要语料级推理的任务中成为主要瓶颈。

Method: 提出MARAG-R1框架，配备四种检索工具（语义搜索、关键词搜索、过滤和聚合），通过两阶段训练过程（监督微调+强化学习）学习如何和何时使用这些工具，实现推理与检索的交错进行。

Result: 在GlobalQA、HotpotQA和2WikiMultiHopQA上的实验表明，MARAG-R1显著优于强基线方法，在语料级推理任务中取得了新的最先进结果。

Conclusion: MARAG-R1通过强化学习的多工具协调机制，有效解决了传统RAG系统的信息访问限制问题，为LLMs提供了更全面和精确的外部知识获取能力。

Abstract: Large Language Models (LLMs) excel at reasoning and generation but are
inherently limited by static pretraining data, resulting in factual
inaccuracies and weak adaptability to new information. Retrieval-Augmented
Generation (RAG) addresses this issue by grounding LLMs in external knowledge;
However, the effectiveness of RAG critically depends on whether the model can
adequately access relevant information. Existing RAG systems rely on a single
retriever with fixed top-k selection, restricting access to a narrow and static
subset of the corpus. As a result, this single-retriever paradigm has become
the primary bottleneck for comprehensive external information acquisition,
especially in tasks requiring corpus-level reasoning. To overcome this
limitation, we propose MARAG-R1, a reinforcement-learned multi-tool RAG
framework that enables LLMs to dynamically coordinate multiple retrieval
mechanisms for broader and more precise information access. MARAG-R1 equips the
model with four retrieval tools -- semantic search, keyword search, filtering,
and aggregation -- and learns both how and when to use them through a two-stage
training process: supervised fine-tuning followed by reinforcement learning.
This design allows the model to interleave reasoning and retrieval,
progressively gathering sufficient evidence for corpus-level synthesis.
Experiments on GlobalQA, HotpotQA, and 2WikiMultiHopQA demonstrate that
MARAG-R1 substantially outperforms strong baselines and achieves new
state-of-the-art results in corpus-level reasoning tasks.

</details>


### [42] [SpecAttn: Speculating Sparse Attention](https://arxiv.org/abs/2510.27641)
*Harsh Shah*

Main category: cs.CL

TL;DR: SpecAttn是一种无需训练的稀疏注意力方法，通过利用推测解码中草稿模型的注意力权重来识别重要token，减少KV缓存访问75%以上，同时仅增加15.29%的困惑度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理时面临计算瓶颈，特别是自注意力机制的二次复杂度随着上下文长度增加而显著影响效率。

Method: 结合推测解码技术，利用草稿模型已计算的注意力权重识别重要token，采用KL散度层对齐、GPU优化的排序无关top-p token选择算法，以及基于预测的动态KV缓存剪枝。

Result: 在PG-19数据集上实现超过75%的KV缓存访问减少，仅增加15.29%的困惑度，显著优于现有稀疏注意力方法。

Conclusion: 推测执行可以通过近似验证得到增强，而不会导致显著的性能下降，为预训练变压器的高效稀疏注意力提供了有效解决方案。

Abstract: Large Language Models (LLMs) face significant computational bottlenecks
during inference due to the quadratic complexity of self-attention mechanisms,
particularly as context lengths increase. We introduce SpecAttn, a novel
training-free approach that seamlessly integrates with existing speculative
decoding techniques to enable efficient sparse attention in pre-trained
transformers. Our key insight is to exploit the attention weights already
computed by the draft model during speculative decoding to identify important
tokens for the target model, eliminating redundant computation while
maintaining output quality. SpecAttn employs three core techniques: KL
divergence-based layer alignment between draft and target models, a
GPU-optimized sorting-free algorithm for top-p token selection from draft
attention patterns, and dynamic key-value cache pruning guided by these
predictions. By leveraging the computational work already performed in standard
speculative decoding pipelines, SpecAttn achieves over 75% reduction in
key-value cache accesses with a mere 15.29% increase in perplexity on the PG-19
dataset, significantly outperforming existing sparse attention methods. Our
approach demonstrates that speculative execution can be enhanced to provide
approximate verification without significant performance degradation.

</details>


### [43] [Culture Cartography: Mapping the Landscape of Cultural Knowledge](https://arxiv.org/abs/2510.27672)
*Caleb Ziems,William Held,Jane Yu,Amir Goldberg,David Grusky,Diyi Yang*

Main category: cs.CL

TL;DR: 提出了一种名为CultureCartography的混合主动方法，通过LLM初始化低置信度问题标注，让人类参与者填补知识空白并引导模型关注重要文化主题，从而更有效地发现LLM缺失的文化特定知识。


<details>
  <summary>Details</summary>
Motivation: LLM需要文化特定知识来安全有效地服务全球用户，但这些知识可能在预训练期间未被学习。需要找到既对内部用户重要又对LLM未知的知识。

Method: 使用CultureCartography方法，让LLM提出低置信度答案的问题，人类参与者填补知识空白并通过直接编辑引导模型关注重要主题。实现为CultureExplorer工具。

Result: 相比人类回答LLM提出问题的基线，CultureExplorer更有效地产生了DeepSeek R1和GPT-4o等领先模型缺失的知识，即使使用网络搜索也无法获得。在这些数据上微调使Llama-3.1-8B在相关文化基准上的准确率提高了19.2%。

Conclusion: 混合主动方法CultureCartography能有效识别和填补LLM的文化知识空白，通过人类与LLM的协作产生对内部用户重要且模型缺失的知识，显著提升模型在文化相关任务上的表现。

Abstract: To serve global users safely and productively, LLMs need culture-specific
knowledge that might not be learned during pre-training. How do we find such
knowledge that is (1) salient to in-group users, but (2) unknown to LLMs? The
most common solutions are single-initiative: either researchers define
challenging questions that users passively answer (traditional annotation), or
users actively produce data that researchers structure as benchmarks (knowledge
extraction). The process would benefit from mixed-initiative collaboration,
where users guide the process to meaningfully reflect their cultures, and LLMs
steer the process towards more challenging questions that meet the researcher's
goals. We propose a mixed-initiative methodology called CultureCartography.
Here, an LLM initializes annotation with questions for which it has
low-confidence answers, making explicit both its prior knowledge and the gaps
therein. This allows a human respondent to fill these gaps and steer the model
towards salient topics through direct edits. We implement this methodology as a
tool called CultureExplorer. Compared to a baseline where humans answer
LLM-proposed questions, we find that CultureExplorer more effectively produces
knowledge that leading models like DeepSeek R1 and GPT-4o are missing, even
with web search. Fine-tuning on this data boosts the accuracy of Llama-3.1-8B
by up to 19.2% on related culture benchmarks.

</details>


### [44] [Continuous Autoregressive Language Models](https://arxiv.org/abs/2510.27688)
*Chenze Shao,Darren Li,Fandong Meng,Jie Zhou*

Main category: cs.CL

TL;DR: CALM模型通过将离散的逐词预测转变为连续的向量预测，使用自编码器将K个词压缩为单个连续向量，显著减少生成步骤，在保持性能的同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的效率受到逐词生成过程的限制，需要新的扩展设计轴来提高每个生成步骤的语义带宽。

Method: 引入连续自回归语言模型（CALM），使用高保真自编码器将K个词块压缩为单个连续向量，从该向量可以以超过99.9%的准确率重建原始词。开发了无似然框架来支持连续域中的训练、评估和可控采样。

Result: CALM显著改善了性能-计算权衡，在显著降低计算成本的情况下实现了强离散基线的性能。

Conclusion: 这些发现确立了向量预测作为实现超高效语言模型的有力且可扩展的途径。

Abstract: The efficiency of large language models (LLMs) is fundamentally limited by
their sequential, token-by-token generation process. We argue that overcoming
this bottleneck requires a new design axis for LLM scaling: increasing the
semantic bandwidth of each generative step. To this end, we introduce
Continuous Autoregressive Language Models (CALM), a paradigm shift from
discrete next-token prediction to continuous next-vector prediction. CALM uses
a high-fidelity autoencoder to compress a chunk of K tokens into a single
continuous vector, from which the original tokens can be reconstructed with
over 99.9\% accuracy. This allows us to model language as a sequence of
continuous vectors instead of discrete tokens, which reduces the number of
generative steps by a factor of K. The paradigm shift necessitates a new
modeling toolkit; therefore, we develop a comprehensive likelihood-free
framework that enables robust training, evaluation, and controllable sampling
in the continuous domain. Experiments show that CALM significantly improves the
performance-compute trade-off, achieving the performance of strong discrete
baselines at a significantly lower computational cost. More importantly, these
findings establish next-vector prediction as a powerful and scalable pathway
towards ultra-efficient language models. Code:
https://github.com/shaochenze/calm. Project:
https://shaochenze.github.io/blog/2025/CALM.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [45] [Evaluating Perspectival Biases in Cross-Modal Retrieval](https://arxiv.org/abs/2510.26861)
*Teerapol Saengsukhiran,Peerawat Chomphooyod,Narabodee Rodjananant,Chompakorn Chaksangchaichot,Patawee Prakrankamanant,Witthawin Sripheanpol,Pak Lovichit,SarChaksaana Nutanong,Ekapol Chuangsuwanich*

Main category: cs.IR

TL;DR: 该论文研究了多模态检索系统中的两种偏见：流行度偏见（图像到文本检索中偏向流行语言）和关联偏见（文本到图像检索中偏向文化关联图像），发现显式对齐能有效缓解流行度偏见，但关联偏见是更复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 多模态检索系统理论上应在语义空间中运行，不受查询语言或文化背景影响，但实际上存在系统性偏见，这些偏见由语言流行度和文化关联塑造。

Method: 研究两种偏见：流行度偏见（图像到文本检索中偏向流行语言）和关联偏见（文本到图像检索中偏向文化关联图像），并比较不同缓解策略的效果。

Result: 显式对齐是缓解流行度偏见的有效策略，但关联偏见仍然是一个更复杂和具有挑战性的问题。

Conclusion: 实现真正公平的多模态系统需要超越简单数据扩展的针对性策略，由文化关联产生的偏见比由语言流行度产生的偏见更具挑战性。

Abstract: Multimodal retrieval systems are expected to operate in a semantic space,
agnostic to the language or cultural origin of the query. In practice, however,
retrieval outcomes systematically reflect perspectival biases: deviations
shaped by linguistic prevalence and cultural associations. We study two such
biases. First, prevalence bias refers to the tendency to favor entries from
prevalent languages over semantically faithful entries in image-to-text
retrieval. Second, association bias refers to the tendency to favor images
culturally associated with the query over semantically correct ones in
text-to-image retrieval. Results show that explicit alignment is a more
effective strategy for mitigating prevalence bias. However, association bias
remains a distinct and more challenging problem. These findings suggest that
achieving truly equitable multimodal systems requires targeted strategies
beyond simple data scaling and that bias arising from cultural association may
be treated as a more challenging problem than one arising from linguistic
prevalence.

</details>


### [46] [A Survey on Generative Recommendation: Data, Model, and Tasks](https://arxiv.org/abs/2510.27157)
*Min Hou,Le Wu,Yuxin Liao,Yonghui Yang,Zhen Zhang,Changlong Zheng,Han Wu,Richang Hong*

Main category: cs.IR

TL;DR: 这篇综述论文系统分析了生成式推荐系统的新范式，将其统一分解为数据、模型和任务三个维度，探讨了生成模型在推荐领域的应用、优势和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型（尤其是大语言模型和扩散模型）的出现，推荐系统正在经历从判别式评分到生成式任务的范式转变，需要系统性地梳理这一新兴领域。

Method: 采用统一的三元框架：数据层面（知识增强和代理模拟）、模型层面（LLM方法、大型推荐模型、扩散方法）和任务层面（对话交互、可解释推理、个性化内容生成）。

Result: 识别了生成式推荐的五大优势：世界知识整合、自然语言理解、推理能力、缩放定律和创造性生成，同时指出了基准设计、模型鲁棒性和部署效率等挑战。

Conclusion: 生成式推荐系统有望发展成为智能推荐助手，从根本上重塑人与信息的交互方式，为推荐系统领域开辟了新的研究方向和发展路径。

Abstract: Recommender systems serve as foundational infrastructure in modern
information ecosystems, helping users navigate digital content and discover
items aligned with their preferences. At their core, recommender systems
address a fundamental problem: matching users with items. Over the past
decades, the field has experienced successive paradigm shifts, from
collaborative filtering and matrix factorization in the machine learning era to
neural architectures in the deep learning era. Recently, the emergence of
generative models, especially large language models (LLMs) and diffusion
models, have sparked a new paradigm: generative recommendation, which
reconceptualizes recommendation as a generation task rather than discriminative
scoring. This survey provides a comprehensive examination through a unified
tripartite framework spanning data, model, and task dimensions. Rather than
simply categorizing works, we systematically decompose approaches into
operational stages-data augmentation and unification, model alignment and
training, task formulation and execution. At the data level, generative models
enable knowledge-infused augmentation and agent-based simulation while unifying
heterogeneous signals. At the model level, we taxonomize LLM-based methods,
large recommendation models, and diffusion approaches, analyzing their
alignment mechanisms and innovations. At the task level, we illuminate new
capabilities including conversational interaction, explainable reasoning, and
personalized content generation. We identify five key advantages: world
knowledge integration, natural language understanding, reasoning capabilities,
scaling laws, and creative generation. We critically examine challenges in
benchmark design, model robustness, and deployment efficiency, while charting a
roadmap toward intelligent recommendation assistants that fundamentally reshape
human-information interaction.

</details>


### [47] [A Survey on Deep Text Hashing: Efficient Semantic Text Retrieval with Binary Representation](https://arxiv.org/abs/2510.27232)
*Liyang He,Zhenya Huang,Cheng Yang,Rui Li,Zheng Zhang,Kai Zhang,Zhi Li,Qi Liu,Enhong Chen*

Main category: cs.IR

TL;DR: 本综述系统回顾了深度文本哈希方法，将其按核心组件分类，评估了多种数据集上的性能，讨论了实际应用和开源工具，并指出了与大型语言模型结合等未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着互联网文本内容的快速增长，大规模语义文本检索需求日益增长。文本哈希通过将文本投影为紧凑的二进制哈希码，能显著加速语义相似度计算并降低存储成本。

Method: 将深度文本哈希方法按核心组件分类：语义提取、哈希码质量保持和其他关键技术。建立了详细的评估框架，在多个流行数据集上进行测试，并讨论了实际应用和开源实现工具。

Result: 深度文本哈希相比传统数据无关哈希方法展现出显著优势，能够直接从数据中学习紧凑且语义丰富的二进制表示，突破了早期方法的性能限制。

Conclusion: 深度文本哈希是高效大规模语义文本检索的关键技术，未来研究方向包括与大型语言模型的集成，以进一步推动该领域发展。

Abstract: With the rapid growth of textual content on the Internet, efficient
large-scale semantic text retrieval has garnered increasing attention from both
academia and industry. Text hashing, which projects original texts into compact
binary hash codes, is a crucial method for this task. By using binary codes,
the semantic similarity computation for text pairs is significantly accelerated
via fast Hamming distance calculations, and storage costs are greatly reduced.
With the advancement of deep learning, deep text hashing has demonstrated
significant advantages over traditional, data-independent hashing techniques.
By leveraging deep neural networks, these methods can learn compact and
semantically rich binary representations directly from data, overcoming the
performance limitations of earlier approaches. This survey investigates current
deep text hashing methods by categorizing them based on their core components:
semantic extraction, hash code quality preservation, and other key
technologies. We then present a detailed evaluation schema with results on
several popular datasets, followed by a discussion of practical applications
and open-source tools for implementation. Finally, we conclude by discussing
key challenges and future research directions, including the integration of
deep text hashing with large language models to further advance the field. The
project for this survey can be accessed at
https://github.com/hly1998/DeepTextHashing.

</details>


### [48] [Traceable Drug Recommendation over Medical Knowledge Graphs](https://arxiv.org/abs/2510.27274)
*Yu Lin,Zhen Jia,Philipp Christmann,Xu Zhang,Shengdong Du,Tianrui Li*

Main category: cs.IR

TL;DR: TraceDR是一个基于医学知识图谱的药物推荐系统，通过多任务学习框架同时预测药物推荐和相关证据，实现了推荐的可追溯性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在药物推荐中无法提供推荐推导过程的洞察，这在医疗等高风险应用中是一个关键限制。

Method: 在医学知识图谱上运行的多任务学习框架，自动构建患者健康记录，并创建了新的DrugRec大规模测试平台。

Result: 系统能够覆盖比现有工作更多样化的疾病和药物，确保访问大规模高质量信息。

Conclusion: TraceDR通过提供可追溯的药物推荐，解决了现有方法在解释性方面的不足，为医疗专业人员提供了更好的决策支持。

Abstract: Drug recommendation (DR) systems aim to support healthcare professionals in
selecting appropriate medications based on patients' medical conditions.
State-of-the-art approaches utilize deep learning techniques for improving DR,
but fall short in providing any insights on the derivation process of
recommendations -- a critical limitation in such high-stake applications. We
propose TraceDR, a novel DR system operating over a medical knowledge graph
(MKG), which ensures access to large-scale and high-quality information.
TraceDR simultaneously predicts drug recommendations and related evidence
within a multi-task learning framework, enabling traceability of medication
recommendations. For covering a more diverse set of diseases and drugs than
existing works, we devise a framework for automatically constructing patient
health records and release DrugRec, a new large-scale testbed for DR.

</details>


### [49] [Pairwise and Attribute-Aware Decision Tree-Based Preference Elicitation for Cold-Start Recommendation](https://arxiv.org/abs/2510.27342)
*Alireza Gharahighehi,Felipe Kenji Nakano,Xuehua Yang,Wenhan Cu,Celine Vens*

Main category: cs.IR

TL;DR: 本文提出了一种改进的决策树评分获取方法，用于解决音乐推荐系统中的冷启动问题，通过获取属性偏好和使用项目对来提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 解决推荐系统中冷启动用户缺乏历史交互数据的问题，传统决策树方法在音乐推荐中效果有限，需要更有效的评分获取策略。

Method: 扩展决策树评分获取方法：(i) 获取项目评分和属性偏好（如流派）以更好地聚类用户；(ii) 在每个节点使用项目对而非单个项目来更有效地学习用户偏好。

Result: 实验结果表明，两种改进都提升了性能，特别是在减少查询次数的情况下效果更明显。

Conclusion: 提出的扩展决策树方法在音乐推荐冷启动场景中有效，通过结合属性偏好和项目对查询策略，能够用更少的查询获得更好的推荐效果。

Abstract: Recommender systems (RSs) are intelligent filtering methods that suggest
items to users based on their inferred preferences, derived from their
interaction history on the platform. Collaborative filtering-based RSs rely on
users past interactions to generate recommendations. However, when a user is
new to the platform, referred to as a cold-start user, there is no historical
data available, making it difficult to provide personalized recommendations. To
address this, rating elicitation techniques can be used to gather initial
ratings or preferences on selected items, helping to build an early
understanding of the user's tastes. Rating elicitation approaches are generally
categorized into two types: non-personalized and personalized. Decision
tree-based rating elicitation is a personalized method that queries users about
their preferences at each node of the tree until sufficient information is
gathered. In this paper, we propose an extension to the decision tree approach
for rating elicitation in the context of music recommendation. Our method: (i)
elicits not only item ratings but also preferences on attributes such as genres
to better cluster users, and (ii) uses item pairs instead of single items at
each node to more effectively learn user preferences. Experimental results
demonstrate that both proposed enhancements lead to improved performance,
particularly with a reduced number of queries.

</details>


### [50] [Interact-RAG: Reason and Interact with the Corpus, Beyond Black-Box Retrieval](https://arxiv.org/abs/2510.27566)
*Yulong Hui,Chao Chen,Zhihang Fu,Yihao Liu,Jieping Ye,Huanchen Zhang*

Main category: cs.IR

TL;DR: Interact-RAG是一种新的检索增强生成范式，将LLM代理从被动的查询发出者提升为检索过程的主动操控者，通过语料交互引擎和推理增强工作流实现端到端自主代理训练。


<details>
  <summary>Details</summary>
Motivation: 现有代理式RAG方法将检索过程视为黑盒查询操作，限制了代理处理复杂信息搜索任务的能力，需要打破这种限制。

Method: 开发语料交互引擎提供细粒度检索控制原语，构建推理增强工作流支持零样本执行和交互轨迹合成，通过监督微调和强化学习训练端到端自主代理。

Result: 在六个基准测试上的广泛实验表明，Interact-RAG显著优于其他先进方法，验证了推理-交互策略的有效性。

Conclusion: Interact-RAG通过将LLM代理转变为检索过程的主动操控者，成功解决了现有代理式RAG方法的局限性，为复杂信息搜索任务提供了有效解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has significantly enhanced LLMs by
incorporating external information. However, prevailing agentic RAG approaches
are constrained by a critical limitation: they treat the retrieval process as a
black-box querying operation. This confines agents' actions to query issuing,
hindering its ability to tackle complex information-seeking tasks. To address
this, we introduce Interact-RAG, a new paradigm that elevates the LLM agent
from a passive query issuer into an active manipulator of the retrieval
process. We dismantle the black-box with a Corpus Interaction Engine, equipping
the agent with a set of action primitives for fine-grained control over
information retrieval. To further empower the agent on the entire RAG pipeline,
we first develop a reasoning-enhanced workflow, which enables both zero-shot
execution and the synthesis of interaction trajectories. We then leverage this
synthetic data to train a fully autonomous end-to-end agent via Supervised
Fine-Tuning (SFT), followed by refinement with Reinforcement Learning (RL).
Extensive experiments across six benchmarks demonstrate that Interact-RAG
significantly outperforms other advanced methods, validating the efficacy of
our reasoning-interaction strategy.

</details>
