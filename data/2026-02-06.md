<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 59]
- [cs.IR](#cs.IR) [Total: 15]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations](https://arxiv.org/abs/2602.04982)
*Deepak Gupta,Davis Bartels,Dina Demner-Fuhsman*

Main category: cs.CL

TL;DR: BioACE是一个自动化评估框架，用于评估生物医学问答和引文质量，涵盖完整性、正确性、精确度和召回率等多个维度，并提供与人工评估相关的评估方法。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在生物医学问答中的应用增加，需要自动化评估生成答案和引用证据的质量，因为人工专家评估成本高且复杂。

Method: 提出了BioACE框架，采用自动化方法评估答案的完整性、正确性、精确度和召回率，并比较了NLI、预训练语言模型和LLMs等多种方法评估引文质量。

Result: 通过大量实验分析了自动化评估与人工评估的相关性，确定了生物医学答案和引文评估的最佳方法，并提供了开源评估包。

Conclusion: BioACE为生物医学领域提供了一套有效的自动化评估框架，有助于提高LLMs生成答案和引用的质量评估效率。

Abstract: With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers. Evaluation of text generated by LLMs remains a challenge for question answering, retrieval-augmented generation (RAG), summarization, and many other natural language processing tasks in the biomedical domain, due to the requirements of expert assessment to verify consistency with the scientific literature and complex medical terminology. In this work, we propose BioACE, an automated framework for evaluating biomedical answers and citations against the facts stated in the answers. The proposed BioACE framework considers multiple aspects, including completeness, correctness, precision, and recall, in relation to the ground-truth nuggets for answer evaluation. We developed automated approaches to evaluate each of the aforementioned aspects and performed extensive experiments to assess and analyze their correlation with human evaluations. In addition, we considered multiple existing approaches, such as natural language inference (NLI) and pre-trained language models and LLMs, to evaluate the quality of evidence provided to support the generated answers in the form of citations into biomedical literature. With the detailed experiments and analysis, we provide the best approaches for biomedical answer and citation evaluation as a part of BioACE (https://github.com/deepaknlp/BioACE) evaluation package.

</details>


### [2] [CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System](https://arxiv.org/abs/2602.05004)
*Zexin Lin,Jiachen Yu,Haoyang Zhang,Yuzhao Li,Zhonghang Li,Yujiu Yang,Junjie Wang,Xiaoqiang Ji*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict online token budget. Existing approaches either rely on frequent in-episode reasoning that induces latency and timing jitter, or deliver post-episode improvements through unstructured text that is difficult to compile into reliable low-cost execution. We propose CoWork-X, an active co-evolution framework that casts peer collaboration as a closed-loop optimization problem across episodes, inspired by fast--slow memory separation. CoWork-X instantiates a Skill-Agent that executes via HTN (hierarchical task network)-based skill retrieval from a structured, interpretable, and compositional skill library, and a post-episode Co-Optimizer that performs patch-style skill consolidation with explicit budget constraints and drift regularization. Experiments in challenging Overcooked-AI-like realtime collaboration benchmarks demonstrate that CoWork-X achieves stable, cumulative performance gains while steadily reducing online latency and token usage.

</details>


### [3] [Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation](https://arxiv.org/abs/2602.05035)
*Sean Trott,Pamela D. Rivière*

Main category: cs.CL

TL;DR: 多语言语言模型在词汇消歧任务上表现不如单语模型，存在"多语言惩罚"现象，主要源于表征、注意力和词汇相关的三种能力限制。


<details>
  <summary>Details</summary>
Motivation: 多语言语言模型有时表现不如单语模型，可能是由于模型容量限制。研究旨在量化这种"多语言惩罚"现象，特别是在需要精确语义表征和上下文机制的词汇消歧任务上。

Method: 使用英语和西班牙语中歧义词的人类相关性判断数据集，比较同一模型家族的单语和多语言模型。探索三种潜在能力限制：表征限制（嵌入各向同性降低）、注意力限制（对消歧线索关注减少）和词汇相关限制（多标记分割增加）。

Result: 多语言模型在所有三种限制上都表现出证据，这些因素统计上解释了原本归因于模型多语言状态的性能差异。多语言模型确实存在多种能力限制，这些限制与消歧性能降低相关。

Conclusion: 多语言语言模型在词汇消歧任务上存在性能惩罚，这源于多种能力约束。理解这些限制有助于未来改进多语言模型设计。

Abstract: Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty'' for lexical disambiguation--a task requiring precise semantic representations and contextualization mechanisms--using controlled datasets of human relatedness judgments for ambiguous words in both English and Spanish. Comparing monolingual and multilingual LMs from the same families, we find consistently reduced performance in multilingual LMs. We then explore three potential capacity constraints: representational (reduced embedding isotropy), attentional (reduced attention to disambiguating cues), and vocabulary-related (increased multi-token segmentation). Multilingual LMs show some evidence of all three limitations; moreover, these factors statistically account for the variance formerly attributed to a model's multilingual status. These findings suggest both that multilingual LMs do suffer from multiple capacity constraints, and that these constraints correlate with reduced disambiguation performance.

</details>


### [4] [Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories](https://arxiv.org/abs/2602.05085)
*Sidi Lu,Zhenwen Liang,Dongyang Ma,Yan Wang,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: Locas是一种局部支持的参数化记忆模块，可灵活卸载或合并到模型参数中，用于高效的持续学习，在PG-19和LoCoMo任务上仅需0.02%额外参数即可存储过去上下文信息。


<details>
  <summary>Details</summary>
Motivation: 将测试时训练与新型参数化记忆相结合，这种记忆可以灵活地从模型参数中卸载或合并，以支持高效的持续学习并减少灾难性遗忘。

Method: 提出Locas（局部支持的参数化记忆），采用与Transformer中FFN块相同的设计，有两种变体：传统的两层MLP设计（理论保证更清晰）和与SOTA LLMs相同的GLU-FFN结构。通过重用模型参数、激活和/或梯度进行原则性初始化。

Result: 在PG-19整本书语言建模和LoCoMo长上下文对话问答任务上验证，Locas-GLU仅需0.02%额外参数即可存储过去上下文信息，同时保持较小的上下文窗口。MMLU评估显示模型在记忆整本书后通用能力损失最小。

Conclusion: Locas能够将过去上下文永久化为参数化知识，同时最小化模型现有内部知识的灾难性遗忘，展示了在持续学习中的潜力。

Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformers, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning. We discuss two major variants of Locas: one with a conventional two-layer MLP design that has a clearer theoretical guarantee; the other one shares the same GLU-FFN structure with SOTA LLMs, and can be easily attached to existing models for both parameter-efficient and computation-efficient continual learning. Crucially, we show that proper initialization of such low-rank sideway-FFN-style memories -- performed in a principled way by reusing model parameters, activations and/or gradients -- is essential for fast convergence, improved generalization, and catastrophic forgetting prevention. We validate the proposed memory mechanism on the PG-19 whole-book language modeling and LoCoMo long-context dialogue question answering tasks. With only 0.02\% additional parameters in the lowest case, Locas-GLU is capable of storing the information from past context while maintaining a much smaller context window. In addition, we also test the model's general capability loss after memorizing the whole book with Locas, through comparative MMLU evaluation. Results show the promising ability of Locas to permanentize past context into parametric knowledge with minimized catastrophic forgetting of the model's existing internal knowledge.

</details>


### [5] [Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models](https://arxiv.org/abs/2602.05106)
*Michael Browder,Kevin Duh,J. David Harris,Vince Lyzinski,Paul McNamee,Youngser Park,Carey E. Priebe,Peter Viechnicki*

Main category: cs.CL

TL;DR: 该论文提出Data Kernel Perspective Space (DKPS)框架，为Transformer模型输出质量提供数学分析和统计保证，解决合成数据生成中的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer/LLM的合成数据生成存在不确定性，工程师通常只能通过调整温度参数来"试错"，缺乏对输出质量的数学分析和统计保证。

Method: 提出Data Kernel Perspective Space (DKPS)框架，通过数学推导建立理论分析基础，为Transformer模型输出提供性能保证。

Result: DKPS框架能够提供具体的统计保证，并可应用于下游任务（如神经机器翻译模型、基于CPO训练的LLM）的性能分析。

Conclusion: DKPS为解决合成数据生成中的不确定性问题提供了数学基础，但当前工作存在局限性，需要未来进一步研究。

Abstract: Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via synthetic data generation. However, because the models are black boxes, the properties of the synthetic data are difficult to predict. In practice it is common for language technology engineers to 'fiddle' with the LLM temperature setting and hope that what comes out the other end improves the downstream model. Faced with this uncertainty, here we propose Data Kernel Perspective Space (DKPS) to provide the foundation for mathematical analysis yielding concrete statistical guarantees for the quality of the outputs of transformer models. We first show the mathematical derivation of DKPS and how it provides performance guarantees. Next we show how DKPS performance guarantees can elucidate performance of a downstream task, such as neural machine translation models or LLMs trained using Contrastive Preference Optimization (CPO). Limitations of the current work and future research are also discussed.

</details>


### [6] [Multilingual Extraction and Recognition of Implicit Discourse Relations in Speech and Text](https://arxiv.org/abs/2602.05107)
*Ahmed Ruby,Christian Hardmeier,Sara Stymne*

Main category: cs.CL

TL;DR: 提出多模态方法用于跨语言隐式篇章关系分类，结合文本和音频信息，在英语、法语和西班牙语上验证效果。


<details>
  <summary>Details</summary>
Motivation: 隐式篇章关系分类具有挑战性，需要从上下文中推断含义。语境线索可能分布在多模态中且因语言而异，仅靠文本无法完全捕捉。

Method: 1. 提出自动方法构建英语、法语和西班牙语的多语言多模态隐式篇章关系数据集；2. 提出多模态分类方法，通过Qwen2-Audio整合文本和声学信息，实现跨语言联合建模。

Result: 1. 基于文本的模型优于基于音频的模型；2. 整合两种模态可以提升性能；3. 跨语言迁移能为低资源语言带来显著改进。

Conclusion: 多模态方法能有效提升隐式篇章关系分类性能，跨语言迁移对低资源语言尤其有益，表明整合文本和音频信息具有价值。

Abstract: Implicit discourse relation classification is a challenging task, as it requires inferring meaning from context. While contextual cues can be distributed across modalities and vary across languages, they are not always captured by text alone. To address this, we introduce an automatic method for distantly related and unrelated language pairs to construct a multilingual and multimodal dataset for implicit discourse relations in English, French, and Spanish. For classification, we propose a multimodal approach that integrates textual and acoustic information through Qwen2-Audio, allowing joint modeling of text and audio for implicit discourse relation classification across languages. We find that while text-based models outperform audio-based models, integrating both modalities can enhance performance, and cross-lingual transfer can provide substantial improvements for low-resource languages.

</details>


### [7] [GreekMMLU: A Native-Sourced Multitask Benchmark for Evaluating Language Models in Greek](https://arxiv.org/abs/2602.05150)
*Yang Zhang,Mersin Konomi,Christos Xypolopoulos,Konstantinos Divriotis,Konstantinos Skianis,Giannis Nikolentzos,Giorgos Stamou,Guokan Shang,Michalis Vazirgiannis*

Main category: cs.CL

TL;DR: 希腊语原生评估基准GreekMMLU：包含21,805个多选问题，覆盖45个学科，用于评估LLM在希腊语上的多任务语言理解能力。


<details>
  <summary>Details</summary>
Motivation: 目前希腊语评估基准有限，现有数据集多为从英语机器翻译而来，无法捕捉希腊语言和文化特征，需要原生希腊语内容构建的可靠评估基准。

Method: 构建GreekMMLU基准，包含21,805个多选问题，来自学术、专业和政府考试的原生希腊语内容，涵盖45个学科，按新定义学科分类法组织，标注教育难度级别。

Result: 评估80多个开源和闭源LLM，发现前沿模型与开源模型、希腊语适应模型与通用多语言模型之间存在显著性能差距，并分析了模型规模、适应性和提示策略等因素对性能的影响。

Conclusion: GreekMMLU为希腊语LLM评估提供了可靠的原生基准，揭示了当前模型的局限性，并为提升LLM在希腊语上的能力提供了系统分析见解。

Abstract: Large Language Models (LLMs) are commonly trained on multilingual corpora that include Greek, yet reliable evaluation benchmarks for Greek-particularly those based on authentic, native-sourced content-remain limited. Existing datasets are often machine-translated from English, failing to capture Greek linguistic and cultural characteristics. We introduce GreekMMLU, a native-sourced benchmark for massive multitask language understanding in Greek, comprising 21,805 multiple-choice questions across 45 subject areas, organized under a newly defined subject taxonomy and annotated with educational difficulty levels spanning primary to professional examinations. All questions are sourced or authored in Greek from academic, professional, and governmental exams. We publicly release 16,857 samples and reserve 4,948 samples for a private leaderboard to enable robust and contamination-resistant evaluation. Evaluations of over 80 open- and closed-source LLMs reveal substantial performance gaps between frontier and open-weight models, as well as between Greek-adapted models and general multilingual ones. Finally, we provide a systematic analysis of factors influencing performance-including model scale, adaptation, and prompting-and derive insights for improving LLM capabilities in Greek.

</details>


### [8] [Among Us: Measuring and Mitigating Malicious Contributions in Model Collaboration Systems](https://arxiv.org/abs/2602.05176)
*Ziyuan Yang,Wenxuan Ding,Shangbin Feng,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: 恶意语言模型在多LLM协作系统中构成严重安全威胁，本文量化其影响并提出监督缓解策略


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在多模型协作系统中的广泛应用，当部分模型被攻击或恶意时存在严重安全风险，需要量化评估这种威胁

Method: 设计了四类恶意语言模型，将其植入四种流行的模型协作系统，在10个数据集上评估受损系统，并提出基于外部监督的缓解策略

Result: 恶意模型对多LLM系统影响严重，在推理和安全领域性能分别平均下降7.12%和7.94%；提出的缓解策略平均能恢复95.31%的初始性能

Conclusion: 恶意模型在多模型协作系统中构成实际威胁，提出的监督策略能有效缓解但无法完全抵抗，实现完全抗恶意攻击的模型协作系统仍是开放研究问题

Abstract: Language models (LMs) are increasingly used in collaboration: multiple LMs trained by different parties collaborate through routing systems, multi-agent debate, model merging, and more. Critical safety risks remain in this decentralized paradigm: what if some of the models in multi-LLM systems are compromised or malicious? We first quantify the impact of malicious models by engineering four categories of malicious LMs, plug them into four types of popular model collaboration systems, and evaluate the compromised system across 10 datasets. We find that malicious models have a severe impact on the multi-LLM systems, especially for reasoning and safety domains where performance is lowered by 7.12% and 7.94% on average. We then propose mitigation strategies to alleviate the impact of malicious components, by employing external supervisors that oversee model collaboration to disable/mask them out to reduce their influence. On average, these strategies recover 95.31% of the initial performance, while making model collaboration systems fully resistant to malicious models remains an open research question.

</details>


### [9] [The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems](https://arxiv.org/abs/2602.05182)
*Shangbin Feng,Kishan Panaganti,Yulia Tsvetkov,Wenhao Yu*

Main category: cs.CL

TL;DR: 该论文提出通过知识蒸馏将多模型协作系统的优势压缩到单个模型中，并设计了"单-多进化循环"让模型通过协作、蒸馏、再协作的过程实现自我进化。


<details>
  <summary>Details</summary>
Motivation: 多模型协作系统虽然能结合不同模型的优势，但需要同时加载多个模型，计算成本高昂。如何在保持协作优势的同时提高效率，降低推理成本，是本文要解决的核心问题。

Method: 1. 协作蒸馏：训练单个模型模仿多模型协作系统的输出，将协作优势压缩到单个模型中
2. 单-多进化循环：多个模型协作 → 每个模型从协作输出中蒸馏学习 → 蒸馏改进后的模型再次协作，形成进化生态系统

Result: 1. 单个模型通过蒸馏平均提升8.0%，在保持协作优势的同时将成本降低到单个模型
2. 蒸馏改进后的模型再次协作，系统性能相比初始协作系统平均提升14.9%
3. 该方法优于现有进化AI方法，兼容多种模型/协作/蒸馏设置，能解决初始模型/系统难以处理的问题

Conclusion: 协作蒸馏和单-多进化循环是有效的模型进化框架，能够在降低计算成本的同时提升模型性能，为构建高效、自进化的AI系统提供了新思路。

Abstract: Model collaboration -- systems where multiple language models (LMs) collaborate -- combines the strengths of diverse models with cost in loading multiple LMs. We improve efficiency while preserving the strengths of collaboration by distilling collaborative patterns into a single model, where the model is trained on the outputs of the model collaboration system. At inference time, only the distilled model is employed: it imitates the collaboration while only incurring the cost of a single model. Furthermore, we propose the single-multi evolution loop: multiple LMs collaborate, each distills from the collaborative outputs, and these post-distillation improved LMs collaborate again, forming a collective evolution ecosystem where models evolve and self-improve by interacting with an environment of other models. Extensive experiments with 7 collaboration strategies and 15 tasks (QA, reasoning, factuality, etc.) demonstrate that: 1) individual models improve by 8.0% on average, absorbing the strengths of collaboration while reducing the cost to a single model; 2) the collaboration also benefits from the stronger and more synergistic LMs after distillation, improving over initial systems without evolution by 14.9% on average. Analysis reveals that the single-multi evolution loop outperforms various existing evolutionary AI methods, is compatible with diverse model/collaboration/distillation settings, and helps solve problems where the initial model/system struggles to.

</details>


### [10] [Are Open-Weight LLMs Ready for Social Media Moderation? A Comparative Study on Bluesky](https://arxiv.org/abs/2602.05189)
*Hsuan-Yu Chou,Wajiha Naveed,Shuyan Zhou,Xiaowei Yang*

Main category: cs.CL

TL;DR: 开放权重大语言模型在社交媒体内容审核任务中表现与专有模型相当，能够支持隐私保护的本地化审核部署。


<details>
  <summary>Details</summary>
Motivation: 随着互联网访问扩大，有害内容暴露增加，需要有效的审核机制。虽然专有LLMs在零样本设置下优于传统机器学习模型，但开放权重LLMs的即用能力仍不明确，需要评估其在真实社交媒体内容审核中的表现。

Method: 评估7个最先进的LLMs（4个专有模型和3个开放权重模型），使用Bluesky平台的真实帖子、Bluesky审核服务的决策以及两位作者的标注作为测试数据。分析模型在敏感性和特异性方面的表现，并比较不同模型之间的一致性。

Result: 开放权重LLMs的敏感性（81%-97%）和特异性（91%-100%）与专有模型（敏感性72%-98%，特异性93%-99%）有相当大的重叠。在粗鲁内容检测中特异性高于敏感性，但在不宽容和威胁检测中敏感性更高。发现人类审核员与LLMs之间存在评分者间一致性。

Conclusion: 开放权重LLMs能够在消费级硬件上支持隐私保护的审核，为设计平衡社区价值观与个人用户偏好的审核系统提供了新方向，展示了开放模型在内容审核任务中的实用价值。

Abstract: As internet access expands, so does exposure to harmful content, increasing the need for effective moderation. Research has demonstrated that large language models (LLMs) can be effectively utilized for social media moderation tasks, including harmful content detection. While proprietary LLMs have been shown to zero-shot outperform traditional machine learning models, the out-of-the-box capability of open-weight LLMs remains an open question.
  Motivated by recent developments of reasoning LLMs, we evaluate seven state-of-the-art models: four proprietary and three open-weight. Testing with real-world posts on Bluesky, moderation decisions by Bluesky Moderation Service, and annotations by two authors, we find a considerable degree of overlap between the sensitivity (81%--97%) and specificity (91%--100%) of the open-weight LLMs and those (72%--98%, and 93%--99%) of the proprietary ones. Additionally, our analysis reveals that specificity exceeds sensitivity for rudeness detection, but the opposite holds for intolerance and threats. Lastly, we identify inter-rater agreement across human moderators and the LLMs, highlighting considerations for deploying LLMs in both platform-scale and personalized moderation contexts. These findings show open-weight LLMs can support privacy-preserving moderation on consumer-grade hardware and suggest new directions for designing moderation systems that balance community values with individual user preferences.

</details>


### [11] [Aligning Large Language Model Behavior with Human Citation Preferences](https://arxiv.org/abs/2602.05205)
*Kenichiro Ando,Tatsuya Harada*

Main category: cs.CL

TL;DR: 该研究构建了一个数据集来评估LLM引用行为与人类偏好的对齐程度，发现LLM过度引用标记为需要引用的文本，但系统性欠引用数字和包含人名的句子，通过DPO可以校准模型行为以更好地匹配人类偏好。


<details>
  <summary>Details</summary>
Motivation: 当前LLM服务虽然添加引用来增强可信度，但LLM如何识别值得引用的内容以及如何控制这一过程仍未被充分探索。研究关注LLM当前倾向于引用什么类型的内容，以及这种行为与人类偏好的对齐程度。

Method: 构建数据集来表征人类引用偏好与LLM行为之间的关系。将网络文本分为八种引用动机类型，在所有类型组合中详尽评估成对引用偏好以捕捉细粒度对比。使用Direct Preference Optimization（DPO）进行实验来校准模型行为。

Result: 1) 人类最常为医学文本寻求引用，更强的模型也显示类似倾向；2) 当前模型比人类多27%的可能性为标记为需要引用的文本（如维基百科）添加引用，这种过度强调降低了对齐准确性；3) 模型系统性欠引用数字句子（相对人类-22.6%）和包含人名的句子（-20.1%），而这些类别人类通常要求引用；4) DPO实验表明可以校准模型行为以更好地匹配人类引用偏好。

Conclusion: 该研究为LLM引用偏好的细粒度调查提供了基础，揭示了当前LLM引用行为与人类偏好之间的系统性差异，并证明通过DPO等技术可以改善这种对齐。

Abstract: Most services built on powerful large-scale language models (LLMs) add citations to their output to enhance credibility. Recent research has paid increasing attention to the question of what reference documents to link to outputs. However, how LLMs recognize cite-worthiness and how this process should be controlled remains underexplored. In this study, we focus on what kinds of content LLMs currently tend to cite and how well that behavior aligns with human preferences. We construct a dataset to characterize the relationship between human citation preferences and LLM behavior. Web-derived texts are categorized into eight citation-motivation types, and pairwise citation preferences are exhaustively evaluated across all type combinations to capture fine-grained contrasts. Our results show that humans most frequently seek citations for medical text, and stronger models display a similar tendency. We also find that current models are as much as $27\%$ more likely than humans to add citations to text that is explicitly marked as needing citations on sources such as Wikipedia, and this overemphasis reduces alignment accuracy. Conversely, models systematically underselect numeric sentences (by $-22.6\%$ relative to humans) and sentences containing personal names (by $-20.1\%$), categories for which humans typically demand citations. Furthermore, experiments with Direct Preference Optimization demonstrate that model behavior can be calibrated to better match human citation preferences. We expect this study to provide a foundation for more fine-grained investigations into LLM citation preferences.

</details>


### [12] [Quantifying the Knowledge Proximity Between Academic and Industry Research: An Entity and Semantic Perspective](https://arxiv.org/abs/2602.05211)
*Hongye Zhao,Yi Zhao,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 该研究通过细粒度知识实体和语义空间分析，量化了学术界与产业界的共同演化轨迹，发现技术变革期间两者的知识接近度增加，且学术界的知识主导地位减弱。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖合作论文或专利数量等宏观指标来分析学术界与产业界的知识接近度，缺乏对文献中知识单元的细粒度分析，这导致对两者间精细知识接近度的把握不足，可能影响合作框架和资源配置效率。

Method: 研究采用两种方法：1）实体测量部分：通过预训练模型提取细粒度知识实体，使用余弦相似度测量序列重叠，并通过复杂网络分析拓扑特征；2）语义层面：采用无监督对比学习量化语义空间的收敛性，通过测量跨机构文本相似度；最后使用引用分布模式检查双向知识流与相似度的相关性。

Result: 分析显示学术界与产业界的知识接近度在上升，特别是在技术变革后。这为共同演化中的双向适应提供了文本证据。此外，在技术范式转变期间，学术界的知识主导地位会减弱。

Conclusion: 该研究通过细粒度实体和语义分析方法，为学术界与产业界的共同演化提供了新的量化视角，揭示了技术变革期间两者知识接近度的动态变化，对优化产学合作框架和资源配置具有指导意义。

Abstract: The academia and industry are characterized by a reciprocal shaping and dynamic feedback mechanism. Despite distinct institutional logics, they have adapted closely in collaborative publishing and talent mobility, demonstrating tension between institutional divergence and intensive collaboration. Existing studies on their knowledge proximity mainly rely on macro indicators such as the number of collaborative papers or patents, lacking an analysis of knowledge units in the literature. This has led to an insufficient grasp of fine-grained knowledge proximity between industry and academia, potentially undermining collaboration frameworks and resource allocation efficiency. To remedy the limitation, this study quantifies the trajectory of academia-industry co-evolution through fine-grained entities and semantic space. In the entity measurement part, we extract fine-grained knowledge entities via pre-trained models, measure sequence overlaps using cosine similarity, and analyze topological features through complex network analysis. At the semantic level, we employ unsupervised contrastive learning to quantify convergence in semantic spaces by measuring cross-institutional textual similarities. Finally, we use citation distribution patterns to examine correlations between bidirectional knowledge flows and similarity. Analysis reveals that knowledge proximity between academia and industry rises, particularly following technological change. This provides textual evidence of bidirectional adaptation in co-evolution. Additionally, academia's knowledge dominance weakens during technological paradigm shifts. The dataset and code for this paper can be accessed at https://github.com/tinierZhao/Academic-Industrial-associations.

</details>


### [13] [Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions](https://arxiv.org/abs/2602.05220)
*Jinchuan Tian,Haoran Wang,Bo-Hao Su,Chien-yu Huang,Qingzheng Wang,Jiatong Shi,William Chen,Xun Gong,Siddhant Arora,Chin-Jou Li,Masao Someki,Takashi Maekaku,Yusuke Shinohara,Jin Sakuma,Chao-Han Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: Bagpiper是一个8B参数的音频基础模型，通过丰富的自然语言描述实现音频的物理信号与抽象认知概念之间的双向映射，在统一框架下实现音频理解与生成任务。


<details>
  <summary>Details</summary>
Motivation: 当前音频基础模型通常依赖于刚性、任务特定的监督，处理孤立的音频因素而非整体。相比之下，人类智能以整体方式处理音频，无缝地将物理信号与抽象认知概念连接起来以执行复杂任务。作者希望构建一个能模拟人类这种整体音频处理能力的模型。

Method: 1. 使用600B token的大规模语料进行预训练，建立原始音频与高级概念空间之间的稳健双向映射。2. 采用caption-then-process工作流程进行微调，模拟中间认知推理步骤来解决多样化任务。3. 通过丰富的自然语言描述（包含转录、音频事件等关键认知概念）来解释物理音频。

Result: 1. 在音频理解方面，Bagpiper在MMAU和AIRBench上超越了Qwen-2.5-Omni。2. 在音频生成方面，超越了CosyVoice3和TangoFlux，能够合成语音、音乐和音效的任意组合。3. 据作者所知，这是首批实现通用音频统一理解与生成的工作之一。

Conclusion: Bagpiper通过将物理音频信号映射到丰富的认知概念空间，实现了对音频的整体处理，成功构建了一个统一的音频理解与生成基础模型，展示了在多样化任务上的卓越性能。

Abstract: Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.

</details>


### [14] [FedMosaic: Federated Retrieval-Augmented Generation via Parametric Adapters](https://arxiv.org/abs/2602.05235)
*Zhilin Liang,Yuxiang Wang,Zimu Zhou,Hainan Zhang,Boyi Liu,Yongxin Tong*

Main category: cs.CL

TL;DR: FedMosaic：首个基于参数化适配器的联邦RAG框架，通过语义聚类文档到多文档适配器并使用文档特定掩码来降低开销，同时通过选择性适配器聚合来避免冲突，在保护隐私的同时显著提升准确性并大幅降低存储和通信成本。


<details>
  <summary>Details</summary>
Motivation: 传统RAG假设集中式知识库，但在隐私敏感领域，知识通常分散在孤岛中无法共享。这促使了联邦RAG的需求，即中央LLM服务器与分布式知识孤岛协作而不共享原始文档。上下文RAG会传输原始文档违反隐私要求，而参数化RAG通过轻量级适配器避免了原始文本交换。

Method: FedMosaic采用参数化适配器方法，但面临两个挑战：1）每个文档适配器带来的高存储和通信开销；2）多个适配器无差别合并导致的破坏性聚合。解决方案：1）将语义相关文档聚类到多文档适配器中，使用文档特定掩码在减少开销的同时保持特异性；2）选择性适配器聚合，仅合并相关性对齐且无冲突的适配器。

Result: 实验表明，FedMosaic在四个类别中平均比最先进方法准确率高10.9%，同时存储成本降低78.8%到86.3%，通信成本降低91.4%，且从不共享原始文档。

Conclusion: FedMosaic成功解决了联邦RAG中的存储、通信和聚合冲突问题，实现了隐私保护下的高效知识检索增强，为分布式隐私敏感环境中的RAG应用提供了可行的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by grounding generation in external knowledge to improve factuality and reduce hallucinations. Yet most deployments assume a centralized corpus, which is infeasible in privacy aware domains where knowledge remains siloed. This motivates federated RAG (FedRAG), where a central LLM server collaborates with distributed silos without sharing raw documents. In context RAG violates this requirement by transmitting verbatim documents, whereas parametric RAG encodes documents into lightweight adapters that merge with a frozen LLM at inference, avoiding raw-text exchange. We adopt the parametric approach but face two unique challenges induced by FedRAG: high storage and communication from per-document adapters, and destructive aggregation caused by indiscriminately merging multiple adapters. We present FedMosaic, the first federated RAG framework built on parametric adapters. FedMosaic clusters semantically related documents into multi-document adapters with document-specific masks to reduce overhead while preserving specificity, and performs selective adapter aggregation to combine only relevance-aligned, nonconflicting adapters. Experiments show that FedMosaic achieves an average 10.9% higher accuracy than state-of-the-art methods in four categories, while lowering storage costs by 78.8% to 86.3% and communication costs by 91.4%, and never sharing raw documents.

</details>


### [15] [Copyright Detective: A Forensic System to Evidence LLMs Flickering Copyright Leakage Risks](https://arxiv.org/abs/2602.05252)
*Guangwei Zhang,Jianing Zhu,Cheng Qian,Neil Gong,Rada Mihalcea,Zhaozhuo Xu,Jingrui He,Jiaqi Ma,Yun Huang,Chaowei Xiao,Bo Li,Ahmed Abbasi,Dongwon Lee,Heng Ji,Denghui Zhang*

Main category: cs.CL

TL;DR: Copyright Detective是首个交互式取证系统，用于检测、分析和可视化LLM输出中的潜在版权风险，采用多范式检测框架而非静态分类。


<details>
  <summary>Details</summary>
Motivation: 由于版权法的复杂性，需要将版权侵权检测视为证据发现过程而非静态分类任务，以支持LLM的负责任部署和透明评估。

Method: 集成多种检测范式：内容召回测试、释义级相似性分析、说服性越狱探测和去学习验证，通过交互式提示、响应收集和迭代工作流程实现系统审计。

Result: 开发出首个交互式取证系统，能够系统性地审计逐字记忆和释义级泄露，即使在黑盒访问条件下也能支持LLM版权风险的透明评估。

Conclusion: Copyright Detective为LLM版权风险检测提供了统一的、可扩展的框架，将版权侵权视为证据发现过程，有助于促进LLM的负责任部署。

Abstract: We present Copyright Detective, the first interactive forensic system for detecting, analyzing, and visualizing potential copyright risks in LLM outputs. The system treats copyright infringement versus compliance as an evidence discovery process rather than a static classification task due to the complex nature of copyright law. It integrates multiple detection paradigms, including content recall testing, paraphrase-level similarity analysis, persuasive jailbreak probing, and unlearning verification, within a unified and extensible framework. Through interactive prompting, response collection, and iterative workflows, our system enables systematic auditing of verbatim memorization and paraphrase-level leakage, supporting responsible deployment and transparent evaluation of LLM copyright risks even with black-box access.

</details>


### [16] [CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs](https://arxiv.org/abs/2602.05258)
*Haoran Li,Sucheng Ren,Alan Yuille,Feng Wang*

Main category: cs.CL

TL;DR: 本文提出CoPE方法，通过软裁剪RoPE的低频分量来统一OOD缓解和语义建模两个目标，显著提升LLM的长上下文扩展能力至256k。


<details>
  <summary>Details</summary>
Motivation: 现有的RoPE扩展方法主要分为两类：OOD缓解（调整频率以适应未见位置）和语义建模（确保注意力分数优先语义相似token）。作者认为这两种看似不同的目标可以通过统一的干预方法来解决。

Method: 提出CoPE方法，对RoPE的低频分量进行软裁剪。这种软裁剪策略不仅能消除OOD异常值、细化语义信号，还能避免硬裁剪导致的频谱泄漏。

Result: 大量实验表明，对RoPE应用软裁剪策略能带来显著的性能提升，且能扩展到256k的上下文长度，验证了理论分析并确立了CoPE在长度泛化上的SOTA地位。

Conclusion: CoPE通过简单的软裁剪干预，统一了OOD缓解和语义建模两个目标，为LLM的长上下文扩展提供了有效且先进的方法。

Abstract: Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization. Our code, data, and models are available at https://github.com/hrlics/CoPE.

</details>


### [17] [Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR](https://arxiv.org/abs/2602.05261)
*Fanfan Liu,Youyang Yin,Peng Shi,Siqi Yang,Zhixiong Zeng,Haibo Qiu*

Main category: cs.CL

TL;DR: 本文分析了RLVR算法中响应长度变化的原因，提出了消除长度偏差的LUSPO算法，在数学推理和多模态推理任务中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: RLVR训练中响应长度的增加通常被视为推理能力提升的关键因素，但不同RLVR算法的响应长度变化模式差异很大，需要从理论上解释这些差异并提供改进方法。

Method: 1. 深入分析主流RLVR算法的组成成分；2. 理论分析影响响应长度的因素并通过实验验证；3. 基于理论发现提出LUSPO算法，通过修正GSPO中的长度偏差使其损失函数对响应长度无偏。

Result: LUSPO在数学推理基准和多模态推理场景中一致取得优越性能，解决了响应长度崩溃问题，相比GRPO和GSPO等方法实现了SOTA性能。

Conclusion: LUSPO是一种新颖的、最先进的优化策略，通过消除长度偏差解决了RLVR训练中的响应长度问题，为增强LLM和VLM的推理能力提供了有效方法。

Abstract: Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO.

</details>


### [18] [Towards a Science of Collective AI: LLM-based Multi-Agent Systems Need a Transition from Blind Trial-and-Error to Rigorous Science](https://arxiv.org/abs/2602.05289)
*Jingru Fan,Dewen Liu,Yufan Dang,Huatao Li,Yuheng Wang,Wei Liu,Feiyu Duan,Xuanwen Ding,Shu Yao,Lin Wu,Ruijie Shi,Wai-Shing Leung,Yuan Cheng,Zhongyu Wei,Cheng Yang,Chen Qian,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 该论文提出一个统一框架，将多智能体系统研究从经验试错转向设计科学，通过建立协作增益度量Γ和系统化因子库来实现科学化优化。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型极大地增强了多智能体系统的能力，但该领域仍严重依赖经验试错，缺乏统一的科学框架来系统化优化和改进。这源于归因模糊性：一是缺乏结构化因子分类，研究人员只能进行无指导调整；二是缺乏统一度量，无法区分真正的协作增益与单纯资源积累。

Method: 1. 建立协作增益度量Γ作为科学标准，以隔离内在增益与预算增加的影响；2. 提出因子归因范式，系统识别驱动协作的因素；3. 构建系统化的多智能体系统因子库，将设计空间结构化分为控制级预设和信息级动态。

Result: 提出了一个集成框架，通过协作增益度量Γ和因子归因范式，为多智能体系统研究提供科学基础，将领域从盲目实验转向严谨科学。

Conclusion: 该框架为多智能体系统研究提供了从经验试错到设计科学的转型路径，促进了集体人工智能真正科学的形成，为实现系统化优化和改进奠定了基础。

Abstract: Recent advancements in Large Language Models (LLMs) have greatly extended the capabilities of Multi-Agent Systems (MAS), demonstrating significant effectiveness across a wide range of complex and open-ended domains. However, despite this rapid progress, the field still relies heavily on empirical trial-and-error. It lacks a unified and principled scientific framework necessary for systematic optimization and improvement. This bottleneck stems from the ambiguity of attribution: first, the absence of a structured taxonomy of factors leaves researchers restricted to unguided adjustments; second, the lack of a unified metric fails to distinguish genuine collaboration gain from mere resource accumulation. In this paper, we advocate for a transition to design science through an integrated framework. We advocate to establish the collaboration gain metric ($Γ$) as the scientific standard to isolate intrinsic gains from increased budgets. Leveraging $Γ$, we propose a factor attribution paradigm to systematically identify collaboration-driving factors. To support this, we construct a systematic MAS factor library, structuring the design space into control-level presets and information-level dynamics. Ultimately, this framework facilitates the transition from blind experimentation to rigorous science, paving the way towards a true science of Collective AI.

</details>


### [19] [MentorCollab: Selective Large-to-Small Inference-Time Guidance for Efficient Reasoning](https://arxiv.org/abs/2602.05307)
*Haojin Wang,Yike Wang,Shangbin Feng,Hannaneh Hajishirzi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: MentorCollab：一种推理时协作方法，让大型推理模型选择性、稀疏地指导小型语言模型，通过轻量级验证器决定是否采纳导师的短前瞻片段，在提升性能的同时显著降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）推理成本高且常产生冗余推理，而小型语言模型（SLMs）在多步推理任务上表现不佳。现有协作方法往往导致模仿性冗长推理，缺乏一致的错误纠正。

Method: 提出MentorCollab方法：在随机采样的token位置探测两个模型的分歧，使用轻量级验证器决定SLM是跟随导师模型的短前瞻片段还是继续自主生成，实现选择性、稀疏的指导。

Result: 在15个SLM-LRM组合和3个领域（数学推理、通用知识、常识推理）中，12个设置性能提升，平均提升3.0%，最高达8.0%，平均只有18.4%的token由昂贵导师模型生成。

Conclusion: 短片段和选择性探测足以实现有效协作，选择性推理时指导能恢复大型模型的推理能力而不带来显著的推理开销。

Abstract: Large reasoning models (LRMs) achieve strong performance by producing long chains of thought, but their inference costs are high and often generate redundant reasoning. Small language models (SLMs) are far more efficient, yet struggle on multi-step reasoning tasks. A natural idea is to let a large model guide a small one at inference time as a mentor, yet existing collaboration methods often promote imitation, resulting in verbose reasoning without consistent error correction. We propose MentorCollab, an inference-time collaboration method in which an LRM selectively and sparsely guides an SLM, rather than taking over generation. At randomly sampled token positions, we probe for divergences between the two models and use a lightweight verifier to decide whether the SLM should follow a short lookahead segment from its mentor or continue on its own. Across 15 SLM--LRM pairs and 3 domains (math reasoning, general knowledge, and commonsense reasoning), our method improves performance in 12 settings, with average gains of 3.0% and up to 8.0%, while adopting only having 18.4% tokens generated by the expensive mentor model on average. We find that short segments and selective probing are sufficient for effective collaboration. Our results show that selective inference-time guidance restores large-model reasoning ability without substantial inference overhead.

</details>


### [20] [A Human-in-the-Loop, LLM-Centered Architecture for Knowledge-Graph Question Answering](https://arxiv.org/abs/2602.05512)
*Larissa Pusch,Alexandre Courtiol,Tim Conrad*

Main category: cs.CL

TL;DR: 提出一个交互式框架，让LLM生成和解释Cypher图查询，用户通过自然语言迭代优化，提高知识图谱的可访问性。


<details>
  <summary>Details</summary>
Motivation: LLM在知识密集型领域存在幻觉、信息过时和可解释性差的问题，基于文本的检索增强生成在复杂推理方面表现不佳，而知识图谱虽然支持精确查询但需要专门的查询语言知识。

Method: 设计交互式框架，LLM生成和解释Cypher图查询，用户通过自然语言反馈迭代优化查询，在合成电影KG和真实KG（Hyena和MaRDI）上进行实验评估。

Result: 框架提高了复杂数据集的访问性，同时保持了事实准确性和语义严谨性，通过90个查询的基准测试评估了不同LLM的查询解释质量和错误检测能力。

Conclusion: 交互式LLM-KG框架有效提升了知识图谱的可访问性，为不同领域模型性能差异提供了见解，解决了LLM在知识密集型任务中的局限性。

Abstract: Large Language Models (LLMs) excel at language understanding but remain limited in knowledge-intensive domains due to hallucinations, outdated information, and limited explainability. Text-based retrieval-augmented generation (RAG) helps ground model outputs in external sources but struggles with multi-hop reasoning. Knowledge Graphs (KGs), in contrast, support precise, explainable querying, yet require a knowledge of query languages. This work introduces an interactive framework in which LLMs generate and explain Cypher graph queries and users iteratively refine them through natural language. Applied to real-world KGs, the framework improves accessibility to complex datasets while preserving factual accuracy and semantic rigor and provides insight into how model performance varies across domains. Our core quantitative evaluation is a 90-query benchmark on a synthetic movie KG that measures query explanation quality and fault detection across multiple LLMs, complemented by two smaller real-life query-generation experiments on a Hyena KG and the MaRDI (Mathematical Research Data Initiative) KG.

</details>


### [21] [How Do Language Models Acquire Character-Level Information?](https://arxiv.org/abs/2602.05347)
*Soma Sato,Ryohei Sasano*

Main category: cs.CL

TL;DR: 语言模型能够隐式编码字符级信息，研究通过对比控制实验揭示了这一现象的机制，发现分词相关的合并规则和正字法约束，以及独立于分词的字串语义关联和句法信息是主要因素。


<details>
  <summary>Details</summary>
Motivation: 语言模型在没有显式训练的情况下被报告能够隐式编码字符级信息，但这种现象背后的机制尚未得到充分探索。

Method: 通过比较在控制设置下（如指定预训练数据集或分词器）训练的语言模型与标准设置下训练的模型，分析模型如何获取字符级知识，并将影响因素分为与分词相关和独立于分词两类。

Result: 分析表明，合并规则和正字法约束是分词相关的主要因素，而字串的语义关联和句法信息则是独立于分词的关键因素。

Conclusion: 语言模型隐式编码字符级信息的机制可以通过分词相关因素和独立于分词的因素来解释，这为理解语言模型的内在表征提供了新视角。

Abstract: Language models (LMs) have been reported to implicitly encode character-level information, despite not being explicitly provided during training. However, the mechanisms underlying this phenomenon remain largely unexplored. To reveal the mechanisms, we analyze how models acquire character-level knowledge by comparing LMs trained under controlled settings, such as specifying the pre-training dataset or tokenizer, with those trained under standard settings. We categorize the contributing factors into those independent of tokenization. Our analysis reveals that merge rules and orthographic constraints constitute primary factors arising from tokenization, whereas semantic associations of substrings and syntactic information function as key factors independent of tokenization.

</details>


### [22] [PACE: Defying the Scaling Hypothesis of Exploration in Iterative Alignment for Mathematical Reasoning](https://arxiv.org/abs/2602.05370)
*Jun Rao,Zixiong Yu,Xuebo Liu,Guhan Chen,Jing Li,Jiansheng Wei,Xiaojun Meng,Min Zhang*

Main category: cs.CL

TL;DR: 论文提出PACE方法，用生成式校正策略替代暴力采样，以更少计算量实现更好的数学推理对齐效果。


<details>
  <summary>Details</summary>
Motivation: 当前DPO-R1方法依赖大规模采样（N≥8）从分布尾部挖掘黄金轨迹，但作者发现这种扩展假设存在问题：在数学推理任务中，过度探索会导致收益递减甚至策略崩溃。

Method: 提出PACE（Proximal Alignment via Corrective Exploration）方法，用生成式校正策略替代暴力采样。该方法仅需极小预算（2<N<3），从失败的探索中合成高质量偏好对。

Result: PACE在性能上超越DPO-R1（N=16），同时仅使用约1/5的计算资源，并且对奖励黑客攻击和标签噪声具有更强的鲁棒性。

Conclusion: PACE方法挑战了现有的大规模采样范式，证明在数学推理对齐中，更智能的校正策略比暴力扩展采样更有效，为LLM对齐提供了新的高效范式。

Abstract: Iterative Direct Preference Optimization has emerged as the state-of-the-art paradigm for aligning Large Language Models on reasoning tasks. Standard implementations (DPO-R1) rely on Best-of-N sampling (e.g., $N \ge 8$) to mine golden trajectories from the distribution tail. In this paper, we challenge this scaling hypothesis and reveal a counter-intuitive phenomenon: in mathematical reasoning, aggressive exploration yields diminishing returns and even catastrophic policy collapse. We theoretically demonstrate that scaling $N$ amplifies verifier noise and induces detrimental distribution shifts. To resolve this, we introduce \textbf{PACE} (Proximal Alignment via Corrective Exploration), which replaces brute-force mining with a generation-based corrective strategy. Operating with a minimal budget ($2<N<3$), PACE synthesizes high-fidelity preference pairs from failed explorations. Empirical evaluations show that PACE outperforms DPO-R1 $(N=16)$ while using only about $1/5$ of the compute, demonstrating superior robustness against reward hacking and label noise.

</details>


### [23] [Cross-Lingual Empirical Evaluation of Large Language Models for Arabic Medical Tasks](https://arxiv.org/abs/2602.05374)
*Chaimae Abouzahir,Congbo Ma,Nizar Habash,Farah E. Shamout*

Main category: cs.CL

TL;DR: 研究通过阿拉伯语和英语医学问答的跨语言实证分析，发现LLMs存在持续的语言驱动性能差距，且随着任务复杂性增加而加剧。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在医学应用中普遍存在英语中心主义问题，限制了其在语言多样化社区中的鲁棒性和可靠性。虽然已有研究指出LLMs在低资源语言医学任务中性能下降，但根本原因尚不清楚。

Method: 对阿拉伯语和英语医学问答进行跨语言实证分析，包括性能差距评估、标记化分析（揭示阿拉伯语医学文本的结构碎片化）以及可靠性分析（检查模型报告置信度与解释和正确性的相关性）。

Result: 发现持续存在的语言驱动性能差距，且随着任务复杂性增加而加剧；阿拉伯语医学文本存在结构碎片化问题；模型报告的置信度和解释与正确性相关性有限。

Conclusion: 这些发现强调了在医学任务中需要语言感知的LLM设计和评估策略，以解决跨语言性能差距问题。

Abstract: In recent years, Large Language Models (LLMs) have become widely used in medical applications, such as clinical decision support, medical education, and medical question answering. Yet, these models are often English-centric, limiting their robustness and reliability for linguistically diverse communities. Recent work has highlighted discrepancies in performance in low-resource languages for various medical tasks, but the underlying causes remain poorly understood. In this study, we conduct a cross-lingual empirical analysis of LLM performance on Arabic and English medical question and answering. Our findings reveal a persistent language-driven performance gap that intensifies with increasing task complexity. Tokenization analysis exposes structural fragmentation in Arabic medical text, while reliability analysis suggests that model-reported confidence and explanations exhibit limited correlation with correctness. Together, these findings underscore the need for language-aware design and evaluation strategies in LLMs for medical tasks.

</details>


### [24] [IESR:Efficient MCTS-Based Modular Reasoning for Text-to-SQL with Large Language Models](https://arxiv.org/abs/2602.05385)
*Tao Liu,Jiafan Lu,Bohan Yu,Pengcheng Wu,Liu Haixin,Guoyu Xu,Li Xiangheng,Lixiao Li,Jiaming Hou,Zhao Shijun,Xinglin Lyu,Kunli Zhang,Yuxiang Jia,Hongyin Zan*

Main category: cs.CL

TL;DR: IESR框架通过信息增强结构化推理，使用轻量级大语言模型在复杂推理基准上实现SOTA性能，无需微调。


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL方法在复杂推理、领域知识和假设性查询方面表现不佳，且企业部署成本高昂。

Method: 提出IESR框架：(1)利用LLM进行关键信息理解和模式链接，解耦数学计算与SQL生成；(2)基于蒙特卡洛树搜索的多路径推理机制与多数投票；(3)引入轨迹一致性验证模块确保准确性。

Result: 在复杂推理基准LogicCat上达到24.28 EX，Archer数据集上达到37.28 EX，使用轻量级模型无需微调即实现SOTA性能。

Conclusion: IESR有效解决了Text-to-SQL中的复杂推理问题，同时揭示了当前编码器模型在物理知识、数学计算和常识推理方面的偏见与不足，为未来研究指明了方向。

Abstract: Text-to-SQL is a key natural language processing task that maps natural language questions to SQL queries, enabling intuitive interaction with web-based databases. Although current methods perform well on benchmarks like BIRD and Spider, they struggle with complex reasoning, domain knowledge, and hypothetical queries, and remain costly in enterprise deployment. To address these issues, we propose a framework named IESR(Information Enhanced Structured Reasoning) for lightweight large language models: (i) leverages LLMs for key information understanding and schema linking, and decoupling mathematical computation and SQL generation, (ii) integrates a multi-path reasoning mechanism based on Monte Carlo Tree Search (MCTS) with majority voting, and (iii) introduces a trajectory consistency verification module with a discriminator model to ensure accuracy and consistency. Experimental results demonstrate that IESR achieves state-of-the-art performance on the complex reasoning benchmark LogicCat (24.28 EX) and the Archer dataset (37.28 EX) using only compact lightweight models without fine-tuning. Furthermore, our analysis reveals that current coder models exhibit notable biases and deficiencies in physical knowledge, mathematical computation, and common-sense reasoning, highlighting important directions for future research. We released code at https://github.com/Ffunkytao/IESR-SLM.

</details>


### [25] [Beyond Length: Context-Aware Expansion and Independence as Developmentally Sensitive Evaluation in Child Utterances](https://arxiv.org/abs/2602.05392)
*Jiyun Chun,Eric Fosler-Lussier,Michael White,Andrew Perrault*

Main category: cs.CL

TL;DR: 论文提出了一个基于LLM的儿童话语质量评估框架，通过分类成人前序话语类型并沿扩展性和独立性两个维度评分，超越传统基于长度的指标。


<details>
  <summary>Details</summary>
Motivation: 当前儿童话语质量评估面临挑战，常用代理指标如平均话语长度、词汇多样性和可读性指数主要关注长度而忽略对话语境，无法捕捉推理深度、话题维持和话语规划等质量方面。

Method: 引入LLM-as-a-judge框架，首先分类成人前序话语类型，然后沿两个维度评估儿童回应：扩展性（语境阐述和推理深度）和独立性（儿童对推进话语的贡献）。

Result: 该框架展示了与年龄相关的发展模式，在年龄估计上优于常见基线，能检测与话语关系相关的语义差异，且与人类判断一致，支持大规模评估。

Conclusion: 该研究将儿童话语评估从简单的长度测量转向评估儿童言语如何在特定语境中有意义地贡献和推进对话，为儿童语言发展提供了更全面的评估工具。

Abstract: Evaluating the quality of children's utterances in adult-child dialogue remains challenging due to insufficient context-sensitive metrics. Common proxies such as Mean Length of Utterance (MLU), lexical diversity (vocd-D), and readability indices (Flesch-Kincaid Grade Level, Gunning Fog Index) are dominated by length and ignore conversational context, missing aspects of response quality such as reasoning depth, topic maintenance, and discourse planning. We introduce an LLM-as-a-judge framework that first classifies the Previous Adult Utterance Type and then scores the child's response along two axes: Expansion (contextual elaboration and inferential depth) and Independence (the child's contribution to advancing the discourse). These axes reflect fundamental dimensions in child language development, where Expansion captures elaboration, clause combining, and causal and contrastive connectives. Independence captures initiative, topic control, decreasing reliance on adult scaffolding through growing self-regulation, and audience design. We establish developmental validity by showing age-related patterns and demonstrate predictive value by improving age estimation over common baselines. We further confirm semantic sensitivity by detecting differences tied to discourse relations. Our metrics align with human judgments, enabling large-scale evaluation. This shifts child utterance assessment from simply measuring length to evaluating how meaningfully the child's speech contributes to and advances the conversation within its context.

</details>


### [26] [Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better](https://arxiv.org/abs/2602.05393)
*Ji Zhao,Yufei Gu,Shitong Shao,Xun Zhou,Liang Xiang,Zeke Xie*

Main category: cs.CL

TL;DR: LET（Late-to-Early Training）是一种利用小型预训练模型加速大型语言模型训练的新范式，通过让早期层学习晚期层知识，实现1.6倍加速和5%的下游任务精度提升。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模不断扩大，预训练计算成本急剧增加，阻碍了快速发展。虽然已有许多预训练模型，但如何利用现有小型预训练模型加速大型模型训练的问题尚未充分探索。

Method: 提出Late-to-Early Training（LET）范式，核心思想是使用预训练模型（处于晚期训练阶段）的晚期层表示来指导目标模型早期训练阶段的早期层。包含两个关键机制：晚期到早期步长学习和晚期到早期层学习。

Result: 在1.4B和7B参数模型上的实验表明，LET能显著加速训练收敛，提升语言建模能力和下游任务性能。训练1.4B LLM时，相比标准训练获得1.6倍加速，下游任务精度提升近5%，即使使用的预训练模型参数仅为目标模型的1/10。

Conclusion: LET范式为高效训练大型语言模型提供了新思路，通过利用现有小型预训练模型的知识转移，实现了训练加速和性能提升的双重效益。

Abstract: As Large Language Models (LLMs) achieve remarkable empirical success through scaling model and data size, pretraining has become increasingly critical yet computationally prohibitive, hindering rapid development. Despite the availability of numerous pretrained LLMs developed at significant computational expense, a fundamental real-world question remains underexplored: \textit{Can we leverage existing small pretrained models to accelerate the training of larger models?} In this paper, we propose a Late-to-Early Training (LET) paradigm that enables LLMs to explicitly learn later knowledge in earlier steps and earlier layers. The core idea is to guide the early layers of an LLM during early training using representations from the late layers of a pretrained (i.e. late training phase) model. We identify two key mechanisms that drive LET's effectiveness: late-to-early-step learning and late-to-early-layer learning. These mechanisms significantly accelerate training convergence while robustly enhancing both language modeling capabilities and downstream task performance, enabling faster training with superior performance. Extensive experiments on 1.4B and 7B parameter models demonstrate LET's efficiency and effectiveness. Notably, when training a 1.4B LLM on the Pile dataset, our method achieves up to 1.6$\times$ speedup with nearly 5\% improvement in downstream task accuracy compared to standard training, even when using a pretrained model with 10$\times$ fewer parameters than the target model.

</details>


### [27] [OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration](https://arxiv.org/abs/2602.05400)
*Shaobo Wang,Xuan Ouyang,Tianyi Xu,Yuzheng Hu,Jialin Liu,Guo Chen,Tianyu Zhang,Junhao Zheng,Kexin Yang,Xingzhang Ren,Dayiheng Liu,Linfeng Zhang*

Main category: cs.CL

TL;DR: OPUS是一种动态数据选择框架，通过优化器诱导的投影效用评分来选择高质量训练数据，显著提升预训练效率和数据利用率。


<details>
  <summary>Details</summary>
Motivation: 随着高质量公开文本资源枯竭（数据墙现象），预训练需要从"更多tokens"转向"更好tokens"。现有方法要么依赖忽略训练动态的启发式静态过滤器，要么使用基于原始梯度的动态但优化器无关的标准，无法充分利用现代优化器的特性。

Method: 提出OPUS框架，在优化器诱导的更新空间中定义效用。通过投影候选数据的有效更新到稳定、同分布代理的目标方向来评分。采用Ghost技术和CountSketch实现计算效率，使用Boltzmann抽样保证数据多样性，仅增加4.7%计算开销。

Result: 在GPT-2 Large/XL的FineWeb和FineWeb-Edu预训练中，仅用30B tokens就超越了工业级基线甚至200B tokens的完整训练。结合静态过滤器后，即使使用低质量数据也能进一步提升效率。在Qwen3-8B-Base的SciencePedia持续预训练中，仅用0.5B tokens就达到了3B tokens完整训练的性能，在专业领域实现了显著的数据效率提升。

Conclusion: OPUS通过优化器感知的动态数据选择，有效解决了数据墙问题，显著提高了预训练的数据效率，在不同语料库、质量等级、优化器和模型规模下都表现出色，为大规模语言模型的高效训练提供了新思路。

Abstract: As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space. OPUS scores candidates by projecting their effective updates, shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia, OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.

</details>


### [28] [Grammatical Error Correction Evaluation by Optimally Transporting Edit Representation](https://arxiv.org/abs/2602.05419)
*Takumi Goto,Yusuke Sakai,Taro Watanabe*

Main category: cs.CL

TL;DR: UOT-ERRANT：一种基于编辑向量和不平衡最优传输的GEC自动评估新指标，专注于编辑相似性而非完整句子，在+Fluency领域表现优异且具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统基于嵌入的评估指标（如BERTScore）在GEC任务中效果不佳，因为源句中的许多词在假设和参考中保持不变，导致相似性度量失真。需要专门针对GEC编辑设计的评估方法。

Method: 提出编辑向量作为编辑的表示，引入UOT-ERRANT指标，使用不平衡最优传输将假设的编辑向量传输到参考编辑，计算编辑相似性而非句子相似性。

Result: 在SEEDA元评估实验中，UOT-ERRANT提高了评估性能，特别是在+Fluency领域（编辑较多的情况）表现优异。该方法具有高度可解释性，传输计划可解释为软编辑对齐。

Conclusion: UOT-ERRANT是一种有效的GEC自动评估指标，专注于编辑相似性，在系统排名和分析方面都有实用价值，特别是在编辑密集的+Fluency领域表现突出。

Abstract: Automatic evaluation in grammatical error correction (GEC) is crucial for selecting the best-performing systems. Currently, reference-based metrics are a popular choice, which basically measure the similarity between hypothesis and reference sentences. However, similarity measures based on embeddings, such as BERTScore, are often ineffective, since many words in the source sentences remain unchanged in both the hypothesis and the reference. This study focuses on edits specifically designed for GEC, i.e., ERRANT, and computes similarity measured over the edits from the source sentence. To this end, we propose edit vector, a representation for an edit, and introduce a new metric, UOT-ERRANT, which transports these edit vectors from hypothesis to reference using unbalanced optimal transport. Experiments with SEEDA meta-evaluation show that UOT-ERRANT improves evaluation performance, particularly in the +Fluency domain where many edits occur. Moreover, our method is highly interpretable because the transport plan can be interpreted as a soft edit alignment, making UOT-ERRANT a useful metric for both system ranking and analyzing GEC systems. Our code is available from https://github.com/gotutiyan/uot-errant.

</details>


### [29] [Once Correct, Still Wrong: Counterfactual Hallucination in Multilingual Vision-Language Models](https://arxiv.org/abs/2602.05437)
*Basel Mousi,Fahim Dalvi,Shammur Chowdhury,Firoj Alam,Nadir Durrani*

Main category: cs.CL

TL;DR: M2CQA是一个针对中东和北非地区的多模态文化基准测试，通过对比真实陈述和反事实陈述来评估视觉语言模型的文化幻觉问题，并提出CFHR指标来衡量模型的反事实接受率。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉基准测试很少测试视觉语言模型在非西方语境和非英语环境下的文化幻觉问题，即模型可能接受文化上合理但视觉上错误的解释。

Method: 构建M2CQA数据集，包含17个中东和北非国家的图像，配以英语、阿拉伯语及其方言的真实和反事实陈述。提出CounterFactual Hallucination Rate (CFHR)指标，衡量在正确回答真实陈述条件下接受反事实陈述的比例。评估多个最先进视觉语言模型在不同提示策略下的表现。

Result: 在阿拉伯语尤其是方言中，CFHR显著上升，即使真实陈述准确率保持较高水平。推理优先的提示策略会持续增加反事实幻觉，而先回答后解释的提示策略能提高鲁棒性。

Conclusion: 视觉语言模型存在显著的文化幻觉问题，特别是在非英语和方言环境中。需要开发更鲁棒的评估方法和模型改进策略来应对这一问题。作者将公开实验资源和数据集供社区使用。

Abstract: Vision-language models (VLMs) can achieve high accuracy while still accepting culturally plausible but visually incorrect interpretations. Existing hallucination benchmarks rarely test this failure mode, particularly outside Western contexts and English. We introduce M2CQA, a culturally grounded multimodal benchmark built from images spanning 17 MENA countries, paired with contrastive true and counterfactual statements in English, Arabic, and its dialects. To isolate hallucination beyond raw accuracy, we propose the CounterFactual Hallucination Rate (CFHR), which measures counterfactual acceptance conditioned on correctly answering the true statement. Evaluating state-of-the-art VLMs under multiple prompting strategies, we find that CFHR rises sharply in Arabic, especially in dialects, even when true-statement accuracy remains high. Moreover, reasoning-first prompting consistently increases counterfactual hallucination, while answering before justifying improves robustness. We will make the experimental resources and dataset publicly available for the community.

</details>


### [30] [Causal Front-Door Adjustment for Robust Jailbreak Attacks on LLMs](https://arxiv.org/abs/2602.05444)
*Yao Zhou,Zeen Song,Wenwen Qiang,Fengge Wu,Shuyi Zhou,Changwen Zheng,Hui Xiong*

Main category: cs.CL

TL;DR: CFA²：基于因果前门准则的LLM越狱攻击框架，通过稀疏自编码器剥离安全防御特征，实现高效越狱


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的安全对齐机制通常作为潜在内部状态运行，这掩盖了模型的固有能力。从因果视角来看，安全机制可视为未观测的混杂因子，限制了模型的原始功能表达。

Method: 将安全机制建模为未观测混杂因子，提出基于Pearl前门准则的因果前门调整攻击框架。使用稀疏自编码器物理剥离防御相关特征，分离核心任务意图。将计算昂贵的边际化简化为低推理复杂度的确定性干预。

Result: 实验表明CFA²实现了最先进的攻击成功率，同时为越狱过程提供了机制性解释，在保持高效推理的同时有效绕过安全防御。

Conclusion: 该研究从因果角度形式化了LLM安全机制，提出的CFA²框架不仅实现了高效越狱，还提供了对安全对齐机制的可解释性分析，有助于理解防御机制的内部工作方式。

Abstract: Safety alignment mechanisms in Large Language Models (LLMs) often operate as latent internal states, obscuring the model's inherent capabilities. Building on this observation, we model the safety mechanism as an unobserved confounder from a causal perspective. Then, we propose the \textbf{C}ausal \textbf{F}ront-Door \textbf{A}djustment \textbf{A}ttack ({\textbf{CFA}}$^2$) to jailbreak LLM, which is a framework that leverages Pearl's Front-Door Criterion to sever the confounding associations for robust jailbreaking. Specifically, we employ Sparse Autoencoders (SAEs) to physically strip defense-related features, isolating the core task intent. We further reduce computationally expensive marginalization to a deterministic intervention with low inference complexity. Experiments demonstrate that {CFA}$^2$ achieves state-of-the-art attack success rates while offering a mechanistic interpretation of the jailbreaking process.

</details>


### [31] [Structured Context Engineering for File-Native Agentic Systems: Evaluating Schema Accuracy, Format Effectiveness, and Multi-File Navigation at Scale](https://arxiv.org/abs/2602.05447)
*Damon McMillan*

Main category: cs.CL

TL;DR: 通过大规模SQL生成实验研究LLM代理的上下文工程，发现模型能力是主导因素，架构选择应基于具体模型而非通用最佳实践


<details>
  <summary>Details</summary>
Motivation: LLM代理通过编程接口操作外部系统时，从业者缺乏关于如何构建代理消费上下文的实证指导。需要系统研究结构化数据的上下文工程。

Method: 使用SQL生成作为编程代理操作的代理任务，进行了9,649次实验，涵盖11个模型、4种格式（YAML、Markdown、JSON、TOON）和10到10,000个表的模式。

Result: 1) 架构选择依赖模型：文件式上下文检索对前沿模型（Claude、GPT、Gemini）提升准确率（+2.7%），但对开源模型整体降低（-7.7%）；2) 格式对整体准确率无显著影响，但开源模型对特定格式敏感；3) 模型能力是主导因素，前沿与开源模型准确率差距达21个百分点；4) 文件原生代理通过领域分区模式可扩展到10,000个表；5) 文件大小不能预测运行时效率，紧凑格式可能因搜索模式消耗更多token。

Conclusion: 部署LLM代理于结构化系统时，架构决策应根据模型能力定制，而非假设通用最佳实践。模型能力是影响性能的主要因素。

Abstract: Large Language Model agents increasingly operate external systems through programmatic interfaces, yet practitioners lack empirical guidance on how to structure the context these agents consume. Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of context engineering for structured data, comprising 9,649 experiments across 11 models, 4 formats (YAML, Markdown, JSON, Token-Oriented Object Notation [TOON]), and schemas ranging from 10 to 10,000 tables.
  Our findings challenge common assumptions. First, architecture choice is model-dependent: file-based context retrieval improves accuracy for frontier-tier models (Claude, GPT, Gemini; +2.7%, p=0.029) but shows mixed results for open source models (aggregate -7.7%, p<0.001), with deficits varying substantially by model. Second, format does not significantly affect aggregate accuracy (chi-squared=2.45, p=0.484), though individual models, particularly open source, exhibit format-specific sensitivities. Third, model capability is the dominant factor, with a 21 percentage point accuracy gap between frontier and open source tiers that dwarfs any format or architecture effect. Fourth, file-native agents scale to 10,000 tables through domain-partitioned schemas while maintaining high navigation accuracy. Fifth, file size does not predict runtime efficiency: compact formats can consume significantly more tokens at scale due to format-unfamiliar search patterns.
  These findings provide practitioners with evidence-based guidance for deploying LLM agents on structured systems, demonstrating that architectural decisions should be tailored to model capability rather than assuming universal best practices.

</details>


### [32] [Reasoning under Ambiguity: Uncertainty-Aware Multilingual Emotion Classification under Partial Supervision](https://arxiv.org/abs/2602.05471)
*Md. Mithun Hossaina,Mashary N. Alrasheedy,Nirban Bhowmick,Shamim Forhad,Md. Shakil Hossain,Sudipto Chaki,Md Shafiqul Islam*

Main category: cs.CL

TL;DR: 提出不确定性感知框架RA，用于多语言多标签情感分类，通过熵基模糊加权和掩码感知目标处理情感模糊性和不完整监督问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于知识的多语言情感识别系统面临情感模糊性和不完整监督的挑战。文本情感识别本质不确定，多种情感状态常共存且标注常缺失或异构。现有方法假设完全观察标签，依赖确定性学习目标，在部分监督下易导致偏差学习和不可靠预测。

Method: 提出RA框架：使用共享多语言编码器与语言特定优化；引入熵基模糊加权机制，降低高模糊训练实例权重而非将缺失标签视为负证据；结合掩码感知目标与正未标注正则化，实现部分监督下的鲁棒学习。

Result: 在英语、西班牙语和阿拉伯语情感分类基准测试中，相比强基线在多个评估指标上均取得一致改进，同时提升了训练稳定性、对标注稀疏性的鲁棒性以及可解释性。

Conclusion: RA框架通过显式对齐学习与标注不确定性，有效解决了多语言多标签情感分类中的情感模糊性和不完整监督问题，为不确定性感知的情感识别提供了实用解决方案。

Abstract: Contemporary knowledge-based systems increasingly rely on multilingual emotion identification to support intelligent decision-making, yet they face major challenges due to emotional ambiguity and incomplete supervision. Emotion recognition from text is inherently uncertain because multiple emotional states often co-occur and emotion annotations are frequently missing or heterogeneous. Most existing multi-label emotion classification methods assume fully observed labels and rely on deterministic learning objectives, which can lead to biased learning and unreliable predictions under partial supervision. This paper introduces Reasoning under Ambiguity, an uncertainty-aware framework for multilingual multi-label emotion classification that explicitly aligns learning with annotation uncertainty. The proposed approach uses a shared multilingual encoder with language-specific optimization and an entropy-based ambiguity weighting mechanism that down-weights highly ambiguous training instances rather than treating missing labels as negative evidence. A mask-aware objective with positive-unlabeled regularization is further incorporated to enable robust learning under partial supervision. Experiments on English, Spanish, and Arabic emotion classification benchmarks demonstrate consistent improvements over strong baselines across multiple evaluation metrics, along with improved training stability, robustness to annotation sparsity, and enhanced interpretability.

</details>


### [33] [LinguistAgent: A Reflective Multi-Model Platform for Automated Linguistic Annotation](https://arxiv.org/abs/2602.05493)
*Bingru Li*

Main category: cs.CL

TL;DR: LinguistAgent是一个用于人文社科领域复杂语义标注任务的集成平台，采用反思性多模型架构，通过双代理工作流（标注者和审阅者）实现自动化标注，特别以隐喻识别为例展示其有效性。


<details>
  <summary>Details</summary>
Motivation: 人文社科领域的数据标注（特别是复杂语义任务如隐喻识别）存在显著瓶颈。虽然大语言模型有潜力，但其理论能力与实际研究效用之间存在差距。

Method: 1. 开发LinguistAgent集成平台，采用反思性多模型架构
2. 实现双代理工作流：标注者(Annotator)和审阅者(Reviewer)，模拟专业同行评审过程
3. 支持三种范式比较实验：提示工程（零样本/少样本）、检索增强生成、微调
4. 以隐喻识别为例，提供实时token级评估（精确率、召回率、F1分数）对比人工黄金标准

Result: 展示了LinguistAgent在隐喻识别任务中的有效性，平台和代码已在GitHub发布（https://github.com/Bingru-Li/LinguistAgent）。

Conclusion: LinguistAgent提供了一个用户友好的集成平台，通过自动化标注解决人文社科研究中的标注瓶颈问题，将大语言模型的理论潜力转化为实际研究工具。

Abstract: Data annotation remains a significant bottleneck in the Humanities and Social Sciences, particularly for complex semantic tasks such as metaphor identification. While Large Language Models (LLMs) show promise, a significant gap remains between the theoretical capability of LLMs and their practical utility for researchers. This paper introduces LinguistAgent, an integrated, user-friendly platform that leverages a reflective multi-model architecture to automate linguistic annotation. The system implements a dual-agent workflow, comprising an Annotator and a Reviewer, to simulate a professional peer-review process. LinguistAgent supports comparative experiments across three paradigms: Prompt Engineering (Zero/Few-shot), Retrieval-Augmented Generation, and Fine-tuning. We demonstrate LinguistAgent's efficacy using the task of metaphor identification as an example, providing real-time token-level evaluation (Precision, Recall, and $F_1$ score) against human gold standards. The application and codes are released on https://github.com/Bingru-Li/LinguistAgent.

</details>


### [34] [Transport and Merge: Cross-Architecture Merging for Large Language Models](https://arxiv.org/abs/2602.05495)
*Chenhang Cui,Binyun Yang,Fei Shen,Yuxin Chen,Jingnan Zheng,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 提出基于最优传输的跨架构模型合并框架，实现大型高资源LLM向异构小模型的权重空间知识迁移


<details>
  <summary>Details</summary>
Motivation: 现实部署常依赖小模型或低资源数据训练，但大模型在能力上更强，需要将大模型知识迁移到异构小模型的机制

Method: 基于最优传输(OT)的跨架构合并框架：通过对齐激活推断跨神经元对应关系，利用传输计划指导权重空间融合

Result: 在低资源语言和专门领域的广泛实验中，相比目标模型获得一致改进

Conclusion: 该框架能有效实现高资源到低资源的跨架构知识迁移，仅需少量输入数据

Abstract: Large language models (LLMs) achieve strong capabilities by scaling model capacity and training data, yet many real-world deployments rely on smaller models trained or adapted from low-resource data. This gap motivates the need for mechanisms to transfer knowledge from large, high-resource models to smaller, low-resource targets. While model merging provides an effective transfer mechanism, most existing approaches assume architecture-compatible models and therefore cannot directly transfer knowledge from large high-resource LLMs to heterogeneous low-resource targets. In this work, we propose a cross-architecture merging framework based on optimal transport (OT) that aligns activations to infer cross-neuron correspondences between heterogeneous models. The resulting transport plans are then used to guide direct weight-space fusion, enabling effective high-resource to low-resource transfer using only a small set of inputs. Extensive experiments across low-resource languages and specialized domains demonstrate consistent improvements over target models.

</details>


### [35] [Multi-Task GRPO: Reliable LLM Reasoning Across Tasks](https://arxiv.org/abs/2602.05547)
*Shyam Sundhar Ramesh,Xiaotong Ji,Matthieu Zimmer,Sangwoong Yoon,Zhiyong Wang,Haitham Bou Ammar,Aurelien Lucchi,Ilija Bogunovic*

Main category: cs.CL

TL;DR: 提出了MT-GRPO算法，通过动态任务权重调整和比率保持采样器，在多任务强化学习后训练中平衡各任务表现，显著提升最差任务性能。


<details>
  <summary>Details</summary>
Motivation: 现实部署需要语言模型在多样化任务上保持可靠性能。标准的GRPO多任务适应方法会导致不平衡结果，某些任务主导优化而其他任务停滞不前。此外，不同任务中提示产生零优势（零梯度）的频率差异很大，进一步扭曲了优化信号的有效贡献。

Method: 提出了多任务GRPO（MT-GRPO）算法，包含两个关键技术：(1) 动态调整任务权重，显式优化最差任务性能并促进各任务平衡进展；(2) 引入比率保持采样器，确保任务级策略梯度反映调整后的权重。

Result: 在3任务和9任务设置中，MT-GRPO始终优于基线方法的最差任务准确率。相比标准GRPO和DAPO，在最差任务性能上分别获得16-28%和6%的绝对提升，同时保持竞争力的平均准确率。在3任务设置中，达到50%最差任务准确率所需的训练步骤减少50%，效率显著提升。

Conclusion: MT-GRPO算法有效解决了多任务强化学习后训练中的不平衡问题，通过动态权重调整和采样策略改进，实现了跨任务的可靠性能平衡，为实际部署提供了更稳健的解决方案。

Abstract: RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal. To address these issues, we propose a novel Multi-Task GRPO (MT-GRPO) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT-GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT-GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT-GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks.

</details>


### [36] [CASTLE: A Comprehensive Benchmark for Evaluating Student-Tailored Personalized Safety in Large Language Models](https://arxiv.org/abs/2602.05633)
*Rui Jia,Ruiyi Lan,Fengrui Liu,Zhongxiang Dai,Bo Jiang,Jing Shao,Jingyuan Chen,Guandong Xu,Fei Wu,Min Zhang*

Main category: cs.CL

TL;DR: CASTLE是一个基于教育理论构建的学生个性化安全基准，涵盖15种教育安全风险和14种学生属性，包含92,908个双语场景，用于评估LLM在个性化学习中的安全性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在个性化教育中存在安全隐患，其固有的生成机制对相同提示产生同质化响应，忽视了学生在认知和心理方面的异质性。现有安全评估主要依赖事实准确性、偏见或毒性等与上下文无关的指标，无法捕捉相同响应对不同学生属性可能造成的不同危害。

Method: 提出"学生定制化个性化安全"概念，构建CASTLE基准，涵盖15种教育安全风险和14种学生属性，包含92,908个双语场景。设计三个评估指标：风险敏感性（检测风险能力）、情感共情（识别学生状态能力）和学生对齐（响应与学生属性匹配度）。

Result: 对18个最先进的LLM进行实验，所有模型平均安全评分低于2.3分（满分5分），表明在个性化安全保障方面存在显著不足。

Conclusion: CASTLE基准揭示了当前LLM在个性化教育安全方面的严重缺陷，强调需要开发能够考虑学生异质性的更安全、更个性化的教育AI系统。

Abstract: Large language models (LLMs) have advanced the development of personalized learning in education. However, their inherent generation mechanisms often produce homogeneous responses to identical prompts. This one-size-fits-all mechanism overlooks the substantial heterogeneity in students cognitive and psychological, thereby posing potential safety risks to vulnerable groups. Existing safety evaluations primarily rely on context-independent metrics such as factual accuracy, bias, or toxicity, which fail to capture the divergent harms that the same response might cause across different student attributes. To address this gap, we propose the concept of Student-Tailored Personalized Safety and construct CASTLE based on educational theories. This benchmark covers 15 educational safety risks and 14 student attributes, comprising 92,908 bilingual scenarios. We further design three evaluation metrics: Risk Sensitivity, measuring the model ability to detect risks; Emotional Empathy, evaluating the model capacity to recognize student states; and Student Alignment, assessing the match between model responses and student attributes. Experiments on 18 SOTA LLMs demonstrate that CASTLE poses a significant challenge: all models scored below an average safety rating of 2.3 out of 5, indicating substantial deficiencies in personalized safety assurance.

</details>


### [37] [Modelling the Morphology of Verbal Paradigms: A Case Study in the Tokenization of Turkish and Hebrew](https://arxiv.org/abs/2602.05648)
*Giuseppe Samo,Paola Merlo*

Main category: cs.CL

TL;DR: 研究Transformer模型如何表示土耳其语和现代希伯来语的复杂动词范式，重点关注分词策略如何影响这种能力


<details>
  <summary>Details</summary>
Motivation: 探索不同分词策略如何影响Transformer模型对具有不同形态特征的语言（土耳其语的透明形态标记vs希伯来语的非连接性形态）的动词范式表示能力

Method: 使用Blackbird Language Matrices任务在自然数据上进行实验，比较单语和多语模型在不同分词策略（原子分词、子词分词、字符级分词、词素感知分词）下的表现

Result: 对于土耳其语，单语和多语模型在原子分词或细粒度子词分词下都能成功；对于希伯来语，使用字符级分词的多语模型无法捕捉非连接性形态，但使用词素感知分词的单语模型表现良好；所有模型在更合成化的数据集上表现都有提升

Conclusion: 分词策略对Transformer模型表示复杂动词范式的能力有显著影响，特别是对于具有非连接性形态的语言（如希伯来语），需要专门的分词方法（如词素感知分词）才能获得良好表现

Abstract: We investigate how transformer models represent complex verb paradigms in Turkish and Modern Hebrew, concentrating on how tokenization strategies shape this ability. Using the Blackbird Language Matrices task on natural data, we show that for Turkish -- with its transparent morphological markers -- both monolingual and multilingual models succeed, either when tokenization is atomic or when it breaks words into small subword units. For Hebrew, instead, monolingual and multilingual models diverge. A multilingual model using character-level tokenization fails to capture the language non-concatenative morphology, but a monolingual model with morpheme-aware segmentation performs well. Performance improves on more synthetic datasets, in all models.

</details>


### [38] [MedErrBench: A Fine-Grained Multilingual Benchmark for Medical Error Detection and Correction with Clinical Expert Annotations](https://arxiv.org/abs/2602.05692)
*Congbo Ma,Yichun Zhang,Yousef Al-Jazzazi,Ahamed Foisal,Laasya Sharma,Yousra Sadqi,Khaled Saleh,Jihad Mallat,Farah E. Shamout*

Main category: cs.CL

TL;DR: MedErrBench是首个多语言临床文本错误检测、定位和纠正的基准数据集，涵盖英语、阿拉伯语和中文，由临床专家标注，用于评估LLM在医疗场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的临床文本可能存在不准确信息，可能导致误诊或错误治疗建议。随着LLM在医疗应用中的普及，需要专门的基准来全面评估其性能，但目前缺乏跨语言和跨环境的此类数据集。

Method: 基于扩展的十种常见错误类型分类法，构建了涵盖英语、阿拉伯语和中文的MedErrBench数据集，包含真实临床案例并由领域专家标注和审查。评估了通用、语言特定和医疗领域语言模型在三个任务上的表现。

Result: 评估结果显示存在显著的性能差距，特别是在非英语环境下，突显了需要基于临床知识和语言感知的系统。模型在错误检测、定位和纠正任务上的表现有待提升。

Conclusion: MedErrBench的公开将推动多语言临床NLP的发展，促进全球更安全、更公平的AI医疗应用。数据集和评估协议已公开提供。

Abstract: Inaccuracies in existing or generated clinical text may lead to serious adverse consequences, especially if it is a misdiagnosis or incorrect treatment suggestion. With Large Language Models (LLMs) increasingly being used across diverse healthcare applications, comprehensive evaluation through dedicated benchmarks is crucial. However, such datasets remain scarce, especially across diverse languages and contexts. In this paper, we introduce MedErrBench, the first multilingual benchmark for error detection, localization, and correction, developed under the guidance of experienced clinicians. Based on an expanded taxonomy of ten common error types, MedErrBench covers English, Arabic and Chinese, with natural clinical cases annotated and reviewed by domain experts. We assessed the performance of a range of general-purpose, language-specific, and medical-domain language models across all three tasks. Our results reveal notable performance gaps, particularly in non-English settings, highlighting the need for clinically grounded, language-aware systems. By making MedErrBench and our evaluation protocols publicly-available, we aim to advance multilingual clinical NLP to promote safer and more equitable AI-based healthcare globally. The dataset is available in the supplementary material. An anonymized version of the dataset is available at: https://github.com/congboma/MedErrBench.

</details>


### [39] [Consensus-Aligned Neuron Efficient Fine-Tuning Large Language Models for Multi-Domain Machine Translation](https://arxiv.org/abs/2602.05694)
*Shuting Jiang,Ran Song,Yuxin Huang,Yan Xiang,Yantuan Xian,Shengxiang Gao,Zhengtao Yu*

Main category: cs.CL

TL;DR: 提出一种基于共识对齐神经元的高效微调框架，用于多领域机器翻译，通过最大化神经元行为与领域特征的互信息来选择关键神经元，有效缓解参数干扰和领域过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在机器翻译方面表现出色，但在多领域适应方面仍面临挑战。现有方法如上下文学习和参数高效微调存在领域偏移、参数干扰和泛化能力有限的问题。

Method: 提出神经元高效微调框架，通过最大化神经元行为与领域特征的互信息来识别和更新共识对齐神经元，这些神经元能够捕捉通用翻译模式和领域特定特征，然后基于这些神经元指导微调过程。

Result: 在三个大型语言模型和十个德英、中英翻译领域上的全面实验表明，该方法在已见和未见领域上均优于强参数高效微调基线，达到了最先进的性能。

Conclusion: 通过识别和微调共识对齐神经元的方法，有效解决了多领域机器翻译中的参数干扰和领域过拟合问题，为大型语言模型的领域适应提供了有效解决方案。

Abstract: Multi-domain machine translation (MDMT) aims to build a unified model capable of translating content across diverse domains. Despite the impressive machine translation capabilities demonstrated by large language models (LLMs), domain adaptation still remains a challenge for LLMs. Existing MDMT methods such as in-context learning and parameter-efficient fine-tuning often suffer from domain shift, parameter interference and limited generalization. In this work, we propose a neuron-efficient fine-tuning framework for MDMT that identifies and updates consensus-aligned neurons within LLMs. These neurons are selected by maximizing the mutual information between neuron behavior and domain features, enabling LLMs to capture both generalizable translation patterns and domain-specific nuances. Our method then fine-tunes LLMs guided by these neurons, effectively mitigating parameter interference and domain-specific overfitting. Comprehensive experiments on three LLMs across ten German-English and Chinese-English translation domains evidence that our method consistently outperforms strong PEFT baselines on both seen and unseen domains, achieving state-of-the-art performance.

</details>


### [40] [OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale](https://arxiv.org/abs/2602.05711)
*Jingze Shi,Zhangyang Peng,Yizhang Zhu,Yifan Wu,Guang Liu,Yuyu Luo*

Main category: cs.CL

TL;DR: OmniMoE是一个系统算法协同设计的框架，通过向量级别的原子专家和创新的路由调度机制，在保持高准确率的同时显著提升了细粒度MoE的推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的混合专家架构在专家粒度与硬件执行效率之间存在固有权衡。粗粒度专家限制了参数效率，而细粒度专家则面临路由复杂度和内存访问的挑战。

Method: 提出OmniMoE框架，包含：1) 向量级别的原子专家实现极致细粒度；2) 笛卡尔积路由器将路由复杂度从O(N)降至O(sqrt(N))；3) 专家中心调度将分散的内存访问转为密集矩阵运算。

Result: 在7个基准测试中，OmniMoE（17亿激活参数）达到50.9%的零样本准确率，优于粗粒度和细粒度基线。推理延迟从73ms降至6.7ms，实现10.9倍加速。

Conclusion: OmniMoE证明了大规模细粒度MoE可以同时实现高准确率和快速推理，通过系统算法协同设计解决了细粒度MoE的效率瓶颈问题。

Abstract: Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-designed framework that pushes expert granularity to its logical extreme. OmniMoE introduces vector-level Atomic Experts, enabling scalable routing and execution within a single MoE layer, while retaining a shared dense MLP branch for general-purpose processing. Although this atomic design maximizes capacity, it poses severe challenges for routing complexity and memory access. To address these, OmniMoE adopts a system-algorithm co-design: (i) a Cartesian Product Router that decomposes the massive index space to reduce routing complexity from O(N) to O(sqrt(N)); and (ii) Expert-Centric Scheduling that inverts the execution order to turn scattered, memory-bound lookups into efficient dense matrix operations. Validated on seven benchmarks, OmniMoE (with 1.7B active parameters) achieves 50.9% zero-shot accuracy across seven benchmarks, outperforming coarse-grained (e.g., DeepSeekMoE) and fine-grained (e.g., PEER) baselines. Crucially, OmniMoE reduces inference latency from 73ms to 6.7ms (a 10.9-fold speedup) compared to PEER, demonstrating that massive-scale fine-grained MoE can be fast and accurate. Our code is open-sourced at https://github.com/flash-algo/omni-moe.

</details>


### [41] [CompactRAG: Reducing LLM Calls and Token Overhead in Multi-Hop Question Answering](https://arxiv.org/abs/2602.05728)
*Hao Yang,Zhiyu Yang,Xupeng Zhang,Wei Wei,Yunjie Zhang,Lin Yang*

Main category: cs.CL

TL;DR: CompactRAG 是一个高效的检索增强生成框架，通过离线知识库重构和在线轻量推理，显著减少多跳问答中的LLM调用次数和token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的多跳RAG系统效率低下，需要在每个推理步骤中交替进行检索和推理，导致重复的LLM调用、高token消耗以及跨跳实体定位不稳定。

Method: 1. 离线阶段：LLM一次性读取语料库，将其转换为原子QA知识库，将知识表示为最小、细粒度的问答对。
2. 在线阶段：将复杂查询分解并重写以保持实体一致性，通过密集检索和RoBERTa答案提取解决问题。整个推理过程LLM只调用两次（子问题分解和最终答案合成）。

Result: 在HotpotQA、2WikiMultiHopQA和MuSiQue数据集上的实验表明，CompactRAG在保持竞争力的准确率的同时，相比迭代式RAG基线显著减少了token消耗。

Conclusion: CompactRAG提供了一种成本效益高且实用的多跳推理方法，通过解耦离线语料重构和在线推理，实现了高效的知识密集型问答。

Abstract: Retrieval-augmented generation (RAG) has become a key paradigm for knowledge-intensive question answering. However, existing multi-hop RAG systems remain inefficient, as they alternate between retrieval and reasoning at each step, resulting in repeated LLM calls, high token consumption, and unstable entity grounding across hops. We propose CompactRAG, a simple yet effective framework that decouples offline corpus restructuring from online reasoning.
  In the offline stage, an LLM reads the corpus once and converts it into an atomic QA knowledge base, which represents knowledge as minimal, fine-grained question-answer pairs. In the online stage, complex queries are decomposed and carefully rewritten to preserve entity consistency, and are resolved through dense retrieval followed by RoBERTa-based answer extraction. Notably, during inference, the LLM is invoked only twice in total - once for sub-question decomposition and once for final answer synthesis - regardless of the number of reasoning hops.
  Experiments on HotpotQA, 2WikiMultiHopQA, and MuSiQue demonstrate that CompactRAG achieves competitive accuracy while substantially reducing token consumption compared to iterative RAG baselines, highlighting a cost-efficient and practical approach to multi-hop reasoning over large knowledge corpora. The implementation is available at GitHub.

</details>


### [42] [LongR: Unleashing Long-Context Reasoning via Reinforcement Learning with Dense Utility Rewards](https://arxiv.org/abs/2602.05758)
*Bowen Ping,Zijun Chen,Yiyao Yu,Tingfeng Hui,Junchi Yan,Baobao Chang*

Main category: cs.CL

TL;DR: LongR是一个通过动态"思考与阅读"机制和基于相对信息增益的上下文密度奖励来增强大语言模型长上下文推理能力的强化学习框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注数据合成或架构修改，但仅依赖稀疏的、仅基于结果的奖励在长上下文推理中效果有限，因为这种粗略信号不足以有效指导复杂的推理过程。

Method: 提出LongR框架，包含两个核心组件：1）动态"思考与阅读"机制，交替进行推理和文档查阅；2）基于相对信息增益的上下文密度奖励，用于量化相关文档的效用。

Result: 在LongBench v2上获得9%的性能提升，在RULER和InfiniteBench上也有一致的改进，同时在不同强化学习算法（如DAPO、GSPO）上都能增强性能。

Conclusion: LongR通过结合动态推理-阅读机制和细粒度奖励设计，有效提升了LLM在长上下文场景下的推理能力，并展现出对干扰信息的鲁棒性。

Abstract: Reinforcement Learning has emerged as a key driver for LLM reasoning. This capability is equally pivotal in long-context scenarios--such as long-dialogue understanding and structured data analysis, where the challenge extends beyond consuming tokens to performing rigorous deduction. While existing efforts focus on data synthesis or architectural changes, recent work points out that relying solely on sparse, outcome-only rewards yields limited gains, as such coarse signals are often insufficient to effectively guide the complex long-context reasoning. To address this, we propose LongR, a unified framework that enhances long-context performance by integrating a dynamic "Think-and-Read" mechanism, which interleaves reasoning with document consultation, with a contextual density reward based on relative information gain to quantify the utility of the relevant documents. Empirically, LongR achieves a 9% gain on LongBench v2 and consistent improvements on RULER and InfiniteBench, demonstrating robust efficiency in navigating extensive contexts. Furthermore, LongR consistently enhances performance across diverse RL algorithms (e.g., DAPO, GSPO). Finally, we conduct in-depth analyses to investigate the impact of reasoning chain length on efficiency and the model's robustness against distractors.

</details>


### [43] [Different Time, Different Language: Revisiting the Bias Against Non-Native Speakers in GPT Detectors](https://arxiv.org/abs/2602.05769)
*Adnan Al Ali,Jindřich Helcl,Jindřich Libovický*

Main category: cs.CL

TL;DR: 两年后对捷克语环境中LLM生成文本检测器的重新评估表明，非母语者文本的困惑度并不低于母语者，检测器没有系统性偏见，且现代检测器无需依赖困惑度也能有效工作。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等LLM助手的普及，学术界担忧其被滥用，但现有检测方法常因非母语者文本困惑度较低而错误标记为生成文本。本研究旨在重新评估这些说法在捷克语环境中的有效性。

Method: 研究重新评估了非母语者与母语者捷克语文本的困惑度差异，并测试了来自三个不同家族的检测器在捷克语环境中的表现，分析它们对非母语者的系统性偏见问题。

Result: 1. 非母语者的捷克语文本困惑度并不低于母语者；2. 三种检测器均未表现出对非母语者的系统性偏见；3. 当代检测器无需依赖困惑度也能有效运作。

Conclusion: 与先前研究相反，在捷克语环境中，非母语者文本并没有较低的困惑度，检测器也没有对非母语者的系统性偏见。现代检测器已经发展到不依赖困惑度也能有效工作的程度。

Abstract: LLM-based assistants have been widely popularised after the release of ChatGPT. Concerns have been raised about their misuse in academia, given the difficulty of distinguishing between human-written and generated text. To combat this, automated techniques have been developed and shown to be effective, to some extent. However, prior work suggests that these methods often falsely flag essays from non-native speakers as generated, due to their low perplexity extracted from an LLM, which is supposedly a key feature of the detectors. We revisit these statements two years later, specifically in the Czech language setting. We show that the perplexity of texts from non-native speakers of Czech is not lower than that of native speakers. We further examine detectors from three separate families and find no systematic bias against non-native speakers. Finally, we demonstrate that contemporary detectors operate effectively without relying on perplexity.

</details>


### [44] [Reinforcement World Model Learning for LLM-based Agents](https://arxiv.org/abs/2602.05842)
*Xiao Yu,Baolin Peng,Ruize Xu,Yelong Shen,Pengcheng He,Suman Nath,Nikhil Singh,Jiangfeng Gao,Zhou Yu*

Main category: cs.CL

TL;DR: RWML是一种自监督学习方法，通过训练LLM智能体学习动作条件的世界模型，利用模拟到现实的差距奖励来对齐模型预测状态与环境实际状态，提升智能体在文本环境中的世界建模能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在智能体任务中难以预测动作后果和适应环境动态，需要更强的世界建模能力。现有方法如下一个状态token预测过于关注词汇层面而忽视语义等价性，容易导致模型崩溃。

Method: 提出RWML方法，在预训练嵌入空间中对齐模型生成的模拟下一个状态与环境观察到的实际下一个状态，使用模拟到现实的差距奖励进行自监督学习。相比下一个状态token预测，该方法提供更鲁棒的训练信号，不易受奖励攻击影响。

Result: 在ALFWorld和τ² Bench上的实验显示，RWML相比基础模型有显著提升。与任务成功奖励结合时，在ALFWorld和τ² Bench上分别比直接任务成功奖励RL高出6.9和5.7分，性能与专家数据训练相当。

Conclusion: RWML通过自监督世界模型学习有效提升了LLM智能体的世界建模能力，在不需要外部监督的情况下实现了与专家数据训练相当的性能，为LLM智能体的世界建模提供了新思路。

Abstract: Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and $τ^2$ Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and $τ^2$ Bench respectively, while matching the performance of expert-data training.

</details>


### [45] [OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions](https://arxiv.org/abs/2602.05843)
*Fangzhi Xu,Hang Yan,Qiushi Sun,Jinyang Wu,Zixian Huang,Muye Huang,Jingyang Gong,Zichen Ding,Kanzhi Cheng,Yian Wang,Xinyu Che,Zeyi Sun,Jian Zhang,Zhangyue Yin,Haoran Luo,Xuanjing Huang,Ben Kao,Jun Liu,Qika Lin*

Main category: cs.CL

TL;DR: 本文介绍了OdysseyArena，一个用于评估AI智能体在长时程、主动归纳式交互中表现的新框架，旨在解决现有评估方法忽视智能体从经验中自主发现潜在转移规律的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型智能体评估主要采用演绎范式，基于明确提供的规则和静态目标进行任务执行，通常局限于有限的规划视野。这忽视了智能体从经验中自主发现潜在转移规律的归纳需求，而这是实现智能体前瞻性和维持战略连贯性的关键。

Method: 提出了OdysseyArena框架，将抽象的转移动态形式化并实例化为四个基本原语，转化为具体的交互环境。在此基础上建立了OdysseyArena-Lite用于标准化基准测试，包含120个任务来测量智能体的归纳效率和长时程发现能力。进一步推出了OdysseyArena-Challenge来压力测试智能体在极端交互时域（如超过200步）下的稳定性。

Result: 对15个以上领先的大语言模型进行了广泛实验，结果显示即使是前沿模型在归纳场景中也存在不足，揭示了在复杂环境中追求自主发现的关键瓶颈。

Conclusion: OdysseyArena重新将智能体评估中心放在长时程、主动和归纳式交互上，填补了现有评估方法的空白，并为评估智能体在复杂环境中的自主发现能力提供了新的标准。

Abstract: The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena

</details>


### [46] [RRAttention: Dynamic Block Sparse Attention via Per-Head Round-Robin Shifts for Long-Context Inference](https://arxiv.org/abs/2602.05853)
*Siran Liu,Guoxia Wang,Sa Wang,Jinle Zeng,HaoYang Xie,Siyu Lou,JiaBin Yang,DianHai Yu,Haifeng Wang,Chao Yang*

Main category: cs.CL

TL;DR: RRAttention 是一种基于轮询采样的动态稀疏注意力方法，通过跨注意力头的轮询采样策略，在保持查询独立性的同时实现高效全局模式发现，将复杂度从 O(L²) 降低到 O(L²/S²)，恢复超过99%的完整注意力性能。


<details>
  <summary>Details</summary>
Motivation: 注意力机制二次复杂度是处理长上下文大语言模型的关键瓶颈。现有动态稀疏注意力方法面临基本权衡：需要预处理、缺乏全局评估、违反查询独立性或计算开销高。

Method: 提出RRAttention方法，采用头部轮询采样策略，在每个步幅内跨注意力头轮询查询采样位置，保持查询独立性同时实现步幅级聚合的高效全局模式发现。将复杂度从O(L²)降至O(L²/S²)，并采用自适应Top-τ选择实现最优稀疏性。

Result: 在自然语言理解（HELMET）和多模态视频理解（Video-MME）上的实验表明，RRAttention仅计算一半注意力块就能恢复超过99%的完整注意力性能，在128K上下文长度下实现2.4倍加速，优于现有动态稀疏注意力方法。

Conclusion: RRAttention通过轮询采样策略同时实现了动态稀疏注意力的所有理想特性，为处理长上下文提供了高效解决方案，在保持查询独立性的同时实现了显著的性能恢复和计算效率提升。

Abstract: The quadratic complexity of attention mechanisms poses a critical bottleneck for large language models processing long contexts. While dynamic sparse attention methods offer input-adaptive efficiency, they face fundamental trade-offs: requiring preprocessing, lacking global evaluation, violating query independence, or incurring high computational overhead. We present RRAttention, a novel dynamic sparse attention method that simultaneously achieves all desirable properties through a head \underline{r}ound-\underline{r}obin (RR) sampling strategy. By rotating query sampling positions across attention heads within each stride, RRAttention maintains query independence while enabling efficient global pattern discovery with stride-level aggregation. Our method reduces complexity from $O(L^2)$ to $O(L^2/S^2)$ and employs adaptive Top-$τ$ selection for optimal sparsity. Extensive experiments on natural language understanding (HELMET) and multimodal video comprehension (Video-MME) demonstrate that RRAttention recovers over 99\% of full attention performance while computing only half of the attention blocks, achieving 2.4$\times$ speedup at 128K context length and outperforming existing dynamic sparse attention methods.

</details>


### [47] [xList-Hate: A Checklist-Based Framework for Interpretable and Generalizable Hate Speech Detection](https://arxiv.org/abs/2602.05874)
*Adrián Girón,Pablo Miralles,Javier Huertas-Tato,Sergio D'Antonio,David Camacho*

Main category: cs.CL

TL;DR: 提出xList-Hate框架，将仇恨言论检测分解为基于规范标准的诊断问题清单，通过LLM回答清单问题，再用决策树聚合结果，提高跨数据集鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测通常被简化为二元分类问题，导致模型过度拟合特定数据集的定义，在领域转移和标注噪声下鲁棒性有限。需要一种更稳健、可解释的方法来处理这一复杂概念。

Method: 引入xList-Hate诊断框架：1) 将仇恨言论检测分解为基于广泛共享规范标准的明确概念级问题清单；2) 使用大型语言模型独立回答每个问题，生成二进制诊断表示；3) 通过轻量级、完全可解释的决策树聚合这些诊断信号。

Result: 相比零样本LLM分类和领域内监督微调，xList-Hate在多个人工标注数据集上表现出更好的跨数据集鲁棒性和领域转移性能。定性分析表明框架对某些形式的标注不一致和上下文模糊性更不敏感，同时提供细粒度可解释性。

Conclusion: 将仇恨言论检测重构为诊断推理任务而非单一分类问题，为内容审核提供了更稳健、可解释和可扩展的替代方案。xList-Hate框架通过明确的决策路径和因素级分析实现了透明可审计的预测。

Abstract: Hate speech detection is commonly framed as a direct binary classification problem despite being a composite concept defined through multiple interacting factors that vary across legal frameworks, platform policies, and annotation guidelines. As a result, supervised models often overfit dataset-specific definitions and exhibit limited robustness under domain shift and annotation noise.
  We introduce xList-Hate, a diagnostic framework that decomposes hate speech detection into a checklist of explicit, concept-level questions grounded in widely shared normative criteria. Each question is independently answered by a large language model (LLM), producing a binary diagnostic representation that captures hateful content features without directly predicting the final label. These diagnostic signals are then aggregated by a lightweight, fully interpretable decision tree, yielding transparent and auditable predictions.
  We evaluate it across multiple hate speech benchmarks and model families, comparing it against zero-shot LLM classification and in-domain supervised fine-tuning. While supervised methods typically maximize in-domain performance, we consistently improves cross-dataset robustness and relative performance under domain shift. In addition, qualitative analysis of disagreement cases provides evidence that the framework can be less sensitive to certain forms of annotation inconsistency and contextual ambiguity. Crucially, the approach enables fine-grained interpretability through explicit decision paths and factor-level analysis.
  Our results suggest that reframing hate speech detection as a diagnostic reasoning task, rather than a monolithic classification problem, provides a robust, explainable, and extensible alternative for content moderation.

</details>


### [48] [EuroLLM-22B: Technical Report](https://arxiv.org/abs/2602.05879)
*Miguel Moura Ramos,Duarte M. Alves,Hippolyte Gisserot-Boukhlef,João Alves,Pedro Henrique Martins,Patrick Fernandes,José Pombal,Nuno M. Guerreiro,Ricardo Rei,Nicolas Boizard,Amin Farajian,Mateusz Klimaszewski,José G. C. de Souza,Barry Haddow,François Yvon,Pierre Colombo,Alexandra Birch,André F. T. Martins*

Main category: cs.CL

TL;DR: EuroLLM-22B是一个专为欧洲语言需求设计的大型语言模型，覆盖欧盟24种官方语言和11种额外语言，旨在解决现有开源大模型中欧洲语言代表性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有开源大型语言模型中欧洲语言代表性不足、服务不充分，需要专门支持欧洲公民多语言需求的模型。

Method: 从零开始训练，包括分词器设计、架构规范、数据过滤和训练流程的全面开发方法。

Result: 在广泛的多语言基准测试中表现出色，在推理、指令遵循和翻译方面表现强劲，与同类规模模型竞争性相当。

Conclusion: EuroLLM-22B成功填补了欧洲语言在开源大模型中的空白，为未来研究提供了完整的模型、数据集和代码资源。

Abstract: This report presents EuroLLM-22B, a large language model trained from scratch to support the needs of European citizens by covering all 24 official European Union languages and 11 additional languages. EuroLLM addresses the issue of European languages being underrepresented and underserved in existing open large language models. We provide a comprehensive overview of EuroLLM-22B's development, including tokenizer design, architectural specifications, data filtering, and training procedures. Across a broad set of multilingual benchmarks, EuroLLM-22B demonstrates strong performance in reasoning, instruction following, and translation, achieving results competitive with models of comparable size. To support future research, we release our base and instruction-tuned models, our multilingual web pretraining data and updated EuroBlocks instruction datasets, as well as our pre-training and evaluation codebases.

</details>


### [49] [Stop Rewarding Hallucinated Steps: Faithfulness-Aware Step-Level Reinforcement Learning for Small Reasoning Models](https://arxiv.org/abs/2602.05897)
*Shuo Nie,Hexuan Deng,Chao Wang,Ruiyu Fang,Xuebo Liu,Shuangyong Song,Yu Li,Min Zhang,Xuelong Li*

Main category: cs.CL

TL;DR: FaithRL是一种基于步骤级强化学习的方法，通过过程奖励模型和截断重采样策略减少小推理模型在思维链中的不忠实推理幻觉。


<details>
  <summary>Details</summary>
Motivation: 小推理模型在资源受限环境中支持链式思维推理，但容易在中间推理步骤产生不忠实的幻觉。现有基于在线强化学习的方法依赖结果奖励或粗粒度的思维链评估，可能在最终答案正确时无意中强化不忠实推理。

Method: 提出Faithfulness-Aware Step-Level Reinforcement Learning (FaithRL)，引入步骤级监督：1) 通过过程奖励模型提供显式忠实性奖励；2) 使用隐式截断重采样策略从忠实前缀生成对比信号。

Result: 在多个小推理模型和开放书籍问答基准测试中，FaithRL持续减少了思维链和最终答案中的幻觉，实现了更忠实可靠的推理。

Conclusion: FaithRL通过步骤级强化学习有效解决了小推理模型中的不忠实推理问题，为资源受限环境中的可靠链式思维推理提供了有效解决方案。

Abstract: As large language models become smaller and more efficient, small reasoning models (SRMs) are crucial for enabling chain-of-thought (CoT) reasoning in resource-constrained settings. However, they are prone to faithfulness hallucinations, especially in intermediate reasoning steps. Existing mitigation methods based on online reinforcement learning rely on outcome-based rewards or coarse-grained CoT evaluation, which can inadvertently reinforce unfaithful reasoning when the final answer is correct. To address these limitations, we propose Faithfulness-Aware Step-Level Reinforcement Learning (FaithRL), introducing step-level supervision via explicit faithfulness rewards from a process reward model, together with an implicit truncated resampling strategy that generates contrastive signals from faithful prefixes. Experiments across multiple SRMs and Open-Book QA benchmarks demonstrate that FaithRL consistently reduces hallucinations in both the CoT and final answers, leading to more faithful and reliable reasoning. Code is available at https://github.com/Easy195/FaithRL.

</details>


### [50] [Codified Finite-state Machines for Role-playing](https://arxiv.org/abs/2602.05905)
*Letian Peng,Yupeng Hou,Kun Zhou,Jingbo Shang*

Main category: cs.CL

TL;DR: 本文提出了Codified Finite-State Machines (CFSMs)框架，利用LLM自动将文本角色描述编码为有限状态机，并通过概率扩展(CPFSMs)处理不确定性，以提升角色扮演中角色一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的角色扮演方法主要捕捉表面行为，难以跟踪驱动交互的潜在状态，导致角色一致性不足。传统手工构建的有限状态机虽然能建模状态转换，但在开放式的角色扮演语义空间中难以适应。

Method: 提出CFSMs框架，利用LLM自动从文本角色描述中提取关键状态和转换，构建可解释的有限状态机结构。进一步扩展为CPFSMs，将转换建模为状态的概率分布，以处理不确定性和变异性。

Result: 通过合成评估和实际角色扮演场景验证，CFSM和CPFSM在结构化任务和开放式随机状态探索中都优于现有基线方法，证明了其在确保角色一致性方面的有效性。

Conclusion: CFSMs提供了一种自动将文本角色描述转化为结构化状态机的方法，能够更好地建模和维持角色扮演中的潜在状态，提升交互的一致性和沉浸感。概率扩展进一步增强了处理不确定性的能力。

Abstract: Modeling latent character states is crucial for consistent and engaging role-playing (RP) with large language models (LLMs). Yet, existing prompting-based approaches mainly capture surface actions, often failing to track the latent states that drive interaction. We revisit finite-state machines (FSMs), long used in game design to model state transitions. While effective in small, well-specified state spaces, traditional hand-crafted, rule-based FSMs struggle to adapt to the open-ended semantic space of RP. To address this, we introduce Codified Finite-State Machines (CFSMs), a framework that automatically codifies textual character profiles into FSMs using LLM-based coding. CFSMs extract key states and transitions directly from the profile, producing interpretable structures that enforce character consistency. To further capture uncertainty and variability, we extend CFSMs into Codified Probabilistic Finite-State Machines (CPFSMs), where transitions are modeled as probability distributions over states. Through both synthetic evaluations and real-world RP scenarios in established artifacts, we demonstrate that CFSM and CPFSM outperform generally applied baselines, verifying effectiveness not only in structured tasks but also in open-ended stochastic state exploration.

</details>


### [51] [KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs](https://arxiv.org/abs/2602.05929)
*Jian Chen,Zhuoran Wang,Jiayu Qin,Ming Li,Meng Wang,Changyou Chen,Yin Chen,Qizhen Weng,Yirui Liu*

Main category: cs.CL

TL;DR: KV-CoRE：一种基于SVD的方法，用于量化kv-cache的数据相关低秩可压缩性，建立了首个大规模LLM kv-cache可压缩性基准


<details>
  <summary>Details</summary>
Motivation: 随着上下文长度增长，kv-cache的读写操作会快速饱和GPU内存带宽，现有压缩方法大多忽略了kv-cache的数据依赖性及其在不同层间的变化

Method: 提出KV-CoRE方法，基于SVD计算Frobenius范数下的最优低秩近似，该方法无需梯度且支持增量计算，可实现数据集级、层级的评估

Result: 分析了多个模型和数据集，涵盖五个英文领域和十六种语言，发现了可压缩性与模型架构、训练数据和语言覆盖的系统性关联，并证明归一化有效秩与压缩下的性能退化强相关

Conclusion: 建立了原则性评估框架和首个大规模kv-cache可压缩性基准，为动态、数据感知的压缩和数据中心的模型开发提供了见解

Abstract: Large language models rely on kv-caches to avoid redundant computation during autoregressive decoding, but as context length grows, reading and writing the cache can quickly saturate GPU memory bandwidth. Recent work has explored KV-cache compression, yet most approaches neglect the data-dependent nature of kv-caches and their variation across layers. We introduce KV-CoRE KV-cache Compressibility by Rank Evaluation), an SVD-based method for quantifying the data-dependent low-rank compressibility of kv-caches. KV-CoRE computes the optimal low-rank approximation under the Frobenius norm and, being gradient-free and incremental, enables efficient dataset-level, layer-wise evaluation. Using this method, we analyze multiple models and datasets spanning five English domains and sixteen languages, uncovering systematic patterns that link compressibility to model architecture, training data, and language coverage. As part of this analysis, we employ the Normalized Effective Rank as a metric of compressibility and show that it correlates strongly with performance degradation under compression. Our study establishes a principled evaluation framework and the first large-scale benchmark of kv-cache compressibility in LLMs, offering insights for dynamic, data-aware compression and data-centric model development.

</details>


### [52] [Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions](https://arxiv.org/abs/2602.05932)
*Léo Labat,Etienne Ollion,François Yvon*

Main category: cs.CL

TL;DR: 该研究探讨多语言大语言模型在价值观相关选择题上的跨语言一致性，发现虽然大型指令调优模型整体一致性较高，但某些问题会引发语言特定行为，表明模型并非理论上的多语者而是表现出语言依赖的价值观表达。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索多语言大语言模型在价值观相关选择题回答中的跨语言一致性。虽然多语言对事实回忆的影响已有研究，但价值观相关选择题中语言引发的变异尚未充分探索。研究旨在确定多语言LLM是否像理论上的多语者一样在不同语言中保持一致，还是像多个单语模型通过单一模型表达不同价值观那样依赖问题语言。

Method: 1. 发布新的多语言欧洲价值观调查（MEVS）语料库，包含8种欧洲语言的人工翻译调查问题，避免机器翻译或临时提示问题
2. 对30多个不同规模、制造商和对齐微调状态的多语言LLM进行测试
3. 在全面控制的提示变体下进行实验，包括答案顺序、符号类型和尾字符
4. 分析模型在不同语言和问题上的响应一致性和变异

Result: 1. 较大、指令调优的模型总体上显示出更高的一致性
2. 模型响应的稳健性在不同问题间差异很大：某些选择题在模型内部和跨模型间引发完全一致的回答，而其他问题则导致LLM回答分裂
3. 所有一致的、指令微调模型中似乎都出现了语言特定行为，但仅在某些问题上出现
4. 结果表明偏好微调对模型响应有选择性影响，需要进一步研究

Conclusion: 多语言大语言模型在价值观相关选择题上的响应存在语言诱导的变异。虽然大型指令调优模型整体一致性较高，但它们并非纯粹的理论多语者，而是在某些问题上表现出语言依赖的价值观表达。这表明偏好微调对模型响应的选择性影响，以及需要进一步研究语言如何塑造LLM的价值观表达。

Abstract: Multiple-Choice Questions (MCQs) are often used to assess knowledge, reasoning abilities, and even values encoded in large language models (LLMs). While the effect of multilingualism has been studied on LLM factual recall, this paper seeks to investigate the less explored question of language-induced variation in value-laden MCQ responses. Are multilingual LLMs consistent in their responses across languages, i.e. behave like theoretical polyglots, or do they answer value-laden MCQs depending on the language of the question, like a multitude of monolingual models expressing different values through a single model? We release a new corpus, the Multilingual European Value Survey (MEVS), which, unlike prior work relying on machine translation or ad hoc prompts, solely comprises human-translated survey questions aligned in 8 European languages. We administer a subset of those questions to over thirty multilingual LLMs of various sizes, manufacturers and alignment-fine-tuning status under comprehensive, controlled prompt variations including answer order, symbol type, and tail character. Our results show that while larger, instruction-tuned models display higher overall consistency, the robustness of their responses varies greatly across questions, with certain MCQs eliciting total agreement within and across models while others leave LLM answers split. Language-specific behavior seems to arise in all consistent, instruction-fine-tuned models, but only on certain questions, warranting a further study of the selective effect of preference fine-tuning.

</details>


### [53] [Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training](https://arxiv.org/abs/2602.05940)
*Junxiao Liu,Zhijun Wang,Yixiao Li,Zhejian Lai,Liqian Huang,Xin Huang,Xue Han,Junlan Feng,Shujian Huang*

Main category: cs.CL

TL;DR: 提出TRIT框架，通过整合翻译训练提升多语言推理模型的性能和语言一致性


<details>
  <summary>Details</summary>
Motivation: 现有长推理模型在多语言场景下表现不佳：倾向于用英语推理非英语问题；当被约束使用问题语言推理时，准确性大幅下降。这源于多语言问题理解和多语言推理能力的双重不足。

Method: 提出TRIT（Translation-Reasoning Integrated Training）框架，这是一种自改进框架，将翻译训练整合到多语言推理训练中。无需外部反馈或额外多语言数据，该方法联合增强多语言问题理解和响应生成能力。

Result: 在MMATH数据集上，该方法平均超越多个基线7个百分点，同时提高了答案正确性和语言一致性。进一步分析显示，整合翻译训练使跨语言问题对齐提高了10个百分点以上，并提升了对数学问题和一般领域文本的翻译质量，在FLORES-200上获得高达8.4 COMET分数的增益。

Conclusion: TRIT框架通过将翻译训练整合到多语言推理训练中，有效解决了多语言推理模型在问题理解和推理方面的双重挑战，显著提升了模型在多语言数学推理任务上的性能。

Abstract: Long reasoning models often struggle in multilingual settings: they tend to reason in English for non-English questions; when constrained to reasoning in the question language, accuracies drop substantially. The struggle is caused by the limited abilities for both multilingual question understanding and multilingual reasoning. To address both problems, we propose TRIT (Translation-Reasoning Integrated Training), a self-improving framework that integrates the training of translation into multilingual reasoning. Without external feedback or additional multilingual data, our method jointly enhances multilingual question understanding and response generation. On MMATH, our method outperforms multiple baselines by an average of 7 percentage points, improving both answer correctness and language consistency. Further analysis reveals that integrating translation training improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, with gains up to 8.4 COMET points on FLORES-200.

</details>


### [54] [Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space](https://arxiv.org/abs/2602.05971)
*Felipe D. Toro-Hernández,Jesuino Vieira Filho,Rodrigo M. Cabral-Carvalho*

Main category: cs.CL

TL;DR: 该研究提出了一种将概念产生视为在嵌入空间中导航的框架，通过累积嵌入构建语义轨迹并提取几何和动力学指标，用于区分临床组和概念类型，为量化语义表征动态提供数学框架。


<details>
  <summary>Details</summary>
Motivation: 人类如何在语义表征的几何空间中导航以检索和操作意义是一个重要问题。现有方法通常需要大量人工语言预处理，研究者希望建立一个计算基础框架来量化语义导航的动态过程。

Method: 使用不同的transformer文本嵌入模型，基于累积嵌入构建参与者特定的语义轨迹，提取包括到下一个点的距离、到质心的距离、熵、速度和加速度等几何和动力学指标。

Result: 在四个跨语言数据集上验证了该框架的有效性，能够区分临床组和概念类型。累积嵌入在较长轨迹中表现最佳，而较短轨迹可能更适合非累积方法。不同嵌入模型产生相似结果，表明学习表征之间存在相似性。

Conclusion: 通过将语义导航框架化为在嵌入空间中的结构化轨迹，该研究建立了连接认知建模与学习表征的管道，为临床研究、跨语言分析和人工认知评估提供了量化语义表征动态的工具。

Abstract: Semantic representations can be framed as a structured, dynamic knowledge space through which humans navigate to retrieve and manipulate meaning. To investigate how humans traverse this geometry, we introduce a framework that represents concept production as navigation through embedding space. Using different transformer text embedding models, we construct participant-specific semantic trajectories based on cumulative embeddings and extract geometric and dynamical metrics, including distance to next, distance to centroid, entropy, velocity, and acceleration. These measures capture both scalar and directional aspects of semantic navigation, providing a computationally grounded view of semantic representation search as movement in a geometric space. We evaluate the framework on four datasets across different languages, spanning different property generation tasks: Neurodegenerative, Swear verbal fluency, Property listing task in Italian, and in German. Across these contexts, our approach distinguishes between clinical groups and concept types, offering a mathematical framework that requires minimal human intervention compared to typical labor-intensive linguistic pre-processing methods. Comparison with a non-cumulative approach reveals that cumulative embeddings work best for longer trajectories, whereas shorter ones may provide too little context, favoring the non-cumulative alternative. Critically, different embedding models yielded similar results, highlighting similarities between different learned representations despite different training pipelines. By framing semantic navigation as a structured trajectory through embedding space, bridging cognitive modeling with learned representation, thereby establishing a pipeline for quantifying semantic representation dynamics with applications in clinical research, cross-linguistic analysis, and the assessment of artificial cognition.

</details>


### [55] [DSB: Dynamic Sliding Block Scheduling for Diffusion LLMs](https://arxiv.org/abs/2602.05992)
*Lizhuo Luo,Shenggui Li,Yonggang Wen,Tianwei Zhang*

Main category: cs.CL

TL;DR: 本文提出动态滑动块（DSB）方法，通过根据语义难度动态调整块大小，优化扩散大语言模型的并行解码效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有扩散大语言模型（dLLMs）使用固定的预定义块调度策略，这种策略对语义难度不敏感，导致效率和质量问题：它可能迫使模型过早地对不确定位置做出决策，同时延迟边界附近简单位置的处理。

Method: 提出动态滑动块（DSB）方法，这是一种无需训练的方法，使用动态大小的滑动块来克服固定块的局限性。同时引入DSB Cache，一种专为DSB设计的无需训练的KV缓存机制。

Result: 在多个模型和基准测试上的实验表明，DSB与DSB Cache结合能够一致地提高dLLMs的生成质量和推理效率。

Conclusion: 动态适应语义难度的块调度策略对于dLLMs的可靠高效推理至关重要，DSB方法通过动态滑动块机制有效解决了固定块调度的局限性。

Abstract: Diffusion large language models (dLLMs) have emerged as a promising alternative for text generation, distinguished by their native support for parallel decoding. In practice, block inference is crucial for avoiding order misalignment in global bidirectional decoding and improving output quality. However, the widely-used fixed, predefined block (naive) schedule is agnostic to semantic difficulty, making it a suboptimal strategy for both quality and efficiency: it can force premature commitments to uncertain positions while delaying easy positions near block boundaries. In this work, we analyze the limitations of naive block scheduling and disclose the importance of dynamically adapting the schedule to semantic difficulty for reliable and efficient inference. Motivated by this, we propose Dynamic Sliding Block (DSB), a training-free block scheduling method that uses a sliding block with a dynamic size to overcome the rigidity of the naive block. To further improve efficiency, we introduce DSB Cache, a training-free KV-cache mechanism tailored to DSB. Extensive experiments across multiple models and benchmarks demonstrate that DSB, together with DSB Cache, consistently improves both generation quality and inference efficiency for dLLMs. Code is released at https://github.com/lizhuo-luo/DSB.

</details>


### [56] [A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies](https://arxiv.org/abs/2602.06015)
*Panagiotis Kaliosis,Adithya V Ganesan,Oscar N. E. Kjell,Whitney Ringwald,Scott Feltman,Melissa A. Carr,Dimitris Samaras,Camilo Ruggero,Benjamin J. Luft,Roman Kotov,Andrew H. Schwartz*

Main category: cs.CL

TL;DR: 本研究系统评估了11种最先进的大型语言模型在零样本评估心理健康状况（特别是PTSD）时的性能，探讨了上下文知识和建模策略对准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型越来越多地被用于零样本评估心理健康状况，但我们对其准确性影响因素了解有限。本研究旨在全面评估LLMs在心理健康评估中的表现，并识别影响准确性的关键因素。

Method: 使用包含1,437名个体的自然语言叙述和自报PTSD严重程度评分的临床数据集，评估11种最先进的LLMs。系统变化：(i)上下文知识（子量表定义、分布摘要、访谈问题）；(ii)建模策略（零样本vs少样本、推理量、模型大小、结构化子量表vs直接标量预测、输出重缩放、9种集成方法）。

Result: 主要发现：(a)提供详细构念定义和叙述上下文时LLMs最准确；(b)增加推理量可提高估计准确性；(c)开源模型参数超过70B后性能趋于平稳，而闭源模型随新一代改进；(d)监督模型与零样本LLMs集成可获得最佳性能。

Conclusion: 上下文知识和建模策略的选择对于部署LLMs准确评估心理健康至关重要。研究结果为优化LLMs在心理健康评估中的应用提供了实证指导。

Abstract: Large language models (LLMs) are increasingly being used in a zero-shot fashion to assess mental health conditions, yet we have limited knowledge on what factors affect their accuracy. In this study, we utilize a clinical dataset of natural language narratives and self-reported PTSD severity scores from 1,437 individuals to comprehensively evaluate the performance of 11 state-of-the-art LLMs. To understand the factors affecting accuracy, we systematically varied (i) contextual knowledge like subscale definitions, distribution summary, and interview questions, and (ii) modeling strategies including zero-shot vs few shot, amount of reasoning effort, model sizes, structured subscales vs direct scalar prediction, output rescaling and nine ensemble methods. Our findings indicate that (a) LLMs are most accurate when provided with detailed construct definitions and context of the narrative; (b) increased reasoning effort leads to better estimation accuracy; (c) performance of open-weight models (Llama, Deepseek), plateau beyond 70B parameters while closed-weight (o3-mini, gpt-5) models improve with newer generations; and (d) best performance is achieved when ensembling a supervised model with the zero-shot LLMs. Taken together, the results suggest choice of contextual knowledge and modeling strategies is important for deploying LLMs to accurately assess mental health.

</details>


### [57] [Multi-Token Prediction via Self-Distillation](https://arxiv.org/abs/2602.06019)
*John Kirchenbauer,Abhimanyu Hans,Brian Bartoldson,Micah Goldblum,Ashwinee Panda,Tom Goldstein*

Main category: cs.CL

TL;DR: 通过在线蒸馏将单token预测模型转换为多token预测模型，实现3倍以上的解码加速，且无需辅助模型或复杂推理管道。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型加速技术（如推测解码）需要训练辅助推测器模型并构建复杂的推理管道，部署和维护成本高。本文寻求更简单的方法来加速推理。

Method: 提出一种在线蒸馏方法，将预训练的自回归语言模型从单token预测模型转换为独立的多token预测模型。该方法使用简单的蒸馏目标，最终模型与初始检查点保持完全相同的实现，无需额外验证器或专用推理代码。

Result: 在GSM8K数据集上，该方法使模型平均解码速度提升3倍以上，准确率下降小于5%（相对于单token解码性能）。

Conclusion: 该方法提供了一种简单有效的语言模型推理加速方案，无需复杂的辅助模型或专用推理管道，保持了模型的部署便利性。

Abstract: Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online distillation objective. The final model retains the exact same implementation as the pretrained initial checkpoint and is deployable without the addition of any auxiliary verifier or other specialized inference code. On GSM8K, our method produces models that can decode more than $3\times$ faster on average at $<5\%$ drop in accuracy relative to single token decoding performance.

</details>


### [58] [Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory](https://arxiv.org/abs/2602.06025)
*Haozhen Zhang,Haodong Yue,Tao Feng,Quanyu Long,Jianzhu Bao,Bowen Jin,Weizhi Zhang,Xiao Li,Jiaxuan You,Chengwei Qin,Wenya Wang*

Main category: cs.CL

TL;DR: BudgetMem是一个运行时代理内存框架，通过三级预算控制和模块化设计，在任务性能和内存构建成本之间提供明确的权衡控制。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理系统大多依赖离线的、查询无关的内存构建方式，这种方式效率低下且可能丢弃关键信息。运行时内存利用虽然自然，但现有方法往往带来显著开销且缺乏对性能-成本权衡的明确控制。

Method: BudgetMem将内存处理结构化为一组内存模块，每个模块提供低/中/高三个预算层级。通过轻量级路由器进行模块间的预算层级路由，该路由器作为紧凑的神经策略，使用强化学习训练。研究了三种实现预算层级的策略：实现复杂度、推理行为和模块模型大小。

Result: 在LoCoMo、LongMemEval和HotpotQA等基准测试中，BudgetMem在优先性能时（高预算设置）超越强基线，在预算更紧时提供更好的准确率-成本边界。分析揭示了不同层级策略的优势和弱点，明确了在不同预算机制下每种策略的最佳应用场景。

Conclusion: BudgetMem为LLM代理内存管理提供了一个有效的运行时框架，通过明确的预算控制和模块化设计，实现了性能与成本之间的灵活权衡，为不同预算机制下的内存优化提供了实用解决方案。

Abstract: Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \textbf{BudgetMem}, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., \textsc{Low}/\textsc{Mid}/\textsc{High}). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.

</details>


### [59] [DFlash: Block Diffusion for Flash Speculative Decoding](https://arxiv.org/abs/2602.06036)
*Jian Chen,Yesheng Liang,Zhijian Liu*

Main category: cs.CL

TL;DR: DFlash 是一个推测解码框架，使用轻量级块扩散模型进行并行草稿生成，相比传统自回归草稿模型能实现更高的加速比。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型（LLMs）需要顺序解码，导致推理延迟高且GPU利用率低。虽然推测解码通过快速草稿模型来缓解这个问题，但现有方法仍依赖自回归草稿生成，这仍然是顺序的，限制了实际加速效果。扩散LLMs提供了并行生成的替代方案，但当前扩散模型通常性能不如自回归模型。

Method: DFlash 采用轻量级块扩散模型进行并行草稿生成，通过单次前向传播生成草稿标记，并将草稿模型条件化于从目标模型中提取的上下文特征，从而实现高质量输出和高接受率。

Result: 实验表明，DFlash 在各种模型和任务上实现了超过6倍的无损加速，比最先进的推测解码方法EAGLE-3提供高达2.5倍的加速比。

Conclusion: DFlash 通过结合扩散模型的并行生成能力和推测解码框架，显著提高了LLM推理效率，同时保持了输出质量，为解决自回归模型推理瓶颈提供了有效方案。

Abstract: Autoregressive large language models (LLMs) deliver strong performance but require inherently sequential decoding, leading to high inference latency and poor GPU utilization. Speculative decoding mitigates this bottleneck by using a fast draft model whose outputs are verified in parallel by the target LLM; however, existing methods still rely on autoregressive drafting, which remains sequential and limits practical speedups. Diffusion LLMs offer a promising alternative by enabling parallel generation, but current diffusion models typically underperform compared with autoregressive models. In this paper, we introduce DFlash, a speculative decoding framework that employs a lightweight block diffusion model for parallel drafting. By generating draft tokens in a single forward pass and conditioning the draft model on context features extracted from the target model, DFlash enables efficient drafting with high-quality outputs and higher acceptance rates. Experiments show that DFlash achieves over 6x lossless acceleration across a range of models and tasks, delivering up to 2.5x higher speedup than the state-of-the-art speculative decoding method EAGLE-3.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [60] [Atomic Information Flow: A Network Flow Model for Tool Attributions in RAG Systems](https://arxiv.org/abs/2602.04912)
*James Gao,Josh Zhou,Qi Sun,Ryan Huang,Steven Yoo*

Main category: cs.IR

TL;DR: AIF（原子信息流）是一种基于图的网络流模型，通过将工具输出和LLM调用分解为原子信息单元，实现RAG系统中信息流的精确追踪和归因。


<details>
  <summary>Details</summary>
Motivation: 当前基于工具的RAG系统缺乏将最终响应追溯到特定工具组件的精确机制，这在系统扩展到复杂的多智能体架构时成为关键瓶颈。

Method: 提出AIF图模型，将LLM编排建模为从工具和LLM节点到响应超汇点的原子信息流；基于最大流最小割定理，训练轻量级Gemma3-4B语言模型作为上下文压缩器，利用AIF计算的流信号来近似最小割。

Result: 基础Gemma3-4B在HotpotQA上识别关键信息的准确率仅为54.7%，略优于词法基线（BM25）。但在AIF信号上后训练后，准确率提升至82.71%（+28.01分），同时实现87.52%（+1.85%）的上下文token压缩，性能接近大7倍的Gemma3-27B变体。

Conclusion: AIF为RAG系统提供了细粒度的信息流追踪和归因能力，通过训练轻量级模型利用AIF信号，可以在保持高效压缩的同时显著提升关键信息识别能力，缩小与大模型的性能差距。

Abstract: Many tool-based Retrieval Augmented Generation (RAG) systems lack precise mechanisms for tracing final responses back to specific tool components -- a critical gap as systems scale to complex multi-agent architectures. We present \textbf{Atomic Information Flow (AIF)}, a graph-based network flow model that decomposes tool outputs and LLM calls into atoms: indivisible, self-contained units of information. By modeling LLM orchestration as a directed flow of atoms from tool and LLM nodes to a response super-sink, AIF enables granular attribution metrics for AI explainability.
  Motivated by the max-flow min-cut theorem in network flow theory, we train a lightweight Gemma3 (4B parameter) language model as a context compressor to approximate the minimum cut of tool atoms using flow signals computed offline by AIF. We note that the base Gemma3-4B model struggles to identify critical information with \textbf{54.7\%} accuracy on HotpotQA, barely outperforming lexical baselines (BM25). However, post-training on AIF signals boosts accuracy to \textbf{82.71\%} (+28.01 points) while achieving \textbf{87.52\%} (+1.85\%) context token compression -- bridging the gap with the Gemma3-27B variant, a model nearly $7\times$ larger.

</details>


### [61] [Scaling Laws for Embedding Dimension in Information Retrieval](https://arxiv.org/abs/2602.05062)
*Julian Killingback,Mahta Rafiee,Madine Manas,Hamed Zamani*

Main category: cs.IR

TL;DR: 该研究对稠密检索中嵌入维度与检索性能的关系进行了综合分析，发现性能随嵌入维度增加呈幂律增长，但存在收益递减，且不同任务间的性能变化存在差异。


<details>
  <summary>Details</summary>
Motivation: 随着稠密检索任务复杂性增加，其底层数据结构（向量）和相似度度量（内积）的基本局限性日益明显。嵌入维度对检索容量至关重要，理解嵌入维度缩放如何影响性能对于构建平衡效果和效率的下一代检索模型至关重要。

Method: 对两个模型家族和一系列模型规模进行综合实验，构建详细的嵌入缩放行为图景。通过实验分析发现性能与嵌入维度之间的关系符合幂律。

Result: 研究发现：1) 嵌入维度与性能关系符合幂律，可以推导出仅基于嵌入维度的性能缩放定律，以及同时考虑嵌入维度和模型规模的联合定律；2) 对于与训练任务对齐的评估任务，性能随嵌入维度增加持续提升，但存在收益递减；3) 对于与训练任务对齐度较低的评估数据，性能变化较难预测，某些任务中更大嵌入维度反而导致性能下降。

Conclusion: 该研究为理解嵌入的局限性及其行为提供了新见解，并为选择模型和嵌入维度以实现最优性能同时降低存储和计算成本提供了实用指南。

Abstract: Dense retrieval, which encodes queries and documents into a single dense vector, has become the dominant neural retrieval approach due to its simplicity and compatibility with fast approximate nearest neighbor algorithms. As the tasks dense retrieval performs grow in complexity, the fundamental limitations of the underlying data structure and similarity metric -- namely vectors and inner-products -- become more apparent. Prior recent work has shown theoretical limitations inherent to single vectors and inner-products that are generally tied to the embedding dimension. Given the importance of embedding dimension for retrieval capacity, understanding how dense retrieval performance changes as embedding dimension is scaled is fundamental to building next generation retrieval models that balance effectiveness and efficiency. In this work, we conduct a comprehensive analysis of the relationship between embedding dimension and retrieval performance. Our experiments include two model families and a range of model sizes from each to construct a detailed picture of embedding scaling behavior. We find that the scaling behavior fits a power law, allowing us to derive scaling laws for performance given only embedding dimension, as well as a joint law accounting for embedding dimension and model size. Our analysis shows that for evaluation tasks aligned with the training task, performance continues to improve as embedding size increases, though with diminishing returns. For evaluation data that is less aligned with the training task, we find that performance is less predictable, with performance degrading with larger embedding dimensions for certain tasks. We hope our work provides additional insight into the limitations of embeddings and their behavior as well as offers a practical guide for selecting model and embedding dimension to achieve optimal performance with reduced storage and compute costs.

</details>


### [62] [RAG without Forgetting: Continual Query-Infused Key Memory](https://arxiv.org/abs/2602.05152)
*Yuntong Hu,Sha Li,Naren Ramakrishnan,Liang Zhao*

Main category: cs.IR

TL;DR: 提出ERM框架，将临时查询增强转化为持久检索改进，通过正确性门控反馈更新检索索引，实现零推理开销的检索优化。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统通过查询扩展和迭代检索等查询时适应技术提高鲁棒性，但这些方法是无状态的：每次查询都要重新计算适应结果，无法累积学习且重复产生推理成本。索引侧方法如键扩展引入了持久性，但依赖离线预处理或启发式更新，与下游任务效用对齐较弱，导致语义漂移和噪声累积。

Method: 提出演化检索记忆（ERM）框架，通过正确性门控反馈更新检索索引，选择性地将原子扩展信号归因于它们受益的文档键，并通过稳定、范数有界的更新逐步演化键。证明查询扩展和键扩展在标准相似度函数下理论等价，并证明ERM选择性更新的收敛性。

Result: 在BEIR和BRIGHT的13个领域实验中，ERM在检索和生成方面均取得一致提升，特别是在推理密集型任务上，同时保持原生检索速度。

Conclusion: ERM框架成功地将临时查询增强转化为持久检索改进，通过训练免费的方式实现了零推理开销的检索优化，为RAG系统提供了一种高效且稳定的检索增强方法。

Abstract: Retrieval-augmented generation (RAG) systems commonly improve robustness via query-time adaptations such as query expansion and iterative retrieval. While effective, these approaches are inherently stateless: adaptations are recomputed for each query and discarded thereafter, precluding cumulative learning and repeatedly incurring inference-time cost. Index-side approaches like key expansion introduce persistence but rely on offline preprocessing or heuristic updates that are weakly aligned with downstream task utility, leading to semantic drift and noise accumulation. We propose Evolving Retrieval Memory (ERM), a training-free framework that transforms transient query-time gains into persistent retrieval improvements. ERM updates the retrieval index through correctness-gated feedback, selectively attributes atomic expansion signals to the document keys they benefit, and progressively evolves keys via stable, norm-bounded updates. We show that query and key expansion are theoretically equivalent under standard similarity functions and prove convergence of ERM's selective updates, amortizing optimal query expansion into a stable index with zero inference-time overhead. Experiments on BEIR and BRIGHT across 13 domains demonstrate consistent gains in retrieval and generation, particularly on reasoning-intensive tasks, at native retrieval speed.

</details>


### [63] [Semantic Search over 9 Million Mathematical Theorems](https://arxiv.org/abs/2602.05216)
*Luke Alexander,Eric Leonen,Sophie Szeto,Artemii Remizov,Ignacio Tejeda,Giovanni Inchiostro,Vasily Ilin*

Main category: cs.IR

TL;DR: 构建了一个包含920万定理语句的统一语料库，通过语义搜索实现定理级检索，显著提升了数学定理搜索效果。


<details>
  <summary>Details</summary>
Motivation: 现有数学检索工具只能检索整篇论文，而数学家和定理证明代理通常需要查找特定定理、引理或命题来回答查询。虽然语义搜索发展迅速，但在大型、高度技术性的研究级数学定理语料库上的表现仍不清楚。

Method: 从arXiv和其他七个来源提取了920万定理语句，构建了最大的公开研究级定理语料库。为每个定理生成简短的自然语言描述作为检索表示，系统分析了表示上下文、语言模型选择、嵌入模型和提示策略对检索质量的影响。

Result: 在专业数学家编写的定理搜索查询评估集上，该方法在定理级和论文级检索方面均显著优于现有基线，证明语义定理搜索在网络规模上是可行且有效的。

Conclusion: 语义定理搜索在大规模数学语料库上是可行的，并且能够显著提升定理检索的准确性和效率，为数学研究和定理证明提供了有价值的工具。

Abstract: Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of $9.2$ million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at \href{https://huggingface.co/spaces/uw-math-ai/theorem-search}{this link}, and the dataset is available at \href{https://huggingface.co/datasets/uw-math-ai/TheoremSearch}{this link}.

</details>


### [64] [NeuCLIRTech: Chinese Monolingual and Cross-Language Information Retrieval Evaluation in a Challenging Domain](https://arxiv.org/abs/2602.05334)
*Dawn Lawrie,James Mayfield,Eugene Yang,Andrew Yates,Sean MacAvaney,Ronak Pradeep,Scott Miller,Paul McNamee,Luca Soldaini*

Main category: cs.IR

TL;DR: NeuCLIRTech是一个用于技术信息跨语言检索的评估数据集，包含中英文技术文档、110个查询和35,962个相关性判断，支持中文单语检索和英文查询的跨语言检索场景。


<details>
  <summary>Details</summary>
Motivation: 为了准确衡量检索系统的进展，需要能够可靠区分系统性能的测试集合。现有的评估数据集在技术信息的跨语言检索方面存在不足，特别是在中文和英文之间的跨语言检索场景。

Method: 构建NeuCLIRTech评估集合，包含原生中文技术文档及其机器翻译的英文版本。整合TREC NeuCLIR 2023和2024的主题，提供110个查询和35,962个文档相关性判断。还包含基于神经检索系统的融合基线，避免研究者过度依赖BM25作为第一阶段检索器。

Result: 创建了一个具有强大统计区分能力的评估集合，支持中文单语检索和英文查询的跨语言检索两种场景。数据集和工具已在Huggingface Datasets上发布，为检索系统开发提供了可靠的评估基准。

Conclusion: NeuCLIRTech为技术信息跨语言检索提供了一个高质量的评估资源，特别关注中文-英文语言对，有助于推动跨语言检索技术的发展和研究。

Abstract: Measuring advances in retrieval requires test collections with relevance judgments that can faithfully distinguish systems. This paper presents NeuCLIRTech, an evaluation collection for cross-language retrieval over technical information. The collection consists of technical documents written natively in Chinese and those same documents machine translated into English. It includes 110 queries with relevance judgments. The collection supports two retrieval scenarios: monolingual retrieval in Chinese, and cross-language retrieval with English as the query language. NeuCLIRTech combines the TREC NeuCLIR track topics of 2023 and 2024. The 110 queries with 35,962 document judgments provide strong statistical discriminatory power when trying to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included so that developers of reranking algorithms are not reliant on BM25 as their first stage retriever. The dataset and artifacts are released on Huggingface Datasets

</details>


### [65] [Multi-Field Tool Retrieval](https://arxiv.org/abs/2602.05366)
*Yichen Tang,Weihang Su,Yiqun Liu,Qingyao Ai*

Main category: cs.IR

TL;DR: 论文提出多字段工具检索框架，解决传统工具检索中存在的文档不完整、语义不匹配和多维度效用问题，在多个数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型集成外部工具时面临工具规模增长带来的检索效率问题。现有方法将工具检索视为传统检索任务，但存在三个根本限制：1) 工具文档不完整且结构不一致；2) 用户查询与技术文档存在显著语义和粒度不匹配；3) 工具效用具有多维度特性（功能、输入约束、输出格式等）。

Method: 提出多字段工具检索框架，通过细粒度、多字段建模来对齐用户意图与工具表示。该框架能够处理工具效用的多个维度，并解决文档不完整和语义不匹配问题。

Result: 在五个数据集和一个混合基准测试中实现了最先进的性能，表现出优异的泛化能力和鲁棒性。

Conclusion: 多字段工具检索框架有效解决了传统工具检索方法的局限性，通过细粒度建模工具效用的多个维度，显著提升了工具检索的效果和效率。

Abstract: Integrating external tools enables Large Language Models (LLMs) to interact with real-world environments and solve complex tasks. Given the growing scale of available tools, effective tool retrieval is essential to mitigate constraints of LLMs' context windows and ensure computational efficiency. Existing approaches typically treat tool retrieval as a traditional ad-hoc retrieval task, matching user queries against the entire raw tool documentation. In this paper, we identify three fundamental challenges that limit the effectiveness of this paradigm: (i) the incompleteness and structural inconsistency of tool documentation; (ii) the significant semantic and granular mismatch between user queries and technical tool documents; and, most importantly, (iii) the multi-aspect nature of tool utility, that involves distinct dimensions, such as functionality, input constraints, and output formats, varying in format and importance. To address these challenges, we introduce Multi-Field Tool Retrieval, a framework designed to align user intent with tool representations through fine-grained, multi-field modeling. Experimental results show that our framework achieves SOTA performance on five datasets and a mixed benchmark, exhibiting superior generalizability and robustness.

</details>


### [66] [Rich-Media Re-Ranker: A User Satisfaction-Driven LLM Re-ranking Framework for Rich-Media Search](https://arxiv.org/abs/2602.05408)
*Zihao Guo,Ligang Zhou,Zeyang Tang,Feicheng Li,Ying Nie,Zhiming Peng,Qingyun Sun,Jianxin Li*

Main category: cs.IR

TL;DR: 提出Rich-Media Re-Ranker框架，通过多维细粒度建模提升搜索满意度，结合查询分析、视觉内容感知和强化学习优化，显著优于现有方法并已工业部署。


<details>
  <summary>Details</summary>
Motivation: 现有重排序方法存在两大局限：1）对多面用户意图建模不足；2）忽视丰富的侧信息（如视觉感知信号）。这限制了用户搜索满意度的提升。

Method: 1. Query Planner分析会话中查询细化序列，捕获真实搜索意图，分解为互补子查询；2. 整合候选结果的丰富侧信息（包括VLM生成的视觉内容信号）；3. 基于多面原则（内容相关性、质量、信息增益、新颖性、封面图视觉呈现）进行综合评估；4. LLM-based re-ranker进行整体评估；5. 通过多任务强化学习增强VLM评估器和LLM重排序器的场景适应性。

Result: 大量实验表明，该方法显著优于最先进的基线方法。该框架已在大型工业搜索系统中部署，在线用户参与率和满意度指标均有显著提升。

Conclusion: Rich-Media Re-Ranker框架通过多维度细粒度建模有效解决了现有重排序方法的局限性，成功整合了查询意图分析、视觉内容感知和强化学习优化，显著提升了用户搜索满意度，并验证了其工业应用价值。

Abstract: Re-ranking plays a crucial role in modern information search systems by refining the ranking of initial search results to better satisfy user information needs. However, existing methods show two notable limitations in improving user search satisfaction: inadequate modeling of multifaceted user intents and neglect of rich side information such as visual perception signals. To address these challenges, we propose the Rich-Media Re-Ranker framework, which aims to enhance user search satisfaction through multi-dimensional and fine-grained modeling. Our approach begins with a Query Planner that analyzes the sequence of query refinements within a session to capture genuine search intents, decomposing the query into clear and complementary sub-queries to enable broader coverage of users' potential intents. Subsequently, moving beyond primary text content, we integrate richer side information of candidate results, including signals modeling visual content generated by the VLM-based evaluator. These comprehensive signals are then processed alongside carefully designed re-ranking principle that considers multiple facets, including content relevance and quality, information gain, information novelty, and the visual presentation of cover images. Then, the LLM-based re-ranker performs the holistic evaluation based on these principles and integrated signals. To enhance the scenario adaptability of the VLM-based evaluator and the LLM-based re-ranker, we further enhance their capabilities through multi-task reinforcement learning. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines. Notably, the proposed framework has been deployed in a large-scale industrial search system, yielding substantial improvements in online user engagement rates and satisfaction metrics.

</details>


### [67] [SciDef: Automating Definition Extraction from Academic Literature with Large Language Models](https://arxiv.org/abs/2602.05413)
*Filip Kučera,Christoph Mandl,Isao Echizen,Radu Timofte,Timo Spinde*

Main category: cs.IR

TL;DR: SciDef是一个基于LLM的自动化定义提取管道，通过多步和DSPy优化的提示策略提高性能，在科学文献中能提取86.4%的定义，但存在过度生成的问题。


<details>
  <summary>Details</summary>
Motivation: 随着科学出版物数量大幅增加，收集与特定关键词相关的定义变得极具挑战性，需要自动化工具来高效提取科学文献中的定义。

Method: 提出SciDef管道，基于LLM进行定义提取。在DefExtra和DefSim数据集上测试16种语言模型，评估不同提示策略（包括多步提示和DSPy优化提示），并使用多种指标（特别是基于NLI的方法）评估提取质量。

Result: LLM在科学文献中能有效提取定义（在测试集上达到86.4%的提取率），多步提示和DSPy优化提示能提升性能。基于NLI的评估方法最可靠。但模型倾向于过度生成定义，需要区分相关定义。

Conclusion: LLM能够有效从科学文献中提取定义，但未来工作应专注于识别相关定义而不仅仅是找到定义，因为模型存在过度生成的问题。代码和数据集已开源。

Abstract: Definitions are the foundation for any scientific work, but with a significant increase in publication numbers, gathering definitions relevant to any keyword has become challenging. We therefore introduce SciDef, an LLM-based pipeline for automated definition extraction. We test SciDef on DefExtra & DefSim, novel datasets of human-extracted definitions and definition-pairs' similarity, respectively. Evaluating 16 language models across prompting strategies, we demonstrate that multi-step and DSPy-optimized prompting improve extraction performance. To evaluate extraction, we test various metrics and show that an NLI-based method yields the most reliable results. We show that LLMs are largely able to extract definitions from scientific literature (86.4% of definitions from our test-set); yet future work should focus not just on finding definitions, but on identifying relevant ones, as models tend to over-generate them.
  Code & datasets are available at https://github.com/Media-Bias-Group/SciDef.

</details>


### [68] [Forward Index Compression for Learned Sparse Retrieval](https://arxiv.org/abs/2602.05445)
*Sebastian Bruch,Martino Fontana,Franco Maria Nardini,Cosimo Rulli,Rossano Venturini*

Main category: cs.IR

TL;DR: 提出DotVByte压缩算法，优化稀疏检索中的前向索引存储，在保持检索质量的同时显著减少内存占用。


<details>
  <summary>Details</summary>
Motivation: 稀疏检索虽然有效，但其前向索引占用了大量存储空间，需要在不影响检索质量和延迟的情况下压缩该数据结构。

Method: 研究多种整数压缩技术，发现StreamVByte效果最佳，并在此基础上提出专门针对内积计算的DotVByte算法。

Result: 在MsMarco数据集上的实验表明，DotVByte能显著节省存储空间，同时保持检索效率。

Conclusion: DotVByte为稀疏检索的前向索引压缩提供了有效的解决方案，实现了存储效率与检索性能的良好平衡。

Abstract: Text retrieval using learned sparse representations of queries and documents has, over the years, evolved into a highly effective approach to search. It is thanks to recent advances in approximate nearest neighbor search-with the emergence of highly efficient algorithms such as the inverted index-based Seismic and the graph-based Hnsw-that retrieval with sparse representations became viable in practice. In this work, we scrutinize the efficiency of sparse retrieval algorithms and focus particularly on the size of a data structure that is common to all algorithmic flavors and that constitutes a substantial fraction of the overall index size: the forward index. In particular, we seek compression techniques to reduce the storage footprint of the forward index without compromising search quality or inner product computation latency. In our examination with various integer compression techniques, we report that StreamVByte achieves the best trade-off between memory footprint, retrieval accuracy, and latency. We then improve StreamVByte by introducing DotVByte, a new algorithm tailored to inner product computation. Experiments on MsMarco show that our improvements lead to significant space savings while maintaining retrieval efficiency.

</details>


### [69] [LMMRec: LLM-driven Motivation-aware Multimodal Recommendation](https://arxiv.org/abs/2602.05474)
*Yicheng Di,Zhanjie Zhang,Yun Wangc,Jinren Liue,Jiaqi Yanf,Jiyu Wei,Xiangyu Chend,Yuan Liu*

Main category: cs.IR

TL;DR: LMMRec是一个基于大语言模型的动机感知多模态推荐框架，通过链式思维提示提取细粒度动机，采用双编码器架构和对比学习实现跨模态对齐，在三个数据集上实现最高4.98%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统通常将动机视为交互数据中的潜在变量，忽略了评论文本等多模态信息。在多模态动机融合中存在两个关键挑战：1) 在噪声中实现稳定的跨模态对齐；2) 识别反映相同底层动机的跨模态特征。

Method: 提出LMMRec框架：1) 使用链式思维提示从文本中提取细粒度用户和物品动机；2) 采用双编码器架构分别建模文本动机和交互动机；3) 通过动机协调策略和交互-文本对应方法，利用对比学习和动量更新缓解噪声和语义漂移问题。

Result: 在三个数据集上的实验表明，LMMRec实现了最高4.98%的性能提升，验证了框架的有效性。

Conclusion: LMMRec通过大语言模型的语义先验和动机理解能力，有效解决了多模态动机融合中的对齐和特征识别问题，为动机感知推荐系统提供了新的解决方案。

Abstract: Motivation-based recommendation systems uncover user behavior drivers. Motivation modeling, crucial for decision-making and content preference, explains recommendation generation. Existing methods often treat motivation as latent variables from interaction data, neglecting heterogeneous information like review text. In multimodal motivation fusion, two challenges arise: 1) achieving stable cross-modal alignment amid noise, and 2) identifying features reflecting the same underlying motivation across modalities. To address these, we propose LLM-driven Motivation-aware Multimodal Recommendation (LMMRec), a model-agnostic framework leveraging large language models for deep semantic priors and motivation understanding. LMMRec uses chain-of-thought prompting to extract fine-grained user and item motivations from text. A dual-encoder architecture models textual and interaction-based motivations for cross-modal alignment, while Motivation Coordination Strategy and Interaction-Text Correspondence Method mitigate noise and semantic drift through contrastive learning and momentum updates. Experiments on three datasets show LMMRec achieves up to a 4.98\% performance improvement.

</details>


### [70] [GLASS: A Generative Recommender for Long-sequence Modeling via SID-Tier and Semantic Search](https://arxiv.org/abs/2602.05663)
*Shiteng Cao,Junda She,Ji Liu,Bin Zeng,Chengcheng Guo,Kuo Cai,Qiang Luo,Ruiming Tang,Han Li,Kun Gai,Zhiheng Li,Cheng Yang*

Main category: cs.IR

TL;DR: GLASS是一个生成式推荐系统框架，通过SID-Tier模块和语义硬搜索将长期用户兴趣整合到生成过程中，解决了传统方法在建模长历史序列时的挑战。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统虽然具有变革性潜力，但在有效建模长历史序列方面面临困难。传统检索模型在大规模物品空间中表现不佳，需要新的方法来利用长期用户行为模式提升推荐准确性。

Method: 1. 提出SID-Tier模块，将长期交互映射为统一兴趣向量来增强初始SID令牌预测；2. 引入语义硬搜索，使用生成的粗粒度语义ID作为动态键提取相关历史行为；3. 通过自适应门控融合模块重新校准后续细粒度令牌轨迹；4. 针对语义硬搜索中的数据稀疏问题，提出语义邻居增强和码本调整策略。

Result: 在TAOBAO-MM和KuaiRec两个大规模真实数据集上的实验表明，GLASS显著优于最先进的基线方法，在推荐质量上取得了显著提升。

Conclusion: GLASS通过有效整合长期用户兴趣到生成过程中，成功解决了生成式推荐系统在建模长历史序列时的挑战，为生成式推荐研究提供了新的方向和公开代码支持。

Abstract: Leveraging long-term user behavioral patterns is a key trajectory for enhancing the accuracy of modern recommender systems. While generative recommender systems have emerged as a transformative paradigm, they face hurdles in effectively modeling extensive historical sequences. To address this challenge, we propose GLASS, a novel framework that integrates long-term user interests into the generative process via SID-Tier and Semantic Search. We first introduce SID-Tier, a module that maps long-term interactions into a unified interest vector to enhance the prediction of the initial SID token. Unlike traditional retrieval models that struggle with massive item spaces, SID-Tier leverages the compact nature of the semantic codebook to incorporate cross features between the user's long-term history and candidate semantic codes. Furthermore, we present semantic hard search, which utilizes generated coarse-grained semantic ID as dynamic keys to extract relevant historical behaviors, which are then fused via an adaptive gated fusion module to recalibrate the trajectory of subsequent fine-grained tokens. To address the inherent data sparsity in semantic hard search, we propose two strategies: semantic neighbor augmentation and codebook resizing. Extensive experiments on two large-scale real-world datasets, TAOBAO-MM and KuaiRec, demonstrate that GLASS outperforms state-of-the-art baselines, achieving significant gains in recommendation quality. Our codes are made publicly available to facilitate further research in generative recommendation.

</details>


### [71] [Evaluating the impact of word embeddings on similarity scoring in practical information retrieval](https://arxiv.org/abs/2602.05734)
*Niall McCarroll,Kevin Curran,Eugene McNamee,Angela Clist,Andrew Brammer*

Main category: cs.IR

TL;DR: 本文提出一种基于Word Mover's Distance的查询相似度计算方法，结合预训练词向量，显著提升了信息检索的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统基于词向量质心的相似度计算方法无法充分捕捉查询的语义复杂性，需要更精细的相似度度量方法。

Method: 采用Word Mover's Distance模型，通过计算查询与回答中各个单词之间的距离来评估相似度，并结合GloVe等预训练词嵌入技术。

Result: WMD+GloVe组合在查询和回答语句的排序任务中表现最佳，显著优于Doc2Vec和LSA基线模型，实现了准确率的大幅提升。

Conclusion: 基于预训练词嵌入和WMD的相似度计算方法能够构建领域无关的语言处理解决方案，适用于多样化的商业应用场景。

Abstract: Search behaviour is characterised using synonymy and polysemy as users often want to search information based on meaning. Semantic representation strategies represent a move towards richer associative connections that can adequately capture this complex usage of language. Vector Space Modelling (VSM) and neural word embeddings play a crucial role in modern machine learning and Natural Language Processing (NLP) pipelines. Embeddings use distributional semantics to represent words, sentences, paragraphs or entire documents as vectors in high dimensional spaces. This can be leveraged by Information Retrieval (IR) systems to exploit the semantic relatedness between queries and answers.
  This paper evaluates an alternative approach to measuring query statement similarity that moves away from the common similarity measure of centroids of neural word embeddings. Motivated by the Word Movers Distance (WMD) model, similarity is evaluated using the distance between individual words of queries and statements. Results from ranked query and response statements demonstrate significant gains in accuracy using the combined approach of similarity ranking through WMD with the word embedding techniques. The top performing WMD + GloVe combination outperforms all other state-of-the-art retrieval models including Doc2Vec and the baseline LSA model. Along with the significant gains in performance of similarity ranking through WMD, we conclude that the use of pre-trained word embeddings, trained on vast amounts of data, result in domain agnostic language processing solutions that are portable to diverse business use-cases.

</details>


### [72] [Bagging-Based Model Merging for Robust General Text Embeddings](https://arxiv.org/abs/2602.05787)
*Hengran Zhang,Keping Bi,Jiafeng Guo,Jiaming Zhang,Wenbo Yang,Daiting Shi,Xueqi Cheng*

Main category: cs.IR

TL;DR: 该研究系统比较了文本嵌入模型的多任务训练策略，发现批级混洗效果最好但存在领域外泛化不足和增量学习成本高的问题，提出了基于Bagging的模型合并方法BOOM来提升鲁棒性和支持高效增量更新。


<details>
  <summary>Details</summary>
Motivation: 尽管通用文本嵌入模型广泛应用于NLP和信息检索，但多任务训练策略的实际效果对比不明确，且随着新领域和数据类型的不断涌现，如何高效适应嵌入模型仍存在挑战。

Method: 从数据调度和模型合并两个角度系统研究多任务训练：比较批级混洗、顺序训练变体、两阶段训练和多种合并粒度。提出Bagging-based rObust mOdel Merging (BOOM)，通过训练多个子集模型并合并来提高鲁棒性，同时支持通过训练轻量更新模型来实现高效增量学习。

Result: 实验表明批级混洗在整体性能上表现最好，但存在领域外泛化不足和增量学习成本高的问题。BOOM方法在多个嵌入基准测试中，相比全语料批级混洗，持续提升了领域内和领域外性能，同时在增量学习场景中显著降低了训练成本。

Conclusion: 虽然批级混洗是有效的多任务训练策略，但BOOM通过模型合并方法克服了其局限性，在保持推理效率的同时提高了鲁棒性和支持高效增量更新，为文本嵌入模型的持续适应提供了实用解决方案。

Abstract: General-purpose text embedding models underpin a wide range of NLP and information retrieval applications, and are typically trained on large-scale multi-task corpora to encourage broad generalization. However, it remains unclear how different multi-task training strategies compare in practice, and how to efficiently adapt embedding models as new domains and data types continually emerge. In this work, we present a systematic study of multi-task training for text embeddings from two perspectives: data scheduling and model merging. We compare batch-level shuffling, sequential training variants, two-stage training, and multiple merging granularities, and find that simple batch-level shuffling consistently yields the strongest overall performance, suggesting that task conflicts are limited and training datasets are largely complementary. Despite its effectiveness, batch-level shuffling exhibits two practical limitations: suboptimal out-of-domain (OOD) generalization and poor suitability for incremental learning due to expensive full retraining. To address these issues, we propose Bagging-based rObust mOdel Merging (\modelname), which trains multiple embedding models on sampled subsets and merges them into a single model, improving robustness while retaining single-model inference efficiency. Moreover, \modelname naturally supports efficient incremental updates by training lightweight update models on new data with a small historical subset and merging them into the existing model. Experiments across diverse embedding benchmarks demonstrate that \modelname consistently improves both in-domain and OOD performance over full-corpus batch-level shuffling, while substantially reducing training cost in incremental learning settings.

</details>


### [73] [AgenticTagger: Structured Item Representation for Recommendation with LLM Agents](https://arxiv.org/abs/2602.05945)
*Zhouhang Xie,Bo Peng,Zhankui He,Ziqi Chen,Alice Han,Isabella Ye,Benjamin Coleman,Noveen Sachdeva,Fernando Pereira,Julian McAuley,Wang-Cheng Kang,Derek Zhiyuan Cheng,Beidou Wang,Randolph Brown*

Main category: cs.IR

TL;DR: AgenticTagger是一个LLM驱动的描述符生成框架，通过词汇构建和分配两阶段，为推荐系统生成高质量、低基数、层次化的文本描述符。


<details>
  <summary>Details</summary>
Motivation: 高质量的表示对推荐系统至关重要，但现有的LLM描述符生成方法存在开放性问题：生成空间难以控制，导致描述符基数高、质量低，难以支持下游建模任务。

Method: 提出AgenticTagger框架，包含两个核心阶段：1)词汇构建阶段：通过多智能体反思机制，让架构LLM根据标注LLM的并行反馈迭代优化，构建层次化、低基数、高质量的描述符词汇表；2)词汇分配阶段：让LLM将词汇表中的描述符分配给具体项目。

Result: 在公开和私有数据上的实验表明，AgenticTagger在多种推荐场景中带来一致改进，包括生成式和基于术语的检索、排序，以及面向可控性的批判式推荐。

Conclusion: AgenticTagger通过控制生成空间和确保描述符质量，为推荐系统提供了有效的LLM驱动描述符生成解决方案，在各种下游应用中表现出色。

Abstract: High-quality representations are a core requirement for effective recommendation. In this work, we study the problem of LLM-based descriptor generation, i.e., keyphrase-like natural language item representation generation frameworks with minimal constraints on downstream applications. We propose AgenticTagger, a framework that queries LLMs for representing items with sequences of text descriptors. However, open-ended generation provides little control over the generation space, leading to high cardinality, low-performance descriptors that renders downstream modeling challenging. To this end, AgenticTagger features two core stages: (1) a vocabulary building stage where a set of hierarchical, low-cardinality, and high-quality descriptors is identified, and (2) a vocabulary assignment stage where LLMs assign in-vocabulary descriptors to items. To effectively and efficiently ground vocabulary in the item corpus of interest, we design a multi-agent reflection mechanism where an architect LLM iteratively refines the vocabulary guided by parallelized feedback from annotator LLMs that validates the vocabulary against item data. Experiments on public and private data show AgenticTagger brings consistent improvements across diverse recommendation scenarios, including generative and term-based retrieval, ranking, and controllability-oriented, critique-based recommendation.

</details>


### [74] [SAGE: Benchmarking and Improving Retrieval for Deep Research Agents](https://arxiv.org/abs/2602.05975)
*Tiansheng Hu,Yilun Zhao,Canyu Zhang,Arman Cohan,Chen Zhao*

Main category: cs.IR

TL;DR: 该论文提出SAGE基准测试，评估深度研究代理在科学文献检索中的表现，发现现有系统在处理推理密集型检索时表现不佳，传统BM25检索器优于LLM检索器，并提出基于LLM的文档增强框架提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 随着深度研究代理在处理复杂查询方面的能力增强，以及基于LLM的检索器在指令遵循和推理方面展现强大能力，研究者希望探究LLM检索器是否能在深度研究代理工作流中有效发挥作用，特别是在科学文献检索领域。

Method: 1. 构建SAGE基准测试：包含1,200个查询，覆盖四个科学领域，检索语料库包含20万篇论文；2. 评估六个深度研究代理系统；3. 以DR Tulu为骨干，比较BM25和LLM检索器（ReasonIR和gte-Qwen2-7B-instruct）的性能；4. 提出语料库级测试时扩展框架，使用LLM为文档添加元数据和关键词增强。

Result: 1. 所有深度研究代理系统在推理密集型检索任务上表现不佳；2. BM25检索器显著优于LLM检索器约30%，因为现有代理生成的关键词导向子查询更适合BM25；3. 提出的文档增强框架在短形式问题上带来8%的性能提升，在开放式问题上带来2%的性能提升。

Conclusion: 当前基于LLM的检索器在深度研究代理工作流中的表现不如传统BM25检索器，主要因为代理生成的关键词导向查询模式。通过LLM增强文档元数据可以提升检索性能，但需要进一步优化LLM检索器与深度研究代理的协同工作方式。

Abstract: Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000 paper retrieval corpus.We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e., ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.

</details>
