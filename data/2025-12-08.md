<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 29]
- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale](https://arxiv.org/abs/2512.05179)
*Aurélie Montfrond*

Main category: cs.CL

TL;DR: 本研究通过微调BERT模型，为利默里克大学电子与计算机工程系开发了一个课程信息问答聊天机器人，展示了基础模型在教育领域的适应可行性。


<details>
  <summary>Details</summary>
Motivation: 现有科学问答系统多为通用聊天机器人，缺乏针对特定教育领域（如大学课程材料）的专门化基础模型。本研究旨在填补这一空白，探索如何将基础模型适应到教育领域，为大学课程信息提供专门的问答能力。

Method: 构建了包含1,203个问答对的SQuAD格式自定义数据集，数据来源于大学课程手册，并辅以人工和合成生成的内容。使用PyTorch对BERT模型进行微调，采用精确匹配和F1分数作为评估指标。

Result: 结果显示，即使是适度的微调也能显著改善假设构建和知识提取能力。微调后的BERT模型在课程信息问答任务上表现有效，证明了将基础模型适应到教育领域的可行性。

Conclusion: 本研究展示了微调基础模型（如BERT）用于大学课程材料问答的有效性，为开发首个针对大学领域的领域特定问答模型奠定了基础，并有望推动自主教育知识系统的发展。

Abstract: Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated performance with Exact Match and F1 scores. Results show that even modest fine-tuning improves hypothesis framing and knowledge extraction, demonstrating the feasibility of adapting foundation models to educational domains. While domain-specific BERT variants such as BioBERT and SciBERT exist for biomedical and scientific literature, no foundation model has yet been tailored to university course materials. Our work addresses this gap by showing that fine-tuning BERT with academic QA pairs yields effective results, highlighting the potential to scale towards the first domain-specific QA model for universities and enabling autonomous educational knowledge systems.

</details>


### [2] [ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering](https://arxiv.org/abs/2512.05430)
*Daeyong Kwon,SeungHeon Doh,Juhan Nam*

Main category: cs.CL

TL;DR: MusWikiDB和ArtistMus：用于音乐问答的检索增强生成系统，显著提升LLMs在音乐领域的事实准确性和上下文推理能力


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在音乐相关推理方面效果有限，因为预训练数据中音乐知识稀疏。虽然音乐信息检索和计算音乐学已经探索了结构化和多模态理解，但缺乏基于艺术家元数据或历史背景的事实性和上下文音乐问答资源。

Method: 引入MusWikiDB（包含144K音乐相关维基百科页面的320万段落的向量数据库）和ArtistMus（包含500位多样化艺术家的1000个问题的基准测试，包含流派、出道年份等元数据）。使用检索增强生成（RAG）进行系统评估，并进行RAG风格的微调。

Result: RAG显著提高事实准确性：开源模型提升高达+56.8个百分点（如Qwen3 8B从35.0提升到91.8），接近专有模型性能。RAG风格微调进一步提升事实回忆和上下文推理能力。MusWikiDB相比通用维基百科语料库准确率提高约6个百分点，检索速度快40%。

Conclusion: MusWikiDB和ArtistMus为音乐信息检索和领域特定问答研究提供了基础，建立了在音乐等文化丰富领域中检索增强推理的框架，并公开发布这些资源以推动相关研究发展。

Abstract: Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.

</details>


### [3] [Unveiling Affective Polarization Trends in Parliamentary Proceedings](https://arxiv.org/abs/2512.05231)
*Gili Goldin,Ella Rabinovich,Shuly Wintner*

Main category: cs.CL

TL;DR: 提出基于情感风格而非意识形态立场的新型极化量化方法，应用于以色列议会语料库，发现政府与反对派情感风格差异且情感极化随时间显著增强


<details>
  <summary>Details</summary>
Motivation: 近年来全球极化言论增多，现有方法多基于意识形态立场差异，需要更直接的情感风格量化方法来衡量情感极化

Method: 使用效价、唤醒度和支配度三个情感维度检测情感话语信号，以此操作化情感极化概念，应用于以色列议会（希伯来语）最新语料库

Result: 政府成员与反对派成员的情感风格存在差异，基于情感风格的情感极化水平随时间显著增加

Conclusion: 基于情感风格的极化量化方法有效，情感极化在政治话语中日益严重，该方法为理解政治极化提供了新视角

Abstract: Recent years have seen an increase in polarized discourse worldwide, on various platforms. We propose a novel method for quantifying polarization, based on the emotional style of the discourse rather than on differences in ideological stands. Using measures of Valence, Arousal and Dominance, we detect signals of emotional discourse and use them to operationalize the concept of affective polarization. Applying this method to a recently released corpus of proceedings of the Knesset, the Israeli parliament (in Hebrew), we find that the emotional style of members of government differs from that of opposition members; and that the level of affective polarization, as reflected by this style, is significantly increasing with time.

</details>


### [4] [Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting](https://arxiv.org/abs/2512.05243)
*P. D. Edgar,Alia Hall*

Main category: cs.CL

TL;DR: 诗歌提示模式可作为提示工程的有用工具，用于评估LLM的创造性和改编倾向


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索诗歌提示模式作为提示工程工具的价值，并评估LLM对著名诗人作品的描述、评价以及改编原创创意作品的意愿

Method: 提出诗歌提示模式作为提示工程方法，使用诗歌提示评估三个著名诗人模型，测试模型为预设受众改编或重写原创创意作品的意愿

Result: 诗歌提示模式被证明是提示工程师工具箱的有用补充，可用于评估LLM的算法倾向和偏见，特别是对创意作品的描述、评价和改编能力

Conclusion: 创造性文本提示，特别是诗歌提示模式，为研究LLM的创造性和改编能力提供了有价值的工具，有助于理解模型如何对待和处理原创创意作品

Abstract: Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.

</details>


### [5] [Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4](https://arxiv.org/abs/2512.05256)
*Ivan Makohon,Mohamad Najafi,Jian Wu,Mathias Brochhausen,Yaohang Li*

Main category: cs.CL

TL;DR: 该研究提出了一种结合思维链、语义搜索和知识图谱的提示工程技术，用于改进大型语言模型生成临床笔记的质量。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据激增，但医生手动撰写临床笔记耗时巨大，增加了患者等待时间并可能延误诊断。大型语言模型具有生成类似人类文本的能力，但需要改进其在临床领域的应用。

Method: 使用思维链提示工程，结合国际疾病分类代码和基本患者信息作为输入。将传统思维链与语义搜索结果结合，并注入基于临床本体构建的知识图谱，以丰富领域特定知识。

Result: 在CodiEsp测试数据集的六个临床案例上使用GPT-4测试，该提示技术优于标准单样本提示生成的临床笔记。

Conclusion: 结合思维链、语义搜索和知识图谱的提示工程技术能有效提高大型语言模型生成临床笔记的质量，为自动化临床文档提供了有前景的方法。

Abstract: In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts.

</details>


### [6] [To Think or Not to Think: The Hidden Cost of Meta-Training with Excessive CoT Examples](https://arxiv.org/abs/2512.05318)
*Vignesh Kothapalli,Ata Fatahibaarzi,Hamed Firooz,Maziar Sanjabi*

Main category: cs.CL

TL;DR: CoT-Recipe：通过元训练中调节CoT与非CoT示例比例，提升LLM在新颖任务上的推理能力，即使上下文没有CoT示例也能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 虽然CoT提示结合少样本上下文学习能解锁LLM的推理能力，但在预训练知识不足的新任务上效果不佳。研究发现元训练中过多包含CoT示例会降低性能，需要平衡CoT与非CoT示例。

Method: 提出CoT-Recipe方法，在元训练序列中正式调节CoT与非CoT示例的混合比例。使用CoT-ICL Lab框架进行控制实验，并在预训练LLM（Qwen2.5系列）的符号推理任务上验证。

Result: CoT-Recipe能将transformer在新任务上的准确率提升高达300%（即使上下文没有CoT示例）。在预训练LLM的符号推理任务上观察到准确率提升高达130%。

Conclusion: 通过CoT-Recipe调节元训练中CoT与非CoT示例的比例，能显著提升LLM在新颖任务上的推理能力，为解决预训练知识不足时的推理问题提供了有效方法。

Abstract: Chain-of-thought (CoT) prompting combined with few-shot in-context learning (ICL) has unlocked significant reasoning capabilities in large language models (LLMs). However, ICL with CoT examples is ineffective on novel tasks when the pre-training knowledge is insufficient. We study this problem in a controlled setting using the CoT-ICL Lab framework, and propose meta-training techniques to learn novel abstract reasoning tasks in-context. Although CoT examples facilitate reasoning, we noticed that their excessive inclusion during meta-training degrades performance when CoT supervision is limited. To mitigate such behavior, we propose CoT-Recipe, a formal approach to modulate the mix of CoT and non-CoT examples in meta-training sequences. We demonstrate that careful modulation via CoT-Recipe can increase the accuracy of transformers on novel tasks by up to 300% even when there are no CoT examples available in-context. We confirm the broader effectiveness of these techniques by applying them to pretrained LLMs (Qwen2.5 series) for symbolic reasoning tasks and observing gains of up to 130% in accuracy.

</details>


### [7] [LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning](https://arxiv.org/abs/2512.05325)
*Ömer Faruk Akgül,Yusuf Hakan Kalaycı,Rajgopal Kannan,Willie Neiswanger,Viktor Prasanna*

Main category: cs.CL

TL;DR: LYNX是一种在线早期退出机制，利用模型隐藏状态意识进行置信度控制的停止决策，显著减少推理计算量同时保持或提高准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型经常"过度思考"：在已有足够信息回答问题后仍继续推理，浪费推理计算资源并可能损害准确性。现有早期停止方法要么需要额外采样和启发式方法，要么依赖辅助验证模型，要么仅作为事后分析流程而没有形式化保证。

Method: LYNX将退出决策附加到自然出现的推理线索（如"hmm"、"wait"）上，在这些线索标记处使用隐藏状态训练轻量级探针，监督来自强制退出，并使用分割共形预测包装得到的分数以获得对过早退出的分布无关控制。该方法只需在通用数学语料上训练和校准一次探针，即可跨基准、解码温度甚至非数学任务重用。

Result: 在1.5B到32B参数的三个模型系列上，每个基础模型使用单个数学训练的探针产生强大的准确性-效率权衡：在GSM8K上匹配或提高基线准确性同时减少40-65%的标记；在MATH-500上提高准确性达12个百分点同时减少35-60%的标记；在AIME 2024上恢复基线准确性同时节省超过50%的标记；在非数学基准CommonsenseQA上零样本转移，准确性略有提高同时减少高达70%的标记。

Conclusion: LYNX相比最先进的早期退出方法提供竞争性或更优的帕累托前沿，同时保持完全在线，推理时不需要代理模型，并提供明确的用户可调置信度保证。

Abstract: Large reasoning models achieve strong performance on complex tasks by generating extended chains of thought, but they often "overthink": continuing to reason long after they have enough information to answer correctly. This wastes inference-time compute and can hurt accuracy. Existing attempts to stop early either manipulate decoding with extra sampling and heuristics, rely on auxiliary verifier models, or operate only as post-hoc analysis pipelines without formal guarantees. We introduce LYNX, an online early-exit mechanism that turns a model's own hidden-state awareness into confidence-controlled stopping decisions. LYNX attaches exit decisions to naturally occurring reasoning cues (e.g., "hmm", "wait") during generation, trains a lightweight probe on hidden states at those cue tokens using supervision from forced exits, and wraps the resulting scores in split conformal prediction to obtain distribution-free control over premature exits. Crucially, we train and calibrate this probe once on a generic mathematical corpus and reuse it unchanged across benchmarks, decoding temperatures, and even non-mathematical tasks. Across three model families spanning 1.5B to 32B parameters, a single mathematically trained probe per base model yields strong accuracy--efficiency tradeoffs. On GSM8K, LYNX matches or improves baseline accuracy while reducing tokens by 40--65\%; on MATH-500 it improves accuracy by up to 12 points with roughly 35--60\% fewer tokens; on AIME 2024 it recovers baseline accuracy with more than 50\% token savings; and on CommonsenseQA, a non-math benchmark, it transfers zero-shot with modest accuracy gains and up to 70\% fewer tokens. Compared to state-of-the-art early-exit methods, LYNX offers competitive or superior Pareto frontiers while remaining fully online, requiring no proxy models at inference, and providing explicit, user-tunable confidence guarantees.

</details>


### [8] [Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection Against LLM-Generated Threats](https://arxiv.org/abs/2512.05331)
*Sadat Shahriar,Navid Ayoobi,Arjun Mukherjee,Mostafa Musharrat,Sai Vishnu Vamsi*

Main category: cs.CL

TL;DR: 该研究分析了粉红粘液新闻的特征，揭示了LLM对抗性攻击对检测系统的威胁，并提出了一个鲁棒的学习框架来抵御此类攻击。


<details>
  <summary>Details</summary>
Motivation: 粉红粘液新闻作为低质量、自动生成的内容，模仿合法地方新闻报道，威胁着为2800万美国人提供可靠信息的本地新闻生态。需要精细分析其语言、风格和词汇特征来检测这些欺骗性文章。

Method: 进行了全面研究以揭示粉红粘液内容的区分模式，并基于这些洞察提出检测策略。特别关注LLM对抗性攻击这一新威胁向量，并设计了一个专门抵抗LLM对抗性攻击的鲁棒学习框架。

Result: 研究发现即使是消费者可访问的LLM也能显著削弱现有检测系统，使其F1分数性能下降高达40%。提出的鲁棒学习框架能够抵抗LLM对抗性攻击，性能提升高达27%。

Conclusion: 粉红粘液新闻检测面临LLM对抗性攻击的新挑战，需要专门设计的鲁棒框架来应对不断演变的自动化粉红粘液新闻威胁，以保护本地新闻生态系统的完整性。

Abstract: The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive articles requires a fine-grained analysis of their linguistic, stylistic, and lexical characteristics. In this work, we conduct a comprehensive study to uncover the distinguishing patterns of Pink Slime content and propose detection strategies based on these insights. Beyond traditional generation methods, we highlight a new adversarial vector: modifications through large language models (LLMs). Our findings reveal that even consumer-accessible LLMs can significantly undermine existing detection systems, reducing their performance by up to 40% in F1-score. To counter this threat, we introduce a robust learning framework specifically designed to resist LLM-based adversarial attacks and adapt to the evolving landscape of automated pink slime journalism, and showed and improvement by up to 27%.

</details>


### [9] [Transformer-Enabled Diachronic Analysis of Vedic Sanskrit: Neural Methods for Quantifying Types of Language Change](https://arxiv.org/abs/2512.05364)
*Ananth Hariharan,David Mortensen*

Main category: cs.CL

TL;DR: 该研究使用混合神经符号方法分析梵语2000多年的演变，挑战了语言变化是简化的假设，发现梵语形态复杂性并未减少而是动态重新分布。


<details>
  <summary>Details</summary>
Motivation: 挑战语言变化是简化的朴素假设，为形态丰富、资源匮乏的语言演化提供新的定量分析视角，解决数据稀缺问题。

Method: 采用弱监督混合方法：使用100多个高精度正则表达式生成伪标签来微调多语言BERT，通过新颖的置信度加权集成融合符号和神经输出。

Result: 在147万词历时语料库中，集成系统实现52.4%的特征检测率。发现梵语整体形态复杂性未减少而是动态重新分布：早期动词特征呈周期性下降，复杂性转移到其他领域，表现为复合词显著扩展和新哲学术语出现。系统产生良好校准的不确定性估计，置信度与准确性强相关（Pearson r=0.92），校准误差低（ECE=0.043）。

Conclusion: 混合神经符号方法能为形态丰富、资源匮乏的语言演化提供可扩展且可解释的新见解，梵语的形态复杂性并未简化而是重新分布，为计算文献学提供了可靠的分析框架。

Abstract: This study demonstrates how hybrid neural-symbolic methods can yield significant new insights into the evolution of a morphologically rich, low-resource language. We challenge the naive assumption that linguistic change is simplification by quantitatively analyzing over 2,000 years of Sanskrit, demonstrating how weakly-supervised hybrid methods can yield new insights into the evolution of morphologically rich, low-resource languages. Our approach addresses data scarcity through weak supervision, using 100+ high-precision regex patterns to generate pseudo-labels for fine-tuning a multilingual BERT. We then fuse symbolic and neural outputs via a novel confidence-weighted ensemble, creating a system that is both scalable and interpretable. Applying this framework to a 1.47-million-word diachronic corpus, our ensemble achieves a 52.4% overall feature detection rate. Our findings reveal that Sanskrit's overall morphological complexity does not decrease but is instead dynamically redistributed: while earlier verbal features show cyclical patterns of decline, complexity shifts to other domains, evidenced by a dramatic expansion in compounding and the emergence of new philosophical terminology. Critically, our system produces well-calibrated uncertainty estimates, with confidence strongly correlating with accuracy (Pearson r = 0.92) and low overall calibration error (ECE = 0.043), bolstering the reliability of these findings for computational philology.

</details>


### [10] [Mitigating Self-Preference by Authorship Obfuscation](https://arxiv.org/abs/2512.05379)
*Taslim Mahbub,Shi Feng*

Main category: cs.CL

TL;DR: 通过扰动候选答案来模糊作者身份，减少语言模型评委识别自身输出的能力，从而缓解自我偏好偏见，但完全消除偏见仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 语言模型评委在评估中表现出自我偏好偏见，即倾向于选择自己生成的答案而非其他模型或人类的答案。这种偏见难以消除，因为前沿语言模型评委即使在没有标注来源的情况下也能识别自己的输出。

Method: 采用黑盒扰动方法，在成对比较中对评估候选答案进行扰动以模糊作者身份。具体使用简单的同义词替换等扰动技术，减少模型识别自身输出的能力。

Result: 简单的扰动（如替换少量词语的同义词）能够可预测地减少自我偏好。但当将扰动外推至更彻底地消除候选答案之间的风格差异时，自我偏好会重新出现，表明自我识别和自我偏好可能发生在多个语义层面。

Conclusion: 虽然初步结果令人鼓舞，但完全缓解语言模型评委的自我偏好偏见仍然具有挑战性，因为自我识别和自我偏好可能发生在多个语义层面，难以完全消除。

Abstract: Language models (LMs) judges are widely used to evaluate the quality of LM outputs. Despite many advantages, LM judges display concerning biases that can impair their integrity in evaluations. One such bias is self-preference: LM judges preferring their own answers over those produced by other LMs or humans. The bias is hard to eliminate as frontier LM judges can distinguish their own outputs from those of others, even when the evaluation candidates are not labeled with their sources. In this paper, we investigate strategies to mitigate self-preference by reducing the LM judges' ability to recognize their own outputs. We apply black-box perturbations to evaluation candidates in pairwise comparison to obfuscate the authorship and reduce self-recognition. We find that perturbations as simple as synonym replacement for a few words predictably reduce self-preference. However, we also uncover fundamental challenges to eliminating the bias: when we extrapolate our perturbations to a more complete neutralization of stylistic differences between the evaluation candidates, self-preference recovers. Our findings suggest that self-recognition and self-preference can happen on many semantic levels, and complete mitigation remains challenging despite promising initial results.

</details>


### [11] [Learning from Self Critique and Refinement for Faithful LLM Summarization](https://arxiv.org/abs/2512.05387)
*Ting-Yao Hu,Hema Swetha Koppula,Hadi Pouransari,Cem Koc,Oncel Tuzel,Raviteja Vemulapalli*

Main category: cs.CL

TL;DR: SCRPO：一种自监督训练框架，通过利用LLM自身的批判和精炼能力构建偏好数据集，然后应用偏好学习来提升同一LLM在摘要生成中的忠实度。


<details>
  <summary>Details</summary>
Motivation: LLM在长文本生成任务（如摘要）中经常出现幻觉问题。现有方法通过迭代批判和精炼来减少幻觉，但要么需要额外的推理时间计算，要么需要更强大的教师模型，导致成本高且不实用。

Method: 提出SCRPO框架：1）利用LLM自身的批判和精炼能力构建偏好数据集；2）应用偏好学习来训练同一LLM，提升其在摘要生成中的忠实度。

Result: 在三个摘要基准测试（XSUM、CNNDM和SAMSum）上，SCRPO在忠实度指标上优于最先进的自监督学习方法，同时保持或改进了衡量摘要整体质量的其他指标。相比推理时精炼方法，SCRPO不仅效率更高，而且生成更忠实的摘要。

Conclusion: SCRPO提供了一种有效且实用的自监督训练方法，能够显著减少LLM在摘要生成中的幻觉问题，同时保持或提升摘要的整体质量，且不需要额外的推理时间计算或更强大的教师模型。

Abstract: Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced by iteratively critiquing and refining previously generated outputs using either the same model or a more powerful teacher model as the critique. However, these approaches either require additional test-time compute or assume access to more powerful teacher models, making them costly and less practical. In this work, we propose Self Critique and Refinement-based Preference Optimization (SCRPO), which is a self-supervised training framework that first constructs a preference dataset by leveraging the LLM's own critique and refinement capabilities, and then applies preference learning to improve the same LLM for faithful summarization. Experiments on three summarization benchmarks (XSUM CNNDM and SAMSum), demonstrate that our approach outperforms state-of-the-art self-supervised learning methods in terms of faithfulness metrics while either maintaining or improving other metrics that measure the overall quality of the summary. Moreover, compared to test-time refinement, our approach not only improves efficiency but also results in more faithful summaries.

</details>


### [12] [SQ-format: A Unified Sparse-Quantized Hardware-friendly Data Format for LLMs](https://arxiv.org/abs/2512.05409)
*Ruixuan Huang,Hao Zeng,Hantao Huang,Jinyuan Shi,Minghui Yu,Ian En-Hsu Yen,Shuai Wang*

Main category: cs.CL

TL;DR: 提出SQ-format统一数据格式，通过结合稀疏化和量化实现性能与吞吐量的帕累托改进，特别适合具有离群值分布的激活张量。


<details>
  <summary>Details</summary>
Motivation: 现有低比特量化和稀疏化技术由于硬件支持有限，难以平衡准确性和效率。例如W4A8只能达到与W8A8相同的峰值TOPS，而GPU支持的稀疏数据格式(2:4半结构化稀疏)由于精度损失很少被采用。

Method: 提出稀疏量化格式(SQ-format)，这是一种统一的数据格式，利用稀疏矩阵可以在高精度下加速，而低精度矩阵乘法也可以相应加速的事实。该格式特别适合具有离群值不平等状态的激活张量，使其静态压缩成为可能。

Result: 展示了SQ-format在PTQ上的最先进性能，提出了支持该格式所需的硬件要求，并为下一代AI加速器提供了设计探索和见解。

Conclusion: SQ-format为量化和稀疏化提供了一个统一的硬件友好数据格式，实现了性能与吞吐量的帕累托改进，为下一代AI加速器设计提供了新方向。

Abstract: Post-training quantization (PTQ) plays a crucial role in the democratization of large language models (LLMs). However, existing low-bit quantization and sparsification techniques are difficult to balance accuracy and efficiency due to the limited hardware support. For example, W4A8 can only achieve the same peak TOPS as W8A8 whereas the GPU-supported sparse data format (2:4 semi-structure sparse) is seldomly adopted due to the loss of accuracy. To bridge this gap, in this paper, we propose the Sparse-Quantized Format (SQ-format), which is a unified data format for quantization and sparsification potentially easily supported by new hardware and existing GPUs. SQ-format makes use of the fact that sparse matrix can be accelerated in high-precision, and low-precision matrix multiplication can also be accelerated accordingly. As such, SQ-format is proposed to achieve Pareto improvement between performance and throughput. This format is particularly suitable for activations with outlier inequality status and makes their static compression possible. We show the state-of-the-art PTQ performance with SQ-format, propose the hardware required to support it, and further offer the design exploration and insights for the next-generation AI accelerators.

</details>


### [13] [LMSpell: Neural Spell Checking for Low-Resource Languages](https://arxiv.org/abs/2512.05414)
*Akesh Gunathilakea,Nadil Karunarathnea,Tharusha Bandaranayakea,Nisansa de Silvaa,Surangika Ranathunga*

Main category: cs.CL

TL;DR: 首个关于预训练语言模型在拼写纠正中有效性的实证研究，特别关注低资源语言，发现大语言模型在微调数据量大时表现最佳，并发布了LMSpell工具包。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的拼写纠正仍然是一个挑战性问题。虽然预训练语言模型已被用于拼写纠正，但其应用仍局限于少数语言，且缺乏跨模型的系统比较。

Method: 进行首个关于预训练语言模型在拼写纠正中有效性的实证研究，包括低资源语言。比较不同类型的PLMs（编码器、编码器-解码器、大语言模型），并开发LMSpell工具包，包含评估函数以补偿LLMs的幻觉问题。

Result: 发现大语言模型在微调数据集较大时优于其他模型（编码器基和编码器-解码器模型），即使对于LLM未预训练的语言也是如此。通过僧伽罗语的案例研究揭示了低资源语言拼写纠正的困境。

Conclusion: LLMs在拼写纠正任务中具有优势，特别是在数据充足的情况下。LMSpell工具包为研究人员提供了跨PLMs的易用拼写纠正解决方案，并解决了LLMs的幻觉问题。低资源语言的拼写纠正仍需要更多关注和研究。

Abstract: Spell correction is still a challenging problem for low-resource languages (LRLs). While pretrained language models (PLMs) have been employed for spell correction, their use is still limited to a handful of languages, and there has been no proper comparison across PLMs. We present the first empirical study on the effectiveness of PLMs for spell correction, which includes LRLs. We find that Large Language Models (LLMs) outperform their counterparts (encoder-based and encoder-decoder) when the fine-tuning dataset is large. This observation holds even in languages for which the LLM is not pre-trained. We release LMSpell, an easy- to use spell correction toolkit across PLMs. It includes an evaluation function that compensates for the hallucination of LLMs. Further, we present a case study with Sinhala to shed light on the plight of spell correction for LRLs.

</details>


### [14] [Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment](https://arxiv.org/abs/2512.05464)
*Panatchakorn Anantaprayoon,Nataliia Babina,Jad Tarifi,Nima Asgharbeygi*

Main category: cs.CL

TL;DR: 提出Collective Agency作为更全面的对齐价值，并设计Dynamic Alignment框架实现LLM的自我迭代对齐


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法基于人类偏好或预设原则（如帮助性、诚实性、无害性），但随着AI向AGI/ASI发展，这些价值体系可能不足。人类反馈对齐资源密集且难以扩展，而AI反馈的自改进对齐方法仍局限于传统对齐价值。

Method: 提出Collective Agency作为统一开放的对齐价值，鼓励综合智能体能力。设计Dynamic Alignment框架，包含两个关键组件：1）使用LLM自动生成训练数据集；2）自奖励机制，策略模型评估自身输出候选并为GRPO学习分配奖励。

Result: 实验结果表明，该方法成功将模型对齐到Collective Agency，同时保留一般NLP能力。

Conclusion: 研究探索了更全面的对齐目标和可扩展的自改进对齐方法，为超越传统对齐规范提供了新方向。

Abstract: Large Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.

</details>


### [15] [SEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures](https://arxiv.org/abs/2512.05501)
*Panuthep Tasawong,Jian Gang Ngui,Alham Fikri Aji,Trevor Cohn,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: SEA-SafeguardBench：首个东南亚语言安全基准，包含8种语言、21,640个人工验证样本，揭示现有LLM在东南亚文化安全场景中的不足


<details>
  <summary>Details</summary>
Motivation: 当前安全模型评估主要关注英语，缺乏对语言和文化多样性的考虑。东南亚语言在安全基准中代表性不足，但该地区有独特的文化敏感性和安全关切（如政治言论、地区性虚假信息）。现有基准多依赖机器翻译的英语数据，无法捕捉低资源语言的细微差别。

Method: 创建SEA-SafeguardBench基准，包含8种东南亚语言，21,640个人工验证样本，分为三个子集：通用安全场景、真实环境样本、内容生成场景。所有样本均为本地原生创作，反映当地规范和安全场景。

Result: 实验结果显示，即使是当前最先进的LLM和安全防护系统，在东南亚文化安全场景中也面临挑战，表现明显低于处理英语文本时的水平。

Conclusion: 需要针对特定语言和文化背景开发更有效的安全防护系统，SEA-SafeguardBench为评估和改进东南亚语言安全模型提供了重要基准。

Abstract: Safeguard models help large language models (LLMs) detect and block harmful content, but most evaluations remain English-centric and overlook linguistic and cultural diversity. Existing multilingual safety benchmarks often rely on machine-translated English data, which fails to capture nuances in low-resource languages. Southeast Asian (SEA) languages are underrepresented despite the region's linguistic diversity and unique safety concerns, from culturally sensitive political speech to region-specific misinformation. Addressing these gaps requires benchmarks that are natively authored to reflect local norms and harm scenarios. We introduce SEA-SafeguardBench, the first human-verified safety benchmark for SEA, covering eight languages, 21,640 samples, across three subsets: general, in-the-wild, and content generation. The experimental results from our benchmark demonstrate that even state-of-the-art LLMs and guardrails are challenged by SEA cultural and harm scenarios and underperform when compared to English texts.

</details>


### [16] [Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches](https://arxiv.org/abs/2512.05537)
*Namu Park,Farzad Ahmed,Zhaoyi Sun,Kevin Lybarger,Ethan Breinhorst,Julie Hu,Ozlem Uzuner,Martin Gunn,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 生成式大语言模型通过病灶标记和解剖学提示，在放射学报告中检测需要随访的偶发瘤方面，显著优于传统监督学习方法，性能接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 当前基于文档级别的分类系统在检测需要随访的偶发瘤方面存在局限性，需要更细粒度的病灶级别检测方法。

Method: 使用400份标注的放射学报告（包含1,623个已验证的病灶发现），比较三种监督式transformer编码器（BioClinicalModernBERT、ModernBERT、Clinical Longformer）与四种生成式LLM配置（Llama 3.1-8B、GPT-4o、GPT-OSS-20b）。引入使用病灶标记输入和解剖学感知提示的新推理策略来增强模型推理能力。

Result: 解剖学感知的GPT-OSS-20b模型表现最佳，偶发瘤阳性macro-F1达到0.79，超过所有监督基线（最高macro-F1：0.70），接近0.76的标注者间一致性。解剖学基础显著提升GPT模型性能（p<0.05），多数投票集成进一步将macro-F1提升至0.90。

Conclusion: 增强结构化病灶标记和解剖学上下文的生成式LLM显著优于传统监督编码器，性能与人类专家相当，为放射学工作流程中的自动化偶发发现监测提供了可靠、可解释的途径。

Abstract: Objective: To evaluate large language models (LLMs) against supervised baselines for fine-grained, lesion-level detection of incidentalomas requiring follow-up, addressing the limitations of current document-level classification systems.
  Methods: We utilized a dataset of 400 annotated radiology reports containing 1,623 verified lesion findings. We compared three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b). We introduced a novel inference strategy using lesion-tagged inputs and anatomy-aware prompting to ground model reasoning. Performance was evaluated using class-specific F1-scores.
  Results: The anatomy-informed GPT-OSS-20b model achieved the highest performance, yielding an incidentaloma-positive macro-F1 of 0.79. This surpassed all supervised baselines (maximum macro-F1: 0.70) and closely matched the inter-annotator agreement of 0.76. Explicit anatomical grounding yielded statistically significant performance gains across GPT-based models (p < 0.05), while a majority-vote ensemble of the top systems further improved the macro-F1 to 0.90. Error analysis revealed that anatomy-aware LLMs demonstrated superior contextual reasoning in distinguishing actionable findings from benign lesions.
  Conclusion: Generative LLMs, when enhanced with structured lesion tagging and anatomical context, significantly outperform traditional supervised encoders and achieve performance comparable to human experts. This approach offers a reliable, interpretable pathway for automated incidental finding surveillance in radiology workflows.

</details>


### [17] [Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems](https://arxiv.org/abs/2512.05580)
*Aurprita Mahmood,Sabrin alam,Neloy kumer Sagor,Md. Abdul Hadi,Md. Sehab Al Islam,Minhajul Islam*

Main category: cs.CL

TL;DR: 本文系统研究了Tree-of-Thought推理在孟加拉语数学应用题上的应用，发现ToT相比CoT能进一步提升性能，在GPT-OSS-120B上达到88%准确率。


<details>
  <summary>Details</summary>
Motivation: 数学应用题是NLP中最具挑战性的任务之一，需要语言理解和多步数值推理。虽然Chain-of-Thought提示已显示出潜力，但其线性结构容易传播错误，限制了整体效果。

Method: 使用SOMADHAN数据集，在计算和token成本约束下，选取100个代表性孟加拉语数学应用题，在多个大语言模型（包括GPT-OSS和LLaMA变体）上评估标准提示、CoT和ToT策略。

Result: CoT将基线准确率从78%（标准提示）提升到平均83%，而ToT进一步将性能提升高达5个百分点，在GPT-OSS-120B上达到88%准确率。ToT在中大型模型中特别有效，但对较小模型优势较小。

Conclusion: ToT是解决低资源语言（如孟加拉语）数学问题的稳健框架。结构化推理方法如ToT能提供比CoT更可靠和全局一致的结果，为多语言NLP中更好的推理策略铺平道路。

Abstract: Mathematical Word Problems (MWPs) are among the most challenging tasks in natural language processing because they require both linguistic understanding and multi-step numerical reasoning. While Chain-of-Thought (CoT) prompting has shown promise, its linear structure often propagates errors, limiting overall effectiveness. To address this limitation, we present the a systematic study of Tree-of-Thought (ToT) reasoning for Bengali MWPs using the SOMADHAN dataset. Owing to computational and token-cost constraints, we evaluate a curated set of 100 representative problems across multiple large language models (LLMs), including GPT-OSS and LLaMA variants, under standard prompting, CoT, and ToT strategies. Our results show that CoT improves baseline accuracy from 78% (standard prompting) to 83% on average, while ToT further increases performance by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B. These improvements highlight that ToT is particularly effective in medium-to-large-scale models but may offer less advantage for smaller ones. Overall, our findings establish ToT as a robust framework for solving mathematical problems in low-resource languages such as Bengali. More broadly, this study shows that structured reasoning methods like ToT can provide more reliable and globally consistent outcomes than CoT, paving the way for better reasoning strategies in multilingual NLP.

</details>


### [18] [A Greek Government Decisions Dataset for Public-Sector Analysis and Insight](https://arxiv.org/abs/2512.05647)
*Giorgos Antoniou,Giorgos Filandrianos,Aggelos Vlachos,Giorgos Stamou,Lampros Kollimenos,Konstantinos Skianis,Michalis Vazirgiannis*

Main category: cs.CL

TL;DR: 构建了一个包含100万份希腊政府决策的开放机器可读语料库，包含高质量原始文本和可复现的提取流程，并设计了RAG任务评估系统检索和推理能力。


<details>
  <summary>Details</summary>
Motivation: 利用希腊国家透明度平台Diavgeia的政府决策数据，创建大规模公共部门语料库，支持高级信息访问和透明度，为语言模型提供高质量训练数据。

Method: 从Diavgeia平台提取100万份政府决策，开发可复现的PDF文本提取流程，将原始文本转换为Markdown格式，设计RAG任务并创建代表性问题和高质量答案。

Result: 成功构建了大规模希腊政府决策语料库，设计了RAG评估任务，展示了系统能够检索和推理政府文档，为语言模型训练提供高质量专业数据。

Conclusion: 大规模公共部门语料库有潜力通过结构化检索和推理支持高级信息访问，可作为专业领域语言模型的训练数据，并讨论了局限性和未来方向。

Abstract: We introduce an open, machine-readable corpus of Greek government decisions sourced from the national transparency platform Diavgeia. The resource comprises 1 million decisions, featuring and high-quality raw text extracted from PDFs. It is released with raw extracted text in Markdown format, alongside a fully reproducible extraction pipeline. Beyond the core dataset, we conduct qualitative analyses to explore boilerplate patterns and design a retrieval-augmented generation (RAG) task by formulating a set of representative questions, creating high-quality answers, and evaluating a baseline RAG system on its ability to retrieve and reason over public decisions. This evaluation demonstrates the potential of large-scale public-sector corpora to support advanced information access and transparency through structured retrieval and reasoning over governmental documents, and highlights how such a RAG pipeline could simulate a chat-based assistant capable of interactively answering questions about public decisions. Due to its scale, quality, and domain coverage, the corpus can also serve as high-value pre-training or fine-tuning material for new Language Models (LMs) and Large Language Models (LLMs) respectively, including specialized models for legal and governmental domains, and as a foundation for novel approaches in domain adaptation, knowledge-grounded generation, and explainable AI. Finally, we discuss limitations, outline future directions, and make both the data and the code accessible.

</details>


### [19] [Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models](https://arxiv.org/abs/2512.05658)
*Pietro Ferrazzi,Aitor Soroa,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 该研究提出了一种生成基于医学事实的多语言推理轨迹的方法，通过检索增强生成技术创建了50万条英语、意大利语和西班牙语的医学推理轨迹，用于提升LLMs在医学问答中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有医学问答方法主要依赖英语，且大多通过蒸馏通用LLMs获得，这引发了对其医学知识可靠性的担忧。需要开发基于事实医学知识的多语言推理方法。

Method: 使用检索增强生成方法，基于维基百科医学信息生成多语言推理轨迹。将MedQA和MedMCQA数据集扩展到意大利语和西班牙语，生成50万条英语、意大利语和西班牙语的推理轨迹。

Result: 在医学QA基准测试中，无论是域内还是域外设置，推理轨迹通过上下文学习（few-shot）和监督微调都能提升性能，在8B参数LLMs中达到最先进结果。

Conclusion: 该方法支持开发更安全、更透明的多语言临床决策支持工具。研究团队发布了完整资源套件：推理轨迹、翻译的QA数据集、Medical-Wikipedia和微调模型。

Abstract: Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.

</details>


### [20] [Interleaved Latent Visual Reasoning with Selective Perceptual Modeling](https://arxiv.org/abs/2512.05665)
*Shuai Dong,Siyuan Wang,Xingyu Liu,Zhongyu Wei*

Main category: cs.CL

TL;DR: ILVR框架通过交错潜在视觉表示与文本生成，解决了多模态大语言模型中视觉重编码计算成本高的问题，实现了精确感知建模与动态状态演化的统一。


<details>
  <summary>Details</summary>
Motivation: 现有的交错推理范式虽然能增强多模态大语言模型的视觉反馈能力，但反复重编码像素密集图像的计算成本过高。而潜在视觉推理方法要么因过度压缩特征而牺牲精确感知建模，要么因静态非交错结构而无法处理动态问题。

Method: ILVR框架交错文本生成与潜在视觉表示，后者作为后续推理的具体演化线索。采用自监督策略，通过动量教师模型从辅助图像中选择性提取相关特征作为稀疏监督目标，引导模型自主生成上下文感知的视觉信号。

Result: 在多模态推理基准测试中，ILVR显著优于现有方法，有效弥合了细粒度感知与序列多模态推理之间的差距。

Conclusion: ILVR框架成功统一了动态状态演化与精确感知建模，为多模态大语言模型提供了一种高效且有效的交错潜在视觉推理方法。

Abstract: Interleaved reasoning paradigms enhance Multimodal Large Language Models (MLLMs) with visual feedback but are hindered by the prohibitive computational cost of repeatedly re-encoding pixel-dense images. A promising alternative, latent visual reasoning, circumvents this bottleneck yet currently forces a critical trade-off: methods either sacrifice precise perceptual modeling by over-compressing features or fail to model dynamic problems due to static, non-interleaved structures. We introduce Interleaved Latent Visual Reasoning (ILVR), a framework that unifies dynamic state evolution with precise perceptual modeling. ILVR interleaves textual generation with latent visual representations that act as specific, evolving cues for subsequent reasoning. To enable this, we employ a self-supervision strategy where a Momentum Teacher Model selectively distills relevant features from helper images into sparse supervision targets. This adaptive selection mechanism guides the model to autonomously generate context-aware visual signals. Extensive experiments on multimodal reasoning benchmarks demonstrate that ILVR significantly outperforms existing approaches, effectively bridging the gap between fine-grained perception and sequential multimodal reasoning.

</details>


### [21] [MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation](https://arxiv.org/abs/2512.05671)
*Zhitao He,Haolin Yang,Zeyu Qin,Yi R Fung*

Main category: cs.CL

TL;DR: 开发了ClinEdu多智能体教学模拟器和ClinTeach数据集，训练出MedTutor-R1多模态苏格拉底式导师，用于临床医学教育的一对多教学，显著提升教学效果。


<details>
  <summary>Details</summary>
Motivation: 临床医学教育面临专家指导稀缺与学生需求增长的矛盾，现有LLM研究主要关注一对一知识传授，忽视了团队协作推理这一关键临床技能。

Method: 1) 开发ClinEdu多智能体教学模拟器，包含个性化患者和多样化学生群体；2) 构建ClinTeach大规模苏格拉底教学对话数据集；3) 训练MedTutor-R1多模态导师，先指令调优再强化学习优化，使用三轴评估标准（结构保真度、分析质量、临床安全性）；4) 通过模拟环境进行交互式评估。

Result: MedTutor-R1在平均教学评分上比基础模型提升超过20%，与o3模型相当，在处理不同数量学生时表现出高适应性，验证了ClinEdu教学模拟器的有效性。

Conclusion: 通过多智能体模拟器和强化学习优化的苏格拉底式教学策略，能够有效解决临床医学教育中一对多教学的挑战，为规模化临床培训提供了可行方案。

Abstract: The significant gap between rising demands for clinical training and the scarcity of expert instruction poses a major challenge to medical education. With powerful capabilities in personalized guidance, Large Language Models (LLMs) offer a promising solution to bridge this gap. However, current research focuses mainly on one-on-one knowledge instruction, overlooking collaborative reasoning, a key skill for students developed in teamwork like ward rounds. To this end, we develop ClinEdu, a multi-agent pedagogical simulator with personality-driven patients and diverse student cohorts, enabling controlled testing of complex pedagogical processes and scalable generation of teaching data. Based on ClinEdu, we construct ClinTeach, a large Socratic teaching dialogue dataset that captures the complexities of group instruction. We then train MedTutor-R1, the first multimodal Socratic tutor designed for one-to-many instruction in clinical medical education. MedTutor-R1 is first instruction-tuned on our ClinTeach dataset and then optimized with reinforcement learning, using rewards derived from a three-axis rubric, covering structural fidelity, analytical quality, and clinical safety, to refine its adaptive Socratic strategies. For authentic in-situ assessment, we use simulation-based interactive evaluation that redeploys the tutor back into ClinEdu. Experimental results demonstrate that our MedTutor-R1 outperforms the base model by over 20% in average pedagogical score and is comparable to o3, while also exhibiting high adaptability in handling a varying number of students. This promising performance underscores the effectiveness of our pedagogical simulator, ClinEdu.

</details>


### [22] [Retrieving Semantically Similar Decisions under Noisy Institutional Labels: Robust Comparison of Embedding Methods](https://arxiv.org/abs/2512.05681)
*Tereza Novotna,Jakub Harasta*

Main category: cs.CL

TL;DR: 比较OpenAI通用嵌入模型与捷克宪法法院决策领域专用BERT模型在案例检索任务中的表现，提出噪声感知评估框架，发现通用模型显著优于领域专用模型。


<details>
  <summary>Details</summary>
Motivation: 案例检索是耗时任务，通常通过查询数据库进行。需要评估不同模型在捷克宪法法院决策检索中的表现，特别是在存在噪声标签的司法数据库环境中。

Method: 比较两种模型：1) OpenAI通用嵌入模型；2) 在约30,000个决策上使用滑动窗口和注意力池化从头训练的领域专用BERT。采用噪声感知评估框架，包括IDF加权关键词重叠作为分级相关性、通过两个阈值(0.20平衡、0.28严格)进行二值化、配对自助法显著性检验，以及结合定性分析的nDCG诊断。

Result: 尽管绝对nDCG值较低（在噪声标签下预期如此），OpenAI通用嵌入模型在@10/@20/@100两个阈值下均显著优于领域预训练的BERT模型；差异具有统计显著性。诊断表明低绝对值是由于标签漂移和强理想标准，而非缺乏实用性。

Conclusion: 通用嵌入模型在捷克宪法法院决策检索中优于领域专用模型。提出的评估框架足够稳健，可用于在噪声黄金数据集下的评估，这在处理来自遗留司法数据库的异构标签数据时很典型。

Abstract: Retrieving case law is a time-consuming task predominantly carried out by querying databases. We provide a comparison of two models in three different settings for Czech Constitutional Court decisions: (i) a large general-purpose embedder (OpenAI), (ii) a domain-specific BERT-trained from scratch on ~30,000 decisions using sliding windows and attention pooling. We propose a noise-aware evaluation including IDF-weighted keyword overlap as graded relevance, binarization via two thresholds (0.20 balanced, 0.28 strict), significance via paired bootstrap, and an nDCG diagnosis supported with qualitative analysis. Despite modest absolute nDCG (expected under noisy labels), the general OpenAI embedder decisively outperforms the domain pre-trained BERT in both settings at @10/@20/@100 across both thresholds; differences are statistically significant. Diagnostics attribute low absolutes to label drift and strong ideals rather than lack of utility. Additionally, our framework is robust enough to be used for evaluation under a noisy gold dataset, which is typical when handling data with heterogeneous labels stemming from legacy judicial databases.

</details>


### [23] [Faithfulness metric fusion: Improving the evaluation of LLM trustworthiness across domains](https://arxiv.org/abs/2512.05700)
*Ben Malin,Tatiana Kalganova,Nikolaos Boulgouris*

Main category: cs.CL

TL;DR: 提出一种通过融合基础指标来提升大语言模型忠实度评估准确性的方法，使用树模型结合人类判断来加权指标，创建跨领域数据集用于复现和测试。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的忠实度评估需要更准确的方法，以增强对模型的信任，使其能在更多样化的场景中应用。

Method: 将多个基础忠实度指标融合为组合指标，使用树模型根据人类对LLM回答忠实度的判断来确定各指标的重要性权重。

Result: 融合后的指标在所有测试领域都与人类判断有更强的相关性，同时创建了包含问答和对话领域的数据集，集成了人类判断和LLM回答。

Conclusion: 该方法显著提升了LLM忠实度评估的准确性，增强了模型可信度，为跨领域忠实度评估提供了可复现的基准。

Abstract: We present a methodology for improving the accuracy of faithfulness evaluation in Large Language Models (LLMs). The proposed methodology is based on the combination of elementary faithfulness metrics into a combined (fused) metric, for the purpose of improving the faithfulness of LLM outputs. The proposed strategy for metric fusion deploys a tree-based model to identify the importance of each metric, which is driven by the integration of human judgements evaluating the faithfulness of LLM responses. This fused metric is demonstrated to correlate more strongly with human judgements across all tested domains for faithfulness. Improving the ability to evaluate the faithfulness of LLMs, allows for greater confidence to be placed within models, allowing for their implementation in a greater diversity of scenarios. Additionally, we homogenise a collection of datasets across question answering and dialogue-based domains and implement human judgements and LLM responses within this dataset, allowing for the reproduction and trialling of faithfulness evaluation across domains.

</details>


### [24] [Efficient Text Classification with Conformal In-Context Learning](https://arxiv.org/abs/2512.05732)
*Ippokratis Pantelidis,Korbinian Randl,Aron Henriksson*

Main category: cs.CL

TL;DR: CICLe框架通过结合轻量级基础分类器和保形预测来指导LLM提示，在文本分类任务中显著提升效率和性能，特别是在样本充足和高类别不平衡的情况下。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型具有强大的上下文学习能力，但在文本分类任务中，其效果严重依赖提示设计且计算成本高昂。现有的CICLe框架虽然提出了资源高效的解决方案，但其在多个领域的适用性和效率优势尚未得到系统验证。

Method: CICLe框架整合轻量级基础分类器和保形预测技术，通过自适应减少候选类别集合来指导LLM提示。该方法在不同NLP分类基准上进行了全面评估，比较了基础分类器、少样本提示基线以及CICLe在不同数据规模下的表现。

Result: CICLe在样本充足时持续优于基础分类器和少样本提示基线，在低数据场景下表现相当。效率方面，CICLe将提示次数减少达34.45%，提示长度减少达25.16%，并能使用更小的模型保持竞争力。该框架在类别高度不平衡的文本分类任务中特别有效。

Conclusion: CICLe是一种实用且可扩展的高效文本分类方法，结合了传统分类器的鲁棒性和LLM的适应性，在数据和计算效率方面取得了显著提升，为资源受限环境下的文本分类提供了有效解决方案。

Abstract: Large Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.

</details>


### [25] [Capturing Classic Authorial Style in Long-Form Story Generation with GRPO Fine-Tuning](https://arxiv.org/abs/2512.05747)
*Jinlong Liu,Mohammed Bahja,Venelin Kovatchev,Mark Lee*

Main category: cs.CL

TL;DR: 提出基于GRPO和多奖励训练框架的细粒度风格控制故事生成方法，在8B模型上实现超越GPT-4o等大模型的作者风格模仿效果


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在开放式故事生成方面表现优秀，但在细粒度风格控制方面有限，现有方法通常依赖浅层线索（如姓名或主题）来模拟作者风格，缺乏稳健的评估

Method: 使用Group Relative Policy Optimization（GRPO）训练框架和定制化多奖励设置，风格奖励来自基于作者验证信号微调的句子转换器，结合内容和完整性评分以稳定长文本叙事生成

Result: 以马克·吐温的《哈克贝利·费恩历险记》为风格参考，8B模型在作者验证风格指标上超越GPT-4o和Claude Sonnet 4等更大基线模型，获得0.628的风格分数和具有竞争力的内容质量

Conclusion: 证明了中等规模模型通过任务特定训练实现代理风格生成的可行性，虽然输出明显风格对齐，但叙事完整性仍是挑战，未来需要更好建模全局连贯性和故事结局

Abstract: Recent advances in large language models (LLMs) show impressive performance in open-ended story generation, but fine-grained stylistic control remains limited. Existing methods often rely on shallow cues (e.g., names or topics) to simulate authorial style, without robust evaluation. In this work, we present a training framework for style-conditioned story generation using Group Relative Policy Optimization (GRPO) and a custom multi-reward setup. The style reward is derived from a fine-tuned sentence transformer using authorship verification (AV) signals, combined with content and completeness scores to stabilize long-form narrative generation. We conduct experiments using fiction by Mark Twain, a prominent 19th-century American author, with The Adventures of Huckleberry Finn serving as the reference style exemplar. Our 8B model outperforms larger baselines such as GPT-4o and Claude Sonnet 4 in AV-style metrics, achieving a style score of 0.628 and competitive content quality. Results demonstrate the feasibility of agentic stylistic generation with moderate model size and task-specific training. While the output is clearly style-aligned, narrative completeness remains a challenge, indicating future work is needed to better model global coherence and story resolution.

</details>


### [26] [Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments](https://arxiv.org/abs/2512.05832)
*Yifei Tong*

Main category: cs.CL

TL;DR: 研究美国最高法院口头辩论中打断行为对律师语义内容和情感语调的影响，特别关注性别差异


<details>
  <summary>Details</summary>
Motivation: 探究最高法院口头辩论中的打断行为如何影响律师的论证内容和情感表达，特别关注性别动态在司法话语中的表现

Method: 使用ConvoKit最高法院语料库（2010-2019），分析12,663个律师-法官互动片段；使用GloVe句子嵌入量化语义变化，通过词典分析测量情感

Result: 打断前后语义相似度保持高位（打断不改变论证内容），但针对女性律师的打断包含显著更高的负面情感

Conclusion: 研究深化了对精英机构中性别化沟通的理解，展示了计算语言学方法在研究司法程序中的权力、话语和公平方面的价值

Abstract: This study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates' speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate's argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.

</details>


### [27] [Prompting Science Report 4: Playing Pretend: Expert Personas Don't Improve Factual Accuracy](https://arxiv.org/abs/2512.05858)
*Savir Basil,Ina Shapiro,Dan Shapiro,Ethan Mollick,Lilach Mollick,Lennart Meincke*

Main category: cs.CL

TL;DR: 研究发现，为AI模型分配专家或低知识角色提示通常不会提高其在困难选择题上的准确性，反而可能降低性能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨为AI模型分配特定角色（专家或低知识者）是否能够提升其在困难客观选择题上的表现，帮助商业、教育和政策领导者理解AI技术细节。

Method: 使用六个AI模型在GPQA Diamond和MMLU-Pro两个研究生级别的科学、工程和法律问题数据集上进行测试。测试了三种角色分配方法：领域匹配的专家角色、领域不匹配的专家角色、以及低知识角色（外行、幼儿等）。

Result: 角色提示总体上未能提高准确性：领域匹配的专家角色对性能无显著影响（除Gemini 2.0 Flash外）；领域不匹配的专家角色导致边际差异；低知识角色通常损害基准准确性。

Conclusion: 角色提示在提高AI模型事实准确性方面效果有限，虽然可能改变输出语气，但不能作为提升事实性能的可靠方法。

Abstract: This is the fourth in a series of short reports that help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. Here, we ask whether assigning personas to models improves performance on difficult objective multiple-choice questions. We study both domain-specific expert personas and low-knowledge personas, evaluating six models on GPQA Diamond (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024), graduate-level questions spanning science, engineering, and law.
  We tested three approaches:
  -In-Domain Experts: Assigning the model an expert persona ("you are a physics expert") matched to the problem type (physics problems) had no significant impact on performance (with the exception of the Gemini 2.0 Flash model).
  -Off-Domain Experts (Domain-Mismatched): Assigning the model an expert persona ("you are a physics expert") not matched to the problem type (law problems) resulted in marginal differences.
  -Low-Knowledge Personas: We assigned the model negative capability personas (layperson, young child, toddler), which were generally harmful to benchmark accuracy.
  Across both benchmarks, persona prompts generally did not improve accuracy relative to a no-persona baseline. Expert personas showed no consistent benefit across models, with few exceptions. Domain-mismatched expert personas sometimes degraded performance. Low-knowledge personas often reduced accuracy. These results are about the accuracy of answers only; personas may serve other purposes (such as altering the tone of outputs), beyond improving factual performance.

</details>


### [28] [Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework](https://arxiv.org/abs/2512.05863)
*Tasnimul Hassan,Md Faisal Karim,Haziq Jeelani,Elham Behnam,Robert Green,Fayeq Jeelani Syed*

Main category: cs.CL

TL;DR: 基于检索增强生成（RAG）的医疗问答系统，通过结合领域知识检索与开源LLM，提高医学问题回答的事实准确性和减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 直接将大型语言模型应用于临床领域存在挑战，如保持事实准确性和避免幻觉，需要结合领域专业知识来提升医疗问答系统的可靠性。

Method: 采用检索增强生成框架，结合医学文献检索与开源LLM（LLaMA~2和Falcon），使用低秩适应（LoRA）进行高效领域微调，通过检索相关医学文献来支撑LLM的回答。

Result: 在PubMedQA和MedMCQA基准测试中，检索增强显著提高了答案准确性。微调的LLaMA~2模型在PubMedQA上达到71.8%准确率，相比零样本基线的55.4%有显著提升，同时通过提供来源引用保持透明度，减少了约60%的无支持内容。

Conclusion: 检索增强生成的开源LLM在可靠生物医学问答方面具有潜力，为实际临床信息学应用指明了方向，通过证据基础的回答提高了系统的可信度。

Abstract: Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical literature to ground the LLM's answers, thereby improving factual correctness and reducing hallucinations. We evaluate the approach on benchmark datasets (PubMedQA and MedMCQA) and show that retrieval augmentation yields measurable improvements in answer accuracy compared to using LLMs alone. Our fine-tuned LLaMA~2 model achieves 71.8% accuracy on PubMedQA, substantially improving over the 55.4% zero-shot baseline, while maintaining transparency by providing source references. We also detail the system design and fine-tuning methodology, demonstrating that grounding answers in retrieved evidence reduces unsupported content by approximately 60%. These results highlight the potential of RAG-augmented open-source LLMs for reliable biomedical QA, pointing toward practical clinical informatics applications.

</details>


### [29] [M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG](https://arxiv.org/abs/2512.05959)
*David Anugraha,Patrick Amadeus Irawan,Anshul Singh,En-Shiun Annie Lee,Genta Indra Winata*

Main category: cs.CL

TL;DR: M4-RAG是一个大规模多语言多模态检索增强生成基准，涵盖42种语言和56种地区方言，包含8万多个文化多样图像-问题对，用于评估跨语言和模态的检索增强视觉问答系统。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型受限于静态训练数据，检索增强生成虽然能访问最新、文化相关和多语言信息，但多语言多模态RAG研究不足，需要系统评估框架。

Method: 构建M4-RAG基准，包含42种语言、56种方言的8万+文化多样图像-问题对；创建受控检索环境，包含数百万精心策划的多语言文档，平衡真实性与可重复性。

Result: 系统评估显示：RAG对小规模VLMs有持续益处，但对大规模模型效果不佳甚至降低性能，揭示了模型规模与当前检索效果之间的关键不匹配。

Conclusion: M4-RAG为推进下一代RAG系统奠定了基础，使其能够在语言、模态和文化语境中无缝推理，解决多语言多模态检索增强的挑战。

Abstract: Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [30] [RAG-IGBench: Innovative Evaluation for RAG-based Interleaved Generation in Open-domain Question Answering](https://arxiv.org/abs/2512.05119)
*Rongyang Zhang,Yuqing Huang,Chengqiang Lu,Qimeng Wang,Yan Gao,Yi Wu,Yao Hu,Yin Xu,Wei Wang,Hao Wang,Enhong Chen*

Main category: cs.IR

TL;DR: 提出了RAG-IGBench基准，专门评估基于检索增强生成的多模态交错生成任务，包含创新的评估指标和高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 现实场景中视觉增强的响应能显著提升理解和记忆，但现有交错图像-文本生成方法质量有限，且缺乏专门的评估基准和合适的评价指标。

Method: 构建RAG-IGBench基准，整合多模态大语言模型与检索机制，从社交平台获取最新公开内容，设计评估文本质量、图像质量及其一致性的创新指标。

Result: 在RAG-IGBench上对多种先进MLLM进行实验分析，验证了评估指标与人工评估的高相关性，在训练集上微调的模型在多个基准上表现提升。

Conclusion: RAG-IGBench为交错生成任务提供了全面的评估框架，数据集质量和实用性得到验证，有助于推动多模态内容生成研究。

Abstract: In real-world scenarios, providing user queries with visually enhanced responses can considerably benefit understanding and memory, underscoring the great value of interleaved image-text generation. Despite recent progress, like the visual autoregressive model that unifies text and image processing in a single transformer architecture, generating high-quality interleaved content remains challenging. Moreover, evaluations of these interleaved sequences largely remain underexplored, with existing benchmarks often limited by unimodal metrics that inadequately assess the intricacies of combined image-text outputs. To address these issues, we present RAG-IGBench, a thorough benchmark designed specifically to evaluate the task of Interleaved Generation based on Retrieval-Augmented Generation (RAG-IG) in open-domain question answering. RAG-IG integrates multimodal large language models (MLLMs) with retrieval mechanisms, enabling the models to access external image-text information for generating coherent multimodal content. Distinct from previous datasets, RAG-IGBench draws on the latest publicly available content from social platforms and introduces innovative evaluation metrics that measure the quality of text and images, as well as their consistency. Through extensive experiments with state-of-the-art MLLMs (both open-source and proprietary) on RAG-IGBench, we provide an in-depth analysis examining the capabilities and limitations of these models. Additionally, we validate our evaluation metrics by demonstrating their high correlation with human assessments. Models fine-tuned on RAG-IGBench's training set exhibit improved performance across multiple benchmarks, confirming both the quality and practical utility of our dataset. Our benchmark is available at https://github.com/USTC-StarTeam/RAG-IGBench.

</details>


### [31] [The Effect of Document Summarization on LLM-Based Relevance Judgments](https://arxiv.org/abs/2512.05334)
*Samaneh Mohtadi,Kevin Roitero,Stefano Mizzaro,Gianluca Demartini*

Main category: cs.IR

TL;DR: LLM生成的摘要可用于信息检索评估，替代完整文档，在系统排名稳定性上表现相当，但会引入标签分布的系统性偏移和偏差。


<details>
  <summary>Details</summary>
Motivation: 人工相关性标注成本高、耗时，LLM作为自动评估器显示出潜力。现有研究大多使用完整文档，但未研究文本摘要如何影响LLM评估的可靠性及其对IR评估的下游影响。

Method: 使用最先进的LLM在多个TREC数据集上，比较基于完整文档的评估与基于不同长度LLM生成摘要的评估。分析它们与人工标注的一致性、对检索效果评估的影响，以及对IR系统排名稳定性的影响。

Result: 基于摘要的评估在系统排名稳定性方面与完整文档评估相当，但会引入标签分布的系统性偏移和偏差，这些偏移和偏差因模型和数据集而异。

Conclusion: 文本摘要既是大规模IR评估效率提升的机会，也是一个具有重要方法论意义的选择，会影响自动评估的可靠性。

Abstract: Relevance judgments are central to the evaluation of Information Retrieval (IR) systems, but obtaining them from human annotators is costly and time-consuming. Large Language Models (LLMs) have recently been proposed as automated assessors, showing promising alignment with human annotations. Most prior studies have treated documents as fixed units, feeding their full content directly to LLM assessors. We investigate how text summarization affects the reliability of LLM-based judgments and their downstream impact on IR evaluation. Using state-of-the-art LLMs across multiple TREC collections, we compare judgments made from full documents with those based on LLM-generated summaries of different lengths. We examine their agreement with human labels, their effect on retrieval effectiveness evaluation, and their influence on IR systems' ranking stability. Our findings show that summary-based judgments achieve comparable stability in systems' ranking to full-document judgments, while introducing systematic shifts in label distributions and biases that vary by model and dataset. These results highlight summarization as both an opportunity for more efficient large-scale IR evaluation and a methodological choice with important implications for the reliability of automatic judgments.

</details>


### [32] [A Systematic Framework for Enterprise Knowledge Retrieval: Leveraging LLM-Generated Metadata to Enhance RAG Systems](https://arxiv.org/abs/2512.05411)
*Pranav Pushkar Mishra,Kranti Prakash Yeole,Ramyashree Keshavamurthy,Mokshit Bharat Surana,Fatemeh Sarayloo*

Main category: cs.IR

TL;DR: 使用LLM进行元数据增强的系统框架，通过三种分块策略和嵌入技术显著提升RAG系统的文档检索性能


<details>
  <summary>Details</summary>
Motivation: 在企业环境中，从大型复杂知识库中高效检索相关信息对运营生产力和决策制定至关重要，需要提升RAG系统的文档检索效果

Method: 提出系统化元数据增强框架，采用结构化流水线动态生成文档片段的元数据，比较语义分块、递归分块和朴素分块三种策略，结合TF-IDF加权嵌入等高级嵌入技术

Result: 元数据增强方法始终优于纯内容基线，递归分块+TF-IDF加权嵌入达到82.5%精确率（vs 73.3%语义纯内容），朴素分块+前缀融合实现最高Hit Rate@10 0.925，元数据增强提升向量聚类质量并降低检索延迟

Conclusion: 元数据增强是提升RAG系统效果的关键优化技术，为企业环境中部署高性能、可扩展的文档检索解决方案提供了实用见解

Abstract: In enterprise settings, efficiently retrieving relevant information from large and complex knowledge bases is essential for operational productivity and informed decision-making. This research presents a systematic framework for metadata enrichment using large language models (LLMs) to enhance document retrieval in Retrieval-Augmented Generation (RAG) systems. Our approach employs a comprehensive, structured pipeline that dynamically generates meaningful metadata for document segments, substantially improving their semantic representations and retrieval accuracy. Through extensive experiments, we compare three chunking strategies-semantic, recursive, and naive-and evaluate their effectiveness when combined with advanced embedding techniques. The results demonstrate that metadata-enriched approaches consistently outperform content-only baselines, with recursive chunking paired with TF-IDF weighted embeddings yielding an 82.5% precision rate compared to 73.3% for semantic content-only approaches. The naive chunking strategy with prefix-fusion achieved the highest Hit Rate@10 of 0.925. Our evaluation employs cross-encoder reranking for ground truth generation, enabling rigorous assessment via Hit Rate and Metadata Consistency metrics. These findings confirm that metadata enrichment enhances vector clustering quality while reducing retrieval latency, making it a key optimization for RAG systems across knowledge domains. This work offers practical insights for deploying high-performance, scalable document retrieval solutions in enterprise settings, demonstrating that metadata enrichment is a powerful approach for enhancing RAG effectiveness.

</details>


### [33] [Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms](https://arxiv.org/abs/2512.05967)
*Francesco Granata,Francesco Poggi,Misael Mongiovì*

Main category: cs.IR

TL;DR: 本研究提出了一种增强的RAG架构，通过集成实体链接的事实信号来提高意大利语教育问答系统的准确性，在特定领域任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 基于纯语义相似性的RAG系统在专业领域中难以确保事实准确性，因为术语歧义会影响检索相关性，特别是在教育问答系统中需要更高的精确度。

Method: 提出增强的RAG架构，集成基于Wikidata的实体链接模块，并实现三种重排序策略：混合分数加权模型、互逆排名融合和交叉编码器重排序器，结合语义和实体信息。

Result: 在特定领域上下文中，基于互逆排名融合的混合方案显著优于基线和交叉编码器方法；而在通用领域数据集上，交叉编码器获得最佳结果，证实了领域不匹配效应。

Conclusion: 研究证实了领域不匹配效应的存在，强调了领域适应和混合排名策略对增强检索增强生成的事实精确度和可靠性的重要性，展示了实体感知RAG系统在教育环境中的潜力。

Abstract: In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answering systems in Italian. The system includes a Wikidata-based Entity Linking module and implements three re-ranking strategies to combine semantic and entity-based information: a hybrid score weighting model, reciprocal rank fusion, and a cross-encoder re-ranker. Experiments were conducted on two benchmarks: a custom academic dataset and the standard SQuAD-it dataset. Results show that, in domain-specific contexts, the hybrid schema based on reciprocal rank fusion significantly outperforms both the baseline and the cross-encoder approach, while the cross-encoder achieves the best results on the general-domain dataset. These findings confirm the presence of an effect of domain mismatch and highlight the importance of domain adaptation and hybrid ranking strategies to enhance factual precision and reliability in retrieval-augmented generation. They also demonstrate the potential of entity-aware RAG systems in educational environments, fostering adaptive and reliable AI-based tutoring tools.

</details>
