<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 31]
- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [FiNERweb: Datasets and Artifacts for Scalable Multilingual Named Entity Recognition](https://arxiv.org/abs/2512.13884)
*Jonas Golde,Patrick Haller,Alan Akbik*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent multilingual named entity recognition (NER) work has shown that large language models (LLMs) can provide effective synthetic supervision, yet such datasets have mostly appeared as by-products of broader experiments rather than as systematic, reusable resources. We introduce FiNERweb, a dataset-creation pipeline that scales the teacher-student paradigm to 91 languages and 25 scripts. Building on FineWeb-Edu, our approach trains regression models to identify NER-relevant passages and annotates them with multilingual LLMs, resulting in about 225k passages with 235k distinct entity labels. Our experiments show that the regression model achieves more than 84 F1, and that models trained on FiNERweb obtain comparable or improved performance in zero shot transfer settings on English, Thai, and Swahili, despite being trained on 19x less data than strong baselines. In addition, we assess annotation quality using LLM-as-a-judge and observe consistently high scores for both faithfulness (3.99 out of 5) and completeness (4.05 out of 5), indicating reliable and informative annotations. Further, we release the dataset with both English labels and translated label sets in the respective target languages because we observe that the performance of current state-of-the-art models drops by 0.02 to 0.09 F1 when evaluated using target language labels instead of English ones. We release FiNERweb together with all accompanying artifacts to the research community in order to facilitate more effective student-teacher training for multilingual named entity recognition.

</details>


### [2] [Olmo 3](https://arxiv.org/abs/2512.13961)
*Team Olmo,:,Allyson Ettinger,Amanda Bertsch,Bailey Kuehl,David Graham,David Heineman,Dirk Groeneveld,Faeze Brahman,Finbarr Timbers,Hamish Ivison,Jacob Morrison,Jake Poznanski,Kyle Lo,Luca Soldaini,Matt Jordan,Mayee Chen,Michael Noukhovitch,Nathan Lambert,Pete Walsh,Pradeep Dasigi,Robert Berry,Saumya Malik,Saurabh Shah,Scott Geng,Shane Arora,Shashank Gupta,Taira Anderson,Teng Xiao,Tyler Murray,Tyler Romero,Victoria Graf,Akari Asai,Akshita Bhagia,Alexander Wettig,Alisa Liu,Aman Rangapur,Chloe Anastasiades,Costa Huang,Dustin Schwenk,Harsh Trivedi,Ian Magnusson,Jaron Lochner,Jiacheng Liu,Lester James V. Miranda,Maarten Sap,Malia Morgan,Michael Schmitz,Michal Guerquin,Michael Wilson,Regan Huff,Ronan Le Bras,Rui Xin,Rulin Shao,Sam Skjonsberg,Shannon Zejiang Shen,Shuyue Stella Li,Tucker Wilde,Valentina Pyatkin,Will Merrill,Yapei Chang,Yuling Gu,Zhiyuan Zeng,Ashish Sabharwal,Luke Zettlemoyer,Pang Wei Koh,Ali Farhadi,Noah A. Smith,Hannaneh Hajishirzi*

Main category: cs.CL

TL;DR: Olmo 3是一个完全开源的7B和32B参数语言模型家族，专注于长上下文推理、函数调用等能力，提供完整的模型构建流程，其中32B模型是目前最强的完全开源思考模型。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个完全开源、透明的语言模型家族，覆盖从7B到32B参数规模，专注于提升长上下文推理、函数调用、编码等关键能力，为研究社区提供完整的模型生命周期信息。

Method: 通过完整的模型流程构建，包括所有阶段、检查点、数据点和依赖项，专注于长上下文推理、函数调用、编码、指令遵循、通用对话和知识回忆等能力。

Result: 成功开发了Olmo 3系列模型，其中旗舰模型Olmo 3 Think 32B是目前最强的完全开源思考模型，在多个关键任务上表现出色。

Conclusion: Olmo 3系列模型代表了完全开源语言模型的最新进展，特别是在32B参数规模上实现了当前最强的完全开源思考模型，为研究社区提供了前所未有的透明度。

Abstract: We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall. This release includes the entire model flow, i.e., the full lifecycle of the family of models, including every stage, checkpoint, data point, and dependency used to build it. Our flagship model, Olmo 3 Think 32B, is the strongest fully-open thinking model released to-date.

</details>


### [3] [Structure-Aware Decoding Mechanisms for Complex Entity Extraction with Large-Scale Language Models](https://arxiv.org/abs/2512.13980)
*Zhimin Qiu,Di Wu,Feng Liu,Chenrui Hu,Yuxiao Wang*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes a structure-aware decoding method based on large language models to address the difficulty of traditional approaches in maintaining both semantic integrity and structural consistency in nested and overlapping entity extraction tasks. The method introduces a candidate span generation mechanism and structured attention modeling to achieve unified modeling of entity boundaries, hierarchical relationships, and cross-dependencies. The model first uses a pretrained language model to obtain context-aware semantic representations, then captures multi-granular entity span features through candidate representation combinations, and introduces hierarchical structural constraints during decoding to ensure consistency between semantics and structure. To enhance stability in complex scenarios, the model jointly optimizes classification loss and structural consistency loss, maintaining high recognition accuracy under multi-entity co-occurrence and long-sentence dependency conditions. Experiments conducted on the ACE 2005 dataset demonstrate significant improvements in Accuracy, Precision, Recall, and F1-Score, particularly in nested and overlapping entity recognition, where the model shows stronger boundary localization and structural modeling capability. This study verifies the effectiveness of structure-aware decoding in complex semantic extraction tasks, provides a new perspective for developing language models with hierarchical understanding, and establishes a methodological foundation for high-precision information extraction.

</details>


### [4] [What Affects the Effective Depth of Large Language Models?](https://arxiv.org/abs/2512.14064)
*Yi Hu,Cai Zhou,Muhan Zhang*

Main category: cs.CL

TL;DR: 研究发现当前LLM在不同规模、训练范式和任务难度下都未能充分利用其深度，有效深度比例稳定，推理改进来自上下文而非更深计算，为提升层利用率提供了研究方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常通过增加深度来扩展，但性能提升随层数增加而递减。先前研究提出'有效深度'概念，认为更深模型未能充分利用其层进行有意义的计算。

Method: 系统研究有效深度如何随模型规模、训练类型和任务难度变化。首先分析Qwen-2.5系列模型行为，比较基础模型与长思维链模型，并在不同难度任务上进行评估。

Result: 发现有效层数随模型规模增长，但有效深度比例保持稳定；基础模型与长思维链模型的有效深度没有增加，表明推理能力提升源于更长上下文而非更深计算；模型不会为更难问题动态使用更多层。

Conclusion: 当前LLM在不同规模、训练范式和任务难度下都未能充分利用其可用深度，这为提升LLM层利用率、模型剪枝和早期退出等研究方向提供了机会。

Abstract: The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of "effective depth", arguing that deeper models fail to fully utilize their layers for meaningful computation. Building on this, we systematically study how effective depth varies with model scale, training type, and task difficulty. First, we analyze the model behavior of Qwen-2.5 family (1.5B-32B) and find that while the number of effective layers grows with model size, the effective depth ratio remains stable. Besides, comparisons between base and corresponding long-CoT models show no increase in effective depth, suggesting that improved reasoning stems from longer context rather than deeper per-token computation. Furthermore, evaluations across tasks of varying difficulty indicate that models do not dynamically use more layers for harder problems. Our results suggest that current LLMs underuse available depth across scales, training paradigms and tasks of varying difficulties, pointing out research opportunities on increasing the layer utilization rate of LLMs, model pruning, and early exiting. Our code is released at https://github.com/AheadOFpotato/what_affects_effective_depth.

</details>


### [5] [Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed](https://arxiv.org/abs/2512.14067)
*Yonggan Fu,Lexington Whalen,Zhifan Ye,Xin Dong,Shizhe Diao,Jingyu Liu,Chengyue Wu,Hao Zhang,Enze Xie,Song Han,Maksim Khadkevich,Jan Kautz,Yingyan Celine Lin,Pavlo Molchanov*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models' task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce a continuous pretraining scheme with a block-wise attention pattern, which remains causal across blocks while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models' weight distributions than fully bidirectional modeling, in addition to its known benefit of enabling KV caching, and leads to a win-win in accuracy and efficiency. Second, to mitigate the training-test gap in mask token distributions (uniform vs. highly left-to-right), we propose a position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs' attention patterns, training dynamics, and other design choices, providing actionable insights into scalable AR-to-dLM conversion. These studies lead to the Efficient-DLM family, which outperforms state-of-the-art AR models and dLMs, e.g., our Efficient-DLM 8B achieves +5.4%/+2.7% higher accuracy with 4.5x/2.7x higher throughput compared to Dream 7B and Qwen3 4B, respectively.

</details>


### [6] [A Unified Sparse Attention via Multi-Granularity Compression](https://arxiv.org/abs/2512.14082)
*Siran Liu,Zane Cao,Yongchao He*

Main category: cs.CL

TL;DR: UniSparse：通过复合令牌和多粒度压缩的动态稀疏注意力机制，高效解决LLM长上下文计算瓶颈，在保持高准确性的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型长上下文理解中的计算瓶颈问题，现有稀疏注意力方法存在训练成本高、无法作为加速插件通用使用、效率与跨模态通用性不足等限制。

Method: 提出UniSparse统一机制，引入复合令牌概念来聚合多粒度上下文信息，通过多粒度压缩和块级选择动态构建稀疏注意力，实现GPU上的高效硬件友好执行。

Result: 在多种模态和任务上，UniSparse在准确性和效率方面均优于现有稀疏注意力方法（如MInference、XAttention、FlexPrefill），达到全注意力99%以上的准确率，注意力计算速度比FlashAttention快2.61倍。

Conclusion: UniSparse通过引入复合令牌和动态稀疏注意力机制，在保持高准确性的同时显著提升了长上下文处理效率，为LLM的长序列处理提供了有效的解决方案。

Abstract: Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottleneck. Existing sparse attention methods alleviate this issue but face trade-offs: training-based methods are costly and cannot be directly applied as acceleration plugins for other models, while inference-time methods often compromise efficiency or cross-modal generality. To address these limitations, we present UniSparse, a unified mechanism that introduces the notion of composite tokens--compact representations that aggregate multi-granularity contextual information. Building on this abstraction, UniSparse dynamically constructs sparse attention through multi-granularity compression and block-level selection, enabling efficient and hardware-friendly execution on GPU. Across multiple modalities and tasks ranging from synthetic benchmarks to real-world applications, UniSparse consistently surpasses state-of-the-art sparse attention methods (e.g., MInference, XAttention, FlexPrefill) in both accuracy and efficiency, achieving $\ge$ 99% of full-attention accuracy and up to 2.61$\times$ faster attention computation than FlashAttention.

</details>


### [7] [Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study](https://arxiv.org/abs/2512.14085)
*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Taiga Mori,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a multilingual, continuous backchannel prediction model for Japanese, English, and Chinese, and use it to investigate cross-linguistic timing behavior. The model is Transformer-based and operates at the frame level, jointly trained with auxiliary tasks on approximately 300 hours of dyadic conversations. Across all three languages, the multilingual model matches or surpasses monolingual baselines, indicating that it learns both language-universal cues and language-specific timing patterns. Zero-shot transfer with two-language training remains limited, underscoring substantive cross-lingual differences. Perturbation analyses reveal distinct cue usage: Japanese relies more on short-term linguistic information, whereas English and Chinese are more sensitive to silence duration and prosodic variation; multilingual training encourages shared yet adaptable representations and reduces overreliance on pitch in Chinese. A context-length study further shows that Japanese is relatively robust to shorter contexts, while Chinese benefits markedly from longer contexts. Finally, we integrate the trained model into a real-time processing software, demonstrating CPU-only inference. Together, these findings provide a unified model and empirical evidence for how backchannel timing differs across languages, informing the design of more natural, culturally-aware spoken dialogue systems.

</details>


### [8] [A Comparative Analysis of Retrieval-Augmented Generation Techniques for Bengali Standard-to-Dialect Machine Translation Using LLMs](https://arxiv.org/abs/2512.14179)
*K. M. Jubair Sami,Dipto Sumit,Ariyan Hossain,Farig Sadeque*

Main category: cs.CL

TL;DR: 提出两种RAG管道用于标准孟加拉语到方言翻译，句子对方法优于转录本方法，小模型通过良好检索策略能超越大模型。为低资源方言翻译提供无需微调的有效解决方案。


<details>
  <summary>Details</summary>
Motivation: 标准语言到其区域方言的翻译是NLP的重要挑战，特别是在孟加拉语中，由于数据稀缺和语言变异性问题突出。

Method: 提出并比较了两种新颖的RAG管道：基于转录本的管道（使用音频转录中的大方言语境）和标准句子对管道（使用结构化的local_dialect:standard_bengali句子对）。在六个孟加拉方言和多个LLM上使用BLEU、ChrF、WER和BERTScore进行评估。

Result: 句子对管道始终优于转录本管道，将吉大港方言的词错误率从76%降低到55%。关键发现是，这种RAG方法使较小模型（如Llama-3.1-8B）能够超越大得多的模型（如GPT-OSS-120B），表明精心设计的检索策略比模型规模更重要。

Conclusion: 这项研究表明，精心设计的检索策略比模型规模更重要，为低资源方言翻译提供了无需微调的有效解决方案，并为保护语言多样性提供了实用蓝图。

Abstract: Translating from a standard language to its regional dialects is a significant NLP challenge due to scarce data and linguistic variation, a problem prominent in the Bengali language. This paper proposes and compares two novel RAG pipelines for standard-to-dialectal Bengali translation. The first, a Transcript-Based Pipeline, uses large dialect sentence contexts from audio transcripts. The second, a more effective Standardized Sentence-Pairs Pipeline, utilizes structured local\_dialect:standard\_bengali sentence pairs. We evaluated both pipelines across six Bengali dialects and multiple LLMs using BLEU, ChrF, WER, and BERTScore. Our findings show that the sentence-pair pipeline consistently outperforms the transcript-based one, reducing Word Error Rate (WER) from 76\% to 55\% for the Chittagong dialect. Critically, this RAG approach enables smaller models (e.g., Llama-3.1-8B) to outperform much larger models (e.g., GPT-OSS-120B), demonstrating that a well-designed retrieval strategy can be more crucial than model size. This work contributes an effective, fine-tuning-free solution for low-resource dialect translation, offering a practical blueprint for preserving linguistic diversity.

</details>


### [9] [CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models](https://arxiv.org/abs/2512.14118)
*Yiran Zhang,Jincheng Hu,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination, overconfidence, and memory decay. Current approaches typically append full conversational histories, causing unbounded context growth, higher computational costs, and degraded reasoning efficiency. We introduce CogMem, a cognitively inspired, memory-augmented LLM architecture that supports sustained iterative reasoning through structured, persistent memory. CogMem incorporates three layers: a Long-Term Memory (LTM) that consolidates cross-session reasoning strategies; a Direct Access (DA) memory that maintains session-level notes and retrieves relevant long-term memories; and a Focus of Attention (FoA) mechanism that dynamically reconstructs concise, task-relevant context at each turn. Experiments on TurnBench show that this layered design mitigates reasoning failures, controls context growth, and improves consistency across extended reasoning chains, moving toward more reliable, human-like reasoning in LLMs.

</details>


### [10] [Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents](https://arxiv.org/abs/2512.14142)
*Hongqiu Ni,Jiabao Zhang,Guopeng Li,Zilong Wang,Ruiqi Wu,Chi Zhang,Haisheng Tan*

Main category: cs.CL

TL;DR: Astraea是一个为LLM智能代理设计的服务引擎，通过全局请求生命周期优化、状态感知分层调度和自适应KV缓存管理，显著降低端到端延迟。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能代理的多阶段工作流（交替进行本地计算和调用外部网络服务如Web API）与现有推理系统（如vLLM）的调度粒度不匹配。现有系统通常关注局部段优化，无法最小化整个智能代理工作流的端到端延迟，即整个请求生命周期的全局作业完成时间（JCT）。

Method: Astraea采用状态感知的分层调度算法，结合请求的历史状态和未来预测，动态分类I/O密集型和计算密集型请求，并使用增强的HRRN策略平衡效率与公平性。同时，系统实现了自适应的KV缓存管理器，根据内存压力智能管理I/O等待期间的代理状态。

Result: 实验表明，Astraea相比基线方法将平均JCT降低了高达25.5%，并且在各种模型规模的高负载下表现出强大的鲁棒性和稳定性。

Conclusion: Astraea通过将优化重点从局部计算段转向全局请求生命周期，显著降低了LLM智能代理工作流的端到端延迟，并在高负载下表现出良好的鲁棒性和稳定性，为LLM智能代理的高效部署提供了有效的系统支持。

Abstract: Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.

</details>


### [11] [Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets](https://arxiv.org/abs/2512.14237)
*Estelle Zheng,Nathan Cerisara,Sébastien Warichet,Emmanuel Helbert,Christophe Cerisara*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage induced by the backward pass in the full model. We revisit Ladder Side Tuning (LST), a rarely explored PEFT technique that adds a lightweight side network, and show that it matches QLoRA's compute scaling slope while cutting peak memory by 50\%. Across different downstream benchmarks spanning natural language understanding, mathematical and LLM-critic tasks, LST has competitive performance with QLoRA's accuracy on average while being much more memory-efficient. This efficiency enables fine-tuning of 7B-parameter models on a single 12 GB consumer GPU with 2k-token contexts, requiring no gradient checkpointing\textemdash conditions under which QLoRA exhausts memory. Beyond memory efficiency, we also establish scaling laws showing that LST scales similarly to QLoRA. We exploit Ladder's architectural flexibility by introducing xLadder, a depth-extended variant that increases effective depth via cross-connections and shortens chain-of-thought (CoT) at fixed parameter count. Ladder is strong when memory is the bottleneck; xLadder builds on this by enabling deeper reasoning without additional memory overhead.

</details>


### [12] [Two CFG Nahuatl for automatic corpora expansion](https://arxiv.org/abs/2512.14239)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Ligia Quintana-Torres,Graham Ranger Martha-Lorena Avendaño-Garrido*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The aim of this article is to introduce two Context-Free Grammars (CFG) for Nawatl Corpora expansion. Nawatl is an Amerindian language (it is a National Language of Mexico) of the $π$-language type, i.e. a language with few digital resources. For this reason the corpora available for the learning of Large Language Models (LLMs) are virtually non-existent, posing a significant challenge. The goal is to produce a substantial number of syntactically valid artificial Nawatl sentences and thereby to expand the corpora for the purpose of learning non contextual embeddings. For this objective, we introduce two new Nawatl CFGs and use them in generative mode. Using these grammars, it is possible to expand Nawatl corpus significantly and subsequently to use it to learn embeddings and to evaluate their relevance in a sentences semantic similarity task. The results show an improvement compared to the results obtained using only the original corpus without artificial expansion, and also demonstrate that economic embeddings often perform better than some LLMs.

</details>


### [13] [From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition](https://arxiv.org/abs/2512.14244)
*Yiqing Zhou,Yu Lei,Shuzheng Si,Qingyan Sun,Wei Wang,Yifei Wu,Hao Wen,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.CL

TL;DR: 提出EDU-based Context Compressor，通过将文本转换为EDU结构树并选择相关子树的显式压缩方法，有效解决长上下文管理问题，在保持结构的同时提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长上下文时面临高计算成本和噪声引入的问题，现有压缩技术要么破坏局部连贯性，要么存在位置偏差且与闭源API不兼容，需要一种能同时保持全局结构和细粒度细节的显式压缩框架。

Method: 该方法采用结构-选择的两阶段框架：首先使用LingoEDU将线性文本转换为基于Elementary Discourse Units（EDUs）的结构关系树，严格锚定源索引以避免幻觉；然后通过轻量级排序模块选择与查询相关的子树进行线性化。

Result: 该方法在结构预测准确率上达到最先进水平，显著优于前沿LLMs同时降低成本；在StructBench数据集上验证了其结构理解能力；结构感知压缩在从长上下文任务到复杂深度搜索场景的下游任务中都大幅提升了性能。

Conclusion: EDU-based Context Compressor 通过结构化的压缩方法，在保持全局结构和细粒度细节的同时，显著降低了计算成本，并在多种下游任务中提升了性能，为长上下文管理提供了有效的解决方案。

Abstract: Managing extensive context remains a critical bottleneck for Large Language Models (LLMs), particularly in applications like long-document question answering and autonomous agents where lengthy inputs incur high computational costs and introduce noise. Existing compression techniques often disrupt local coherence through discrete token removal or rely on implicit latent encoding that suffers from positional bias and incompatibility with closed-source APIs. To address these limitations, we introduce the EDU-based Context Compressor, a novel explicit compression framework designed to preserve both global structure and fine-grained details. Our approach reformulates context compression as a structure-then-select process. First, our LingoEDU transforms linear text into a structural relation tree of Elementary Discourse Units (EDUs) which are anchored strictly to source indices to eliminate hallucination. Second, a lightweight ranking module selects query-relevant sub-trees for linearization. To rigorously evaluate structural understanding, we release StructBench, a manually annotated dataset of 248 diverse documents. Empirical results demonstrate that our method achieves state-of-the-art structural prediction accuracy and significantly outperforms frontier LLMs while reducing costs. Furthermore, our structure-aware compression substantially enhances performance across downstream tasks ranging from long-context tasks to complex Deep Search scenarios.

</details>


### [14] [Inflation Attitudes of Large Language Models](https://arxiv.org/abs/2512.14306)
*Nikoleta Anesti,Edward Hill,Andreas Joseph*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates the ability of Large Language Models (LLMs), specifically GPT-3.5-turbo (GPT), to form inflation perceptions and expectations based on macroeconomic price signals. We compare the LLM's output to household survey data and official statistics, mimicking the information set and demographic characteristics of the Bank of England's Inflation Attitudes Survey (IAS). Our quasi-experimental design exploits the timing of GPT's training cut-off in September 2021 which means it has no knowledge of the subsequent UK inflation surge. We find that GPT tracks aggregate survey projections and official statistics at short horizons. At a disaggregated level, GPT replicates key empirical regularities of households' inflation perceptions, particularly for income, housing tenure, and social class. A novel Shapley value decomposition of LLM outputs suited for the synthetic survey setting provides well-defined insights into the drivers of model outputs linked to prompt content. We find that GPT demonstrates a heightened sensitivity to food inflation information similar to that of human respondents. However, we also find that it lacks a consistent model of consumer price inflation. More generally, our approach could be used to evaluate the behaviour of LLMs for use in the social sciences, to compare different models, or to assist in survey design.

</details>


### [15] [Step-Tagging: Toward controlling the generation of Language Reasoning Models through step monitoring](https://arxiv.org/abs/2512.14332)
*Yannis Belkhiter,Seshu Tirupathi,Giulio Zizzo,John D. Kelleher*

Main category: cs.CL

TL;DR: 提出Step-Tagging框架，通过实时监控推理步骤类型实现早期停止，显著减少token使用量同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 当前语言推理模型（LRMs）在推理过程中存在效率低下、过度生成验证和反思步骤的问题，需要更有效的监控和控制机制。

Method: 提出了Step-Tagging框架，包含一个轻量级句子分类器用于实时标注推理步骤类型，并引入了ReasonType推理步骤分类法。通过在线监控特定步骤的数量，建立可解释的早期停止标准。

Result: 在MATH500、GSM8K、AIME等数学任务以及GPQA、MMLU-Pro等非数学任务上评估，实现了20-50%的token减少，同时保持与标准生成相当的准确性，在计算密集型任务上效果最显著。

Conclusion: Step-Tagging框架为语言推理模型提供了一种新颖的轻量级监控和早期停止方法，能够在保持准确性的同时显著减少计算开销，并为研究LRM的推理行为提供了新工具。

Abstract: The field of Language Reasoning Models (LRMs) has been very active over the past few years with advances in training and inference techniques enabling LRMs to reason longer, and more accurately. However, a growing body of studies show that LRMs are still inefficient, over-generating verification and reflection steps. To address this challenge, we introduce the Step-Tagging framework, a lightweight sentence-classifier enabling real-time annotation of the type of reasoning steps that an LRM is generating. To monitor reasoning behaviors, we introduced ReasonType: a novel taxonomy of reasoning steps. Building on this framework, we demonstrated that online monitoring of the count of specific steps can produce effective interpretable early stopping criteria of LRM inferences. We evaluate the Step-tagging framework on three open-source reasoning models across standard benchmark datasets: MATH500, GSM8K, AIME and non-mathematical tasks (GPQA and MMLU-Pro). We achieve 20 to 50\% token reduction while maintaining comparable accuracy to standard generation, with largest gains observed on more computation-heavy tasks. This work offers a novel way to increase control over the generation of LRMs, and a new tool to study behaviors of LRMs.

</details>


### [16] [Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2512.14427)
*Gabriele Prato,Shagun Sodhani,Alessandro Sordoni,Sarath Chandar*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.

</details>


### [17] [SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models](https://arxiv.org/abs/2512.14481)
*Shizhuo Mao,Song Chen,Yi Kang*

Main category: cs.CL

TL;DR: SASQ 是一种轻量化 QAT 框架，仅优化激活量化因子而不改变预训练权重，实现了高精度静态推理，在 LLaMA2-7B 上超越了现有量化方案和 FP16 模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言任务上表现出色，但其规模增长速度快于 GPU 内存技术进步，导致部署困难。模型量化通过降低权重和激活的精度来缓解这一问题，但现有方案存在根本性权衡：动态量化计算开销大且难以在边缘设备部署，静态量化则牺牲精度。现有的量化感知训练（QAT）方法还存在权重训练成本高的问题。

Method: SASQ 框架专注于激活量化因子的优化，通过自适应截断部分异常值来降低量化难度，同时保持激活的分布特性。该方法不改变预训练权重，仅对量化因子进行轻量化训练，从而实现静态推理。

Result: SASQ 不仅超越了现有的 SOTA 量化方案，甚至优于对应的 FP16 模型。在 LLaMA2-7B 上，SASQ 在 WikiText2 数据集上的困惑度比 QuaRot 低 5.2%，比 FP16 模型低 4.7%。

Conclusion: SASQ 是一种专为激活量化因子设计的轻量化 QAT 框架，通过仅优化量化因子而不改变预训练权重，实现了高精度的静态推理和部署效率。该方法在 LLaMA2-7B 等模型上显著超越了现有 SOTA 量化方案，甚至优于 FP16 原始模型，为大型语言模型的高效部署提供了有前景的解决方案。

Abstract: Large language models (LLMs) excel at natural language tasks but face deployment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation precision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accuracy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the distributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 models. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.

</details>


### [18] [C-ing Clearly: Enhanced Binary Code Explanations using C code](https://arxiv.org/abs/2512.14500)
*Teodor Poncu,Ioana Pintilie,Marius Dragoi,Dragos Tantaru,Florin Brad*

Main category: cs.CL

TL;DR: 提出C-ing Clearly方法，利用C代码生成合成数据来增强LLM对汇编语言的理解，在二进制代码摘要和漏洞检测任务上取得改进。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常在高级编程语言编码任务上表现优异，但在低级编程语言（如汇编语言）方面理解能力有限，需要提升LLM对汇编代码的理解能力。

Method: 提出名为C-ing Clearly的合成数据生成方法，利用对应的C代码来增强LLM对汇编语言的理解，通过生成的数据对LLM进行微调。

Result: 实验表明，通过该方法微调的LLM在二进制代码摘要和漏洞检测任务上性能得到提升，且在不同LLM家族和模型规模上都取得了稳定的增益。

Conclusion: 通过C-ing Clearly方法生成合成数据并微调LLM，能够有效提升LLM在汇编语言理解方面的能力，在二进制代码摘要和漏洞检测任务上取得了稳定改进，且该方法在不同LLM家族和模型规模上均表现一致。

Abstract: Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.

</details>


### [19] [Linguists should learn to love speech-based deep learning models](https://arxiv.org/abs/2512.14506)
*Marianne de Heer Kloots,Paul Boersma,Willem Zuidema*

Main category: cs.CL

TL;DR: 批评现有文本LLM框架的局限性，主张音频深度学习模型对语言学研究至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的LLM框架限制了与语言学的有效互动，许多关于人类语言的有趣问题无法通过书面文本充分捕捉。

Method: 通过论证音频模型在捕捉人类语言本质特征方面的优势，提出将音频深度学习纳入研究框架。

Result: 确立了音频深度学习模型在语言研究中的关键地位，为技术系统与语言学理论的融合提供了新方向。

Conclusion: 音频深度学习模型应成为连接深度学习系统与语言学理论的关键桥梁，以弥补文本模型的局限性。

Abstract: Futrell and Mahowald present a useful framework bridging technology-oriented deep learning systems and explanation-oriented linguistic theories. Unfortunately, the target article's focus on generative text-based LLMs fundamentally limits fruitful interactions with linguistics, as many interesting questions on human language fall outside what is captured by written text. We argue that audio-based deep learning models can and should play a crucial role.

</details>


### [20] [VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse](https://arxiv.org/abs/2512.14531)
*Ying Nie,Kai Han,Hongguang Li,Hang Zhou,Tianyu Guo,Enhua Wu,Xinghao Chen,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出VersatileFFN，一种新颖的FFN架构，通过宽度和深度维度的参数复用，在固定参数预算下提升LLM能力，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效方法（如剪枝和量化）主要压缩预训练模型而不增强架构能力，达到基础模型的表示上限，需要新的方法在固定参数预算下提升模型能力。

Method: 提出VersatileFFN，包含宽度自适应路径（从单个共享FFN生成子专家混合）和深度自适应路径（递归应用同一FFN模拟深层处理），通过难度感知门控动态平衡两条路径。

Result: 在多样化基准测试和模型规模上的实验证明了该方法的有效性，所有额外能力都来自计算而非内存增加。

Conclusion: VersatileFFN通过创新的双路径设计，在固定参数预算下实现了参数在宽度和深度维度的灵活复用，为LLM的高效扩展提供了新思路。

Abstract: The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering "easy" tokens through the efficient width-wise route and allocating deeper iterative refinement to "hard" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN.

</details>


### [21] [Dual Language Models: Balancing Training Efficiency and Overfitting Resilience](https://arxiv.org/abs/2512.14549)
*David Samuel,Lucas Georges Gabriel Charpentier*

Main category: cs.CL

TL;DR: 通过结合自回归和掩码扩散训练目标，无需架构修改就能获得优于单一目标模型的性能，且最优比例在不同任务中保持一致。


<details>
  <summary>Details</summary>
Motivation: 自回归模型训练效率高但容易过拟合，掩码扩散模型训练效率低但抗过拟合能力强。研究者希望结合两者的优势，探索双目标训练是否能达到最佳平衡。

Method: 作者训练并评估了50个在不同数据重复水平下的语言模型，通过调整自回归和掩码扩散目标的权重比例来寻找最优组合策略。

Result: 实验表明，在所有评估设置下，结合两种目标都是最优选择，而且无论目标是优化自回归还是掩码扩散的下游性能，最优比例都相似。

Conclusion: 该研究表明，通过结合自回归和掩码扩散训练目标，可以在不改变架构的情况下获得优于单一目标模型的性能，这种双目标训练方法在各种数据重复设置下都能达到最佳效果，且最优比例在不同下游任务中具有一致性。

Abstract: This paper combines autoregressive and masked-diffusion training objectives without any architectural modifications, resulting in flexible language models that outperform single-objective models. Autoregressive modeling has been a popular approach, partly because of its training efficiency; however, that comes at the cost of sensitivity to overfitting. On the other hand, masked-diffusion models are less efficient to train while being more resilient to overfitting. In this work, we demonstrate that dual-objective training achieves the best of both worlds. To derive the optimal ratio between both objectives, we train and evaluate 50 language models under varying levels of data repetition. We show that it is optimal to combine both objectives under all evaluated settings and that the optimal ratio is similar whether targeting autoregressive or masked-diffusion downstream performance.

</details>


### [22] [VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models](https://arxiv.org/abs/2512.14554)
*Nguyen Tien Dong,Minh-Anh Nguyen,Thanh Dat Hoang,Nguyen Tuan Ngoc,Dao Xuan Quang Minh,Phan Phi Hai,Nguyen Thi Ngoc Anh,Dang Van Tu,Binh Vu*

Main category: cs.CL

TL;DR: VLegal-Bench是首个针对越南法律任务的全面基准，基于Bloom认知分类法设计，包含10,450个专家标注样本，用于系统评估LLM的法律理解能力。


<details>
  <summary>Details</summary>
Motivation: 越南法律的复杂性、层级结构和频繁修订给评估大语言模型（LLM）理解和运用法律知识的能力带来了巨大挑战，需要专门的基准来系统评估LLM在越南法律任务上的表现。

Method: 通过严格的标注流程生成10,450个样本，由法律专家使用标注系统进行标注和交叉验证，确保每个样本都基于权威法律文件，并反映真实世界法律助理工作流程，包括一般法律问答、检索增强生成、多步推理和基于越南法律的场景问题解决。

Result: VLegal-Bench是首个全面评估LLM在越南法律任务上的基准，基于Bloom认知分类法设计，涵盖多个层次的法律理解任务，反映了实际使用场景。

Conclusion: VLegal-Bench为评估LLM在越南法律领域的性能提供了标准化、透明且认知科学的评估框架，支持开发更可靠、可解释且符合伦理的AI辅助法律系统。

Abstract: The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.

</details>


### [23] [Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis](https://arxiv.org/abs/2512.14561)
*Hongli Li,Che Han Chen,Kevin Fan,Chiho Young-Johnson,Soyoung Lim,Yali Feng*

Main category: cs.CL

TL;DR: 系统综述显示LLM在作文评分中与人工评分员的一致性为中等至良好，但存在显著变异性，需要标准化报告实践。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自动作文评分中展现出潜力，但其与人工评分员一致性的实证研究结果存在矛盾，需要系统评估其可靠性。

Method: 遵循PRISMA 2020指南，对2022年1月至2025年8月期间发表的65项研究进行系统综述，分析LLM与人工评分员在自动作文评分中的一致性指标。

Result: 研究发现LLM与人工评分员的一致性普遍处于中等至良好水平（一致性指数多在0.30-0.80之间），但不同研究间存在显著变异性，反映了研究特定因素和缺乏标准化报告实践的影响。

Conclusion: LLM与人工评分员在自动作文评分中的一致性存在中等至良好的水平，但存在显著变异性，需要标准化报告实践和进一步研究来提升可靠性。

Abstract: Despite the growing promise of large language models (LLMs) in automatic essay scoring (AES), empirical findings regarding their reliability compared to human raters remain mixed. Following the PRISMA 2020 guidelines, we synthesized 65 published and unpublished studies from January 2022 to August 2025 that examined agreement between LLMs and human raters in AES. Across studies, reported LLM-human agreement was generally moderate to good, with agreement indices (e.g., Quadratic Weighted Kappa, Pearson correlation, and Spearman's rho) mostly ranging between 0.30 and 0.80. Substantial variability in agreement levels was observed across studies, reflecting differences in study-specific factors as well as the lack of standardized reporting practices. Implications and directions for future research are discussed.

</details>


### [24] [Polypersona: Persona-Grounded LLM for Synthetic Survey Responses](https://arxiv.org/abs/2512.14562)
*Tejaswani Dash,Dinesh Karri,Anudeep Vurity,Gautam Datla,Tazeem Ahmad,Saima Rafi,Rohith Tangudu*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper introduces PolyPersona, a generative framework for synthesizing persona-conditioned survey responses across multiple domains. The framework instruction-tunes compact chat models using parameter-efficient LoRA adapters with 4-bit quantization under a resource-adaptive training setup. A dialogue-based data pipeline explicitly preserves persona cues, ensuring consistent behavioral alignment across generated responses. Using this pipeline, we construct a dataset of 3,568 synthetic survey responses spanning ten domains and 433 distinct personas, enabling controlled instruction tuning and systematic multi-domain evaluation. We evaluate the generated responses using a multi-metric evaluation suite that combines standard text generation metrics, including BLEU, ROUGE, and BERTScore, with survey-specific metrics designed to assess structural coherence, stylistic consistency, and sentiment alignment.Experimental results show that compact models such as TinyLlama 1.1B and Phi-2 achieve performance comparable to larger 7B to 8B baselines, with a highest BLEU score of 0.090 and ROUGE-1 of 0.429. These findings demonstrate that persona-conditioned fine-tuning enables small language models to generate reliable and coherent synthetic survey data. The proposed framework provides an efficient and reproducible approach for survey data generation, supporting scalable evaluation while facilitating bias analysis through transparent and open protocols.

</details>


### [25] [Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies](https://arxiv.org/abs/2512.14576)
*Ekaterina Artemova,Laurie Burchell,Daryna Dementieva,Shu Okabe,Mariya Shmatova,Pedro Ortiz Suarez*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This tutorial (https://tum-nlp.github.io/low-resource-tutorial) is designed for NLP practitioners, researchers, and developers working with multilingual and low-resource languages who seek to create more equitable and socially impactful language technologies. Participants will walk away with a practical toolkit for building end-to-end NLP pipelines for underrepresented languages -- from data collection and web crawling to parallel sentence mining, machine translation, and downstream applications such as text classification and multimodal reasoning. The tutorial presents strategies for tackling the challenges of data scarcity and cultural variance, offering hands-on methods and modeling frameworks. We will focus on fair, reproducible, and community-informed development approaches, grounded in real-world scenarios. We will showcase a diverse set of use cases covering over 10 languages from different language families and geopolitical contexts, including both digitally resource-rich and severely underrepresented languages.

</details>


### [26] [Towards Nepali-language LLMs: Efficient GPT training with a Nepali BPE tokenizer](https://arxiv.org/abs/2512.14585)
*Adarsha Shrestha,Basanta Pokharel,Binit Shrestha,Smriti Adhikari,Dinesh Gothe*

Main category: cs.CL

TL;DR: 本研究开发了一个基于GPT-2的尼泊尔语语言模型，通过定制分词器、优化训练策略和集成FlashAttention，显著提升了尼泊尔语文本生成能力，最终困惑度达到21.80。


<details>
  <summary>Details</summary>
Motivation: 尼泊尔语作为一种低资源语言，由于其复杂的语法、粘着性形态和高质量语料库的有限可用性，在自然语言处理领域面临挑战。现有的编码器架构不足以满足尼泊尔语特定文本生成的需求。

Method: 采用GPT-2架构，结合GPT-3启发的训练策略（优化学习率调度、批量缩放和架构改进），训练定制16k BPE分词器，使用10.75GB清洗后的NepBERTa语料库和网络爬取的尼泊尔新闻文章进行预训练，集成FlashAttention以减少内存使用并稳定训练。

Result: 经过两个epoch的训练，模型取得了训练损失3.168177、验证损失3.081982和最终困惑度21.80的成绩，能够生成连贯的尼泊尔新闻风格文本。

Conclusion: 该研究成功开发了一个基于GPT-2的尼泊尔语语言模型，通过定制化分词器、优化训练策略和注意力机制改进，显著提升了尼泊尔语文本生成的质量和效率，为低资源语言NLP研究提供了有价值的参考。

Abstract: Nepali, a low-resource language spoken by over 32 million people, continues to face challenges in natural language processing (NLP) due to its complex grammar, agglutinative morphology, and limited availability of high-quality corpora. Most efforts to date have centered on basic encoder architectures; they remain insufficient for Nepali-specific text generation. This study presents a GPT-2-based Nepali language model trained using several training strategies inspired by GPT-3, including optimized learning rate schedules, batch scaling, and architectural refinements. A custom 16k Byte-Pair Encoding (BPE) tokenizer was trained exclusively on Nepali text to ensure more consistent segmentation and improved input representation. The model was pretrained on a combined dataset comprising a 10.75GB cleaned NepBERTa corpus and additional web-scraped Nepali news articles. FlashAttention was integrated to reduce memory usage and stabilize training. After two epochs, the model achieved a training loss of 3.168177, a validation loss of 3.081982, and a final perplexity of 21.80, demonstrating its capability to generate coherent Nepali news-style text.

</details>


### [27] [JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction](https://arxiv.org/abs/2512.14620)
*Atsuyuki Miyai,Shota Onohara,Jeonghun Baek,Kiyoharu Aizawa*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and humans verify the outputs and, when necessary, regenerate with adjusted prompts to ensure quality. By leveraging Nano Banana Pro's highly realistic image generation capabilities and its ability to embed clean Japanese text, we construct a high-quality benchmark at low cost, covering a wide range of background and layout designs. Experimental results show that all open-source LMMs struggle substantially with JMMMU-Pro, underscoring JMMMU-Pro as an important benchmark for guiding future efforts in the open-source community. We believe that JMMMU-Pro provides a more rigorous evaluation tool for assessing the Japanese capabilities of LMMs and that our Vibe Benchmark Construction also offers an efficient guideline for future development of image-based VQA benchmarks.

</details>


### [28] [TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines](https://arxiv.org/abs/2512.14645)
*David Schulmeister,Valentin Hartmann,Lars Klein,Robert West*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Today, a lot of research on language models is focused on large, general-purpose models. However, many NLP pipelines only require models with a well-defined, small set of capabilities. While large models are capable of performing the tasks of those smaller models, they are simply not fast enough to process large amounts of data or offer real-time responses. Furthermore, they often use unnecessarily large amounts of energy, leading to sustainability concerns and problems when deploying them on battery-powered devices. In our work, we show how to train small models for such efficiency-critical applications. As opposed to many off-the-shelf NLP pipelines, our models use modern training techniques such as distillation, and offer support for low-resource languages. We call our models TiME (Tiny Monolingual Encoders) and comprehensively evaluate them on a range of common NLP tasks, observing an improved trade-off between benchmark performance on one hand, and throughput, latency and energy consumption on the other. Along the way, we show that distilling monolingual models from multilingual teachers is possible, and likewise distilling models with absolute positional embeddings from teachers with relative positional embeddings.

</details>


### [29] [Fast and Accurate Causal Parallel Decoding using Jacobi Forcing](https://arxiv.org/abs/2512.14681)
*Lanxiang Hu,Siqi Kou,Yichao Fu,Samyam Rajbhandari,Tajana Rosing,Yuxiong He,Zhijie Deng,Hao Zhang*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multi-token generation has emerged as a promising paradigm for accelerating transformer-based large model inference. Recent efforts primarily explore diffusion Large Language Models (dLLMs) for parallel decoding to reduce inference latency. To achieve AR-level generation quality, many techniques adapt AR models into dLLMs to enable parallel decoding. However, they suffer from limited speedup compared to AR models due to a pretrain-to-posttrain mismatch. Specifically, the masked data distribution in post-training deviates significantly from the real-world data distribution seen during pretraining, and dLLMs rely on bidirectional attention, which conflicts with the causal prior learned during pretraining and hinders the integration of exact KV cache reuse. To address this, we introduce Jacobi Forcing, a progressive distillation paradigm where models are trained on their own generated parallel decoding trajectories, smoothly shifting AR models into efficient parallel decoders while preserving their pretrained causal inference property. The models trained under this paradigm, Jacobi Forcing Model, achieves 3.8x wall-clock speedup on coding and math benchmarks with minimal loss in performance. Based on Jacobi Forcing Models' trajectory characteristics, we introduce multi-block decoding with rejection recycling, which enables up to 4.5x higher token acceptance count per iteration and nearly 4.0x wall-clock speedup, effectively trading additional compute for lower inference latency. Our code is available at https://github.com/hao-ai-lab/JacobiForcing.

</details>


### [30] [Spoken DialogSum: An Emotion-Rich Conversational Dataset for Spoken Dialogue Summarization](https://arxiv.org/abs/2512.14687)
*Yen-Ju Lu,Kunxiao Gao,Mingrui Liang,Helin Wang,Thomas Thebaud,Laureano Moro-Velazquez,Najim Dehak,Jesus Villalba*

Main category: cs.CL

TL;DR: 提出了首个对齐原始对话音频、事实摘要、情感摘要及副语言标签的数据集 Spoken DialogSum，用于情感感知的口语对话摘要研究。


<details>
  <summary>Details</summary>
Motivation: 当前音频语言模型能够处理长对话，但情感感知或口语对话摘要研究受限于缺乏同时包含语音、摘要和副语言线索的数据集。

Method: 数据集构建分为两个阶段：1）使用大语言模型重写 DialogSum 脚本，加入类似 Switchboard 的填充词和反馈词，并为每个话语标注情感、音高和语速；2）使用富有表现力的 TTS 引擎从标注脚本合成语音，并与副语言标签对齐。

Result: 构建了 Spoken DialogSum 数据集，包含 13,460 个情感多样的对话，每个对话都配有事实摘要和情感聚焦摘要。基线实验显示，音频语言模型将情感摘要的 ROUGE-L 分数相对级联 ASR-LLM 系统提高了 28%。

Conclusion: Spoken DialogSum 填补了语音、摘要和副语言线索对齐数据的空白，为情感感知和口语对话摘要研究提供了重要资源。实验表明，端到端的音频语言模型在情感摘要任务上显著优于级联系统，验证了直接建模语音的价值。

Abstract: Recent audio language models can follow long conversations. However, research on emotion-aware or spoken dialogue summarization is constrained by the lack of data that links speech, summaries, and paralinguistic cues. We introduce Spoken DialogSum, the first corpus aligning raw conversational audio with factual summaries, emotion-rich summaries, and utterance-level labels for speaker age, gender, and emotion. The dataset is built in two stages: first, an LLM rewrites DialogSum scripts with Switchboard-style fillers and back-channels, then tags each utterance with emotion, pitch, and speaking rate. Second, an expressive TTS engine synthesizes speech from the tagged scripts, aligned with paralinguistic labels. Spoken DialogSum comprises 13,460 emotion-diverse dialogues, each paired with both a factual and an emotion-focused summary. The dataset is available online at https://fatfat-emosum.github.io/EmoDialog-Sum-Audio-Samples/. Baselines show that an Audio-LLM raises emotional-summary ROUGE-L by 28% relative to a cascaded ASR-LLM system, confirming the value of end-to-end speech modeling.

</details>


### [31] [MMGR: Multi-Modal Generative Reasoning](https://arxiv.org/abs/2512.14691)
*Zefan Cai,Haoyi Qiu,Tianyi Ma,Haozhe Zhao,Gengze Zhou,Kung-Hsiang Huang,Parisa Kordjamshidi,Minjia Zhang,Xiao Wen,Jiuxiang Gu,Nanyun Peng,Junjie Hu*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [32] [BiCoRec: Bias-Mitigated Context-Aware Sequential Recommendation Model](https://arxiv.org/abs/2512.13848)
*Mufhumudzi Muthivhi,Terence L van Zyl,Hairong Wang*

Main category: cs.IR

TL;DR: 提出BiCoRec框架，通过协同注意力机制和一致性损失训练，有效缓解序列推荐中的流行度偏差，显著提升冷门物品偏好用户的推荐性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的序列推荐模型存在固有的流行度偏差问题，需要一种能够自适应适应用户对热门和冷门物品偏好变化的解决方案。

Method: 提出BiCoRec框架，利用协同注意力机制获取流行度加权的用户序列表示，并采用基于一致性损失的新训练方案从未来偏好中学习。

Result: BiCoRec在偏好冷门物品的用户中，NDCG@10平均提升26.00%；在Movies、Fashion、Games和Music数据集上的NDCG@10得分分别为0.0102、0.0047、0.0021和0.0005。

Conclusion: BiCoRec通过自适应处理用户对热门和冷门物品的偏好变化，显著提升了推荐性能，特别是在偏好冷门物品的用户群体中表现突出，证明了该框架在缓解流行度偏差方面的有效性。

Abstract: Sequential recommendation models aim to learn from users evolving preferences. However, current state-of-the-art models suffer from an inherent popularity bias. This study developed a novel framework, BiCoRec, that adaptively accommodates users changing preferences for popular and niche items. Our approach leverages a co-attention mechanism to obtain a popularity-weighted user sequence representation, facilitating more accurate predictions. We then present a new training scheme that learns from future preferences using a consistency loss function. BiCoRec aimed to improve the recommendation performance of users who preferred niche items. For these users, BiCoRec achieves a 26.00% average improvement in NDCG@10 over state-of-the-art baselines. When ranking the relevant item against the entire collection, BiCoRec achieves NDCG@10 scores of 0.0102, 0.0047, 0.0021, and 0.0005 for the Movies, Fashion, Games and Music datasets.

</details>


### [33] [Intent-Guided Reasoning for Sequential Recommendation](https://arxiv.org/abs/2512.14034)
*Yifan Shao,Peilin Zhou*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sequential recommendation systems aim to capture users' evolving preferences from their interaction histories. Recent reasoningenhanced methods have shown promise by introducing deliberate, chain-of-thought-like processes with intermediate reasoning steps. However, these methods rely solely on the next target item as supervision, leading to two critical issues: (1) reasoning instability--the process becomes overly sensitive to recent behaviors and spurious interactions like accidental clicks, and (2) surface-level reasoning--the model memorizes item-to-item transitions rather than understanding intrinsic behavior patterns. To address these challenges, we propose IGR-SR, an Intent-Guided Reasoning framework for Sequential Recommendation that anchors the reasoning process to explicitly extracted high-level intents. Our framework comprises three key components: (1) a Latent Intent Distiller (LID) that efficiently extracts multi-faceted intents using a frozen encoder with learnable tokens, (2) an Intent-aware Deliberative Reasoner (IDR) that decouples reasoning into intent deliberation and decision-making via a dual-attention architecture, and (3) an Intent Consistency Regularization (ICR) that ensures robustness by enforcing consistent representations across different intent views. Extensive experiments on three public datasets demonstrate that IGR-SR achieves an average 7.13% improvement over state-of-the-art baselines. Critically, under 20% behavioral noise, IGR-SR degrades only 10.4% compared to 16.2% and 18.6% for competing methods, validating the effectiveness and robustness of intent-guided reasoning.

</details>


### [34] [DTRec: Learning Dynamic Reasoning Trajectories for Sequential Recommendation](https://arxiv.org/abs/2512.14036)
*Yifan Shao,Peilin Zhou,Shoujin Wang,Weizhi Zhang,Xu Cai,Sunghun Kim*

Main category: cs.IR

TL;DR: DTRec：一种动态推理轨迹顺序推荐框架，通过层次化过程监督和自适应推理停止机制，解决了现有方法在推理方向和深度上的静态限制，显著提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有推理增强顺序推荐方法存在两个关键限制：1) 静态推理方向，使用与人类层次化推理不匹配的扁平监督信号；2) 固定推理深度，对所有用户应用相同的计算量而不考虑模式复杂性。这些刚性导致性能次优和计算资源浪费。

Method: 提出了DTRec框架，包含两个核心组件：1) 层次化过程监督(HPS)：提供从粗到细的监督信号，模拟人类认知过程的渐进式细化；2) 自适应推理停止(ARH)：通过联合监控三个指标动态调整推理步数。

Result: 在三个真实世界数据集上的实验表明，DTRec相比强基线实现了最高24.5%的性能提升，同时计算成本降低了最高41.6%。

Conclusion: DTRec通过引入层次化过程监督和自适应推理停止机制，成功解决了现有推理增强顺序推荐方法在推理方向和深度上的静态限制，实现了在提升推荐性能的同时显著降低计算成本，为动态推理轨迹在推荐系统中的应用提供了有效框架。

Abstract: Inspired by advances in LLMs, reasoning-enhanced sequential recommendation performs multi-step deliberation before making final predictions, unlocking greater potential for capturing user preferences. However, current methods are constrained by static reasoning trajectories that are ill-suited for the diverse complexity of user behaviors. They suffer from two key limitations: (1) a static reasoning direction, which uses flat supervision signals misaligned with human-like hierarchical reasoning, and (2) a fixed reasoning depth, which inefficiently applies the same computational effort to all users, regardless of pattern complexity. These rigidity lead to suboptimal performance and significant computational waste. To overcome these challenges, we propose DTRec, a novel and effective framework that explores the Dynamic reasoning Trajectory for Sequential Recommendation along both direction and depth. To guide the direction, we develop Hierarchical Process Supervision (HPS), which provides coarse-to-fine supervisory signals to emulate the natural, progressive refinement of human cognitive processes. To optimize the depth, we introduce the Adaptive Reasoning Halting (ARH) mechanism that dynamically adjusts the number of reasoning steps by jointly monitoring three indicators. Extensive experiments on three real-world datasets demonstrate the superiority of our approach, achieving up to a 24.5% performance improvement over strong baselines while simultaneously reducing computational cost by up to 41.6%.

</details>


### [35] [From Feature Interaction to Feature Generation: A Generative Paradigm of CTR Prediction Models](https://arxiv.org/abs/2512.14041)
*Mingjia Yin,Junwei Pan,Hao Wang,Ximei Wang,Shangyu Zhang,Jie Jiang,Defu Lian,Enhong Chen*

Main category: cs.IR

TL;DR: 提出监督特征生成框架SFG，将CTR预测从判别式特征交互转向生成式特征生成，解决嵌入坍缩和信息冗余问题，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有CTR预测模型主要遵循判别式范式，过度依赖原始ID嵌入的特征交互，导致嵌入维度坍缩和信息冗余问题。

Method: 提出监督特征生成（SFG）框架，包含编码器构建特征隐藏表示和解码器从隐藏表示重构所有特征嵌入，并引入监督损失利用点击信号。该框架可与现有CTR模型无缝集成。

Result: 大量实验表明SFG能持续缓解嵌入坍缩、减少信息冗余，并在多个数据集和基础模型上带来显著性能提升。

Conclusion: SFG框架通过将CTR预测从判别式特征交互范式转向生成式特征生成范式，有效解决了嵌入维度坍缩和信息冗余问题，为CTR模型提供了一种通用且有效的增强方案。

Abstract: Click-Through Rate (CTR) prediction, a core task in recommendation systems, aims to estimate the probability of users clicking on items. Existing models predominantly follow a discriminative paradigm, which relies heavily on explicit interactions between raw ID embeddings. However, this paradigm inherently renders them susceptible to two critical issues: embedding dimensional collapse and information redundancy, stemming from the over-reliance on feature interactions \emph{over raw ID embeddings}. To address these limitations, we propose a novel \emph{Supervised Feature Generation (SFG)} framework, \emph{shifting the paradigm from discriminative ``feature interaction" to generative ``feature generation"}. Specifically, SFG comprises two key components: an \emph{Encoder} that constructs hidden embeddings for each feature, and a \emph{Decoder} tasked with regenerating the feature embeddings of all features from these hidden representations. Unlike existing generative approaches that adopt self-supervised losses, we introduce a supervised loss to utilize the supervised signal, \ie, click or not, in the CTR prediction task. This framework exhibits strong generalizability: it can be seamlessly integrated with most existing CTR models, reformulating them under the generative paradigm. Extensive experiments demonstrate that SFG consistently mitigates embedding collapse and reduces information redundancy, while yielding substantial performance gains across various datasets and base models. The code is available at https://github.com/USTC-StarTeam/GE4Rec.

</details>


### [36] [AsarRec: Adaptive Sequential Augmentation for Robust Self-supervised Sequential Recommendation](https://arxiv.org/abs/2512.14047)
*Kaike Zhang,Qi Cao,Fei Sun,Xinran Liu*

Main category: cs.IR

TL;DR: 提出AsarRec自适应序列增强框架，通过可学习变换矩阵解决传统静态增强策略在序列推荐中的局限性，提升模型对噪声用户行为的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界用户行为常因人为错误、不确定性和行为模糊性而产生噪声，导致推荐性能下降。现有自监督学习方法依赖预定义的静态增强策略，存在两个关键问题：(1)最优增强类型在不同场景差异显著；(2)不恰当的增强可能降低推荐性能，限制了SSL的有效性。

Method: 首先将现有基本增强操作统一为结构化变换矩阵的公式化表示，然后通过编码用户序列为概率转移矩阵，并使用可微分的Semi-Sinkhorn算法将其投影为硬半双随机矩阵来学习生成变换矩阵。通过联合优化多样性、语义不变性和信息性三个目标来确保增强对下游任务有益。

Result: 在三个基准数据集上不同噪声水平下的广泛实验验证了AsarRec的有效性，证明了其优越的鲁棒性和一致的改进效果。

Conclusion: AsarRec通过自适应增强框架有效解决了传统静态增强策略的局限性，在多种噪声水平下展现出优越的鲁棒性和一致的性能提升，为序列推荐系统的噪声处理提供了新思路。

Abstract: Sequential recommender systems have demonstrated strong capabilities in modeling users' dynamic preferences and capturing item transition patterns. However, real-world user behaviors are often noisy due to factors such as human errors, uncertainty, and behavioral ambiguity, which can lead to degraded recommendation performance. To address this issue, recent approaches widely adopt self-supervised learning (SSL), particularly contrastive learning, by generating perturbed views of user interaction sequences and maximizing their mutual information to improve model robustness. However, these methods heavily rely on their pre-defined static augmentation strategies~(where the augmentation type remains fixed once chosen) to construct augmented views, leading to two critical challenges: (1) the optimal augmentation type can vary significantly across different scenarios; (2) inappropriate augmentations may even degrade recommendation performance, limiting the effectiveness of SSL. To overcome these limitations, we propose an adaptive augmentation framework. We first unify existing basic augmentation operations into a unified formulation via structured transformation matrices. Building on this, we introduce AsarRec (Adaptive Sequential Augmentation for Robust Sequential Recommendation), which learns to generate transformation matrices by encoding user sequences into probabilistic transition matrices and projecting them into hard semi-doubly stochastic matrices via a differentiable Semi-Sinkhorn algorithm. To ensure that the learned augmentations benefit downstream performance, we jointly optimize three objectives: diversity, semantic invariance, and informativeness. Extensive experiments on three benchmark datasets under varying noise levels validate the effectiveness of AsarRec, demonstrating its superior robustness and consistent improvements.

</details>


### [37] [SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions](https://arxiv.org/abs/2512.14277)
*Panayiotis Smeros,Vincent Emonet,Ruijie Wang,Ana-Claudia Sima,Tarcisio Mendes de Farias*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.

</details>


### [38] [Dynamic Context Selection for Retrieval-Augmented Generation: Mitigating Distractors and Positional Bias](https://arxiv.org/abs/2512.14313)
*Malika Iratni,Mohand Boughanem,Taoufiq Dkaki*

Main category: cs.IR

TL;DR: 本文分析RAG系统中干扰文档和文档位置对生成质量的影响，提出动态预测最优检索文档数量的分类器，相比固定k值基线获得更好性能。


<details>
  <summary>Details</summary>
Motivation: 标准RAG系统通常采用固定的top k检索策略，这种策略存在两个主要问题：1) 可能错过相关信息或引入语义不相关的干扰文档，从而降低输出质量；2) 检索到的文档在输入上下文中的位置会影响模型注意力和生成结果，特别是'中间迷失'现象（位于中间的上下文容易被忽视）。

Method: 1. 系统分析干扰文档对生成质量的影响，量化不同条件下的效果；2. 研究相关文档在上下文窗口中的位置如何影响生成结果，特别是'中间迷失'现象；3. 提出一个上下文大小分类器，基于查询特定的信息需求动态预测最优检索文档数量；4. 将该方法集成到完整的RAG流程中进行验证。

Result: 提出的动态上下文大小分类器在完整RAG流程中表现出优于固定k值基线方法的性能，能够根据查询需求自适应地调整检索文档数量，提高生成质量。

Conclusion: 本文通过系统分析RAG系统中干扰文档对生成质量的影响，并研究相关文档在上下文中的位置效应，提出了一个动态预测最优检索文档数量的上下文大小分类器。该分类器能根据查询的具体信息需求自适应地调整检索数量，集成到完整RAG流程后，相比固定k值基线方法取得了更好的性能表现。

Abstract: Retrieval Augmented Generation (RAG) enhances language model performance by incorporating external knowledge retrieved from large corpora, which makes it highly suitable for tasks such as open domain question answering. Standard RAG systems typically rely on a fixed top k retrieval strategy, which can either miss relevant information or introduce semantically irrelevant passages, known as distractors, that degrade output quality. Additionally, the positioning of retrieved passages within the input context can influence the model attention and generation outcomes. Context placed in the middle tends to be overlooked, which is an issue known as the "lost in the middle" phenomenon. In this work, we systematically analyze the impact of distractors on generation quality, and quantify their effects under varying conditions. We also investigate how the position of relevant passages within the context window affects their influence on generation. Building on these insights, we propose a context-size classifier that dynamically predicts the optimal number of documents to retrieve based on query-specific informational needs. We integrate this approach into a full RAG pipeline, and demonstrate improved performance over fixed k baselines.

</details>


### [39] [PushGen: Push Notifications Generation with LLM](https://arxiv.org/abs/2512.14490)
*Shifu Bie,Jiangxia Cao,Zixiao Luo,Yichuan Zou,Lei Liang,Lu Zhang,Linxun Chen,Zhaojie Liu,Xuanping Li,Guorui Zhou,Kaiqiao Zhan,Kun Gai*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present PushGen, an automated framework for generating high-quality push notifications comparable to human-crafted content. With the rise of generative models, there is growing interest in leveraging LLMs for push content generation. Although LLMs make content generation straightforward and cost-effective, maintaining stylistic control and reliable quality assessment remains challenging, as both directly impact user engagement. To address these issues, PushGen combines two key components: (1) a controllable category prompt technique to guide LLM outputs toward desired styles, and (2) a reward model that ranks and selects generated candidates. Extensive offline and online experiments demonstrate its effectiveness, which has been deployed in large-scale industrial applications, serving hundreds of millions of users daily.

</details>


### [40] [RecGPT-V2 Technical Report](https://arxiv.org/abs/2512.14503)
*Chao Yi,Dian Chen,Gaoyang Guo,Jiakai Tang,Jian Wu,Jing Yu,Mao Zhang,Wen Chen,Wenjun Yang,Yujie Luo,Yuning Jiang,Zhujin Gao,Bo Zheng,Binbin Cao,Changfa Wu,Dixuan Wang,Han Wu,Haoyi Hu,Kewei Zhu,Lang Tian,Lin Yang,Qiqi Huang,Siqi Yang,Wenbo Su,Xiaoxiao He,Xin Tong,Xu Chen,Xunke Xi,Xiaowei Huang,Yaxuan Wu,Yeqiu Yang,Yi Hu,Yujin Yuan,Yuliang Yan,Zile Zhou*

Main category: cs.IR

TL;DR: RecGPT-V2通过分层多智能体系统、元提示、约束强化学习和智能体评估框架，解决了V1的计算效率、解释多样性、泛化能力和评估标准问题，在淘宝A/B测试中显著提升了各项指标，证明了LLM意图推理的工业可行性。


<details>
  <summary>Details</summary>
Motivation: RecGPT-V1虽然成功将LLM推理集成到用户兴趣挖掘和物品标签预测中，但存在四大根本局限：1) 跨多个推理路径的计算效率低下和认知冗余；2) 固定模板生成中解释多样性不足；3) 监督学习范式下泛化能力有限；4) 结果导向的简单评估无法匹配人类标准。

Method: 1. 分层多智能体系统：通过协调协作重构意图推理，消除认知重复，实现多样化意图覆盖；结合混合表示推理压缩用户行为上下文。
2. 元提示框架：动态生成上下文自适应提示，提升解释多样性。
3. 约束强化学习：缓解多奖励冲突，优化标签预测和解释接受度。
4. 智能体即法官评估框架：将评估分解为多步推理，提升人类偏好对齐。

Result: 1. 计算效率：GPU消耗降低60%，独家召回率从9.39%提升至10.99%。
2. 解释多样性：提升+7.3%。
3. 预测性能：标签预测提升+24.1%，解释接受度提升+13.0%。
4. 在线A/B测试：CTR提升+2.98%，IPV提升+3.71%，TV提升+2.19%，NER提升+11.46%。
5. 人类偏好对齐：通过智能体即法官框架得到改善。

Conclusion: RecGPT-V2通过分层多智能体系统、元提示框架、约束强化学习和智能体即法官评估框架，成功解决了RecGPT-V1的四大局限性，显著提升了推荐系统的效率、多样性、泛化能力和人类偏好对齐，证明了LLM驱动的意图推理在大规模工业部署中的技术可行性和商业价值。

Abstract: Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards.
  To address these challenges, we present RecGPT-V2 with four key innovations. First, a Hierarchical Multi-Agent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, a Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility.

</details>


### [41] [Pairwise Comparison for Bias Identification and Quantification](https://arxiv.org/abs/2512.14565)
*Fabian Haak,Philipp Schaer*

Main category: cs.IR

TL;DR: 通过优化成对比较标注方法，降低主观语言特征（如偏见）的标注成本，支持可复现的量化分析。


<details>
  <summary>Details</summary>
Motivation: 在线新闻和社交媒体中的语言偏见普遍存在但难以测量，其识别和量化面临主观性、语境依赖性和高质量标注数据稀缺等挑战。研究旨在通过利用成对比较来减少标注工作量，并克服该方法成本高昂的问题。

Method: 研究采用成对比较标注方法，通过模拟环境评估不同评分技术和三种成本感知替代方案的参数效果。模拟包括潜在严重程度分布、距离校准噪声和合成标注者偏见。在真实数据集上评估最有前景的设置，并与大语言模型直接评估及原始成对比较基线进行对比。

Result: 研究发现成对比较可作为量化主观语言特征的实用基础，支持可复现的偏见分析。通过优化比较和匹配组件，在模拟和真实数据应用中验证了成本感知标注方案的有效性。

Conclusion: 本研究通过优化成对比较标注方法，为量化主观语言特征（如偏见）提供了实用基础，支持可复现的偏见分析。贡献包括比较与匹配组件的优化、端到端评估框架以及成本感知的大规模标注实施蓝图。

Abstract: Linguistic bias in online news and social media is widespread but difficult to measure. Yet, its identification and quantification remain difficult due to subjectivity, context dependence, and the scarcity of high-quality gold-label datasets. We aim to reduce annotation effort by leveraging pairwise comparison for bias annotation. To overcome the costliness of the approach, we evaluate more efficient implementations of pairwise comparison-based rating. We achieve this by investigating the effects of various rating techniques and the parameters of three cost-aware alternatives in a simulation environment. Since the approach can in principle be applied to both human and large language model annotation, our work provides a basis for creating high-quality benchmark datasets and for quantifying biases and other subjective linguistic aspects.
  The controlled simulations include latent severity distributions, distance-calibrated noise, and synthetic annotator bias to probe robustness and cost-quality trade-offs. In applying the approach to human-labeled bias benchmark datasets, we then evaluate the most promising setups and compare them to direct assessment by large language models and unmodified pairwise comparison labels as baselines. Our findings support the use of pairwise comparison as a practical foundation for quantifying subjective linguistic aspects, enabling reproducible bias analysis. We contribute an optimization of comparison and matchmaking components, an end-to-end evaluation including simulation and real-data application, and an implementation blueprint for cost-aware large-scale annotation

</details>
