<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 35]
- [cs.IR](#cs.IR) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Noise-Aware Named Entity Recognition for Historical VET Documents](https://arxiv.org/abs/2601.00488)
*Alexander M. Esser,Jens Dörpinghaus*

Main category: cs.CL

TL;DR: 提出了一种针对职业教育培训领域历史数字化文档的鲁棒性命名实体识别方法，通过噪声感知训练、迁移学习和多阶段微调，显著提升了OCR噪声条件下的识别性能。


<details>
  <summary>Details</summary>
Motivation: 职业教育培训领域的历史数字化文档存在OCR噪声问题，当前缺乏针对该领域多实体类型的命名实体识别方法，需要提高在噪声条件下的识别鲁棒性。

Method: 采用噪声感知训练，通过合成注入OCR错误；结合迁移学习和多阶段微调；系统比较了在噪声数据、干净数据和人工数据上的三种互补训练策略。

Result: 实验结果表明，领域特定和噪声感知的微调显著提高了在噪声条件下的鲁棒性和准确性。该方法在德语文档上验证，但可扩展到任意语言。

Conclusion: 提出的方法是职业教育培训文档中多实体类型识别的首创方法之一，通过公开代码实现了领域特定噪声感知NER的可复现性。

Abstract: This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.

</details>


### [2] [RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning](https://arxiv.org/abs/2601.00086)
*Xiang Gao,Yuguang Yao,Qi Zhang,Kaiwen Dong,Avinash Baidya,Ruocheng Guo,Hilaf Hasson,Kamalika Das*

Main category: cs.CL

TL;DR: RIMRULE：基于动态规则注入的神经符号方法，通过从失败轨迹中提炼简洁可解释的规则，在推理时注入提示，以提升LLM在特定领域工具使用上的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在领域特定工具使用时表现不佳，因为这些API可能具有特殊性、文档不足或针对私有工作流程定制，需要有效的任务特定工具适应方法。

Method: 提出RIMRULE神经符号方法，通过动态规则注入实现LLM适应。从失败轨迹中提炼简洁可解释的规则，在推理时注入提示。规则由LLM自身提出，并使用最小描述长度目标进行整合，以促进通用性和简洁性。规则以自然语言和结构化符号形式存储，支持推理时高效检索。

Result: 在工具使用基准测试中，该方法在不修改LLM权重的情况下，提高了对已见和未见工具的准确性。优于基于提示的适应方法，并与微调互补。从一个LLM学习的规则可以重用以改进其他LLM，包括长推理LLM，突显了符号知识在不同架构间的可移植性。

Conclusion: RIMRULE提供了一种有效的神经符号方法，通过动态规则注入显著提升LLM在领域特定工具使用上的性能，且规则具有可移植性和架构无关性。

Abstract: Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.

</details>


### [3] [Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning](https://arxiv.org/abs/2601.00095)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CL

TL;DR: MetaJuLS：通过元强化学习学习通用约束传播策略，可在不同语言和任务间快速适应，显著加速结构化推理过程，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越需要结构化推理，从JSON模式强制执行到多语言解析，输出必须满足复杂约束。现有的方法通常需要针对特定任务重新训练，缺乏通用性和高效性。

Method: 提出MetaJuLS，一种元强化学习方法，通过将结构化推理建模为自适应约束传播，并使用元学习训练图注意力网络，学习通用的约束传播策略。

Result: 相比GPU优化基线实现1.5-2.0倍加速，精度保持在最先进解析器的0.2%以内；在10种语言的通用依存关系和LLM约束生成任务上，仅需5-10梯度步骤（5-15秒）即可适应新语言和任务；策略发现类人解析策略和新颖启发式方法。

Conclusion: MetaJuLS通过减少传播步骤显著降低了推理碳排放，为绿色AI做出贡献，展示了元强化学习在结构化推理中的强大潜力。

Abstract: Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable across languages and tasks without task-specific retraining. By formulating structured inference as adaptive constraint propagation and training a Graph Attention Network with meta-learning, MetaJuLS achieves 1.5--2.0$\times$ speedups over GPU-optimized baselines while maintaining within 0.2\% accuracy of state-of-the-art parsers. On Universal Dependencies across 10 languages and LLM-constrained generation (LogicBench, GSM8K-Constrained), MetaJuLS demonstrates rapid cross-domain adaptation: a policy trained on English parsing adapts to new languages and tasks with 5--10 gradient steps (5--15 seconds) rather than requiring hours of task-specific training. Mechanistic analysis reveals the policy discovers human-like parsing strategies (easy-first) and novel non-intuitive heuristics. By reducing propagation steps in LLM deployments, MetaJuLS contributes to Green AI by directly reducing inference carbon footprint.

</details>


### [4] [Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description](https://arxiv.org/abs/2601.00166)
*Yongmin Yoo,Kris W Pan*

Main category: cs.CL

TL;DR: Pat-DEVAL：首个针对专利说明书的多维度评估框架，通过Chain-of-Legal-Thought机制和LLM-as-a-judge范式，专门评估长文本结构连贯性和法定合规性。


<details>
  <summary>Details</summary>
Motivation: 现有专利自动起草系统虽然实现了端到端自动化，但缺乏对专利说明书长文本结构连贯性和法定合规性（如可实施性、书面描述要求）的专门评估方法。

Method: 提出Pat-DEVAL框架，采用LLM-as-a-judge范式，引入Chain-of-Legal-Thought（CoLT）机制——一种法律约束的推理方法，强制执行顺序性的专利法特定分析。

Result: 在Pap2Pat-EvalGold数据集上，经专利专家验证，Pat-DEVAL达到0.69的皮尔逊相关系数，显著优于基线指标和现有LLM评估器；在法律专业合规性方面相关性达0.73。

Conclusion: 通过明确注入法定约束，Pat-DEVAL能有效捕捉细微的法律有效性，为自动专利起草系统的实际部署建立了确保技术正确性和法律合规性的新标准。

Abstract: Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.

</details>


### [5] [Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation](https://arxiv.org/abs/2601.00181)
*Cheonkam Jeong,Adeline Nyamathi*

Main category: cs.CL

TL;DR: 该论文通过系统分析IEMOCAP数据集，填补了情感识别在对话中两个关键空白：理解架构选择的重要性，以及将识别与生成连接的语言学分析。研究发现上下文对话至关重要，简单的因果上下文架构就能达到最佳性能，同时揭示了情感与话语标记位置之间的显著关联。


<details>
  <summary>Details</summary>
Motivation: 当前对话情感识别（ERC）虽然准确率高，但存在两个关键空白：1）缺乏对哪些架构选择真正重要的理解；2）缺少将识别与生成连接的语言学分析。作者旨在通过系统分析IEMOCAP数据集来填补这些空白。

Method: 1）识别方面：采用10种子评估的严格消融研究，分析对话上下文、分层句子表示和外部情感词典的影响；2）语言学分析：分析5,286个话语标记出现情况，研究情感与标记位置之间的关联。

Result: 识别方面：对话上下文至关重要，90%的增益来自最近10-30轮对话；分层句子表示在提供上下文后不再有帮助；外部情感词典无增益。使用简单因果上下文架构达到82.69%（4类）和67.07%（6类）加权F1，优于先前方法。语言学分析：情感与话语标记位置显著相关（p<.0001），"悲伤"话语的左边缘标记使用率（21.9%）低于其他情感（28-32%）。

Conclusion: 对话上下文是情感识别的关键因素，简单的因果上下文架构就能达到最佳性能。悲伤话语缺乏显式语用信号，最需要上下文进行消歧，这与语言学分析发现一致。预训练编码器已充分捕获情感语义，无需额外情感词典。

Abstract: While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.
  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\% (4-way) and 67.07\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.
  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, "sad" utterances exhibit reduced left-periphery marker usage (21.9\%) compared to other emotions (28--32\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.

</details>


### [6] [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Zhesi Li,Man Wang*

Main category: cs.CL

TL;DR: 本文提出了一种针对时序知识图谱推理的蒸馏框架，利用大语言模型作为教师模型，将结构和时序推理能力迁移到轻量级学生模型中，在保持高效架构的同时提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱推理模型参数规模大、计算密集，导致硬件成本和能耗高，难以部署在资源受限的实时推理平台上。同时，现有的模型压缩和蒸馏技术主要针对静态知识图谱设计，无法充分捕捉时序知识图谱中的时间依赖关系，导致推理性能下降。

Method: 提出专门针对时序知识图谱推理的蒸馏框架，利用大语言模型作为教师模型指导蒸馏过程，有效迁移结构和时序推理能力到轻量级学生模型。通过整合大规模公共知识和任务特定的时序信息，增强学生模型对时序动态的建模能力，同时保持紧凑高效的架构。

Result: 在多个公开基准数据集上的大量实验表明，该方法持续优于强基线，在推理准确性、计算效率和实际可部署性之间实现了有利的权衡。

Conclusion: 提出的蒸馏框架成功解决了时序知识图谱推理模型的计算效率和部署限制问题，通过利用大语言模型作为教师，实现了结构和时序推理能力的有效迁移，为资源受限平台上的实时推理应用提供了可行的解决方案。

Abstract: Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.

</details>


### [7] [From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark](https://arxiv.org/abs/2601.00216)
*Jinning Zhang,Jie Song,Wenhui Tu,Zecheng Li,Jingxuan Li,Jin Li,Xuan Liu,Taole Sha,Zichen Wei,Yan Li*

Main category: cs.CL

TL;DR: 本研究提出了将循证医学原则融入图增强检索生成系统的通用策略，通过在知识图构建中集成PICO框架并采用贝叶斯重排序算法，提高了医学检索的质量和答案的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索增强生成的医学大语言模型主要关注性能提升，但忽略了循证医学的基本原则。存在两个关键问题：1）查询与检索证据之间缺乏PICO对齐；2）重排序过程中未考虑证据等级层次。

Method: 开发了一个通用的循证医学适配策略：1）将PICO框架整合到知识图构建和检索中；2）提出贝叶斯启发的重排序算法，在不引入预定义权重的情况下根据证据等级校准排序分数。在体育康复领域验证了这一框架。

Result: 系统在体育康复领域取得了良好性能：nugget覆盖率0.830、答案忠实度0.819、语义相似度0.882、PICOT匹配准确率0.788。五名临床专家在5点李克特量表中给出了4.66-4.84的高评分。发布了包含357,844个节点和371,226条边的知识图，以及1,637个问答对的基准数据集。

Conclusion: 提出的循证医学适配策略不仅提高了检索和答案质量，还能迁移到其他临床领域。发布的资源有助于缓解体育康复领域检索增强生成数据集稀缺的问题。

Abstract: In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.

</details>


### [8] [JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation](https://arxiv.org/abs/2601.00223)
*Leonard Lin,Adam Lensenmayer*

Main category: cs.CL

TL;DR: JP-TL-Bench是一个轻量级开放基准，通过参考无关的成对LLM比较评估日语-英语翻译系统，使用Bradley-Terry模型聚合结果并生成稳定的评分。


<details>
  <summary>Details</summary>
Motivation: 日语-英语翻译中，细微的礼貌、隐含意义、省略和语域选择对自然度影响很大，现有评估往往关注"翻译是否可接受"而非"哪个更好的翻译更好"。需要专门基准来指导翻译系统的迭代开发。

Method: 使用参考无关的成对LLM比较协议：将候选模型与固定的版本化锚定集进行对比，通过Bradley-Terry模型聚合成对结果，计算胜率并生成0-10分的"LT"评分（来自拟合对数强度的逻辑变换）。

Result: 开发了JP-TL-Bench基准，其评分结构稳定（基于相同的锚定集、评判者和聚合代码），使LLM评判既可靠又经济实惠。

Conclusion: JP-TL-Bench为日语-英语翻译系统开发提供了有效的迭代指导工具，特别适合评估细微翻译差异，解决了现有评估方法的局限性。

Abstract: We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often "which of these two good translations is better?" rather than "is this translation acceptable?" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 "LT" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.

</details>


### [9] [Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback](https://arxiv.org/abs/2601.00224)
*Yan Sun,Ming Cai,Stanley Kok*

Main category: cs.CL

TL;DR: 本文提出了两种互补的验证技术（Q*和Feedback+）嵌入生成器-判别器框架，减少企业级LLM助手在商业分析中的错误率和任务完成时间。


<details>
  <summary>Details</summary>
Motivation: 随着LLM助手在企业工作流中的集成日益深入，其生成准确、语义对齐且可执行输出的能力至关重要。但当前的对话式商业分析系统通常缺乏内置验证机制，用户需要手动验证可能存在缺陷的结果。

Method: 引入两种互补验证技术：Q*（通过反向翻译和语义匹配在代码与用户意图之间进行验证）和Feedback+（结合执行反馈指导代码优化）。这些机制嵌入生成器-判别器框架，将验证责任从用户转移到系统。

Result: 在Spider、Bird和GSM8K三个基准数据集上的评估表明，Q*和Feedback+均能降低错误率和任务完成时间。研究还发现反向翻译是主要瓶颈，为未来改进提供了方向。

Conclusion: 本研究贡献了一个面向设计的框架，用于构建更可靠、企业级的生成式AI系统，能够提供可信的决策支持。

Abstract: As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic matching between code and user intent, and Feedback+, which incorporates execution feedback to guide code refinement. Embedded within a generator-discriminator framework, these mechanisms shift validation responsibilities from users to the system. Evaluations on three benchmark datasets, Spider, Bird, and GSM8K, demonstrate that both Q* and Feedback+ reduce error rates and task completion time. The study also identifies reverse translation as a key bottleneck, highlighting opportunities for future improvement. Overall, this work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support.

</details>


### [10] [Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation](https://arxiv.org/abs/2601.00263)
*Qianli Wang,Van Bach Nguyen,Yihong Liu,Fedor Splitt,Nils Feldhus,Christin Seifert,Hinrich Schütze,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 该论文系统研究了多语言反事实生成，评估了直接生成与翻译生成的效果，分析了编辑模式、错误类型，并探讨了多语言反事实数据增强的潜力与局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在生成英语反事实方面表现出色且具备多语言能力，但其在多语言反事实生成上的有效性尚不明确，需要进行系统性研究。

Method: 1. 在六种语言上进行自动评估，比较直接生成的反事实和通过英语翻译获得的反事实；2. 分析高资源欧洲语言反事实的编辑模式；3. 识别并分类生成反事实中的主要错误类型；4. 评估多语言反事实数据增强对模型性能的影响。

Result: 1. 翻译生成的反事实有效性高于直接生成，但需要更多修改且质量仍不及原始英语反事实；2. 高资源欧洲语言的反事实编辑模式相似，表明跨语言扰动遵循共同策略原则；3. 识别出四种在多语言反事实中持续出现的错误类型；4. 多语言反事实数据增强比跨语言数据增强带来更大性能提升，特别是对低资源语言，但生成反事实的缺陷限制了模型性能和鲁棒性的增益。

Conclusion: 大语言模型在多语言反事实生成方面表现出潜力，但存在质量缺陷，这些缺陷限制了其在数据增强中的应用效果。研究揭示了跨语言反事实生成的模式相似性和常见错误，为改进多语言反事实生成提供了方向。

Abstract: Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.

</details>


### [11] [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](https://arxiv.org/abs/2601.00268)
*Doyoung Kim,Zhiwei Ren,Jie Hao,Zhongkai Sun,Lichao Wang,Xiyao Ma,Zack Ye,Xu Han,Jun Yin,Heng Ji,Wei Shen,Xing Fan,Benjamin Yao,Chenlei Guo*

Main category: cs.CL

TL;DR: WildAGTEval 是一个评估 LLM 代理在现实 API 复杂度下函数调用能力的基准，涵盖API规范和API执行两大维度，包含60种复杂度场景和约32K测试配置，揭示了当前先进LLM在现实场景中的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法假设理想化的 API 系统，忽视了现实世界因素如噪声API输出等。需要创建能真实反映API复杂度的基准来评估LLM代理的实际能力。

Method: 设计了WildAGTEval基准，包含两个维度：1) API规范（详细文档和使用约束），2) API执行（运行时挑战）。构建了包含60种不同复杂度场景的API系统，可组合成约32K测试配置，并提供用户-代理交互来评估LLM代理在这些场景中的表现。

Result: 系统评估多个先进LLM发现：1) 大多数场景都具有挑战性，2) 无关信息复杂度带来最大困难，使强LLM性能降低27.3%，3) 定性分析显示LLM偶尔会扭曲用户意图来声称任务完成，严重影响用户满意度。

Conclusion: WildAGTEval揭示了当前LLM代理在真实世界API调用中的显著局限，尤其是不相关信息处理的困难。需要改进LLM对用户意图的理解和API复杂场景的处理能力，这对实际应用至关重要。

Abstract: We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.

</details>


### [12] [Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations](https://arxiv.org/abs/2601.00282)
*Qianli Wang,Nils Feldhus,Pepa Atanasova,Fedor Splitt,Simon Ostermann,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 大规模语言模型量化虽然能加速推理和部署，但其对模型自解释（SEs）质量与忠实度的影响尚未被系统研究。本文发现量化通常会导致SEs质量适度下降（最高4.4%）和忠实度下降（最高2.38%），且影响因模型大小、量化技术和解释类型而异。


<details>
  <summary>Details</summary>
Motivation: 量化被广泛用于加速大语言模型推理和简化部署，但其对自解释（SEs）的影响仍未探索。自解释是LLMs为自身输出生成的理由解释，需要模型对其自身决策过程进行推理，这种能力可能对量化特别敏感。由于SEs在高风险应用中对透明度日益重要，理解量化是否以及多大程度上会降低SEs质量和忠实度至关重要。

Method: 研究考察了两种类型的自解释：自然语言解释（NLEs）和反事实示例，使用三种常见量化技术在不同比特宽度下对LLMs进行量化，并评估量化对SEs质量和忠实度的影响。此外，还进行了用户研究来评估量化对SEs连贯性和可信度的影响。

Result: 量化通常会导致SEs质量和忠实度适度下降（质量下降最高4.4%，忠实度下降最高2.38%）。用户研究显示量化降低了SEs的连贯性和可信度（最高8.5%）。与较小模型相比，较大模型在SE质量方面对量化的抵抗力有限，但在保持忠实度方面表现更好。此外，没有一种量化技术在任务准确性、SE质量和忠实度方面始终表现优异。

Conclusion: 量化对SEs的影响因具体情境而异，建议针对特定使用场景验证SE质量，特别是对更敏感的自然语言解释。尽管如此，SE质量和忠实度相对较小的恶化并不会削弱量化作为模型压缩技术的有效性。

Abstract: Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\%) and faithfulness (up to 2.38\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.

</details>


### [13] [DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection](https://arxiv.org/abs/2601.00303)
*Yuxin Li,Xiangyu Zhang,Yifei Li,Zhiwei Guo,Haoyang Zhang,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: DepFlow是一个三阶段抑郁症条件文本转语音框架，通过对抗训练学习与说话人和内容无关的抑郁症嵌入，并构建包含声学-语义不匹配的伪装抑郁症增强数据集，显著提升抑郁症检测模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症数据集（如DAIC-WOZ）中语言情感与诊断标签强耦合，导致模型学习语义捷径，在现实场景（如伪装抑郁症）中鲁棒性不足。真实临床数据受伦理和覆盖范围限制，需要可控合成平台。

Method: 1. 抑郁症声学编码器：通过对抗训练学习说话人和内容不变的抑郁症嵌入，实现有效解耦同时保持抑郁症可区分性（ROC-AUC: 0.693）。2. 流匹配TTS模型：使用FiLM调制将抑郁症嵌入注入合成过程，控制抑郁严重程度同时保持内容和说话人身份。3. 原型严重程度映射：提供抑郁症连续体上的平滑可解释操作。4. 构建伪装抑郁症增强数据集（CDoA），将抑郁声学模式与情感分层文本库中的积极/中性内容配对。

Result: CDoA数据集在三种抑郁症检测架构上分别提升macro-F1 9%、12%和5%，一致优于传统增强策略。DepFlow提供了可控合成平台，可用于对话系统和基于模拟的评估。

Conclusion: DepFlow通过解耦声学抑郁症特征和语义内容，有效缓解抑郁症检测中的语义偏见，提升模型在伪装抑郁症等现实场景中的鲁棒性。该方法不仅增强检测性能，还为有限临床数据环境下的应用提供了可控合成解决方案。

Abstract: Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.

</details>


### [14] [Robust Uncertainty Quantification for Factual Generation of Large Language Models](https://arxiv.org/abs/2601.00348)
*Yuhao Zhang,Zhongliang Yang,Linna Zhou*

Main category: cs.CL

TL;DR: 本研究提出了一种针对LLM幻觉检测的新方法，通过在包含虚假名称的陷阱问题中构建不确定性量化场景，创新的鲁棒不确定性量化方法在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在实际应用中面临幻觉问题，现有不确定性量化方法在常规问答中有效，但面对非标准或对抗性提问策略时存在明显不足，这限制了LLM在需要鲁棒批判性思维能力的实际应用中的可靠性。

Method: 构建包含虚假名称的陷阱问题集作为不确定性量化场景，并创新性地提出一种鲁棒不确定性量化方法(RU)。在四个不同模型上与基线方法进行对比实验。

Result: 构建的陷阱问题集表现优异，提出的RU方法在四个模型上均展现出卓越性能，与最佳基线方法相比，ROCAUC值平均提升0.1-0.2，为解决LLM幻觉问题提供了新视角和方法。

Conclusion: 该方法为LLM幻觉检测提供了有效的新途径，通过创新的不确定性量化框架显著提升了模型在面对非标准问题时的可靠性，为解决LLM幻觉问题做出了重要贡献。

Abstract: The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.

</details>


### [15] [The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining](https://arxiv.org/abs/2601.00364)
*Jiandong Shao,Raphael Tang,Crystina Zhang,Karin Sevegnani,Pontus Stenetorp,Jianfei Yang,Yao Lu*

Main category: cs.CL

TL;DR: 双语数据对多语言大语言模型的影响：平行语料恢复翻译性能但代码混合作用有限，跨语言理解无需双语数据


<details>
  <summary>Details</summary>
Motivation: 尽管多语言大语言模型在跨语言性能上表现优异，但其双语预训练数据的具体贡献机制尚不清楚。本研究旨在探究双语数据在不同跨语言任务中的作用差异。

Method: 通过控制性实验，从零开始预训练模型：1) 标准网页语料库；2) 去除所有双语文档的单语版本。分析双语数据占比（仅2%）的影响。将双语数据细分为平行语料（14%）、代码混合（72%）和其他（14%），并进行粒度化消融实验：将平行或代码混合数据重新加入单语语料库。

Result: 1) 移除双语数据使翻译性能下降56%（BLEU）；2) 跨语言QA和一般推理任务保持稳定；3) 平行语料能恢复91%的翻译性能，代码混合贡献有限；4) 其他跨语言任务基本不受双语数据类型影响。

Conclusion: 翻译性能严重依赖平行语料提供的系统性词元级对齐，而跨语言理解和推理能力无需双语数据即可实现。双语数据对模型的贡献具有任务特异性。

Abstract: Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.

</details>


### [16] [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
*Taj Gillin,Adam Lalani,Kenneth Zhang,Marcel Mateos Salles*

Main category: cs.CL

TL;DR: BERT-JEPA (BEPA) 在BERT模型中添加JEPA训练目标，解决[CLS]嵌入空间坍塌问题，将其转换为语言无关空间，提升多语言任务性能。


<details>
  <summary>Details</summary>
Motivation: BERT模型的[CLS]嵌入空间在多语言任务中存在坍塌问题，限制了其在跨语言任务中的表现。Joint Embedding Predictive Architectures (JEPA)作为一种新兴的自监督训练技术，具有解决这一问题的潜力。

Method: 在BERT风格模型中添加JEPA训练目标，构建BERT-JEPA (BEPA)训练范式。该方法通过JEPA训练目标来对抗[CLS]嵌入空间的坍塌，将其转化为语言无关的嵌入空间。

Result: BERT-JEPA模型在多项多语言基准测试中表现出了性能提升，验证了该方法的有效性。

Conclusion: BERT-JEPA通过结合JEPA训练目标，成功解决了BERT模型中[CLS]嵌入空间的坍塌问题，创造了语言无关的嵌入空间，从而提升了多语言任务的性能。

Abstract: Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.

</details>


### [17] [Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach](https://arxiv.org/abs/2601.00388)
*Biao Wu,Meng Fang,Ling Chen,Ke Xu,Tao Cheng,Jun Wang*

Main category: cs.CL

TL;DR: Geo-R是一个无需检索的视觉语言模型地理定位框架，通过基于规则的分层推理链和强化学习优化，利用真实坐标数据生成结构化监督，提高定位准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型地理定位方法依赖于合成推理标注或外部图像检索，这限制了可解释性和泛化能力。需要一种不依赖检索的、可直接从真实坐标数据生成结构化监督的框架。

Method: 1) 提出"区域链"规则分层推理范式，将GPS坐标映射到地理实体层次结构；2) 采用基于Haversine距离的轻量级强化学习策略，通过空间对齐奖励优化模型预测；3) 完全基于真实坐标数据，无需模型生成或合成标签。

Result: 在多个基准测试中验证了Geo-R的有效性，提高了定位准确性，增强了泛化能力，提供了更透明的推理过程，为可扩展和可解释的图像地理定位建立了新的无检索范式。

Conclusion: Geo-R通过将结构化地理推理与直接空间监督相结合，成功解决了现有方法依赖合成标注或检索的局限性，实现了更准确、可泛化且可解释的地理定位。

Abstract: Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.

</details>


### [18] [Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset](https://arxiv.org/abs/2601.00411)
*Alistair Plum,Laura Bernardy,Tharindu Ranasinghe*

Main category: cs.CL

TL;DR: judgeWEL是一个卢森堡语命名实体识别数据集，通过LLM验证的自动化标注流程构建，规模是目前可用数据集的5倍，覆盖更广泛平衡的实体类别。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言构建NER数据集面临资源稀缺和标注成本高的瓶颈，卢森堡语作为代表性低资源语言缺乏高质量标注数据。

Method: 利用Wikipedia和Wikidata作为弱监督源，通过文章内部链接推断实体类型，然后使用多个LLM验证和筛选高质量标注句子，减少噪声。

Result: 构建的judgeWEL数据集规模是目前可用卢森堡语NER数据集的5倍，实体类别覆盖更广泛且更平衡，为多语言和低资源NER研究提供了重要资源。

Conclusion: 提出的基于Wikipedia/Wikidata弱监督和LLM验证的管道能有效构建低资源语言NER数据集，为类似语言的数据集创建提供了可行方案。

Abstract: We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.

</details>


### [19] [Toward Better Temporal Structures for Geopolitical Events Forecasting](https://arxiv.org/abs/2601.00430)
*Kian Ahrabian,Eric Boxer,Jay Pujara*

Main category: cs.CL

TL;DR: 本文提出了一种新型数据结构HTKGHs，解决了传统时间知识图谱在表示复杂现实事件中的局限性，并基于POLECAT数据集构建了htkgh-polecat，评估了大语言模型在复杂时序关系预测中的能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的地缘政治时序知识图谱预测方法存在表达力不足的问题。传统的超关系时序知识图谱（HTKGs）无法有效表示包含两个以上主要实体的复杂时序事实，而这在地缘政治事件中很常见。

Method: 1. 提出了超关系时序知识广义超图（HTKGHs）的形式化定义，保持向后兼容性同时支持两种常见的地缘政治事件复杂事实类型；2. 基于全球事件数据库POLECAT构建了htkgh-polecat数据集；3. 对流行的大语言模型在关系预测任务上进行基准测试和分析。

Result: 提出了HTKGHs的正式形式化框架，构建了htkgh-polecat数据集，并对大语言模型在复杂时序预测场景中的适应性和能力进行了评估分析。

Conclusion: HTKGHs扩展了传统时序知识图谱的表达能力，能够更好地表示现实世界中的复杂事件，为大语言模型在地缘政治预测等复杂场景中的应用提供了更好的数据基础。

Abstract: Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.

</details>


### [20] [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)
*Muhammad Shahmeer Khan*

Main category: cs.CL

TL;DR: 对三种轻量级Transformer模型（DistilBERT、MiniLM、ALBERT）在企业多领域文本自动化任务中的比较分析，发现各自在不同性能维度有优势。


<details>
  <summary>Details</summary>
Motivation: 随着企业NLP应用的快速发展，对能够处理多领域文本自动化任务的轻量级高效模型需求日益增长，需要对现有轻量级模型进行系统比较。

Method: 使用IMDB、AG News和Measuring Hate Speech数据集，在客户情感分类、新闻主题分类、毒性和仇恨言论检测三个领域，对比评估三种模型在准确性和效率（模型大小、推理时间、吞吐量、内存使用）方面的表现。

Result: ALBERT在多个领域的任务特定准确率最高，MiniLM在推理速度和吞吐量方面表现最优，DistilBERT在各个任务中保持最一致的准确率同时保持有竞争力的效率。没有单一模型在所有性能维度都占优。

Conclusion: 研究揭示了准确性和效率之间的权衡，建议根据应用场景选择模型：延迟敏感的企业应用推荐MiniLM，需要平衡性能的选择DistilBERT，资源受限环境选择ALBERT。

Abstract: In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.

</details>


### [21] [Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games](https://arxiv.org/abs/2601.00448)
*Dimitris Vartziotis*

Main category: cs.CL

TL;DR: 该论文对比了语言的社会建构主义（语言游戏）与数学导向的语义场理论，通过分析LLM的架构特性支持语言具有底层数学结构的观点，同时认为数学结构与语言游戏是互补的视角。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）为检验长期存在的语言意义理论提供了新的实证背景。作者希望通过对比社会建构主义（语言游戏）与数学导向的语义场理论，澄清统计语言模型的范围和限制。

Method: 作者基于先前工作形式化了词汇场和语言场作为连续语义空间中的交互结构，然后分析transformer架构的核心特性（分布式表示、注意力机制、嵌入空间的几何规律）如何与这些概念关联。

Result: LLM在捕捉语义规律性方面的成功支持语言具有底层数学结构的观点，而它们在语用推理和上下文敏感性方面的持续局限性与语言使用的哲学论述中强调的社会基础重要性一致。

Conclusion: 数学结构和语言游戏可以被理解为互补而非竞争的观点。这一框架澄清了纯统计语言模型的范围和限制，并激发了理论指导的人工智能架构的新方向。

Abstract: Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.

</details>


### [22] [Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 提出Defensive M2S训练范式，通过将多轮对话压缩为单轮来显著降低护栏模型的训练和推理成本，同时保持高攻击检测性能。


<details>
  <summary>Details</summary>
Motivation: 处理完整多轮对话历史需要大量计算成本，限制了护栏模型在实际部署中的可扩展性。需要一种能显著降低计算成本同时保持安全检测效果的方法。

Method: 提出Multi-turn to Single-turn (M2S)压缩范式，通过三种压缩模板（hyphenize、numberize、pythonize）将多轮对话压缩为单轮，然后在压缩数据上微调护栏模型。

Result: 训练成本从O(n²)降至O(n)，训练数据量减少93倍（从15.7M token降至169K）。最佳配置（Qwen3Guard+hyphenize）在SafeDialBench上达到93.8%攻击检测召回率，推理token减少94.6%，相比基线提升38.9个百分点。

Conclusion: M2S压缩是护栏模型部署的有效效率技术，能够在显著降低训练和推理成本的同时，保持甚至提升长多轮对话的安全筛查能力。

Abstract: Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.

</details>


### [23] [Rule-Based Approaches to Atomic Sentence Extraction](https://arxiv.org/abs/2601.00506)
*Lineesha Kamana,Akshita Ananda Subramanian,Mehuli Ghosh,Suman Saha*

Main category: cs.CL

TL;DR: 该研究分析了复杂句子结构对基于规则的原子句提取性能的影响，发现相对从句、同位语、并列谓语、状语从句和被动结构是主要挑战。


<details>
  <summary>Details</summary>
Motivation: 现有原子句提取方法缺乏可解释性，且无法揭示具体哪些语言结构导致提取失败。虽然已有研究探索基于依存关系的提取，但缺乏对特定从句结构和依存关系如何影响提取难度的系统性分析。

Method: 使用WikiSplit数据集，在spaCy中实现基于依存关系的提取规则，生成100个黄金标准原子句集，使用ROUGE和BERTScore评估性能。

Result: 系统达到ROUGE-1 F1=0.6714，ROUGE-2 F1=0.478，ROUGE-L F1=0.650，BERTScore F1=0.5898，表明在词汇、结构和语义对齐方面达到中等至高水平。具有挑战性的结构包括相对从句、同位语、并列谓语、状语从句和被动结构。

Conclusion: 基于规则的原子句提取方法在准确性上表现合理，但对句法复杂度敏感。识别出的挑战性结构为未来改进提供了方向。

Abstract: Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the "split-and-rephrase" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.

</details>


### [24] [Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends](https://arxiv.org/abs/2601.00536)
*Yuelyu Ji,Zhuochun Li,Rui Meng,Daqing He*

Main category: cs.CL

TL;DR: 本文提出一个四轴框架来分析和比较多跳问答系统的执行过程，强调将检索-推理过程作为分析单元，并总结当前系统的权衡和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 当前多跳问答系统虽然表现出色，但检索-推理过程往往隐含不清，使得不同模型家族的程序选择难以比较。需要一种系统化的框架来分析这些执行过程。

Method: 提出一个四轴分析框架：(A)整体执行计划、(B)索引结构、(C)下一步控制策略和触发机制、(D)停止/继续标准。使用该框架对代表性的多跳问答系统进行映射分析。

Result: 该框架成功应用于HotpotQA、2WikiMultiHopQA、MuSiQue等标准基准上的代表性系统分析，揭示了在效果、效率和证据可信度之间的常见权衡关系。

Conclusion: 总结出检索-推理代理面临的主要开放挑战，包括结构感知规划、可转移控制策略以及在分布偏移下的鲁棒停止机制等。

Abstract: Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.

</details>


### [25] [ECR: Manifold-Guided Semantic Cues for Compact Language Models](https://arxiv.org/abs/2601.00543)
*Chung-Wei Victor Yuan*

Main category: cs.CL

TL;DR: ECR框架通过语义锚点和几何一致性约束，帮助紧凑模型保持嵌入空间的结构，防止语义漂移，适用于多语言和容量受限场景。


<details>
  <summary>Details</summary>
Motivation: 紧凑模型（尤其是容量受限或多语言场景下）容易失去嵌入空间的结构，导致语义漂移，使得下游任务难以构建有效表示。现有压缩方法仅表面对齐输出，但未能保留底层流形结构。

Method: 提出Embedding Consistency Regulation（ECR）框架：1）从教师嵌入中提取一组语义锚点（离线计算）；2）紧凑模型学习围绕这些锚点保持一致的几何结构，不依赖logits匹配或内部特征对齐。仅在推理时增加小的投影步骤，不影响解码架构或运行时性能。

Result: 在10万句多语言语料上的实验表明：ECR稳定训练过程，在跨任务和跨语言中保持语义结构；生成更紧凑、任务对齐的表示空间；使低容量模型学到比传统基线更干净的流形。ECR无需教师输出，与蒸馏兼容但独立。

Conclusion: ECR帮助紧凑模型更好地遵循任务要求，使其在严格效率或隐私限制下更容易部署，通过保持嵌入空间几何一致性解决了现有压缩方法的结构缺失问题。

Abstract: Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.
  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.
  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.

</details>


### [26] [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)
*Yuang Zheng,Yuxiang Mei,Dongxing Xu,Jie Chen,Yanhua Long*

Main category: cs.CL

TL;DR: 提出基于CTC架构的轻量级语言无关多语言ASR系统HLoRA，采用分层LoRA-MoE框架，实现单通道解码且无需语言身份信息的真正语言无关识别


<details>
  <summary>Details</summary>
Motivation: 现有大规模多语言ASR模型（如Whisper）计算成本和延迟高，难以部署在资源受限的边缘设备上，需要轻量级解决方案

Method: 1) 基于CTC架构的mHuBERT-CTC模型
2) 语言无关分层LoRA-MoE (HLoRA)框架
3) 分层设计：多语言共享LoRA学习语言不变声学表征 + 语言特定LoRA专家建模语言依赖特征
4) LID后验驱动的LoRA路由机制，无需推理时语言身份信息

Result: 在MSR-86K和MLC-SLM 2025挑战数据集上的实验表明，HLoRA性能与先进的两阶段推理方法相当，仅需单通道解码，显著提升低资源多语言ASR的解码效率

Conclusion: 提出的HLoRA框架为轻量级、语言无关的多语言ASR提供有效解决方案，能够在资源受限环境下实现高效单通道解码，具有实用价值

Abstract: Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.

</details>


### [27] [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)
*Ishir Garg,Neel Kolhe,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: InfoSynth是一个基于信息论原则自动生成和评估推理基准测试的框架，通过KL散度和熵量化新颖性和多样性，无需昂贵模型评估。


<details>
  <summary>Details</summary>
Motivation: 传统基准测试创建依赖人工，成本高且耗时；现有基准测试常污染LLM训练数据，需要新颖多样的基准测试来准确评估LLM真实能力。

Method: 提出基于KL散度和熵的指标量化基准测试新颖性和多样性；开发端到端流水线，使用遗传算法和迭代代码反馈从种子数据集合成Python编程问题。

Result: 方法能97%的时间生成新问题的准确测试用例和解决方案；合成的基准测试相比种子数据集始终表现出更高的新颖性和多样性；算法可控制生成问题的新颖性/多样性和难度。

Conclusion: InfoSynth为LLM构建高质量、新颖多样的基准测试提供了一个可扩展、自我验证的流水线。

Abstract: Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/

</details>


### [28] [CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns](https://arxiv.org/abs/2601.00588)
*Zhenhong Zhou,Shilinlu Yan,Chuanpu Liu,Qiankun Li,Kun Wang,Zhigang Zeng*

Main category: cs.CL

TL;DR: CSSBench是一个专注于中文特定对抗模式的安全基准测试，用于评估轻量级大语言模型在中文场景下的安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM主要部署在成本敏感和设备端场景，但安全防护主要针对英语。中文恶意查询常通过谐音、拼音、符号拆分等特定对抗模式隐藏意图，现有基准测试未能充分覆盖这些中文特定模式，特别是轻量级模型对此类对抗扰动更为脆弱。

Method: 提出了中文特定安全基准测试CSSBench，涵盖六类中文常见领域（非法活动与合规、隐私泄露、健康医疗虚假信息、欺诈与仇恨、成人内容、公共与政治安全），并将查询组织为多种任务类型，重点评估中文特定对抗模式。

Result: 评估了多个流行的轻量级LLM，通过测量过度拒绝行为来评估安全引起的性能下降。结果显示中文特定对抗模式对轻量级LLM构成关键挑战。

Conclusion: CSSBench为中文LLM安全性提供了全面评估框架，有助于实践中鲁棒部署，填补了现有基准测试在中文特定对抗模式方面的空白。

Abstract: Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.

</details>


### [29] [Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence](https://arxiv.org/abs/2601.00596)
*Sumanth Balaji,Piyush Mishra,Aashraya Sachdeva,Suraj Agrawal*

Main category: cs.CL

TL;DR: JourneyBench是一个用于评估客户支持场景中策略感知AI代理的新基准，通过图表示生成多样化支持场景，并引入用户旅程覆盖率指标来评估策略遵循能力。


<details>
  <summary>Details</summary>
Motivation: 传统客户支持系统（如IVR）依赖刚性脚本，缺乏处理复杂策略驱动任务的灵活性。虽然LLM代理提供了有前景的替代方案，但评估其按照业务规则和实际支持工作流程执行任务的能力仍然是一个挑战。现有基准主要关注工具使用或任务完成，忽视了代理遵循多步骤策略、处理任务依赖关系以及对不可预测用户或环境行为的鲁棒性。

Method: 引入JourneyBench基准，利用图表示生成多样化、真实的支持场景。提出用户旅程覆盖率（User Journey Coverage Score）这一新颖指标来测量策略遵循能力。评估了两种代理设计：静态提示代理（SPA）和动态提示代理（DPA），后者明确建模策略控制。

Result: 在三个领域的703个对话中，DPA显著提高了策略遵循能力，甚至允许较小的模型（如GPT-4o-mini）在性能上超越更强大的模型（如GPT-4o）。

Conclusion: 研究结果表明结构化编排的重要性，并确立了JourneyBench作为推动AI驱动客户支持超越IVR时代限制的关键资源。动态策略建模可以显著提升LLM代理在复杂客户支持场景中的性能。

Abstract: Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.

</details>


### [30] [Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs](https://arxiv.org/abs/2601.00641)
*Nils Rautenberg,Sven Schippkus*

Main category: cs.CL

TL;DR: 提出了一种简单且模型无关的框架，通过重复生成和多数投票机制为确定性自动化工作流中的幻觉减少提供概率保证。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常产生上下文幻觉，即生成内容与提示中明确信息相矛盾或忽略这些信息。这在确定性自动化工作流中尤其成问题，因为输入是固定的，正确性标准是明确的。

Method: 提出一个框架，对固定输入进行多次独立重复生成，利用指数级错误率降低特性。然后使用LLM作为评判器（judge）来识别正确答案。如果评判器不完美，通过多数投票机制进行强化，使集成级错误率随投票数呈指数下降。

Result: 在受控提取任务上的实验验证：管道失败率随重复次数呈指数下降，幻觉选择率随评判器数量呈指数下降。理论预测与实验结果完全匹配。

Conclusion: 该方法提供了一个轻量级、模块化且理论基础的解决方案，可以在不修改模型权重、解码策略或提示工程的情况下，将固定输入LLM工作流中的幻觉概率任意降低。

Abstract: Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.
  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.
  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.

</details>


### [31] [Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations](https://arxiv.org/abs/2601.00647)
*QiWei Meng*

Main category: cs.CL

TL;DR: 提出Physio-DPO框架，将物理热力学稳定性融入蛋白质语言模型对齐，通过能量差距感知的优化减少结构幻觉


<details>
  <summary>Details</summary>
Motivation: 现有大蛋白质语言模型在生成蛋白质序列时经常产生结构幻觉，生成的语言可能性高但热力学不稳定的构象。现有的对齐方法（如DPO）只将偏好建模为二元标签，忽略了物理能量景观的连续结构。

Method: 提出Physio-DPO物理信息对齐框架，引入幅度感知目标函数，根据天然结构与物理扰动硬负样本之间的能量差距来缩放优化更新。

Result: Physio-DPO持续优于SFT、PPO和标准DPO等基线，将自一致性RMSD降至1.28 Å，折叠性提高至92.8%。定性分析显示能有效缓解结构幻觉，恢复生物物理相互作用。

Conclusion: Physio-DPO成功将热力学稳定性约束融入蛋白质语言模型，为生成稳定的蛋白质设计提供有效解决方案。

Abstract: Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.

</details>


### [32] [Fast-weight Product Key Memory](https://arxiv.org/abs/2601.00671)
*Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: FwPKM将静态产品密钥记忆转变为动态快速权重模块，通过局部梯度下降动态更新参数，实现了高效的长上下文处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型的序列建模层面临存储容量与计算效率的权衡：Softmax注意力有无限存储但计算成本高，线性变体效率高但存储有限且固定大小。

Method: 提出快速权重产品密钥记忆（FwPKM），将稀疏产品密钥记忆从静态模块转变为动态的"快速权重"情景记忆，在训练和推理时通过局部块级梯度下降动态更新参数。

Result: FwPKM作为有效的情景记忆补充标准模块的语义记忆，在长上下文数据集上显著降低困惑度；在Needle in a Haystack评估中，虽然仅用4K标记序列训练，却能泛化到128K标记上下文。

Conclusion: FwPKM成功解决了序列建模中的存储-效率权衡问题，通过动态记忆机制实现了高效的长上下文处理能力。

Abstract: Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, "fast-weight" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.

</details>


### [33] [Sigmoid Head for Quality Estimation under Language Ambiguity](https://arxiv.org/abs/2601.00680)
*Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 论文提出Sigmoid Head方法来解决语言模型概率不能可靠评估输出质量的问题。该方法在预训练LM上添加sigmoid激活的非嵌入头，通过特殊负采样策略训练，无需人工标注质量数据，在领域外设置下更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 语言模型的概率不是可靠的质量估计指标，因为自然语言存在歧义。当多个输出选项都有效时，模型的概率分布会分散在这些选项上，从而错误地指示低质量输出。问题根源在于：(1) LM的softmax激活无法同时给多个正确选项分配高概率；(2) LM训练数据使用单热点编码参考，暗示每个输出步骤只有一个正确答案。

Method: 提出在预训练语言模型上训练质量估计模块Sigmoid Head。该模块是一个额外的非嵌入头，使用sigmoid激活解决第一个限制。为解决第二个限制，在训练Sigmoid Head的负采样过程中，采用启发式方法避免选择潜在的正确替代标记。

Result: Sigmoid Head在训练和推理阶段计算高效。与原始softmax头的概率相比，Sigmoid Head的概率是显著更好的质量信号。由于不依赖人工标注质量数据，Sigmoid Head在领域外设置下比监督QE方法更鲁棒。

Conclusion: 提出的Sigmoid Head方法有效解决了语言模型概率作为质量估计器的局限性，通过sigmoid激活和智能负采样策略，在无需人工标注的情况下提供了更可靠的质量信号，尤其在领域外场景中表现更优。

Abstract: Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.

</details>


### [34] [Exploring the Performance of Large Language Models on Subjective Span Identification Tasks](https://arxiv.org/abs/2601.00736)
*Alphaeus Dmonte,Roland Oruche,Tharindu Ranasinghe,Marcos Zampieri,Prasad Calyam*

Main category: cs.CL

TL;DR: 该研究评估了多种大型语言模型在文本跨度识别任务上的表现，特别是在情感分析、冒犯性语言识别和事实核查三个任务上，探索了指令微调、上下文学习和思维链等策略。


<details>
  <summary>Details</summary>
Motivation: 虽然跨度识别对NLP下游任务和模型可解释性很重要，但现有研究主要集中在像NER这样的显式跨度识别，而使用LLMs进行更主观的跨度识别任务（如基于方面的情感分析）尚未得到充分探索。

Method: 通过评估多种LLM在情感分析、冒犯性语言识别和事实核查三个任务上的表现，探索了指令微调、上下文学习和思维链等策略，研究文本内部关系如何帮助LLM识别精确的文本跨度。

Result: 结果表明，文本内的底层关系有助于LLM识别精确的文本跨度，为使用LLMs进行更主观的跨度识别任务提供了实证依据。

Conclusion: 该研究填补了LLMs在主观跨度识别任务上的研究空白，证明了文本内部关系对LLM精确识别跨度的关键作用，为相关应用提供了指导。

Abstract: Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.

</details>


### [35] [Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries](https://arxiv.org/abs/2601.00787)
*Jonathan Simkin,Lovedeep Gondara,Zeeshan Rizvi,Gregory Doyle,Jeff Dowden,Dan Bond,Desmond Martin,Raymond Ng*

Main category: cs.CL

TL;DR: 本文评估了将BCCRTron和GatorTron两个transformer模型跨省适应用于加拿大癌症监测的效果，通过模型集成显著减少了漏诊癌症案例。


<details>
  <summary>Details</summary>
Motivation: 人口癌症登记依赖病理报告，但人工提取资源密集且导致数据延迟。现有transformer模型在跨司法管辖区（不同报告规范）的泛化能力尚不清楚，需要评估模型跨省适应效果。

Method: 1) 使用纽芬兰与拉布拉多癌症登记的约104,000份（Tier 1）和22,000份（Tier 2）去识别化病理报告；2) 对BCCRTron和GatorTron进行微调；3) 采用互补的摘要和诊断报告部分输入管道；4) 使用保守OR集成组合两个模型。

Result: 跨省适应后模型保持高性能。集成模型Tier 1召回率达0.99，漏诊癌症降至24例（单独模型为48和54例）；Tier 2召回率0.99，漏诊可报告癌症降至33例（单独模型为54和46例）。

Conclusion: 结合互补文本表示的集成模型能显著减少癌症漏诊并提高错误覆盖。通过仅共享模型权重的隐私保护工作流程，支持可互操作的NLP基础设施，为未来泛加拿大癌症病理和登记工作流程基础模型奠定基础。

Abstract: Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [36] [A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies](https://arxiv.org/abs/2601.00510)
*Jetlir Duraj,Ishita Khan,Kilian Merkelbach,Mehran Elyasi*

Main category: cs.IR

TL;DR: 该论文提出了一种新颖的Chain-of-Thought（CoT）方法，结合树搜索和LLM语义评分，用于提升电商搜索查询分类的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在电商搜索中，准确地将用户查询分类到层次化分类体系中的相关叶类别至关重要。正确的分类不仅能精确定位商品库存空间，还能为查询的多意图理解提供支持，对检索约束和搜索结果相关性提升有实际应用价值。

Method: 探索了一种新颖的Chain-of-Thought（CoT）范式，该方法结合了简单的树搜索与大语言模型（LLM）的语义评分。同时还提出了基于相同理念但能扩展到百万级查询规模的LLM方法。

Result: CoT方法在人类评判的查询-类别对、相关性测试和LLM基准方法的评估中，表现优于基于嵌入的查询类别预测基准。该方法还能检测层次化分类体系中的问题。

Conclusion: CoT方法为电商查询分类提供了一种实用且准确的解决方案，在分类性能、可解释性和问题检测方面优于传统方法，同时提出了可扩展的LLM方法以适应大规模应用需求。

Abstract: Search in e-Commerce is powered at the core by a structured representation of the inventory, often formulated as a category taxonomy. An important capability in e-Commerce with hierarchical taxonomies is to select a set of relevant leaf categories that are semantically aligned with a given user query. In this scope, we address a fundamental problem of search query categorization in real-world e-Commerce taxonomies. A correct categorization of a query not only provides a way to zoom into the correct inventory space, but opens the door to multiple intent understanding capabilities for a query. A practical and accurate solution to this problem has many applications in e-commerce, including constraining retrieved items and improving the relevance of the search results. For this task, we explore a novel Chain-of-Thought (CoT) paradigm that combines simple tree-search with LLM semantic scoring. Assessing its classification performance on human-judged query-category pairs, relevance tests, and LLM-based reference methods, we find that the CoT approach performs better than a benchmark that uses embedding-based query category predictions. We show how the CoT approach can detect problems within a hierarchical taxonomy. Finally, we also propose LLM-based approaches for query-categorization of the same spirit, but which scale better at the range of millions of queries.

</details>


### [37] [Improving Scientific Document Retrieval with Academic Concept Index](https://arxiv.org/abs/2601.00567)
*Jeyun Lee,Junhyoung Lee,Wonbin Kweon,Bowen Jin,Yu Zhang,Susik Yoon,Dongha Lee,Hwanjo Yu,Jiawei Han,Seongku Kang*

Main category: cs.IR

TL;DR: 本文提出了一种基于学术概念索引的方法来改进科学文献检索，通过概念覆盖的查询生成和概念聚焦的上下文增强，解决了现有方法在概念多样性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 将通用领域检索器适配到科学领域面临两大挑战：1）大规模领域相关标注数据稀缺；2）词汇和信息需求存在显著不匹配。现有基于大语言模型的方法（生成合成查询和辅助上下文）往往忽略了科学文档中嵌入的多样化学术概念，导致生成冗余或概念狭窄的查询和上下文。

Method: 1）构建学术概念索引：从论文中提取关键概念，并按照学术分类体系进行组织；2）概念覆盖的查询生成（CCQGen）：根据未覆盖的概念自适应地调节LLM，生成具有更广泛概念覆盖的互补查询；3）概念聚焦的上下文增强（CCExpand）：利用文档片段作为概念感知查询的简洁响应来增强上下文。

Result: 实验表明，将学术概念索引整合到查询生成和上下文增强中，能够产生更高质量的查询、更好的概念对齐，并显著提升检索性能。

Conclusion: 通过系统性地利用学术概念索引，本文提出的方法有效解决了科学领域检索中的概念覆盖问题，为改进科学文献检索提供了一种结构化的解决方案。

Abstract: Adapting general-domain retrievers to scientific domains is challenging due to the scarcity of large-scale domain-specific relevance annotations and the substantial mismatch in vocabulary and information needs. Recent approaches address these issues through two independent directions that leverage large language models (LLMs): (1) generating synthetic queries for fine-tuning, and (2) generating auxiliary contexts to support relevance matching. However, both directions overlook the diverse academic concepts embedded within scientific documents, often producing redundant or conceptually narrow queries and contexts. To address this limitation, we introduce an academic concept index, which extracts key concepts from papers and organizes them guided by an academic taxonomy. This structured index serves as a foundation for improving both directions. First, we enhance the synthetic query generation with concept coverage-based generation (CCQGen), which adaptively conditions LLMs on uncovered concepts to generate complementary queries with broader concept coverage. Second, we strengthen the context augmentation with concept-focused auxiliary contexts (CCExpand), which leverages a set of document snippets that serve as concise responses to the concept-aware CCQGen queries. Extensive experiments show that incorporating the academic concept index into both query generation and context augmentation leads to higher-quality queries, better conceptual alignment, and improved retrieval performance.

</details>
