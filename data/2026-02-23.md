<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 27]
- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [QueryPlot: Generating Geological Evidence Layers using Natural Language Queries for Mineral Exploration](https://arxiv.org/abs/2602.17784)
*Meng Ye,Xiao Lin,Georgina Lukoczki,Graham W. Lederer,Yi Yao*

Main category: cs.CL

TL;DR: QueryPlot是一个基于语义检索的矿产远景预测框架，通过整合地质文本语料库和地质图数据，利用自然语言处理技术将用户查询与区域描述进行语义匹配，生成连续的远景预测图层。


<details>
  <summary>Details</summary>
Motivation: 传统的矿产远景预测需要人工整合异构的地质知识（包括文本矿床模型和地理空间数据），这一过程耗时且依赖专家知识。因此需要一种自动化方法来提高效率和可重复性。

Method: 1. 整理了120多种矿床类型的描述性模型；2. 将州地质图编译（SGMC）多边形转换为结构化文本表示；3. 使用预训练嵌入模型对查询和区域描述进行编码；4. 计算语义相似度得分进行区域排序和空间可视化；5. 支持组合查询和多个相似度图层的聚合分析。

Result: 1. 在钨矽卡岩矿床案例研究中，基于嵌入的检索方法对已知矿点具有高召回率；2. 生成的远景区域与专家定义的许可带高度一致；3. 相似度得分作为特征加入监督学习管道，显著提高了分类性能。

Conclusion: QueryPlot通过整合地质文本和空间数据，实现了基于语义检索的自动化矿产远景预测，不仅与专家知识高度一致，还能提升机器学习模型的性能，为地质勘探提供了高效的工具。

Abstract: Mineral prospectivity mapping requires synthesizing heterogeneous geological knowledge, including textual deposit models and geospatial datasets, to identify regions likely to host specific mineral deposit types. This process is traditionally manual and knowledge-intensive. We present QueryPlot, a semantic retrieval and mapping framework that integrates large-scale geological text corpora with geologic map data using modern Natural Language Processing techniques. We curate descriptive deposit models for over 120 deposit types and transform the State Geologic Map Compilation (SGMC) polygons into structured textual representations. Given a user-defined natural language query, the system encodes both queries and region descriptions using a pretrained embedding model and computes semantic similarity scores to rank and spatially visualize regions as continuous evidence layers. QueryPlot supports compositional querying over deposit characteristics, enabling aggregation of multiple similarity-derived layers for multi-criteria prospectivity analysis. In a case study on tungsten skarn deposits, we demonstrate that embedding-based retrieval achieves high recall of known occurrences and produces prospective regions that closely align with expert-defined permissive tracts. Furthermore, similarity scores can be incorporated as additional features in supervised learning pipelines, yielding measurable improvements in classification performance. QueryPlot is implemented as a web-based system supporting interactive querying, visualization, and export of GIS-compatible prospectivity layers.To support future research, we have made the source code and datasets used in this study publicly available.

</details>


### [2] [Neural Synchrony Between Socially Interacting Language Models](https://arxiv.org/abs/2602.17815)
*Zhining Zhang,Wentao Zhu,Chi Han,Yizhou Wang,Heng Ji*

Main category: cs.CL

TL;DR: 本文通过神经同步性分析LLM的社会性，发现交互LLM之间出现神经同步，且与社交表现相关，为LLM是否具有"社会心智"提供新视角。


<details>
  <summary>Details</summary>
Motivation: 传统认为社会心智是生物特有属性，尽管LLM能近似人类行为，但能否与人类社会心智相比仍存争议。作者希望通过神经同步性这一神经科学标志性机制来实证检验LLM的社会性。

Method: 引入神经同步性作为分析LLM社会性的新代理指标，通过精心设计的社交模拟实验，在表征层面测量交互LLM之间的神经同步性，评估其反映社交参与度和时间对齐的能力。

Result: 实验表明LLM之间的神经同步性可靠地反映了它们的社交参与度和时间对齐；神经同步性与LLM的社交表现强烈相关，揭示了神经同步性与LLM社交行为之间的重要联系。

Conclusion: LLM在社交互动中表现出与人类相似的神经同步性模式，为理解LLM的"社会心智"提供了新视角，揭示了人类与LLM社交互动内在动态的惊人相似性。

Abstract: Neuroscience has uncovered a fundamental mechanism of our social nature: human brain activity becomes synchronized with others in many social contexts involving interaction. Traditionally, social minds have been regarded as an exclusive property of living beings. Although large language models (LLMs) are widely accepted as powerful approximations of human behavior, with multi-LLM system being extensively explored to enhance their capabilities, it remains controversial whether they can be meaningfully compared to human social minds. In this work, we explore neural synchrony between socially interacting LLMs as an empirical evidence for this debate. Specifically, we introduce neural synchrony during social simulations as a novel proxy for analyzing the sociality of LLMs at the representational level. Through carefully designed experiments, we demonstrate that it reliably reflects both social engagement and temporal alignment in their interactions. Our findings indicate that neural synchrony between LLMs is strongly correlated with their social performance, highlighting an important link between neural synchrony and the social behaviors of LLMs. Our work offers a new perspective to examine the "social minds" of LLMs, highlighting surprising parallels in the internal dynamics that underlie human and LLM social interaction.

</details>


### [3] [On the scaling relationship between cloze probabilities and language model next-token prediction](https://arxiv.org/abs/2602.17848)
*Cassandra L. Jacobs,Morgan Grobol*

Main category: cs.CL

TL;DR: 研究发现更大语言模型在预测眼动和阅读时间数据方面表现更好，但所有模型都低估了人类反应概率。大模型能生成更高质量的下一个词预测，因为对词汇共现统计不敏感，而与人类完形填空反应语义更一致。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型大小如何影响对人类语言处理行为的预测能力，特别是眼动、阅读时间和完形填空任务中的表现。

Method: 通过比较不同规模的语言模型在预测眼动数据、阅读时间数据和完形填空任务中的表现，分析模型对词汇共现统计的敏感性和语义对齐能力。

Result: 1. 更大语言模型在预测眼动和阅读时间数据方面表现更好；2. 所有模型都低估了人类反应概率；3. 大模型能生成更高质量的下一个词预测，因为对词汇共现统计不敏感；4. 大模型与人类完形填空反应语义更一致；5. 大模型更强的记忆能力帮助它们猜测更语义合适的词，但对单词识别相关的低层信息敏感性降低。

Conclusion: 大语言模型的增强记忆能力使其能生成更语义合适的预测，但同时降低了对低层语言信息的敏感性。这支持了模型大小通过增加记忆容量来改善语义对齐的观点。

Abstract: Recent work has shown that larger language models have better predictive power for eye movement and reading time data. While even the best models under-allocate probability mass to human responses, larger models assign higher-quality estimates of next tokens and their likelihood of production in cloze data because they are less sensitive to lexical co-occurrence statistics while being better aligned semantically to human cloze responses. The results provide support for the claim that the greater memorization capacity of larger models helps them guess more semantically appropriate words, but makes them less sensitive to low-level information that is relevant for word recognition.

</details>


### [4] [Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations](https://arxiv.org/abs/2602.17881)
*Joschka Braun*

Main category: cs.CL

TL;DR: 该论文研究了语言模型控制中steering vectors方法的可靠性问题，发现其可靠性取决于目标行为在激活空间的线性可分性，并提出诊断不可靠性的实用方法。


<details>
  <summary>Details</summary>
Motivation: steering vectors虽然是一种轻量级的语言模型控制方法，但其效果在不同样本间差异很大，对许多目标行为不可靠，需要探究其可靠性差异的原因和影响因素。

Method: 通过分析steering vectors训练数据对可靠性的影响，研究训练激活差异的余弦相似度、正负激活在steering方向上的分离程度，以及不同提示变体训练的steering vectors的性能相关性。

Result: 1) 训练激活差异的余弦相似度越高，steering越可靠；2) 正负激活在steering方向上分离度越好的行为数据集越可靠；3) 不同提示变体训练的steering vectors方向不同但性能相似，且在不同数据集上效果相关。

Conclusion: steering vectors不可靠的原因是潜在目标行为表示无法被线性steering方向有效近似，这为诊断不可靠性提供了实用方法，并激励开发更鲁棒的非线性行为表示控制方法。

Abstract: Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.

</details>


### [5] [Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions](https://arxiv.org/abs/2602.17907)
*Raymond Li,Amirhossein Abaskohi,Chuyuan Li,Gabriel Murray,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 提出使用语言模型生成语义软标签目标来训练神经主题模型，显著提升主题质量和文档检索效果


<details>
  <summary>Details</summary>
Motivation: 传统神经主题模型通常通过重构文档的词袋表示进行优化，忽略了上下文信息，且在处理数据稀疏性方面存在困难

Method: 通过语言模型生成语义软标签目标：使用专门设计的提示，将下一个词概率投影到预定义词汇表上，获得上下文丰富的监督信号。然后训练主题模型使用语言模型隐藏状态来重构这些软标签

Result: 在三个数据集上的实验表明，该方法在主题连贯性和纯度方面显著优于现有基线。新引入的检索指标也显示，该方法在识别语义相似文档方面明显优于现有方法

Conclusion: 通过语言模型生成语义软标签为神经主题模型提供上下文丰富的监督信号，能产生更高质量、更符合语料主题结构的主题，特别适用于检索导向的应用

Abstract: Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.

</details>


### [6] [Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering](https://arxiv.org/abs/2602.17911)
*Jash Rajesh Parekh,Wonbin Kweon,Joey Chan,Rezarta Islamaj,Robert Leaman,Pengcheng Jiang,Chih-Hsuan Wei,Zhizheng Wang,Zhiyong Lu,Jiawei Han*

Main category: cs.CL

TL;DR: 提出首个条件性生物医学问答基准CondMedQA和条件门控推理框架CGR，用于处理患者特定条件下的临床推理


<details>
  <summary>Details</summary>
Motivation: 当前生物医学QA系统假设医学知识普遍适用，但真实临床推理本质上是条件性的，每个决策都依赖于患者特定因素。现有基准无法评估这种条件推理，检索增强或基于图的方法缺乏确保检索知识适用于给定上下文的显式机制

Method: 提出CondMedQA基准（包含多跳问题，答案随患者条件变化）和Condition-Gated Reasoning (CGR)框架，构建条件感知知识图，基于查询条件选择性激活或修剪推理路径

Result: CGR能更可靠地选择条件适当的答案，同时在生物医学QA基准上达到或超过最先进性能，突显了显式建模条件性对稳健医学推理的重要性

Conclusion: 条件性建模是生物医学QA系统的重要方向，CGR框架为解决临床推理中的条件依赖问题提供了有效方案

Abstract: Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.

</details>


### [7] [Analyzing LLM Instruction Optimization for Tabular Fact Verification](https://arxiv.org/abs/2602.17937)
*Xiaotang Du,Giwon Hong,Wai-Chung Kwan,Rohit Saxena,Ivan Titov,Pasquale Minervini,Emily Allaway*

Main category: cs.CL

TL;DR: 该论文首次系统比较了基于DSPy优化框架的指令优化方法在表格事实验证任务中的表现，发现指令优化能持续提升验证准确率，不同优化器在不同提示技术和模型规模下各有优势。


<details>
  <summary>Details</summary>
Motivation: 指令优化作为一种轻量级、模型无关的方法，可以提升大语言模型的推理性能。目前缺乏对指令优化在表格事实验证任务中的系统性比较研究。

Method: 基于DSPy优化框架，评估了四种开箱即用的提示技术（直接预测、思维链、带SQL工具的ReAct、带Python执行的CodeAct），并在四个基准测试和三个模型家族上研究了三种DSPy优化器（COPRO、MiPROv2、SIMBA）。

Result: 指令优化持续提升验证准确率：MiPROv2在思维链中表现最稳定，SIMBA对ReAct智能体提供最大收益（尤其在更大模型规模时）。行为分析显示SIMBA通过启发式方法鼓励更直接的推理路径，提升思维链中的数值比较能力，并帮助ReAct智能体避免不必要的工具调用。

Conclusion: 思维链在表格事实检查中保持有效（尤其对小模型），而基于大模型的ReAct智能体虽能达到竞争性能，但需要仔细的指令优化。不同提示技术中，优化器的选择应考虑模型规模和任务特性。

Abstract: Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.

</details>


### [8] [CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications](https://arxiv.org/abs/2602.17949)
*Victoria Blake,Mathew Miller,Jamie Novak,Sze-yuan Ooi,Blanca Gallego*

Main category: cs.CL

TL;DR: CUICurate是一个基于图检索增强生成的框架，用于自动化UMLS概念集构建，通过知识图谱检索和LLM过滤分类，显著减少人工工作量并提升概念集完整性。


<details>
  <summary>Details</summary>
Motivation: 临床命名实体识别工具通常将自由文本映射到UMLS概念唯一标识符（CUI），但许多下游任务需要的是包含相关同义词、子类型和超类型的概念集。目前构建这种概念集是劳动密集型的、执行不一致的，且现有工具支持不足，特别是对于直接操作UMLS CUI的NLP流水线。

Method: 提出CUICurate框架，采用基于图的检索增强生成方法：1）构建UMLS知识图谱并进行嵌入用于语义检索；2）对每个目标概念，从知识图谱检索候选CUI；3）使用大型语言模型进行过滤和分类，比较了GPT-5和GPT-5-mini两种模型。

Result: 在五个词汇异质性临床概念上的评估显示：CUICurate生成的概念集比人工基准集更大、更完整，同时保持与人类相当的精确度。GPT-5-mini在过滤阶段召回率更高，而GPT-5的分类结果更符合临床医生判断。输出在重复运行中稳定且计算成本低。

Conclusion: CUICurate提供了一个可扩展、可重复的方法来支持UMLS概念集构建，显著减少了人工工作量。通过整合基于图的检索和LLM推理，该框架生成聚焦的候选概念集，可适应不同表型和分析需求的临床NLP流水线。

Abstract: Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.

</details>


### [9] [Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering](https://arxiv.org/abs/2602.17981)
*Amine Kobeissi,Philippe Langlais*

Main category: cs.CL

TL;DR: 论文研究了金融问答中检索增强生成的失败模式，提出了针对财务报告页面级检索的优化方法，显著提升了页面和块级检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法在金融监管文件问答中存在频繁失败模式：虽然检索到了正确文档，但错过了包含答案的具体页面或块，导致生成器基于不完整上下文进行推断。这种文档内检索失败在实际应用中很严重，但在金融问答文献中缺乏系统研究。

Method: 1) 在多粒度级别评估检索性能（文档、页面、块级）；2) 引入基于oracle的分析提供检索和生成性能的实证上限；3) 在FinanceBench的150个问题上比较多种检索策略（稠密、稀疏、混合、分层检索，配合重排序和查询重构）；4) 提出领域微调的页面评分器，将页面作为文档和块之间的中间检索单元，专门为财务报告页面级相关性微调双编码器。

Result: 研究显示，文档发现能力的提升通常能转化为更强的页面召回率，但oracle性能表明页面和块级检索仍有提升空间。提出的领域微调页面评分器在页面召回和块检索方面实现了显著改进。

Conclusion: 针对金融监管文件页面级检索的专门优化能有效解决文档内检索失败问题，提升检索增强生成系统的可靠性。页面作为语义连贯的中间检索单元具有重要价值，领域特定的微调方法能显著改善金融问答性能。

Abstract: Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.

</details>


### [10] [Towards More Standardized AI Evaluation: From Models to Agents](https://arxiv.org/abs/2602.18029)
*Ali El Filali,Inès Bedar*

Main category: cs.CL

TL;DR: 评估在AI时代应从静态模型检查点转变为对复合工具使用智能体的持续控制与信任测量


<details>
  <summary>Details</summary>
Motivation: 当前评估实践仍停留在模型中心时代的静态基准、聚合分数和一次性成功标准，无法有效评估现代复合工具使用智能体系统的真实行为，导致高基准分数经常误导团队，评估管道本身引入静默故障模式

Method: 通过分析评估管道如何引入故障模式、探讨高基准分数误导性原因、研究智能体系统如何根本改变性能测量的意义，来重新定义评估在AI时代的作用

Result: 论证了传统评估方法对智能体系统越来越模糊而非清晰，需要将评估重新定义为测量学科，作为信任、迭代和治理非确定性系统的条件

Conclusion: 评估不应是性能剧场，而应成为测量学科，为智能体系统的信任建立、迭代改进和治理提供基础，特别是在变化和规模化条件下确保系统按预期行为

Abstract: Evaluation is no longer a final checkpoint in the machine learning lifecycle. As AI systems evolve from static models to compound, tool-using agents, evaluation becomes a core control function. The question is no longer "How good is the model?" but "Can we trust the system to behave as intended, under change, at scale?". Yet most evaluation practices remain anchored in assumptions inherited from the model-centric era: static benchmarks, aggregate scores, and one-off success criteria. This paper argues that such approaches are increasingly obscure rather than illuminating system behavior. We examine how evaluation pipelines themselves introduce silent failure modes, why high benchmark scores routinely mislead teams, and how agentic systems fundamentally alter the meaning of performance measurement. Rather than proposing new metrics or harder benchmarks, we aim to clarify the role of evaluation in the AI era, and especially for agents: not as performance theater, but as a measurement discipline that conditions trust, iteration, and governance in non-deterministic systems.

</details>


### [11] [Perceived Political Bias in LLMs Reduces Persuasive Abilities](https://arxiv.org/abs/2602.18092)
*Matthew DiGiuseppe,Joshua Robison*

Main category: cs.CL

TL;DR: LLM的政治中立性感知影响其说服效果：党派偏见警告会降低28%的说服力


<details>
  <summary>Details</summary>
Motivation: 随着LLMs进入党派冲突，精英们越来越多地将它们描绘成具有意识形态倾向。本研究旨在测试这些可信度攻击是否会降低基于LLM的说服效果。

Method: 在美国进行了一项预注册调查实验（N=2144），参与者与ChatGPT进行三轮对话，讨论个人持有的经济政策误解。实验组收到简短信息，表明LLM对参与者所在党派有偏见，对照组为中立信息。

Result: 与中立对照组相比，党派偏见警告使LLM的说服效果降低了28%。文本分析表明，警告改变了互动模式：受访者更频繁地反驳，接受度更低。

Conclusion: 对话式AI的说服效果具有政治依赖性，受到党派一致性感知的限制。政治中立性感知是LLM有效性的关键因素。

Abstract: Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.

</details>


### [12] [Agentic Adversarial QA for Improving Domain-Specific LLMs](https://arxiv.org/abs/2602.18137)
*Vincent Grari,Ciprian Tomoiaga,Sylvain Lamprier,Tatsunori Hashimoto,Marcin Detyniecki*

Main category: cs.CL

TL;DR: 提出对抗性提问生成框架，通过比较待适应模型与专家模型输出，生成紧凑的语义挑战性问题，提升模型在专业领域的适应效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专业领域适应能力不足，现有方法主要依赖改写或知识提取生成的合成数据，存在两个关键缺陷：1) 对解释性推理能力支持不足；2) 生成的数据集过大且冗余，样本效率低。

Method: 提出对抗性提问生成框架，通过迭代反馈过程比较待适应模型与基于参考文档的专家模型输出，识别理解差距并生成紧凑的语义挑战性问题。

Result: 在LegalBench语料的专业子集上评估，该方法以显著更少的合成样本实现了更高的准确率。

Conclusion: 对抗性提问生成框架能有效解决专业领域适应中的合成数据效率问题，通过生成紧凑的语义挑战性问题提升模型性能。

Abstract: Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.

</details>


### [13] [Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention](https://arxiv.org/abs/2602.18145)
*Siya Qi,Yudong Chen,Runcong Zhao,Qinglin Zhu,Zhanghao Hu,Wei Liu,Yulan He,Zheng Yuan,Lin Gui*

Main category: cs.CL

TL;DR: 该论文提出了一种基于频率感知的注意力分析方法来检测LLM幻觉，通过分析注意力分布的高频成分来识别不稳定的注意力模式，并开发了轻量级幻觉检测器。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力的幻觉检测方法通常依赖粗粒度的注意力汇总，无法捕捉注意力中的细粒度不稳定模式。需要更精细的方法来分析注意力动态以检测幻觉。

Method: 受信号处理启发，将注意力分布建模为离散信号，提取反映注意力快速局部变化的高频成分。分析发现幻觉token与高频注意力能量相关，反映了不稳定的注意力行为。基于此开发了使用高频注意力特征的轻量级幻觉检测器。

Result: 在RAGTruth和HalluRAG基准测试中，该方法在多个模型和任务上优于基于验证、内部表示和注意力的现有方法。

Conclusion: 注意力分布的高频成分能有效反映LLM生成中的幻觉行为，基于频率感知的注意力分析为幻觉检测提供了新的有效视角。

Abstract: Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.

</details>


### [14] [The Statistical Signature of LLMs](https://arxiv.org/abs/2602.18152)
*Ortal Hadad,Edoardo Loru,Jacopo Nudo,Niccolò Di Marco,Matteo Cinelli,Walter Quattrociocchi*

Main category: cs.CL

TL;DR: 压缩率可作为区分LLM生成文本与人类文本的简单有效指标，揭示了生成文本具有更高的结构规律性和可压缩性，但在小尺度互动环境中这种差异会减弱。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过概率采样生成文本，但这一过程如何重塑语言的结构统计组织尚不完全清楚。研究旨在开发一种模型无关的方法来量化生成系统如何重塑文本生产。

Method: 使用无损压缩作为衡量统计规律性的简单、模型无关的度量标准，分析三个渐进复杂的信息生态系统：受控的人-LLM延续、知识基础设施的生成中介（维基百科 vs Grokipedia）、完全合成的社交互动环境（Moltbook vs Reddit）。

Result: 压缩揭示了概率生成的结构特征：在受控和中介环境中，LLM产生的语言比人类文本表现出更高的结构规律性和可压缩性，但该特征具有尺度依赖性，在碎片化的互动环境中分离减弱，表明小尺度表面可区分性存在基本限制。

Conclusion: 压缩率提供了一种简单稳健的框架来量化生成系统如何重塑文本生产，为通信演化复杂性提供了结构视角，无需依赖模型内部或语义评估即可从表面文本直接观察。

Abstract: Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.

</details>


### [15] [RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering](https://arxiv.org/abs/2602.18425)
*Deniz Qian,Hung-Ting Chen,Eunsol Choi*

Main category: cs.CL

TL;DR: RVR是一个多轮检索框架，通过检索-验证-检索的迭代过程最大化答案覆盖率，显著提升多答案查询的完整召回率。


<details>
  <summary>Details</summary>
Motivation: 处理多答案查询时需要全面检索多样化的文档，现有方法在最大化答案覆盖率方面存在不足。

Method: 提出检索-验证-检索（RVR）框架：首轮用原始查询检索候选文档，验证器筛选高质量子集；后续轮次将已验证文档作为查询补充，逐步发现未被覆盖的答案。

Result: 在QAMPARI数据集上相对提升至少10%，绝对提升3%的完整召回率；在QUEST和WebQuestionsSP数据集上也有稳定增益；即使使用现成检索器也有效，微调后效果更佳。

Conclusion: RVR是一种有前景的迭代方法，通过验证器和检索器适应新推理场景，显著提升多答案检索的全面性。

Abstract: Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.

</details>


### [16] [FENCE: A Financial and Multimodal Jailbreak Detection Dataset](https://arxiv.org/abs/2602.18154)
*Mirae Kim,Seonghun Jeong,Youngjun Kwak*

Main category: cs.CL

TL;DR: FENCE是一个双语多模态数据集，用于训练和评估金融领域中的越狱检测器，包含金融相关查询和基于图像的威胁，实验显示现有VLM存在漏洞，基线检测器达到99%准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和视觉语言模型的越狱攻击存在显著风险，特别是VLM因处理文本和图像而更脆弱。金融领域缺乏越狱检测资源，需要专门的检测数据集来应对这一挑战。

Method: 创建FENCE双语多模态数据集（韩语-英语），包含金融相关查询和基于图像的威胁，强调领域真实性。在商业和开源VLM上进行实验，并训练基线越狱检测器进行评估。

Result: 实验显示商业和开源VLM均存在一致漏洞，GPT-4o有显著攻击成功率，开源模型暴露更大风险。基于FENCE训练的基线检测器达到99%分布内准确率，并在外部基准测试中保持强性能。

Conclusion: FENCE为金融领域多模态越狱检测提供了专门资源，有助于训练可靠的检测模型，支持敏感领域构建更安全可靠的AI系统。

Abstract: Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.

</details>


### [17] [VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning](https://arxiv.org/abs/2602.18429)
*Harshul Raj Surana,Arijit Maji,Aryan Vats,Akash Ghosh,Sriparna Saha,Amit Sheth*

Main category: cs.CL

TL;DR: 提出VIRAASAT数据集和SCoM框架，用于提升LLM在印度文化多跳推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有文化基准多为手工构建、单跳问题且成本高昂，无法有效衡量LLM在需要丰富社会文化知识和本地情境（特别是印度文化）任务上的表现缺陷。

Method: 1) 创建VIRAASAT数据集：半自动多跳方法生成印度文化特定QA数据集，基于包含700+专家策划文化实体的知识图谱，覆盖13个文化属性，涵盖28个邦和8个联邦属地；2) 提出SCoM框架：训练模型内部模拟知识图谱的原子操作，可靠遍历图谱拓扑结构。

Result: 生成超过3,200个多跳问题，发现当前SOTA LLMs在文化推理中存在关键限制（CoT微调无法处理低概率事实）。SCoM在监督微调中比标准CoT基线提升达20%。

Conclusion: VIRAASAT数据集和SCoM框架为构建文化感知推理模型奠定了坚实基础，解决了LLM在文化推理任务中的不足。

Abstract: Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.

</details>


### [18] [Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models](https://arxiv.org/abs/2602.18171)
*Wojciech Michaluk,Tymoteusz Urban,Mateusz Kubita,Soveatin Kuntur,Anna Wroblewska*

Main category: cs.CL

TL;DR: 本文提出了一种混合方法用于点击诱饵检测，结合了基于Transformer的文本嵌入和语言学特征，通过XGBoost分类器实现了91%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 点击诱饵标题降低了在线信息质量并损害用户信任，需要有效的检测方法来应对这一问题。

Method: 使用混合方法，结合基于Transformer的文本嵌入和15个语言学特征（如第二人称代词、最高级、数字、注意力导向标点等），通过XGBoost等树基分类器进行检测。

Result: 最佳模型（XGBoost结合嵌入和15个显式特征）达到91%的F1分数，优于TF-IDF、Word2Vec、GloVe、LLM提示分类和仅特征基线。

Conclusion: 提出的特征集通过突出显式语言学线索增强了可解释性，实现了透明且校准良好的点击诱饵预测，并发布了代码和训练模型以支持可重复研究。

Abstract: Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.

</details>


### [19] [Improving Sampling for Masked Diffusion Models via Information Gain](https://arxiv.org/abs/2602.18176)
*Kaisen Yang,Jayden Teoh,Kaicheng Yang,Yitong Zhang,Alex Lamb*

Main category: cs.CL

TL;DR: 提出Info-Gain Sampler，一种新的掩码扩散模型解码框架，通过平衡即时不确定性和未来信息增益，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型解码器采用贪心策略，只关注局部最高确定性位置，忽略了当前解码决策对后续步骤的累积影响，未能充分利用MDMs的非因果特性。

Method: 提出Info-Gain Sampler，这是一个原则性解码框架，不仅考虑当前位置的不确定性，还评估当前解码决策如何重塑所有剩余掩码位置的token概率/不确定性，实现即时不确定性与未来信息增益的平衡。

Result: 在推理、编码、创意写作和图像生成等多样化任务上，Info-Gain Sampler始终优于现有采样器。推理任务平均准确率提升3.6%，创意写作任务胜率63.1%，累积不确定性从78.4降至48.6。

Conclusion: Info-Gain Sampler通过系统性地考虑解码决策的长期影响，显著提升了掩码扩散模型的生成质量，证明了平衡即时不确定性和未来信息增益的重要性。

Abstract: Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.

</details>


### [20] [Information-Theoretic Storage Cost in Sentence Comprehension](https://arxiv.org/abs/2602.18217)
*Kohei Kajikawa,Shinnosuke Isono,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 提出基于信息论的形式化处理存储成本度量，使用预训练神经语言模型估计，能预测阅读时间并解释已知处理不对称性


<details>
  <summary>Details</summary>
Motivation: 实时句子理解对工作记忆有显著负荷，现有基于符号语法的离散度量方法存在局限，需要连续、理论中立且能从预训练模型估计的度量方法

Method: 基于信息论提出处理存储成本度量，定义为先前词汇在不确定性下对未来语境携带的信息量，使用预训练神经语言模型进行估计

Result: 1) 恢复了中心嵌入和关系从句中已知的处理不对称性 2) 与语法化存储成本相关 3) 在自然数据集上预测阅读时间方差，优于传统信息预测器基线模型

Conclusion: 信息论形式化的处理存储成本度量是有效的，提供连续、理论中立的替代方案，能更好地解释实时句子理解中的处理负荷

Abstract: Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.

</details>


### [21] [Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning](https://arxiv.org/abs/2602.18232)
*Lexiang Tang,Weihao Gao,Bingchen Zhao,Lu Ma,Qiao jin,Bang Yang,Yuexian Zou*

Main category: cs.CL

TL;DR: 提出Confidence-Driven Contrastive Decoding方法，通过检测解码过程中的低置信度token进行针对性干预，提升大语言模型推理可靠性并减少输出长度。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设增加推理时计算能均匀提升正确性，但实际推理不确定性高度局部化：少数低置信度token导致推理错误和不必要的输出扩展。

Method: 提出Confidence-Driven Contrastive Decoding方法：检测解码过程中的低置信度token，构建对比参考（将高置信度token替换为最小占位符），在低置信度位置通过减去参考分布来优化预测。

Result: 实验显示CCD显著提升数学推理基准的准确性，同时大幅减少输出长度，KV缓存开销最小。作为无需训练的方法，通过针对性低置信度干预提升推理可靠性，避免计算冗余。

Conclusion: CCD通过置信度驱动的对比解码，实现了对大语言模型推理的针对性干预，在提升准确性的同时优化计算效率，为推理可靠性提供了有效的训练免费解决方案。

Abstract: Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.

</details>


### [22] [Simplifying Outcomes of Language Model Component Analyses with ELIA](https://arxiv.org/abs/2602.18262)
*Aaron Louis Eidt,Nils Feldhus*

Main category: cs.CL

TL;DR: ELIA是一个交互式网络应用，通过整合多种语言模型分析技术并使用视觉语言模型自动生成解释，降低了机制可解释性工具的使用门槛。


<details>
  <summary>Details</summary>
Motivation: 尽管机制可解释性已经开发了强大的工具来分析大型语言模型的内部工作原理，但其复杂性造成了使用门槛，仅限于专家使用。需要设计更易访问的工具来让更广泛的受众理解这些分析结果。

Method: 设计、构建和评估ELIA交互式网络应用，整合归因分析、函数向量分析和电路追踪三种关键技术，并引入新方法：使用视觉语言模型自动为这些方法产生的复杂可视化生成自然语言解释。

Result: 通过混合方法的用户研究验证了该方法的有效性，结果显示用户明显偏好交互式、可探索的界面而非简单的静态可视化。关键发现是AI驱动的解释帮助非专家缩小了知识差距；统计分析显示用户先前的LLM经验与其理解分数之间没有显著相关性，表明系统减少了不同经验水平用户的理
解障碍。

Conclusion: AI系统确实可以简化复杂的模型分析，但其真正潜力在于与深思熟虑、以用户为中心的设计相结合，优先考虑交互性、具体性和叙事指导。

Abstract: While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.

</details>


### [23] [PsihoRo: Depression and Anxiety Romanian Text Corpus](https://arxiv.org/abs/2602.18324)
*Alexandra Ciobotaru,Ana-Maria Bucur,Liviu P. Dinu*

Main category: cs.CL

TL;DR: 创建了首个罗马尼亚语抑郁和焦虑语料库PsihoRo，填补了该语言在心理健康NLP资源方面的空白


<details>
  <summary>Details</summary>
Motivation: 罗马尼亚语目前没有开源的心理健康语料库，而现有的心理语料库收集方法（特别是从社交媒体收集）存在假设偏差问题，需要更可靠的数据收集策略

Method: 通过6个开放式问题结合标准化的PHQ-9和GAD-7筛查问卷收集数据，共获得205名受访者的文本，然后使用统计分析、罗马尼亚语LIWC文本分析、情感检测和主题建模等方法进行分析

Result: 成功创建了PsihoRo语料库，这是第一个罗马尼亚语抑郁和焦虑语料库，虽然样本量较小（205名受访者），但为分析罗马尼亚人口的心理健康文本提供了基础

Conclusion: PsihoRo是理解罗马尼亚人口心理健康文本的第一步，为NLP社区提供了重要的新资源，展示了通过开放式问题结合标准化问卷收集心理健康数据的有效方法

Abstract: Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.

</details>


### [24] [Predicting Contextual Informativeness for Vocabulary Learning using Deep Learning](https://arxiv.org/abs/2602.18326)
*Tao Wu,Adam Kapelner*

Main category: cs.CL

TL;DR: 本研究开发了一个深度学习系统，用于自动筛选高中英语词汇教学的有效语境示例，通过对比三种建模方法，证明结合监督学习和人工特征的模型能高效生成高质量教学语境。


<details>
  <summary>Details</summary>
Motivation: 传统的词汇教学需要教师花费大量时间寻找合适的语境示例，效率低下且质量参差不齐。本研究旨在开发一个自动化的深度学习系统，能够高效、低成本地生成高质量的教学语境，解决词汇教学中语境资源不足的问题。

Method: 提出了三种建模方法：(1) 基于MPNet统一上下文嵌入的无监督相似度策略；(2) 基于指令感知、微调Qwen3嵌入和监督学习的非线性回归框架；(3) 在方法(2)基础上加入人工设计的语境特征。同时引入了新的评估指标"保留能力曲线"，用于可视化模型在丢弃良好语境比例和良好-不良语境比率之间的权衡。

Result: 模型(3)表现最佳，在仅丢弃70%良好语境的情况下，达到了440的良好-不良语境比率，实现了显著的性能提升。这表明结合监督学习和人工特征的深度学习方法能够高效生成大量近乎完美的教学语境。

Conclusion: 研究表明，基于现代嵌入模型和神经网络架构，在人类监督指导下，能够以低成本大规模生成近乎完美的词汇教学语境，为多种目标词汇提供高质量的教学资源。

Abstract: We describe a modern deep learning system that automatically identifies informative contextual examples (\qu{contexts}) for first language vocabulary instruction for high school student. Our paper compares three modeling approaches: (i) an unsupervised similarity-based strategy using MPNet's uniformly contextualized embeddings, (ii) a supervised framework built on instruction-aware, fine-tuned Qwen3 embeddings with a nonlinear regression head and (iii) model (ii) plus handcrafted context features. We introduce a novel metric called the Retention Competency Curve to visualize trade-offs between the discarded proportion of good contexts and the \qu{good-to-bad} contexts ratio providing a compact, unified lens on model performance. Model (iii) delivers the most dramatic gains with performance of a good-to-bad ratio of 440 all while only throwing out 70\% of the good contexts. In summary, we demonstrate that a modern embedding model on neural network architecture, when guided by human supervision, results in a low-cost large supply of near-perfect contexts for teaching vocabulary for a variety of target words.

</details>


### [25] [Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System](https://arxiv.org/abs/2602.18346)
*Pavithra PM Nair,Preethu Rose Anish*

Main category: cs.CL

TL;DR: Vichara是一个专为印度司法系统设计的框架，能够预测和解释上诉判决，通过分解案件文档为决策点，采用类似IRAC的结构化解释，在多个数据集上超越了现有基准。


<details>
  <summary>Details</summary>
Motivation: 印度法院面临大量案件积压，上诉案件是其中的重要组成部分。人工智能在预测法律判决方面具有变革潜力，但需要专门针对印度司法系统的解决方案。

Method: Vichara框架处理英文上诉案件文件，将其分解为决策点（包含法律问题、裁决机构、结果、推理和时间背景的结构化表示）。解释采用受IRAC启发并适应印度法律推理的结构化格式。

Result: 在PredEx和ILDC_expert两个数据集上，Vichara超越了现有的判决预测基准。GPT-4o mini表现最佳（F1：PredEx 81.5，ILDC_expert 80.3），其次是Llama-3.1-8B。人工评估显示GPT-4o mini在解释的清晰度、关联性和实用性方面表现最优。

Conclusion: Vichara框架通过结构化决策点和解释，为印度上诉案件提供了准确且可解释的判决预测，有助于减轻司法积压问题，并为法律专业人士提供有效的决策支持工具。

Abstract: In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.

</details>


### [26] [Validating Political Position Predictions of Arguments](https://arxiv.org/abs/2602.18351)
*Jordan Robinson,Angus R. Williams,Katie Atkinson,Anthony G. Cohn*

Main category: cs.CL

TL;DR: 该论文提出了一种双尺度验证框架，结合点式和成对人类标注，用于政治立场预测任务，构建了大规模结构化论证知识库。


<details>
  <summary>Details</summary>
Motivation: 现实世界知识表示常需要捕捉主观、连续属性（如政治立场），这与广泛接受的成对验证黄金标准存在冲突。需要解决主观连续知识验证的挑战。

Method: 采用双尺度验证框架：结合点式（pointwise）和成对（pairwise）人类标注。使用22个语言模型对30场辩论中的23,228个论点进行政治立场预测，构建大规模知识库。

Result: 点式评估显示中等水平的人-模型一致性（Krippendorff's α=0.578），反映内在主观性；成对验证显示更强的一致性（最佳模型α=0.86）。成功构建了经过验证的结构化论证知识库。

Conclusion: 该工作贡献包括：实用的主观连续知识验证方法、可用于图推理和检索增强生成的政治领域知识库、证明可以从点式语言模型预测中提取序数结构，推进了传统符号或分类方法不足的领域知识表示能力。

Abstract: Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $α=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($α=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.

</details>


### [27] [SPQ: An Ensemble Technique for Large Language Model Compression](https://arxiv.org/abs/2602.18420)
*Jiamin Yao,Eren Gultepe*

Main category: cs.CL

TL;DR: SPQ是一种结合SVD、剪枝和量化的集成压缩技术，能在保持模型性能的同时显著减少LLM的内存占用和提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 为了在内存受限的环境中实际部署大型语言模型，需要一种有效的压缩技术来减少模型的内存占用，同时保持或提升模型性能。

Method: SPQ集成三种互补技术：1)基于激活的剪枝去除MLP层的冗余神经元；2)保留方差的SVD将注意力投影分解为紧凑低秩因子；3)8位线性量化均匀压缩所有线性层。

Result: 在LLaMA-2-7B上，SPQ实现高达75%的内存减少，困惑度从5.47降至4.91（WikiText-2），在下游任务上保持准确率。相比GPTQ和SparseGPT，SPQ使用更少内存（6.86 GB vs 7.16 GB）且推理速度提升1.9倍。

Conclusion: SPQ通过层感知和互补的压缩技术，为LLM在内存受限环境中的实际部署提供了有效的解决方案，在压缩比、性能和推理速度方面都表现出色。

Abstract: This study presents an ensemble technique, SPQ (SVD-Pruning-Quantization), for large language model (LLM) compression that combines variance-retained singular value decomposition (SVD), activation-based pruning, and post-training linear quantization. Each component targets a different source of inefficiency: i) pruning removes redundant neurons in MLP layers, ii) SVD reduces attention projections into compact low-rank factors, iii) and 8-bit quantization uniformly compresses all linear layers. At matched compression ratios, SPQ outperforms individual methods (SVD-only, pruning-only, or quantization-only) in perplexity, demonstrating the benefit of combining complementary techniques. Applied to LLaMA-2-7B, SPQ achieves up to 75% memory reduction while maintaining or improving perplexity (e.g., WikiText-2 5.47 to 4.91) and preserving accuracy on downstream benchmarks such as C4, TruthfulQA, and GSM8K. Compared to strong baselines like GPTQ and SparseGPT, SPQ offers competitive perplexity and accuracy while using less memory (6.86 GB vs. 7.16 GB for GPTQ). Moreover, SPQ improves inference throughput over GPTQ, achieving up to a 1.9x speedup, which further enhances its practicality for real-world deployment. The effectiveness of SPQ's robust compression through layer-aware and complementary compression techniques may provide practical deployment of LLMs in memory-constrained environments. Code is available at: https://github.com/JiaminYao/SPQ_LLM_Compression/

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [28] [When & How to Write for Personalized Demand-aware Query Rewriting in Video Search](https://arxiv.org/abs/2602.17667)
*Cheng cheng,Chenxing Wang,Aolin Li,Haijun Wu,Huiyun Hu,Juyuan Wang*

Main category: cs.IR

TL;DR: WeWrite是一个个性化需求感知的查询重写框架，通过自动化挖掘策略、混合训练范式和并行部署架构，解决视频搜索中的个性化查询重写问题。


<details>
  <summary>Details</summary>
Motivation: 视频搜索系统中，用户历史行为为识别搜索意图和消除歧义提供了丰富上下文，但传统使用隐式历史特征的方法存在信号稀释和反馈延迟的问题。

Method: 1) 何时重写：基于后验的自动化挖掘策略从用户日志中提取高质量样本，识别严格需要个性化的场景；2) 如何重写：结合监督微调（SFT）和组相对策略优化（GRPO）的混合训练范式，使LLM输出风格与检索系统对齐；3) 部署：采用并行"伪召回"架构确保低延迟。

Result: 在大规模视频平台上的在线A/B测试显示，WeWrite将点击观看视频量（VV>10s）提升了1.07%，并将查询重构率降低了2.97%。

Conclusion: WeWrite通过解决个性化查询重写中的关键挑战，有效提升了视频搜索系统的性能，证明了其在现实应用中的有效性。

Abstract: In video search systems, user historical behaviors provide rich context for identifying search intent and resolving ambiguity. However, traditional methods utilizing implicit history features often suffer from signal dilution and delayed feedback. To address these challenges, we propose WeWrite, a novel Personalized Demand-aware Query Rewriting framework. Specifically, WeWrite tackles three key challenges: (1) When to Write: An automated posterior-based mining strategy extracts high-quality samples from user logs, identifying scenarios where personalization is strictly necessary; (2) How to Write: A hybrid training paradigm combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to align the LLM's output style with the retrieval system; (3) Deployment: A parallel "Fake Recall" architecture ensures low latency. Online A/B testing on a large-scale video platform demonstrates that WeWrite improves the Click-Through Video Volume (VV$>$10s) by 1.07% and reduces the Query Reformulation Rate by 2.97%.

</details>


### [29] [IRPAPERS: A Visual Document Benchmark for Scientific Retrieval and Question Answering](https://arxiv.org/abs/2602.17687)
*Connor Shorten,Augustas Skaburskas,Daniel M. Jones,Charles Pierse,Roberto Esposito,John Trengrove,Etienne Dilocker,Bob van Luijt*

Main category: cs.IR

TL;DR: IRPAPERS是一个包含3,230页科学论文的基准数据集，用于比较基于图像和基于文本的文档检索与问答系统。研究发现两种模态具有互补性，多模态混合检索优于单一模态，且封闭源图像嵌入模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在文本和关系数据处理方面取得了显著成功，但视觉文档处理仍相对未被充分探索。传统系统需要OCR转录将视觉文档转换为文本和元数据，而最近的多模态基础模型提供了直接从文档图像进行检索和生成的能力。这引发了一个关键问题：基于图像的系统与成熟的基于文本方法相比如何？

Method: 引入IRPAPERS基准数据集，包含166篇科学论文的3,230页，每页都有图像和OCR转录。使用180个"大海捞针"式问题，比较基于图像和基于文本的检索与问答系统。评估了多种检索方法：文本检索使用Arctic 2.0嵌入、BM25和混合文本搜索；图像检索使用多向量图像嵌入模型；以及多模态混合搜索。还评估了效率-性能权衡和多个问答系统。

Result: 文本检索达到46% Recall@1、78% Recall@5和91% Recall@20，图像检索达到43%、78%和93%。两种模态表现出互补的失败模式，使多模态混合搜索优于任一单独模态，达到49% Recall@1、81% Recall@5和95% Recall@20。封闭源模型中，Cohere Embed v4页面图像嵌入优于Voyage 3 Large文本嵌入和所有开源模型，达到58% Recall@1、87% Recall@5和97% Recall@20。在问答方面，基于文本的RAG系统比基于图像的系统具有更高的真实对齐度（0.82 vs. 0.71），且两者都从增加检索深度中受益显著。

Conclusion: 基于图像和基于文本的文档处理系统各有优势和局限性，它们具有互补性。多模态混合方法能够结合两者的优势，在文档检索任务上表现最佳。封闭源图像嵌入模型在检索性能上领先。研究还识别了需要特定模态的问题类型，为未来视觉文档处理系统的设计提供了指导。IRPAPERS数据集和实验代码已公开提供。

Abstract: AI systems have achieved remarkable success in processing text and relational data, yet visual document processing remains relatively underexplored. Whereas traditional systems require OCR transcriptions to convert these visual documents into text and metadata, recent advances in multimodal foundation models offer retrieval and generation directly from document images. This raises a key question: How do image-based systems compare to established text-based methods? We introduce IRPAPERS, a benchmark of 3,230 pages from 166 scientific papers, with both an image and an OCR transcription for each page. Using 180 needle-in-the-haystack questions, we compare image- and text-based retrieval and question answering systems. Text retrieval using Arctic 2.0 embeddings, BM25, and hybrid text search achieved 46% Recall@1, 78% Recall@5, and 91% Recall@20, while image-based retrieval reaches 43%, 78%, and 93%, respectively. The two modalities exhibit complementary failures, enabling multimodal hybrid search to outperform either alone, achieving 49% Recall@1, 81% Recall@5, and 95% Recall@20. We further evaluate efficiency-performance tradeoffs with MUVERA and assess multiple multi-vector image embedding models. Among closed-source models, Cohere Embed v4 page image embeddings outperform Voyage 3 Large text embeddings and all tested open-source models, achieving 58% Recall@1, 87% Recall@5, and 97% Recall@20. For question answering, text-based RAG systems achieved higher ground-truth alignment than image-based systems (0.82 vs. 0.71), and both benefit substantially from increased retrieval depth, with multi-document retrieval outperforming oracle single-document retrieval. We analyze the complementary limitations of unimodal text and image representations and identify question types that require one modality over the other. The IRPAPERS dataset and all experimental code are publicly available.

</details>


### [30] [Enhancing Scientific Literature Chatbots with Retrieval-Augmented Generation: A Performance Evaluation of Vector and Graph-Based Systems](https://arxiv.org/abs/2602.17856)
*Hamideh Ghanadian,Amin Kamali,Mohammad Hossein Tekieh*

Main category: cs.IR

TL;DR: 本研究评估了基于向量和图检索的RAG系统在科学文献聊天机器人中的应用，通过混合检索策略提升科学知识获取效率。


<details>
  <summary>Details</summary>
Motivation: 科学文献数量庞大且形式多样（结构化与非结构化），传统检索方式难以高效支持证据驱动的决策。需要探索更有效的检索增强生成方法，以提升科学知识获取的准确性和相关性。

Method: 构建了结合图数据库（结构化）和向量数据库（非结构化）的混合RAG系统。设计了两种使用场景：单文档检索和大规模语料库检索。使用GPT生成基准测试集，并对部分输出进行人工标注评估。重点比较检索准确性和响应相关性。

Result: 研究表明混合RAG系统在科学文献检索中表现优异，能根据研究目标高效筛选资源。向量和图检索各有优势，混合方法能互补提升整体性能。

Conclusion: 混合RAG系统能显著改善科学知识的可访问性，支持基于证据的决策制定。未来的研究可进一步优化检索策略，提升系统在复杂科学查询中的表现。

Abstract: This paper investigates the enhancement of scientific literature chatbots through retrieval-augmented generation (RAG), with a focus on evaluating vector- and graph-based retrieval systems. The proposed chatbot leverages both structured (graph) and unstructured (vector) databases to access scientific articles and gray literature, enabling efficient triage of sources according to research objectives. To systematically assess performance, we examine two use-case scenarios: retrieval from a single uploaded document and retrieval from a large-scale corpus. Benchmark test sets were generated using a GPT model, with selected outputs annotated for evaluation. The comparative analysis emphasizes retrieval accuracy and response relevance, providing insight into the strengths and limitations of each approach. The findings demonstrate the potential of hybrid RAG systems to improve accessibility to scientific knowledge and to support evidence-based decision making.

</details>


### [31] [SuiteEval: Simplifying Retrieval Benchmarks](https://arxiv.org/abs/2602.18107)
*Andrew Parry,Debasis Ganguly,Sean MacAvaney*

Main category: cs.IR

TL;DR: SuiteEval是一个统一的检索评估框架，提供端到端自动评估、动态索引复用减少磁盘占用，并支持主流基准测试，简化IR研究的可复现评估。


<details>
  <summary>Details</summary>
Motivation: 当前信息检索评估实践碎片化，存在数据集子集、聚合方法、流水线配置等方面的不一致，损害了可复现性和可比性，特别是对于需要在领域外有稳健性能的基础嵌入模型。

Method: 提出SuiteEval框架，提供自动端到端评估、动态索引复用磁盘索引以最小化磁盘使用，内置对BEIR、LoTTE、MS MARCO、NanoBEIR和BRIGHT等主要基准的支持。用户只需提供流水线生成器，框架处理数据加载、索引、排序、指标计算和结果聚合。

Result: SuiteEval减少了样板代码，标准化了评估流程，促进了可复现的IR研究，特别是随着需要更广泛基准集合的趋势。

Conclusion: SuiteEval通过统一框架解决了IR评估碎片化问题，简化了评估流程，提升了研究的可复现性和可比性。

Abstract: Information retrieval evaluation often suffers from fragmented practices -- varying dataset subsets, aggregation methods, and pipeline configurations -- that undermine reproducibility and comparability, especially for foundation embedding models requiring robust out-of-domain performance. We introduce SuiteEval, a unified framework that offers automatic end-to-end evaluation, dynamic indexing that reuses on-disk indices to minimise disk usage, and built-in support for major benchmarks (BEIR, LoTTE, MS MARCO, NanoBEIR, and BRIGHT). Users only need to supply a pipeline generator. SuiteEval handles data loading, indexing, ranking, metric computation, and result aggregation. New benchmark suites can be added in a single line. SuiteEval reduces boilerplate and standardises evaluations to facilitate reproducible IR research, as a broader benchmark set is increasingly required.

</details>


### [32] [A Simple yet Effective Negative Sampling Plugin for Constructing Positive Sample Pairs in Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18206)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Ronghua Li,Guoren Wang*

Main category: cs.IR

TL;DR: PSP-NS是一个用于隐式协同过滤的负采样插件，通过增强正样本监督信号和活动感知加权来提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 现有隐式CF模型大多关注高质量的负样本设计，但忽视了正样本的探索。现有去噪推荐方法虽然可以用于隐式CF的正样本去噪，但往往会稀疏化正监督信号，并且通常忽略了训练过程中的用户活动偏差，导致不活跃用户学习不足。

Method: 提出PSP-NS负采样插件：1）构建用户-物品二部图，边权重表示从全局和局部模式推断的交互置信度；2）通过基于复制的重加权生成正样本对以增强正信号；3）采用活动感知加权方案有效学习不活跃用户的偏好。

Result: 在四个真实世界数据集上进行广泛实验，证明其优越性。例如在Yelp数据集上，PSP-NS比最强基线提升了Recall@30 32.11%和Precision@30 22.90%。该插件可以与各种隐式CF推荐器或负采样方法集成以增强性能。

Conclusion: PSP-NS是一个简单有效的负采样插件，通过增强正监督信号和活动感知加权，解决了现有方法忽视正样本探索和用户活动偏差的问题，显著提升了推荐排名质量。

Abstract: Most implicit collaborative filtering (CF) models are trained with negative sampling, where existing work designs sophisticated strategies for high-quality negatives while largely overlooking the exploration of positive samples. Although some denoising recommendation methods can be applied to implicit CF for denoising positive samples, they often sparsify positive supervision. Moreover, these approaches generally overlook user activity bias during training, leading to insufficient learning for inactive users. To address these issues, we propose a simple yet effective negative sampling plugin, PSP-NS, from the perspective of enhancing positive supervision signals. It builds a user-item bipartite graph with edge weights indicating interaction confidence inferred from global and local patterns, generates positive sample pairs via replication-based reweighting to strengthen positive signals, and adopts an activity-aware weighting scheme to effectively learn inactive users' preferences. We provide theoretical insights from a margin-improvement perspective, explaining why PSP-NS tends to improve ranking quality (e.g., Precision@k/Recall@k), and conduct extensive experiments on four real-world datasets to demonstrate its superiority. For instance, PSP-NS boosts Recall@30 and Precision@30 by 32.11% and 22.90% on Yelp over the strongest baselines. PSP-NS can be integrated with various implicit CF recommenders or negative sampling methods to enhance their performance.

</details>


### [33] [The Economical-Ecological Benefits of Matching Non-matching Socks](https://arxiv.org/abs/2602.18221)
*Teddy Lazebnik*

Main category: cs.IR

TL;DR: 研究发现严格配对袜子会浪费资源，而容忍不匹配的袜子配对可以显著减少浪费并维持使用。


<details>
  <summary>Details</summary>
Motivation: 袜子作为成对使用的物品，单只丢失会导致另一只被闲置并触发过早更换，造成大量经济浪费和生态影响。研究旨在量化"孤儿袜"配对的经济和生态价值，以及阻碍这种行为的社会成本。

Method: 将袜子所有权建模为不确定条件下的序列决策问题，考虑洗涤过程中的随机磨损和丢失，以及公共场合暴露带来的个人特定不匹配惩罚。通过现场研究估计不匹配敏感性和多样性偏好，将行为异质性与最优配对策略联系起来。使用计算机模拟评估可解释的配对策略。

Result: 严格配对袜子表面上看似节省资源，但实际上是因为产生了许多无袜可穿的日子。而有控制地容忍不匹配的袜子配对可以维持袜子服务功能，并在各种丢失情况下减少闲置容量。

Conclusion: 研究证实了配对不匹配袜子的可行性，同时也指出了其局限性和挑战。通过容忍一定的不匹配，可以在减少浪费的同时维持袜子使用。

Abstract: Socks are produced and replaced at a massive scale, yet their paired use makes them unusually vulnerable to waste, as the loss of a single sock can strand usable wear-capacity and trigger premature replacement. In this study, we quantify the economic and ecological value of pairing non-matching \say{orphan} socks, and the social cost that discourages this behaviour. We formalize sock ownership as a sequential decision problem under uncertainty in which socks wear out and disappear stochastically during laundering, while public exposure induces a person-specific mismatch penalty. We conducted an in-person study to estimate mismatch sensitivity and diversity preference, linking behavioural heterogeneity to optimal mixing strategies. Using these results and a computer simulation-based evaluation of interpretable pairing policies, we show that strict matching can appear resource-frugal largely because it generates many sockless days, whereas controlled tolerance for mismatch sustains service and reduces stranded capacity across loss regimes. This study establishes the feasibility of matching non-matching socks while outlining its limitations and challenges.

</details>


### [34] [Dual-Tree LLM-Enhanced Negative Sampling for Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18249)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.IR

TL;DR: DTL-NS是一种无需文本和微调的双树LLM增强负采样方法，通过离线假负样本识别和多视角硬负采样模块，提升隐式协同过滤推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的负采样方法过度依赖文本信息和任务特定微调，限制了实际应用。需要开发无需文本和微调的LLM增强负采样方法。

Method: 提出DTL-NS方法，包含两个模块：1）离线假负样本识别模块，利用分层索引树将协同结构和潜在语义信息转化为结构化项目ID编码供LLM推理；2）多视角硬负采样模块，结合用户-项目偏好分数和项目间分层相似性挖掘高质量硬负样本。

Result: 在Amazon-sports数据集上，DTL-NS在Recall@20和NDCG@20指标上分别优于最强基线10.64%和19.12%。该方法可集成到多种隐式CF模型和负采样方法中，持续提升性能。

Conclusion: DTL-NS通过文本无关、无需微调的LLM增强负采样，有效识别假负样本并挖掘高质量硬负样本，显著提升推荐系统性能，具有广泛的适用性。

Abstract: Negative sampling is a pivotal technique in implicit collaborative filtering (CF) recommendation, enabling efficient and effective training by contrasting observed interactions with sampled unobserved ones.
  Recently, large language models (LLMs) have shown promise in recommender systems; however, research on LLM-empowered negative sampling remains underexplored.
  Existing methods heavily rely on textual information and task-specific fine-tuning, limiting practical applicability.
  To address this limitation, we propose a text-free and fine-tuning-free Dual-Tree LLM-enhanced Negative Sampling method (DTL-NS).
  It consists of two modules: (i) an offline false negative identification module that leverages hierarchical index trees to transform collaborative structural and latent semantic information into structured item-ID encodings for LLM inference, enabling accurate identification of false negatives; and (ii) a multi-view hard negative sampling module that combines user-item preference scores with item-item hierarchical similarities from these encodings to mine high-quality hard negatives, thus improving models' discriminative ability.
  Extensive experiments demonstrate the effectiveness of DTL-NS. For example, on the Amazon-sports dataset, DTL-NS outperforms the strongest baseline by 10.64% and 19.12% in Recall@20 and NDCG@20, respectively.
  Moreover, DTL-NS can be integrated into various implicit CF models and negative sampling methods, consistently enhancing their performance.

</details>


### [35] [HyTRec: A Hybrid Temporal-Aware Attention Architecture for Long Behavior Sequential Recommendation](https://arxiv.org/abs/2602.18283)
*Lei Xin,Yuhao Zheng,Ke Cheng,Changjiang Jiang,Zifan Zhang,Fanhu Zeng*

Main category: cs.IR

TL;DR: HyTRec提出混合注意力架构，将长序列行为解耦为长期稳定偏好和短期意图波动，通过线性注意力处理历史序列、软注意力处理近期交互，在保持线性推理速度的同时提升检索精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临两难困境：线性注意力机制效率高但检索精度有限（状态容量不足），而softmax注意力计算开销巨大。需要一种能在工业规模（上万次交互）下既高效又精确的序列建模方法。

Method: 1. 混合注意力架构：线性注意力分支处理大规模历史序列，软注意力分支专门处理近期交互
2. 时间感知Delta网络（TADN）：动态提升新鲜行为信号的权重，抑制历史噪声
3. 显式解耦长期稳定偏好和短期意图波动

Result: 在工业规模数据集上，模型保持线性推理速度的同时优于强基线，对超长序列用户的命中率提升超过8%，且效率优异。

Conclusion: HyTRec通过混合注意力架构有效解决了长序列建模中效率与精度的权衡问题，为工业级生成式推荐系统提供了实用解决方案。

Abstract: Modeling long sequences of user behaviors has emerged as a critical frontier in generative recommendation. However, existing solutions face a dilemma: linear attention mechanisms achieve efficiency at the cost of retrieval precision due to limited state capacity, while softmax attention suffers from prohibitive computational overhead. To address this challenge, we propose HyTRec, a model featuring a Hybrid Attention architecture that explicitly decouples long-term stable preferences from short-term intent spikes. By assigning massive historical sequences to a linear attention branch and reserving a specialized softmax attention branch for recent interactions, our approach restores precise retrieval capabilities within industrial-scale contexts involving ten thousand interactions. To mitigate the lag in capturing rapid interest drifts within the linear layers, we furthermore design Temporal-Aware Delta Network (TADN) to dynamically upweight fresh behavioral signals while effectively suppressing historical noise. Empirical results on industrial-scale datasets confirm the superiority that our model maintains linear inference speed and outperforms strong baselines, notably delivering over 8% improvement in Hit Rate for users with ultra-long sequences with great efficiency.

</details>


### [36] [A Topology-Aware Positive Sample Set Construction and Feature Optimization Method in Implicit Collaborative Filtering](https://arxiv.org/abs/2602.18288)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.IR

TL;DR: 提出TPSC-FO方法，通过拓扑感知的正样本集构建和特征优化，解决隐式协同过滤中负采样引入假阴性的问题


<details>
  <summary>Details</summary>
Motivation: 现有负采样方法在隐式协同过滤中存在两个关键限制：过度依赖模型当前表示能力；未能利用假阴性样本作为潜在正样本来更准确地学习用户偏好

Method: 提出TPSC-FO方法，包含拓扑感知正样本集构建模块（使用差分社区检测策略和个性化噪声过滤识别假阴性并转为正样本）和邻域引导特征优化模块（在嵌入空间中结合邻域特征细化正样本特征）

Result: 在五个真实世界数据集和两个合成数据集上的广泛实验验证了TPSC-FO的有效性

Conclusion: TPSC-FO通过利用交互网络中的拓扑社区结构识别假阴性并将其转化为正样本，结合邻域特征优化，能够更准确地学习用户偏好，提高隐式协同过滤性能

Abstract: Negative sampling strategies are widely used in implicit collaborative filtering to address issues like data sparsity and class imbalance. However, these methods often introduce false negatives, hindering the model's ability to accurately learn users' latent preferences. To mitigate this problem, existing methods adjust the negative sampling distribution based on statistical features from model training or the hardness of negative samples. Nevertheless, these methods face two key limitations: (1) over-reliance on the model's current representation capabilities; (2) failure to leverage the potential of false negatives as latent positive samples to guide model learning of user preferences more accurately. To address the above issues, we propose a Topology-aware Positive Sample Set Construction and Feature Optimization method (TPSC-FO). First, we design a simple topological community-aware false negative identification (FNI) method and observe that topological community structures in interaction networks can effectively identify false negatives. Motivated by this, we develop a topology-aware positive sample set construction module. This module employs a differential community detection strategy to capture topological community structures in implicit feedback, coupled with personalized noise filtration to reliably identify false negatives and convert them into positive samples. Additionally, we introduce a neighborhood-guided feature optimization module that refines positive sample features by incorporating neighborhood features in the embedding space, effectively mitigating noise in the positive samples. Extensive experiments on five real-world datasets and two synthetic datasets validate the effectiveness of TPSC-FO.

</details>
