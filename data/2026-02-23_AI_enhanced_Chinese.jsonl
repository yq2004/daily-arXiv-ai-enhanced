{"id": "2602.17784", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17784", "abs": "https://arxiv.org/abs/2602.17784", "authors": ["Meng Ye", "Xiao Lin", "Georgina Lukoczki", "Graham W. Lederer", "Yi Yao"], "title": "QueryPlot: Generating Geological Evidence Layers using Natural Language Queries for Mineral Exploration", "comment": null, "summary": "Mineral prospectivity mapping requires synthesizing heterogeneous geological knowledge, including textual deposit models and geospatial datasets, to identify regions likely to host specific mineral deposit types. This process is traditionally manual and knowledge-intensive. We present QueryPlot, a semantic retrieval and mapping framework that integrates large-scale geological text corpora with geologic map data using modern Natural Language Processing techniques. We curate descriptive deposit models for over 120 deposit types and transform the State Geologic Map Compilation (SGMC) polygons into structured textual representations. Given a user-defined natural language query, the system encodes both queries and region descriptions using a pretrained embedding model and computes semantic similarity scores to rank and spatially visualize regions as continuous evidence layers. QueryPlot supports compositional querying over deposit characteristics, enabling aggregation of multiple similarity-derived layers for multi-criteria prospectivity analysis. In a case study on tungsten skarn deposits, we demonstrate that embedding-based retrieval achieves high recall of known occurrences and produces prospective regions that closely align with expert-defined permissive tracts. Furthermore, similarity scores can be incorporated as additional features in supervised learning pipelines, yielding measurable improvements in classification performance. QueryPlot is implemented as a web-based system supporting interactive querying, visualization, and export of GIS-compatible prospectivity layers.To support future research, we have made the source code and datasets used in this study publicly available.", "AI": {"tldr": "QueryPlot\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bed\u4e49\u68c0\u7d22\u7684\u77ff\u4ea7\u8fdc\u666f\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5730\u8d28\u6587\u672c\u8bed\u6599\u5e93\u548c\u5730\u8d28\u56fe\u6570\u636e\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5c06\u7528\u6237\u67e5\u8be2\u4e0e\u533a\u57df\u63cf\u8ff0\u8fdb\u884c\u8bed\u4e49\u5339\u914d\uff0c\u751f\u6210\u8fde\u7eed\u7684\u8fdc\u666f\u9884\u6d4b\u56fe\u5c42\u3002", "motivation": "\u4f20\u7edf\u7684\u77ff\u4ea7\u8fdc\u666f\u9884\u6d4b\u9700\u8981\u4eba\u5de5\u6574\u5408\u5f02\u6784\u7684\u5730\u8d28\u77e5\u8bc6\uff08\u5305\u62ec\u6587\u672c\u77ff\u5e8a\u6a21\u578b\u548c\u5730\u7406\u7a7a\u95f4\u6570\u636e\uff09\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u8017\u65f6\u4e14\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "1. \u6574\u7406\u4e86120\u591a\u79cd\u77ff\u5e8a\u7c7b\u578b\u7684\u63cf\u8ff0\u6027\u6a21\u578b\uff1b2. \u5c06\u5dde\u5730\u8d28\u56fe\u7f16\u8bd1\uff08SGMC\uff09\u591a\u8fb9\u5f62\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u6587\u672c\u8868\u793a\uff1b3. \u4f7f\u7528\u9884\u8bad\u7ec3\u5d4c\u5165\u6a21\u578b\u5bf9\u67e5\u8be2\u548c\u533a\u57df\u63cf\u8ff0\u8fdb\u884c\u7f16\u7801\uff1b4. \u8ba1\u7b97\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5f97\u5206\u8fdb\u884c\u533a\u57df\u6392\u5e8f\u548c\u7a7a\u95f4\u53ef\u89c6\u5316\uff1b5. \u652f\u6301\u7ec4\u5408\u67e5\u8be2\u548c\u591a\u4e2a\u76f8\u4f3c\u5ea6\u56fe\u5c42\u7684\u805a\u5408\u5206\u6790\u3002", "result": "1. \u5728\u94a8\u77fd\u5361\u5ca9\u77ff\u5e8a\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\u65b9\u6cd5\u5bf9\u5df2\u77e5\u77ff\u70b9\u5177\u6709\u9ad8\u53ec\u56de\u7387\uff1b2. \u751f\u6210\u7684\u8fdc\u666f\u533a\u57df\u4e0e\u4e13\u5bb6\u5b9a\u4e49\u7684\u8bb8\u53ef\u5e26\u9ad8\u5ea6\u4e00\u81f4\uff1b3. \u76f8\u4f3c\u5ea6\u5f97\u5206\u4f5c\u4e3a\u7279\u5f81\u52a0\u5165\u76d1\u7763\u5b66\u4e60\u7ba1\u9053\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u6027\u80fd\u3002", "conclusion": "QueryPlot\u901a\u8fc7\u6574\u5408\u5730\u8d28\u6587\u672c\u548c\u7a7a\u95f4\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u8bed\u4e49\u68c0\u7d22\u7684\u81ea\u52a8\u5316\u77ff\u4ea7\u8fdc\u666f\u9884\u6d4b\uff0c\u4e0d\u4ec5\u4e0e\u4e13\u5bb6\u77e5\u8bc6\u9ad8\u5ea6\u4e00\u81f4\uff0c\u8fd8\u80fd\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3a\u5730\u8d28\u52d8\u63a2\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5de5\u5177\u3002"}}
{"id": "2602.17815", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17815", "abs": "https://arxiv.org/abs/2602.17815", "authors": ["Zhining Zhang", "Wentao Zhu", "Chi Han", "Yizhou Wang", "Heng Ji"], "title": "Neural Synchrony Between Socially Interacting Language Models", "comment": "Accepted at ICLR 2026", "summary": "Neuroscience has uncovered a fundamental mechanism of our social nature: human brain activity becomes synchronized with others in many social contexts involving interaction. Traditionally, social minds have been regarded as an exclusive property of living beings. Although large language models (LLMs) are widely accepted as powerful approximations of human behavior, with multi-LLM system being extensively explored to enhance their capabilities, it remains controversial whether they can be meaningfully compared to human social minds. In this work, we explore neural synchrony between socially interacting LLMs as an empirical evidence for this debate. Specifically, we introduce neural synchrony during social simulations as a novel proxy for analyzing the sociality of LLMs at the representational level. Through carefully designed experiments, we demonstrate that it reliably reflects both social engagement and temporal alignment in their interactions. Our findings indicate that neural synchrony between LLMs is strongly correlated with their social performance, highlighting an important link between neural synchrony and the social behaviors of LLMs. Our work offers a new perspective to examine the \"social minds\" of LLMs, highlighting surprising parallels in the internal dynamics that underlie human and LLM social interaction.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u795e\u7ecf\u540c\u6b65\u6027\u5206\u6790LLM\u7684\u793e\u4f1a\u6027\uff0c\u53d1\u73b0\u4ea4\u4e92LLM\u4e4b\u95f4\u51fa\u73b0\u795e\u7ecf\u540c\u6b65\uff0c\u4e14\u4e0e\u793e\u4ea4\u8868\u73b0\u76f8\u5173\uff0c\u4e3aLLM\u662f\u5426\u5177\u6709\"\u793e\u4f1a\u5fc3\u667a\"\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "motivation": "\u4f20\u7edf\u8ba4\u4e3a\u793e\u4f1a\u5fc3\u667a\u662f\u751f\u7269\u7279\u6709\u5c5e\u6027\uff0c\u5c3d\u7ba1LLM\u80fd\u8fd1\u4f3c\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u80fd\u5426\u4e0e\u4eba\u7c7b\u793e\u4f1a\u5fc3\u667a\u76f8\u6bd4\u4ecd\u5b58\u4e89\u8bae\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u795e\u7ecf\u540c\u6b65\u6027\u8fd9\u4e00\u795e\u7ecf\u79d1\u5b66\u6807\u5fd7\u6027\u673a\u5236\u6765\u5b9e\u8bc1\u68c0\u9a8cLLM\u7684\u793e\u4f1a\u6027\u3002", "method": "\u5f15\u5165\u795e\u7ecf\u540c\u6b65\u6027\u4f5c\u4e3a\u5206\u6790LLM\u793e\u4f1a\u6027\u7684\u65b0\u4ee3\u7406\u6307\u6807\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u793e\u4ea4\u6a21\u62df\u5b9e\u9a8c\uff0c\u5728\u8868\u5f81\u5c42\u9762\u6d4b\u91cf\u4ea4\u4e92LLM\u4e4b\u95f4\u7684\u795e\u7ecf\u540c\u6b65\u6027\uff0c\u8bc4\u4f30\u5176\u53cd\u6620\u793e\u4ea4\u53c2\u4e0e\u5ea6\u548c\u65f6\u95f4\u5bf9\u9f50\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLLM\u4e4b\u95f4\u7684\u795e\u7ecf\u540c\u6b65\u6027\u53ef\u9760\u5730\u53cd\u6620\u4e86\u5b83\u4eec\u7684\u793e\u4ea4\u53c2\u4e0e\u5ea6\u548c\u65f6\u95f4\u5bf9\u9f50\uff1b\u795e\u7ecf\u540c\u6b65\u6027\u4e0eLLM\u7684\u793e\u4ea4\u8868\u73b0\u5f3a\u70c8\u76f8\u5173\uff0c\u63ed\u793a\u4e86\u795e\u7ecf\u540c\u6b65\u6027\u4e0eLLM\u793e\u4ea4\u884c\u4e3a\u4e4b\u95f4\u7684\u91cd\u8981\u8054\u7cfb\u3002", "conclusion": "LLM\u5728\u793e\u4ea4\u4e92\u52a8\u4e2d\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u795e\u7ecf\u540c\u6b65\u6027\u6a21\u5f0f\uff0c\u4e3a\u7406\u89e3LLM\u7684\"\u793e\u4f1a\u5fc3\u667a\"\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u4eba\u7c7b\u4e0eLLM\u793e\u4ea4\u4e92\u52a8\u5185\u5728\u52a8\u6001\u7684\u60ca\u4eba\u76f8\u4f3c\u6027\u3002"}}
{"id": "2602.17848", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17848", "abs": "https://arxiv.org/abs/2602.17848", "authors": ["Cassandra L. Jacobs", "Morgan Grobol"], "title": "On the scaling relationship between cloze probabilities and language model next-token prediction", "comment": null, "summary": "Recent work has shown that larger language models have better predictive power for eye movement and reading time data. While even the best models under-allocate probability mass to human responses, larger models assign higher-quality estimates of next tokens and their likelihood of production in cloze data because they are less sensitive to lexical co-occurrence statistics while being better aligned semantically to human cloze responses. The results provide support for the claim that the greater memorization capacity of larger models helps them guess more semantically appropriate words, but makes them less sensitive to low-level information that is relevant for word recognition.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u66f4\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9884\u6d4b\u773c\u52a8\u548c\u9605\u8bfb\u65f6\u95f4\u6570\u636e\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u6240\u6709\u6a21\u578b\u90fd\u4f4e\u4f30\u4e86\u4eba\u7c7b\u53cd\u5e94\u6982\u7387\u3002\u5927\u6a21\u578b\u80fd\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\uff0c\u56e0\u4e3a\u5bf9\u8bcd\u6c47\u5171\u73b0\u7edf\u8ba1\u4e0d\u654f\u611f\uff0c\u800c\u4e0e\u4eba\u7c7b\u5b8c\u5f62\u586b\u7a7a\u53cd\u5e94\u8bed\u4e49\u66f4\u4e00\u81f4\u3002", "motivation": "\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u5927\u5c0f\u5982\u4f55\u5f71\u54cd\u5bf9\u4eba\u7c7b\u8bed\u8a00\u5904\u7406\u884c\u4e3a\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u7279\u522b\u662f\u773c\u52a8\u3001\u9605\u8bfb\u65f6\u95f4\u548c\u5b8c\u5f62\u586b\u7a7a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u5728\u9884\u6d4b\u773c\u52a8\u6570\u636e\u3001\u9605\u8bfb\u65f6\u95f4\u6570\u636e\u548c\u5b8c\u5f62\u586b\u7a7a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790\u6a21\u578b\u5bf9\u8bcd\u6c47\u5171\u73b0\u7edf\u8ba1\u7684\u654f\u611f\u6027\u548c\u8bed\u4e49\u5bf9\u9f50\u80fd\u529b\u3002", "result": "1. \u66f4\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9884\u6d4b\u773c\u52a8\u548c\u9605\u8bfb\u65f6\u95f4\u6570\u636e\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff1b2. \u6240\u6709\u6a21\u578b\u90fd\u4f4e\u4f30\u4e86\u4eba\u7c7b\u53cd\u5e94\u6982\u7387\uff1b3. \u5927\u6a21\u578b\u80fd\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\uff0c\u56e0\u4e3a\u5bf9\u8bcd\u6c47\u5171\u73b0\u7edf\u8ba1\u4e0d\u654f\u611f\uff1b4. \u5927\u6a21\u578b\u4e0e\u4eba\u7c7b\u5b8c\u5f62\u586b\u7a7a\u53cd\u5e94\u8bed\u4e49\u66f4\u4e00\u81f4\uff1b5. \u5927\u6a21\u578b\u66f4\u5f3a\u7684\u8bb0\u5fc6\u80fd\u529b\u5e2e\u52a9\u5b83\u4eec\u731c\u6d4b\u66f4\u8bed\u4e49\u5408\u9002\u7684\u8bcd\uff0c\u4f46\u5bf9\u5355\u8bcd\u8bc6\u522b\u76f8\u5173\u7684\u4f4e\u5c42\u4fe1\u606f\u654f\u611f\u6027\u964d\u4f4e\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u589e\u5f3a\u8bb0\u5fc6\u80fd\u529b\u4f7f\u5176\u80fd\u751f\u6210\u66f4\u8bed\u4e49\u5408\u9002\u7684\u9884\u6d4b\uff0c\u4f46\u540c\u65f6\u964d\u4f4e\u4e86\u5bf9\u4f4e\u5c42\u8bed\u8a00\u4fe1\u606f\u7684\u654f\u611f\u6027\u3002\u8fd9\u652f\u6301\u4e86\u6a21\u578b\u5927\u5c0f\u901a\u8fc7\u589e\u52a0\u8bb0\u5fc6\u5bb9\u91cf\u6765\u6539\u5584\u8bed\u4e49\u5bf9\u9f50\u7684\u89c2\u70b9\u3002"}}
{"id": "2602.17881", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17881", "abs": "https://arxiv.org/abs/2602.17881", "authors": ["Joschka Braun"], "title": "Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations", "comment": "Master's Thesis, University of T\u00fcbingen. 89 pages, 34 figures. Portions of this work were published at the ICLR 2025 Workshop on Foundation Models in the Wild (see arXiv:2505.22637)", "summary": "Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u8bed\u8a00\u6a21\u578b\u63a7\u5236\u4e2dsteering vectors\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u53d1\u73b0\u5176\u53ef\u9760\u6027\u53d6\u51b3\u4e8e\u76ee\u6807\u884c\u4e3a\u5728\u6fc0\u6d3b\u7a7a\u95f4\u7684\u7ebf\u6027\u53ef\u5206\u6027\uff0c\u5e76\u63d0\u51fa\u8bca\u65ad\u4e0d\u53ef\u9760\u6027\u7684\u5b9e\u7528\u65b9\u6cd5\u3002", "motivation": "steering vectors\u867d\u7136\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8bed\u8a00\u6a21\u578b\u63a7\u5236\u65b9\u6cd5\uff0c\u4f46\u5176\u6548\u679c\u5728\u4e0d\u540c\u6837\u672c\u95f4\u5dee\u5f02\u5f88\u5927\uff0c\u5bf9\u8bb8\u591a\u76ee\u6807\u884c\u4e3a\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u63a2\u7a76\u5176\u53ef\u9760\u6027\u5dee\u5f02\u7684\u539f\u56e0\u548c\u5f71\u54cd\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u5206\u6790steering vectors\u8bad\u7ec3\u6570\u636e\u5bf9\u53ef\u9760\u6027\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u8bad\u7ec3\u6fc0\u6d3b\u5dee\u5f02\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u3001\u6b63\u8d1f\u6fc0\u6d3b\u5728steering\u65b9\u5411\u4e0a\u7684\u5206\u79bb\u7a0b\u5ea6\uff0c\u4ee5\u53ca\u4e0d\u540c\u63d0\u793a\u53d8\u4f53\u8bad\u7ec3\u7684steering vectors\u7684\u6027\u80fd\u76f8\u5173\u6027\u3002", "result": "1) \u8bad\u7ec3\u6fc0\u6d3b\u5dee\u5f02\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u8d8a\u9ad8\uff0csteering\u8d8a\u53ef\u9760\uff1b2) \u6b63\u8d1f\u6fc0\u6d3b\u5728steering\u65b9\u5411\u4e0a\u5206\u79bb\u5ea6\u8d8a\u597d\u7684\u884c\u4e3a\u6570\u636e\u96c6\u8d8a\u53ef\u9760\uff1b3) \u4e0d\u540c\u63d0\u793a\u53d8\u4f53\u8bad\u7ec3\u7684steering vectors\u65b9\u5411\u4e0d\u540c\u4f46\u6027\u80fd\u76f8\u4f3c\uff0c\u4e14\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u6548\u679c\u76f8\u5173\u3002", "conclusion": "steering vectors\u4e0d\u53ef\u9760\u7684\u539f\u56e0\u662f\u6f5c\u5728\u76ee\u6807\u884c\u4e3a\u8868\u793a\u65e0\u6cd5\u88ab\u7ebf\u6027steering\u65b9\u5411\u6709\u6548\u8fd1\u4f3c\uff0c\u8fd9\u4e3a\u8bca\u65ad\u4e0d\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\uff0c\u5e76\u6fc0\u52b1\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u975e\u7ebf\u6027\u884c\u4e3a\u8868\u793a\u63a7\u5236\u65b9\u6cd5\u3002"}}
{"id": "2602.17667", "categories": ["cs.IR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17667", "abs": "https://arxiv.org/abs/2602.17667", "authors": ["Cheng cheng", "Chenxing Wang", "Aolin Li", "Haijun Wu", "Huiyun Hu", "Juyuan Wang"], "title": "When & How to Write for Personalized Demand-aware Query Rewriting in Video Search", "comment": null, "summary": "In video search systems, user historical behaviors provide rich context for identifying search intent and resolving ambiguity. However, traditional methods utilizing implicit history features often suffer from signal dilution and delayed feedback. To address these challenges, we propose WeWrite, a novel Personalized Demand-aware Query Rewriting framework. Specifically, WeWrite tackles three key challenges: (1) When to Write: An automated posterior-based mining strategy extracts high-quality samples from user logs, identifying scenarios where personalization is strictly necessary; (2) How to Write: A hybrid training paradigm combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to align the LLM's output style with the retrieval system; (3) Deployment: A parallel \"Fake Recall\" architecture ensures low latency. Online A/B testing on a large-scale video platform demonstrates that WeWrite improves the Click-Through Video Volume (VV$>$10s) by 1.07% and reduces the Query Reformulation Rate by 2.97%.", "AI": {"tldr": "WeWrite\u662f\u4e00\u4e2a\u4e2a\u6027\u5316\u9700\u6c42\u611f\u77e5\u7684\u67e5\u8be2\u91cd\u5199\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6316\u6398\u7b56\u7565\u3001\u6df7\u5408\u8bad\u7ec3\u8303\u5f0f\u548c\u5e76\u884c\u90e8\u7f72\u67b6\u6784\uff0c\u89e3\u51b3\u89c6\u9891\u641c\u7d22\u4e2d\u7684\u4e2a\u6027\u5316\u67e5\u8be2\u91cd\u5199\u95ee\u9898\u3002", "motivation": "\u89c6\u9891\u641c\u7d22\u7cfb\u7edf\u4e2d\uff0c\u7528\u6237\u5386\u53f2\u884c\u4e3a\u4e3a\u8bc6\u522b\u641c\u7d22\u610f\u56fe\u548c\u6d88\u9664\u6b67\u4e49\u63d0\u4f9b\u4e86\u4e30\u5bcc\u4e0a\u4e0b\u6587\uff0c\u4f46\u4f20\u7edf\u4f7f\u7528\u9690\u5f0f\u5386\u53f2\u7279\u5f81\u7684\u65b9\u6cd5\u5b58\u5728\u4fe1\u53f7\u7a00\u91ca\u548c\u53cd\u9988\u5ef6\u8fdf\u7684\u95ee\u9898\u3002", "method": "1) \u4f55\u65f6\u91cd\u5199\uff1a\u57fa\u4e8e\u540e\u9a8c\u7684\u81ea\u52a8\u5316\u6316\u6398\u7b56\u7565\u4ece\u7528\u6237\u65e5\u5fd7\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u8bc6\u522b\u4e25\u683c\u9700\u8981\u4e2a\u6027\u5316\u7684\u573a\u666f\uff1b2) \u5982\u4f55\u91cd\u5199\uff1a\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u7684\u6df7\u5408\u8bad\u7ec3\u8303\u5f0f\uff0c\u4f7fLLM\u8f93\u51fa\u98ce\u683c\u4e0e\u68c0\u7d22\u7cfb\u7edf\u5bf9\u9f50\uff1b3) \u90e8\u7f72\uff1a\u91c7\u7528\u5e76\u884c\"\u4f2a\u53ec\u56de\"\u67b6\u6784\u786e\u4fdd\u4f4e\u5ef6\u8fdf\u3002", "result": "\u5728\u5927\u89c4\u6a21\u89c6\u9891\u5e73\u53f0\u4e0a\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff0cWeWrite\u5c06\u70b9\u51fb\u89c2\u770b\u89c6\u9891\u91cf\uff08VV>10s\uff09\u63d0\u5347\u4e861.07%\uff0c\u5e76\u5c06\u67e5\u8be2\u91cd\u6784\u7387\u964d\u4f4e\u4e862.97%\u3002", "conclusion": "WeWrite\u901a\u8fc7\u89e3\u51b3\u4e2a\u6027\u5316\u67e5\u8be2\u91cd\u5199\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u6709\u6548\u63d0\u5347\u4e86\u89c6\u9891\u641c\u7d22\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.17907", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17907", "abs": "https://arxiv.org/abs/2602.17907", "authors": ["Raymond Li", "Amirhossein Abaskohi", "Chuyuan Li", "Gabriel Murray", "Giuseppe Carenini"], "title": "Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions", "comment": "20 pages, 5 figures", "summary": "Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u4e49\u8f6f\u6807\u7b7e\u76ee\u6807\u6765\u8bad\u7ec3\u795e\u7ecf\u4e3b\u9898\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e3b\u9898\u8d28\u91cf\u548c\u6587\u6863\u68c0\u7d22\u6548\u679c", "motivation": "\u4f20\u7edf\u795e\u7ecf\u4e3b\u9898\u6a21\u578b\u901a\u5e38\u901a\u8fc7\u91cd\u6784\u6587\u6863\u7684\u8bcd\u888b\u8868\u793a\u8fdb\u884c\u4f18\u5316\uff0c\u5ffd\u7565\u4e86\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4e14\u5728\u5904\u7406\u6570\u636e\u7a00\u758f\u6027\u65b9\u9762\u5b58\u5728\u56f0\u96be", "method": "\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u4e49\u8f6f\u6807\u7b7e\u76ee\u6807\uff1a\u4f7f\u7528\u4e13\u95e8\u8bbe\u8ba1\u7684\u63d0\u793a\uff0c\u5c06\u4e0b\u4e00\u4e2a\u8bcd\u6982\u7387\u6295\u5f71\u5230\u9884\u5b9a\u4e49\u8bcd\u6c47\u8868\u4e0a\uff0c\u83b7\u5f97\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u76d1\u7763\u4fe1\u53f7\u3002\u7136\u540e\u8bad\u7ec3\u4e3b\u9898\u6a21\u578b\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u9690\u85cf\u72b6\u6001\u6765\u91cd\u6784\u8fd9\u4e9b\u8f6f\u6807\u7b7e", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e3b\u9898\u8fde\u8d2f\u6027\u548c\u7eaf\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002\u65b0\u5f15\u5165\u7684\u68c0\u7d22\u6307\u6807\u4e5f\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u8bc6\u522b\u8bed\u4e49\u76f8\u4f3c\u6587\u6863\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u4e49\u8f6f\u6807\u7b7e\u4e3a\u795e\u7ecf\u4e3b\u9898\u6a21\u578b\u63d0\u4f9b\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u80fd\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u3001\u66f4\u7b26\u5408\u8bed\u6599\u4e3b\u9898\u7ed3\u6784\u7684\u4e3b\u9898\uff0c\u7279\u522b\u9002\u7528\u4e8e\u68c0\u7d22\u5bfc\u5411\u7684\u5e94\u7528"}}
{"id": "2602.17687", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17687", "abs": "https://arxiv.org/abs/2602.17687", "authors": ["Connor Shorten", "Augustas Skaburskas", "Daniel M. Jones", "Charles Pierse", "Roberto Esposito", "John Trengrove", "Etienne Dilocker", "Bob van Luijt"], "title": "IRPAPERS: A Visual Document Benchmark for Scientific Retrieval and Question Answering", "comment": "23 pages, 6 figures", "summary": "AI systems have achieved remarkable success in processing text and relational data, yet visual document processing remains relatively underexplored. Whereas traditional systems require OCR transcriptions to convert these visual documents into text and metadata, recent advances in multimodal foundation models offer retrieval and generation directly from document images. This raises a key question: How do image-based systems compare to established text-based methods? We introduce IRPAPERS, a benchmark of 3,230 pages from 166 scientific papers, with both an image and an OCR transcription for each page. Using 180 needle-in-the-haystack questions, we compare image- and text-based retrieval and question answering systems. Text retrieval using Arctic 2.0 embeddings, BM25, and hybrid text search achieved 46% Recall@1, 78% Recall@5, and 91% Recall@20, while image-based retrieval reaches 43%, 78%, and 93%, respectively. The two modalities exhibit complementary failures, enabling multimodal hybrid search to outperform either alone, achieving 49% Recall@1, 81% Recall@5, and 95% Recall@20. We further evaluate efficiency-performance tradeoffs with MUVERA and assess multiple multi-vector image embedding models. Among closed-source models, Cohere Embed v4 page image embeddings outperform Voyage 3 Large text embeddings and all tested open-source models, achieving 58% Recall@1, 87% Recall@5, and 97% Recall@20. For question answering, text-based RAG systems achieved higher ground-truth alignment than image-based systems (0.82 vs. 0.71), and both benefit substantially from increased retrieval depth, with multi-document retrieval outperforming oracle single-document retrieval. We analyze the complementary limitations of unimodal text and image representations and identify question types that require one modality over the other. The IRPAPERS dataset and all experimental code are publicly available.", "AI": {"tldr": "IRPAPERS\u662f\u4e00\u4e2a\u5305\u542b3,230\u9875\u79d1\u5b66\u8bba\u6587\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6bd4\u8f83\u57fa\u4e8e\u56fe\u50cf\u548c\u57fa\u4e8e\u6587\u672c\u7684\u6587\u6863\u68c0\u7d22\u4e0e\u95ee\u7b54\u7cfb\u7edf\u3002\u7814\u7a76\u53d1\u73b0\u4e24\u79cd\u6a21\u6001\u5177\u6709\u4e92\u8865\u6027\uff0c\u591a\u6a21\u6001\u6df7\u5408\u68c0\u7d22\u4f18\u4e8e\u5355\u4e00\u6a21\u6001\uff0c\u4e14\u5c01\u95ed\u6e90\u56fe\u50cf\u5d4c\u5165\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u6587\u672c\u548c\u5173\u7cfb\u6570\u636e\u5904\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u89c6\u89c9\u6587\u6863\u5904\u7406\u4ecd\u76f8\u5bf9\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u4f20\u7edf\u7cfb\u7edf\u9700\u8981OCR\u8f6c\u5f55\u5c06\u89c6\u89c9\u6587\u6863\u8f6c\u6362\u4e3a\u6587\u672c\u548c\u5143\u6570\u636e\uff0c\u800c\u6700\u8fd1\u7684\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u76f4\u63a5\u4ece\u6587\u6863\u56fe\u50cf\u8fdb\u884c\u68c0\u7d22\u548c\u751f\u6210\u7684\u80fd\u529b\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u57fa\u4e8e\u56fe\u50cf\u7684\u7cfb\u7edf\u4e0e\u6210\u719f\u7684\u57fa\u4e8e\u6587\u672c\u65b9\u6cd5\u76f8\u6bd4\u5982\u4f55\uff1f", "method": "\u5f15\u5165IRPAPERS\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b166\u7bc7\u79d1\u5b66\u8bba\u6587\u76843,230\u9875\uff0c\u6bcf\u9875\u90fd\u6709\u56fe\u50cf\u548cOCR\u8f6c\u5f55\u3002\u4f7f\u7528180\u4e2a\"\u5927\u6d77\u635e\u9488\"\u5f0f\u95ee\u9898\uff0c\u6bd4\u8f83\u57fa\u4e8e\u56fe\u50cf\u548c\u57fa\u4e8e\u6587\u672c\u7684\u68c0\u7d22\u4e0e\u95ee\u7b54\u7cfb\u7edf\u3002\u8bc4\u4f30\u4e86\u591a\u79cd\u68c0\u7d22\u65b9\u6cd5\uff1a\u6587\u672c\u68c0\u7d22\u4f7f\u7528Arctic 2.0\u5d4c\u5165\u3001BM25\u548c\u6df7\u5408\u6587\u672c\u641c\u7d22\uff1b\u56fe\u50cf\u68c0\u7d22\u4f7f\u7528\u591a\u5411\u91cf\u56fe\u50cf\u5d4c\u5165\u6a21\u578b\uff1b\u4ee5\u53ca\u591a\u6a21\u6001\u6df7\u5408\u641c\u7d22\u3002\u8fd8\u8bc4\u4f30\u4e86\u6548\u7387-\u6027\u80fd\u6743\u8861\u548c\u591a\u4e2a\u95ee\u7b54\u7cfb\u7edf\u3002", "result": "\u6587\u672c\u68c0\u7d22\u8fbe\u523046% Recall@1\u300178% Recall@5\u548c91% Recall@20\uff0c\u56fe\u50cf\u68c0\u7d22\u8fbe\u523043%\u300178%\u548c93%\u3002\u4e24\u79cd\u6a21\u6001\u8868\u73b0\u51fa\u4e92\u8865\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u4f7f\u591a\u6a21\u6001\u6df7\u5408\u641c\u7d22\u4f18\u4e8e\u4efb\u4e00\u5355\u72ec\u6a21\u6001\uff0c\u8fbe\u523049% Recall@1\u300181% Recall@5\u548c95% Recall@20\u3002\u5c01\u95ed\u6e90\u6a21\u578b\u4e2d\uff0cCohere Embed v4\u9875\u9762\u56fe\u50cf\u5d4c\u5165\u4f18\u4e8eVoyage 3 Large\u6587\u672c\u5d4c\u5165\u548c\u6240\u6709\u5f00\u6e90\u6a21\u578b\uff0c\u8fbe\u523058% Recall@1\u300187% Recall@5\u548c97% Recall@20\u3002\u5728\u95ee\u7b54\u65b9\u9762\uff0c\u57fa\u4e8e\u6587\u672c\u7684RAG\u7cfb\u7edf\u6bd4\u57fa\u4e8e\u56fe\u50cf\u7684\u7cfb\u7edf\u5177\u6709\u66f4\u9ad8\u7684\u771f\u5b9e\u5bf9\u9f50\u5ea6\uff080.82 vs. 0.71\uff09\uff0c\u4e14\u4e24\u8005\u90fd\u4ece\u589e\u52a0\u68c0\u7d22\u6df1\u5ea6\u4e2d\u53d7\u76ca\u663e\u8457\u3002", "conclusion": "\u57fa\u4e8e\u56fe\u50cf\u548c\u57fa\u4e8e\u6587\u672c\u7684\u6587\u6863\u5904\u7406\u7cfb\u7edf\u5404\u6709\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5b83\u4eec\u5177\u6709\u4e92\u8865\u6027\u3002\u591a\u6a21\u6001\u6df7\u5408\u65b9\u6cd5\u80fd\u591f\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u52bf\uff0c\u5728\u6587\u6863\u68c0\u7d22\u4efb\u52a1\u4e0a\u8868\u73b0\u6700\u4f73\u3002\u5c01\u95ed\u6e90\u56fe\u50cf\u5d4c\u5165\u6a21\u578b\u5728\u68c0\u7d22\u6027\u80fd\u4e0a\u9886\u5148\u3002\u7814\u7a76\u8fd8\u8bc6\u522b\u4e86\u9700\u8981\u7279\u5b9a\u6a21\u6001\u7684\u95ee\u9898\u7c7b\u578b\uff0c\u4e3a\u672a\u6765\u89c6\u89c9\u6587\u6863\u5904\u7406\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002IRPAPERS\u6570\u636e\u96c6\u548c\u5b9e\u9a8c\u4ee3\u7801\u5df2\u516c\u5f00\u63d0\u4f9b\u3002"}}
{"id": "2602.17911", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17911", "abs": "https://arxiv.org/abs/2602.17911", "authors": ["Jash Rajesh Parekh", "Wonbin Kweon", "Joey Chan", "Rezarta Islamaj", "Robert Leaman", "Pengcheng Jiang", "Chih-Hsuan Wei", "Zhizheng Wang", "Zhiyong Lu", "Jiawei Han"], "title": "Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering", "comment": null, "summary": "Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u6761\u4ef6\u6027\u751f\u7269\u533b\u5b66\u95ee\u7b54\u57fa\u51c6CondMedQA\u548c\u6761\u4ef6\u95e8\u63a7\u63a8\u7406\u6846\u67b6CGR\uff0c\u7528\u4e8e\u5904\u7406\u60a3\u8005\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u4e34\u5e8a\u63a8\u7406", "motivation": "\u5f53\u524d\u751f\u7269\u533b\u5b66QA\u7cfb\u7edf\u5047\u8bbe\u533b\u5b66\u77e5\u8bc6\u666e\u904d\u9002\u7528\uff0c\u4f46\u771f\u5b9e\u4e34\u5e8a\u63a8\u7406\u672c\u8d28\u4e0a\u662f\u6761\u4ef6\u6027\u7684\uff0c\u6bcf\u4e2a\u51b3\u7b56\u90fd\u4f9d\u8d56\u4e8e\u60a3\u8005\u7279\u5b9a\u56e0\u7d20\u3002\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u8bc4\u4f30\u8fd9\u79cd\u6761\u4ef6\u63a8\u7406\uff0c\u68c0\u7d22\u589e\u5f3a\u6216\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u7f3a\u4e4f\u786e\u4fdd\u68c0\u7d22\u77e5\u8bc6\u9002\u7528\u4e8e\u7ed9\u5b9a\u4e0a\u4e0b\u6587\u7684\u663e\u5f0f\u673a\u5236", "method": "\u63d0\u51faCondMedQA\u57fa\u51c6\uff08\u5305\u542b\u591a\u8df3\u95ee\u9898\uff0c\u7b54\u6848\u968f\u60a3\u8005\u6761\u4ef6\u53d8\u5316\uff09\u548cCondition-Gated Reasoning (CGR)\u6846\u67b6\uff0c\u6784\u5efa\u6761\u4ef6\u611f\u77e5\u77e5\u8bc6\u56fe\uff0c\u57fa\u4e8e\u67e5\u8be2\u6761\u4ef6\u9009\u62e9\u6027\u6fc0\u6d3b\u6216\u4fee\u526a\u63a8\u7406\u8def\u5f84", "result": "CGR\u80fd\u66f4\u53ef\u9760\u5730\u9009\u62e9\u6761\u4ef6\u9002\u5f53\u7684\u7b54\u6848\uff0c\u540c\u65f6\u5728\u751f\u7269\u533b\u5b66QA\u57fa\u51c6\u4e0a\u8fbe\u5230\u6216\u8d85\u8fc7\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7a81\u663e\u4e86\u663e\u5f0f\u5efa\u6a21\u6761\u4ef6\u6027\u5bf9\u7a33\u5065\u533b\u5b66\u63a8\u7406\u7684\u91cd\u8981\u6027", "conclusion": "\u6761\u4ef6\u6027\u5efa\u6a21\u662f\u751f\u7269\u533b\u5b66QA\u7cfb\u7edf\u7684\u91cd\u8981\u65b9\u5411\uff0cCGR\u6846\u67b6\u4e3a\u89e3\u51b3\u4e34\u5e8a\u63a8\u7406\u4e2d\u7684\u6761\u4ef6\u4f9d\u8d56\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848"}}
{"id": "2602.17856", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17856", "abs": "https://arxiv.org/abs/2602.17856", "authors": ["Hamideh Ghanadian", "Amin Kamali", "Mohammad Hossein Tekieh"], "title": "Enhancing Scientific Literature Chatbots with Retrieval-Augmented Generation: A Performance Evaluation of Vector and Graph-Based Systems", "comment": null, "summary": "This paper investigates the enhancement of scientific literature chatbots through retrieval-augmented generation (RAG), with a focus on evaluating vector- and graph-based retrieval systems. The proposed chatbot leverages both structured (graph) and unstructured (vector) databases to access scientific articles and gray literature, enabling efficient triage of sources according to research objectives. To systematically assess performance, we examine two use-case scenarios: retrieval from a single uploaded document and retrieval from a large-scale corpus. Benchmark test sets were generated using a GPT model, with selected outputs annotated for evaluation. The comparative analysis emphasizes retrieval accuracy and response relevance, providing insight into the strengths and limitations of each approach. The findings demonstrate the potential of hybrid RAG systems to improve accessibility to scientific knowledge and to support evidence-based decision making.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5411\u91cf\u548c\u56fe\u68c0\u7d22\u7684RAG\u7cfb\u7edf\u5728\u79d1\u5b66\u6587\u732e\u804a\u5929\u673a\u5668\u4eba\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u6df7\u5408\u68c0\u7d22\u7b56\u7565\u63d0\u5347\u79d1\u5b66\u77e5\u8bc6\u83b7\u53d6\u6548\u7387\u3002", "motivation": "\u79d1\u5b66\u6587\u732e\u6570\u91cf\u5e9e\u5927\u4e14\u5f62\u5f0f\u591a\u6837\uff08\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\uff09\uff0c\u4f20\u7edf\u68c0\u7d22\u65b9\u5f0f\u96be\u4ee5\u9ad8\u6548\u652f\u6301\u8bc1\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u3002\u9700\u8981\u63a2\u7d22\u66f4\u6709\u6548\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u79d1\u5b66\u77e5\u8bc6\u83b7\u53d6\u7684\u51c6\u786e\u6027\u548c\u76f8\u5173\u6027\u3002", "method": "\u6784\u5efa\u4e86\u7ed3\u5408\u56fe\u6570\u636e\u5e93\uff08\u7ed3\u6784\u5316\uff09\u548c\u5411\u91cf\u6570\u636e\u5e93\uff08\u975e\u7ed3\u6784\u5316\uff09\u7684\u6df7\u5408RAG\u7cfb\u7edf\u3002\u8bbe\u8ba1\u4e86\u4e24\u79cd\u4f7f\u7528\u573a\u666f\uff1a\u5355\u6587\u6863\u68c0\u7d22\u548c\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u68c0\u7d22\u3002\u4f7f\u7528GPT\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u5e76\u5bf9\u90e8\u5206\u8f93\u51fa\u8fdb\u884c\u4eba\u5de5\u6807\u6ce8\u8bc4\u4f30\u3002\u91cd\u70b9\u6bd4\u8f83\u68c0\u7d22\u51c6\u786e\u6027\u548c\u54cd\u5e94\u76f8\u5173\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\u6df7\u5408RAG\u7cfb\u7edf\u5728\u79d1\u5b66\u6587\u732e\u68c0\u7d22\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u6839\u636e\u7814\u7a76\u76ee\u6807\u9ad8\u6548\u7b5b\u9009\u8d44\u6e90\u3002\u5411\u91cf\u548c\u56fe\u68c0\u7d22\u5404\u6709\u4f18\u52bf\uff0c\u6df7\u5408\u65b9\u6cd5\u80fd\u4e92\u8865\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u6df7\u5408RAG\u7cfb\u7edf\u80fd\u663e\u8457\u6539\u5584\u79d1\u5b66\u77e5\u8bc6\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u652f\u6301\u57fa\u4e8e\u8bc1\u636e\u7684\u51b3\u7b56\u5236\u5b9a\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u68c0\u7d22\u7b56\u7565\uff0c\u63d0\u5347\u7cfb\u7edf\u5728\u590d\u6742\u79d1\u5b66\u67e5\u8be2\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2602.17937", "categories": ["cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.17937", "abs": "https://arxiv.org/abs/2602.17937", "authors": ["Xiaotang Du", "Giwon Hong", "Wai-Chung Kwan", "Rohit Saxena", "Ivan Titov", "Pasquale Minervini", "Emily Allaway"], "title": "Analyzing LLM Instruction Optimization for Tabular Fact Verification", "comment": null, "summary": "Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e86\u57fa\u4e8eDSPy\u4f18\u5316\u6846\u67b6\u7684\u6307\u4ee4\u4f18\u5316\u65b9\u6cd5\u5728\u8868\u683c\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6307\u4ee4\u4f18\u5316\u80fd\u6301\u7eed\u63d0\u5347\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u4e0d\u540c\u4f18\u5316\u5668\u5728\u4e0d\u540c\u63d0\u793a\u6280\u672f\u548c\u6a21\u578b\u89c4\u6a21\u4e0b\u5404\u6709\u4f18\u52bf\u3002", "motivation": "\u6307\u4ee4\u4f18\u5316\u4f5c\u4e3a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u6307\u4ee4\u4f18\u5316\u5728\u8868\u683c\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u7814\u7a76\u3002", "method": "\u57fa\u4e8eDSPy\u4f18\u5316\u6846\u67b6\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u5f00\u7bb1\u5373\u7528\u7684\u63d0\u793a\u6280\u672f\uff08\u76f4\u63a5\u9884\u6d4b\u3001\u601d\u7ef4\u94fe\u3001\u5e26SQL\u5de5\u5177\u7684ReAct\u3001\u5e26Python\u6267\u884c\u7684CodeAct\uff09\uff0c\u5e76\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e09\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e0a\u7814\u7a76\u4e86\u4e09\u79cdDSPy\u4f18\u5316\u5668\uff08COPRO\u3001MiPROv2\u3001SIMBA\uff09\u3002", "result": "\u6307\u4ee4\u4f18\u5316\u6301\u7eed\u63d0\u5347\u9a8c\u8bc1\u51c6\u786e\u7387\uff1aMiPROv2\u5728\u601d\u7ef4\u94fe\u4e2d\u8868\u73b0\u6700\u7a33\u5b9a\uff0cSIMBA\u5bf9ReAct\u667a\u80fd\u4f53\u63d0\u4f9b\u6700\u5927\u6536\u76ca\uff08\u5c24\u5176\u5728\u66f4\u5927\u6a21\u578b\u89c4\u6a21\u65f6\uff09\u3002\u884c\u4e3a\u5206\u6790\u663e\u793aSIMBA\u901a\u8fc7\u542f\u53d1\u5f0f\u65b9\u6cd5\u9f13\u52b1\u66f4\u76f4\u63a5\u7684\u63a8\u7406\u8def\u5f84\uff0c\u63d0\u5347\u601d\u7ef4\u94fe\u4e2d\u7684\u6570\u503c\u6bd4\u8f83\u80fd\u529b\uff0c\u5e76\u5e2e\u52a9ReAct\u667a\u80fd\u4f53\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5de5\u5177\u8c03\u7528\u3002", "conclusion": "\u601d\u7ef4\u94fe\u5728\u8868\u683c\u4e8b\u5b9e\u68c0\u67e5\u4e2d\u4fdd\u6301\u6709\u6548\uff08\u5c24\u5176\u5bf9\u5c0f\u6a21\u578b\uff09\uff0c\u800c\u57fa\u4e8e\u5927\u6a21\u578b\u7684ReAct\u667a\u80fd\u4f53\u867d\u80fd\u8fbe\u5230\u7ade\u4e89\u6027\u80fd\uff0c\u4f46\u9700\u8981\u4ed4\u7ec6\u7684\u6307\u4ee4\u4f18\u5316\u3002\u4e0d\u540c\u63d0\u793a\u6280\u672f\u4e2d\uff0c\u4f18\u5316\u5668\u7684\u9009\u62e9\u5e94\u8003\u8651\u6a21\u578b\u89c4\u6a21\u548c\u4efb\u52a1\u7279\u6027\u3002"}}
{"id": "2602.18107", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18107", "abs": "https://arxiv.org/abs/2602.18107", "authors": ["Andrew Parry", "Debasis Ganguly", "Sean MacAvaney"], "title": "SuiteEval: Simplifying Retrieval Benchmarks", "comment": "5 pages, 3 figures, 2 tables, Accepted as a Demonstration to ECIR 2026", "summary": "Information retrieval evaluation often suffers from fragmented practices -- varying dataset subsets, aggregation methods, and pipeline configurations -- that undermine reproducibility and comparability, especially for foundation embedding models requiring robust out-of-domain performance. We introduce SuiteEval, a unified framework that offers automatic end-to-end evaluation, dynamic indexing that reuses on-disk indices to minimise disk usage, and built-in support for major benchmarks (BEIR, LoTTE, MS MARCO, NanoBEIR, and BRIGHT). Users only need to supply a pipeline generator. SuiteEval handles data loading, indexing, ranking, metric computation, and result aggregation. New benchmark suites can be added in a single line. SuiteEval reduces boilerplate and standardises evaluations to facilitate reproducible IR research, as a broader benchmark set is increasingly required.", "AI": {"tldr": "SuiteEval\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u68c0\u7d22\u8bc4\u4f30\u6846\u67b6\uff0c\u63d0\u4f9b\u7aef\u5230\u7aef\u81ea\u52a8\u8bc4\u4f30\u3001\u52a8\u6001\u7d22\u5f15\u590d\u7528\u51cf\u5c11\u78c1\u76d8\u5360\u7528\uff0c\u5e76\u652f\u6301\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7b80\u5316IR\u7814\u7a76\u7684\u53ef\u590d\u73b0\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u4fe1\u606f\u68c0\u7d22\u8bc4\u4f30\u5b9e\u8df5\u788e\u7247\u5316\uff0c\u5b58\u5728\u6570\u636e\u96c6\u5b50\u96c6\u3001\u805a\u5408\u65b9\u6cd5\u3001\u6d41\u6c34\u7ebf\u914d\u7f6e\u7b49\u65b9\u9762\u7684\u4e0d\u4e00\u81f4\uff0c\u635f\u5bb3\u4e86\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6bd4\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9700\u8981\u5728\u9886\u57df\u5916\u6709\u7a33\u5065\u6027\u80fd\u7684\u57fa\u7840\u5d4c\u5165\u6a21\u578b\u3002", "method": "\u63d0\u51faSuiteEval\u6846\u67b6\uff0c\u63d0\u4f9b\u81ea\u52a8\u7aef\u5230\u7aef\u8bc4\u4f30\u3001\u52a8\u6001\u7d22\u5f15\u590d\u7528\u78c1\u76d8\u7d22\u5f15\u4ee5\u6700\u5c0f\u5316\u78c1\u76d8\u4f7f\u7528\uff0c\u5185\u7f6e\u5bf9BEIR\u3001LoTTE\u3001MS MARCO\u3001NanoBEIR\u548cBRIGHT\u7b49\u4e3b\u8981\u57fa\u51c6\u7684\u652f\u6301\u3002\u7528\u6237\u53ea\u9700\u63d0\u4f9b\u6d41\u6c34\u7ebf\u751f\u6210\u5668\uff0c\u6846\u67b6\u5904\u7406\u6570\u636e\u52a0\u8f7d\u3001\u7d22\u5f15\u3001\u6392\u5e8f\u3001\u6307\u6807\u8ba1\u7b97\u548c\u7ed3\u679c\u805a\u5408\u3002", "result": "SuiteEval\u51cf\u5c11\u4e86\u6837\u677f\u4ee3\u7801\uff0c\u6807\u51c6\u5316\u4e86\u8bc4\u4f30\u6d41\u7a0b\uff0c\u4fc3\u8fdb\u4e86\u53ef\u590d\u73b0\u7684IR\u7814\u7a76\uff0c\u7279\u522b\u662f\u968f\u7740\u9700\u8981\u66f4\u5e7f\u6cdb\u57fa\u51c6\u96c6\u5408\u7684\u8d8b\u52bf\u3002", "conclusion": "SuiteEval\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u89e3\u51b3\u4e86IR\u8bc4\u4f30\u788e\u7247\u5316\u95ee\u9898\uff0c\u7b80\u5316\u4e86\u8bc4\u4f30\u6d41\u7a0b\uff0c\u63d0\u5347\u4e86\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6bd4\u6027\u3002"}}
{"id": "2602.17949", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17949", "abs": "https://arxiv.org/abs/2602.17949", "authors": ["Victoria Blake", "Mathew Miller", "Jamie Novak", "Sze-yuan Ooi", "Blanca Gallego"], "title": "CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications", "comment": "30 pages, 6 figures, 4 tables", "summary": "Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.", "AI": {"tldr": "CUICurate\u662f\u4e00\u4e2a\u57fa\u4e8e\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316UMLS\u6982\u5ff5\u96c6\u6784\u5efa\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u548cLLM\u8fc7\u6ee4\u5206\u7c7b\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u5e76\u63d0\u5347\u6982\u5ff5\u96c6\u5b8c\u6574\u6027\u3002", "motivation": "\u4e34\u5e8a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u5de5\u5177\u901a\u5e38\u5c06\u81ea\u7531\u6587\u672c\u6620\u5c04\u5230UMLS\u6982\u5ff5\u552f\u4e00\u6807\u8bc6\u7b26\uff08CUI\uff09\uff0c\u4f46\u8bb8\u591a\u4e0b\u6e38\u4efb\u52a1\u9700\u8981\u7684\u662f\u5305\u542b\u76f8\u5173\u540c\u4e49\u8bcd\u3001\u5b50\u7c7b\u578b\u548c\u8d85\u7c7b\u578b\u7684\u6982\u5ff5\u96c6\u3002\u76ee\u524d\u6784\u5efa\u8fd9\u79cd\u6982\u5ff5\u96c6\u662f\u52b3\u52a8\u5bc6\u96c6\u578b\u7684\u3001\u6267\u884c\u4e0d\u4e00\u81f4\u7684\uff0c\u4e14\u73b0\u6709\u5de5\u5177\u652f\u6301\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u76f4\u63a5\u64cd\u4f5cUMLS CUI\u7684NLP\u6d41\u6c34\u7ebf\u3002", "method": "\u63d0\u51faCUICurate\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff1a1\uff09\u6784\u5efaUMLS\u77e5\u8bc6\u56fe\u8c31\u5e76\u8fdb\u884c\u5d4c\u5165\u7528\u4e8e\u8bed\u4e49\u68c0\u7d22\uff1b2\uff09\u5bf9\u6bcf\u4e2a\u76ee\u6807\u6982\u5ff5\uff0c\u4ece\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u5019\u9009CUI\uff1b3\uff09\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8fc7\u6ee4\u548c\u5206\u7c7b\uff0c\u6bd4\u8f83\u4e86GPT-5\u548cGPT-5-mini\u4e24\u79cd\u6a21\u578b\u3002", "result": "\u5728\u4e94\u4e2a\u8bcd\u6c47\u5f02\u8d28\u6027\u4e34\u5e8a\u6982\u5ff5\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff1aCUICurate\u751f\u6210\u7684\u6982\u5ff5\u96c6\u6bd4\u4eba\u5de5\u57fa\u51c6\u96c6\u66f4\u5927\u3001\u66f4\u5b8c\u6574\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u4eba\u7c7b\u76f8\u5f53\u7684\u7cbe\u786e\u5ea6\u3002GPT-5-mini\u5728\u8fc7\u6ee4\u9636\u6bb5\u53ec\u56de\u7387\u66f4\u9ad8\uff0c\u800cGPT-5\u7684\u5206\u7c7b\u7ed3\u679c\u66f4\u7b26\u5408\u4e34\u5e8a\u533b\u751f\u5224\u65ad\u3002\u8f93\u51fa\u5728\u91cd\u590d\u8fd0\u884c\u4e2d\u7a33\u5b9a\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "conclusion": "CUICurate\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u91cd\u590d\u7684\u65b9\u6cd5\u6765\u652f\u6301UMLS\u6982\u5ff5\u96c6\u6784\u5efa\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002\u901a\u8fc7\u6574\u5408\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u548cLLM\u63a8\u7406\uff0c\u8be5\u6846\u67b6\u751f\u6210\u805a\u7126\u7684\u5019\u9009\u6982\u5ff5\u96c6\uff0c\u53ef\u9002\u5e94\u4e0d\u540c\u8868\u578b\u548c\u5206\u6790\u9700\u6c42\u7684\u4e34\u5e8aNLP\u6d41\u6c34\u7ebf\u3002"}}
{"id": "2602.18206", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18206", "abs": "https://arxiv.org/abs/2602.18206", "authors": ["Jiayi Wu", "Zhengyu Wu", "Xunkai Li", "Ronghua Li", "Guoren Wang"], "title": "A Simple yet Effective Negative Sampling Plugin for Constructing Positive Sample Pairs in Implicit Collaborative Filtering", "comment": null, "summary": "Most implicit collaborative filtering (CF) models are trained with negative sampling, where existing work designs sophisticated strategies for high-quality negatives while largely overlooking the exploration of positive samples. Although some denoising recommendation methods can be applied to implicit CF for denoising positive samples, they often sparsify positive supervision. Moreover, these approaches generally overlook user activity bias during training, leading to insufficient learning for inactive users. To address these issues, we propose a simple yet effective negative sampling plugin, PSP-NS, from the perspective of enhancing positive supervision signals. It builds a user-item bipartite graph with edge weights indicating interaction confidence inferred from global and local patterns, generates positive sample pairs via replication-based reweighting to strengthen positive signals, and adopts an activity-aware weighting scheme to effectively learn inactive users' preferences. We provide theoretical insights from a margin-improvement perspective, explaining why PSP-NS tends to improve ranking quality (e.g., Precision@k/Recall@k), and conduct extensive experiments on four real-world datasets to demonstrate its superiority. For instance, PSP-NS boosts Recall@30 and Precision@30 by 32.11% and 22.90% on Yelp over the strongest baselines. PSP-NS can be integrated with various implicit CF recommenders or negative sampling methods to enhance their performance.", "AI": {"tldr": "PSP-NS\u662f\u4e00\u4e2a\u7528\u4e8e\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u7684\u8d1f\u91c7\u6837\u63d2\u4ef6\uff0c\u901a\u8fc7\u589e\u5f3a\u6b63\u6837\u672c\u76d1\u7763\u4fe1\u53f7\u548c\u6d3b\u52a8\u611f\u77e5\u52a0\u6743\u6765\u63d0\u5347\u63a8\u8350\u6027\u80fd", "motivation": "\u73b0\u6709\u9690\u5f0fCF\u6a21\u578b\u5927\u591a\u5173\u6ce8\u9ad8\u8d28\u91cf\u7684\u8d1f\u6837\u672c\u8bbe\u8ba1\uff0c\u4f46\u5ffd\u89c6\u4e86\u6b63\u6837\u672c\u7684\u63a2\u7d22\u3002\u73b0\u6709\u53bb\u566a\u63a8\u8350\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u7528\u4e8e\u9690\u5f0fCF\u7684\u6b63\u6837\u672c\u53bb\u566a\uff0c\u4f46\u5f80\u5f80\u4f1a\u7a00\u758f\u5316\u6b63\u76d1\u7763\u4fe1\u53f7\uff0c\u5e76\u4e14\u901a\u5e38\u5ffd\u7565\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7528\u6237\u6d3b\u52a8\u504f\u5dee\uff0c\u5bfc\u81f4\u4e0d\u6d3b\u8dc3\u7528\u6237\u5b66\u4e60\u4e0d\u8db3\u3002", "method": "\u63d0\u51faPSP-NS\u8d1f\u91c7\u6837\u63d2\u4ef6\uff1a1\uff09\u6784\u5efa\u7528\u6237-\u7269\u54c1\u4e8c\u90e8\u56fe\uff0c\u8fb9\u6743\u91cd\u8868\u793a\u4ece\u5168\u5c40\u548c\u5c40\u90e8\u6a21\u5f0f\u63a8\u65ad\u7684\u4ea4\u4e92\u7f6e\u4fe1\u5ea6\uff1b2\uff09\u901a\u8fc7\u57fa\u4e8e\u590d\u5236\u7684\u91cd\u52a0\u6743\u751f\u6210\u6b63\u6837\u672c\u5bf9\u4ee5\u589e\u5f3a\u6b63\u4fe1\u53f7\uff1b3\uff09\u91c7\u7528\u6d3b\u52a8\u611f\u77e5\u52a0\u6743\u65b9\u6848\u6709\u6548\u5b66\u4e60\u4e0d\u6d3b\u8dc3\u7528\u6237\u7684\u504f\u597d\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u3002\u4f8b\u5982\u5728Yelp\u6570\u636e\u96c6\u4e0a\uff0cPSP-NS\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u5347\u4e86Recall@30 32.11%\u548cPrecision@30 22.90%\u3002\u8be5\u63d2\u4ef6\u53ef\u4ee5\u4e0e\u5404\u79cd\u9690\u5f0fCF\u63a8\u8350\u5668\u6216\u8d1f\u91c7\u6837\u65b9\u6cd5\u96c6\u6210\u4ee5\u589e\u5f3a\u6027\u80fd\u3002", "conclusion": "PSP-NS\u662f\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u8d1f\u91c7\u6837\u63d2\u4ef6\uff0c\u901a\u8fc7\u589e\u5f3a\u6b63\u76d1\u7763\u4fe1\u53f7\u548c\u6d3b\u52a8\u611f\u77e5\u52a0\u6743\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u6b63\u6837\u672c\u63a2\u7d22\u548c\u7528\u6237\u6d3b\u52a8\u504f\u5dee\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6392\u540d\u8d28\u91cf\u3002"}}
{"id": "2602.17981", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17981", "abs": "https://arxiv.org/abs/2602.17981", "authors": ["Amine Kobeissi", "Philippe Langlais"], "title": "Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering", "comment": null, "summary": "Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u91d1\u878d\u95ee\u7b54\u4e2d\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e86\u9488\u5bf9\u8d22\u52a1\u62a5\u544a\u9875\u9762\u7ea7\u68c0\u7d22\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9875\u9762\u548c\u5757\u7ea7\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u5728\u91d1\u878d\u76d1\u7ba1\u6587\u4ef6\u95ee\u7b54\u4e2d\u5b58\u5728\u9891\u7e41\u5931\u8d25\u6a21\u5f0f\uff1a\u867d\u7136\u68c0\u7d22\u5230\u4e86\u6b63\u786e\u6587\u6863\uff0c\u4f46\u9519\u8fc7\u4e86\u5305\u542b\u7b54\u6848\u7684\u5177\u4f53\u9875\u9762\u6216\u5757\uff0c\u5bfc\u81f4\u751f\u6210\u5668\u57fa\u4e8e\u4e0d\u5b8c\u6574\u4e0a\u4e0b\u6587\u8fdb\u884c\u63a8\u65ad\u3002\u8fd9\u79cd\u6587\u6863\u5185\u68c0\u7d22\u5931\u8d25\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5f88\u4e25\u91cd\uff0c\u4f46\u5728\u91d1\u878d\u95ee\u7b54\u6587\u732e\u4e2d\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\u3002", "method": "1) \u5728\u591a\u7c92\u5ea6\u7ea7\u522b\u8bc4\u4f30\u68c0\u7d22\u6027\u80fd\uff08\u6587\u6863\u3001\u9875\u9762\u3001\u5757\u7ea7\uff09\uff1b2) \u5f15\u5165\u57fa\u4e8eoracle\u7684\u5206\u6790\u63d0\u4f9b\u68c0\u7d22\u548c\u751f\u6210\u6027\u80fd\u7684\u5b9e\u8bc1\u4e0a\u9650\uff1b3) \u5728FinanceBench\u7684150\u4e2a\u95ee\u9898\u4e0a\u6bd4\u8f83\u591a\u79cd\u68c0\u7d22\u7b56\u7565\uff08\u7a20\u5bc6\u3001\u7a00\u758f\u3001\u6df7\u5408\u3001\u5206\u5c42\u68c0\u7d22\uff0c\u914d\u5408\u91cd\u6392\u5e8f\u548c\u67e5\u8be2\u91cd\u6784\uff09\uff1b4) \u63d0\u51fa\u9886\u57df\u5fae\u8c03\u7684\u9875\u9762\u8bc4\u5206\u5668\uff0c\u5c06\u9875\u9762\u4f5c\u4e3a\u6587\u6863\u548c\u5757\u4e4b\u95f4\u7684\u4e2d\u95f4\u68c0\u7d22\u5355\u5143\uff0c\u4e13\u95e8\u4e3a\u8d22\u52a1\u62a5\u544a\u9875\u9762\u7ea7\u76f8\u5173\u6027\u5fae\u8c03\u53cc\u7f16\u7801\u5668\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u6587\u6863\u53d1\u73b0\u80fd\u529b\u7684\u63d0\u5347\u901a\u5e38\u80fd\u8f6c\u5316\u4e3a\u66f4\u5f3a\u7684\u9875\u9762\u53ec\u56de\u7387\uff0c\u4f46oracle\u6027\u80fd\u8868\u660e\u9875\u9762\u548c\u5757\u7ea7\u68c0\u7d22\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002\u63d0\u51fa\u7684\u9886\u57df\u5fae\u8c03\u9875\u9762\u8bc4\u5206\u5668\u5728\u9875\u9762\u53ec\u56de\u548c\u5757\u68c0\u7d22\u65b9\u9762\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u9488\u5bf9\u91d1\u878d\u76d1\u7ba1\u6587\u4ef6\u9875\u9762\u7ea7\u68c0\u7d22\u7684\u4e13\u95e8\u4f18\u5316\u80fd\u6709\u6548\u89e3\u51b3\u6587\u6863\u5185\u68c0\u7d22\u5931\u8d25\u95ee\u9898\uff0c\u63d0\u5347\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002\u9875\u9762\u4f5c\u4e3a\u8bed\u4e49\u8fde\u8d2f\u7684\u4e2d\u95f4\u68c0\u7d22\u5355\u5143\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u9886\u57df\u7279\u5b9a\u7684\u5fae\u8c03\u65b9\u6cd5\u80fd\u663e\u8457\u6539\u5584\u91d1\u878d\u95ee\u7b54\u6027\u80fd\u3002"}}
{"id": "2602.18221", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18221", "abs": "https://arxiv.org/abs/2602.18221", "authors": ["Teddy Lazebnik"], "title": "The Economical-Ecological Benefits of Matching Non-matching Socks", "comment": null, "summary": "Socks are produced and replaced at a massive scale, yet their paired use makes them unusually vulnerable to waste, as the loss of a single sock can strand usable wear-capacity and trigger premature replacement. In this study, we quantify the economic and ecological value of pairing non-matching \\say{orphan} socks, and the social cost that discourages this behaviour. We formalize sock ownership as a sequential decision problem under uncertainty in which socks wear out and disappear stochastically during laundering, while public exposure induces a person-specific mismatch penalty. We conducted an in-person study to estimate mismatch sensitivity and diversity preference, linking behavioural heterogeneity to optimal mixing strategies. Using these results and a computer simulation-based evaluation of interpretable pairing policies, we show that strict matching can appear resource-frugal largely because it generates many sockless days, whereas controlled tolerance for mismatch sustains service and reduces stranded capacity across loss regimes. This study establishes the feasibility of matching non-matching socks while outlining its limitations and challenges.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4e25\u683c\u914d\u5bf9\u889c\u5b50\u4f1a\u6d6a\u8d39\u8d44\u6e90\uff0c\u800c\u5bb9\u5fcd\u4e0d\u5339\u914d\u7684\u889c\u5b50\u914d\u5bf9\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u6d6a\u8d39\u5e76\u7ef4\u6301\u4f7f\u7528\u3002", "motivation": "\u889c\u5b50\u4f5c\u4e3a\u6210\u5bf9\u4f7f\u7528\u7684\u7269\u54c1\uff0c\u5355\u53ea\u4e22\u5931\u4f1a\u5bfc\u81f4\u53e6\u4e00\u53ea\u88ab\u95f2\u7f6e\u5e76\u89e6\u53d1\u8fc7\u65e9\u66f4\u6362\uff0c\u9020\u6210\u5927\u91cf\u7ecf\u6d4e\u6d6a\u8d39\u548c\u751f\u6001\u5f71\u54cd\u3002\u7814\u7a76\u65e8\u5728\u91cf\u5316\"\u5b64\u513f\u889c\"\u914d\u5bf9\u7684\u7ecf\u6d4e\u548c\u751f\u6001\u4ef7\u503c\uff0c\u4ee5\u53ca\u963b\u788d\u8fd9\u79cd\u884c\u4e3a\u7684\u793e\u4f1a\u6210\u672c\u3002", "method": "\u5c06\u889c\u5b50\u6240\u6709\u6743\u5efa\u6a21\u4e3a\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u7684\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u8003\u8651\u6d17\u6da4\u8fc7\u7a0b\u4e2d\u7684\u968f\u673a\u78e8\u635f\u548c\u4e22\u5931\uff0c\u4ee5\u53ca\u516c\u5171\u573a\u5408\u66b4\u9732\u5e26\u6765\u7684\u4e2a\u4eba\u7279\u5b9a\u4e0d\u5339\u914d\u60e9\u7f5a\u3002\u901a\u8fc7\u73b0\u573a\u7814\u7a76\u4f30\u8ba1\u4e0d\u5339\u914d\u654f\u611f\u6027\u548c\u591a\u6837\u6027\u504f\u597d\uff0c\u5c06\u884c\u4e3a\u5f02\u8d28\u6027\u4e0e\u6700\u4f18\u914d\u5bf9\u7b56\u7565\u8054\u7cfb\u8d77\u6765\u3002\u4f7f\u7528\u8ba1\u7b97\u673a\u6a21\u62df\u8bc4\u4f30\u53ef\u89e3\u91ca\u7684\u914d\u5bf9\u7b56\u7565\u3002", "result": "\u4e25\u683c\u914d\u5bf9\u889c\u5b50\u8868\u9762\u4e0a\u770b\u4f3c\u8282\u7701\u8d44\u6e90\uff0c\u4f46\u5b9e\u9645\u4e0a\u662f\u56e0\u4e3a\u4ea7\u751f\u4e86\u8bb8\u591a\u65e0\u889c\u53ef\u7a7f\u7684\u65e5\u5b50\u3002\u800c\u6709\u63a7\u5236\u5730\u5bb9\u5fcd\u4e0d\u5339\u914d\u7684\u889c\u5b50\u914d\u5bf9\u53ef\u4ee5\u7ef4\u6301\u889c\u5b50\u670d\u52a1\u529f\u80fd\uff0c\u5e76\u5728\u5404\u79cd\u4e22\u5931\u60c5\u51b5\u4e0b\u51cf\u5c11\u95f2\u7f6e\u5bb9\u91cf\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u914d\u5bf9\u4e0d\u5339\u914d\u889c\u5b50\u7684\u53ef\u884c\u6027\uff0c\u540c\u65f6\u4e5f\u6307\u51fa\u4e86\u5176\u5c40\u9650\u6027\u548c\u6311\u6218\u3002\u901a\u8fc7\u5bb9\u5fcd\u4e00\u5b9a\u7684\u4e0d\u5339\u914d\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11\u6d6a\u8d39\u7684\u540c\u65f6\u7ef4\u6301\u889c\u5b50\u4f7f\u7528\u3002"}}
{"id": "2602.18029", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18029", "abs": "https://arxiv.org/abs/2602.18029", "authors": ["Ali El Filali", "In\u00e8s Bedar"], "title": "Towards More Standardized AI Evaluation: From Models to Agents", "comment": "19 pages, 3 figures", "summary": "Evaluation is no longer a final checkpoint in the machine learning lifecycle. As AI systems evolve from static models to compound, tool-using agents, evaluation becomes a core control function. The question is no longer \"How good is the model?\" but \"Can we trust the system to behave as intended, under change, at scale?\". Yet most evaluation practices remain anchored in assumptions inherited from the model-centric era: static benchmarks, aggregate scores, and one-off success criteria. This paper argues that such approaches are increasingly obscure rather than illuminating system behavior. We examine how evaluation pipelines themselves introduce silent failure modes, why high benchmark scores routinely mislead teams, and how agentic systems fundamentally alter the meaning of performance measurement. Rather than proposing new metrics or harder benchmarks, we aim to clarify the role of evaluation in the AI era, and especially for agents: not as performance theater, but as a measurement discipline that conditions trust, iteration, and governance in non-deterministic systems.", "AI": {"tldr": "\u8bc4\u4f30\u5728AI\u65f6\u4ee3\u5e94\u4ece\u9759\u6001\u6a21\u578b\u68c0\u67e5\u70b9\u8f6c\u53d8\u4e3a\u5bf9\u590d\u5408\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\u7684\u6301\u7eed\u63a7\u5236\u4e0e\u4fe1\u4efb\u6d4b\u91cf", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5b9e\u8df5\u4ecd\u505c\u7559\u5728\u6a21\u578b\u4e2d\u5fc3\u65f6\u4ee3\u7684\u9759\u6001\u57fa\u51c6\u3001\u805a\u5408\u5206\u6570\u548c\u4e00\u6b21\u6027\u6210\u529f\u6807\u51c6\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u73b0\u4ee3\u590d\u5408\u5de5\u5177\u4f7f\u7528\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u771f\u5b9e\u884c\u4e3a\uff0c\u5bfc\u81f4\u9ad8\u57fa\u51c6\u5206\u6570\u7ecf\u5e38\u8bef\u5bfc\u56e2\u961f\uff0c\u8bc4\u4f30\u7ba1\u9053\u672c\u8eab\u5f15\u5165\u9759\u9ed8\u6545\u969c\u6a21\u5f0f", "method": "\u901a\u8fc7\u5206\u6790\u8bc4\u4f30\u7ba1\u9053\u5982\u4f55\u5f15\u5165\u6545\u969c\u6a21\u5f0f\u3001\u63a2\u8ba8\u9ad8\u57fa\u51c6\u5206\u6570\u8bef\u5bfc\u6027\u539f\u56e0\u3001\u7814\u7a76\u667a\u80fd\u4f53\u7cfb\u7edf\u5982\u4f55\u6839\u672c\u6539\u53d8\u6027\u80fd\u6d4b\u91cf\u7684\u610f\u4e49\uff0c\u6765\u91cd\u65b0\u5b9a\u4e49\u8bc4\u4f30\u5728AI\u65f6\u4ee3\u7684\u4f5c\u7528", "result": "\u8bba\u8bc1\u4e86\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u8d8a\u6765\u8d8a\u6a21\u7cca\u800c\u975e\u6e05\u6670\uff0c\u9700\u8981\u5c06\u8bc4\u4f30\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6d4b\u91cf\u5b66\u79d1\uff0c\u4f5c\u4e3a\u4fe1\u4efb\u3001\u8fed\u4ee3\u548c\u6cbb\u7406\u975e\u786e\u5b9a\u6027\u7cfb\u7edf\u7684\u6761\u4ef6", "conclusion": "\u8bc4\u4f30\u4e0d\u5e94\u662f\u6027\u80fd\u5267\u573a\uff0c\u800c\u5e94\u6210\u4e3a\u6d4b\u91cf\u5b66\u79d1\uff0c\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4fe1\u4efb\u5efa\u7acb\u3001\u8fed\u4ee3\u6539\u8fdb\u548c\u6cbb\u7406\u63d0\u4f9b\u57fa\u7840\uff0c\u7279\u522b\u662f\u5728\u53d8\u5316\u548c\u89c4\u6a21\u5316\u6761\u4ef6\u4e0b\u786e\u4fdd\u7cfb\u7edf\u6309\u9884\u671f\u884c\u4e3a"}}
{"id": "2602.18249", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18249", "abs": "https://arxiv.org/abs/2602.18249", "authors": ["Jiayi Wu", "Zhengyu Wu", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "Dual-Tree LLM-Enhanced Negative Sampling for Implicit Collaborative Filtering", "comment": null, "summary": "Negative sampling is a pivotal technique in implicit collaborative filtering (CF) recommendation, enabling efficient and effective training by contrasting observed interactions with sampled unobserved ones.\n  Recently, large language models (LLMs) have shown promise in recommender systems; however, research on LLM-empowered negative sampling remains underexplored.\n  Existing methods heavily rely on textual information and task-specific fine-tuning, limiting practical applicability.\n  To address this limitation, we propose a text-free and fine-tuning-free Dual-Tree LLM-enhanced Negative Sampling method (DTL-NS).\n  It consists of two modules: (i) an offline false negative identification module that leverages hierarchical index trees to transform collaborative structural and latent semantic information into structured item-ID encodings for LLM inference, enabling accurate identification of false negatives; and (ii) a multi-view hard negative sampling module that combines user-item preference scores with item-item hierarchical similarities from these encodings to mine high-quality hard negatives, thus improving models' discriminative ability.\n  Extensive experiments demonstrate the effectiveness of DTL-NS. For example, on the Amazon-sports dataset, DTL-NS outperforms the strongest baseline by 10.64% and 19.12% in Recall@20 and NDCG@20, respectively.\n  Moreover, DTL-NS can be integrated into various implicit CF models and negative sampling methods, consistently enhancing their performance.", "AI": {"tldr": "DTL-NS\u662f\u4e00\u79cd\u65e0\u9700\u6587\u672c\u548c\u5fae\u8c03\u7684\u53cc\u6811LLM\u589e\u5f3a\u8d1f\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u7ebf\u5047\u8d1f\u6837\u672c\u8bc6\u522b\u548c\u591a\u89c6\u89d2\u786c\u8d1f\u91c7\u6837\u6a21\u5757\uff0c\u63d0\u5347\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u8d1f\u91c7\u6837\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u4fe1\u606f\u548c\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u65e0\u9700\u6587\u672c\u548c\u5fae\u8c03\u7684LLM\u589e\u5f3a\u8d1f\u91c7\u6837\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDTL-NS\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a1\uff09\u79bb\u7ebf\u5047\u8d1f\u6837\u672c\u8bc6\u522b\u6a21\u5757\uff0c\u5229\u7528\u5206\u5c42\u7d22\u5f15\u6811\u5c06\u534f\u540c\u7ed3\u6784\u548c\u6f5c\u5728\u8bed\u4e49\u4fe1\u606f\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9879\u76eeID\u7f16\u7801\u4f9bLLM\u63a8\u7406\uff1b2\uff09\u591a\u89c6\u89d2\u786c\u8d1f\u91c7\u6837\u6a21\u5757\uff0c\u7ed3\u5408\u7528\u6237-\u9879\u76ee\u504f\u597d\u5206\u6570\u548c\u9879\u76ee\u95f4\u5206\u5c42\u76f8\u4f3c\u6027\u6316\u6398\u9ad8\u8d28\u91cf\u786c\u8d1f\u6837\u672c\u3002", "result": "\u5728Amazon-sports\u6570\u636e\u96c6\u4e0a\uff0cDTL-NS\u5728Recall@20\u548cNDCG@20\u6307\u6807\u4e0a\u5206\u522b\u4f18\u4e8e\u6700\u5f3a\u57fa\u7ebf10.64%\u548c19.12%\u3002\u8be5\u65b9\u6cd5\u53ef\u96c6\u6210\u5230\u591a\u79cd\u9690\u5f0fCF\u6a21\u578b\u548c\u8d1f\u91c7\u6837\u65b9\u6cd5\u4e2d\uff0c\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "DTL-NS\u901a\u8fc7\u6587\u672c\u65e0\u5173\u3001\u65e0\u9700\u5fae\u8c03\u7684LLM\u589e\u5f3a\u8d1f\u91c7\u6837\uff0c\u6709\u6548\u8bc6\u522b\u5047\u8d1f\u6837\u672c\u5e76\u6316\u6398\u9ad8\u8d28\u91cf\u786c\u8d1f\u6837\u672c\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2602.18092", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.18092", "abs": "https://arxiv.org/abs/2602.18092", "authors": ["Matthew DiGiuseppe", "Joshua Robison"], "title": "Perceived Political Bias in LLMs Reduces Persuasive Abilities", "comment": "39 pages, 10 figures", "summary": "Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.", "AI": {"tldr": "LLM\u7684\u653f\u6cbb\u4e2d\u7acb\u6027\u611f\u77e5\u5f71\u54cd\u5176\u8bf4\u670d\u6548\u679c\uff1a\u515a\u6d3e\u504f\u89c1\u8b66\u544a\u4f1a\u964d\u4f4e28%\u7684\u8bf4\u670d\u529b", "motivation": "\u968f\u7740LLMs\u8fdb\u5165\u515a\u6d3e\u51b2\u7a81\uff0c\u7cbe\u82f1\u4eec\u8d8a\u6765\u8d8a\u591a\u5730\u5c06\u5b83\u4eec\u63cf\u7ed8\u6210\u5177\u6709\u610f\u8bc6\u5f62\u6001\u503e\u5411\u3002\u672c\u7814\u7a76\u65e8\u5728\u6d4b\u8bd5\u8fd9\u4e9b\u53ef\u4fe1\u5ea6\u653b\u51fb\u662f\u5426\u4f1a\u964d\u4f4e\u57fa\u4e8eLLM\u7684\u8bf4\u670d\u6548\u679c\u3002", "method": "\u5728\u7f8e\u56fd\u8fdb\u884c\u4e86\u4e00\u9879\u9884\u6ce8\u518c\u8c03\u67e5\u5b9e\u9a8c\uff08N=2144\uff09\uff0c\u53c2\u4e0e\u8005\u4e0eChatGPT\u8fdb\u884c\u4e09\u8f6e\u5bf9\u8bdd\uff0c\u8ba8\u8bba\u4e2a\u4eba\u6301\u6709\u7684\u7ecf\u6d4e\u653f\u7b56\u8bef\u89e3\u3002\u5b9e\u9a8c\u7ec4\u6536\u5230\u7b80\u77ed\u4fe1\u606f\uff0c\u8868\u660eLLM\u5bf9\u53c2\u4e0e\u8005\u6240\u5728\u515a\u6d3e\u6709\u504f\u89c1\uff0c\u5bf9\u7167\u7ec4\u4e3a\u4e2d\u7acb\u4fe1\u606f\u3002", "result": "\u4e0e\u4e2d\u7acb\u5bf9\u7167\u7ec4\u76f8\u6bd4\uff0c\u515a\u6d3e\u504f\u89c1\u8b66\u544a\u4f7fLLM\u7684\u8bf4\u670d\u6548\u679c\u964d\u4f4e\u4e8628%\u3002\u6587\u672c\u5206\u6790\u8868\u660e\uff0c\u8b66\u544a\u6539\u53d8\u4e86\u4e92\u52a8\u6a21\u5f0f\uff1a\u53d7\u8bbf\u8005\u66f4\u9891\u7e41\u5730\u53cd\u9a73\uff0c\u63a5\u53d7\u5ea6\u66f4\u4f4e\u3002", "conclusion": "\u5bf9\u8bdd\u5f0fAI\u7684\u8bf4\u670d\u6548\u679c\u5177\u6709\u653f\u6cbb\u4f9d\u8d56\u6027\uff0c\u53d7\u5230\u515a\u6d3e\u4e00\u81f4\u6027\u611f\u77e5\u7684\u9650\u5236\u3002\u653f\u6cbb\u4e2d\u7acb\u6027\u611f\u77e5\u662fLLM\u6709\u6548\u6027\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2602.18283", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18283", "abs": "https://arxiv.org/abs/2602.18283", "authors": ["Lei Xin", "Yuhao Zheng", "Ke Cheng", "Changjiang Jiang", "Zifan Zhang", "Fanhu Zeng"], "title": "HyTRec: A Hybrid Temporal-Aware Attention Architecture for Long Behavior Sequential Recommendation", "comment": "Preprint", "summary": "Modeling long sequences of user behaviors has emerged as a critical frontier in generative recommendation. However, existing solutions face a dilemma: linear attention mechanisms achieve efficiency at the cost of retrieval precision due to limited state capacity, while softmax attention suffers from prohibitive computational overhead. To address this challenge, we propose HyTRec, a model featuring a Hybrid Attention architecture that explicitly decouples long-term stable preferences from short-term intent spikes. By assigning massive historical sequences to a linear attention branch and reserving a specialized softmax attention branch for recent interactions, our approach restores precise retrieval capabilities within industrial-scale contexts involving ten thousand interactions. To mitigate the lag in capturing rapid interest drifts within the linear layers, we furthermore design Temporal-Aware Delta Network (TADN) to dynamically upweight fresh behavioral signals while effectively suppressing historical noise. Empirical results on industrial-scale datasets confirm the superiority that our model maintains linear inference speed and outperforms strong baselines, notably delivering over 8% improvement in Hit Rate for users with ultra-long sequences with great efficiency.", "AI": {"tldr": "HyTRec\u63d0\u51fa\u6df7\u5408\u6ce8\u610f\u529b\u67b6\u6784\uff0c\u5c06\u957f\u5e8f\u5217\u884c\u4e3a\u89e3\u8026\u4e3a\u957f\u671f\u7a33\u5b9a\u504f\u597d\u548c\u77ed\u671f\u610f\u56fe\u6ce2\u52a8\uff0c\u901a\u8fc7\u7ebf\u6027\u6ce8\u610f\u529b\u5904\u7406\u5386\u53f2\u5e8f\u5217\u3001\u8f6f\u6ce8\u610f\u529b\u5904\u7406\u8fd1\u671f\u4ea4\u4e92\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u63a8\u7406\u901f\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u68c0\u7d22\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u4e24\u96be\u56f0\u5883\uff1a\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u6548\u7387\u9ad8\u4f46\u68c0\u7d22\u7cbe\u5ea6\u6709\u9650\uff08\u72b6\u6001\u5bb9\u91cf\u4e0d\u8db3\uff09\uff0c\u800csoftmax\u6ce8\u610f\u529b\u8ba1\u7b97\u5f00\u9500\u5de8\u5927\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u5de5\u4e1a\u89c4\u6a21\uff08\u4e0a\u4e07\u6b21\u4ea4\u4e92\uff09\u4e0b\u65e2\u9ad8\u6548\u53c8\u7cbe\u786e\u7684\u5e8f\u5217\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "1. \u6df7\u5408\u6ce8\u610f\u529b\u67b6\u6784\uff1a\u7ebf\u6027\u6ce8\u610f\u529b\u5206\u652f\u5904\u7406\u5927\u89c4\u6a21\u5386\u53f2\u5e8f\u5217\uff0c\u8f6f\u6ce8\u610f\u529b\u5206\u652f\u4e13\u95e8\u5904\u7406\u8fd1\u671f\u4ea4\u4e92\n2. \u65f6\u95f4\u611f\u77e5Delta\u7f51\u7edc\uff08TADN\uff09\uff1a\u52a8\u6001\u63d0\u5347\u65b0\u9c9c\u884c\u4e3a\u4fe1\u53f7\u7684\u6743\u91cd\uff0c\u6291\u5236\u5386\u53f2\u566a\u58f0\n3. \u663e\u5f0f\u89e3\u8026\u957f\u671f\u7a33\u5b9a\u504f\u597d\u548c\u77ed\u671f\u610f\u56fe\u6ce2\u52a8", "result": "\u5728\u5de5\u4e1a\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u4fdd\u6301\u7ebf\u6027\u63a8\u7406\u901f\u5ea6\u7684\u540c\u65f6\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5bf9\u8d85\u957f\u5e8f\u5217\u7528\u6237\u7684\u547d\u4e2d\u7387\u63d0\u5347\u8d85\u8fc78%\uff0c\u4e14\u6548\u7387\u4f18\u5f02\u3002", "conclusion": "HyTRec\u901a\u8fc7\u6df7\u5408\u6ce8\u610f\u529b\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u957f\u5e8f\u5217\u5efa\u6a21\u4e2d\u6548\u7387\u4e0e\u7cbe\u5ea6\u7684\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.18137", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18137", "abs": "https://arxiv.org/abs/2602.18137", "authors": ["Vincent Grari", "Ciprian Tomoiaga", "Sylvain Lamprier", "Tatsunori Hashimoto", "Marcin Detyniecki"], "title": "Agentic Adversarial QA for Improving Domain-Specific LLMs", "comment": "9 pages, 1 Figure", "summary": "Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.", "AI": {"tldr": "\u63d0\u51fa\u5bf9\u6297\u6027\u63d0\u95ee\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6bd4\u8f83\u5f85\u9002\u5e94\u6a21\u578b\u4e0e\u4e13\u5bb6\u6a21\u578b\u8f93\u51fa\uff0c\u751f\u6210\u7d27\u51d1\u7684\u8bed\u4e49\u6311\u6218\u6027\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u7684\u9002\u5e94\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u9002\u5e94\u80fd\u529b\u4e0d\u8db3\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6539\u5199\u6216\u77e5\u8bc6\u63d0\u53d6\u751f\u6210\u7684\u5408\u6210\u6570\u636e\uff0c\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u7f3a\u9677\uff1a1) \u5bf9\u89e3\u91ca\u6027\u63a8\u7406\u80fd\u529b\u652f\u6301\u4e0d\u8db3\uff1b2) \u751f\u6210\u7684\u6570\u636e\u96c6\u8fc7\u5927\u4e14\u5197\u4f59\uff0c\u6837\u672c\u6548\u7387\u4f4e\u3002", "method": "\u63d0\u51fa\u5bf9\u6297\u6027\u63d0\u95ee\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u8fc7\u7a0b\u6bd4\u8f83\u5f85\u9002\u5e94\u6a21\u578b\u4e0e\u57fa\u4e8e\u53c2\u8003\u6587\u6863\u7684\u4e13\u5bb6\u6a21\u578b\u8f93\u51fa\uff0c\u8bc6\u522b\u7406\u89e3\u5dee\u8ddd\u5e76\u751f\u6210\u7d27\u51d1\u7684\u8bed\u4e49\u6311\u6218\u6027\u95ee\u9898\u3002", "result": "\u5728LegalBench\u8bed\u6599\u7684\u4e13\u4e1a\u5b50\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u4ee5\u663e\u8457\u66f4\u5c11\u7684\u5408\u6210\u6837\u672c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u5bf9\u6297\u6027\u63d0\u95ee\u751f\u6210\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u4e13\u4e1a\u9886\u57df\u9002\u5e94\u4e2d\u7684\u5408\u6210\u6570\u636e\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u751f\u6210\u7d27\u51d1\u7684\u8bed\u4e49\u6311\u6218\u6027\u95ee\u9898\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.18288", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18288", "abs": "https://arxiv.org/abs/2602.18288", "authors": ["Jiayi Wu", "Zhengyu Wu", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "A Topology-Aware Positive Sample Set Construction and Feature Optimization Method in Implicit Collaborative Filtering", "comment": null, "summary": "Negative sampling strategies are widely used in implicit collaborative filtering to address issues like data sparsity and class imbalance. However, these methods often introduce false negatives, hindering the model's ability to accurately learn users' latent preferences. To mitigate this problem, existing methods adjust the negative sampling distribution based on statistical features from model training or the hardness of negative samples. Nevertheless, these methods face two key limitations: (1) over-reliance on the model's current representation capabilities; (2) failure to leverage the potential of false negatives as latent positive samples to guide model learning of user preferences more accurately. To address the above issues, we propose a Topology-aware Positive Sample Set Construction and Feature Optimization method (TPSC-FO). First, we design a simple topological community-aware false negative identification (FNI) method and observe that topological community structures in interaction networks can effectively identify false negatives. Motivated by this, we develop a topology-aware positive sample set construction module. This module employs a differential community detection strategy to capture topological community structures in implicit feedback, coupled with personalized noise filtration to reliably identify false negatives and convert them into positive samples. Additionally, we introduce a neighborhood-guided feature optimization module that refines positive sample features by incorporating neighborhood features in the embedding space, effectively mitigating noise in the positive samples. Extensive experiments on five real-world datasets and two synthetic datasets validate the effectiveness of TPSC-FO.", "AI": {"tldr": "\u63d0\u51faTPSC-FO\u65b9\u6cd5\uff0c\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u7684\u6b63\u6837\u672c\u96c6\u6784\u5efa\u548c\u7279\u5f81\u4f18\u5316\uff0c\u89e3\u51b3\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u4e2d\u8d1f\u91c7\u6837\u5f15\u5165\u5047\u9634\u6027\u7684\u95ee\u9898", "motivation": "\u73b0\u6709\u8d1f\u91c7\u6837\u65b9\u6cd5\u5728\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u4e2d\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u8fc7\u5ea6\u4f9d\u8d56\u6a21\u578b\u5f53\u524d\u8868\u793a\u80fd\u529b\uff1b\u672a\u80fd\u5229\u7528\u5047\u9634\u6027\u6837\u672c\u4f5c\u4e3a\u6f5c\u5728\u6b63\u6837\u672c\u6765\u66f4\u51c6\u786e\u5730\u5b66\u4e60\u7528\u6237\u504f\u597d", "method": "\u63d0\u51faTPSC-FO\u65b9\u6cd5\uff0c\u5305\u542b\u62d3\u6251\u611f\u77e5\u6b63\u6837\u672c\u96c6\u6784\u5efa\u6a21\u5757\uff08\u4f7f\u7528\u5dee\u5206\u793e\u533a\u68c0\u6d4b\u7b56\u7565\u548c\u4e2a\u6027\u5316\u566a\u58f0\u8fc7\u6ee4\u8bc6\u522b\u5047\u9634\u6027\u5e76\u8f6c\u4e3a\u6b63\u6837\u672c\uff09\u548c\u90bb\u57df\u5f15\u5bfc\u7279\u5f81\u4f18\u5316\u6a21\u5757\uff08\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7ed3\u5408\u90bb\u57df\u7279\u5f81\u7ec6\u5316\u6b63\u6837\u672c\u7279\u5f81\uff09", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86TPSC-FO\u7684\u6709\u6548\u6027", "conclusion": "TPSC-FO\u901a\u8fc7\u5229\u7528\u4ea4\u4e92\u7f51\u7edc\u4e2d\u7684\u62d3\u6251\u793e\u533a\u7ed3\u6784\u8bc6\u522b\u5047\u9634\u6027\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u6b63\u6837\u672c\uff0c\u7ed3\u5408\u90bb\u57df\u7279\u5f81\u4f18\u5316\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u5b66\u4e60\u7528\u6237\u504f\u597d\uff0c\u63d0\u9ad8\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u6027\u80fd"}}
{"id": "2602.18145", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18145", "abs": "https://arxiv.org/abs/2602.18145", "authors": ["Siya Qi", "Yudong Chen", "Runcong Zhao", "Qinglin Zhu", "Zhanghao Hu", "Wei Liu", "Yulan He", "Zheng Yuan", "Lin Gui"], "title": "Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention", "comment": "25 pages, 10 figures", "summary": "Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9891\u7387\u611f\u77e5\u7684\u6ce8\u610f\u529b\u5206\u6790\u65b9\u6cd5\u6765\u68c0\u6d4bLLM\u5e7b\u89c9\uff0c\u901a\u8fc7\u5206\u6790\u6ce8\u610f\u529b\u5206\u5e03\u7684\u9ad8\u9891\u6210\u5206\u6765\u8bc6\u522b\u4e0d\u7a33\u5b9a\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86\u8f7b\u91cf\u7ea7\u5e7b\u89c9\u68c0\u6d4b\u5668\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u7c97\u7c92\u5ea6\u7684\u6ce8\u610f\u529b\u6c47\u603b\uff0c\u65e0\u6cd5\u6355\u6349\u6ce8\u610f\u529b\u4e2d\u7684\u7ec6\u7c92\u5ea6\u4e0d\u7a33\u5b9a\u6a21\u5f0f\u3002\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u65b9\u6cd5\u6765\u5206\u6790\u6ce8\u610f\u529b\u52a8\u6001\u4ee5\u68c0\u6d4b\u5e7b\u89c9\u3002", "method": "\u53d7\u4fe1\u53f7\u5904\u7406\u542f\u53d1\uff0c\u5c06\u6ce8\u610f\u529b\u5206\u5e03\u5efa\u6a21\u4e3a\u79bb\u6563\u4fe1\u53f7\uff0c\u63d0\u53d6\u53cd\u6620\u6ce8\u610f\u529b\u5feb\u901f\u5c40\u90e8\u53d8\u5316\u7684\u9ad8\u9891\u6210\u5206\u3002\u5206\u6790\u53d1\u73b0\u5e7b\u89c9token\u4e0e\u9ad8\u9891\u6ce8\u610f\u529b\u80fd\u91cf\u76f8\u5173\uff0c\u53cd\u6620\u4e86\u4e0d\u7a33\u5b9a\u7684\u6ce8\u610f\u529b\u884c\u4e3a\u3002\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u4f7f\u7528\u9ad8\u9891\u6ce8\u610f\u529b\u7279\u5f81\u7684\u8f7b\u91cf\u7ea7\u5e7b\u89c9\u68c0\u6d4b\u5668\u3002", "result": "\u5728RAGTruth\u548cHalluRAG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u9a8c\u8bc1\u3001\u5185\u90e8\u8868\u793a\u548c\u6ce8\u610f\u529b\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6ce8\u610f\u529b\u5206\u5e03\u7684\u9ad8\u9891\u6210\u5206\u80fd\u6709\u6548\u53cd\u6620LLM\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u884c\u4e3a\uff0c\u57fa\u4e8e\u9891\u7387\u611f\u77e5\u7684\u6ce8\u610f\u529b\u5206\u6790\u4e3a\u5e7b\u89c9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u89c6\u89d2\u3002"}}
{"id": "2602.18152", "categories": ["cs.CL", "cs.CY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.18152", "abs": "https://arxiv.org/abs/2602.18152", "authors": ["Ortal Hadad", "Edoardo Loru", "Jacopo Nudo", "Niccol\u00f2 Di Marco", "Matteo Cinelli", "Walter Quattrociocchi"], "title": "The Statistical Signature of LLMs", "comment": null, "summary": "Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.", "AI": {"tldr": "\u538b\u7f29\u7387\u53ef\u4f5c\u4e3a\u533a\u5206LLM\u751f\u6210\u6587\u672c\u4e0e\u4eba\u7c7b\u6587\u672c\u7684\u7b80\u5355\u6709\u6548\u6307\u6807\uff0c\u63ed\u793a\u4e86\u751f\u6210\u6587\u672c\u5177\u6709\u66f4\u9ad8\u7684\u7ed3\u6784\u89c4\u5f8b\u6027\u548c\u53ef\u538b\u7f29\u6027\uff0c\u4f46\u5728\u5c0f\u5c3a\u5ea6\u4e92\u52a8\u73af\u5883\u4e2d\u8fd9\u79cd\u5dee\u5f02\u4f1a\u51cf\u5f31\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u6982\u7387\u91c7\u6837\u751f\u6210\u6587\u672c\uff0c\u4f46\u8fd9\u4e00\u8fc7\u7a0b\u5982\u4f55\u91cd\u5851\u8bed\u8a00\u7684\u7ed3\u6784\u7edf\u8ba1\u7ec4\u7ec7\u5c1a\u4e0d\u5b8c\u5168\u6e05\u695a\u3002\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u751f\u6210\u7cfb\u7edf\u5982\u4f55\u91cd\u5851\u6587\u672c\u751f\u4ea7\u3002", "method": "\u4f7f\u7528\u65e0\u635f\u538b\u7f29\u4f5c\u4e3a\u8861\u91cf\u7edf\u8ba1\u89c4\u5f8b\u6027\u7684\u7b80\u5355\u3001\u6a21\u578b\u65e0\u5173\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u5206\u6790\u4e09\u4e2a\u6e10\u8fdb\u590d\u6742\u7684\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\uff1a\u53d7\u63a7\u7684\u4eba-LLM\u5ef6\u7eed\u3001\u77e5\u8bc6\u57fa\u7840\u8bbe\u65bd\u7684\u751f\u6210\u4e2d\u4ecb\uff08\u7ef4\u57fa\u767e\u79d1 vs Grokipedia\uff09\u3001\u5b8c\u5168\u5408\u6210\u7684\u793e\u4ea4\u4e92\u52a8\u73af\u5883\uff08Moltbook vs Reddit\uff09\u3002", "result": "\u538b\u7f29\u63ed\u793a\u4e86\u6982\u7387\u751f\u6210\u7684\u7ed3\u6784\u7279\u5f81\uff1a\u5728\u53d7\u63a7\u548c\u4e2d\u4ecb\u73af\u5883\u4e2d\uff0cLLM\u4ea7\u751f\u7684\u8bed\u8a00\u6bd4\u4eba\u7c7b\u6587\u672c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7ed3\u6784\u89c4\u5f8b\u6027\u548c\u53ef\u538b\u7f29\u6027\uff0c\u4f46\u8be5\u7279\u5f81\u5177\u6709\u5c3a\u5ea6\u4f9d\u8d56\u6027\uff0c\u5728\u788e\u7247\u5316\u7684\u4e92\u52a8\u73af\u5883\u4e2d\u5206\u79bb\u51cf\u5f31\uff0c\u8868\u660e\u5c0f\u5c3a\u5ea6\u8868\u9762\u53ef\u533a\u5206\u6027\u5b58\u5728\u57fa\u672c\u9650\u5236\u3002", "conclusion": "\u538b\u7f29\u7387\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u7a33\u5065\u7684\u6846\u67b6\u6765\u91cf\u5316\u751f\u6210\u7cfb\u7edf\u5982\u4f55\u91cd\u5851\u6587\u672c\u751f\u4ea7\uff0c\u4e3a\u901a\u4fe1\u6f14\u5316\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u7ed3\u6784\u89c6\u89d2\uff0c\u65e0\u9700\u4f9d\u8d56\u6a21\u578b\u5185\u90e8\u6216\u8bed\u4e49\u8bc4\u4f30\u5373\u53ef\u4ece\u8868\u9762\u6587\u672c\u76f4\u63a5\u89c2\u5bdf\u3002"}}
{"id": "2602.18425", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18425", "abs": "https://arxiv.org/abs/2602.18425", "authors": ["Deniz Qian", "Hung-Ting Chen", "Eunsol Choi"], "title": "RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering", "comment": "18 pages, 12 figures, 12 tables", "summary": "Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.", "AI": {"tldr": "RVR\u662f\u4e00\u4e2a\u591a\u8f6e\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22-\u9a8c\u8bc1-\u68c0\u7d22\u7684\u8fed\u4ee3\u8fc7\u7a0b\u6700\u5927\u5316\u7b54\u6848\u8986\u76d6\u7387\uff0c\u663e\u8457\u63d0\u5347\u591a\u7b54\u6848\u67e5\u8be2\u7684\u5b8c\u6574\u53ec\u56de\u7387\u3002", "motivation": "\u5904\u7406\u591a\u7b54\u6848\u67e5\u8be2\u65f6\u9700\u8981\u5168\u9762\u68c0\u7d22\u591a\u6837\u5316\u7684\u6587\u6863\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6700\u5927\u5316\u7b54\u6848\u8986\u76d6\u7387\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u68c0\u7d22-\u9a8c\u8bc1-\u68c0\u7d22\uff08RVR\uff09\u6846\u67b6\uff1a\u9996\u8f6e\u7528\u539f\u59cb\u67e5\u8be2\u68c0\u7d22\u5019\u9009\u6587\u6863\uff0c\u9a8c\u8bc1\u5668\u7b5b\u9009\u9ad8\u8d28\u91cf\u5b50\u96c6\uff1b\u540e\u7eed\u8f6e\u6b21\u5c06\u5df2\u9a8c\u8bc1\u6587\u6863\u4f5c\u4e3a\u67e5\u8be2\u8865\u5145\uff0c\u9010\u6b65\u53d1\u73b0\u672a\u88ab\u8986\u76d6\u7684\u7b54\u6848\u3002", "result": "\u5728QAMPARI\u6570\u636e\u96c6\u4e0a\u76f8\u5bf9\u63d0\u5347\u81f3\u5c1110%\uff0c\u7edd\u5bf9\u63d0\u53473%\u7684\u5b8c\u6574\u53ec\u56de\u7387\uff1b\u5728QUEST\u548cWebQuestionsSP\u6570\u636e\u96c6\u4e0a\u4e5f\u6709\u7a33\u5b9a\u589e\u76ca\uff1b\u5373\u4f7f\u4f7f\u7528\u73b0\u6210\u68c0\u7d22\u5668\u4e5f\u6709\u6548\uff0c\u5fae\u8c03\u540e\u6548\u679c\u66f4\u4f73\u3002", "conclusion": "RVR\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5668\u548c\u68c0\u7d22\u5668\u9002\u5e94\u65b0\u63a8\u7406\u573a\u666f\uff0c\u663e\u8457\u63d0\u5347\u591a\u7b54\u6848\u68c0\u7d22\u7684\u5168\u9762\u6027\u3002"}}
{"id": "2602.18154", "categories": ["cs.CL", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.18154", "abs": "https://arxiv.org/abs/2602.18154", "authors": ["Mirae Kim", "Seonghun Jeong", "Youngjun Kwak"], "title": "FENCE: A Financial and Multimodal Jailbreak Detection Dataset", "comment": "lrec 2026 accepted paper", "summary": "Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.", "AI": {"tldr": "FENCE\u662f\u4e00\u4e2a\u53cc\u8bed\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u91d1\u878d\u9886\u57df\u4e2d\u7684\u8d8a\u72f1\u68c0\u6d4b\u5668\uff0c\u5305\u542b\u91d1\u878d\u76f8\u5173\u67e5\u8be2\u548c\u57fa\u4e8e\u56fe\u50cf\u7684\u5a01\u80c1\uff0c\u5b9e\u9a8c\u663e\u793a\u73b0\u6709VLM\u5b58\u5728\u6f0f\u6d1e\uff0c\u57fa\u7ebf\u68c0\u6d4b\u5668\u8fbe\u523099%\u51c6\u786e\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u5b58\u5728\u663e\u8457\u98ce\u9669\uff0c\u7279\u522b\u662fVLM\u56e0\u5904\u7406\u6587\u672c\u548c\u56fe\u50cf\u800c\u66f4\u8106\u5f31\u3002\u91d1\u878d\u9886\u57df\u7f3a\u4e4f\u8d8a\u72f1\u68c0\u6d4b\u8d44\u6e90\uff0c\u9700\u8981\u4e13\u95e8\u7684\u68c0\u6d4b\u6570\u636e\u96c6\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u521b\u5efaFENCE\u53cc\u8bed\u591a\u6a21\u6001\u6570\u636e\u96c6\uff08\u97e9\u8bed-\u82f1\u8bed\uff09\uff0c\u5305\u542b\u91d1\u878d\u76f8\u5173\u67e5\u8be2\u548c\u57fa\u4e8e\u56fe\u50cf\u7684\u5a01\u80c1\uff0c\u5f3a\u8c03\u9886\u57df\u771f\u5b9e\u6027\u3002\u5728\u5546\u4e1a\u548c\u5f00\u6e90VLM\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u8bad\u7ec3\u57fa\u7ebf\u8d8a\u72f1\u68c0\u6d4b\u5668\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5546\u4e1a\u548c\u5f00\u6e90VLM\u5747\u5b58\u5728\u4e00\u81f4\u6f0f\u6d1e\uff0cGPT-4o\u6709\u663e\u8457\u653b\u51fb\u6210\u529f\u7387\uff0c\u5f00\u6e90\u6a21\u578b\u66b4\u9732\u66f4\u5927\u98ce\u9669\u3002\u57fa\u4e8eFENCE\u8bad\u7ec3\u7684\u57fa\u7ebf\u68c0\u6d4b\u5668\u8fbe\u523099%\u5206\u5e03\u5185\u51c6\u786e\u7387\uff0c\u5e76\u5728\u5916\u90e8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u5f3a\u6027\u80fd\u3002", "conclusion": "FENCE\u4e3a\u91d1\u878d\u9886\u57df\u591a\u6a21\u6001\u8d8a\u72f1\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e13\u95e8\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u8bad\u7ec3\u53ef\u9760\u7684\u68c0\u6d4b\u6a21\u578b\uff0c\u652f\u6301\u654f\u611f\u9886\u57df\u6784\u5efa\u66f4\u5b89\u5168\u53ef\u9760\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2602.18429", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18429", "abs": "https://arxiv.org/abs/2602.18429", "authors": ["Harshul Raj Surana", "Arijit Maji", "Aryan Vats", "Akash Ghosh", "Sriparna Saha", "Amit Sheth"], "title": "VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning", "comment": null, "summary": "Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.", "AI": {"tldr": "\u63d0\u51faVIRAASAT\u6570\u636e\u96c6\u548cSCoM\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347LLM\u5728\u5370\u5ea6\u6587\u5316\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u6587\u5316\u57fa\u51c6\u591a\u4e3a\u624b\u5de5\u6784\u5efa\u3001\u5355\u8df3\u95ee\u9898\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u65e0\u6cd5\u6709\u6548\u8861\u91cfLLM\u5728\u9700\u8981\u4e30\u5bcc\u793e\u4f1a\u6587\u5316\u77e5\u8bc6\u548c\u672c\u5730\u60c5\u5883\uff08\u7279\u522b\u662f\u5370\u5ea6\u6587\u5316\uff09\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u7f3a\u9677\u3002", "method": "1) \u521b\u5efaVIRAASAT\u6570\u636e\u96c6\uff1a\u534a\u81ea\u52a8\u591a\u8df3\u65b9\u6cd5\u751f\u6210\u5370\u5ea6\u6587\u5316\u7279\u5b9aQA\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u5305\u542b700+\u4e13\u5bb6\u7b56\u5212\u6587\u5316\u5b9e\u4f53\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u8986\u76d613\u4e2a\u6587\u5316\u5c5e\u6027\uff0c\u6db5\u76d628\u4e2a\u90a6\u548c8\u4e2a\u8054\u90a6\u5c5e\u5730\uff1b2) \u63d0\u51faSCoM\u6846\u67b6\uff1a\u8bad\u7ec3\u6a21\u578b\u5185\u90e8\u6a21\u62df\u77e5\u8bc6\u56fe\u8c31\u7684\u539f\u5b50\u64cd\u4f5c\uff0c\u53ef\u9760\u904d\u5386\u56fe\u8c31\u62d3\u6251\u7ed3\u6784\u3002", "result": "\u751f\u6210\u8d85\u8fc73,200\u4e2a\u591a\u8df3\u95ee\u9898\uff0c\u53d1\u73b0\u5f53\u524dSOTA LLMs\u5728\u6587\u5316\u63a8\u7406\u4e2d\u5b58\u5728\u5173\u952e\u9650\u5236\uff08CoT\u5fae\u8c03\u65e0\u6cd5\u5904\u7406\u4f4e\u6982\u7387\u4e8b\u5b9e\uff09\u3002SCoM\u5728\u76d1\u7763\u5fae\u8c03\u4e2d\u6bd4\u6807\u51c6CoT\u57fa\u7ebf\u63d0\u5347\u8fbe20%\u3002", "conclusion": "VIRAASAT\u6570\u636e\u96c6\u548cSCoM\u6846\u67b6\u4e3a\u6784\u5efa\u6587\u5316\u611f\u77e5\u63a8\u7406\u6a21\u578b\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u89e3\u51b3\u4e86LLM\u5728\u6587\u5316\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\u3002"}}
{"id": "2602.18171", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18171", "abs": "https://arxiv.org/abs/2602.18171", "authors": ["Wojciech Michaluk", "Tymoteusz Urban", "Mateusz Kubita", "Soveatin Kuntur", "Anna Wroblewska"], "title": "Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models", "comment": null, "summary": "Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\u7528\u4e8e\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\uff0c\u7ed3\u5408\u4e86\u57fa\u4e8eTransformer\u7684\u6587\u672c\u5d4c\u5165\u548c\u8bed\u8a00\u5b66\u7279\u5f81\uff0c\u901a\u8fc7XGBoost\u5206\u7c7b\u5668\u5b9e\u73b0\u4e8691%\u7684F1\u5206\u6570\u3002", "motivation": "\u70b9\u51fb\u8bf1\u9975\u6807\u9898\u964d\u4f4e\u4e86\u5728\u7ebf\u4fe1\u606f\u8d28\u91cf\u5e76\u635f\u5bb3\u7528\u6237\u4fe1\u4efb\uff0c\u9700\u8981\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u57fa\u4e8eTransformer\u7684\u6587\u672c\u5d4c\u5165\u548c15\u4e2a\u8bed\u8a00\u5b66\u7279\u5f81\uff08\u5982\u7b2c\u4e8c\u4eba\u79f0\u4ee3\u8bcd\u3001\u6700\u9ad8\u7ea7\u3001\u6570\u5b57\u3001\u6ce8\u610f\u529b\u5bfc\u5411\u6807\u70b9\u7b49\uff09\uff0c\u901a\u8fc7XGBoost\u7b49\u6811\u57fa\u5206\u7c7b\u5668\u8fdb\u884c\u68c0\u6d4b\u3002", "result": "\u6700\u4f73\u6a21\u578b\uff08XGBoost\u7ed3\u5408\u5d4c\u5165\u548c15\u4e2a\u663e\u5f0f\u7279\u5f81\uff09\u8fbe\u523091%\u7684F1\u5206\u6570\uff0c\u4f18\u4e8eTF-IDF\u3001Word2Vec\u3001GloVe\u3001LLM\u63d0\u793a\u5206\u7c7b\u548c\u4ec5\u7279\u5f81\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u7684\u7279\u5f81\u96c6\u901a\u8fc7\u7a81\u51fa\u663e\u5f0f\u8bed\u8a00\u5b66\u7ebf\u7d22\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u5b9e\u73b0\u4e86\u900f\u660e\u4e14\u6821\u51c6\u826f\u597d\u7684\u70b9\u51fb\u8bf1\u9975\u9884\u6d4b\uff0c\u5e76\u53d1\u5e03\u4e86\u4ee3\u7801\u548c\u8bad\u7ec3\u6a21\u578b\u4ee5\u652f\u6301\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2602.18176", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18176", "abs": "https://arxiv.org/abs/2602.18176", "authors": ["Kaisen Yang", "Jayden Teoh", "Kaicheng Yang", "Yitong Zhang", "Alex Lamb"], "title": "Improving Sampling for Masked Diffusion Models via Information Gain", "comment": "https://github.com/yks23/Information-Gain-Sampler", "summary": "Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.", "AI": {"tldr": "\u63d0\u51faInfo-Gain Sampler\uff0c\u4e00\u79cd\u65b0\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5e73\u8861\u5373\u65f6\u4e0d\u786e\u5b9a\u6027\u548c\u672a\u6765\u4fe1\u606f\u589e\u76ca\uff0c\u663e\u8457\u63d0\u5347\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u63a9\u7801\u6269\u6563\u6a21\u578b\u89e3\u7801\u5668\u91c7\u7528\u8d2a\u5fc3\u7b56\u7565\uff0c\u53ea\u5173\u6ce8\u5c40\u90e8\u6700\u9ad8\u786e\u5b9a\u6027\u4f4d\u7f6e\uff0c\u5ffd\u7565\u4e86\u5f53\u524d\u89e3\u7801\u51b3\u7b56\u5bf9\u540e\u7eed\u6b65\u9aa4\u7684\u7d2f\u79ef\u5f71\u54cd\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528MDMs\u7684\u975e\u56e0\u679c\u7279\u6027\u3002", "method": "\u63d0\u51faInfo-Gain Sampler\uff0c\u8fd9\u662f\u4e00\u4e2a\u539f\u5219\u6027\u89e3\u7801\u6846\u67b6\uff0c\u4e0d\u4ec5\u8003\u8651\u5f53\u524d\u4f4d\u7f6e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd8\u8bc4\u4f30\u5f53\u524d\u89e3\u7801\u51b3\u7b56\u5982\u4f55\u91cd\u5851\u6240\u6709\u5269\u4f59\u63a9\u7801\u4f4d\u7f6e\u7684token\u6982\u7387/\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u5373\u65f6\u4e0d\u786e\u5b9a\u6027\u4e0e\u672a\u6765\u4fe1\u606f\u589e\u76ca\u7684\u5e73\u8861\u3002", "result": "\u5728\u63a8\u7406\u3001\u7f16\u7801\u3001\u521b\u610f\u5199\u4f5c\u548c\u56fe\u50cf\u751f\u6210\u7b49\u591a\u6837\u5316\u4efb\u52a1\u4e0a\uff0cInfo-Gain Sampler\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u91c7\u6837\u5668\u3002\u63a8\u7406\u4efb\u52a1\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53473.6%\uff0c\u521b\u610f\u5199\u4f5c\u4efb\u52a1\u80dc\u738763.1%\uff0c\u7d2f\u79ef\u4e0d\u786e\u5b9a\u6027\u4ece78.4\u964d\u81f348.6\u3002", "conclusion": "Info-Gain Sampler\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u8003\u8651\u89e3\u7801\u51b3\u7b56\u7684\u957f\u671f\u5f71\u54cd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf\uff0c\u8bc1\u660e\u4e86\u5e73\u8861\u5373\u65f6\u4e0d\u786e\u5b9a\u6027\u548c\u672a\u6765\u4fe1\u606f\u589e\u76ca\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.18217", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18217", "abs": "https://arxiv.org/abs/2602.18217", "authors": ["Kohei Kajikawa", "Shinnosuke Isono", "Ethan Gotlieb Wilcox"], "title": "Information-Theoretic Storage Cost in Sentence Comprehension", "comment": null, "summary": "Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u5f62\u5f0f\u5316\u5904\u7406\u5b58\u50a8\u6210\u672c\u5ea6\u91cf\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u4f30\u8ba1\uff0c\u80fd\u9884\u6d4b\u9605\u8bfb\u65f6\u95f4\u5e76\u89e3\u91ca\u5df2\u77e5\u5904\u7406\u4e0d\u5bf9\u79f0\u6027", "motivation": "\u5b9e\u65f6\u53e5\u5b50\u7406\u89e3\u5bf9\u5de5\u4f5c\u8bb0\u5fc6\u6709\u663e\u8457\u8d1f\u8377\uff0c\u73b0\u6709\u57fa\u4e8e\u7b26\u53f7\u8bed\u6cd5\u7684\u79bb\u6563\u5ea6\u91cf\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u8fde\u7eed\u3001\u7406\u8bba\u4e2d\u7acb\u4e14\u80fd\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u4f30\u8ba1\u7684\u5ea6\u91cf\u65b9\u6cd5", "method": "\u57fa\u4e8e\u4fe1\u606f\u8bba\u63d0\u51fa\u5904\u7406\u5b58\u50a8\u6210\u672c\u5ea6\u91cf\uff0c\u5b9a\u4e49\u4e3a\u5148\u524d\u8bcd\u6c47\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u5bf9\u672a\u6765\u8bed\u5883\u643a\u5e26\u7684\u4fe1\u606f\u91cf\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4f30\u8ba1", "result": "1) \u6062\u590d\u4e86\u4e2d\u5fc3\u5d4c\u5165\u548c\u5173\u7cfb\u4ece\u53e5\u4e2d\u5df2\u77e5\u7684\u5904\u7406\u4e0d\u5bf9\u79f0\u6027 2) \u4e0e\u8bed\u6cd5\u5316\u5b58\u50a8\u6210\u672c\u76f8\u5173 3) \u5728\u81ea\u7136\u6570\u636e\u96c6\u4e0a\u9884\u6d4b\u9605\u8bfb\u65f6\u95f4\u65b9\u5dee\uff0c\u4f18\u4e8e\u4f20\u7edf\u4fe1\u606f\u9884\u6d4b\u5668\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u4fe1\u606f\u8bba\u5f62\u5f0f\u5316\u7684\u5904\u7406\u5b58\u50a8\u6210\u672c\u5ea6\u91cf\u662f\u6709\u6548\u7684\uff0c\u63d0\u4f9b\u8fde\u7eed\u3001\u7406\u8bba\u4e2d\u7acb\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u66f4\u597d\u5730\u89e3\u91ca\u5b9e\u65f6\u53e5\u5b50\u7406\u89e3\u4e2d\u7684\u5904\u7406\u8d1f\u8377"}}
{"id": "2602.18232", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18232", "abs": "https://arxiv.org/abs/2602.18232", "authors": ["Lexiang Tang", "Weihao Gao", "Bingchen Zhao", "Lu Ma", "Qiao jin", "Bang Yang", "Yuexian Zou"], "title": "Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning", "comment": null, "summary": "Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.", "AI": {"tldr": "\u63d0\u51faConfidence-Driven Contrastive Decoding\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u4f4e\u7f6e\u4fe1\u5ea6token\u8fdb\u884c\u9488\u5bf9\u6027\u5e72\u9884\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u53ef\u9760\u6027\u5e76\u51cf\u5c11\u8f93\u51fa\u957f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5047\u8bbe\u589e\u52a0\u63a8\u7406\u65f6\u8ba1\u7b97\u80fd\u5747\u5300\u63d0\u5347\u6b63\u786e\u6027\uff0c\u4f46\u5b9e\u9645\u63a8\u7406\u4e0d\u786e\u5b9a\u6027\u9ad8\u5ea6\u5c40\u90e8\u5316\uff1a\u5c11\u6570\u4f4e\u7f6e\u4fe1\u5ea6token\u5bfc\u81f4\u63a8\u7406\u9519\u8bef\u548c\u4e0d\u5fc5\u8981\u7684\u8f93\u51fa\u6269\u5c55\u3002", "method": "\u63d0\u51faConfidence-Driven Contrastive Decoding\u65b9\u6cd5\uff1a\u68c0\u6d4b\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u4f4e\u7f6e\u4fe1\u5ea6token\uff0c\u6784\u5efa\u5bf9\u6bd4\u53c2\u8003\uff08\u5c06\u9ad8\u7f6e\u4fe1\u5ea6token\u66ff\u6362\u4e3a\u6700\u5c0f\u5360\u4f4d\u7b26\uff09\uff0c\u5728\u4f4e\u7f6e\u4fe1\u5ea6\u4f4d\u7f6e\u901a\u8fc7\u51cf\u53bb\u53c2\u8003\u5206\u5e03\u6765\u4f18\u5316\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u663e\u793aCCD\u663e\u8457\u63d0\u5347\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u8f93\u51fa\u957f\u5ea6\uff0cKV\u7f13\u5b58\u5f00\u9500\u6700\u5c0f\u3002\u4f5c\u4e3a\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u4f4e\u7f6e\u4fe1\u5ea6\u5e72\u9884\u63d0\u5347\u63a8\u7406\u53ef\u9760\u6027\uff0c\u907f\u514d\u8ba1\u7b97\u5197\u4f59\u3002", "conclusion": "CCD\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u7684\u5bf9\u6bd4\u89e3\u7801\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u9488\u5bf9\u6027\u5e72\u9884\uff0c\u5728\u63d0\u5347\u51c6\u786e\u6027\u7684\u540c\u65f6\u4f18\u5316\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u63a8\u7406\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bad\u7ec3\u514d\u8d39\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.18262", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18262", "abs": "https://arxiv.org/abs/2602.18262", "authors": ["Aaron Louis Eidt", "Nils Feldhus"], "title": "Simplifying Outcomes of Language Model Component Analyses with ELIA", "comment": "EACL 2026 System Demonstrations. GitHub: https://github.com/aaron0eidt/ELIA", "summary": "While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.", "AI": {"tldr": "ELIA\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7f51\u7edc\u5e94\u7528\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cd\u8bed\u8a00\u6a21\u578b\u5206\u6790\u6280\u672f\u5e76\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u89e3\u91ca\uff0c\u964d\u4f4e\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u7684\u4f7f\u7528\u95e8\u69db\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5df2\u7ecf\u5f00\u53d1\u4e86\u5f3a\u5927\u7684\u5de5\u5177\u6765\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u5de5\u4f5c\u539f\u7406\uff0c\u4f46\u5176\u590d\u6742\u6027\u9020\u6210\u4e86\u4f7f\u7528\u95e8\u69db\uff0c\u4ec5\u9650\u4e8e\u4e13\u5bb6\u4f7f\u7528\u3002\u9700\u8981\u8bbe\u8ba1\u66f4\u6613\u8bbf\u95ee\u7684\u5de5\u5177\u6765\u8ba9\u66f4\u5e7f\u6cdb\u7684\u53d7\u4f17\u7406\u89e3\u8fd9\u4e9b\u5206\u6790\u7ed3\u679c\u3002", "method": "\u8bbe\u8ba1\u3001\u6784\u5efa\u548c\u8bc4\u4f30ELIA\u4ea4\u4e92\u5f0f\u7f51\u7edc\u5e94\u7528\uff0c\u6574\u5408\u5f52\u56e0\u5206\u6790\u3001\u51fd\u6570\u5411\u91cf\u5206\u6790\u548c\u7535\u8def\u8ffd\u8e2a\u4e09\u79cd\u5173\u952e\u6280\u672f\uff0c\u5e76\u5f15\u5165\u65b0\u65b9\u6cd5\uff1a\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4e3a\u8fd9\u4e9b\u65b9\u6cd5\u4ea7\u751f\u7684\u590d\u6742\u53ef\u89c6\u5316\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "result": "\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u7684\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7ed3\u679c\u663e\u793a\u7528\u6237\u660e\u663e\u504f\u597d\u4ea4\u4e92\u5f0f\u3001\u53ef\u63a2\u7d22\u7684\u754c\u9762\u800c\u975e\u7b80\u5355\u7684\u9759\u6001\u53ef\u89c6\u5316\u3002\u5173\u952e\u53d1\u73b0\u662fAI\u9a71\u52a8\u7684\u89e3\u91ca\u5e2e\u52a9\u975e\u4e13\u5bb6\u7f29\u5c0f\u4e86\u77e5\u8bc6\u5dee\u8ddd\uff1b\u7edf\u8ba1\u5206\u6790\u663e\u793a\u7528\u6237\u5148\u524d\u7684LLM\u7ecf\u9a8c\u4e0e\u5176\u7406\u89e3\u5206\u6570\u4e4b\u95f4\u6ca1\u6709\u663e\u8457\u76f8\u5173\u6027\uff0c\u8868\u660e\u7cfb\u7edf\u51cf\u5c11\u4e86\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u7528\u6237\u7684\u7406\n\u89e3\u969c\u788d\u3002", "conclusion": "AI\u7cfb\u7edf\u786e\u5b9e\u53ef\u4ee5\u7b80\u5316\u590d\u6742\u7684\u6a21\u578b\u5206\u6790\uff0c\u4f46\u5176\u771f\u6b63\u6f5c\u529b\u5728\u4e8e\u4e0e\u6df1\u601d\u719f\u8651\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u76f8\u7ed3\u5408\uff0c\u4f18\u5148\u8003\u8651\u4ea4\u4e92\u6027\u3001\u5177\u4f53\u6027\u548c\u53d9\u4e8b\u6307\u5bfc\u3002"}}
{"id": "2602.18324", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18324", "abs": "https://arxiv.org/abs/2602.18324", "authors": ["Alexandra Ciobotaru", "Ana-Maria Bucur", "Liviu P. Dinu"], "title": "PsihoRo: Depression and Anxiety Romanian Text Corpus", "comment": "This article was accepted at LREC 2026", "summary": "Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.", "AI": {"tldr": "\u521b\u5efa\u4e86\u9996\u4e2a\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u6291\u90c1\u548c\u7126\u8651\u8bed\u6599\u5e93PsihoRo\uff0c\u586b\u8865\u4e86\u8be5\u8bed\u8a00\u5728\u5fc3\u7406\u5065\u5eb7NLP\u8d44\u6e90\u65b9\u9762\u7684\u7a7a\u767d", "motivation": "\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u76ee\u524d\u6ca1\u6709\u5f00\u6e90\u7684\u5fc3\u7406\u5065\u5eb7\u8bed\u6599\u5e93\uff0c\u800c\u73b0\u6709\u7684\u5fc3\u7406\u8bed\u6599\u5e93\u6536\u96c6\u65b9\u6cd5\uff08\u7279\u522b\u662f\u4ece\u793e\u4ea4\u5a92\u4f53\u6536\u96c6\uff09\u5b58\u5728\u5047\u8bbe\u504f\u5dee\u95ee\u9898\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u6570\u636e\u6536\u96c6\u7b56\u7565", "method": "\u901a\u8fc76\u4e2a\u5f00\u653e\u5f0f\u95ee\u9898\u7ed3\u5408\u6807\u51c6\u5316\u7684PHQ-9\u548cGAD-7\u7b5b\u67e5\u95ee\u5377\u6536\u96c6\u6570\u636e\uff0c\u5171\u83b7\u5f97205\u540d\u53d7\u8bbf\u8005\u7684\u6587\u672c\uff0c\u7136\u540e\u4f7f\u7528\u7edf\u8ba1\u5206\u6790\u3001\u7f57\u9a6c\u5c3c\u4e9a\u8bedLIWC\u6587\u672c\u5206\u6790\u3001\u60c5\u611f\u68c0\u6d4b\u548c\u4e3b\u9898\u5efa\u6a21\u7b49\u65b9\u6cd5\u8fdb\u884c\u5206\u6790", "result": "\u6210\u529f\u521b\u5efa\u4e86PsihoRo\u8bed\u6599\u5e93\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u6291\u90c1\u548c\u7126\u8651\u8bed\u6599\u5e93\uff0c\u867d\u7136\u6837\u672c\u91cf\u8f83\u5c0f\uff08205\u540d\u53d7\u8bbf\u8005\uff09\uff0c\u4f46\u4e3a\u5206\u6790\u7f57\u9a6c\u5c3c\u4e9a\u4eba\u53e3\u7684\u5fc3\u7406\u5065\u5eb7\u6587\u672c\u63d0\u4f9b\u4e86\u57fa\u7840", "conclusion": "PsihoRo\u662f\u7406\u89e3\u7f57\u9a6c\u5c3c\u4e9a\u4eba\u53e3\u5fc3\u7406\u5065\u5eb7\u6587\u672c\u7684\u7b2c\u4e00\u6b65\uff0c\u4e3aNLP\u793e\u533a\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u65b0\u8d44\u6e90\uff0c\u5c55\u793a\u4e86\u901a\u8fc7\u5f00\u653e\u5f0f\u95ee\u9898\u7ed3\u5408\u6807\u51c6\u5316\u95ee\u5377\u6536\u96c6\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u7684\u6709\u6548\u65b9\u6cd5"}}
{"id": "2602.18326", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18326", "abs": "https://arxiv.org/abs/2602.18326", "authors": ["Tao Wu", "Adam Kapelner"], "title": "Predicting Contextual Informativeness for Vocabulary Learning using Deep Learning", "comment": "8 pages, 3 figures, 4 tables", "summary": "We describe a modern deep learning system that automatically identifies informative contextual examples (\\qu{contexts}) for first language vocabulary instruction for high school student. Our paper compares three modeling approaches: (i) an unsupervised similarity-based strategy using MPNet's uniformly contextualized embeddings, (ii) a supervised framework built on instruction-aware, fine-tuned Qwen3 embeddings with a nonlinear regression head and (iii) model (ii) plus handcrafted context features. We introduce a novel metric called the Retention Competency Curve to visualize trade-offs between the discarded proportion of good contexts and the \\qu{good-to-bad} contexts ratio providing a compact, unified lens on model performance. Model (iii) delivers the most dramatic gains with performance of a good-to-bad ratio of 440 all while only throwing out 70\\% of the good contexts. In summary, we demonstrate that a modern embedding model on neural network architecture, when guided by human supervision, results in a low-cost large supply of near-perfect contexts for teaching vocabulary for a variety of target words.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u7b5b\u9009\u9ad8\u4e2d\u82f1\u8bed\u8bcd\u6c47\u6559\u5b66\u7684\u6709\u6548\u8bed\u5883\u793a\u4f8b\uff0c\u901a\u8fc7\u5bf9\u6bd4\u4e09\u79cd\u5efa\u6a21\u65b9\u6cd5\uff0c\u8bc1\u660e\u7ed3\u5408\u76d1\u7763\u5b66\u4e60\u548c\u4eba\u5de5\u7279\u5f81\u7684\u6a21\u578b\u80fd\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u6559\u5b66\u8bed\u5883\u3002", "motivation": "\u4f20\u7edf\u7684\u8bcd\u6c47\u6559\u5b66\u9700\u8981\u6559\u5e08\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u5bfb\u627e\u5408\u9002\u7684\u8bed\u5883\u793a\u4f8b\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u81ea\u52a8\u5316\u7684\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\uff0c\u80fd\u591f\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u5730\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6559\u5b66\u8bed\u5883\uff0c\u89e3\u51b3\u8bcd\u6c47\u6559\u5b66\u4e2d\u8bed\u5883\u8d44\u6e90\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u5efa\u6a21\u65b9\u6cd5\uff1a(1) \u57fa\u4e8eMPNet\u7edf\u4e00\u4e0a\u4e0b\u6587\u5d4c\u5165\u7684\u65e0\u76d1\u7763\u76f8\u4f3c\u5ea6\u7b56\u7565\uff1b(2) \u57fa\u4e8e\u6307\u4ee4\u611f\u77e5\u3001\u5fae\u8c03Qwen3\u5d4c\u5165\u548c\u76d1\u7763\u5b66\u4e60\u7684\u975e\u7ebf\u6027\u56de\u5f52\u6846\u67b6\uff1b(3) \u5728\u65b9\u6cd5(2)\u57fa\u7840\u4e0a\u52a0\u5165\u4eba\u5de5\u8bbe\u8ba1\u7684\u8bed\u5883\u7279\u5f81\u3002\u540c\u65f6\u5f15\u5165\u4e86\u65b0\u7684\u8bc4\u4f30\u6307\u6807\"\u4fdd\u7559\u80fd\u529b\u66f2\u7ebf\"\uff0c\u7528\u4e8e\u53ef\u89c6\u5316\u6a21\u578b\u5728\u4e22\u5f03\u826f\u597d\u8bed\u5883\u6bd4\u4f8b\u548c\u826f\u597d-\u4e0d\u826f\u8bed\u5883\u6bd4\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u6a21\u578b(3)\u8868\u73b0\u6700\u4f73\uff0c\u5728\u4ec5\u4e22\u5f0370%\u826f\u597d\u8bed\u5883\u7684\u60c5\u51b5\u4e0b\uff0c\u8fbe\u5230\u4e86440\u7684\u826f\u597d-\u4e0d\u826f\u8bed\u5883\u6bd4\u7387\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u8fd9\u8868\u660e\u7ed3\u5408\u76d1\u7763\u5b66\u4e60\u548c\u4eba\u5de5\u7279\u5f81\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u751f\u6210\u5927\u91cf\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u6559\u5b66\u8bed\u5883\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u73b0\u4ee3\u5d4c\u5165\u6a21\u578b\u548c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5728\u4eba\u7c7b\u76d1\u7763\u6307\u5bfc\u4e0b\uff0c\u80fd\u591f\u4ee5\u4f4e\u6210\u672c\u5927\u89c4\u6a21\u751f\u6210\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u8bcd\u6c47\u6559\u5b66\u8bed\u5883\uff0c\u4e3a\u591a\u79cd\u76ee\u6807\u8bcd\u6c47\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u6559\u5b66\u8d44\u6e90\u3002"}}
{"id": "2602.18346", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18346", "abs": "https://arxiv.org/abs/2602.18346", "authors": ["Pavithra PM Nair", "Preethu Rose Anish"], "title": "Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System", "comment": null, "summary": "In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.", "AI": {"tldr": "Vichara\u662f\u4e00\u4e2a\u4e13\u4e3a\u5370\u5ea6\u53f8\u6cd5\u7cfb\u7edf\u8bbe\u8ba1\u7684\u6846\u67b6\uff0c\u80fd\u591f\u9884\u6d4b\u548c\u89e3\u91ca\u4e0a\u8bc9\u5224\u51b3\uff0c\u901a\u8fc7\u5206\u89e3\u6848\u4ef6\u6587\u6863\u4e3a\u51b3\u7b56\u70b9\uff0c\u91c7\u7528\u7c7b\u4f3cIRAC\u7684\u7ed3\u6784\u5316\u89e3\u91ca\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u5370\u5ea6\u6cd5\u9662\u9762\u4e34\u5927\u91cf\u6848\u4ef6\u79ef\u538b\uff0c\u4e0a\u8bc9\u6848\u4ef6\u662f\u5176\u4e2d\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\u3002\u4eba\u5de5\u667a\u80fd\u5728\u9884\u6d4b\u6cd5\u5f8b\u5224\u51b3\u65b9\u9762\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u5370\u5ea6\u53f8\u6cd5\u7cfb\u7edf\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "Vichara\u6846\u67b6\u5904\u7406\u82f1\u6587\u4e0a\u8bc9\u6848\u4ef6\u6587\u4ef6\uff0c\u5c06\u5176\u5206\u89e3\u4e3a\u51b3\u7b56\u70b9\uff08\u5305\u542b\u6cd5\u5f8b\u95ee\u9898\u3001\u88c1\u51b3\u673a\u6784\u3001\u7ed3\u679c\u3001\u63a8\u7406\u548c\u65f6\u95f4\u80cc\u666f\u7684\u7ed3\u6784\u5316\u8868\u793a\uff09\u3002\u89e3\u91ca\u91c7\u7528\u53d7IRAC\u542f\u53d1\u5e76\u9002\u5e94\u5370\u5ea6\u6cd5\u5f8b\u63a8\u7406\u7684\u7ed3\u6784\u5316\u683c\u5f0f\u3002", "result": "\u5728PredEx\u548cILDC_expert\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cVichara\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u5224\u51b3\u9884\u6d4b\u57fa\u51c6\u3002GPT-4o mini\u8868\u73b0\u6700\u4f73\uff08F1\uff1aPredEx 81.5\uff0cILDC_expert 80.3\uff09\uff0c\u5176\u6b21\u662fLlama-3.1-8B\u3002\u4eba\u5de5\u8bc4\u4f30\u663e\u793aGPT-4o mini\u5728\u89e3\u91ca\u7684\u6e05\u6670\u5ea6\u3001\u5173\u8054\u6027\u548c\u5b9e\u7528\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "Vichara\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u51b3\u7b56\u70b9\u548c\u89e3\u91ca\uff0c\u4e3a\u5370\u5ea6\u4e0a\u8bc9\u6848\u4ef6\u63d0\u4f9b\u4e86\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u5224\u51b3\u9884\u6d4b\uff0c\u6709\u52a9\u4e8e\u51cf\u8f7b\u53f8\u6cd5\u79ef\u538b\u95ee\u9898\uff0c\u5e76\u4e3a\u6cd5\u5f8b\u4e13\u4e1a\u4eba\u58eb\u63d0\u4f9b\u6709\u6548\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\u3002"}}
{"id": "2602.18351", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18351", "abs": "https://arxiv.org/abs/2602.18351", "authors": ["Jordan Robinson", "Angus R. Williams", "Katie Atkinson", "Anthony G. Cohn"], "title": "Validating Political Position Predictions of Arguments", "comment": "13 pages, 6 figures, 6 tables. Under review", "summary": "Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \\textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $\u03b1=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($\u03b1=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c3a\u5ea6\u9a8c\u8bc1\u6846\u67b6\uff0c\u7ed3\u5408\u70b9\u5f0f\u548c\u6210\u5bf9\u4eba\u7c7b\u6807\u6ce8\uff0c\u7528\u4e8e\u653f\u6cbb\u7acb\u573a\u9884\u6d4b\u4efb\u52a1\uff0c\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u8bba\u8bc1\u77e5\u8bc6\u5e93\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u8868\u793a\u5e38\u9700\u8981\u6355\u6349\u4e3b\u89c2\u3001\u8fde\u7eed\u5c5e\u6027\uff08\u5982\u653f\u6cbb\u7acb\u573a\uff09\uff0c\u8fd9\u4e0e\u5e7f\u6cdb\u63a5\u53d7\u7684\u6210\u5bf9\u9a8c\u8bc1\u9ec4\u91d1\u6807\u51c6\u5b58\u5728\u51b2\u7a81\u3002\u9700\u8981\u89e3\u51b3\u4e3b\u89c2\u8fde\u7eed\u77e5\u8bc6\u9a8c\u8bc1\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u53cc\u5c3a\u5ea6\u9a8c\u8bc1\u6846\u67b6\uff1a\u7ed3\u5408\u70b9\u5f0f\uff08pointwise\uff09\u548c\u6210\u5bf9\uff08pairwise\uff09\u4eba\u7c7b\u6807\u6ce8\u3002\u4f7f\u752822\u4e2a\u8bed\u8a00\u6a21\u578b\u5bf930\u573a\u8fa9\u8bba\u4e2d\u768423,228\u4e2a\u8bba\u70b9\u8fdb\u884c\u653f\u6cbb\u7acb\u573a\u9884\u6d4b\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u77e5\u8bc6\u5e93\u3002", "result": "\u70b9\u5f0f\u8bc4\u4f30\u663e\u793a\u4e2d\u7b49\u6c34\u5e73\u7684\u4eba-\u6a21\u578b\u4e00\u81f4\u6027\uff08Krippendorff's \u03b1=0.578\uff09\uff0c\u53cd\u6620\u5185\u5728\u4e3b\u89c2\u6027\uff1b\u6210\u5bf9\u9a8c\u8bc1\u663e\u793a\u66f4\u5f3a\u7684\u4e00\u81f4\u6027\uff08\u6700\u4f73\u6a21\u578b\u03b1=0.86\uff09\u3002\u6210\u529f\u6784\u5efa\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u7ed3\u6784\u5316\u8bba\u8bc1\u77e5\u8bc6\u5e93\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8d21\u732e\u5305\u62ec\uff1a\u5b9e\u7528\u7684\u4e3b\u89c2\u8fde\u7eed\u77e5\u8bc6\u9a8c\u8bc1\u65b9\u6cd5\u3001\u53ef\u7528\u4e8e\u56fe\u63a8\u7406\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u653f\u6cbb\u9886\u57df\u77e5\u8bc6\u5e93\u3001\u8bc1\u660e\u53ef\u4ee5\u4ece\u70b9\u5f0f\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u4e2d\u63d0\u53d6\u5e8f\u6570\u7ed3\u6784\uff0c\u63a8\u8fdb\u4e86\u4f20\u7edf\u7b26\u53f7\u6216\u5206\u7c7b\u65b9\u6cd5\u4e0d\u8db3\u7684\u9886\u57df\u77e5\u8bc6\u8868\u793a\u80fd\u529b\u3002"}}
{"id": "2602.18420", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18420", "abs": "https://arxiv.org/abs/2602.18420", "authors": ["Jiamin Yao", "Eren Gultepe"], "title": "SPQ: An Ensemble Technique for Large Language Model Compression", "comment": "Accepted to LREC 2026 Main Conference", "summary": "This study presents an ensemble technique, SPQ (SVD-Pruning-Quantization), for large language model (LLM) compression that combines variance-retained singular value decomposition (SVD), activation-based pruning, and post-training linear quantization. Each component targets a different source of inefficiency: i) pruning removes redundant neurons in MLP layers, ii) SVD reduces attention projections into compact low-rank factors, iii) and 8-bit quantization uniformly compresses all linear layers. At matched compression ratios, SPQ outperforms individual methods (SVD-only, pruning-only, or quantization-only) in perplexity, demonstrating the benefit of combining complementary techniques. Applied to LLaMA-2-7B, SPQ achieves up to 75% memory reduction while maintaining or improving perplexity (e.g., WikiText-2 5.47 to 4.91) and preserving accuracy on downstream benchmarks such as C4, TruthfulQA, and GSM8K. Compared to strong baselines like GPTQ and SparseGPT, SPQ offers competitive perplexity and accuracy while using less memory (6.86 GB vs. 7.16 GB for GPTQ). Moreover, SPQ improves inference throughput over GPTQ, achieving up to a 1.9x speedup, which further enhances its practicality for real-world deployment. The effectiveness of SPQ's robust compression through layer-aware and complementary compression techniques may provide practical deployment of LLMs in memory-constrained environments. Code is available at: https://github.com/JiaminYao/SPQ_LLM_Compression/", "AI": {"tldr": "SPQ\u662f\u4e00\u79cd\u7ed3\u5408SVD\u3001\u526a\u679d\u548c\u91cf\u5316\u7684\u96c6\u6210\u538b\u7f29\u6280\u672f\uff0c\u80fd\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11LLM\u7684\u5185\u5b58\u5360\u7528\u548c\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u5728\u5185\u5b58\u53d7\u9650\u7684\u73af\u5883\u4e2d\u5b9e\u9645\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u538b\u7f29\u6280\u672f\u6765\u51cf\u5c11\u6a21\u578b\u7684\u5185\u5b58\u5360\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "SPQ\u96c6\u6210\u4e09\u79cd\u4e92\u8865\u6280\u672f\uff1a1)\u57fa\u4e8e\u6fc0\u6d3b\u7684\u526a\u679d\u53bb\u9664MLP\u5c42\u7684\u5197\u4f59\u795e\u7ecf\u5143\uff1b2)\u4fdd\u7559\u65b9\u5dee\u7684SVD\u5c06\u6ce8\u610f\u529b\u6295\u5f71\u5206\u89e3\u4e3a\u7d27\u51d1\u4f4e\u79e9\u56e0\u5b50\uff1b3)8\u4f4d\u7ebf\u6027\u91cf\u5316\u5747\u5300\u538b\u7f29\u6240\u6709\u7ebf\u6027\u5c42\u3002", "result": "\u5728LLaMA-2-7B\u4e0a\uff0cSPQ\u5b9e\u73b0\u9ad8\u8fbe75%\u7684\u5185\u5b58\u51cf\u5c11\uff0c\u56f0\u60d1\u5ea6\u4ece5.47\u964d\u81f34.91\uff08WikiText-2\uff09\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u4fdd\u6301\u51c6\u786e\u7387\u3002\u76f8\u6bd4GPTQ\u548cSparseGPT\uff0cSPQ\u4f7f\u7528\u66f4\u5c11\u5185\u5b58\uff086.86 GB vs 7.16 GB\uff09\u4e14\u63a8\u7406\u901f\u5ea6\u63d0\u53471.9\u500d\u3002", "conclusion": "SPQ\u901a\u8fc7\u5c42\u611f\u77e5\u548c\u4e92\u8865\u7684\u538b\u7f29\u6280\u672f\uff0c\u4e3aLLM\u5728\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u538b\u7f29\u6bd4\u3001\u6027\u80fd\u548c\u63a8\u7406\u901f\u5ea6\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
