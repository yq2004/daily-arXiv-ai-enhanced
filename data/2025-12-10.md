<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 19]
- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Short-Context Dominance: How Much Local Context Natural Language Actually Needs?](https://arxiv.org/abs/2512.08082)
*Vala Vakilian,Zimeng Wang,Ankit Singh Rawat,Christos Thrampoulidis*

Main category: cs.CL

TL;DR: 该研究验证了"短上下文主导假说"，发现75-80%的长序列仅需最后96个token即可准确预测，并开发了DaMCL指标来检测需要长上下文的挑战性序列，最后提出解码算法来缓解短上下文偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证"短上下文主导假说"——即对于大多数序列，一个小的局部前缀就足以预测下一个token。同时，需要解决如何检测那些需要长上下文的挑战性序列，并缓解短上下文主导带来的LLM输出分布偏见。

Method: 使用大语言模型作为统计预言机，测量重现准确全上下文预测所需的最小上下文长度(MCL)。引入分布感知的MCL(DaMCL)作为实际MCL的代理，该指标不需要知道实际的下一个token，且兼容贪婪解码以外的采样策略。开发了基于DaMCL阈值检测长上下文序列的方法，并设计了利用检测器识别和提升长程相关token的解码算法。

Result: 对于1-7k token的长上下文文档序列，75-80%仅需最后96个token即可准确预测。DaMCL指标能有效检测需要长上下文的挑战性序列。提出的解码算法在问答任务和不同模型架构上都能通过缓解短上下文偏见来提升性能。

Conclusion: 短上下文主导现象确实存在，但可以通过DaMCL指标检测需要长上下文的序列，并通过专门设计的解码算法缓解由此产生的偏见，从而提升LLM在长上下文任务上的性能。

Abstract: We investigate the short-context dominance hypothesis: that for most sequences, a small local prefix suffices to predict their next tokens. Using large language models as statistical oracles, we measure the minimum context length (MCL) needed to reproduce accurate full-context predictions across datasets with sequences of varying lengths. For sequences with 1-7k tokens from long-context documents, we consistently find that 75-80% require only the last 96 tokens at most. Given the dominance of short-context tokens, we then ask whether it is possible to detect challenging long-context sequences for which a short local prefix does not suffice for prediction. We introduce a practical proxy to MCL, called Distributionally Aware MCL (DaMCL), that does not require knowledge of the actual next-token and is compatible with sampling strategies beyond greedy decoding. Our experiments validate that simple thresholding of the metric defining DaMCL achieves high performance in detecting long vs. short context sequences. Finally, to counter the bias that short-context dominance induces in LLM output distributions, we develop an intuitive decoding algorithm that leverages our detector to identify and boost tokens that are long-range-relevant. Across Q&A tasks and model architectures, we confirm that mitigating the bias improves performance.

</details>


### [2] [Adaptation of Embedding Models to Financial Filings via LLM Distillation](https://arxiv.org/abs/2512.08088)
*Eliot Brenner,Dominic Seyler,Manjunath Hegde,Andrei Simion,Koustuv Dasgupta,Bing Xiang*

Main category: cs.CL

TL;DR: 提出一个可扩展的管道，使用通用检索嵌入模型作为基础，从未标记语料库训练专业领域模型，显著提升金融领域信息检索性能。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式大语言模型有进步，但专业对话AI代理的实际应用仍受计算成本、延迟要求和需要精确领域相关度测量的限制。现有嵌入模型在前两个约束上表现良好，但在金融等专业领域的信息检索中表现不佳。

Method: 提出一个可扩展的管道，使用通用检索嵌入模型作为基础，从未标记语料库训练专业模型。方法采用师生模型交互机制，通过检索式挖掘从未标记语料库中获取难正/负例，然后使用这些示例迭代重新训练学生模型权重。每个检索迭代使用精炼的学生模型从语料库中挖掘逐步更难的训练示例用于后续训练迭代。

Result: 在14种财务文件类型上，平均MRR@5提升27.7%，平均DCG@5提升44.6%（基于21,800个查询-文档对）。在FinanceBench的4个文档类别中，有3个类别NDCG得到改善。

Conclusion: 该方法提供了一种经济高效的解决方案，无需劳动密集型人工标注，就能弥合通用模型与专业领域之间的差距，特别适用于RAG系统中的检索嵌入优化。

Abstract: Despite advances in generative large language models (LLMs), practical application of specialized conversational AI agents remains constrained by computation costs, latency requirements, and the need for precise domain-specific relevance measures. While existing embedding models address the first two constraints, they underperform on information retrieval in specialized domains like finance. This paper introduces a scalable pipeline that trains specialized models from an unlabeled corpus using a general purpose retrieval embedding model as foundation. Our method yields an average of 27.7% improvement in MRR$\texttt{@}$5, 44.6% improvement in mean DCG$\texttt{@}$5 across 14 financial filing types measured over 21,800 query-document pairs, and improved NDCG on 3 of 4 document classes in FinanceBench. We adapt retrieval embeddings (bi-encoder) for RAG, not LLM generators, using LLM-judged relevance to distill domain knowledge into a compact retriever. There are prior works which pair synthetically generated queries with real passages to directly fine-tune the retrieval model. Our pipeline differs from these by introducing interaction between student and teacher models that interleaves retrieval-based mining of hard positive/negative examples from the unlabeled corpus with iterative retraining of the student model's weights using these examples. Each retrieval iteration uses the refined student model to mine the corpus for progressively harder training examples for the subsequent training iteration. The methodology provides a cost-effective solution to bridging the gap between general-purpose models and specialized domains without requiring labor-intensive human annotation.

</details>


### [3] [Segment, Embed, and Align: A Universal Recipe for Aligning Subtitles to Signing](https://arxiv.org/abs/2512.08094)
*Zifan Jiang,Youngjoon Jang,Liliane Momeni,Gül Varol,Sarah Ebling,Andrew Zisserman*

Main category: cs.CL

TL;DR: SEA提出了一种通用方法，用于将字幕与连续手语视频对齐，通过预训练模型分割视频、嵌入共享空间，并使用轻量级动态规划进行高效对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于特定语言或数据集的端到端训练，限制了通用性。需要一种能在多种语言和领域工作的通用字幕对齐方法。

Method: SEA框架包含三个步骤：1) 使用预训练模型将视频帧序列分割为单个手势；2) 将每个手势的视频片段嵌入到与文本共享的潜在空间；3) 使用轻量级动态规划程序进行对齐，即使在小时长的视频上也能在CPU上一分钟内完成。

Result: 在四个手语数据集上的实验表明，SEA实现了最先进的对齐性能，能够生成高质量并行数据以推进手语处理研究。

Conclusion: SEA提供了一个灵活、通用的框架，能够适应从小型词典到大型连续语料库的各种场景，其代码和模型已开源，有望推动手语处理领域的发展。

Abstract: The goal of this work is to develop a universal approach for aligning subtitles (i.e., spoken language text with corresponding timestamps) to continuous sign language videos. Prior approaches typically rely on end-to-end training tied to a specific language or dataset, which limits their generality. In contrast, our method Segment, Embed, and Align (SEA) provides a single framework that works across multiple languages and domains. SEA leverages two pretrained models: the first to segment a video frame sequence into individual signs and the second to embed the video clip of each sign into a shared latent space with text. Alignment is subsequently performed with a lightweight dynamic programming procedure that runs efficiently on CPUs within a minute, even for hour-long episodes. SEA is flexible and can adapt to a wide range of scenarios, utilizing resources from small lexicons to large continuous corpora. Experiments on four sign language datasets demonstrate state-of-the-art alignment performance, highlighting the potential of SEA to generate high-quality parallel data for advancing sign language processing. SEA's code and models are openly available.

</details>


### [4] [Universal Adversarial Suffixes Using Calibrated Gumbel-Softmax Relaxation](https://arxiv.org/abs/2512.08123)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 提出通用对抗后缀攻击方法：通过可微优化学习短token序列，附加到任意输入上可跨任务和模型降低分类准确率


<details>
  <summary>Details</summary>
Motivation: 现有对抗提示方法通常是任务或模型特定的，难以比较且迁移性差，需要研究通用、可迁移的对抗攻击方法

Method: 使用Gumbel-Softmax松弛学习可微的"软"后缀，然后离散化用于推理；训练时最大化标签区域的校准交叉熵，同时掩码黄金token防止信息泄露，并加入熵正则化避免崩溃

Result: 在情感分析、自然语言推理、释义检测、常识问答和物理推理等任务上，使用Qwen2-1.5B、Phi-1.5和TinyLlama-1.1B模型验证了攻击有效性和跨任务、跨模型家族的迁移性

Conclusion: 通用对抗后缀是有效的跨任务、跨模型攻击方法，单个后缀就能在不同模型间迁移，显著降低准确率和校准置信度

Abstract: Language models (LMs) are often used as zero-shot or few-shot classifiers by scoring label words, but they remain fragile to adversarial prompts. Prior work typically optimizes task- or model-specific triggers, making results difficult to compare and limiting transferability. We study universal adversarial suffixes: short token sequences (4-10 tokens) that, when appended to any input, broadly reduce accuracy across tasks and models. Our approach learns the suffix in a differentiable "soft" form using Gumbel-Softmax relaxation and then discretizes it for inference. Training maximizes calibrated cross-entropy on the label region while masking gold tokens to prevent trivial leakage, with entropy regularization to avoid collapse. A single suffix trained on one model transfers effectively to others, consistently lowering both accuracy and calibrated confidence. Experiments on sentiment analysis, natural language inference, paraphrase detection, commonsense QA, and physical reasoning with Qwen2-1.5B, Phi-1.5, and TinyLlama-1.1B demonstrate consistent attack effectiveness and transfer across tasks and model families.

</details>


### [5] [Universal Adversarial Suffixes for Language Models Using Reinforcement Learning with Calibrated Reward](https://arxiv.org/abs/2512.08131)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 使用强化学习框架训练对抗性后缀，通过PPO算法优化后缀策略，在多个NLP任务和模型上实现更好的攻击效果和跨任务/模型迁移能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型容易受到短对抗性后缀的影响，但现有方法（梯度搜索或基于规则的方法）通常脆弱且局限于单一任务或模型，需要更鲁棒和可迁移的对抗攻击方法。

Method: 采用强化学习框架，将对抗性后缀视为策略，使用近端策略优化（PPO）算法进行训练，以冻结模型作为奖励计算器。通过校准交叉熵来塑造奖励，消除标签偏差并聚合不同表面形式以提高可迁移性。

Result: 在五个不同的NLP基准数据集（涵盖情感分析、自然语言推理、释义和常识推理）和三个不同语言模型（Qwen2-1.5B Instruct、TinyLlama-1.1B Chat、Phi-1.5）上评估，结果显示RL训练的后缀能持续降低模型准确率，并且比类似类型的先前对抗性触发器在跨任务和模型迁移方面更有效。

Conclusion: 强化学习框架为生成对抗性后缀提供了一种有效方法，相比传统方法具有更好的鲁棒性和可迁移性，能够在不同任务和模型间实现更广泛的攻击效果。

Abstract: Language models are vulnerable to short adversarial suffixes that can reliably alter predictions. Previous works usually find such suffixes with gradient search or rule-based methods, but these are brittle and often tied to a single task or model. In this paper, a reinforcement learning framework is used where the suffix is treated as a policy and trained with Proximal Policy Optimization against a frozen model as a reward oracle. Rewards are shaped using calibrated cross-entropy, removing label bias and aggregating across surface forms to improve transferability. The proposed method is evaluated on five diverse NLP benchmark datasets, covering sentiment, natural language inference, paraphrase, and commonsense reasoning, using three distinct language models: Qwen2-1.5B Instruct, TinyLlama-1.1B Chat, and Phi-1.5. Results show that RL-trained suffixes consistently degrade accuracy and transfer more effectively across tasks and models than previous adversarial triggers of similar genres.

</details>


### [6] [ClinicalTrialsHub: Bridging Registries and Literature for Comprehensive Clinical Trial Access](https://arxiv.org/abs/2512.08193)
*Jiwoo Park,Ruoqi Liu,Avani Jagdale,Andrew Srisuwananukorn,Jing Zhao,Lang Li,Ping Zhang,Sachin Kumar*

Main category: cs.CL

TL;DR: ClinicalTrialsHub是一个整合ClinicalTrials.gov数据和PubMed文献的交互式临床试验搜索平台，通过LLM自动提取结构化信息，将可访问的临床试验数据增加83.8%


<details>
  <summary>Details</summary>
Motivation: 现有临床试验数据分散在ClinicalTrials.gov和PubMed文献中，缺乏统一的搜索平台，限制了患者、临床医生、研究人员和政策制定者获取证据医学信息的能力

Method: 使用GPT-5.1和Gemini-3-Pro等大语言模型，自动解析PubMed全文研究文章提取结构化试验信息，将用户查询转换为结构化数据库搜索，并提供基于证据的问答系统

Result: 系统将可访问的结构化临床试验数据增加了83.8%，通过用户研究（临床医生、研究人员、药学/护理博士生）和系统自动评估验证了信息提取和问答能力

Conclusion: ClinicalTrialsHub通过整合和增强临床试验数据访问，为患者、临床医生、研究人员和政策制定者提供了更全面的证据医学支持平台

Abstract: We present ClinicalTrialsHub, an interactive search-focused platform that consolidates all data from ClinicalTrials.gov and augments it by automatically extracting and structuring trial-relevant information from PubMed research articles. Our system effectively increases access to structured clinical trial data by 83.8% compared to relying on ClinicalTrials.gov alone, with potential to make access easier for patients, clinicians, researchers, and policymakers, advancing evidence-based medicine. ClinicalTrialsHub uses large language models such as GPT-5.1 and Gemini-3-Pro to enhance accessibility. The platform automatically parses full-text research articles to extract structured trial information, translates user queries into structured database searches, and provides an attributed question-answering system that generates evidence-grounded answers linked to specific source sentences. We demonstrate its utility through a user study involving clinicians, clinical researchers, and PhD students of pharmaceutical sciences and nursing, and a systematic automatic evaluation of its information extraction and question answering capabilities.

</details>


### [7] [Are generative AI text annotations systematically biased?](https://arxiv.org/abs/2512.08404)
*Sjoerd B. Stolwijk,Mark Boukes,Damian Trilling*

Main category: cs.CL

TL;DR: 研究发现GLLM在文本标注中存在系统性偏差，虽然F1分数表现尚可，但与人工标注存在显著差异，且不同GLLM之间的相似度高于与人工标注的相似度


<details>
  <summary>Details</summary>
Motivation: 研究旨在调查生成式大语言模型（GLLM）在文本标注任务中是否存在偏差，通过概念性复制Boukes（2024）的人工标注研究来评估GLLM标注的可靠性

Method: 使用四种不同的GLLM（Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b）结合五种不同的提示词，对五个概念（政治内容、互动性、理性、不文明性、意识形态）进行文本标注，并与人工标注结果进行比较

Result: GLLM在F1分数方面表现尚可，但在标注分布（prevalence）上与人工标注存在差异，导致下游分析结果不同，且GLLM之间存在系统性偏差（相互之间的相似度高于与人工标注的相似度），F1分数无法充分反映这种偏差程度

Conclusion: GLLM在文本标注任务中存在系统性偏差，仅依赖F1分数等传统评估指标不足以全面评估标注质量，需要更细致的偏差分析来确保研究结果的可靠性

Abstract: This paper investigates bias in GLLM annotations by conceptually replicating manual annotations of Boukes (2024). Using various GLLMs (Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b) in combination with five different prompts for five concepts (political content, interactivity, rationality, incivility, and ideology). We find GLLMs perform adequate in terms of F1 scores, but differ from manual annotations in terms of prevalence, yield substantively different downstream results, and display systematic bias in that they overlap more with each other than with manual annotations. Differences in F1 scores fail to account for the degree of bias.

</details>


### [8] [What Triggers my Model? Contrastive Explanations Inform Gender Choices by Translation Models](https://arxiv.org/abs/2512.08440)
*Janiça Hackenbuchner,Arda Tezcan,Joke Daems*

Main category: cs.CL

TL;DR: 该研究通过对比解释和显著性归因分析，探索机器翻译模型中性别偏见的起源，而非仅仅测量偏见。研究发现模型归因与人类感知存在显著重叠，并提供了显著词语的语言学分析。


<details>
  <summary>Details</summary>
Motivation: 当前可解释性研究主要关注理解黑盒模型决策，但在性别偏见这一重要问题上研究有限。研究旨在从单纯测量偏见转向探索偏见的起源，理解哪些上下文因素触发翻译模型选择特定的性别屈折变化。

Method: 使用性别模糊的自然源数据，采用对比解释方法计算显著性归因。首先解决缺乏评分阈值的问题，分析不同归因水平的源词对模型性别决策的影响。将显著源词与人类性别感知进行比较，并进行语言学分析。

Result: 研究发现模型归因与人类性别感知存在显著重叠，表明模型在性别决策时关注与人类相似的上下文线索。语言学分析揭示了影响性别决策的具体词语特征。

Conclusion: 理解模型在性别方面的翻译决策至关重要，这些信息应与人类决策进行比较，并用于缓解性别偏见。研究展示了可解释性方法在探索偏见起源方面的价值。

Abstract: Interpretability can be implemented as a means to understand decisions taken by (black box) models, such as machine translation (MT) or large language models (LLMs). Yet, research in this area has been limited in relation to a manifested problem in these models: gender bias. With this research, we aim to move away from simply measuring bias to exploring its origins. Working with gender-ambiguous natural source data, this study examines which context, in the form of input tokens in the source sentence, influences (or triggers) the translation model choice of a certain gender inflection in the target language. To analyse this, we use contrastive explanations and compute saliency attribution. We first address the challenge of a lacking scoring threshold and specifically examine different attribution levels of source words on the model gender decisions in the translation. We compare salient source words with human perceptions of gender and demonstrate a noticeable overlap between human perceptions and model attribution. Additionally, we provide a linguistic analysis of salient words. Our work showcases the relevance of understanding model translation decisions in terms of gender, how this compares to human decisions and that this information should be leveraged to mitigate gender bias.

</details>


### [9] [Soft Inductive Bias Approach via Explicit Reasoning Perspectives in Inappropriate Utterance Detection Using Large Language Models](https://arxiv.org/abs/2512.08480)
*Ju-Young Kim,Ji-Hong Park,Se-Yeon Lee,Sujin Park,Gun-Woo Kim*

Main category: cs.CL

TL;DR: 该研究提出了一种软归纳偏置方法，通过明确定义推理视角来指导韩语大语言模型进行不当言论检测，相比标准监督学习提升了约3.89%的准确率。


<details>
  <summary>Details</summary>
Motivation: 在线游戏和社区中匿名环境下的不当言论经常升级为言语暴力和犯罪行为，需要构建更安全的交流环境。虽然韩语大语言模型和思维链推理受到关注，但在不当言论检测方面的应用研究仍然有限。

Method: 提出软归纳偏置方法，明确定义推理视角来指导推理过程，促进理性决策并防止推理错误。使用该方法对韩语大语言模型进行微调，并比较不同训练策略。

Result: Kanana-1.5模型平均准确率达到87.0046，相比标准监督学习提升了约3.89%。该方法超越了简单的大语言模型知识模仿，通过约束推理视角实现了更精确和一致的判断。

Conclusion: 提出的软归纳偏置方法通过约束推理视角，使大语言模型能够进行更精确和一致的不当言论检测，证明了该方法在构建安全交流环境方面的有效性。

Abstract: Recent incidents in certain online games and communities, where anonymity is guaranteed, show that unchecked inappropriate remarks frequently escalate into verbal abuse and even criminal behavior, raising significant social concerns. Consequently, there is a growing need for research on techniques that can detect inappropriate utterances within conversational texts to help build a safer communication environment. Although large-scale language models trained on Korean corpora and chain-of-thought reasoning have recently gained attention, research applying these approaches to inappropriate utterance detection remains limited. In this study, we propose a soft inductive bias approach that explicitly defines reasoning perspectives to guide the inference process, thereby promoting rational decision-making and preventing errors that may arise during reasoning. We fine-tune a Korean large language model using the proposed method and conduct both quantitative performance comparisons and qualitative evaluations across different training strategies. Experimental results show that the Kanana-1.5 model achieves an average accuracy of 87.0046, improving by approximately 3.89 percent over standard supervised learning. These findings indicate that the proposed method goes beyond simple knowledge imitation by large language models and enables more precise and consistent judgments through constrained reasoning perspectives, demonstrating its effectiveness for inappropriate utterance detection.

</details>


### [10] [Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks](https://arxiv.org/abs/2512.08545)
*Indrajit Kar,Kalathur Chenchu Kishore Kumar*

Main category: cs.CL

TL;DR: 提出了一种分层多智能体架构，在64*64网格上分布轻量级智能体，通过空间课程学习和置信度评估提升长时程推理能力


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和多智能体系统在处理复杂任务分解方面有潜力，但在长时程推理任务中表现不佳且计算成本高昂

Method: 采用分层多智能体架构，将推理分布在64*64网格的轻量级智能体上，使用选择性oracle支持；通过空间课程学习逐步扩展操作区域；集成负对数似然作为置信度度量；使用Thompson Sampling课程管理器自适应选择训练区域

Result: 在空间接地的汉诺塔基准测试中，系统表现出改进的稳定性、减少的oracle使用率以及分布式智能体合作带来的更强长程推理能力

Conclusion: 该分层多智能体架构通过分布式推理、空间课程学习和置信度评估，有效解决了长时程推理任务中的挑战，为机器人操作和规划任务提供了有前景的解决方案

Abstract: Large Language Models and multi-agent systems have shown promise in decomposing complex tasks, yet they struggle with long-horizon reasoning tasks and escalating computation cost. This work introduces a hierarchical multi-agent architecture that distributes reasoning across a 64*64 grid of lightweight agents, supported by a selective oracle. A spatial curriculum progressively expands the operational region of the grid, ensuring that agents master easier central tasks before tackling harder peripheral ones. To improve reliability, the system integrates Negative Log-Likelihood as a measure of confidence, allowing the curriculum to prioritize regions where agents are both accurate and well calibrated. A Thompson Sampling curriculum manager adaptively chooses training zones based on competence and NLL-driven reward signals. We evaluate the approach on a spatially grounded Tower of Hanoi benchmark, which mirrors the long-horizon structure of many robotic manipulation and planning tasks. Results demonstrate improved stability, reduced oracle usage, and stronger long-range reasoning from distributed agent cooperation.

</details>


### [11] [HealthcareNLP: where are we and what is next?](https://arxiv.org/abs/2512.08617)
*Lifeng Han,Paul Rayson,Suzan Verberne,Andrew Moore,Goran Nenadic*

Main category: cs.CL

TL;DR: 这是一个关于医疗领域NLP应用的入门教程，涵盖数据层、NLP评估层和患者层三个层次，包括实践环节，面向医疗NLP从业者和研究人员。


<details>
  <summary>Details</summary>
Motivation: 现有医疗NLP综述要么忽略重要任务（如隐私保护的合成数据生成、可解释性临床NLP），要么遗漏重要方法（如检索增强生成、LLM与KG的神经符号集成），因此需要提供全面的入门概述。

Method: 采用三层层次结构：1) 数据/资源层（标注指南、伦理审批、治理、合成数据）；2) NLP评估层（NER、关系抽取、情感分析等任务及可解释性方法）；3) 患者层（患者参与、健康素养、翻译简化等任务）。包含实践环节。

Result: 提供了一个系统性的医疗NLP教程框架，涵盖从数据准备到患者应用的全流程，帮助参与者理解医疗NLP的关键子领域和挑战。

Conclusion: 该教程为医疗NLP领域提供了全面的入门指导，填补了现有综述的空白，通过三层架构和实践环节帮助不同背景的参与者掌握医疗NLP的核心概念和应用。

Abstract: This proposed tutorial focuses on Healthcare Domain Applications of NLP, what we have achieved around HealthcareNLP, and the challenges that lie ahead for the future. Existing reviews in this domain either overlook some important tasks, such as synthetic data generation for addressing privacy concerns, or explainable clinical NLP for improved integration and implementation, or fail to mention important methodologies, including retrieval augmented generation and the neural symbolic integration of LLMs and KGs. In light of this, the goal of this tutorial is to provide an introductory overview of the most important sub-areas of a patient- and resource-oriented HealthcareNLP, with three layers of hierarchy: data/resource layer: annotation guidelines, ethical approvals, governance, synthetic data; NLP-Eval layer: NLP tasks such as NER, RE, sentiment analysis, and linking/coding with categorised methods, leading to explainable HealthAI; patients layer: Patient Public Involvement and Engagement (PPIE), health literacy, translation, simplification, and summarisation (also NLP tasks), and shared decision-making support. A hands-on session will be included in the tutorial for the audience to use HealthcareNLP applications. The target audience includes NLP practitioners in the healthcare application domain, NLP researchers who are interested in domain applications, healthcare researchers, and students from NLP fields. The type of tutorial is "Introductory to CL/NLP topics (HealthcareNLP)" and the audience does not need prior knowledge to attend this. Tutorial materials: https://github.com/4dpicture/HealthNLP

</details>


### [12] [QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language Models](https://arxiv.org/abs/2512.08646)
*Maximilian Kreutner,Jens Rupprecht,Georg Ahnert,Ahmed Salem,Markus Strohmaier*

Main category: cs.CL

TL;DR: QSTN是一个开源的Python框架，用于通过问卷式提示系统生成LLM响应，支持计算机模拟调查和标注任务，提供无代码界面并显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 需要系统化生成大型语言模型对问卷式提示的响应，以支持计算机模拟调查和标注任务，同时评估问卷呈现、提示扰动和响应生成方法的影响。

Method: 开发了QSTN开源Python框架，包含问卷呈现、提示扰动和响应生成方法的评估系统，提供无代码用户界面，并进行了大规模评估（超过4000万次调查响应）。

Result: 评估显示问题结构和响应生成方法对生成调查响应与人类答案的一致性有显著影响，且可以以极低的计算成本获得结果。框架支持无代码实验设置。

Conclusion: QSTN框架有望支持未来基于LLM的研究的可重复性和可靠性，为研究人员提供了强大的实验工具。

Abstract: We introduce QSTN, an open-source Python framework for systematically generating responses from questionnaire-style prompts to support in-silico surveys and annotation tasks with large language models (LLMs). QSTN enables robust evaluation of questionnaire presentation, prompt perturbations, and response generation methods. Our extensive evaluation ($>40 $ million survey responses) shows that question structure and response generation methods have a significant impact on the alignment of generated survey responses with human answers, and can be obtained for a fraction of the compute cost. In addition, we offer a no-code user interface that allows researchers to set up robust experiments with LLMs without coding knowledge. We hope that QSTN will support the reproducibility and reliability of LLM-based research in the future.

</details>


### [13] [An Agentic AI System for Multi-Framework Communication Coding](https://arxiv.org/abs/2512.08659)
*Bohao Yang,Rui Yang,Joshua M. Biro,Haoyuan Wang,Jessica L. Handley,Brianna Richardson,Sophia Bessias,Nicoleta Economou-Zavlanos,Armando D. Bedoya,Monica Agrawal,Michael M. Zavlanos,Anand Chowdhury,Raj M. Ratwani,Kai Sun,Kathryn I. Pollak,Michael J. Pencina,Chuan Hong*

Main category: cs.CL

TL;DR: MOSAIC是一个基于LangGraph的多框架结构化AI系统，用于临床沟通分析，通过四个核心代理实现代码本选择、数据更新、注释生成和验证，在风湿病学和妇产科领域达到0.928的F1分数。


<details>
  <summary>Details</summary>
Motivation: 临床沟通对患者结果至关重要，但大规模人工标注患者-提供者对话劳动密集、不一致且难以扩展。现有基于大语言模型的方法通常依赖缺乏适应性、可解释性和可靠性的单任务模型，特别是在跨不同沟通框架和临床领域时。

Method: 开发了基于LangGraph架构的多框架结构化AI系统(MOSAIC)，包含四个核心代理：计划代理（代码本选择和流程规划）、更新代理（维护最新检索数据库）、注释代理（应用代码本引导的检索增强生成和动态少样本提示）、验证代理（一致性检查和反馈）。使用26个黄金标准标注转录本进行训练，50个进行测试。

Result: 在测试集上，MOSAIC达到总体F1分数0.928。风湿病学子集表现最佳（F1=0.962），患者行为类别（如患者提问、表达偏好或表现自信）表现最强。消融实验显示MOSAIC优于基准测试。

Conclusion: MOSAIC系统通过多代理架构有效解决了临床沟通标注的扩展性和一致性问题，在不同临床领域和沟通框架中表现出高准确性和可靠性，为临床沟通分析提供了可扩展的解决方案。

Abstract: Clinical communication is central to patient outcomes, yet large-scale human annotation of patient-provider conversation remains labor-intensive, inconsistent, and difficult to scale. Existing approaches based on large language models typically rely on single-task models that lack adaptability, interpretability, and reliability, especially when applied across various communication frameworks and clinical domains. In this study, we developed a Multi-framework Structured Agentic AI system for Clinical Communication (MOSAIC), built on a LangGraph-based architecture that orchestrates four core agents, including a Plan Agent for codebook selection and workflow planning, an Update Agent for maintaining up-to-date retrieval databases, a set of Annotation Agents that applies codebook-guided retrieval-augmented generation (RAG) with dynamic few-shot prompting, and a Verification Agent that provides consistency checks and feedback. To evaluate performance, we compared MOSAIC outputs against gold-standard annotations created by trained human coders. We developed and evaluated MOSAIC using 26 gold standard annotated transcripts for training and 50 transcripts for testing, spanning rheumatology and OB/GYN domains. On the test set, MOSAIC achieved an overall F1 score of 0.928. Performance was highest in the Rheumatology subset (F1 = 0.962) and strongest for Patient Behavior (e.g., patients asking questions, expressing preferences, or showing assertiveness). Ablations revealed that MOSAIC outperforms baseline benchmarking.

</details>


### [14] [Automatic Essay Scoring and Feedback Generation in Basque Language Learning](https://arxiv.org/abs/2512.08713)
*Ekhi Azurmendi,Xabier Arregi,Oier Lopez de Lacalle*

Main category: cs.CL

TL;DR: 首个巴斯克语自动作文评分与反馈生成公开数据集，包含3200篇C1水平作文，专家标注评分与详细反馈，微调开源模型在评分一致性和反馈质量上超越GPT-5等闭源系统。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言（巴斯克语）建立透明、可复现且教育基础扎实的NLP研究基础，填补巴斯克语自动作文评分与反馈生成领域公开数据集的空白。

Method: 构建包含3200篇C1水平作文的数据集，每篇由专家标注五个维度的评分和详细反馈；微调RoBERTa-EusCrawl和Latxa 8B/70B等开源模型进行评分和解释生成；提出结合自动一致性指标和专家验证的新型反馈生成评估方法。

Result: 编码器模型在自动作文评分上保持高可靠性；监督微调的Latxa模型在评分一致性和反馈质量上超越GPT-5和Claude Sonnet 4.5等最先进的闭源系统；微调后的Latxa模型能生成与评分标准对齐、具有教学意义的反馈，并能识别比专有模型更广泛的错误类型。

Conclusion: 该数据集和基准为巴斯克语等低资源语言的透明、可复现且教育基础扎实的NLP研究奠定了基础，展示了开源模型在自动作文评分和反馈生成任务上的优越性能。

Abstract: This paper introduces the first publicly available dataset for Automatic Essay Scoring (AES) and feedback generation in Basque, targeting the CEFR C1 proficiency level. The dataset comprises 3,200 essays from HABE, each annotated by expert evaluators with criterion specific scores covering correctness, richness, coherence, cohesion, and task alignment enriched with detailed feedback and error examples. We fine-tune open-source models, including RoBERTa-EusCrawl and Latxa 8B/70B, for both scoring and explanation generation. Our experiments show that encoder models remain highly reliable for AES, while supervised fine-tuning (SFT) of Latxa significantly enhances performance, surpassing state-of-the-art (SoTA) closed-source systems such as GPT-5 and Claude Sonnet 4.5 in scoring consistency and feedback quality. We also propose a novel evaluation methodology for assessing feedback generation, combining automatic consistency metrics with expert-based validation of extracted learner errors. Results demonstrate that the fine-tuned Latxa model produces criterion-aligned, pedagogically meaningful feedback and identifies a wider range of error types than proprietary models. This resource and benchmark establish a foundation for transparent, reproducible, and educationally grounded NLP research in low-resource languages such as Basque.

</details>


### [15] [Fluent Alignment with Disfluent Judges: Post-training for Lower-resource Languages](https://arxiv.org/abs/2512.08777)
*David Samuel,Lilja Øvrelid,Erik Velldal,Andrey Kutuzov*

Main category: cs.CL

TL;DR: 提出一种针对低资源语言的后训练方法，即使使用不流畅的奖励模型进行对齐，也能保持语言模型的流畅性。


<details>
  <summary>Details</summary>
Motivation: 现有的偏好优化研究主要集中在英语和中文上，低资源语言既缺乏母语者编写的数据集，也缺乏能够生成流畅合成数据的语言模型。因此需要开发一种无需目标语言指令调优数据的流畅偏好对齐语言模型。

Method: 采用基于策略的训练方法，并与两种常见方法进行比较：在机器翻译数据上进行监督微调，以及多语言微调。以挪威博克马尔语为案例进行研究。

Result: 基于策略的训练方法在保持流畅性方面表现关键，优于其他替代方法，且无需依赖难以获取的数据。

Conclusion: 该方法为低资源语言提供了一种有效的偏好对齐解决方案，证明了基于策略训练的重要性，为类似语言的研究提供了可行路径。

Abstract: We propose a post-training method for lower-resource languages that preserves fluency of language models even when aligned by disfluent reward models. Preference-optimization is now a well-researched topic, but previous work has mostly addressed models for English and Chinese. Lower-resource languages lack both datasets written by native speakers and language models capable of generating fluent synthetic data. Thus, in this work, we focus on developing a fluent preference-aligned language model without any instruction-tuning data in the target language. Our approach uses an on-policy training method, which we compare with two common approaches: supervised finetuning on machine-translated data and multilingual finetuning. We conduct a case study on Norwegian Bokmål and evaluate fluency through native-speaker assessments. The results show that the on-policy aspect is crucial and outperforms the alternatives without relying on any hard-to-obtain data.

</details>


### [16] [A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs](https://arxiv.org/abs/2512.08786)
*Mahmoud Srewa,Tianyu Zhao,Salma Elmalaki*

Main category: cs.CL

TL;DR: 本文提出了一种在联邦学习环境中评估LLM与多样化人类偏好对齐的框架，并引入自适应聚合策略来平衡对齐质量与公平性。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习环境中，标准方法往往无法充分代表多样化的人类偏好观点，导致LLM对齐存在公平性问题。

Method: 构建了系统评估框架，在联邦学习设置中让各组本地评估生成结果并产生奖励信号，服务器聚合组级奖励而不访问原始数据。评估了标准聚合技术（最小值、最大值、平均值），并提出了基于历史对齐性能动态调整偏好权重的自适应方案。

Result: 在问答任务上使用PPO-based RLHF管道的实验表明，自适应方法在保持竞争性对齐分数的同时，始终实现更优的公平性。

Conclusion: 这项工作为评估LLM在多样化人群中的行为提供了稳健方法，并为开发真正多元化和公平对齐的模型提供了实用解决方案。

Abstract: This paper addresses the challenge of aligning large language models (LLMs) with diverse human preferences within federated learning (FL) environments, where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group's historical alignment performance. Our experiments on question-answering (Q/A) tasks using a PPO-based RLHF pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating LLM behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.

</details>


### [17] [Ask, Answer, and Detect: Role-Playing LLMs for Personality Detection with Question-Conditioned Mixture-of-Experts](https://arxiv.org/abs/2512.08814)
*Yifan Lyu,Liang Zhang*

Main category: cs.CL

TL;DR: ROME是一个将心理学知识注入人格检测的新框架，通过LLMs模拟用户回答心理测量问卷，将自由文本转换为可解释的问卷证据，显著提升人格检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人格检测方法主要采用"帖子->用户向量->标签"范式，虽然LLMs提升了文本编码能力，但仍受限于标签稀缺性不足以及用户语言与抽象心理构念之间的语义映射不明确。

Method: ROME利用LLMs的角色扮演能力模拟用户回答经过验证的心理测量问卷，将用户帖子转换为可解释的问卷级答案。采用问题条件化的Mixture-of-Experts模块联合路由帖子和问题表示，在多任务学习框架中，将预测答案汇总为可解释的答案向量并与用户表示融合进行最终预测。

Result: 在两个真实世界数据集上的广泛实验表明，ROME始终优于最先进的基线方法，在Kaggle数据集上实现了15.41%的改进。

Conclusion: ROME通过将心理学知识注入人格检测，利用LLMs模拟问卷回答，提供了丰富的中间监督和语义推理链，有效缓解了标签稀缺问题并简化了文本到人格的映射学习。

Abstract: Understanding human personality is crucial for web applications such as personalized recommendation and mental health assessment. Existing studies on personality detection predominantly adopt a "posts -> user vector -> labels" modeling paradigm, which encodes social media posts into user representations for predicting personality labels (e.g., MBTI labels). While recent advances in large language models (LLMs) have improved text encoding capacities, these approaches remain constrained by limited supervision signals due to label scarcity, and under-specified semantic mappings between user language and abstract psychological constructs. We address these challenges by proposing ROME, a novel framework that explicitly injects psychological knowledge into personality detection. Inspired by standardized self-assessment tests, ROME leverages LLMs' role-play capability to simulate user responses to validated psychometric questionnaires. These generated question-level answers transform free-form user posts into interpretable, questionnaire-grounded evidence linking linguistic cues to personality labels, thereby providing rich intermediate supervision to mitigate label scarcity while offering a semantic reasoning chain that guides and simplifies the text-to-personality mapping learning. A question-conditioned Mixture-of-Experts module then jointly routes over post and question representations, learning to answer questionnaire items under explicit supervision. The predicted answers are summarized into an interpretable answer vector and fused with the user representation for final prediction within a multi-task learning framework, where question answering serves as a powerful auxiliary task for personality detection. Extensive experiments on two real-world datasets demonstrate that ROME consistently outperforms state-of-the-art baselines, achieving improvements (15.41% on Kaggle dataset).

</details>


### [18] [Do Depth-Grown Models Overcome the Curse of Depth? An In-Depth Analysis](https://arxiv.org/abs/2512.08819)
*Ferdinand Kapl,Emmanouil Angelis,Tobias Höppe,Kaitlin Maile,Johannes von Oswald,Nino Scherrer,Stefan Bauer*

Main category: cs.CL

TL;DR: 深度逐渐增长的Transformer训练不仅能降低训练成本，还能提升推理性能，本文通过机制分析揭示了这种改进源于更好的深度利用和计算结构优化。


<details>
  <summary>Details</summary>
Motivation: MIDAS方法显示逐渐增加Transformer深度能提升推理性能，但缺乏机制理解。同时，已有研究表明标准Transformer存在"深度诅咒"现象——后半部分层对输出的贡献远小于前半部分。

Method: 通过深度分析技术，研究逐步中间堆叠增长方式如何影响模型。提出MIDAS的轻量级改进，并在下游推理基准上测试。

Result: 逐步增长深度能更有效地利用模型深度，改变残差流结构，促进可置换计算块的形成。改进的MIDAS在推理基准上获得进一步提升。

Conclusion: 深度逐步增长能形成独特的计算电路，克服标准模型中深度利用有限的问题，为高效训练和性能提升提供机制解释。

Abstract: Gradually growing the depth of Transformers during training can not only reduce training cost but also lead to improved reasoning performance, as shown by MIDAS (Saunshi et al., 2024). Thus far, however, a mechanistic understanding of these gains has been missing. In this work, we establish a connection to recent work showing that layers in the second half of non-grown, pre-layernorm Transformers contribute much less to the final output distribution than those in the first half - also known as the Curse of Depth (Sun et al., 2025, Csordás et al., 2025). Using depth-wise analyses, we demonstrate that growth via gradual middle stacking yields more effective utilization of model depth, alters the residual stream structure, and facilitates the formation of permutable computational blocks. In addition, we propose a lightweight modification of MIDAS that yields further improvements in downstream reasoning benchmarks. Overall, this work highlights how the gradual growth of model depth can lead to the formation of distinct computational circuits and overcome the limited depth utilization seen in standard non-grown models.

</details>


### [19] [Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders](https://arxiv.org/abs/2512.08892)
*Guangzhi Xiong,Zhenghao He,Bohan Liu,Sanchit Sinha,Aidong Zhang*

Main category: cs.CL

TL;DR: RAGLens：一种基于稀疏自编码器和LLM内部表征的轻量级RAG幻觉检测器，无需大规模训练或外部LLM查询，提供可解释的检测结果。


<details>
  <summary>Details</summary>
Motivation: 现有RAG幻觉检测方法存在两大问题：1）需要大规模标注数据进行检测器训练；2）依赖外部LLM法官导致高推理成本。虽然有些方法尝试利用LLM内部表征，但准确率有限。

Method: 利用稀疏自编码器（SAEs）解耦LLM内部激活，识别RAG幻觉触发特征。基于信息特征选择和加性特征建模的系统化流程，构建轻量级幻觉检测器RAGLens。

Result: RAGLens在检测性能上优于现有方法，提供可解释的决策依据，并能有效进行后处理缓解不忠实的RAG输出。同时揭示了LLM中幻觉相关信号的分布新见解。

Conclusion: RAGLens通过利用LLM内部表征和稀疏自编码器，实现了高效、轻量且可解释的RAG幻觉检测，为RAG系统的可靠性提供了新解决方案。

Abstract: Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [20] [MixLM: High-Throughput and Effective LLM Ranking via Text-Embedding Mix-Interaction](https://arxiv.org/abs/2512.07846)
*Guoyao Li,Ran He,Shusen Jing,Kayhan Behdin,Yubo Wang,Sundara Raman Ramachandran,Chanh Nguyen,Jian Sheng,Xiaojing Ma,Chuanrui Zhu,Sriram Vasudevan,Muchen Wu,Sayan Ghosh,Lin Su,Qingquan Song,Xiaoqing Wang,Zhipeng Wang,Qing Lan,Yanning Chen,Jingwei Wu,Luke Simon,Wenjing Zhang,Qi Guo,Fedor Borisyuk*

Main category: cs.IR

TL;DR: MixLM是一种新颖的LLM排序框架，通过将物品描述编码为少量嵌入token来减少输入上下文长度，在保持相关性的同时将吞吐量提升10倍，实现了LLM搜索的全流量部署。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推荐和搜索系统中表现出色，但在工业级延迟和吞吐量要求下计算开销过高。特别是交叉编码器排序系统通常需要处理长上下文预填充工作负载，因为模型需要同时处理用户、查询和物品信息。

Method: 提出MixLM框架，使用混合交互（文本和嵌入token的混合）来表示输入。具体方法是将目录中的所有物品编码为少量嵌入token并存储在近线缓存中，在线推理时使用编码后的物品描述，从而将物品长度从数千个文本token减少到几个嵌入token。

Result: 在LinkedIn真实搜索应用中部署MixLM框架，在相同延迟预算下吞吐量提升10.0倍，同时保持相关性指标。效率提升使LLM搜索实现全流量部署，在线A/B测试中每日活跃用户显著增加0.47%。

Conclusion: MixLM通过减少输入上下文长度显著提高了LLM排序系统的效率，同时保持了交叉编码器排序器的语义强度，为工业级LLM搜索部署提供了可行的解决方案。

Abstract: Large language models (LLMs) excel at capturing semantic nuances and therefore show impressive relevance ranking performance in modern recommendation and search systems. However, they suffer from high computational overhead under industrial latency and throughput requirements. In particular, cross-encoder ranking systems often create long context prefill-heavy workloads, as the model has to be presented with the user, query and item information. To this end, we propose MixLM, a novel LLM-based ranking framework, which significantly improves the system throughput via reducing the input context length, while preserving the semantic strength of cross-encoder rankers. In contrast to a standard ranking system where the context is presented to the model as pure text, we propose to use mix-interaction, a mixture of text and embedding tokens to represent the input. Specifically, MixLM encodes all items in the catalog into a few embedding tokens and stores in a nearline cache. The encoded item descriptions are used during online inference, effectively reducing the item length from a few thousand text tokens to a few embedding tokens. We share insights from deploying our MixLM framework to a real-world search application at LinkedIn, including a detailed discussion of our training pipelines, as well as a thorough analysis of our online serving infrastructure optimization. Comparing with strong baselines, MixLM increased throughput by 10.0x under the same latency budget, while maintaining relevance metrics. The efficiency gains delivered by MixLM enabled full-traffic deployment of LLM-powered search, which resulted in a significant 0.47% increase in Daily Active Users (DAU) in online A/B tests.

</details>


### [21] [Detecting Privileged Documents by Ranking Connected Network Entities](https://arxiv.org/abs/2512.08073)
*Jianping Zhang,Han Qin,Nathaniel Huber-Fliflet*

Main category: cs.IR

TL;DR: 基于邮件元数据构建人际关系网络，通过分析实体与律师的互动频率来识别特权文档


<details>
  <summary>Details</summary>
Motivation: 在法律文档审查中，识别特权文档（如律师-客户保密通信）是重要但耗时的任务。传统方法依赖关键词搜索或人工审查，效率低下且容易遗漏。

Method: 从邮件头元数据中提取人类实体构建网络，将实体分类为律师和非律师。核心算法假设与律师频繁互动的个体更可能参与特权通信，通过计算实体在网络中的得分和连接强度来量化这种可能性。

Result: 实验结果表明该算法在特权文档检测中对法律实体的排序具有有效性，能够提升特权文档的识别准确率。

Conclusion: 基于链接分析的方法为特权文档识别提供了有效途径，通过分析实体互动模式能够增强文档审查的效率和准确性。

Abstract: This paper presents a link analysis approach for identifying privileged documents by constructing a network of human entities derived from email header metadata. Entities are classified as either counsel or non-counsel based on a predefined list of known legal professionals. The core assumption is that individuals with frequent interactions with lawyers are more likely to participate in privileged communications. To quantify this likelihood, an algorithm assigns a score to each entity within the network. By utilizing both entity scores and the strength of their connections, the method enhances the identification of privileged documents. Experimental results demonstrate the algorithm's effectiveness in ranking legal entities for privileged document detection.

</details>


### [22] [A Comparative Study of Retrieval Methods in Azure AI Search](https://arxiv.org/abs/2512.08078)
*Qiang Mao,Han Qin,Robert Neary,Charles Wang,Fusheng Wei,Jianping Zhang,Nathaniel Huber-Fliflet*

Main category: cs.IR

TL;DR: 评估Azure AI Search中不同检索方法（关键词、语义、向量、混合、混合语义）在电子取证早期案件评估中的性能，为法律从业者选择RAG配置提供指导。


<details>
  <summary>Details</summary>
Motivation: 律师希望超越传统的关键词和语义搜索，利用大语言模型通过自然语言提问来更高效地查找文档审查中的关键信息。电子取证中的早期案件评估需要快速理解数据并确定关键事实和风险。

Method: 在Microsoft Azure的RAG框架内，比较Azure AI Search的五种检索方法：关键词检索、语义检索、向量检索、混合检索和混合语义检索，评估每种方法在早期案件评估任务中的表现。

Result: 研究呈现了每种检索方法AI生成响应的准确性、相关性和一致性结果，为法律从业者提供了不同RAG配置的性能比较数据。

Conclusion: 法律从业者可以利用本研究结果来优化未来RAG配置的选择，从而提高电子取证早期案件评估的效率和效果。

Abstract: Increasingly, attorneys are interested in moving beyond keyword and semantic search to improve the efficiency of how they find key information during a document review task. Large language models (LLMs) are now seen as tools that attorneys can use to ask natural language questions of their data during document review to receive accurate and concise answers. This study evaluates retrieval strategies within Microsoft Azure's Retrieval-Augmented Generation (RAG) framework to identify effective approaches for Early Case Assessment (ECA) in eDiscovery. During ECA, legal teams analyze data at the outset of a matter to gain a general understanding of the data and attempt to determine key facts and risks before beginning full-scale review. In this paper, we compare the performance of Azure AI Search's keyword, semantic, vector, hybrid, and hybrid-semantic retrieval methods. We then present the accuracy, relevance, and consistency of each method's AI-generated responses. Legal practitioners can use the results of this study to enhance how they select RAG configurations in the future.

</details>


### [23] [Leveraging Machine Learning and Large Language Models for Automated Image Clustering and Description in Legal Discovery](https://arxiv.org/abs/2512.08079)
*Qiang Mao,Fusheng Wei,Robert Neary,Charles Wang,Han Qin,Jianping Zhang,Nathaniel Huber-Fliflet*

Main category: cs.IR

TL;DR: 本文系统研究了自动化图像聚类描述生成方法，通过结合图像聚类、图像描述和大型语言模型，为大规模图像数据集提供高效的组织和描述方案。


<details>
  <summary>Details</summary>
Motivation: 数字图像数量的快速增长给法律发现、数字档案和内容管理带来了巨大挑战。企业和法律团队需要在严格时间压力下组织、分析和从大型图像集合中提取有意义的见解，手动审查既不切实际又成本高昂，因此迫切需要自动化方法来高效组织和描述大规模图像数据集。

Method: 使用K-means聚类将图像分为20个视觉一致的簇，通过Azure AI Vision API生成基础描述。系统评估了三个关键维度：(1) 图像采样策略：随机、基于质心、分层、混合和基于密度的采样与使用所有图像对比；(2) 提示技术：标准提示与思维链提示对比；(3) 描述生成方法：基于LLM的方法与传统TF-IDF和基于模板的方法对比。

Result: 结果显示，每个簇使用20张图像的战略采样与穷尽包含方法表现相当，同时显著降低计算成本，仅分层采样显示适度退化。基于LLM的方法始终优于TF-IDF基线，且标准提示在此任务中优于思维链提示。

Conclusion: 这些发现为部署可扩展、准确的聚类描述系统提供了实用指导，支持法律发现和其他需要自动化组织大型图像集合的领域中的高容量工作流程。

Abstract: The rapid increase in digital image creation and retention presents substantial challenges during legal discovery, digital archive, and content management. Corporations and legal teams must organize, analyze, and extract meaningful insights from large image collections under strict time pressures, making manual review impractical and costly. These demands have intensified interest in automated methods that can efficiently organize and describe large-scale image datasets. This paper presents a systematic investigation of automated cluster description generation through the integration of image clustering, image captioning, and large language models (LLMs). We apply K-means clustering to group images into 20 visually coherent clusters and generate base captions using the Azure AI Vision API. We then evaluate three critical dimensions of the cluster description process: (1) image sampling strategies, comparing random, centroid-based, stratified, hybrid, and density-based sampling against using all cluster images; (2) prompting techniques, contrasting standard prompting with chain-of-thought prompting; and (3) description generation methods, comparing LLM-based generation with traditional TF-IDF and template-based approaches. We assess description quality using semantic similarity and coverage metrics. Results show that strategic sampling with 20 images per cluster performs comparably to exhaustive inclusion while significantly reducing computational cost, with only stratified sampling showing modest degradation. LLM-based methods consistently outperform TF-IDF baselines, and standard prompts outperform chain-of-thought prompts for this task. These findings provide practical guidance for deploying scalable, accurate cluster description systems that support high-volume workflows in legal discovery and other domains requiring automated organization of large image collections.

</details>


### [24] [Exploiting the Randomness of Large Language Models (LLM) in Text Classification Tasks: Locating Privileged Documents in Legal Matters](https://arxiv.org/abs/2512.08083)
*Keith Huffman,Jianping Zhang,Nathaniel Huber-Fliflet,Fusheng Wei,Peter Gronvall*

Main category: cs.IR

TL;DR: 本文实证研究了随机性在基于LLM的法律特权文档检测分类中的作用，发现LLM能有效识别特权文档，随机性控制参数对性能影响很小，而利用随机性的方法能显著提高准确性。


<details>
  <summary>Details</summary>
Motivation: 在法律事务中，文本分类模型常用于筛选大型数据集以查找符合特定标准（如法律特权通信和律师指导文件）的文档。虽然LLM在此类任务中表现出色，但随机性对其分类输出的影响尚未得到充分研究，特别是在法律特权文档检测这一关键应用场景中。

Method: 本文进行了实证研究，重点关注四个维度：1) LLM识别法律特权文档的有效性；2) 随机性控制参数对分类输出的影响；3) 随机性对整体分类性能的影响；4) 利用随机性提高准确性的方法学。研究针对律师-客户特权文档检测任务展开实验。

Result: 实验结果显示：1) LLM能有效识别特权文档；2) 随机性控制参数对分类性能影响很小；3) 提出的利用随机性的方法学能显著提高准确性；4) 该方法还能增强企业在制裁合规流程中对LLM输出的信心。

Conclusion: 随着组织越来越多地依赖LLM增强合规工作流程，减少输出变异性有助于建立内部和监管机构对LLM衍生制裁筛查决策的信心。利用随机性的方法不仅能提高准确性，还能增强企业对LLM输出的信任度，特别是在法律合规等关键应用中。

Abstract: In legal matters, text classification models are most often used to filter through large datasets in search of documents that meet certain pre-selected criteria like relevance to a certain subject matter, such as legally privileged communications and attorney-directed documents. In this context, large language models have demonstrated strong performance. This paper presents an empirical study investigating the role of randomness in LLM-based classification for attorney-client privileged document detection, focusing on four key dimensions: (1) the effectiveness of LLMs in identifying legally privileged documents, (2) the influence of randomness control parameters on classification outputs, (3) their impact on overall classification performance, and (4) a methodology for leveraging randomness to enhance accuracy. Experimental results showed that LLMs can identify privileged documents effectively, randomness control parameters have minimal impact on classification performance, and importantly, our developed methodology for leveraging randomness can have a significant impact on improving accuracy. Notably, this methodology that leverages randomness could also enhance a corporation's confidence in an LLM's output when incorporated into its sanctions-compliance processes. As organizations increasingly rely on LLMs to augment compliance workflows, reducing output variability helps build internal and regulatory confidence in LLM-derived sanctions-screening decisions.

</details>


### [25] [Ontology-Based Knowledge Graph Framework for Industrial Standard Documents via Hierarchical and Propositional Structuring](https://arxiv.org/abs/2512.08398)
*Jiin Park,Hyuna Jeon,Yoonseo Lee,Jisu Hong,Misuk Kim*

Main category: cs.IR

TL;DR: 提出一种基于LLM的三元组抽取方法，将工业标准文档组织成层次语义结构，分解句子和表格为原子命题，构建本体知识图谱，显著提升KG-RAG性能。


<details>
  <summary>Details</summary>
Motivation: 工业标准文档包含大量技术信息和复杂规则，以高度结构化格式呈现（表格、适用范围、约束、例外、数值计算），传统知识图谱构建方法难以有效处理这种复杂结构。

Method: 1) 将文档组织成层次语义结构；2) 将句子和表格分解为基于条件和数值规则的原子命题；3) 通过LLM进行三元组抽取；4) 将抽取结果集成到本体知识图谱中。

Result: 构建了规则、表格、多跳问答和有毒条款检测数据集，实现了本体感知的KG-RAG框架。实验结果显示，相比现有KG-RAG方法，在所有问答类型上都取得了显著性能提升。

Conclusion: 该方法证明了即使对于条件、约束和适用范围交织的工业文档，可靠且可扩展的知识表示也是可行的，为未来领域特定RAG开发和智能文档管理做出了贡献。

Abstract: Ontology-based knowledge graph (KG) construction is a core technology that enables multidimensional understanding and advanced reasoning over domain knowledge. Industrial standards, in particular, contain extensive technical information and complex rules presented in highly structured formats that combine tables, scopes of application, constraints, exceptions, and numerical calculations, making KG construction especially challenging. In this study, we propose a method that organizes such documents into a hierarchical semantic structure, decomposes sentences and tables into atomic propositions derived from conditional and numerical rules, and integrates them into an ontology-knowledge graph through LLM-based triple extraction. Our approach captures both the hierarchical and logical structures of documents, effectively representing domain-specific semantics that conventional methods fail to reflect. To verify its effectiveness, we constructed rule, table, and multi-hop QA datasets, as well as a toxic clause detection dataset, from industrial standards, and implemented an ontology-aware KG-RAG framework for comparative evaluation. Experimental results show that our method achieves significant performance improvements across all QA types compared to existing KG-RAG approaches. This study demonstrates that reliable and scalable knowledge representation is feasible even for industrial documents with intertwined conditions, constraints, and scopes, contributing to future domain-specific RAG development and intelligent document management.

</details>


### [26] [VI-MMRec: Similarity-Aware Training Cost-free Virtual User-Item Interactions for Multimodal Recommendation](https://arxiv.org/abs/2512.08702)
*Jinfeng Xu,Zheyu Chen,Shuo Yang,Jinze Li,Zitong Wan,Hewei Wang,Weijie Liu,Yijie Li,Edith C. H. Ngai*

Main category: cs.IR

TL;DR: VI-MMRec是一个模型无关、无需训练成本的框架，通过基于模态特征相似性的虚拟用户-物品交互来缓解多模态推荐中的数据稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推荐模型虽然表现出色，但仍受限于普遍存在的数据稀疏问题。用户通常只与少量物品交互，导致模型将未观测到的物品任意视为负样本，限制了模型效果。

Method: 提出VI-MMRec框架，通过基于模态特征相似性的虚拟用户-物品交互来丰富稀疏交互。采用两种策略：1) Overlay策略独立聚合模态特定相似性以保留模态特定用户偏好；2) Synergistic策略整体融合跨模态相似性以捕捉互补用户偏好。设计了基于统计信息的权重分配机制，根据数据集特定模态相关性自适应分配权重。

Result: 在六个真实世界数据集上使用七个最先进的多模态推荐模型进行的综合实验验证了VI-MMRec的有效性。该框架能无缝集成到现有模型中，无需修改核心架构，且训练时无额外开销。

Conclusion: VI-MMRec是一个灵活、即插即用的框架，能有效缓解多模态推荐中的数据稀疏问题，显著提升现有模型性能，且易于实际部署。

Abstract: Although existing multimodal recommendation models have shown promising performance, their effectiveness continues to be limited by the pervasive data sparsity problem. This problem arises because users typically interact with only a small subset of available items, leading existing models to arbitrarily treat unobserved items as negative samples. To this end, we propose VI-MMRec, a model-agnostic and training cost-free framework that enriches sparse user-item interactions via similarity-aware virtual user-item interactions. These virtual interactions are constructed based on modality-specific feature similarities of user-interacted items. Specifically, VI-MMRec introduces two different strategies: (1) Overlay, which independently aggregates modality-specific similarities to preserve modality-specific user preferences, and (2) Synergistic, which holistically fuses cross-modal similarities to capture complementary user preferences. To ensure high-quality augmentation, we design a statistically informed weight allocation mechanism that adaptively assigns weights to virtual user-item interactions based on dataset-specific modality relevance. As a plug-and-play framework, VI-MMRec seamlessly integrates with existing models to enhance their performance without modifying their core architecture. Its flexibility allows it to be easily incorporated into various existing models, maximizing performance with minimal implementation effort. Moreover, VI-MMRec introduces no additional overhead during training, making it significantly advantageous for practical deployment. Comprehensive experiments conducted on six real-world datasets using seven state-of-the-art multimodal recommendation models validate the effectiveness of our VI-MMRec.

</details>
