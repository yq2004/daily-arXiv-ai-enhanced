<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 28]
- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Women's Health Benchmark for Large Language Models](https://arxiv.org/abs/2512.17028)
*Victoria-Elisabeth Gruber,Razvan Marinescu,Diego Fajardo,Amin H. Nassar,Christopher Arkfeld,Alexandria Ludlow,Shama Patel,Mehrnoosh Samaei,Valerie Klug,Anna Huber,Marcel Gühner,Albert Botta i Orfila,Irene Lagoja,Kimya Tarr,Haleigh Larson,Mary Beth Howard*

Main category: cs.CL

TL;DR: 论文提出了首个专门评估大语言模型在女性健康领域表现的基准测试WHB，发现当前模型在该领域有约60%的失败率，存在显著性能差距。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型成为数百万人获取健康信息的主要来源，其在女性健康领域的准确性仍未被充分检验，需要专门的评估基准来揭示潜在风险。

Method: 创建了包含96个严格验证模型样本的WHB基准，涵盖5个医学专业领域、3种查询类型和8种错误类型，并评估了13个最先进的大语言模型。

Result: 当前模型在女性健康基准上的失败率约为60%，性能在不同专业领域和错误类型间差异显著。所有模型在"错过紧急情况"指标上普遍表现不佳，而GPT-5等新模型在避免不当建议方面有显著改进。

Conclusion: AI聊天机器人目前尚不能为女性健康提供可靠建议，需要更严格的评估和改进才能在这一关键领域安全部署。

Abstract: As large language models (LLMs) become primary sources of health information for millions, their accuracy in women's health remains critically unexamined. We introduce the Women's Health Benchmark (WHB), the first benchmark evaluating LLM performance specifically in women's health. Our benchmark comprises 96 rigorously validated model stumps covering five medical specialties (obstetrics and gynecology, emergency medicine, primary care, oncology, and neurology), three query types (patient query, clinician query, and evidence/policy query), and eight error types (dosage/medication errors, missing critical information, outdated guidelines/treatment recommendations, incorrect treatment advice, incorrect factual information, missing/incorrect differential diagnosis, missed urgency, and inappropriate recommendations). We evaluated 13 state-of-the-art LLMs and revealed alarming gaps: current models show approximately 60\% failure rates on the women's health benchmark, with performance varying dramatically across specialties and error types. Notably, models universally struggle with "missed urgency" indicators, while newer models like GPT-5 show significant improvements in avoiding inappropriate recommendations. Our findings underscore that AI chatbots are not yet fully able of providing reliable advice in women's health.

</details>


### [2] [Knowledge Distillation with Structured Chain-of-Thought for Text-to-SQL](https://arxiv.org/abs/2512.17053)
*Khushboo Thaker,Yony Bresler*

Main category: cs.CL

TL;DR: Struct-SQL框架使用结构化查询执行计划代替非结构化思维链，通过知识蒸馏训练小型语言模型，在Text-to-SQL任务上实现了8.1%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 企业级Text-to-SQL系统面临成本、安全和性能的三难困境：要么选择昂贵的大型专有模型，要么选择性能较差的小型模型。现有方法依赖非结构化思维链进行知识蒸馏，存在固有模糊性，无法提供清晰可靠的教学信号。

Method: 提出Struct-SQL知识蒸馏框架，使用查询执行计划作为结构化推理蓝图，训练小型语言模型模仿大型语言模型的能力。这种结构化思维链比非结构化思维链提供更明确、更精确的逻辑步骤。

Result: 采用结构化思维链蒸馏的小型模型相比非结构化思维链蒸馏基线实现了8.1%的绝对性能提升。错误分析显示，关键改进因素是在句法错误方面的显著减少。

Conclusion: 使用结构化逻辑蓝图教导模型进行推理，对于小型语言模型中可靠的SQL生成是有益的。结构化推理表示提供了更清晰、更可靠的教学信号，特别是在需要明确和精确逻辑步骤的Text-to-SQL任务中。

Abstract: Deploying accurate Text-to-SQL systems at the enterprise level faces a difficult trilemma involving cost, security and performance. Current solutions force enterprises to choose between expensive, proprietary Large Language Models (LLMs) and low-performing Small Language Models (SLMs). Efforts to improve SLMs often rely on distilling reasoning from large LLMs using unstructured Chain-of-Thought (CoT) traces, a process that remains inherently ambiguous. Instead, we hypothesize that a formal, structured reasoning representation provides a clearer, more reliable teaching signal, as the Text-to-SQL task requires explicit and precise logical steps. To evaluate this hypothesis, we propose Struct-SQL, a novel Knowledge Distillation (KD) framework that trains an SLM to emulate a powerful large LLM. Consequently, we adopt a query execution plan as a formal blueprint to derive this structured reasoning. Our SLM, distilled with structured CoT, achieves an absolute improvement of 8.1% over an unstructured CoT distillation baseline. A detailed error analysis reveals that a key factor in this gain is a marked reduction in syntactic errors. This demonstrates that teaching a model to reason using a structured logical blueprint is beneficial for reliable SQL generation in SLMs.

</details>


### [3] [XLM: A Python package for non-autoregressive language models](https://arxiv.org/abs/2512.17065)
*Dhruvesh Patel,Durga Prasad Maram,Sai Sreenivas Chintha,Benjamin Rozonoyer,Andrew McCallum*

Main category: cs.CL

TL;DR: XLM是一个用于快速实现小型非自回归语言模型的Python包，附带预训练模型库，旨在简化非自回归方法的实现和比较。


<details>
  <summary>Details</summary>
Motivation: 非自回归文本生成领域缺乏标准化的训练和推理库，不同方法的实现多为定制化，难以进行系统比较，且组件复用困难。

Method: 开发XLM Python包，提供标准化的数据整理、损失函数和预测逻辑，并配套预训练模型库xlm-models。

Result: 开源了XLM包（https://github.com/dhruvdcoder/xlm-core），为研究社区提供了快速实现非自回归语言模型的工具和预训练模型。

Conclusion: XLM包降低了非自回归语言模型的实现门槛，促进了该领域方法的标准化和可比较性，有助于研究社区的发展。

Abstract: In recent years, there has been a resurgence of interest in non-autoregressive text generation in the context of general language modeling. Unlike the well-established autoregressive language modeling paradigm, which has a plethora of standard training and inference libraries, implementations of non-autoregressive language modeling have largely been bespoke making it difficult to perform systematic comparisons of different methods. Moreover, each non-autoregressive language model typically requires it own data collation, loss, and prediction logic, making it challenging to reuse common components. In this work, we present the XLM python package, which is designed to make implementing small non-autoregressive language models faster with a secondary goal of providing a suite of small pre-trained models (through a companion xlm-models package) that can be used by the research community. The code is available at https://github.com/dhruvdcoder/xlm-core.

</details>


### [4] [Perturb Your Data: Paraphrase-Guided Training Data Watermarking](https://arxiv.org/abs/2512.17075)
*Pranav Shetty,Mirazul Haque,Petr Babkin,Zhiqiang Ma,Xiaomo Liu,Manuela Veloso*

Main category: cs.CL

TL;DR: SPECTRA是一种用于LLM训练数据检测的水印方法，即使水印数据仅占训练数据的0.001%以下也能可靠检测，通过对比模型token概率实现检测。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在互联网大规模文本数据上训练，训练数据检测对于版权和数据许可执行变得至关重要。需要一种能够在数据被大规模LLM训练后仍能检测其来源的水印方法。

Method: SPECTRA通过使用LLM对文本进行改写，并根据独立的评分模型为每个改写版本分配得分。选择得分与原文本得分最接近的改写版本作为水印文本，以避免引入分布偏移。检测时，通过比较可疑模型的token概率与评分模型的token概率来判断是否使用了水印数据进行训练。

Result: SPECTRA在检测用于训练的数据与未用于训练的数据时，实现了超过九个数量级的p值差距，优于所有基线方法。该方法能够在大规模LLM训练后仍然有效检测水印数据。

Conclusion: SPECTRA为数据所有者提供了一种可扩展的、在发布前部署的水印方案，即使在大规模LLM训练后仍能存活，有效解决了训练数据检测的版权和许可问题。

Abstract: Training data detection is critical for enforcing copyright and data licensing, as Large Language Models (LLM) are trained on massive text corpora scraped from the internet. We present SPECTRA, a watermarking approach that makes training data reliably detectable even when it comprises less than 0.001% of the training corpus. SPECTRA works by paraphrasing text using an LLM and assigning a score based on how likely each paraphrase is, according to a separate scoring model. A paraphrase is chosen so that its score closely matches that of the original text, to avoid introducing any distribution shifts. To test whether a suspect model has been trained on the watermarked data, we compare its token probabilities against those of the scoring model. We demonstrate that SPECTRA achieves a consistent p-value gap of over nine orders of magnitude when detecting data used for training versus data not used for training, which is greater than all baselines tested. SPECTRA equips data owners with a scalable, deploy-before-release watermark that survives even large-scale LLM training.

</details>


### [5] [When F1 Fails: Granularity-Aware Evaluation for Dialogue Topic Segmentation](https://arxiv.org/abs/2512.17083)
*Michael H. Coen*

Main category: cs.CL

TL;DR: 该论文提出对话主题分割的新评估框架，将边界密度和片段连贯性作为主要标准，揭示现有评估方法存在的问题，并建议将主题分割视为选择适当粒度而非预测单一正确边界集。


<details>
  <summary>Details</summary>
Motivation: 现有对话主题分割评估主要依赖严格的边界匹配和F1指标，但这忽略了现代LLM对话系统的实际需求。当对话历史超出固定上下文窗口时，无结构化的上下文积累会降低效率和连贯性。当前的评估方法存在标注粒度不匹配和稀疏边界标签问题，导致报告的性能差异主要由评估伪影而非模型质量驱动。

Method: 论文引入新的评估目标，将边界密度和片段连贯性作为主要标准，同时使用窗口容忍F1（W-F1）。通过对8个不同对话数据集（包括任务导向、开放域、会议风格和合成交互）进行跨数据集实证评估，评估了多种结构不同的对话分割策略，并展示了边界评分与边界选择的分离。

Result: 研究发现：1）跨数据集报告的性能差异主要由标注粒度不匹配和稀疏边界标签驱动，而非模型质量；2）在多种设置下观察到高片段连贯性与极端过分割并存，导致基于精确匹配的F1分数产生误导性低分；3）边界密度和连贯性作为评估标准比传统F1指标更合理。

Conclusion: 对话主题分割应被视为选择适当粒度的问题，而非预测单一正确边界集。最佳实践是将边界评分与边界选择明确分离，并采用边界密度和片段连贯性作为主要评估标准，结合窗口容忍F1，以更准确地反映分割策略的实际效用。

Abstract: Dialogue topic segmentation supports summarization, retrieval, memory management, and conversational continuity. Despite decades of prior work, evaluation practice in dialogue topic segmentation remains dominated by strict boundary matching and F1-based metrics, even as modern LLM-based conversational systems increasingly rely on segmentation to manage conversation history beyond the model's fixed context window, where unstructured context accumulation degrades efficiency and coherence.
  This paper introduces an evaluation objective for dialogue topic segmentation that treats boundary density and segment coherence as primary criteria, alongside window-tolerant F1 (W-F1). Through extensive cross-dataset empirical evaluation, we show that reported performance differences across dialogue segmentation benchmarks are driven not by model quality, but by annotation granularity mismatches and sparse boundary labels. This indicates that many reported improvements arise from evaluation artifacts rather than improved boundary detection.
  We evaluated multiple, structurally distinct dialogue segmentation strategies across eight dialogue datasets spanning task-oriented, open-domain, meeting-style, and synthetic interactions. Across these settings, we observe high segment coherence combined with extreme oversegmentation relative to sparse labels, producing misleadingly low exact-match F1 scores. We show that topic segmentation is best understood as selecting an appropriate granularity rather than predicting a single correct boundary set. We operationalize this view by explicitly separating boundary scoring from boundary selection.

</details>


### [6] [Data Augmentation Supporting a Conversational Agent Designed for Smoking Cessation Support Groups](https://arxiv.org/abs/2512.17092)
*Salar Hashemitaheri,Ian Harris*

Main category: cs.CL

TL;DR: 该研究通过合成数据和真实数据的两级数据增强策略，有效解决了戒烟在线支持群体中意图分类器数据不足的问题，使F1分数提高了32%。


<details>
  <summary>Details</summary>
Motivation: 戒烟在线支持群体面临用户参与度低和污名化问题，自动对话代理可以提高参与度，但缺乏高质量训练数据是主要挑战。

Method: 采用两级数据增强策略：1) 合成数据增强：微调开源LLM识别低F1分数的意图，使用GPT模型生成高质量合成数据；2) 真实数据增强：从相关在线支持环境爬取真实帖子。所有新数据都经过人工评审验证质量。

Result: 合成数据增强覆盖了43%的原帖，并进行了140%的扩展，87%的合成帖子被评估为高质量；真实数据中73%被验证为优质。重训练后的意图分类器F1分数提高了32%，合成和真实数据增强带来了相似的性能提升。

Conclusion: 该研究为数据稀缺领域中的对话代理性能提升提供了一个可复制的框架，证明了两级数据增强策略在改善意图分类器性能方面的有效性。

Abstract: Online support groups for smoking cessation are economical and accessible, yet they often face challenges with low user engagement and stigma. The use of an automatic conversational agent would improve engagement by ensuring that all user comments receive a timely response.). We address the challenge of insufficient high-quality data by employing a two-level data augmentation strategy: synthetic data augmentation and real data augmentation. First, we fine-tuned an open source LLM to classify posts from our existing smoking cessation support groups and identify intents with low F1 (precision+recall) scores. Then, for these intents, we generate additional synthetic data using prompt engineering with the GPT model, with an average of 87\% of the generated synthetic posts deemed high quality by human annotators. Overall, the synthetic augmentation process resulted in 43\% of the original posts being selected for augmentation, followed by 140\% synthetic expansion of these posts. Additionally, we scraped more than 10,000 real posts from a related online support context, of which 73\% were validated as good quality by human annotators. Each synthetic or scraped post underwent rigorous validation involving human reviewers to ensure quality and relevance. The validated new data, combined with the original support group posts, formed an augmented dataset used to retrain the intent classifier. Performance evaluation of the retrained model demonstrated a 32\% improvement in F1, confirming the effectiveness of our data augmentation approach. Synthetic and real post augmentation led to similar performance improvements. This study provides a replicable framework for enhancing conversational agent performance in domains where data scarcity is a critical issue.

</details>


### [7] [Enhancing Long Document Long Form Summarisation with Self-Planning](https://arxiv.org/abs/2512.17179)
*Xiaotang Du,Rohit Saxena,Laura Perez-Beltrachini,Pasquale Minervini,Ivan Titov*

Main category: cs.CL

TL;DR: 提出了一种基于高亮引导的长文本摘要生成方法，通过句子级信息作为内容规划来提高摘要的可追溯性和忠实度。


<details>
  <summary>Details</summary>
Motivation: 长文本摘要生成面临可追溯性和忠实度不足的问题，需要更好的内容规划机制来确保生成摘要的事实一致性。

Method: 采用自规划方法识别重要内容，然后基于规划生成摘要。探索了端到端和两阶段两种变体，发现两阶段流水线在长且信息密集的文档上表现更好。

Result: 在长文本摘要数据集上的实验表明，该方法持续提高了事实一致性，同时保持了相关性和整体质量。在GovReport数据集上，最佳方法将ROUGE-L提高了4.1分，SummaC分数提升了约35%。

Conclusion: 高亮引导的摘要生成有助于保留重要细节，在不同领域产生更准确和深入的摘要，为长文本摘要提供了有效的解决方案。

Abstract: We introduce a novel approach for long context summarisation, highlight-guided generation, that leverages sentence-level information as a content plan to improve the traceability and faithfulness of generated summaries. Our framework applies self-planning methods to identify important content and then generates a summary conditioned on the plan. We explore both an end-to-end and two-stage variants of the approach, finding that the two-stage pipeline performs better on long and information-dense documents. Experiments on long-form summarisation datasets demonstrate that our method consistently improves factual consistency while preserving relevance and overall quality. On GovReport, our best approach has improved ROUGE-L by 4.1 points and achieves about 35% gains in SummaC scores. Qualitative analysis shows that highlight-guided summarisation helps preserve important details, leading to more accurate and insightful summaries across domains.

</details>


### [8] [Mindscape-Aware Retrieval Augmented Generation for Improved Long Context Understanding](https://arxiv.org/abs/2512.17220)
*Yuqing Li,Jiangnan Li,Zheng Lin,Ziyan Zhou,Junjie Wu,Weiping Wang,Jie Zhou,Mo Yu*

Main category: cs.CL

TL;DR: MiA-RAG为RAG系统引入全局上下文感知，通过层次化摘要构建心智景观，指导检索和生成，提升长文本理解能力。


<details>
  <summary>Details</summary>
Motivation: 人类通过全局语义表征理解长复杂文本，而现有RAG系统缺乏全局上下文指导，在长文本任务中表现不佳。

Method: 提出Mindscape-Aware RAG，通过层次化摘要构建心智景观，基于全局语义表征指导检索和生成过程。

Result: 在多样长文本和双语基准测试中，MiA-RAG持续超越基线方法，能将局部细节与全局表征对齐，实现更类人的长文本检索和推理。

Conclusion: MiA-RAG首次为LLM-based RAG系统提供显式全局上下文感知，显著提升长文本理解和推理能力。

Abstract: Humans understand long and complex texts by relying on a holistic semantic representation of the content. This global view helps organize prior knowledge, interpret new information, and integrate evidence dispersed across a document, as revealed by the Mindscape-Aware Capability of humans in psychology. Current Retrieval-Augmented Generation (RAG) systems lack such guidance and therefore struggle with long-context tasks. In this paper, we propose Mindscape-Aware RAG (MiA-RAG), the first approach that equips LLM-based RAG systems with explicit global context awareness. MiA-RAG builds a mindscape through hierarchical summarization and conditions both retrieval and generation on this global semantic representation. This enables the retriever to form enriched query embeddings and the generator to reason over retrieved evidence within a coherent global context. We evaluate MiA-RAG across diverse long-context and bilingual benchmarks for evidence-based understanding and global sense-making. It consistently surpasses baselines, and further analysis shows that it aligns local details with a coherent global representation, enabling more human-like long-context retrieval and reasoning.

</details>


### [9] [Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition](https://arxiv.org/abs/2512.17247)
*Zahra Rahmani,Hossein Sameti*

Main category: cs.CL

TL;DR: 本研究提出了一种针对波斯语的噪声敏感ASR纠错框架，通过结合多个假设和噪声感知建模，显著降低了在噪声环境下的词错误率。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别系统在噪声环境中性能显著下降，特别是对于波斯语等低资源语言。即使是Whisper等最先进的模型在不同信噪比下也难以保持准确性。

Method: 提出了一个鲁棒的噪声敏感ASR纠错框架：1）使用噪声波斯语音生成5个最佳假设；2）引入误差水平噪声表示，捕捉假设间的语义和词元级分歧；3）评估三种模型：未微调的LLaMA-2-7B、仅文本微调模型、以及集成ELN嵌入的噪声条件模型。

Result: 在混合噪声测试集上，提出的微调+ELN模型将词错误率从Whisper基线的31.10%降低到24.84%，显著优于仅文本微调基线的30.79%。原始LLaMA-2-7B模型则使WER增加到64.58%。

Conclusion: 结合多个假设与噪声感知嵌入的方法在噪声现实场景中能有效提升波斯语ASR的鲁棒性，ELN表示能捕捉噪声引起的不确定性，帮助LLM在纠错时评估假设可靠性。

Abstract: Automatic Speech Recognition (ASR) systems suffer significant performance degradation in noisy environments, a challenge that is especially severe for low-resource languages such as Persian. Even state-of-the-art models such as Whisper struggle to maintain accuracy under varying signal-to-noise ratios (SNRs). This study presents a robust noise-sensitive ASR error correction framework that combines multiple hypotheses and noise-aware modeling. Using noisy Persian speech, we generate 5-best hypotheses from a modified Whisper-large decoder. Error Level Noise (ELN) is introduced as a representation that captures semantic- and token-level disagreement across hypotheses, quantifying the linguistic distortions caused by noise. ELN thus provides a direct measure of noise-induced uncertainty, enabling the LLM to reason about the reliability of each hypothesis during correction. Three models are evaluated: (1) a base LLaMA-2-7B model without fine-tuning, (2) a fine-tuned variant trained on text-only hypotheses, and (3) a noise-conditioned model integrating ELN embeddings at both sentence and word levels. Experimental results demonstrate that the ELN-conditioned model achieves substantial reductions in Word Error Rate (WER). Specifically, on the challenging Mixed Noise test set, the proposed Fine-tuned + ELN (Ours) model reduces the WER from a baseline of 31.10\% (Raw Whisper) to 24.84\%, significantly surpassing the Fine-tuned (No ELN) text-only baseline of 30.79\%, whereas the original LLaMA-2-7B model increased the WER to 64.58\%, demonstrating that it is unable to correct Persian errors on its own. This confirms the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust Persian ASR in noisy real-world scenarios.

</details>


### [10] [Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience](https://arxiv.org/abs/2512.17260)
*Jiangjie Chen,Wenxiang Chen,Jiacheng Du,Jinyi Hu,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Wenlei Shi,Zhihong Wang,Mingxuan Wang,Chenrui Wei,Shufa Wei,Huajian Xin,Fan Yang,Weihao Gao,Zheng Yuan,Tianyang Zhan,Zeyu Zheng,Tianxi Zhou,Thomas Hanwen Zhu*

Main category: cs.CL

TL;DR: Seed-Prover 1.5是一个通过大规模智能体强化学习训练的形式定理证明模型，采用高效测试时扩展工作流程，在形式定理证明中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在形式语言（如Lean）中进行定理证明仍然具有挑战性且计算成本高昂，特别是在处理本科及以上水平的数学问题时。需要更高效的方法来提升形式定理证明的能力。

Method: 1. 通过大规模智能体强化学习训练模型，通过与Lean等工具的交互积累经验
2. 采用高效的测试时扩展工作流程，利用自然语言证明的最新进展来弥合自然语言与形式语言之间的差距

Result: 1. 在PutnamBench（本科水平）上解决88%的问题
2. 在Fate-H（研究生水平）上解决80%的问题  
3. 在Fate-X（博士水平）上解决33%的问题
4. 在9小时内解决了Putnam 2025的12个问题中的11个
5. 相比最先进方法，以更小的计算预算获得更优性能

Conclusion: 通过高质量形式反馈驱动的经验学习扩展，在形式数学推理方面具有巨大潜力。Seed-Prover 1.5展示了智能体强化学习在提升形式定理证明能力和效率方面的有效性。

Abstract: Large language models have recently made significant progress to generate rigorous mathematical proofs. In contrast, utilizing LLMs for theorem proving in formal languages (such as Lean) remains challenging and computationally expensive, particularly when addressing problems at the undergraduate level and beyond. In this work, we present \textbf{Seed-Prover 1.5}, a formal theorem-proving model trained via large-scale agentic reinforcement learning, alongside an efficient test-time scaling (TTS) workflow. Through extensive interactions with Lean and other tools, the model continuously accumulates experience during the RL process, substantially enhancing the capability and efficiency of formal theorem proving. Furthermore, leveraging recent advancements in natural language proving, our TTS workflow efficiently bridges the gap between natural and formal languages. Compared to state-of-the-art methods, Seed-Prover 1.5 achieves superior performance with a smaller compute budget. It solves \textbf{88\% of PutnamBench} (undergraduate-level), \textbf{80\% of Fate-H} (graduate-level), and \textbf{33\% of Fate-X} (PhD-level) problems. Notably, using our system, we solved \textbf{11 out of 12 problems} from Putnam 2025 within 9 hours. Our findings suggest that scaling learning from experience, driven by high-quality formal feedback, holds immense potential for the future of formal mathematical reasoning.

</details>


### [11] [AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators](https://arxiv.org/abs/2512.17267)
*Michael J. Ryan,Yanzhe Zhang,Amol Salunkhe,Yi Chu,Di Xu,Diyi Yang*

Main category: cs.CL

TL;DR: AutoMetrics框架通过结合预定义指标库和基于少量人工反馈的LLM评估标准，在低数据约束下合成评估指标，显著提升与人工评分的相关性。


<details>
  <summary>Details</summary>
Motivation: 评估用户面向的AI应用在开放领域（如旅行规划、临床笔记生成、对话）中具有挑战性。黄金标准是用户反馈或行为信号，但这些在原型和研究项目中往往稀缺，或者对于系统优化来说过于缓慢。

Method: AutoMetrics框架结合检索MetricBank（包含48个预定义指标的集合）和基于少量人工反馈自动生成的LLM-as-a-Judge评估标准，通过回归分析将这些指标组合以最大化与人工信号的相关性。

Result: 在5个不同任务中，AutoMetrics将Kendall相关系数比LLM-as-a-Judge提高了33.4%，同时仅需要少于100个反馈点。AutoMetrics可以作为代理奖励函数，效果与可验证奖励相当。

Conclusion: AutoMetrics框架能够从昂贵的测量方法转向可解释的自动指标，加速LLM应用的适应性评估。研究团队发布了完整的AutoMetrics工具包和MetricBank。

Abstract: Evaluating user-facing AI applications remains a central challenge, especially in open-ended domains such as travel planning, clinical note generation, or dialogue. The gold standard is user feedback (e.g., thumbs up/down) or behavioral signals (e.g., retention), but these are often scarce in prototypes and research projects, or too-slow to use for system optimization. We present AutoMetrics, a framework for synthesizing evaluation metrics under low-data constraints. AutoMetrics combines retrieval from MetricBank, a collection of 48 metrics we curate, with automatically generated LLM-as-a-Judge criteria informed by lightweight human feedback. These metrics are composed via regression to maximize correlation with human signal. AutoMetrics takes you from expensive measures to interpretable automatic metrics. Across 5 diverse tasks, AutoMetrics improves Kendall correlation with human ratings by up to 33.4% over LLM-as-a-Judge while requiring fewer than 100 feedback points. We show that AutoMetrics can be used as a proxy reward to equal effect as a verifiable reward. We release the full AutoMetrics toolkit and MetricBank to accelerate adaptive evaluation of LLM applications.

</details>


### [12] [Subjective Question Generation and Answer Evaluation using NLP](https://arxiv.org/abs/2512.17289)
*G. M. Refatul Islam,Safwan Shaheer,Yaseen Nur,Mohammad Rafid Hamid*

Main category: cs.CL

TL;DR: 该研究旨在开发自动化主观问题生成和答案评估的NLP模型，以帮助教师评估学生作业并增强学生自我评估能力。


<details>
  <summary>Details</summary>
Motivation: 虽然NLP在客观问题生成方面已有进展，但自动化主观问题生成和答案评估仍处于发展阶段。这样的系统可以帮助教师评估学生作业，同时让学生通过自我评估来增强学习体验。

Method: 研究计划改进现有NLP模型或开发新模型，从文本输入中实现自动化主观问题生成和答案评估。

Result: 论文摘要未提供具体实验结果，但研究目标是开发能够从文本输入生成主观问题并评估答案的自动化系统。

Conclusion: 自动化主观问题生成和答案评估系统在教育领域具有重要价值，能够减轻教师负担并促进学生自主学习，是NLP在教育应用中有待进一步发展的方向。

Abstract: Natural Language Processing (NLP) is one of the most revolutionary technologies today. It uses artificial intelligence to understand human text and spoken words. It is used for text summarization, grammar checking, sentiment analysis, and advanced chatbots and has many more potential use cases. Furthermore, it has also made its mark on the education sector. Much research and advancements have already been conducted on objective question generation; however, automated subjective question generation and answer evaluation are still in progress. An automated system to generate subjective questions and evaluate the answers can help teachers assess student work and enhance the student's learning experience by allowing them to self-assess their understanding after reading an article or a chapter of a book. This research aims to improve current NLP models or make a novel one for automated subjective question generation and answer evaluation from text input.

</details>


### [13] [Governance-Aware Hybrid Fine-Tuning for Multilingual Large Language Models](https://arxiv.org/abs/2512.17344)
*Haomin Qi,Chengbo Huang,Zihan Dai,Yunkai Gao*

Main category: cs.CL

TL;DR: 本文提出了一个治理感知的混合微调框架，用于大语言模型的多语言低资源适应，结合梯度对齐的低秩更新与结构化正交变换，并通过轻量级数据治理步骤提升准确性和跨语言平衡。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在多语言低资源环境下的适应面临挑战，需要在有限计算预算下实现准确性、校准和跨语言平衡，同时保持训练稳定性。

Method: 提出治理感知的混合微调框架，核心算法结合梯度对齐的低秩更新与结构化正交变换，通过层间混合实现，并在选定子层引入酉约束以稳定深度优化。同时采用轻量级无标签数据治理步骤，包括语言识别、近重复去除和质量过滤。

Result: 在XNLI和FLORES数据集上，混合方法相比强大的PEFT基线获得一致提升，保持方向平衡并改进概率校准。对轻量级正字法变体更具弹性，简单治理步骤带来叠加效益。训练足迹测量显示适度开销和有利的成本-质量边界。

Conclusion: 混合和酉约束PEFT与实用数据治理相结合，为资源高效的多语言适应提供了稳定且可访问的路径。

Abstract: We present a governance-aware hybrid fine-tuning framework for multilingual, low-resource adaptation of large language models. The core algorithm combines gradient-aligned low-rank updates with structured orthogonal transformations through layer-wise mixing and introduces unitary constraints in selected sub-layers to stabilize deep optimization. In tandem with lightweight, label-free data governance steps, including language identification, near-duplicate removal, and quality filtering, the framework targets accuracy, calibration, and cross-language parity under tight compute budgets. Across XNLI and FLORES, the hybrid approach delivers consistent gains over strong PEFT baselines while maintaining directional balance and improving probability calibration, as shown in Tables II and III. It is more resilient to lightweight orthographic variants, as shown in Table IV, and benefits additively from simple governance steps, as shown in Table V. Training footprint measurements indicate modest overhead and a favorable cost-quality frontier, as shown in Table VI and Figure 2. Together, these results show that hybrid and unitary PEFT provide a stable and accessible path to resource-efficient multilingual adaptation when paired with practical data governance.

</details>


### [14] [Stakeholder Suite: A Unified AI Framework for Mapping Actors, Topics and Arguments in Public Debates](https://arxiv.org/abs/2512.17347)
*Mohamed Chenene,Jeanne Rouhier,Jean Daniélou,Mihir Sarkar,Elena Cabrio*

Main category: cs.CL

TL;DR: 提出Stakeholder Suite框架，通过统一管道分析公共辩论中的参与者、话题和论点，帮助基础设施和能源项目团队可视化影响网络、识别争议并支持决策


<details>
  <summary>Details</summary>
Motivation: 基础设施和能源项目的公共辩论涉及复杂的利益相关者网络、论点和不断演变的叙事。现有媒体智能工具主要依赖描述性分析且透明度有限，需要更深入理解这些动态以预测争议并制定参与策略。

Method: 提出Stakeholder Suite框架，结合参与者检测、话题建模、论点提取和立场分类的统一管道。该系统在操作环境中部署，以多个能源基础设施项目为案例进行研究。

Result: 框架在检索精度和立场准确性方面表现强劲，在试点用例中产生75%的相关论点。工具在操作使用中被证明有效：帮助项目团队可视化影响网络、识别新兴争议并支持基于证据的决策。

Conclusion: Stakeholder Suite框架为公共辩论分析提供了细粒度、基于来源的洞察，同时保持对不同领域的适应性。该工具超越了定量指标，在实际操作中证明了对决策支持的有效性。

Abstract: Public debates surrounding infrastructure and energy projects involve complex networks of stakeholders, arguments, and evolving narratives. Understanding these dynamics is crucial for anticipating controversies and informing engagement strategies, yet existing tools in media intelligence largely rely on descriptive analytics with limited transparency. This paper presents Stakeholder Suite, a framework deployed in operational contexts for mapping actors, topics, and arguments within public debates. The system combines actor detection, topic modeling, argument extraction and stance classification in a unified pipeline. Tested on multiple energy infrastructure projects as a case study, the approach delivers fine-grained, source-grounded insights while remaining adaptable to diverse domains. The framework achieves strong retrieval precision and stance accuracy, producing arguments judged relevant in 75% of pilot use cases. Beyond quantitative metrics, the tool has proven effective for operational use: helping project teams visualize networks of influence, identify emerging controversies, and support evidence-based decision-making.

</details>


### [15] [Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers](https://arxiv.org/abs/2512.17351)
*Zeyuan Allen-Zhu*

Main category: cs.CL

TL;DR: 论文提出了CANON LAYERS——一种轻量级架构组件，通过促进相邻token间的水平信息流动来增强语言模型的核心能力，并在学术规模预训练中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在学术规模预训练（如13亿参数、1000亿token）中，语言模型的架构差异难以评估，因为结果常被噪声和随机性主导。需要一种方法来隔离和评估模型的核心能力。

Method: 引入受控的合成预训练任务框架，并提出了CANON LAYERS——基于音乐术语"canon"的轻量级架构组件，计算相邻token表示的加权和，可无缝集成到Transformer、线性注意力、状态空间模型等序列架构中。

Result: 展示了12个关键结果：CANON LAYERS将推理深度提升2倍，增强推理广度、知识操作等能力；使弱架构（如NoPE）达到RoPE水平，使线性注意力模型媲美Mamba2/GDN等SOTA线性模型；在合成任务和真实学术规模预训练中都得到验证。

Conclusion: 合成任务框架为隔离学术规模下常被掩盖的核心模型能力提供了经济、原则性的途径。借助无限高质量数据，甚至可以预测未来架构在训练流程改进（如更好的数据管理或RL后训练）后的表现，解锁更深层次的推理和分层推断能力。

Abstract: Understanding architectural differences in language models is challenging, especially at academic-scale pretraining (e.g., 1.3B parameters, 100B tokens), where results are often dominated by noise and randomness. To overcome this, we introduce controlled synthetic pretraining tasks that isolate and evaluate core model capabilities. Within this framework, we discover CANON LAYERS: lightweight architectural components -- named after the musical term "canon" -- that promote horizontal information flow across neighboring tokens. Canon layers compute weighted sums of nearby token representations and integrate seamlessly into Transformers, linear attention, state-space models, or any sequence architecture.
  We present 12 key results. This includes how Canon layers enhance reasoning depth (e.g., by $2\times$), reasoning breadth, knowledge manipulation, etc. They lift weak architectures like NoPE to match RoPE, and linear attention to rival SOTA linear models like Mamba2/GDN -- validated both through synthetic tasks and real-world academic-scale pretraining. This synthetic playground offers an economical, principled path to isolate core model capabilities often obscured at academic scales. Equipped with infinite high-quality data, it may even PREDICT how future architectures will behave as training pipelines improve -- e.g., through better data curation or RL-based post-training -- unlocking deeper reasoning and hierarchical inference.

</details>


### [16] [UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models](https://arxiv.org/abs/2512.17385)
*Jiajun Wu,Jian Yang,Wei Zhang,Lin Jing,Yuqing Ma,Ensheng Shi,Yuchi Ma,Zhoujun Li,Xianglong Liu*

Main category: cs.CL

TL;DR: IPC是一个无监督框架，通过探测LLM内部知识和置信模式进行代码生成，无需外部语料库，在资源受限场景下训练代码LLM。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成任务中表现出色，但依赖昂贵且难以大规模获取的有监督训练数据（如问答对）或无监督数据（如代码片段）。需要解决这一限制。

Method: 提出IPC无监督框架，通过问题空间探测、测试理解探测、解决方案空间探测、知识整合与强化来探测LLM内部知识和置信模式。使用自一致性机制和基于表示的质量估计来识别可靠代码候选，训练UCoder（无监督学习的编码器）。

Result: 在多个代码基准测试中验证，无监督方法能达到与有监督方法相当的性能，同时显著减少对标记数据和计算资源的依赖。分析实验表明模型内部状态包含丰富的代码质量和正确性信号。

Conclusion: IPC框架展示了利用LLM内部状态信号进行有效无监督代码生成学习的可行性，为资源受限场景下训练代码LLM开辟了新方向。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in code generation tasks. However, their effectiveness heavily relies on supervised training with extensive labeled (e.g., question-answering pairs) or unlabeled datasets (e.g., code snippets), which are often expensive and difficult to obtain at scale. To address this limitation, this paper introduces a method IPC, an unsupervised framework that leverages Internal Probing of LLMs for Code generation without any external corpus, even unlabeled code snippets. We introduce the problem space probing, test understanding probing, solution space probing, and knowledge consolidation and reinforcement to probe the internal knowledge and confidence patterns existing in LLMs. Further, IPC identifies reliable code candidates through self-consistency mechanisms and representation-based quality estimation to train UCoder (coder with unsupervised learning). We validate the proposed approach across multiple code benchmarks, demonstrating that unsupervised methods can achieve competitive performance compared to supervised approaches while significantly reducing the dependency on labeled data and computational resources. Analytic experiments reveal that internal model states contain rich signals about code quality and correctness, and that properly harnessing these signals enables effective unsupervised learning for code generation tasks, opening new directions for training code LLMs in resource-constrained scenarios.

</details>


### [17] [Are Vision Language Models Cross-Cultural Theory of Mind Reasoners?](https://arxiv.org/abs/2512.17394)
*Zabir Al Nazi,G M Shahariar,Abrar Hossain,Wei Peng*

Main category: cs.CL

TL;DR: 研究人员创建了CulturalToM-VQA基准测试，包含5095个问题，用于评估视觉语言模型在不同文化背景下的心理理论推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型越来越多地应用于社会性任务，但它们在跨文化心理理论推理方面的能力尚未得到充分探索。当前的心理理论评估基准往往以西方文化为中心，缺乏对不同文化背景下的社会认知能力的系统评估。

Method: 通过VLM辅助的人机协作流程构建数据集：人类专家首先收集包含文化丰富元素的图像（传统、仪式、社交互动），然后使用VLM生成结构化的心理理论场景描述，最后将这些描述精炼成问答对，涵盖六种心理理论任务和四个复杂度等级。

Result: 创建了CulturalToM-VQA基准测试，包含5095个问题，涵盖文化线索如仪式、服饰、手势和人际动态，能够系统评估心理理论推理的多个方面，包括心理状态归因、错误信念推理、非字面沟通、社会规范违反、视角协调和多智能体推理。

Conclusion: CulturalToM-VQA填补了现有心理理论评估的空白，提供了一个能够评估AI系统在不同文化背景下社会认知能力的基准测试，对于开发更具文化敏感性和普适性的AI系统具有重要意义。

Abstract: Theory of Mind (ToM) -- the ability to attribute beliefs, desires, and emotions to others -- is fundamental for human social intelligence, yet remains a major challenge for artificial agents. Existing Vision-Language Models (VLMs) are increasingly applied in socially grounded tasks, but their capacity for cross-cultural ToM reasoning is largely unexplored. In this work, we introduce CulturalToM-VQA, a new evaluation benchmark containing 5095 questions designed to probe ToM reasoning across diverse cultural contexts through visual question answering. The dataset captures culturally grounded cues such as rituals, attire, gestures, and interpersonal dynamics, enabling systematic evaluation of ToM reasoning beyond Western-centric benchmarks. Our dataset is built through a VLM-assisted human-in-the-loop pipeline, where human experts first curate culturally rich images across traditions, rituals, and social interactions; a VLM then assist in generating structured ToM-focused scene descriptions, which are refined into question-answer pairs spanning a taxonomy of six ToM tasks and four graded complexity levels. The resulting dataset covers diverse theory of mind facets such as mental state attribution, false belief reasoning, non-literal communication, social norm violations, perspective coordination, and multi-agent reasoning.

</details>


### [18] [Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection](https://arxiv.org/abs/2512.17630)
*Menna Elgabry,Ali Hamdi*

Main category: cs.CL

TL;DR: 本文提出了一种基于置信度加权和可信度感知的集成框架，用于文本情感检测，结合了多种小型Transformer模型，在DAIR-AI数据集上实现了93.5%的宏F1分数，超越了大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 传统集成方法通常依赖同质化架构，而本文受到Condorcet陪审团定理启发，旨在通过架构多样化的小型LLMs集成来提升情感检测性能，同时保持错误多样性并利用各模型的独特偏置。

Method: 结合BERT、RoBERTa、DistilBERT、DeBERTa和ELECTRA五种架构多样化的小型Transformer模型，每个模型都经过完整微调。采用双重加权投票机制，整合全局可信度（验证F1分数）和局部置信度（实例级概率）来动态加权模型贡献。

Result: 在DAIR-AI数据集上达到93.5%的宏F1分数，超越了Falcon、Mistral、Qwen和Phi等大型LLMs（即使经过LoRA微调）。总参数量仅595M，比参数量达7B的模型更参数高效且鲁棒。

Conclusion: 精心设计的小型微调模型集成可以在专门的自然语言处理任务（如情感检测）中超越大型语言模型，证明了参数效率与性能的平衡可以通过智能集成实现。

Abstract: This paper introduces a confidence-weighted, credibility-aware ensemble framework for text-based emotion detection, inspired by Condorcet's Jury Theorem (CJT). Unlike conventional ensembles that often rely on homogeneous architectures, our approach combines architecturally diverse small transformer-based large language models (sLLMs) - BERT, RoBERTa, DistilBERT, DeBERTa, and ELECTRA, each fully fine-tuned for emotion classification. To preserve error diversity, we minimize parameter convergence while taking advantage of the unique biases of each model. A dual-weighted voting mechanism integrates both global credibility (validation F1 score) and local confidence (instance-level probability) to dynamically weight model contributions. Experiments on the DAIR-AI dataset demonstrate that our credibility-confidence ensemble achieves a macro F1 score of 93.5 percent, surpassing state-of-the-art benchmarks and significantly outperforming large-scale LLMs, including Falcon, Mistral, Qwen, and Phi, even after task-specific Low-Rank Adaptation (LoRA). With only 595M parameters in total, our small LLMs ensemble proves more parameter-efficient and robust than models up to 7B parameters, establishing that carefully designed ensembles of small, fine-tuned models can outperform much larger LLMs in specialized natural language processing (NLP) tasks such as emotion detection.

</details>


### [19] [Linear Personality Probing and Steering in LLMs: A Big Five Study](https://arxiv.org/abs/2512.17639)
*Michel Frising,Daniel Balcells*

Main category: cs.CL

TL;DR: 研究发现LLM人格特征可以通过线性方向探测和引导，在选择题任务中效果显著，但在开放式生成或上下文丰富的情况下影响有限。


<details>
  <summary>Details</summary>
Motivation: LLM展现出独特且一致的人格特征，这对信任和参与度有重要影响。虽然人格框架对描述和控制LLM行为很有价值，但现有方法要么成本高昂（后训练），要么脆弱（提示工程）。线性方向的探测和引导成为一种廉价高效的替代方案。

Method: 使用Llama 3.3 70B模型生成406个虚构角色及其大五人格特质分数描述。用这些描述和Alpaca问卷问题提示模型，采样隐藏激活值。通过线性回归学习激活空间中每层的线性方向，测试其在探测和引导模型行为方面的有效性。

Result: 与特质分数对齐的线性方向在人格检测中是有效的探针，但其引导能力强烈依赖于上下文：在选择题任务中能产生可靠效果，但在开放式生成或提示中存在额外上下文时影响有限。

Conclusion: 线性方向可以作为LLM人格特征的有效探测工具，但作为引导工具时受上下文限制。这表明需要更复杂的干预策略来可靠地引导模型行为。

Abstract: Large language models (LLMs) exhibit distinct and consistent personalities that greatly impact trust and engagement. While this means that personality frameworks would be highly valuable tools to characterize and control LLMs' behavior, current approaches remain either costly (post-training) or brittle (prompt engineering). Probing and steering via linear directions has recently emerged as a cheap and efficient alternative. In this paper, we investigate whether linear directions aligned with the Big Five personality traits can be used for probing and steering model behavior. Using Llama 3.3 70B, we generate descriptions of 406 fictional characters and their Big Five trait scores. We then prompt the model with these descriptions and questions from the Alpaca questionnaire, allowing us to sample hidden activations that vary along personality traits in known, quantifiable ways. Using linear regression, we learn a set of per-layer directions in activation space, and test their effectiveness for probing and steering model behavior. Our results suggest that linear directions aligned with trait-scores are effective probes for personality detection, while their steering capabilities strongly depend on context, producing reliable effects in forced-choice tasks but limited influence in open-ended generation or when additional context is present in the prompt.

</details>


### [20] [Simulstream: Open-Source Toolkit for Evaluation and Demonstration of Streaming Speech-to-Text Translation Systems](https://arxiv.org/abs/2512.17648)
*Marco Gaido,Sara Papi,Mauro Cettolo,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: simulstream：首个专用于流式语音翻译统一评估和演示的开源框架，支持增量解码和重翻译方法，提供交互式Web界面。


<details>
  <summary>Details</summary>
Motivation: 现有流式语音翻译研究依赖的SimulEval库已不再维护，不支持输出修订系统，且设计用于短片段而非长音频流处理，缺乏方便的演示功能。

Method: 开发了simulstream框架，专为长音频流处理设计，支持增量解码和重翻译方法，提供统一的质量和延迟评估平台。

Result: simulstream是首个开源流式语音翻译框架，能够比较不同系统在质量和延迟方面的表现，并提供交互式Web演示界面。

Conclusion: simulstream解决了当前流式语音翻译评估工具的局限性，为研究社区提供了统一的评估和演示平台，支持更全面的系统比较。

Abstract: Streaming Speech-to-Text Translation (StreamST) requires producing translations concurrently with incoming speech, imposing strict latency constraints and demanding models that balance partial-information decision-making with high translation quality. Research efforts on the topic have so far relied on the SimulEval repository, which is no longer maintained and does not support systems that revise their outputs. In addition, it has been designed for simulating the processing of short segments, rather than long-form audio streams, and it does not provide an easy method to showcase systems in a demo. As a solution, we introduce simulstream, the first open-source framework dedicated to unified evaluation and demonstration of StreamST systems. Designed for long-form speech processing, it supports not only incremental decoding approaches, but also re-translation methods, enabling for their comparison within the same framework both in terms of quality and latency. In addition, it also offers an interactive web interface to demo any system built within the tool.

</details>


### [21] [Peeking Into The Future For Contextual Biasing](https://arxiv.org/abs/2512.17657)
*Ramaneswaran Selvakumar,Cindy Tseng,Eesung Kim,Vijendra Raj Apsingekar,Yun Tang*

Main category: cs.CL

TL;DR: 提出一种基于注意力编码器解码器模型的上下文偏置方法，通过多令牌预测来识别命名实体，无需额外实体编码器或交叉注意力层。


<details>
  <summary>Details</summary>
Motivation: 端到端ASR模型在一般转录任务上表现出色，但在识别罕见或未见过的命名实体（如联系人姓名、地点）时表现不佳，而这些实体对于虚拟助手等下游应用至关重要。

Method: 使用候选命名实体列表的上下文偏置方法，不仅预测下一个令牌，同时预测多个未来令牌，使模型能够"窥视未来"并评分实体列表中的候选实体。直接利用多令牌预测logits，无需额外实体编码器或交叉注意力层。

Result: 在Librispeech上的实验表明，与基线AED模型相比，该方法在命名实体词错误率上实现了高达50.34%的相对改进。

Conclusion: 提出的上下文偏置方法通过多令牌预测有效提升了ASR模型对命名实体的识别能力，同时保持了架构的简洁性。

Abstract: While end-to-end (E2E) automatic speech recognition (ASR) models excel at general transcription, they struggle to recognize rare or unseen named entities (e.g., contact names, locations), which are critical for downstream applications like virtual assistants. In this paper, we propose a contextual biasing method for attention based encoder decoder (AED) models using a list of candidate named entities. Instead of predicting only the next token, we simultaneously predict multiple future tokens, enabling the model to "peek into the future" and score potential candidate entities in the entity list. Moreover, our approach leverages the multi-token prediction logits directly without requiring additional entity encoders or cross-attention layers, significantly reducing architectural complexity. Experiments on Librispeech demonstrate that our approach achieves up to 50.34% relative improvement in named entity word error rate compared to the baseline AED model.

</details>


### [22] [Toward Ethical AI Through Bayesian Uncertainty in Neural Question Answering](https://arxiv.org/abs/2512.17677)
*Riccardo Di Sipio*

Main category: cs.CL

TL;DR: 该研究探索使用贝叶斯推理量化问答神经网络的不确定性，比较拉普拉斯近似与MAP估计，以提升不确定性校准和选择性预测能力


<details>
  <summary>Details</summary>
Motivation: 当前神经网络在问答系统中缺乏不确定性量化能力，这限制了模型的可靠性和可解释性。研究旨在通过贝叶斯方法让模型能够表达"我不知道"的响应，从而促进更负责任和伦理的神经问答系统部署。

Method: 研究采用渐进式方法：1）在Iris数据集上使用多层感知机展示后验推理如何传递预测置信度；2）将贝叶斯推理扩展到语言模型，首先应用于冻结的头部；3）最终应用于LoRA自适应的transformer模型，在CommonsenseQA基准上进行评估。重点比较拉普拉斯近似与最大后验估计。

Result: 研究展示了贝叶斯方法如何改善不确定性校准和选择性预测。通过让模型在置信度低时弃权（abstain），不仅提高了可解释性，还实现了更可靠的预测。研究重点不在于达到最先进的准确率，而在于展示不确定性量化的价值。

Conclusion: 贝叶斯推理为神经问答系统提供了有效的量化不确定性方法。通过选择性预测和"我不知道"的响应能力，贝叶斯方法有助于开发更负责任、更伦理的AI系统，增强了模型的可解释性和部署安全性。

Abstract: We explore Bayesian reasoning as a means to quantify uncertainty in neural networks for question answering. Starting with a multilayer perceptron on the Iris dataset, we show how posterior inference conveys confidence in predictions. We then extend this to language models, applying Bayesian inference first to a frozen head and finally to LoRA-adapted transformers, evaluated on the CommonsenseQA benchmark. Rather than aiming for state-of-the-art accuracy, we compare Laplace approximations against maximum a posteriori (MAP) estimates to highlight uncertainty calibration and selective prediction. This allows models to abstain when confidence is low. An ``I don't know'' response not only improves interpretability but also illustrates how Bayesian methods can contribute to more responsible and ethical deployment of neural question-answering systems.

</details>


### [23] [When the Gold Standard isn't Necessarily Standard: Challenges of Evaluating the Translation of User-Generated Content](https://arxiv.org/abs/2512.17738)
*Lydia Nishimwe,Benoît Sagot,Rachel Bawden*

Main category: cs.CL

TL;DR: 本文探讨了用户生成内容(UGC)翻译的挑战，分析了UGC中的非标准语言现象，提出了翻译操作分类，并研究了大型语言模型在UGC翻译中的表现及其与数据集指导原则的一致性。


<details>
  <summary>Details</summary>
Motivation: 用户生成内容(UGC)中大量使用非标准语言（如拼写错误、俚语、字符重复和表情符号），这使得评估UGC翻译变得特别困难，因为"好"翻译的标准取决于输出中期望的标准化程度。

Method: 研究了四个UGC数据集的人工翻译指导原则，推导出12种非标准现象和5种翻译操作（标准化、复制、转移、省略、审查）的分类法。通过大型语言模型(LLMs)的案例研究，分析了翻译分数对明确UGC翻译指令提示的敏感性。

Result: 分析揭示了UGC处理方式的显著差异，导致参考翻译中存在标准化程度的谱系。翻译分数对包含明确UGC翻译指令的提示高度敏感，当这些指令与数据集指导原则一致时，翻译质量会提高。

Conclusion: 当保留UGC风格很重要时，公平评估需要模型和指标都能理解翻译指导原则。呼吁在数据集创建时制定清晰的指导原则，并开发可控的、指导原则感知的UGC翻译评估框架。

Abstract: User-generated content (UGC) is characterised by frequent use of non-standard language, from spelling errors to expressive choices such as slang, character repetitions, and emojis. This makes evaluating UGC translation particularly challenging: what counts as a "good" translation depends on the level of standardness desired in the output. To explore this, we examine the human translation guidelines of four UGC datasets, and derive a taxonomy of twelve non-standard phenomena and five translation actions (NORMALISE, COPY, TRANSFER, OMIT, CENSOR). Our analysis reveals notable differences in how UGC is treated, resulting in a spectrum of standardness in reference translations. Through a case study on large language models (LLMs), we show that translation scores are highly sensitive to prompts with explicit translation instructions for UGC, and that they improve when these align with the dataset's guidelines. We argue that when preserving UGC style is important, fair evaluation requires both models and metrics to be aware of translation guidelines. Finally, we call for clear guidelines during dataset creation and for the development of controllable, guideline-aware evaluation frameworks for UGC translation.

</details>


### [24] [Affect, Body, Cognition, Demographics, and Emotion: The ABCDE of Text Features for Computational Affective Science](https://arxiv.org/abs/2512.17752)
*Jan Philip Wahle,Krishnapriya Vishnubhotla,Bela Gipp,Saif M. Mohammad*

Main category: cs.CL

TL;DR: ABCDE数据集是一个大规模文本语料库，包含4亿多条来自社交媒体、博客、书籍和AI生成来源的文本，标注了情感、身体、认知、人口统计和情绪等多维度特征，旨在促进跨学科研究。


<details>
  <summary>Details</summary>
Motivation: 目前计算情感科学和计算社会科学研究依赖于标注的语言数据，但现有资源和算法在发现、访问和使用方面存在障碍，特别是对计算机科学领域之外的研究者来说。

Method: 构建了ABCDE数据集，收集超过4亿条来自社交媒体、博客、书籍和AI生成来源的文本话语，并标注了情感、身体、认知、人口统计和情绪等多维度特征。

Result: 创建了一个大规模、多来源、多维度标注的文本数据集，涵盖情感、身体、认知、人口统计和情绪等特征，为跨学科研究提供资源支持。

Conclusion: ABCDE数据集通过提供大规模、多维度的标注文本数据，降低了计算情感科学和计算社会科学研究的门槛，促进了跨学科合作与研究。

Abstract: Work in Computational Affective Science and Computational Social Science explores a wide variety of research questions about people, emotions, behavior, and health. Such work often relies on language data that is first labeled with relevant information, such as the use of emotion words or the age of the speaker. Although many resources and algorithms exist to enable this type of labeling, discovering, accessing, and using them remains a substantial impediment, particularly for practitioners outside of computer science. Here, we present the ABCDE dataset (Affect, Body, Cognition, Demographics, and Emotion), a large-scale collection of over 400 million text utterances drawn from social media, blogs, books, and AI-generated sources. The dataset is annotated with a wide range of features relevant to computational affective and social science. ABCDE facilitates interdisciplinary research across numerous fields, including affective science, cognitive science, the digital humanities, sociology, political science, and computational linguistics.

</details>


### [25] [AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora](https://arxiv.org/abs/2512.17756)
*Zhihan Zhou,Daqian Shi,Rui Song,Lida Shi,Xiaolei Diao,Hao Xu*

Main category: cs.CL

TL;DR: AncientBench：首个针对出土文献古文字理解的基准测试，评估大语言模型在古文字字形、发音、意义和上下文理解四个维度的能力。


<details>
  <summary>Details</summary>
Motivation: 现有中文基准测试主要针对现代汉语和传世文献的古汉语，缺乏对出土文献古汉语的评估。古文字理解对考古学和中华文明研究很重要，需要专门基准来评估大语言模型在这方面的能力。

Method: 提出AncientBench基准，包含字形理解、发音理解、意义理解和上下文理解四个维度，设计十项具体任务（如部首、声旁、同音字、完形填空、翻译等）。召集考古研究人员进行实验评估，建立古文字模型作为基线，并对当前表现最佳的大语言模型进行广泛实验。

Result: 实验结果显示大语言模型在古文字场景具有巨大潜力，但与人类专家仍存在差距。基准测试为古文字理解提供了全面的评估框架。

Conclusion: AncientBench填补了出土文献古文字理解评估的空白，将促进大语言模型在考古学和古汉语领域的发展与应用。

Abstract: Comprehension of ancient texts plays an important role in archaeology and understanding of Chinese history and civilization. The rapid development of large language models needs benchmarks that can evaluate their comprehension of ancient characters. Existing Chinese benchmarks are mostly targeted at modern Chinese and transmitted documents in ancient Chinese, but the part of excavated documents in ancient Chinese is not covered. To meet this need, we propose the AncientBench, which aims to evaluate the comprehension of ancient characters, especially in the scenario of excavated documents. The AncientBench is divided into four dimensions, which correspond to the four competencies of ancient character comprehension: glyph comprehension, pronunciation comprehension, meaning comprehension, and contextual comprehension. The benchmark also contains ten tasks, including radical, phonetic radical, homophone, cloze, translation, and more, providing a comprehensive framework for evaluation. We convened archaeological researchers to conduct experimental evaluations, proposed an ancient model as baseline, and conducted extensive experiments on the currently best-performing large language models. The experimental results reveal the great potential of large language models in ancient textual scenarios as well as the gap with humans. Our research aims to promote the development and application of large language models in the field of archaeology and ancient Chinese language.

</details>


### [26] [Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity](https://arxiv.org/abs/2512.17769)
*Tanjim Taharat Aurpa,Farzana Akter,Md. Mehedi Hasan,Shakil Ahmed,Shifat Ara Rafiq,Fatema Khan*

Main category: cs.CL

TL;DR: 该研究提出了一种用于孟加拉语医学实体识别的多BERT集成方法，在缺乏标注数据的低资源语言环境下取得了89.58%的最高准确率，比单层BERT模型提升了11.80%。


<details>
  <summary>Details</summary>
Motivation: 医学实体识别对医疗自动化系统发展至关重要，但目前大多数研究集中在英语，像孟加拉语这样的低资源语言研究不足。同时，缺乏高质量标注数据集是低资源语言医学实体识别的主要挑战。

Method: 首先评估了BERT、DistilBERT、ELECTRA和RoBERTa等Transformer模型，然后提出了一种新颖的多BERT集成方法。为解决数据稀缺问题，专门为孟加拉语医学实体识别任务开发了高质量标注数据集。

Result: 多BERT集成方法在所有基线模型中表现最佳，达到89.58%的最高准确率，比单层BERT模型提升了11.80%的准确率。通过多种性能指标验证了模型的鲁棒性和适用性。

Conclusion: 该研究证明了多BERT集成模型在改善孟加拉语医学实体识别方面的潜力，为低资源医疗NLP的进一步发展奠定了基础。开发的数据集也为后续研究提供了重要资源。

Abstract: Medical Entity Recognition (MedER) is an essential NLP task for extracting meaningful entities from the medical corpus. Nowadays, MedER-based research outcomes can remarkably contribute to the development of automated systems in the medical sector, ultimately enhancing patient care and outcomes. While extensive research has been conducted on MedER in English, low-resource languages like Bangla remain underexplored. Our work aims to bridge this gap. For Bangla medical entity recognition, this study first examined a number of transformer models, including BERT, DistilBERT, ELECTRA, and RoBERTa. We also propose a novel Multi-BERT Ensemble approach that outperformed all baseline models with the highest accuracy of 89.58%. Notably, it provides an 11.80% accuracy improvement over the single-layer BERT model, demonstrating its effectiveness for this task. A major challenge in MedER for low-resource languages is the lack of annotated datasets. To address this issue, we developed a high-quality dataset tailored for the Bangla MedER task. The dataset was used to evaluate the effectiveness of our model through multiple performance metrics, demonstrating its robustness and applicability. Our findings highlight the potential of Multi-BERT Ensemble models in improving MedER for Bangla and set the foundation for further advancements in low-resource medical NLP.

</details>


### [27] [DEER: A Comprehensive and Reliable Benchmark for Deep-Research Expert Reports](https://arxiv.org/abs/2512.17776)
*Janghoon Han,Heegyu Kim,Changho Lee,Dahm Lee,Min Hyung Park,Hosung Song,Stanley Jungkyu Choi,Moontae Lee,Honglak Lee*

Main category: cs.CL

TL;DR: DEER是一个评估专家级深度研究报告的基准，包含50个跨13个领域的研究任务、专家评估分类体系和文档级事实核查架构，能提供可解释的系统诊断。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准缺乏系统性专家报告标准，LLM法官评估可能忽略需要专家判断的问题，且源验证通常只覆盖有限显式引用而非报告整体事实可靠性。

Method: 1) 构建包含50个报告写作任务和13个领域的DEER基准；2) 建立专家评估分类体系(7维度25子维度130细粒度评估项)；3) 提供任务特定专家指导以提高LLM法官评估一致性；4) 提出文档级事实核查架构，提取验证报告中所有声明(包括引用和未引用的)。

Result: DEER与人类专家判断密切相关，能提供可解释的系统优劣势诊断，量化外部证据质量，全面评估报告的事实可靠性。

Conclusion: DEER基准通过系统化评估分类和文档级事实核查，解决了现有专家级研究报告评估的局限性，为深度研究系统提供了更可靠、可解释的评估框架。

Abstract: As large language models (LLMs) advance, deep research systems can generate expert-level reports via multi-step reasoning and evidence-based synthesis, but evaluating such reports remains challenging. Existing benchmarks often lack systematic criteria for expert reporting, evaluations that rely heavily on LLM judges can fail to capture issues that require expert judgment, and source verification typically covers only a limited subset of explicitly cited statements rather than report-wide factual reliability. We introduce DEER, a benchmark for evaluating expert-level deep research reports. DEER comprises 50 report-writing tasks spanning 13 domains and an expert-grounded evaluation taxonomy (7 dimensions, 25 sub-dimension) operationalized into 130 fine-grained rubric items. DEER further provides task-specific expert guidance to help LLM judges assess expert-level report quality more consistently. Complementing rubric-based assessment, we propose a document-level fact-checking architecture that extracts and verifies all claims across the entire report, including both cited and uncited ones, and quantifies external-evidence quality. DEER correlates closely with human expert judgments and yields interpretable diagnostics of system strengths and weaknesses.

</details>


### [28] [ShareChat: A Dataset of Chatbot Conversations in the Wild](https://arxiv.org/abs/2512.17843)
*Yueru Yan,Tuc Nguyen,Bo Su,Melissa Lieffers,Thai Le*

Main category: cs.CL

TL;DR: ShareChat是一个大规模跨平台语料库，包含来自ChatGPT、Claude、Gemini、Perplexity和Grok五个主要平台的142,808个对话和超过660,000轮互动，保留了原生平台特性，涵盖101种语言，时间跨度为2023年4月至2025年10月。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集将大语言模型视为通用文本生成器，忽略了不同平台独特的界面设计和功能特性，这些界面上下文对用户交互有重要影响。

Method: 从五个主要LLM平台（ChatGPT、Claude、Gemini、Perplexity、Grok）收集公开分享的URL，构建包含142,808个对话和超过660,000轮互动的大规模语料库，保留原生平台特性如推理轨迹、来源链接和代码工件。

Result: 创建了ShareChat数据集，具有比现有数据集更长的上下文窗口和更大的交互深度。通过三个代表性分析展示了数据集的实用性：分析对话完整性以衡量用户意图满意度、评估内容生成中的来源引用行为、进行时间分析以追踪使用模式演变。

Conclusion: ShareChat为研究社区提供了理解真实用户-LLM聊天机器人交互的重要资源，填补了现有数据集忽略平台界面上下文影响的空白。

Abstract: While Large Language Models (LLMs) have evolved into distinct platforms with unique interface designs and capabilities, existing public datasets treat models as generic text generators, stripping away the interface context that actively shapes user interaction. To address this limitation, we present ShareChat, a large-scale, cross-platform corpus comprising 142,808 conversations and over 660,000 turns collected from publicly shared URLs across five major platforms: ChatGPT, Claude, Gemini, Perplexity, and Grok. ShareChat distinguishes itself by preserving native platform affordances often lost in standard logs, including reasoning traces, source links, and code artifacts, while spanning 101 languages over the period from April 2023 to October 2025. Furthermore, ShareChat offers substantially longer context windows and greater interaction depth than prior datasets. We demonstrate the dataset's multifaceted utility through three representative analyses: (1) analyzing conversation completeness to measure user intent satisfaction; (2) evaluating source citation behaviors in content generation; and (3) conducting temporal analysis to track evolving usage patterns. This work provides the community with a vital and timely resource for understanding authentic user-LLM chatbot interactions in the wild.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [29] [A Reproducible and Fair Evaluation of Partition-aware Collaborative Filtering](https://arxiv.org/abs/2512.17015)
*Domenico De Gioia,Claudio Pomo,Ludovico Boratto,Tommaso Di Noia*

Main category: cs.IR

TL;DR: 该论文对FPSR/FPSR+分区感知协同过滤模型进行了可复现基准测试，发现该模型家族虽未始终达到最高性能，但在长尾场景下表现优异，揭示了分区、全局组件和枢纽设计带来的准确率-覆盖率权衡。


<details>
  <summary>Details</summary>
Motivation: 基于相似性的协同过滤模型存在二次计算成本的可扩展性问题，分区范式成为平衡效果与效率的有效策略。然而，FPSR/FPSR+模型的评估存在可复现性挑战，先前研究使用来源不明的数据分割并遗漏了一些相似性基线，难以进行公平比较。

Method: 提出了透明、完全可复现的FPSR和FPSR+基准测试框架，对分区感知协同过滤模型进行系统评估，包括与相似性基线的全面比较。

Result: FPSR模型家族并未始终达到最高性能水平，但整体保持竞争力，验证了其设计选择，并在长尾场景下显示出显著优势。研究揭示了分区、全局组件和枢纽设计带来的准确率-覆盖率权衡。

Conclusion: 该研究阐明了分区感知相似性建模在何种情况下最为有益，并为可扩展推荐系统设计在可复现协议下提供了实用指导。强调了可复现评估在推荐系统研究中的重要性。

Abstract: Similarity-based collaborative filtering (CF) models have long demonstrated strong offline performance and conceptual simplicity. However, their scalability is limited by the quadratic cost of maintaining dense item-item similarity matrices. Partitioning-based paradigms have recently emerged as an effective strategy for balancing effectiveness and efficiency, enabling models to learn local similarities within coherent subgraphs while maintaining a limited global context. In this work, we focus on the Fine-tuning Partition-aware Similarity Refinement (FPSR) framework, a prominent representative of this family, as well as its extension, FPSR+. Reproducible evaluation of partition-aware collaborative filtering remains challenging, as prior FPSR/FPSR+ reports often rely on splits of unclear provenance and omit some similarity-based baselines, thereby complicating fair comparison. We present a transparent, fully reproducible benchmark of FPSR and FPSR+. Based on our results, the family of FPSR models does not consistently perform at the highest level. Overall, it remains competitive, validates its design choices, and shows significant advantages in long-tail scenarios. This highlights the accuracy-coverage trade-offs resulting from partitioning, global components, and hub design. Our investigation clarifies when partition-aware similarity modeling is most beneficial and offers actionable guidance for scalable recommender system design under reproducible protocols.

</details>


### [30] [Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations](https://arxiv.org/abs/2512.17027)
*Erica Coppolillo,Simone Mungari*

Main category: cs.IR

TL;DR: 对维基百科和Grokipedia两大百科平台的搜索引擎进行首次比较分析，发现两者都存在搜索结果与查询语义弱相关、无害查询引发意外内容的问题，但推荐结果存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成的百科全书Grokipedia的出现，搜索引擎在不同百科系统中的行为尚未得到充分研究。搜索引擎作为引导用户探索信息的关键机制，在不同平台上的表现差异值得深入分析。

Method: 使用近10,000个中性英文单词及其子字符串作为查询，收集超过70,000个搜索结果，分析语义对齐度、结果重叠度和主题结构。通过主题标注和轨迹分析，研究内容类别呈现方式和搜索结果在多阶段探索中的演变。

Result: 两个平台都频繁产生与原始查询弱相关的搜索结果，且无害查询常常引发意外内容。尽管存在这些共性，两个系统对相同查询产生的推荐结果存在显著差异。主题分布和查询建议方面也表现出系统性差异。

Conclusion: 意外搜索结果在维基百科和Grokipedia中都是常见现象，尽管它们在主题分布和查询建议方面存在差异。这表明AI生成和传统百科平台的搜索引擎都存在相似的问题，需要进一步优化以提供更准确的信息检索体验。

Abstract: Encyclopedic knowledge platforms are key gateways through which users explore information online. The recent release of Grokipedia, a fully AI-generated encyclopedia, introduces a new alternative to traditional, well-established platforms like Wikipedia. In this context, search engine mechanisms play an important role in guiding users exploratory paths, yet their behavior across different encyclopedic systems remains underexplored. In this work, we address this gap by providing the first comparative analysis of search engine in Wikipedia and Grokipedia.
  Using nearly 10,000 neutral English words and their substrings as queries, we collect over 70,000 search engine results and examine their semantic alignment, overlap, and topical structure. We find that both platforms frequently generate results that are weakly related to the original query and, in many cases, surface unexpected content starting from innocuous queries. Despite these shared properties, the two systems often produce substantially different recommendation sets for the same query. Through topical annotation and trajectory analysis, we further identify systematic differences in how content categories are surfaced and how search engine results evolve over multiple stages of exploration.
  Overall, our findings show that unexpected search engine outcomes are a common feature of both the platforms, even though they exhibit discrepancies in terms of topical distribution and query suggestions.

</details>


### [31] [TCDE: Topic-Centric Dual Expansion of Queries and Documents with Large Language Models for Information Retrieval](https://arxiv.org/abs/2512.17164)
*Yu Yang,Feng Tian,Ping Chen*

Main category: cs.IR

TL;DR: TCDE提出一种基于大语言模型的查询与文档双向主题中心扩展策略，通过生成伪文档和提炼主题句来增强语义对齐，在检索任务中取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统查询扩展(QE)和文档扩展(DE)通常是单独应用的，这可能导致扩展后的查询（或文档）与相关文档（或查询）之间的语义不对齐问题。

Method: 设计TCDE双重扩展策略：1) 查询侧：使用LLM识别查询中的子主题并为每个子主题生成聚焦的伪文档；2) 文档侧：使用LLM将文档提炼为一组核心主题句。通过这种主题中心的双向扩展建立查询与文档之间的语义桥梁。

Result: 在TREC Deep Learning和BEIR基准测试中，TCDE相比现有扩展基线取得显著改进。特别是在密集检索任务中，在SciFact数据集上NDCG@10相对提升2.8%，优于多个SOTA方法。

Conclusion: TCDE通过主题中心的双重扩展策略有效解决了查询与文档扩展中的语义不对齐问题，实验验证了该方法的有效性，为检索系统提供了更好的语义对齐机制。

Abstract: Query Expansion (QE) enriches queries and Document Expansion (DE) enriches documents, and these two techniques are often applied separately. However, such separate application may lead to semantic misalignment between the expanded queries (or documents) and their relevant documents (or queries). To address this serious issue, we propose TCDE, a dual expansion strategy that leverages large language models (LLMs) for topic-centric enrichment on both queries and documents. In TCDE, we design two distinct prompt templates for processing each query and document. On the query side, an LLM is guided to identify distinct sub-topics within each query and generate a focused pseudo-document for each sub-topic. On the document side, an LLM is guided to distill each document into a set of core topic sentences. The resulting outputs are used to expand the original query and document. This topic-centric dual expansion process establishes semantic bridges between queries and their relevant documents, enabling better alignment for downstream retrieval models. Experiments on two challenging benchmarks, TREC Deep Learning and BEIR, demonstrate that TCDE achieves substantial improvements over strong state-of-the-art expansion baselines. In particular, on dense retrieval tasks, it outperforms several state-of-the-art methods, with a relative improvement of 2.8\% in NDCG@10 on the SciFact dataset. Experimental results validate the effectiveness of our topic-centric and dual expansion strategy.

</details>


### [32] [Warmer for Less: A Cost-Efficient Strategy for Cold-Start Recommendations at Pinterest](https://arxiv.org/abs/2512.17277)
*Saeed Ebrahimi,Weijie Jiang,Jaewon Yang,Olafur Gudmundsson,Yucheng Tu,Huizhong Duan*

Main category: cs.IR

TL;DR: Pinterest提出了一套轻量级解决方案来改善推荐系统中冷启动物品的预测效果，包括残差连接、分数正则化和流形混合技术，实现了新鲜内容参与度提升10%的效果。


<details>
  <summary>Details</summary>
Motivation: 在Pinterest这样的视觉发现平台中，推荐系统对冷启动物品（训练数据中出现频率低的物品）的预测效果不佳。虽然学术界对此问题已有研究，但很少有研究能有效解决像Pinterest这样大规模平台的根本原因。

Method: 通过分析实时流量数据，针对冷启动问题的四个挑战分别设计解决方案：1) 采用轻量级设计，总参数仅增加5%；2) 为非历史特征引入残差连接以提升其重要性；3) 加入分数正则化项来平衡冷启动和非冷启动物品的预测分数；4) 应用流形混合技术解决标签稀疏问题。

Result: 这些方法共同使Pinterest的新鲜内容参与度提升了10%，同时没有对整体参与度和成本产生负面影响，目前已经部署到服务超过5.7亿用户。

Conclusion: 针对工业级推荐系统中冷启动物品的特定挑战，提出了一套成本效益高且有效的解决方案，这些方法在Pinterest平台上成功部署并取得了显著效果。

Abstract: Pinterest is a leading visual discovery platform where recommender systems (RecSys) are key to delivering relevant, engaging, and fresh content to our users. In this paper, we study the problem of improving RecSys model predictions for cold-start (CS) items, which appear infrequently in the training data. Although this problem is well-studied in academia, few studies have addressed its root causes effectively at the scale of a platform like Pinterest. By investigating live traffic data, we identified several challenges of the CS problem and developed a corresponding solution for each: First, industrial-scale RecSys models must operate under tight computational constraints. Since CS items are a minority, any related improvements must be highly cost-efficient. To address this, our solutions were designed to be lightweight, collectively increasing the total parameters by only 5%. Second, CS items are represented only by non-historical (e.g., content or attribute) features, which models often treat as less important. To elevate their significance, we introduce a residual connection for the non-historical features. Third, CS items tend to receive lower prediction scores compared to non-CS items, reducing their likelihood of being surfaced. We mitigate this by incorporating a score regularization term into the model. Fourth, the labels associated with CS items are sparse, making it difficult for the model to learn from them. We apply the manifold mixup technique to address this data sparsity. Implemented together, our methods increased fresh content engagement at Pinterest by 10% without negatively impacting overall engagement and cost, and have been deployed to serve over 570 million users on Pinterest.

</details>


### [33] [The Mental World of Large Language Models in Recommendation: A Benchmark on Association, Personalization, and Knowledgeability](https://arxiv.org/abs/2512.17389)
*Guangneng Hu*

Main category: cs.IR

TL;DR: LRWorld是一个包含38K高质量样本、23M token的推荐系统基准测试，用于评估LLM在推荐任务中的能力边界，涵盖关联性、个性化、知识性三个主要维度。


<details>
  <summary>Details</summary>
Motivation: LLM在推荐系统中展现出潜力，但缺乏全面评估其在推荐任务中能力边界和局限性的基准测试，无法得出可靠结论。

Method: 构建LRWorld基准测试，包含从广泛使用的公共推荐数据集中精心编译和生成的38K高质量样本。将LLM在推荐系统中的心智世界划分为三个主要维度（关联性、个性化、知识性），涵盖10个因素和31个测量任务。

Result: 对数十个LLM的全面实验表明：1）LLM仍不能很好地捕捉深度神经个性化嵌入，但在浅层基于记忆的物品相似性上表现良好；2）在推断用户兴趣时，LLM擅长感知物品实体关系、实体层次分类和物品关联规则；3）在多模态知识推理（电影海报和产品图像）和对噪声配置文件的鲁棒性方面展现出潜力；4）没有一个模型在所有10个因素上都表现一致良好。

Conclusion: LRWorld基准测试揭示了LLM在推荐系统中的具体能力边界，为未来研究提供了评估框架。LLM在某些推荐任务中表现良好，但在个性化深度理解方面仍有局限，且不同模型在不同因素上表现各异。

Abstract: Large language models (LLMs) have shown potential in recommendation systems (RecSys) by using them as either knowledge enhancer or zero-shot ranker. A key challenge lies in the large semantic gap between LLMs and RecSys where the former internalizes language world knowledge while the latter captures personalized world of behaviors. Unfortunately, the research community lacks a comprehensive benchmark that evaluates the LLMs over their limitations and boundaries in RecSys so that we can draw a confident conclusion. To investigate this, we propose a benchmark named LRWorld containing over 38K high-quality samples and 23M tokens carefully compiled and generated from widely used public recommendation datasets. LRWorld categorizes the mental world of LLMs in RecSys as three main scales (association, personalization, and knowledgeability) spanned by ten factors with 31 measures (tasks). Based on LRWorld, comprehensive experiments on dozens of LLMs show that they are still not well capturing the deep neural personalized embeddings but can achieve good results on shallow memory-based item-item similarity. They are also good at perceiving item entity relations, entity hierarchical taxonomies, and item-item association rules when inferring user interests. Furthermore, LLMs show a promising ability in multimodal knowledge reasoning (movie poster and product image) and robustness to noisy profiles. None of them show consistently good performance over the ten factors. Model sizes, position bias, and more are ablated.

</details>


### [34] [A Systematic Reproducibility Study of BSARec for Sequential Recommendation](https://arxiv.org/abs/2512.17442)
*Jan Hutter,Hua Chang Bakker,Stan Fris,Madelon Bernardy,Yuanna Liu*

Main category: cs.IR

TL;DR: 该论文对BSARec方法进行了系统性验证，发现其通过傅里叶变换增强高频信号，在某些数据集上优于其他SR方法，但DSP技术相比简单残差连接优势有限，非恒定填充策略能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer-based的序列推荐模型中，自注意力机制作为低通滤波器，限制了捕捉反映短期用户兴趣的高频信号的能力。BSARec虽然通过傅里叶变换增强高频分量，但其整体有效性和各组件作用尚未得到系统性验证。

Method: 1) 复现BSARec并验证其在多个数据集上的性能；2) 提出量化用户历史频率的指标，评估SR方法在不同用户群的表现；3) 比较不同数字信号处理技术（傅里叶变换vs离散小波变换）的效果；4) 探索不同填充策略对性能的影响。

Result: 1) BSARec在某些数据集上优于其他SR方法；2) 离散小波变换相比傅里叶变换只有轻微改进；3) DSP方法相比简单残差连接没有明显优势；4) 非恒定填充策略显著提升推荐性能，而恒定填充会阻碍频率重缩放器捕捉高频信号。

Conclusion: BSARec通过频率重缩放机制确实能提升序列推荐性能，特别是在捕捉高频信号方面。然而，复杂的DSP技术相比简单架构改进的优势有限，填充策略的选择对模型性能有重要影响。未来研究应更关注基础架构改进而非过度复杂的信号处理技术。

Abstract: In sequential recommendation (SR), the self-attention mechanism of Transformer-based models acts as a low-pass filter, limiting their ability to capture high-frequency signals that reflect short-term user interests. To overcome this, BSARec augments the Transformer encoder with a frequency layer that rescales high-frequency components using the Fourier transform. However, the overall effectiveness of BSARec and the roles of its individual components have yet to be systematically validated. We reproduce BSARec and show that it outperforms other SR methods on some datasets. To empirically assess whether BSARec improves performance on high-frequency signals, we propose a metric to quantify user history frequency and evaluate SR methods across different user groups. We compare digital signal processing (DSP) techniques and find that the discrete wavelet transform (DWT) offer only slight improvements over Fourier transforms, and DSP methods provide no clear advantage over simple residual connections. Finally, we explore padding strategies and find that non-constant padding significantly improves recommendation performance, whereas constant padding hinders the frequency rescaler's ability to capture high-frequency signals.

</details>


### [35] [Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application](https://arxiv.org/abs/2512.17462)
*Olivier Jeunen,Schaun Wheeler*

Main category: cs.IR

TL;DR: 本文通过随机对照试验评估了基于智能体的个性化营销在金融服务应用中的效果，发现相比传统规则系统，智能体消息能减少21%的退订率并促进用户提前完成税务申报。


<details>
  <summary>Details</summary>
Motivation: 营销和产品个性化是信息检索方法在多个商业领域的重要应用场景。近年来，基于智能体的个性化方法越来越受关注，但需要实证评估其对用户行为和留存的实际影响。

Method: 在2025年国家税务申报期间，对金融服务应用的客户沟通系统进行了为期两个月的随机对照试验。比较了基于智能体的消息方法与传统的业务规则系统，重点关注退订行为和转化时机两个主要结果指标。

Result: 实证结果显示：1) 智能体主导的消息使退订事件相比传统系统减少了21%（±0.01）；2) 增加了用户在截止日期前几周的提前申报行为；3) 自适应、用户层面的决策系统能够在调节参与强度的同时改善长期留存指标。

Conclusion: 研究证明基于智能体的个性化方法在金融服务营销中具有显著优势，能够有效减少用户流失并优化用户行为时机，为企业在关键业务场景中实施自适应决策系统提供了实证支持。

Abstract: Marketing and product personalisation provide a prominent and visible use-case for the application of Information Retrieval methods across several business domains. Recently, agentic approaches to these problems have been gaining traction. This work evaluates the behavioural and retention effects of agentic personalisation on a financial service application's customer communication system during a 2025 national tax filing period. Through a two month-long randomised controlled trial, we compare an agentic messaging approach against a business-as-usual (BAU) rule-based campaign system, focusing on two primary outcomes: unsubscribe behaviour and conversion timing. Empirical results show that agent-led messaging reduced unsubscribe events by 21\% ($\pm 0.01$) relative to BAU and increased early filing behaviour in the weeks preceding the national deadline. These findings demonstrate how adaptive, user-level decision-making systems can modulate engagement intensity whilst improving long-term retention indicators.

</details>


### [36] [Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure](https://arxiv.org/abs/2512.17733)
*Jingmao Zhang,Zhiting Zhao,Yunqi Lin,Jianghong Ma,Tianjun Wei,Haijun Zhang,Xiaofeng Zhang*

Main category: cs.IR

TL;DR: 本文提出Cadence框架，通过因果解耦和反事实曝光增强推荐多样性，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统主要依赖共现关系，容易受到商品流行度偏差和用户属性的影响，导致嵌入质量和性能下降。同时，虽然多样性被认为是推荐质量的关键方面，但现有研究对此关注有限，缺乏因果视角和理论基础。

Method: 1. 计算无偏非对称共购关系(UACR)，排除商品流行度和用户属性影响，构建解耦的有向商品图，并通过聚合机制优化嵌入表示。
2. 利用UACR识别与用户交互商品具有强因果相关性但尚未接触的多样化商品类别，模拟高曝光场景下的用户行为。

Result: 在真实世界数据集上的广泛实验表明，该方法在多样性和准确性方面均优于最先进的多样性模型，验证了其有效性、可迁移性和效率。

Conclusion: Cadence框架成功解决了推荐系统中的多样性挑战，通过因果解耦和反事实曝光机制，在保持准确性的同时显著提升了推荐多样性，为推荐系统研究提供了新的因果视角。

Abstract: Beyond user-item modeling, item-to-item relationships are increasingly used to enhance recommendation. However, common methods largely rely on co-occurrence, making them prone to item popularity bias and user attributes, which degrades embedding quality and performance. Meanwhile, although diversity is acknowledged as a key aspect of recommendation quality, existing research offers limited attention to it, with a notable lack of causal perspectives and theoretical grounding. To address these challenges, we propose Cadence: Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure - a plug-and-play framework built upon LightGCN as the backbone, primarily designed to enhance recommendation diversity while preserving accuracy. First, we compute the Unbiased Asymmetric Co-purchase Relationship (UACR) between items - excluding item popularity and user attributes - to construct a deconfounded directed item graph, with an aggregation mechanism to refine embeddings. Second, we leverage UACR to identify diverse categories of items that exhibit strong causal relevance to a user's interacted items but have not yet been engaged with. We then simulate their behavior under high-exposure scenarios, thereby significantly enhancing recommendation diversity while preserving relevance. Extensive experiments on real-world datasets demonstrate that our method consistently outperforms state-of-the-art diversity models in both diversity and accuracy, and further validates its effectiveness, transferability, and efficiency over baselines.

</details>
