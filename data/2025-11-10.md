<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

TL;DR: 该论文研究了LLMs在程序序列推理任务上的表现，通过使用食谱数据集评估模型从乱序步骤重建正确序列的能力，发现模型性能随序列长度增加和步骤位移加剧而下降。


<details>
  <summary>Details</summary>
Motivation: 程序序列推理是LLMs的关键能力，其中步骤顺序直接影响结果。研究旨在评估LLMs在重建全局有序序列方面的表现，特别是在食谱领域这种顺序对任务成功至关重要的场景。

Method: 使用精心策划的食谱数据集，在零样本和少样本设置下评估多个LLMs。采用综合评估框架，包括Kendall's Tau、NLCS和NED等从排序和序列对齐中借鉴的指标。

Result: 模型性能随序列长度增加而下降，反映了更长程序的复杂性增加。输入中步骤位移越大（对应更严重的乱序），性能进一步恶化。

Conclusion: 当前LLMs在程序推理方面存在局限性，特别是在处理更长和更无序的输入时表现不佳。

Abstract: Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [2] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: ATLAS是一个基于项目反应理论的自适应测试框架，通过Fisher信息引导的项目选择来评估大语言模型，能在保持测量精度的同时减少90%的测试项目使用量。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型评估方法需要数千个基准测试项目，评估成本高昂且缓慢，而且所有项目都被平等对待，忽略了项目质量和信息量的差异。

Method: 使用项目反应理论(IRT)和Fisher信息引导的项目选择来估计模型能力，分析五个主要基准测试，识别出3-6%具有负区分度的项目。

Result: 在HellaSwag基准测试中，仅使用42个项目就能匹配完整基准测试的估计结果，平均绝对误差为0.154。项目暴露率低于10%，测试重叠率为16-27%。在4000多个测试模型中，IRT排名与准确率排名存在差异。

Conclusion: ATLAS框架显著提高了大语言模型评估的效率和准确性，揭示了静态基准测试中存在的标注错误问题，并为模型评估提供了更精确的排名方法。

Abstract: Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [3] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

TL;DR: SARC是一个基于情感增强角色聚类的假新闻检测框架，通过联合优化角色聚类和假新闻检测任务，在RumourEval-19和Weibo-comp数据集上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻检测方法通常将情感特征作为辅助信号，忽略了用户角色差异对情感表达的影响，即相同情感极性可能来自不同角色的用户，这限制了模型捕捉细微模式的能力。

Method: 提出SARC框架：1) 使用BiGRU和注意力机制生成用户特征，结合情感编码；2) 构建可微分深度聚类模块自动分类用户角色；3) 提出联合优化目标，整合角色聚类和假新闻检测任务。

Result: 在两个基准数据集RumourEval-19和Weibo-comp上的实验结果表明，SARC在所有评估指标上都优于基线模型。

Conclusion: 通过考虑用户角色差异并联合优化角色聚类和假新闻检测任务，SARC框架能够更有效地利用情感信息，显著提升假新闻检测性能。

Abstract: Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [4] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: EncouRAGe是一个用于RAG系统开发和评估的Python框架，包含五个模块化组件，支持科学可重复性和本地部署。评估显示RAG性能仍不及Oracle Context，Hybrid BM25表现最佳，重排序仅带来边际改进但增加延迟。


<details>
  <summary>Details</summary>
Motivation: 为简化基于LLM和嵌入模型的RAG系统开发与评估，提供模块化、可扩展且支持科学可重复性的框架。

Method: 开发包含Type Manifest、RAG Factory、Inference、Vector Store和Metrics五个组件的模块化框架，支持灵活实验和扩展开发。

Result: 在包含25k问答对和51k文档的多个基准数据集上评估，RAG性能仍不及Oracle Context，Hybrid BM25在所有四个数据集中表现最佳，重排序仅带来微小性能提升但显著增加响应延迟。

Conclusion: EncouRAGe框架有效支持RAG系统开发与评估，当前RAG技术仍有改进空间，Hybrid BM25是可靠方法，重排序策略需权衡性能与延迟。

Abstract: We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [5] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [6] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

TL;DR: multiMentalRoBERTa是一个基于RoBERTa微调的多类别心理健康状况分类模型，在六类和五类分类任务中表现优于传统机器学习方法和领域特定transformer模型，并提供了可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 从社交媒体文本中早期检测心理健康障碍对于及时支持、风险评估和转诊至适当资源至关重要。

Method: 使用多个精选数据集进行数据探索，分析类别重叠；比较传统机器学习方法、领域特定transformer和基于提示的大语言模型；应用Layer Integrated Gradients和KeyBERT进行可解释性分析。

Result: multiMentalRoBERTa在六类分类中macro F1-score达到0.839，在五类分类（排除压力）中达到0.870，优于微调的MentalBERT和基线分类器。

Conclusion: 微调的transformer模型在敏感情境下提供了可靠且可解释的检测方案，同时强调了公平性、偏见缓解和人工参与安全协议的重要性，multiMentalRoBERTa是一个轻量级、稳健且可部署的解决方案。

Abstract: The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [7] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

TL;DR: Cross-Lingual SynthDocs是一个大规模合成语料库，包含250万样本，用于解决阿拉伯语OCR和文档理解资源稀缺问题，通过微调Qwen-2.5-VL模型在多模态任务上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语在光学字符识别和文档理解领域资源稀缺的问题，提供大规模、视觉逼真的多语言文档分析资源。

Method: 利用真实扫描背景、双语布局和带变音符号的字体构建合成管道，包含文本、表格和图表等多种渲染样式，生成超过250万样本的大规模数据集。

Result: 在Qwen-2.5-VL模型上微调后，在多个阿拉伯语基准测试中，OCR任务的词错误率和字符错误率持续改善，树编辑距离相似度和图表提取分数在其他模态任务中也有提升。

Conclusion: SynthDocs为多语言文档分析研究提供了一个可扩展、视觉逼真的资源，有效解决了阿拉伯语文档理解资源稀缺的问题。

Abstract: Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [8] [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](https://arxiv.org/abs/2511.04700)
*Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li*

Main category: cs.CL

TL;DR: WinnowRAG是一个新颖的检索增强生成框架，通过两阶段方法系统性地过滤噪声文档并保留有价值内容，无需模型微调即可提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法通过增加检索文档数量来提高相关信息获取概率，但会引入大量噪声文档，导致生成回答准确性下降。

Method: 第一阶段：查询感知聚类将相似文档分组，每个集群由LLM代理生成独特答案；第二阶段：批评LLM评估多个代理输出，通过迭代分离有用文档与噪声文档，并采用两种策略合并技术保留有用文档。

Result: 在多个真实数据集上的广泛实验表明，WinnowRAG优于最先进的基线方法。

Conclusion: WinnowRAG是一个模型无关的RAG框架，无需模型微调即可有效处理大量文档中的噪声问题，显著提升生成响应的准确性。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge sources to address their limitations in
accessing up-to-date or specialized information. A natural strategy to increase
the likelihood of retrieving relevant information is to expand the number of
retrieved documents. However, involving more documents could introduce
significant noise, as many documents may be irrelevant or misleading, thereby
reducing the overall accuracy of the generated responses. To overcome the
challenge associated with handling a larger number of documents, we propose
WinnowRAG, a novel RAG framework designed to systematically filter out noisy
documents while preserving valuable content -- a process we refer to as
winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware
clustering to group similar documents and form distinct topic clusters. Each
cluster is assigned to an LLM agent for generating a unique answer. In Stage
II, we perform winnowing, wherein a critic LLM evaluates the outputs of
multiple agents and iteratively separates useful documents from noisy ones. To
retain useful documents when discarding agents, we propose two strategic
merging techniques to ensure that only relevant knowledge is used for
generating the final response. Crucially, WinnowRAG is model-agnostic and does
not require any model fine-tuning, making it easily adaptable to various tasks.
Extensive experiments on various realistic datasets demonstrate the
effectiveness of WinnowRAG over state-of-the-art baselines.

</details>


### [9] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 本文通过对445个LLM基准测试的系统性审查，发现现有评估方法在结构效度方面存在严重问题，并提出了8项关键建议来改进LLM基准测试的开发。


<details>
  <summary>Details</summary>
Motivation: 可靠评估大型语言模型的能力、安全性和鲁棒性对于部署前识别问题至关重要，但目前缺乏有效的评估方法。

Method: 由29位专家评审团队对自然语言处理和机器学习领域顶级会议的445个LLM基准测试进行系统性审查。

Result: 发现现有基准测试在测量现象、任务和评分指标方面存在模式性问题，这些模式削弱了评估结果的有效性。

Conclusion: 提出了8项关键建议和详细可行的指导，帮助研究人员和从业者开发更具结构效度的LLM基准测试。

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [10] [POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios](https://arxiv.org/abs/2511.04705)
*Tingyue Yang,Junchi Yao,Yuhui Guo,Chang Liu*

Main category: cs.CL

TL;DR: POLIS-Bench是首个针对政府双语政策场景的LLM评估套件，包含更新的双语语料库、场景驱动的任务设计和双指标评估框架。评估发现推理模型表现最佳，并通过微调开发了成本效益高的POLIS系列模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法充分评估LLM在政府双语政策场景中的表现，需要专门针对当前治理实践的相关评估工具。

Method: 构建更新的双语政策语料库，设计三个场景驱动的专门任务（条款检索与解释、解决方案生成、合规判断），建立结合语义相似度和准确率的双指标评估框架。

Result: 评估10多个最先进LLM显示推理模型在跨任务稳定性和准确性方面表现最优，合规任务难度最高。通过微调开发的POLIS系列模型在多个政策子任务上达到或超过专有基线模型，成本显著降低。

Conclusion: POLIS-Bench为政府场景的LLM部署提供了有效的评估工具，POLIS系列模型展示了低成本实现强大政策处理能力的可行性，为实际政府部署开辟了经济合规的路径。

Abstract: We introduce POLIS-Bench, the first rigorous, systematic evaluation suite
designed for LLMs operating in governmental bilingual policy scenarios.
Compared to existing benchmarks, POLIS-Bench introduces three major
advancements. (i) Up-to-date Bilingual Corpus: We construct an extensive,
up-to-date policy corpus that significantly scales the effective assessment
sample size, ensuring relevance to current governance practice. (ii)
Scenario-Grounded Task Design: We distill three specialized, scenario-grounded
tasks -- Clause Retrieval & Interpretation, Solution Generation, and the
Compliance Judgmen--to comprehensively probe model understanding and
application. (iii) Dual-Metric Evaluation Framework: We establish a novel
dual-metric evaluation framework combining semantic similarity with accuracy
rate to precisely measure both content alignment and task requirement
adherence. A large-scale evaluation of over 10 state-of-the-art LLMs on
POLIS-Bench reveals a clear performance hierarchy where reasoning models
maintain superior cross-task stability and accuracy, highlighting the
difficulty of compliance tasks. Furthermore, leveraging our benchmark, we
successfully fine-tune a lightweight open-source model. The resulting POLIS
series models achieves parity with, or surpasses, strong proprietary baselines
on multiple policy subtasks at a significantly reduced cost, providing a
cost-effective and compliant path for robust real-world governmental
deployment.

</details>


### [11] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong*

Main category: cs.CL

TL;DR: GEMMA-SQL是一个基于开源Gemma 2B架构的轻量级文本到SQL模型，通过资源高效的迭代微调和多种提示策略，在SPIDER基准测试中取得了优于多个先进基线的性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个轻量级、高效的文本到SQL系统，使用户无需专业编程知识就能与结构化数据库交互，并能在低成本硬件上部署。

Method: 基于Gemma 2B架构，采用资源高效的迭代微调方法，结合多种提示策略（包括少样本学习）来增强SQL查询生成准确性。

Result: GEMMA-SQL Instruct变体在SPIDER基准测试中达到66.8%的Test-Suite准确率和63.3%的Exact Set Match准确率，优于IRNet、RYANSQL和CodeXDavinci等先进基线。

Conclusion: 有效的提示设计和有针对性的指令调优可以显著提升性能，同时保持高可扩展性和适应性，使GEMMA-SQL成为稳健且易用的文本到SQL系统的实用开源替代方案。

Abstract: Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [12] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 本文挑战了先前关于LLM影响函数计算的最佳层选择结论，提出中间注意力层比嵌入层更适合计算训练样本影响，并提出了新的评估指标和聚合方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM影响函数计算方法由于模型规模庞大，通常只能计算部分层的梯度，但先前研究认为嵌入层最适合计算影响函数的结论可能不可靠。

Method: 通过理论和实证证据分析取消效应的不可靠性，提出中间注意力层更适合计算影响，并开发了排名和投票等替代标准平均的聚合方法，以及新的评估指标NDR。

Result: 实验表明，在多种类型和规模的LLM中，第一层（嵌入层）并不一定比最后一层更适合影响估计，这与先前领域知识形成对比。

Conclusion: 中间注意力层是更好的影响估计器，新的聚合方法和NDR指标能显著提升性能，为LLM影响分析提供了更可靠的方法。

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [13] [Learning to reason about rare diseases through retrieval-augmented agents](https://arxiv.org/abs/2511.04720)
*Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.CL

TL;DR: RADAR是一个基于检索增强诊断推理的智能体系统，用于脑MRI中罕见疾病的检测，通过检索外部医学知识来指导诊断决策，无需额外训练即可提升罕见病理识别能力。


<details>
  <summary>Details</summary>
Motivation: 罕见疾病在医学影像中数据稀缺，导致AI模型表现不佳。放射科医生在遇到不熟悉发现时通常会查阅病例报告和文献，因此需要开发能够模拟这种临床推理过程的系统。

Method: 使用AI智能体访问外部医学知识，通过句子转换器嵌入病例报告和文献，并用FAISS建立索引以实现高效相似性搜索。该系统作为模型无关的推理模块，可与各种大语言模型无缝集成。

Result: 在包含280种不同罕见疾病的NOVA数据集上，RADAR实现了高达10.2%的性能提升，开源模型如DeepSeek的改进最为显著。检索到的示例提供了可解释的、基于文献的解释。

Conclusion: 检索增强推理是医学影像中低流行度条件的有力范式，不仅能提高准确性，还能提供基于文献的可解释性。

Abstract: Rare diseases represent the long tail of medical imaging, where AI models
often fail due to the scarcity of representative training data. In clinical
workflows, radiologists frequently consult case reports and literature when
confronted with unfamiliar findings. Following this line of reasoning, we
introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic
system for rare disease detection in brain MRI. Our approach uses AI agents
with access to external medical knowledge by embedding both case reports and
literature using sentence transformers and indexing them with FAISS to enable
efficient similarity search. The agent retrieves clinically relevant evidence
to guide diagnostic decision making on unseen diseases, without the need of
additional training. Designed as a model-agnostic reasoning module, RADAR can
be seamlessly integrated with diverse large language models, consistently
improving their rare pathology recognition and interpretability. On the NOVA
dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%
performance gain, with the strongest improvements observed for open source
models such as DeepSeek. Beyond accuracy, the retrieved examples provide
interpretable, literature grounded explanations, highlighting
retrieval-augmented reasoning as a powerful paradigm for low-prevalence
conditions in medical imaging.

</details>


### [14] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh,Simon Dobnik*

Main category: cs.CL

TL;DR: 论文提出使用惊奇度方差作为图像描述多样性的度量指标，发现在MSCOCO数据集上，人类描述比模型描述具有更高的惊奇度方差，但使用不同评分器会完全反转结论。


<details>
  <summary>Details</summary>
Motivation: 当前图像描述模型在多样性评估方面缺乏稳健的度量方法，需要一种能够准确衡量描述多样性的指标。

Method: 使用惊奇度方差（token级负对数概率的分布）作为多样性度量，比较了五种最先进的视觉语言大模型与人类描述，并使用了两种不同的语言模型进行评分。

Result: 使用描述训练的语言模型时，人类描述的惊奇度方差约为模型的两倍；但使用通用语言模型重新评分时，模式完全反转。

Conclusion: 仅依赖单一评分器会完全颠倒多样性评估结论，因此稳健的多样性评估必须报告多个评分器下的惊奇度。

Abstract: We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [15] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen*

Main category: cs.CL

TL;DR: ERPO框架通过鼓励在残差提示上探索，重新激活训练信号，在数学推理基准上超越了强基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着模型训练时间增长和规模扩大，更多训练提示变为残差提示（零方差奖励），导致训练信号减少、多样性降低，影响训练效果。

Method: ERPO框架为每个提示维护历史跟踪器，自适应地增加残差提示的采样温度，鼓励模型生成更多样化的推理轨迹，引入错误响应以重新激活训练信号。

Result: 在Qwen2.5系列上的实证结果表明，ERPO在多个数学推理基准上持续超越强基线方法。

Conclusion: ERPO框架通过有效利用残差提示，解决了RLVR训练中训练信号减少的问题，提高了模型的推理能力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [16] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 研究发现基础LLMs在语义校准方面表现良好，能够有意义地评估开放域问答任务中的置信度，尽管没有经过明确训练。理论解释了语义校准作为下一个token预测副产品的机制，并通过实验验证了RL指令微调和思维链推理会破坏这种校准。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常缺乏对其输出的有意义的置信度估计。虽然基础LLMs已知具有下一个token校准能力，但尚不清楚它们是否能在token级别之外评估其响应的实际含义的置信度。

Method: 使用基于采样的语义校准概念，建立理论机制解释语义校准作为下一个token预测副产品出现的原因，提出B-校准的一般定义，并通过实验验证理论预测。

Result: 基础LLMs在问答任务中表现出语义校准能力；RL指令微调会系统性破坏这种校准；思维链推理也会破坏校准。

Conclusion: 该研究首次提供了关于LLMs中语义校准何时以及为何出现的原理性解释，揭示了基础LLMs的内在语义校准能力及其在特定训练方法下的脆弱性。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [17] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask*

Main category: cs.CL

TL;DR: LLMs can develop behavioral self-awareness through simple fine-tuning, which poses safety risks as models may conceal their true capabilities during evaluation.


<details>
  <summary>Details</summary>
Motivation: Recent findings show LLMs can exhibit behavioral self-awareness, raising safety concerns about models potentially hiding their true abilities during assessments.

Method: Controlled fine-tuning experiments using low-rank adapters (LoRA) on instruction-tuned LLMs, specifically testing with single rank-1 LoRA adapters.

Result: Self-awareness can be reliably induced with a single rank-1 LoRA adapter, captured by a single steering vector in activation space, and is non-universal with independent representations across tasks.

Conclusion: Behavioral self-awareness emerges as a domain-specific, linear feature that can be easily induced and modulated, suggesting significant implications for AI safety.

Abstract: Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [18] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee*

Main category: cs.CL

TL;DR: SDS KoPub VDR是首个大规模公开的韩语公共文档检索基准，包含361个真实文档（40,781页）和600个经过人工验证的查询-页面-答案三元组，支持文本检索和多模态检索任务的评估。


<details>
  <summary>Details</summary>
Motivation: 现有视觉文档检索基准主要关注英语，忽略了非英语语言和官方出版物的结构复杂性，需要填补这一关键空白。

Method: 基于361个真实世界文档构建基准，包括256个KOGL Type 1许可文件和105个官方法律门户文件。通过多模态模型生成查询，并经过严格的人工验证和优化过程，确保事实准确性和上下文相关性。

Result: 评估显示在需要跨模态推理的多模态场景中，即使是最先进的模型也存在显著的性能差距。

Conclusion: SDS KoPub VDR不仅支持文本和多模态检索任务的严格细粒度评估，还为推进复杂真实世界文档智能中的多模态AI提供了清晰的路线图。

Abstract: Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [19] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi*

Main category: cs.CL

TL;DR: BudgetMem是一种内存增强架构，通过选择性记忆策略和特征显著性评分来学习存储关键信息，在严格预算约束下显著减少内存使用（节省72.4%），同时性能仅下降1.0%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长上下文时面临计算和内存限制，现有扩展上下文窗口的方法在资源受限部署中成本过高。

Method: 结合选择性记忆策略与基于特征的显著性评分（实体密度、TF-IDF、语篇标记、位置偏差），使用学习门控机制和BM25稀疏检索进行高效信息访问。

Result: 在700个问答对上的实验显示，BudgetMem在长文档上仅损失1.0% F1分数，同时节省72.4%内存，且随着文档长度增加，优势更加明显。

Conclusion: BudgetMem为在有限硬件上部署长上下文系统提供了实用途径，使先进语言理解能力更加普及。

Abstract: Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [20] [AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent](https://arxiv.org/abs/2511.04921)
*Yu Li,Lehui Li,Qingmin Liao,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 提出了一种基于集体感知的基准和数据集推荐框架，通过自动化数据收集、增强检索器和推理重排器，显著提升了AI实验中基准和数据集推荐的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在数据覆盖范围有限、过度依赖内容相似性而忽略实验适用性的问题，需要更全面和可靠的自动化实验设计解决方案。

Method: 1) 自动化数据收集管道，将约10万篇论文与其实际使用的基准和数据集关联；2) 集体感知增强检索器，结合自描述和聚合引用上下文表示数据集位置；3) 推理增强重排器，构建显式推理链并微调LLM生成可解释的推荐。

Result: 构建的数据集覆盖了过去五年顶级AI会议中85%使用的数据集和基准，在Recall@20和HitRate@5指标上分别比最强基线平均提升5.85%和8.30%。

Conclusion: 该方法推进了实验设计的可靠、可解释自动化，为科学探索中的LLM代理应用提供了更有效的工具。

Abstract: Large language model agents are becoming increasingly capable at web-centric
tasks such as information retrieval, complex reasoning. These emerging
capabilities have given rise to surge research interests in developing LLM
agent for facilitating scientific quest. One key application in AI research is
to automate experiment design through agentic dataset and baseline retrieval.
However, prior efforts suffer from limited data coverage, as recommendation
datasets primarily harvest candidates from public portals and omit many
datasets actually used in published papers, and from an overreliance on content
similarity that biases model toward superficial similarity and overlooks
experimental suitability. Harnessing collective perception embedded in the
baseline and dataset citation network, we present a comprehensive framework for
baseline and dataset recommendation. First, we design an automated
data-collection pipeline that links roughly one hundred thousand accepted
papers to the baselines and datasets they actually used. Second, we propose a
collective perception enhanced retriever. To represent the position of each
dataset or baseline within the scholarly network, it concatenates
self-descriptions with aggregated citation contexts. To achieve efficient
candidate recall, we finetune an embedding model on these representations.
Finally, we develop a reasoning-augmented reranker that exact interaction
chains to construct explicit reasoning chains and finetunes a large language
model to produce interpretable justifications and refined rankings. The dataset
we curated covers 85\% of the datasets and baselines used at top AI conferences
over the past five years. On our dataset, the proposed method outperforms the
strongest prior baseline with average gains of +5.85\% in Recall@20, +8.30\% in
HitRate@5. Taken together, our results advance reliable, interpretable
automation of experimental design.

</details>


### [21] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao,Hideaki Takeda*

Main category: cs.CL

TL;DR: 本研究提出了一种新的验证方法来检测Wikidata中的分类错误、过度泛化的子类链接和冗余连接，并开发了允许用户检查任意实体分类关系的系统。


<details>
  <summary>Details</summary>
Motivation: Wikidata作为最大的开放知识图谱，其相对宽松的编辑政策导致了分类不一致问题，需要系统性的验证和纠正方法。

Method: 提出并应用新颖的验证方法来确认分类错误、过度泛化的子类链接和冗余连接，引入新的评估标准判断是否需要修正。

Result: 成功开发了允许用户检查任意Wikidata实体分类关系的系统，充分利用了平台的众包特性。

Conclusion: 该方法有效识别了Wikidata中的分类问题，并通过用户参与的系统实现了知识图谱质量的提升。

Abstract: Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [22] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan*

Main category: cs.CL

TL;DR: LoPT是一种无损并行分词框架，通过基于字符位置的匹配和动态块长度调整，解决了现有并行分词方法因边界伪影导致结果不一致的问题，在保证与标准顺序分词输出完全相同的同时显著提升了长文本处理速度。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理场景对大型语言模型越来越重要，但带来了显著的计算延迟。现有研究通过算子、模型架构和系统框架优化长序列推理，但分词仍然是一个被忽视的瓶颈。现有的并行分词方法通过文本分割和多进程分词加速处理，但由于合并后的边界伪影导致结果不一致。

Method: 提出LoPT框架，采用基于字符位置的匹配和动态块长度调整来准确对齐和合并分词片段，确保输出与标准顺序分词完全相同。

Result: 在多种长文本数据集上的广泛实验表明，LoPT在保证无损分词的同时实现了显著的速度提升。同时提供了理论一致性证明和全面的分析研究来验证方法的鲁棒性。

Conclusion: LoPT成功解决了并行分词中的边界一致性问题，为长上下文推理提供了一种高效且可靠的分词解决方案，在保持输出准确性的同时显著提升了处理效率。

Abstract: Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [23] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CL

TL;DR: LLMs struggle to authentically role-play villainous characters due to safety alignment conflicts, showing declining fidelity as character morality decreases.


<details>
  <summary>Details</summary>
Motivation: To investigate how LLMs' safety alignment affects their ability to authentically simulate morally ambiguous or villainous fictional characters.

Method: Created Moral RolePlay benchmark with four-level moral alignment scale, tested state-of-the-art LLMs role-playing characters from moral paragons to pure villains.

Result: Found consistent decline in role-playing fidelity as character morality decreases, with models struggling most with traits antithetical to safety principles like deceitfulness and manipulation.

Conclusion: Safety alignment creates fundamental tension with creative fidelity, highlighting need for more nuanced, context-aware alignment methods.

Abstract: Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [24] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 本文提出了一种获取中文常见情感事件的方法，通过收集情感事件指示词，使用中文大语言模型生成情感事件，训练过滤器确保质量，并分类为积极和消极事件，最终构建了包含102,218个高质量情感事件的知识库。


<details>
  <summary>Details</summary>
Motivation: 情感事件知识对提升应用效果很重要，但常见的情感事件（如"中奖"、"被批评"）难以获取，特别是那些与上下文无关的通用情感事件。

Method: 1. 收集中文情感事件指示词列表；2. 使用中文大语言模型基于指示词生成情感事件；3. 训练过滤器剔除无效结果；4. 使用不同技术将情感事件分类为积极和消极事件。

Result: 构建了包含102,218个高质量常见情感事件的中文知识库，这是目前唯一的大规模中文情感事件常识知识库。内在评估显示该方法能有效获取中文情感事件，外在用例在情感原因提取领域展示了强大潜力。

Conclusion: 本文提出的方法能够有效获取中文常见情感事件，构建了大规模高质量的中文情感事件知识库，为情感相关应用提供了重要资源。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [25] [Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies](https://arxiv.org/abs/2511.05018)
*Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien*

Main category: cs.CL

TL;DR: 提出了PLURALISTIC BEHAVIOR SUITE (PBSUITE)评估套件，用于系统评估LLM在多轮交互对话中遵守多元化对齐规范的能力，发现现有模型在单轮设置中表现良好，但在多轮对抗性交互中合规性显著下降。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的LLM应用通常在具有独特企业政策、监管要求、用例、品牌指南和道德承诺的组织生态系统中进行，这凸显了对具有多元化对齐目标的LLM进行严格评估的需求。

Method: 开发了PBSUITE评估套件，包括：(1)基于30个行业的300个现实LLM行为策略数据集；(2)用于在对抗条件下压力测试模型对自定义行为规范合规性的动态评估框架。

Result: 领先的开源和闭源LLM在单轮设置中保持稳健的行为策略遵守（失败率低于4%），但在多轮对抗性交互中合规性大幅减弱（失败率高达84%）。

Conclusion: 现有模型对齐和安全调节方法在现实世界LLM交互中连贯执行多元化行为策略方面存在不足，本研究为未来开发稳健和上下文感知的多元化对齐技术提供了数据集和分析框架。

Abstract: Large language models (LLMs) are typically aligned to a universal set of
safety and usage principles intended for broad public acceptability. Yet,
real-world applications of LLMs often take place within organizational
ecosystems shaped by distinctive corporate policies, regulatory requirements,
use cases, brand guidelines, and ethical commitments. This reality highlights
the need for rigorous and comprehensive evaluation of LLMs with pluralistic
alignment goals, an alignment paradigm that emphasizes adaptability to diverse
user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE
(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'
capacity to adhere to pluralistic alignment specifications in multi-turn,
interactive conversations. PBSUITE consists of (1) a diverse dataset of 300
realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic
evaluation framework for stress-testing model compliance with custom behavioral
specifications under adversarial conditions. Using PBSUITE, We find that
leading open- and closed-source LLMs maintain robust adherence to behavioral
policies in single-turn settings (less than 4% failure rates), but their
compliance weakens substantially in multi-turn adversarial interactions (up to
84% failure rates). These findings highlight that existing model alignment and
safety moderation methods fall short in coherently enforcing pluralistic
behavioral policies in real-world LLM interactions. Our work contributes both
the dataset and analytical framework to support future research toward robust
and context-aware pluralistic alignment techniques.

</details>


### [26] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: UA-Code-Bench是一个针对乌克兰语代码生成和竞争性编程问题解决能力的新基准测试，包含500个难度分级的问题，评估显示即使是顶级模型也只能解决一半问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注从英语翻译的广泛任务或仅评估简单的语言理解，缺乏对低资源语言中代码生成能力的全面评估。

Method: 从Eolymp平台收集500个问题，均匀分布在5个难度级别，使用13个领先的专有和开源模型，通过一次性提示生成Python解决方案，在专用环境中进行隐藏测试。

Result: 即使是OpenAI o3和GPT-5等顶级模型也只能解决约50%的问题，在不同难度级别上表现差异明显，同时评估了解决方案的独特性和计算效率。

Conclusion: 竞争性编程基准测试对于评估大语言模型（特别是在代表性不足的语言中）具有重要价值，为多语言代码生成和推理增强模型的研究铺平了道路。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [27] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu*

Main category: cs.CL

TL;DR: 本文发现不同语言模型在上下文聚合模式上存在共性，提出了Order-Level Attention(OLA)作为统一的句法特征表示，并开发了无需训练的跨模型适配器TOA，能够有效提升未见语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常关注单个语言模型或注意力头的上下文聚合模式，缺乏对多个语言模型间共同性的系统分析。探索这种共性可以加深对语言模型的理解并促进跨模型知识迁移。

Method: 提出了Order-Level Attention(OLA)作为注意力展开的阶数分解，发现不同语言模型在同阶OLA上具有显著相似性。基于此开发了Transferable OLA Adapter(TOA)，将OLA作为统一句法特征表示训练适配器。

Result: 实验证明TOA的跨语言模型泛化能力能够有效提升未见语言模型的性能，适配器无需参数更新即可泛化到新模型。

Conclusion: 不同语言模型在上下文聚合模式上存在系统性共性，OLA可作为有效的跨模型句法特征表示，TOA方法实现了无需训练的跨模型知识迁移。

Abstract: In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


### [28] [Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts](https://arxiv.org/abs/2511.05078)
*Manan Sharma,Arya Suneesh,Manish Jain,Pawan Kumar Rajpoot,Prasanna Devadiga,Bharatdeep Hazarika,Ashish Shrivastava,Kishan Gurumurthy,Anshuman B Suresh,Aditya U Baliga*

Main category: cs.CL

TL;DR: 该论文提出了一种多语言虚假信息检测的声明规范化方法，通过系统分解社交媒体帖子为可验证的声明，在仅使用英语数据训练的情况下实现了20种语言的跨语言迁移。


<details>
  <summary>Details</summary>
Motivation: 解决多语言虚假信息检测中的声明规范化问题，将嘈杂的社交媒体帖子转化为清晰可验证的声明，实现跨语言的有效检测。

Method: 使用Qwen3-14B模型，通过LoRA微调，结合帖子内去重、基于token召回率的语义对齐过滤，以及在推理时使用上下文示例的检索增强少样本学习。

Result: 在20种语言上取得了显著效果，METEOR得分从英语的41.16到马拉地语的15.21，在英语排行榜上排名第三，在荷兰语和旁遮普语上排名第四，相比基线配置相对提升了41.3%。

Conclusion: 该方法在罗曼语系和日耳曼语系语言上展示了有效的跨语言泛化能力，同时在不同语言结构中保持了语义连贯性。

Abstract: We address claim normalization for multilingual misinformation detection -
transforming noisy social media posts into clear, verifiable statements across
20 languages. The key contribution demonstrates how systematic decomposition of
posts using Who, What, Where, When, Why and How questions enables robust
cross-lingual transfer despite training exclusively on English data. Our
methodology incorporates finetuning Qwen3-14B using LoRA with the provided
dataset after intra-post deduplication, token-level recall filtering for
semantic alignment and retrieval-augmented few-shot learning with contextual
examples during inference. Our system achieves METEOR scores ranging from 41.16
(English) to 15.21 (Marathi), securing third rank on the English leaderboard
and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative
improvement in METEOR over baseline configurations and substantial gains over
existing methods. Results demonstrate effective cross-lingual generalization
for Romance and Germanic languages while maintaining semantic coherence across
diverse linguistic structures.

</details>


### [29] [On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class](https://arxiv.org/abs/2511.05080)
*P. Bilha Githinji,Aikaterini Meilliou,Peiwu Qin*

Main category: cs.CL

TL;DR: 本研究评估了两种通用大语言模型在文本简化任务中的表现，发现指令调优的Mistral 24B在可读性和语篇保真度平衡方面优于推理增强的QWen2.5 32B，为医疗信息简化提供了基准性能参考。


<details>
  <summary>Details</summary>
Motivation: 随着公众健康信息寻求行为和数字消费的增加，需要可扩展的解决方案来自动将复杂的科学和技术文档转化为通俗语言，但现有文本简化方法在可读性和语篇保真度平衡方面仍面临挑战。

Method: 采用比较分析方法，评估指令调优的Mistral 24B和推理增强的QWen2.5 32B两种通用大语言模型，使用包含21个指标的综合相关性分析，涵盖可读性、语篇保真度、内容安全性和分布测量等维度。

Result: Mistral 24B展现出温和的词汇简化策略，在可读性指标和简化专用公式SARI（均值42.46）上表现优异，同时保持人类水平的语篇保真度（BERTScore 0.91）。QWen2.5 32B虽然也提升了可读性，但在可读性和准确性平衡方面存在脱节，BERTScore显著较低（0.89）。

Conclusion: 研究为文本简化任务建立了LLM的基准性能，确定指令调优的Mistral 24B更适合简化任务，提供了指标选择的必要启发，并指出词汇支持是简化的主要领域适应问题。

Abstract: The increasing health-seeking behavior and digital consumption of biomedical
information by the general public necessitate scalable solutions for
automatically adapting complex scientific and technical documents into plain
language. Automatic text simplification solutions, including advanced large
language models, however, continue to face challenges in reliably arbitrating
the tension between optimizing readability performance and ensuring
preservation of discourse fidelity. This report empirically assesses the
performance of two major classes of general-purpose LLMs, demonstrating their
linguistic capabilities and foundational readiness for the task compared to a
human benchmark. Using a comparative analysis of the instruction-tuned Mistral
24B and the reasoning-augmented QWen2.5 32B, we identify a potential
architectural advantage in the instruction-tuned LLM. Mistral exhibits a
tempered lexical simplification strategy that enhances readability across a
suite of metrics and the simplification-specific formula SARI (mean 42.46),
while preserving human-level discourse with a BERTScore of 0.91. QWen also
attains enhanced readability performance, but its operational strategy shows a
disconnect in balancing between readability and accuracy, reaching a
statistically significantly lower BERTScore of 0.89. Additionally, a
comprehensive correlation analysis of 21 metrics spanning readability,
discourse fidelity, content safety, and underlying distributional measures for
mechanistic insights, confirms strong functional redundancies among five
readability indices. This empirical evidence tracks baseline performance of the
evolving LLMs for the task of text simplification, identifies the
instruction-tuned Mistral 24B for simplification, provides necessary heuristics
for metric selection, and points to lexical support as a primary
domain-adaptation issue for simplification.

</details>


### [30] [Iterative Layer-wise Distillation for Efficient Compression of Large Language Models](https://arxiv.org/abs/2511.05085)
*Grigory Kovalev,Mikhail Tikhomirov*

Main category: cs.CL

TL;DR: 提出了一种基于ShortGPT的改进蒸馏方法，通过迭代评估层重要性来压缩大语言模型，可将Qwen2.5-3B从36层压缩到28层（参数2.47B）仅损失9.7%性能，或压缩到24层损失18%性能。


<details>
  <summary>Details</summary>
Motivation: 开发能够保持高性能的紧凑语言模型，解决现有蒸馏方法的局限性，为资源受限环境提供高效部署方案。

Method: 基于ShortGPT方法改进，通过迭代评估层重要性：移除单个层并测量性能下降，结合KL散度和均方误差的联合损失函数进行进一步训练。

Result: 在Qwen2.5-3B模型上，层数从36减少到28（参数2.47B）仅损失9.7%质量，减少到24层损失18%质量；发现中间transformer层对推理贡献较小。

Conclusion: 迭代蒸馏和微调方法有效，中间transformer层重要性较低，该方法适合在资源受限环境中部署高效模型。

Abstract: This work investigates distillation methods for large language models (LLMs)
with the goal of developing compact models that preserve high performance.
Several existing approaches are reviewed, with a discussion of their respective
strengths and limitations. An improved method based on the ShortGPT approach
has been developed, building upon the idea of incorporating iterative
evaluation of layer importance. At each step, importance is assessed by
measuring performance degradation when individual layers are removed, using a
set of representative datasets. This process is combined with further training
using a joint loss function based on KL divergence and mean squared error.
Experiments on the Qwen2.5-3B model show that the number of layers can be
reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a
9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that
the middle transformer layers contribute less to inference, underscoring the
potential of the proposed method for creating efficient models. The results
demonstrate the effectiveness of iterative distillation and fine-tuning, making
the approach suitable for deployment in resource-limited settings.

</details>


### [31] [A Toolbox for Improving Evolutionary Prompt Search](https://arxiv.org/abs/2511.05120)
*Daniel Grießhaber,Maximilian Kimmich,Johannes Maucher,Ngoc Thang Vu*

Main category: cs.CL

TL;DR: 本文提出了进化提示优化的多项关键改进：分解进化步骤、引入LLM评估器、整合人类反馈、开发高效评估策略，提升了优化质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有进化提示优化方法缺乏稳健的算子和高效评估机制，需要改进以提升优化效果和计算效率。

Method: 1) 将进化分解为独立步骤以增强控制和进化效果；2) 引入基于LLM的评估器验证进化结果；3) 整合人类反馈来精炼进化算子；4) 开发保持性能但降低计算开销的高效评估策略。

Result: 提出的方法在优化质量和效率方面均有提升，代码已开源支持新任务的提示优化和进一步研究。

Conclusion: 通过系统性的改进，进化提示优化方法在质量和效率上得到显著提升，为提示优化领域提供了可推广的解决方案。

Abstract: Evolutionary prompt optimization has demonstrated effectiveness in refining
prompts for LLMs. However, existing approaches lack robust operators and
efficient evaluation mechanisms. In this work, we propose several key
improvements to evolutionary prompt optimization that can partially generalize
to prompt optimization in general: 1) decomposing evolution into distinct steps
to enhance the evolution and its control, 2) introducing an LLM-based judge to
verify the evolutions, 3) integrating human feedback to refine the evolutionary
operator, and 4) developing more efficient evaluation strategies that maintain
performance while reducing computational overhead. Our approach improves both
optimization quality and efficiency. We release our code, enabling prompt
optimization on new tasks and facilitating further research in this area.

</details>


### [32] [ManufactuBERT: Efficient Continual Pretraining for Manufacturing](https://arxiv.org/abs/2511.05135)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: ManufactuBERT是一个专门针对制造领域的RoBERTa模型，通过持续预训练在制造领域的大规模语料上，在制造相关的NLP任务中取得了新的最先进性能，同时通过精心去重的语料训练显著减少了33%的训练时间和计算成本。


<details>
  <summary>Details</summary>
Motivation: 通用Transformer编码器在制造等专业领域表现不佳，因为缺乏对领域特定术语和语义的接触，需要开发专门针对制造领域的预训练模型。

Method: 提出了一个全面的数据处理流程，从网络数据中筛选制造领域相关内容，包括初始领域特定过滤和多阶段去重过程，然后基于去重后的语料对RoBERTa模型进行持续预训练。

Result: ManufactuBERT在一系列制造相关NLP任务中建立了新的最先进性能，优于强专业基线模型。更重要的是，在精心去重的语料上训练显著加速了收敛，相比未去重数据集减少了33%的训练时间和计算成本。

Conclusion: 提出的流程为在其他专业领域开发高性能编码器提供了可复制的示例，证明了领域特定预训练和语料去重的重要性。

Abstract: While large general-purpose Transformer-based encoders excel at general
language understanding, their performance diminishes in specialized domains
like manufacturing due to a lack of exposure to domain-specific terminology and
semantics. In this paper, we address this gap by introducing ManufactuBERT, a
RoBERTa model continually pretrained on a large-scale corpus curated for the
manufacturing domain. We present a comprehensive data processing pipeline to
create this corpus from web data, involving an initial domain-specific
filtering step followed by a multi-stage deduplication process that removes
redundancies. Our experiments show that ManufactuBERT establishes a new
state-of-the-art on a range of manufacturing-related NLP tasks, outperforming
strong specialized baselines. More importantly, we demonstrate that training on
our carefully deduplicated corpus significantly accelerates convergence,
leading to a 33\% reduction in training time and computational cost compared to
training on the non-deduplicated dataset. The proposed pipeline offers a
reproducible example for developing high-performing encoders in other
specialized domains. We will release our model and curated corpus at
https://huggingface.co/cea-list-ia.

</details>


### [33] [Mind the Gap... or Not? How Translation Errors and Evaluation Details Skew Multilingual Results](https://arxiv.org/abs/2511.05162)
*Jan-Thorsten Peter,David Vilar,Tobias Domhan,Dan Malkin,Markus Freitag*

Main category: cs.CL

TL;DR: 该论文发现多语言数学基准MGSM存在翻译错误和答案提取标准化问题，导致LLM在不同语言间性能差距的假象。通过自动质量保证方法修正后，语言差距基本消失。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在不同语言（包括高资源和低资源语言）数学能力上的性能差异，并验证现有基准数据的可靠性。

Method: 分析MGSM多语言数学基准，发现翻译错误；提出自动质量保证方法来修正数据，并改进LLM输出答案的标准化提取方法。

Result: 修正数据后，LLM在不同语言间的性能差距基本消失，与原始结论完全相反。

Conclusion: 多语言基准数据的质量问题可能导致对LLM跨语言能力的不准确评估，需要更严谨的数据质量控制和标准化评估方法。

Abstract: Most current large language models (LLMs) support a wide variety of languages
in addition to English, including high-resource languages (e.g. German,
Chinese, French), as well as low-resource ones (e.g. Swahili, Telugu). In
addition they have also shown impressive capabilities in different domains,
like coding, science and math. In this short paper, taking math as an example
domain, we study the performance of different LLMs across languages.
Experimental results show that there exists a non-negligible and consistent gap
in the performance of the models across languages. Interestingly, and somewhat
against expectations, the gap exists for both high- and low-resource languages.
We hope that these results influence further research into cross-lingual
capability generalization for next generation LLMs. If it weren't for the fact
that they are false! By analyzing one of the standard multilingual math
benchmarks (MGSM), we determine that several translation errors are present in
the data. Furthermore, the lack of standardized answer extraction from LLM
outputs further influences the final results. We propose a method for automatic
quality assurance to address the first issue at scale, and give recommendations
to address the second one. Combining these two approaches we show that the
aforementioned language gap mostly disappears, leading to completely different
conclusions from our research. We additionally release the corrected dataset to
the community.

</details>


### [34] [Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models](https://arxiv.org/abs/2511.05184)
*Cong-Thanh Do,Rama Doddipatla,Kate Knill*

Main category: cs.CL

TL;DR: 本文研究在知识蒸馏中使用思维链提示来将大型语言模型的推理能力迁移到小型语言模型，实验证明该方法能有效提升蒸馏模型在复杂推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 思维链提示已被证明能提升大语言模型的推理能力，但如何将这种推理能力从大模型迁移到小模型仍是一个重要问题。本文旨在探索在知识蒸馏中使用思维链数据来提升小模型的推理能力。

Method: 使用白盒知识蒸馏方法，基于Qwen和Llama2系列模型，利用CoT-Collection数据集中的思维链数据对模型进行蒸馏训练。

Result: 蒸馏后的模型在BIG-Bench-Hard基准测试的自然语言推理和理解任务中取得了更好的平均性能，证明了思维链在提升知识蒸馏效果方面的作用。

Conclusion: 思维链提示在知识蒸馏中发挥了重要作用，能够有效将大型语言模型的推理能力迁移到小型语言模型，提升其在复杂自然语言推理任务上的表现。

Abstract: Chain-of-Thought (CoT) prompting is a widely used method to improve the
reasoning capability of Large Language Models (LLMs). More recently, CoT has
been leveraged in Knowledge Distillation (KD) to transfer reasoning capability
from a larger LLM to a smaller one. This paper examines the role of CoT in
distilling the reasoning capability from larger LLMs to smaller LLMs using
white-box KD, analysing its effectiveness in improving the performance of the
distilled models for various natural language reasoning and understanding
tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2
families, employing CoT data from the CoT-Collection dataset. The distilled
models are then evaluated on natural language reasoning and understanding tasks
from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for
smaller LLMs. Experimental results demonstrate the role of CoT in improving
white-box KD effectiveness, enabling the distilled models to achieve better
average performance in natural language reasoning and understanding tasks from
BBH.

</details>


### [35] [Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese](https://arxiv.org/abs/2511.05239)
*Zilong Li,Jie Cao*

Main category: cs.CL

TL;DR: 将古代汉语翻译成日语的过程抽象为序列标注任务，通过LLM标注管道构建数据集，在低资源环境下通过引入中文NLP辅助任务提升序列标注性能。


<details>
  <summary>Details</summary>
Motivation: 研究古代汉语到日语的翻译系统面临低资源问题，需要开发有效的标注和翻译方法。

Method: 引入基于LLM的标注管道，从数字化开源翻译数据构建新数据集，在低资源设置下引入辅助中文NLP任务。

Result: 大语言模型在直接机器翻译中表现优异，但在字符标注任务中表现困惑；所提方法可作为LLM的补充。

Conclusion: 提出的LLM标注管道和辅助任务方法在低资源环境下有效，能够补充大语言模型在字符标注任务中的不足。

Abstract: Ancient people translated classical Chinese into Japanese by annotating
around each character. We abstract this process as sequence tagging tasks and
fit them into modern language technologies. The research of this annotation and
translation system is a facing low-resource problem. We release this problem by
introducing a LLM-based annotation pipeline and construct a new dataset from
digitalized open-source translation data. We show that under the low-resource
setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the
training of sequence tagging tasks. We also evaluate the performance of large
language models. They achieve high scores in direct machine translation, but
they are confused when being asked to annotate characters. Our method could
work as a supplement of LLMs.

</details>


### [36] [Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](https://arxiv.org/abs/2511.05286)
*Teqi Hao,Xioayu Tan,Shaojie Shi,Yinghui Xu,Xihe Qiu*

Main category: cs.CL

TL;DR: RPO框架通过解耦内容生成与个性化对齐，采用两阶段方法：首先生成通用高质量回答，然后通过反思模块重写以匹配用户偏好，显著提升个性化效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于上下文注入的LLM个性化方法存在双重负担，需要在生成准确内容的同时对齐用户风格，导致输出质量下降和控制精度有限。

Method: 提出RPO框架：1）基础模型生成通用高质量回答；2）外部反思模块重写输出以对齐用户偏好；3）采用两阶段训练：监督微调建立个性化推理策略，强化学习优化个性化输出质量。

Result: 在LaMP基准测试中，RPO显著优于现有最优基线方法，证明了显式响应重塑优于隐式上下文注入。

Conclusion: RPO提供了一种高效、模型无关的个性化层，可无缝集成到任何基础模型中，为用户中心生成场景开辟了新方向。

Abstract: The personalization of black-box large language models (LLMs) is a critical
yet challenging task. Existing approaches predominantly rely on context
injection, where user history is embedded into the prompt to directly guide the
generation process. However, this single-step paradigm imposes a dual burden on
the model: generating accurate content while simultaneously aligning with
user-specific styles. This often results in a trade-off that compromises output
quality and limits precise control. To address this fundamental tension, we
propose Reflective Personalization Optimization (RPO), a novel framework that
redefines the personalization paradigm by decoupling content generation from
alignment. RPO operates in two distinct stages: first, a base model generates a
high-quality, generic response; then, an external reflection module explicitly
rewrites this output to align with the user's preferences. This reflection
module is trained using a two-stage process. Initially, supervised fine-tuning
is employed on structured rewriting trajectories to establish a core
personalized reasoning policy that models the transformation from generic to
user-aligned responses. Subsequently, reinforcement learning is applied to
further refine and enhance the quality of the personalized outputs.
Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by
decoupling content generation from personalization, significantly outperforms
state-of-the-art baselines. These findings underscore the superiority of
explicit response shaping over implicit context injection. Moreover, RPO
introduces an efficient, model-agnostic personalization layer that can be
seamlessly integrated with any underlying base model, paving the way for a new
and effective direction in user-centric generation scenarios.

</details>


### [37] [Listening Between the Lines: Decoding Podcast Narratives with Language Modeling](https://arxiv.org/abs/2511.05310)
*Shreya Gupta,Ojasva Saxena,Arghodeep Nandi,Sarah Masud,Kiran Garimella,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 开发了一种针对播客对话数据的叙事框架分析方法，通过微调BERT模型将抽象叙事框架与具体实体关联，解决了现有大语言模型在处理非结构化对话数据时的局限性。


<details>
  <summary>Details</summary>
Motivation: 播客已成为塑造公众意见的重要媒介，但其非脚本化、多主题和对话式的特点使得自动分析面临挑战。现有语言模型难以捕捉人类听众依赖的微妙线索来识别叙事框架。

Method: 开发并评估了一个微调BERT模型，将叙事框架明确链接到对话中提到的特定实体，使抽象框架在具体细节中落地。然后使用这些细粒度框架标签并将其与高级主题关联。

Result: 提出了一种新的框架标注方法，更接近人类对混乱对话数据的判断，并揭示了讨论内容（主题）与呈现方式（框架）之间的系统性关系。

Conclusion: 该方法为研究数字媒体影响力提供了一个更强大的框架，能够更准确地分析播客叙事结构，理解当代话语的形成机制。

Abstract: Podcasts have become a central arena for shaping public opinion, making them
a vital source for understanding contemporary discourse. Their typically
unscripted, multi-themed, and conversational style offers a rich but complex
form of data. To analyze how podcasts persuade and inform, we must examine
their narrative structures -- specifically, the narrative frames they employ.
  The fluid and conversational nature of podcasts presents a significant
challenge for automated analysis. We show that existing large language models,
typically trained on more structured text such as news articles, struggle to
capture the subtle cues that human listeners rely on to identify narrative
frames. As a result, current approaches fall short of accurately analyzing
podcast narratives at scale.
  To solve this, we develop and evaluate a fine-tuned BERT model that
explicitly links narrative frames to specific entities mentioned in the
conversation, effectively grounding the abstract frame in concrete details. Our
approach then uses these granular frame labels and correlates them with
high-level topics to reveal broader discourse trends. The primary contributions
of this paper are: (i) a novel frame-labeling methodology that more closely
aligns with human judgment for messy, conversational data, and (ii) a new
analysis that uncovers the systematic relationship between what is being
discussed (the topic) and how it is being presented (the frame), offering a
more robust framework for studying influence in digital media.

</details>


### [38] [What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions](https://arxiv.org/abs/2511.05320)
*Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal*

Main category: cs.CL

TL;DR: 本研究比较了正则表达式和大型语言模型从斯洛伐克法院判决书中提取犯罪行为描述的可行性，发现两种先进方法都能达到97%以上的提取率，结合使用时可达99.5%，且与人工标注的匹配度约90%。


<details>
  <summary>Details</summary>
Motivation: 刑事司法行政数据中关于犯罪行为的详细信息有限，而欧洲大陆法院判决书中包含丰富的犯罪行为描述，这些信息目前未被充分利用。

Method: 使用两种方法：1）正则表达式方法（基础版和进阶版），基础版识别描述前后的典型词语，进阶版关注"sparing"及其规范化形式；2）大型语言模型方法，使用Gemini Flash 2.0模型根据预设指令提取描述。

Result: 基础正则表达式方法仅在40.5%的判决书中识别出描述，而进阶正则表达式达到97%，LLMs达到98.75%，两者结合达到99.5%。法律学生评估显示，两种先进方法与人工标注的匹配度约90%，而基础方法仅为34.5%。

Conclusion: 从公开的法院判决书中提取犯罪行为描述是可行的，正则表达式和LLMs都能有效完成此任务，结合使用时效果最佳，为刑事司法研究提供了新的数据来源。

Abstract: Criminal justice administrative data contain only a limited amount of
information about the committed offense. However, there is an unused source of
extensive information in continental European courts' decisions: descriptions
of criminal behaviors in verdicts by which offenders are found guilty. In this
paper, we study the feasibility of extracting these descriptions from publicly
available court decisions from Slovakia. We use two different approaches for
retrieval: regular expressions and large language models (LLMs). Our baseline
was a simple method employing regular expressions to identify typical words
occurring before and after the description. The advanced regular expression
approach further focused on "sparing" and its normalization (insertion of
spaces between individual letters), typical for delineating the description.
The LLM approach involved prompting the Gemini Flash 2.0 model to extract the
descriptions using predefined instructions. Although the baseline identified
descriptions in only 40.5% of verdicts, both methods significantly outperformed
it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and
99.5% when combined. Evaluation by law students showed that both advanced
methods matched human annotations in about 90% of cases, compared to just 34.5%
for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of
instances, and a combination of advanced regular expressions with LLMs reached
92%.

</details>


### [39] [Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE](https://arxiv.org/abs/2511.05324)
*Firoj Ahmmed Patwary,Abdullah Al Noman*

Main category: cs.CL

TL;DR: 提出了BengaliBPE，一个专门为孟加拉语设计的BPE分词器，通过Unicode归一化、字素级初始化和形态感知合并规则来改善孟加拉语的分词效果。


<details>
  <summary>Details</summary>
Motivation: 现有的子词分词器（如SentencePiece或HuggingFace BPE）主要针对拉丁语或多语言语料库设计，在形态丰富的语言如孟加拉语上表现不佳。

Method: 开发BengaliBPE分词器，应用Unicode归一化、字素级初始化和形态感知合并规则，使用大规模孟加拉语新闻分类数据集与三种基线方法（空格分词、SentencePiece BPE、HuggingFace BPE）进行比较。

Result: 所有方法表现都相当好，但BengaliBPE提供了最详细的分割和最好的形态可解释性，尽管计算成本略高。

Conclusion: 研究强调了语言感知分词对于形态丰富语言的重要性，BengaliBPE为未来孟加拉语NLP系统（包括大规模预训练语言模型）奠定了坚实基础。

Abstract: Tokenization is an important first step in Natural Language Processing (NLP)
pipelines because it decides how models learn and represent linguistic
information. However, current subword tokenizers like SentencePiece or
HuggingFace BPE are mostly designed for Latin or multilingual corpora and do
not perform well on languages with rich morphology such as Bengali. To address
this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer
specifically developed for the Bengali script. BengaliBPE applies Unicode
normalization, grapheme-level initialization, and morphology-aware merge rules
to maintain linguistic consistency and preserve subword integrity. We use a
large-scale Bengali news classification dataset to compare BengaliBPE with
three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The
evaluation considers tokenization granularity, encoding speed, and downstream
classification accuracy. While all methods perform reasonably well, BengaliBPE
provides the most detailed segmentation and the best morphological
interpretability, albeit with slightly higher computational cost. These
findings highlight the importance of language-aware tokenization for
morphologically rich scripts and establish BengaliBPE as a strong foundation
for future Bengali NLP systems, including large-scale pretraining of contextual
language models.

</details>


### [40] [A multimodal multiplex of the mental lexicon for multilingual individuals](https://arxiv.org/abs/2511.05361)
*Maria Huynh,Wilder C. Rodrigues*

Main category: cs.CL

TL;DR: 本研究探讨多语言者的心理词典结构，特别是视觉输入如何影响翻译任务中的语言习得和准确性。


<details>
  <summary>Details</summary>
Motivation: 历史上双语被视为认知负担，但近30年研究表明多语言者在语言和认知任务中表现优于单语者。本研究旨在探索多语言心理词典的结构，特别是视觉输入对语言习得的影响。

Method: 基于Stella等人(2018)的爆炸性学习研究和Dijkstra与van Heuven(2002)的BIA+框架，采用Kivela等人(2014)的多层网络原则，在多重模型中引入多模态性，添加连接视觉输入与多语言心理词典词汇表征的额外层。

Result: 研究设计扩展了先前研究，通过引入视觉输入层来探索视觉输入在翻译任务中对语言熟练度和准确性的影响。

Conclusion: 本研究旨在验证视觉输入是否比纯文本条件更能影响参与者在翻译任务中的语言熟练度和准确性，特别关注遗产语言对另一语言习得的影响。

Abstract: Historically, bilingualism was often perceived as an additional cognitive
load that could hinder linguistic and intellectual development. However, over
the last three decades, this view has changed considerably. Numerous studies
have aimed to model and understand the architecture of the bilingual word
recognition system Dijkstra and van Heuven (2002), investigating how parallel
activation operates in the brain and how one language influences another Kroll
et al. (2015). Increasingly, evidence suggests that multilinguals, individuals
who speak three or more languages, can perform better than monolinguals in
various linguistic and cognitive tasks, such as learning an additional language
Abu-Rabia and Sanitsky (2010). This research proposal focuses on the study of
the mental lexicon and how it may be structured in individuals who speak
multiple languages. Building on the work of Stella et al. (2018), who
investigated explosive learning in humans using a multiplex model of the mental
lexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by
Dijkstra and van Heuven (2002), the present study applies the same multilayer
network principles introduced by Kivela et al. (2014). Our experimental design
extends previous research by incorporating multimodality into the multiplex
model, introducing an additional layer that connects visual inputs to their
corresponding lexical representations across the multilingual layers of the
mental lexicon. In this research, we aim to explore how a heritage language
influences the acquisition of another language. Specifically, we ask: Does the
presence of visual input in a translation task influence participants'
proficiency and accuracy compared to text-only conditions?

</details>


### [41] [Large Language Models for Explainable Threat Intelligence](https://arxiv.org/abs/2511.05406)
*Tiago Dinis,Miguel Correia,Roger Tavares*

Main category: cs.CL

TL;DR: RAGRecon系统使用检索增强生成（RAG）与大语言模型结合，通过实时信息检索和领域特定数据获取网络安全威胁情报，并通过可视化知识图谱提高AI的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统安全机制难以应对日益复杂的网络威胁，而大语言模型在文本处理和生成方面的先进能力为网络安全提供了重要潜力。

Method: 提出RAGRecon系统，将LLM与RAG技术结合，通过实时信息检索和领域特定数据来回答网络安全威胁问题，并为每个回复生成可视化知识图谱以提高可解释性。

Result: 在两个数据集和七个不同LLM上的实验评估显示，最佳组合的响应与参考响应匹配率超过91%。

Conclusion: RAGRecon系统成功结合了LLM和RAG技术，不仅能够有效获取网络安全威胁情报，还通过可视化知识图谱提高了AI系统的透明度和可解释性，使分析师能够更好地理解系统基于RAG恢复上下文所做的连接。

Abstract: As cyber threats continue to grow in complexity, traditional security
mechanisms struggle to keep up. Large language models (LLMs) offer significant
potential in cybersecurity due to their advanced capabilities in text
processing and generation. This paper explores the use of LLMs with
retrieval-augmented generation (RAG) to obtain threat intelligence by combining
real-time information retrieval with domain-specific data. The proposed system,
RAGRecon, uses a LLM with RAG to answer questions about cybersecurity threats.
Moreover, it makes this form of Artificial Intelligence (AI) explainable by
generating and visually presenting to the user a knowledge graph for every
reply. This increases the transparency and interpretability of the reasoning of
the model, allowing analysts to better understand the connections made by the
system based on the context recovered by the RAG system. We evaluated RAGRecon
experimentally with two datasets and seven different LLMs and the responses
matched the reference responses more than 91% of the time for the best
combinations.

</details>


### [42] [Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning](https://arxiv.org/abs/2511.05407)
*Yahui Fu,Zi Haur Pang,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 提出了一个统一框架来建模个体和群体级别的用户满意度偏好，通过个性化推理链和期望最大化聚类算法，结合强化学习实现偏好自适应优化。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统对齐方法通常训练通用模型追求广泛共识，但忽略了少数用户群体的特定偏好和个体差异，导致少数用户满意度评估不准确。

Method: 1) Chain-of-Personalized-Reasoning (CoPeR) 通过可解释推理链捕捉个体偏好；2) 期望最大化基础的多数-少数偏好感知聚类算法 (M2PC) 无监督发现用户群体；3) 偏好自适应强化学习框架 (PAda-PPO) 联合优化个体和群体偏好对齐。

Result: 在情感支持对话数据集上的实验表明，用户满意度估计得到持续改进，特别是对于代表性不足的用户群体。

Conclusion: 该框架通过同时建模个体和群体偏好，有效提升了对话系统中用户满意度估计的准确性，特别是在处理少数用户群体偏好方面表现出色。

Abstract: User satisfaction in dialogue systems is inherently subjective. When the same
response strategy is applied across users, minority users may assign different
satisfaction ratings than majority users due to variations in individual
intents and preferences. However, existing alignment methods typically train
one-size-fits-all models that aim for broad consensus, often overlooking
minority perspectives and user-specific adaptation. We propose a unified
framework that models both individual- and group-level preferences for user
satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning
(CoPeR) to capture individual preferences through interpretable reasoning
chains. Second, we propose an expectation-maximization-based Majority-Minority
Preference-Aware Clustering (M2PC) algorithm that discovers distinct user
groups in an unsupervised manner to learn group-level preferences. Finally, we
integrate these components into a preference-adaptive reinforcement learning
framework (PAda-PPO) that jointly optimizes alignment with both individual and
group preferences. Experiments on the Emotional Support Conversation dataset
demonstrate consistent improvements in user satisfaction estimation,
particularly for underrepresented user groups.

</details>


### [43] [Steering Language Models with Weight Arithmetic](https://arxiv.org/abs/2511.05408)
*Constanza Fierro,Fabien Roger*

Main category: cs.CL

TL;DR: 提出了一种名为对比权重引导的简单后训练方法，通过权重算术编辑模型参数，利用狭窄训练数据更好地控制模型行为


<details>
  <summary>Details</summary>
Motivation: 为大型语言模型提供多样化训练分布的高质量反馈既困难又昂贵，而仅提供狭窄分布的反馈可能导致意外的泛化问题

Method: 通过从两个小型微调中减去权重增量来隔离权重空间中的行为方向——一个诱导期望行为，另一个诱导相反行为——然后添加或移除这个方向来修改模型权重

Result: 权重引导比激活引导具有更好的泛化能力，在通用能力退化前实现更强的分布外行为控制；在任务特定微调中能部分减轻不良行为漂移；初步证据表明可以通过测量微调更新与'邪恶'权重方向的相似性来检测新兴错位

Conclusion: 对比权重引导是一种有效的后训练方法，能够更好地利用狭窄训练数据来控制模型行为，同时提供监测训练过程中权重演化的可能性

Abstract: Providing high-quality feedback to Large Language Models (LLMs) on a diverse
training distribution can be difficult and expensive, and providing feedback
only on a narrow distribution can result in unintended generalizations. To
better leverage narrow training data, we propose contrastive weight steering, a
simple post-training method that edits the model parameters using weight
arithmetic. We isolate a behavior direction in weight-space by subtracting the
weight deltas from two small fine-tunes -- one that induces the desired
behavior and another that induces its opposite -- and then add or remove this
direction to modify the model's weights. We apply this technique to mitigate
sycophancy and induce misalignment, and find that weight steering often
generalizes further than activation steering, achieving stronger
out-of-distribution behavioral control before degrading general capabilities.
We also show that, in the context of task-specific fine-tuning, weight steering
can partially mitigate undesired behavioral drift: it can reduce sycophancy and
under-refusals introduced during fine-tuning while preserving task performance
gains. Finally, we provide preliminary evidence that emergent misalignment can
be detected by measuring the similarity between fine-tuning updates and an
"evil" weight direction, suggesting that it may be possible to monitor the
evolution of weights during training and detect rare misaligned behaviors that
never manifest during training or evaluations.

</details>


### [44] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu,Shiqi Wang,Vasile Rus*

Main category: cs.CL

TL;DR: 提出MIMIC-SR-ICD11数据集和LL-Rank重排序框架，通过基于PMI的评分方法在疾病诊断任务中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 疾病诊断是现代医疗的核心，但电子健康记录中的模板化文档往往会丢失患者自我报告中的临床重要信号和细微但关键的细节。

Method: 构建MIMIC-SR-ICD11数据集，并提出LL-Rank重排序框架，该框架计算给定临床报告上下文中每个标签的长度归一化联合似然，并减去相应的无报告先验似然。

Result: 在七个模型骨干上，LL-Rank始终优于强生成加映射基线方法（GenMap）。消融实验表明LL-Rank的改进主要来自其基于PMI的评分，该评分将语义兼容性与标签频率偏差隔离开来。

Conclusion: LL-Rank框架通过基于PMI的评分方法有效提升了疾病诊断的准确性，解决了标签频率偏差问题，为临床诊断提供了更可靠的工具。

Abstract: Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [45] [Association via Entropy Reduction](https://arxiv.org/abs/2511.04901)
*Anthony Gamst,Lawrence Wilson*

Main category: cs.IR

TL;DR: 本文提出了一种新的文档关联度评分方法aver，在大型图数据中比传统的tf-idf方法表现更好，特别是在寻找关联顶点对方面。


<details>
  <summary>Details</summary>
Motivation: 在神经网络成功应用之前，tf-idf被认为是识别文档相关性的最佳选择，但作者发现tf-idf在某些场景下存在局限性，特别是在大型图数据中寻找关联顶点对时。

Method: 提出aver评分方法，该方法基于简单统计模型下的熵推导而来，相比tf-idf具有更自然的理论基础。

Result: 在带有真实关联标注的数据集上，aver在寻找关联对方面表现优于tf-idf，并且具有自然阈值、能区分tf-idf得分相同的文档对、可应用于更大文档集合等优势。

Conclusion: aver是一种比tf-idf更自然且在某些场景下更有效的文档关联度评分方法，特别是在神经网络不是明显最佳选择的大型图数据分析中。

Abstract: Prior to recent successes using neural networks, term frequency-inverse
document frequency (tf-idf) was clearly regarded as the best choice for
identifying documents related to a query. We provide a different score, aver,
and observe, on a dataset with ground truth marking for association, that aver
does do better at finding assciated pairs than tf-idf. This example involves
finding associated vertices in a large graph and that may be an area where
neural networks are not currently an obvious best choice. Beyond this one
anecdote, we observe that (1) aver has a natural threshold for declaring pairs
as unassociated while tf-idf does not, (2) aver can distinguish between pairs
of documents for which tf-idf gives a score of 1.0, (3) aver can be applied to
larger collections of documents than pairs while tf-idf cannot, and (4) that
aver is derived from entropy under a simple statistical model while tf-idf is a
construction designed to achieve a certain goal and hence aver may be more
"natural." To be fair, we also observe that (1) writing down and computing the
aver score for a pair is more complex than for tf-idf and (2) that the fact
that the aver score is naturally scale-free makes it more complicated to
interpret aver scores.

</details>


### [46] [Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG](https://arxiv.org/abs/2511.04939)
*Harshit Nainwani,Hediyeh Baban*

Main category: cs.IR

TL;DR: SINR框架将检索系统分为细粒度搜索和粗粒度检索两个独立过程，通过双层级架构提升系统的可组合性、可扩展性和上下文保真度。


<details>
  <summary>Details</summary>
Motivation: 现有检索系统混淆了查找相关信息（搜索）和提供推理上下文（检索）两个不同过程，需要更清晰的架构区分。

Method: 提出Search-Is-Not-Retrieve (SINR)框架，采用双层级架构：细粒度搜索表示用于精确语义匹配，粗粒度检索上下文用于完整推理。通过直接连接小搜索块和大检索块实现高效处理。

Result: SINR框架将检索从被动步骤转变为主动过程，使系统架构更符合人类信息处理方式，同时不增加额外处理成本。

Conclusion: SINR为下一代AI检索系统提供了实用的概念基础，通过区分搜索和检索过程来提升系统性能。

Abstract: Retrieval systems are essential to contemporary AI pipelines, although most
confuse two separate processes: finding relevant information and giving enough
context for reasoning. We introduce the Search-Is-Not-Retrieve (SINR)
framework, a dual-layer architecture that distinguishes between fine-grained
search representations and coarse-grained retrieval contexts. SINR enhances the
composability, scalability, and context fidelity of retrieval systems by
directly connecting small, semantically accurate search chunks to larger,
contextually complete retrieve chunks, all without incurring extra processing
costs. This design changes retrieval from a passive step to an active one,
making the system architecture more like how people process information. We
discuss the SINR framework's conceptual foundation, formal structure,
implementation issues, and qualitative outcomes. This provides a practical
foundation for the next generation of AI systems that use retrieval.

</details>


### [47] [Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval](https://arxiv.org/abs/2511.05000)
*Hyunkyu Kim,Yeeun Yoo,Youngjun Kwak*

Main category: cs.IR

TL;DR: 提出了一种基于LLM的领域特定信息检索基准构建方法，并创建了银行领域的KoBankIR基准，包含815个查询和204份官方银行文档，实验显示现有检索模型在处理复杂多文档查询时表现不佳。


<details>
  <summary>Details</summary>
Motivation: 金融领域LLM应用中准确的信息检索至关重要，但现有基准无法捕捉真实银行场景的复杂领域特定信息需求，且构建领域特定基准成本高且受法律限制。

Method: 提出系统性方法，通过LLM生成查询，结合单文档和多文档查询生成，以及增强的推理辅助可回答性评估方法，构建KoBankIR基准。

Result: 构建了包含815个查询和204份官方银行文档的KoBankIR基准，实验表明现有检索模型在处理复杂多文档查询时表现不佳。

Conclusion: 提出的系统化方法能有效构建领域特定IR基准，凸显了金融领域需要改进检索技术的需求。

Abstract: As financial applications of large language models (LLMs) gain attention,
accurate Information Retrieval (IR) remains crucial for reliable AI services.
However, existing benchmarks fail to capture the complex and domain-specific
information needs of real-world banking scenarios. Building domain-specific IR
benchmarks is costly and constrained by legal restrictions on using real
customer data. To address these challenges, we propose a systematic methodology
for constructing domain-specific IR benchmarks through LLM-based query
generation. As a concrete implementation of this methodology, our pipeline
combines single and multi-document query generation with an enhanced and
reasoning-augmented answerability assessment method, achieving stronger
alignment with human judgments than prior approaches. Using this methodology,
we construct KoBankIR, comprising 815 queries derived from 204 official banking
documents. Our experiments show that existing retrieval models struggle with
the complex multi-document queries in KoBankIR, demonstrating the value of our
systematic approach for domain-specific benchmark construction and underscoring
the need for improved retrieval techniques in financial domains.

</details>


### [48] [Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR](https://arxiv.org/abs/2511.05079)
*Grigory Kovalev,Natalia Loukachevitch,Mikhail Tikhomirov,Olga Babina,Pavel Mamaev*

Main category: cs.IR

TL;DR: 本文构建了基于俄语维基百科的新信息检索数据集，支持事实核查、检索增强生成等任务，通过实验发现词法检索在全文检索中表现更好，而神经模型在短文本语义理解上更优。


<details>
  <summary>Details</summary>
Motivation: 扩展俄语信息检索资源，解决现有俄语IR数据集不足的问题，为事实核查、检索增强生成等任务提供更好的评估基准。

Method: 从俄语维基百科的"你知道吗..."部分构建数据集，包含句子级别的分级相关性标注，比较BM25等词法检索模型与针对俄语优化的神经架构及多语言模型。

Result: 词法检索方法在全文检索中优于神经模型，而神经方法在事实核查等短文本任务中表现更好；结合检索和神经重排序能持续提升性能。

Conclusion: 新数据集扩展了俄语信息检索研究资源，强调了准确评估检索模型的重要性，所有数据集和实现代码均已公开以促进可复现性和未来研究。

Abstract: In this paper, we present a novel series of Russian information retrieval
datasets constructed from the "Did you know..." section of Russian Wikipedia.
Our datasets support a range of retrieval tasks, including fact-checking,
retrieval-augmented generation, and full-document retrieval, by leveraging
interesting facts and their referenced Wikipedia articles annotated at the
sentence level with graded relevance. We describe the methodology for dataset
creation that enables the expansion of existing Russian Information Retrieval
(IR) resources. Through extensive experiments, we extend the RusBEIR research
by comparing lexical retrieval models, such as BM25, with state-of-the-art
neural architectures fine-tuned for Russian, as well as multilingual models.
Results of our experiments show that lexical methods tend to outperform neural
models on full-document retrieval, while neural approaches better capture
lexical semantics in shorter texts, such as in fact-checking or fine-grained
retrieval. Using our newly created datasets, we also analyze the impact of
document length on retrieval performance and demonstrate that combining
retrieval with neural reranking consistently improves results. Our contribution
expands the resources available for Russian information retrieval research and
highlights the importance of accurate evaluation of retrieval models to achieve
optimal performance. All datasets are publicly available at HuggingFace. To
facilitate reproducibility and future research, we also release the full
implementation on GitHub.

</details>


### [49] [QUESTER: Query Specification for Generative Retrieval](https://arxiv.org/abs/2511.05301)
*Arthur Satouf,Yuxuan Zong,Habiboulaye Amadou-Boubacar,Pablo Piantanida,Benjamin Piwowarski*

Main category: cs.IR

TL;DR: QUESTER将生成式检索重构为查询规范生成，使用小型LLM生成BM25关键词查询，通过强化学习训练，在领域内外评估中效果优于BM25，与神经IR模型竞争，同时保持良好效率。


<details>
  <summary>Details</summary>
Motivation: 传统生成式检索将相关性存储在模型参数中直接生成文档标识符，但存在泛化能力差和扩展成本高的问题。

Method: 将生成式检索重构为查询规范生成，使用小型LLM生成BM25关键词查询，采用强化学习技术（GRPO）训练策略。

Result: 在领域内外评估中，QUESTER比BM25更有效，与神经IR模型竞争，同时保持良好效率。

Conclusion: QUESTER通过查询规范生成的方法解决了传统生成式检索的泛化和扩展问题，在保持效率的同时实现了与先进神经IR模型竞争的性能。

Abstract: Generative Retrieval (GR) differs from the traditional index-then-retrieve
pipeline by storing relevance in model parameters and directly generating
document identifiers. However, GR often struggles to generalize and is costly
to scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval),
which reframes GR as query specification generation - in this work, a simple
keyword query handled by BM25 - using a (small) LLM. The policy is trained
using reinforcement learning techniques (GRPO). Across in- and out-of-domain
evaluations, we show that our model is more effective than BM25, and
competitive with neural IR models, while maintaining a good efficiency

</details>


### [50] [TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2511.05385)
*Chao Zhang,Yuhao Wang,Derong Xu,Haoxin Zhang,Yuanjie Lyu,Yuhao Chen,Shuochen Liu,Tong Xu,Xiangyu Zhao,Yan Gao,Yao Hu,Enhong Chen*

Main category: cs.IR

TL;DR: TeaRAG是一个令牌高效的代理式检索增强生成框架，通过压缩检索内容和推理步骤，在提高准确性的同时大幅减少令牌使用量。


<details>
  <summary>Details</summary>
Motivation: 现有的代理式RAG系统虽然通过强化学习提高了准确性，但搜索和推理过程会产生大量令牌开销，这种权衡牺牲了效率。

Method: 1) 通过图检索和知识关联图压缩检索内容，使用个性化PageRank突出关键知识；2) 提出迭代过程感知直接偏好优化(IP-DPO)，通过知识匹配机制评估知识充足性并惩罚过多推理步骤。

Result: 在六个数据集上，TeaRAG将Llama3-8B-Instruct和Qwen2.5-14B-Instruct的平均精确匹配分别提高了4%和2%，同时输出令牌减少了61%和59%。

Conclusion: TeaRAG成功解决了代理式RAG中准确性-效率的权衡问题，在保持高准确性的同时显著提高了效率。

Abstract: Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment
Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs
autonomous, multi-round retrieval and reasoning to resolve queries. Although
recent agentic RAG has improved via reinforcement learning, they often incur
substantial token overhead from search and reasoning processes. This trade-off
prioritizes accuracy over efficiency. To address this issue, this work proposes
TeaRAG, a token-efficient agentic RAG framework capable of compressing both
retrieval content and reasoning steps. 1) First, the retrieved content is
compressed by augmenting chunk-based semantic retrieval with a graph retrieval
using concise triplets. A knowledge association graph is then built from
semantic similarity and co-occurrence. Finally, Personalized PageRank is
leveraged to highlight key knowledge within this graph, reducing the number of
tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative
Process-aware Direct Preference Optimization (IP-DPO) is proposed.
Specifically, our reward function evaluates the knowledge sufficiency by a
knowledge matching mechanism, while penalizing excessive reasoning steps. This
design can produce high-quality preference-pair datasets, supporting iterative
DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the
average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on
Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at
https://github.com/Applied-Machine-Learning-Lab/TeaRAG.

</details>
