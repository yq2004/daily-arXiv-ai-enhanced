{"id": "2602.04982", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.04982", "abs": "https://arxiv.org/abs/2602.04982", "authors": ["Deepak Gupta", "Davis Bartels", "Dina Demner-Fuhsman"], "title": "BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations", "comment": "Work in progress", "summary": "With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers. Evaluation of text generated by LLMs remains a challenge for question answering, retrieval-augmented generation (RAG), summarization, and many other natural language processing tasks in the biomedical domain, due to the requirements of expert assessment to verify consistency with the scientific literature and complex medical terminology. In this work, we propose BioACE, an automated framework for evaluating biomedical answers and citations against the facts stated in the answers. The proposed BioACE framework considers multiple aspects, including completeness, correctness, precision, and recall, in relation to the ground-truth nuggets for answer evaluation. We developed automated approaches to evaluate each of the aforementioned aspects and performed extensive experiments to assess and analyze their correlation with human evaluations. In addition, we considered multiple existing approaches, such as natural language inference (NLI) and pre-trained language models and LLMs, to evaluate the quality of evidence provided to support the generated answers in the form of citations into biomedical literature. With the detailed experiments and analysis, we provide the best approaches for biomedical answer and citation evaluation as a part of BioACE (https://github.com/deepaknlp/BioACE) evaluation package.", "AI": {"tldr": "BioACE\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u751f\u7269\u533b\u5b66\u95ee\u7b54\u548c\u5f15\u6587\u8d28\u91cf\uff0c\u6db5\u76d6\u5b8c\u6574\u6027\u3001\u6b63\u786e\u6027\u3001\u7cbe\u786e\u5ea6\u548c\u53ec\u56de\u7387\u7b49\u591a\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e0e\u4eba\u5de5\u8bc4\u4f30\u76f8\u5173\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u533b\u5b66\u95ee\u7b54\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u81ea\u52a8\u5316\u8bc4\u4f30\u751f\u6210\u7b54\u6848\u548c\u5f15\u7528\u8bc1\u636e\u7684\u8d28\u91cf\uff0c\u56e0\u4e3a\u4eba\u5de5\u4e13\u5bb6\u8bc4\u4f30\u6210\u672c\u9ad8\u4e14\u590d\u6742\u3002", "method": "\u63d0\u51fa\u4e86BioACE\u6846\u67b6\uff0c\u91c7\u7528\u81ea\u52a8\u5316\u65b9\u6cd5\u8bc4\u4f30\u7b54\u6848\u7684\u5b8c\u6574\u6027\u3001\u6b63\u786e\u6027\u3001\u7cbe\u786e\u5ea6\u548c\u53ec\u56de\u7387\uff0c\u5e76\u6bd4\u8f83\u4e86NLI\u3001\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548cLLMs\u7b49\u591a\u79cd\u65b9\u6cd5\u8bc4\u4f30\u5f15\u6587\u8d28\u91cf\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u5206\u6790\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30\u4e0e\u4eba\u5de5\u8bc4\u4f30\u7684\u76f8\u5173\u6027\uff0c\u786e\u5b9a\u4e86\u751f\u7269\u533b\u5b66\u7b54\u6848\u548c\u5f15\u6587\u8bc4\u4f30\u7684\u6700\u4f73\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u8bc4\u4f30\u5305\u3002", "conclusion": "BioACE\u4e3a\u751f\u7269\u533b\u5b66\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u5957\u6709\u6548\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8LLMs\u751f\u6210\u7b54\u6848\u548c\u5f15\u7528\u7684\u8d28\u91cf\u8bc4\u4f30\u6548\u7387\u3002"}}
{"id": "2602.05004", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05004", "abs": "https://arxiv.org/abs/2602.05004", "authors": ["Zexin Lin", "Jiachen Yu", "Haoyang Zhang", "Yuzhao Li", "Zhonghang Li", "Yujiu Yang", "Junjie Wang", "Xiaoqiang Ji"], "title": "CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System", "comment": null, "summary": "Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict online token budget. Existing approaches either rely on frequent in-episode reasoning that induces latency and timing jitter, or deliver post-episode improvements through unstructured text that is difficult to compile into reliable low-cost execution. We propose CoWork-X, an active co-evolution framework that casts peer collaboration as a closed-loop optimization problem across episodes, inspired by fast--slow memory separation. CoWork-X instantiates a Skill-Agent that executes via HTN (hierarchical task network)-based skill retrieval from a structured, interpretable, and compositional skill library, and a post-episode Co-Optimizer that performs patch-style skill consolidation with explicit budget constraints and drift regularization. Experiments in challenging Overcooked-AI-like realtime collaboration benchmarks demonstrate that CoWork-X achieves stable, cumulative performance gains while steadily reducing online latency and token usage.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.05035", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05035", "abs": "https://arxiv.org/abs/2602.05035", "authors": ["Sean Trott", "Pamela D. Rivi\u00e8re"], "title": "Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation", "comment": "9 pages, 5 figures, conference", "summary": "Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty'' for lexical disambiguation--a task requiring precise semantic representations and contextualization mechanisms--using controlled datasets of human relatedness judgments for ambiguous words in both English and Spanish. Comparing monolingual and multilingual LMs from the same families, we find consistently reduced performance in multilingual LMs. We then explore three potential capacity constraints: representational (reduced embedding isotropy), attentional (reduced attention to disambiguating cues), and vocabulary-related (increased multi-token segmentation). Multilingual LMs show some evidence of all three limitations; moreover, these factors statistically account for the variance formerly attributed to a model's multilingual status. These findings suggest both that multilingual LMs do suffer from multiple capacity constraints, and that these constraints correlate with reduced disambiguation performance.", "AI": {"tldr": "\u591a\u8bed\u8a00\u8bed\u8a00\u6a21\u578b\u5728\u8bcd\u6c47\u6d88\u6b67\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u5982\u5355\u8bed\u6a21\u578b\uff0c\u5b58\u5728\"\u591a\u8bed\u8a00\u60e9\u7f5a\"\u73b0\u8c61\uff0c\u4e3b\u8981\u6e90\u4e8e\u8868\u5f81\u3001\u6ce8\u610f\u529b\u548c\u8bcd\u6c47\u76f8\u5173\u7684\u4e09\u79cd\u80fd\u529b\u9650\u5236\u3002", "motivation": "\u591a\u8bed\u8a00\u8bed\u8a00\u6a21\u578b\u6709\u65f6\u8868\u73b0\u4e0d\u5982\u5355\u8bed\u6a21\u578b\uff0c\u53ef\u80fd\u662f\u7531\u4e8e\u6a21\u578b\u5bb9\u91cf\u9650\u5236\u3002\u7814\u7a76\u65e8\u5728\u91cf\u5316\u8fd9\u79cd\"\u591a\u8bed\u8a00\u60e9\u7f5a\"\u73b0\u8c61\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7cbe\u786e\u8bed\u4e49\u8868\u5f81\u548c\u4e0a\u4e0b\u6587\u673a\u5236\u7684\u8bcd\u6c47\u6d88\u6b67\u4efb\u52a1\u4e0a\u3002", "method": "\u4f7f\u7528\u82f1\u8bed\u548c\u897f\u73ed\u7259\u8bed\u4e2d\u6b67\u4e49\u8bcd\u7684\u4eba\u7c7b\u76f8\u5173\u6027\u5224\u65ad\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u7684\u5355\u8bed\u548c\u591a\u8bed\u8a00\u6a21\u578b\u3002\u63a2\u7d22\u4e09\u79cd\u6f5c\u5728\u80fd\u529b\u9650\u5236\uff1a\u8868\u5f81\u9650\u5236\uff08\u5d4c\u5165\u5404\u5411\u540c\u6027\u964d\u4f4e\uff09\u3001\u6ce8\u610f\u529b\u9650\u5236\uff08\u5bf9\u6d88\u6b67\u7ebf\u7d22\u5173\u6ce8\u51cf\u5c11\uff09\u548c\u8bcd\u6c47\u76f8\u5173\u9650\u5236\uff08\u591a\u6807\u8bb0\u5206\u5272\u589e\u52a0\uff09\u3002", "result": "\u591a\u8bed\u8a00\u6a21\u578b\u5728\u6240\u6709\u4e09\u79cd\u9650\u5236\u4e0a\u90fd\u8868\u73b0\u51fa\u8bc1\u636e\uff0c\u8fd9\u4e9b\u56e0\u7d20\u7edf\u8ba1\u4e0a\u89e3\u91ca\u4e86\u539f\u672c\u5f52\u56e0\u4e8e\u6a21\u578b\u591a\u8bed\u8a00\u72b6\u6001\u7684\u6027\u80fd\u5dee\u5f02\u3002\u591a\u8bed\u8a00\u6a21\u578b\u786e\u5b9e\u5b58\u5728\u591a\u79cd\u80fd\u529b\u9650\u5236\uff0c\u8fd9\u4e9b\u9650\u5236\u4e0e\u6d88\u6b67\u6027\u80fd\u964d\u4f4e\u76f8\u5173\u3002", "conclusion": "\u591a\u8bed\u8a00\u8bed\u8a00\u6a21\u578b\u5728\u8bcd\u6c47\u6d88\u6b67\u4efb\u52a1\u4e0a\u5b58\u5728\u6027\u80fd\u60e9\u7f5a\uff0c\u8fd9\u6e90\u4e8e\u591a\u79cd\u80fd\u529b\u7ea6\u675f\u3002\u7406\u89e3\u8fd9\u4e9b\u9650\u5236\u6709\u52a9\u4e8e\u672a\u6765\u6539\u8fdb\u591a\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u3002"}}
{"id": "2602.05085", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05085", "abs": "https://arxiv.org/abs/2602.05085", "authors": ["Sidi Lu", "Zhenwen Liang", "Dongyang Ma", "Yan Wang", "Haitao Mi", "Dong Yu"], "title": "Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories", "comment": "Tencent AI Lab Technical Report", "summary": "In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformers, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning. We discuss two major variants of Locas: one with a conventional two-layer MLP design that has a clearer theoretical guarantee; the other one shares the same GLU-FFN structure with SOTA LLMs, and can be easily attached to existing models for both parameter-efficient and computation-efficient continual learning. Crucially, we show that proper initialization of such low-rank sideway-FFN-style memories -- performed in a principled way by reusing model parameters, activations and/or gradients -- is essential for fast convergence, improved generalization, and catastrophic forgetting prevention. We validate the proposed memory mechanism on the PG-19 whole-book language modeling and LoCoMo long-context dialogue question answering tasks. With only 0.02\\% additional parameters in the lowest case, Locas-GLU is capable of storing the information from past context while maintaining a much smaller context window. In addition, we also test the model's general capability loss after memorizing the whole book with Locas, through comparative MMLU evaluation. Results show the promising ability of Locas to permanentize past context into parametric knowledge with minimized catastrophic forgetting of the model's existing internal knowledge.", "AI": {"tldr": "Locas\u662f\u4e00\u79cd\u5c40\u90e8\u652f\u6301\u7684\u53c2\u6570\u5316\u8bb0\u5fc6\u6a21\u5757\uff0c\u53ef\u7075\u6d3b\u5378\u8f7d\u6216\u5408\u5e76\u5230\u6a21\u578b\u53c2\u6570\u4e2d\uff0c\u7528\u4e8e\u9ad8\u6548\u7684\u6301\u7eed\u5b66\u4e60\uff0c\u5728PG-19\u548cLoCoMo\u4efb\u52a1\u4e0a\u4ec5\u97000.02%\u989d\u5916\u53c2\u6570\u5373\u53ef\u5b58\u50a8\u8fc7\u53bb\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "motivation": "\u5c06\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u4e0e\u65b0\u578b\u53c2\u6570\u5316\u8bb0\u5fc6\u76f8\u7ed3\u5408\uff0c\u8fd9\u79cd\u8bb0\u5fc6\u53ef\u4ee5\u7075\u6d3b\u5730\u4ece\u6a21\u578b\u53c2\u6570\u4e2d\u5378\u8f7d\u6216\u5408\u5e76\uff0c\u4ee5\u652f\u6301\u9ad8\u6548\u7684\u6301\u7eed\u5b66\u4e60\u5e76\u51cf\u5c11\u707e\u96be\u6027\u9057\u5fd8\u3002", "method": "\u63d0\u51faLocas\uff08\u5c40\u90e8\u652f\u6301\u7684\u53c2\u6570\u5316\u8bb0\u5fc6\uff09\uff0c\u91c7\u7528\u4e0eTransformer\u4e2dFFN\u5757\u76f8\u540c\u7684\u8bbe\u8ba1\uff0c\u6709\u4e24\u79cd\u53d8\u4f53\uff1a\u4f20\u7edf\u7684\u4e24\u5c42MLP\u8bbe\u8ba1\uff08\u7406\u8bba\u4fdd\u8bc1\u66f4\u6e05\u6670\uff09\u548c\u4e0eSOTA LLMs\u76f8\u540c\u7684GLU-FFN\u7ed3\u6784\u3002\u901a\u8fc7\u91cd\u7528\u6a21\u578b\u53c2\u6570\u3001\u6fc0\u6d3b\u548c/\u6216\u68af\u5ea6\u8fdb\u884c\u539f\u5219\u6027\u521d\u59cb\u5316\u3002", "result": "\u5728PG-19\u6574\u672c\u4e66\u8bed\u8a00\u5efa\u6a21\u548cLoCoMo\u957f\u4e0a\u4e0b\u6587\u5bf9\u8bdd\u95ee\u7b54\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff0cLocas-GLU\u4ec5\u97000.02%\u989d\u5916\u53c2\u6570\u5373\u53ef\u5b58\u50a8\u8fc7\u53bb\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u5c0f\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002MMLU\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u5728\u8bb0\u5fc6\u6574\u672c\u4e66\u540e\u901a\u7528\u80fd\u529b\u635f\u5931\u6700\u5c0f\u3002", "conclusion": "Locas\u80fd\u591f\u5c06\u8fc7\u53bb\u4e0a\u4e0b\u6587\u6c38\u4e45\u5316\u4e3a\u53c2\u6570\u5316\u77e5\u8bc6\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u6a21\u578b\u73b0\u6709\u5185\u90e8\u77e5\u8bc6\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5c55\u793a\u4e86\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.04912", "categories": ["cs.IR", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.04912", "abs": "https://arxiv.org/abs/2602.04912", "authors": ["James Gao", "Josh Zhou", "Qi Sun", "Ryan Huang", "Steven Yoo"], "title": "Atomic Information Flow: A Network Flow Model for Tool Attributions in RAG Systems", "comment": null, "summary": "Many tool-based Retrieval Augmented Generation (RAG) systems lack precise mechanisms for tracing final responses back to specific tool components -- a critical gap as systems scale to complex multi-agent architectures. We present \\textbf{Atomic Information Flow (AIF)}, a graph-based network flow model that decomposes tool outputs and LLM calls into atoms: indivisible, self-contained units of information. By modeling LLM orchestration as a directed flow of atoms from tool and LLM nodes to a response super-sink, AIF enables granular attribution metrics for AI explainability.\n  Motivated by the max-flow min-cut theorem in network flow theory, we train a lightweight Gemma3 (4B parameter) language model as a context compressor to approximate the minimum cut of tool atoms using flow signals computed offline by AIF. We note that the base Gemma3-4B model struggles to identify critical information with \\textbf{54.7\\%} accuracy on HotpotQA, barely outperforming lexical baselines (BM25). However, post-training on AIF signals boosts accuracy to \\textbf{82.71\\%} (+28.01 points) while achieving \\textbf{87.52\\%} (+1.85\\%) context token compression -- bridging the gap with the Gemma3-27B variant, a model nearly $7\\times$ larger.", "AI": {"tldr": "AIF\uff08\u539f\u5b50\u4fe1\u606f\u6d41\uff09\u662f\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u7f51\u7edc\u6d41\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u5de5\u5177\u8f93\u51fa\u548cLLM\u8c03\u7528\u5206\u89e3\u4e3a\u539f\u5b50\u4fe1\u606f\u5355\u5143\uff0c\u5b9e\u73b0RAG\u7cfb\u7edf\u4e2d\u4fe1\u606f\u6d41\u7684\u7cbe\u786e\u8ffd\u8e2a\u548c\u5f52\u56e0\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5de5\u5177\u7684RAG\u7cfb\u7edf\u7f3a\u4e4f\u5c06\u6700\u7ec8\u54cd\u5e94\u8ffd\u6eaf\u5230\u7279\u5b9a\u5de5\u5177\u7ec4\u4ef6\u7684\u7cbe\u786e\u673a\u5236\uff0c\u8fd9\u5728\u7cfb\u7edf\u6269\u5c55\u5230\u590d\u6742\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u65f6\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002", "method": "\u63d0\u51faAIF\u56fe\u6a21\u578b\uff0c\u5c06LLM\u7f16\u6392\u5efa\u6a21\u4e3a\u4ece\u5de5\u5177\u548cLLM\u8282\u70b9\u5230\u54cd\u5e94\u8d85\u6c47\u70b9\u7684\u539f\u5b50\u4fe1\u606f\u6d41\uff1b\u57fa\u4e8e\u6700\u5927\u6d41\u6700\u5c0f\u5272\u5b9a\u7406\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7Gemma3-4B\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u538b\u7f29\u5668\uff0c\u5229\u7528AIF\u8ba1\u7b97\u7684\u6d41\u4fe1\u53f7\u6765\u8fd1\u4f3c\u6700\u5c0f\u5272\u3002", "result": "\u57fa\u7840Gemma3-4B\u5728HotpotQA\u4e0a\u8bc6\u522b\u5173\u952e\u4fe1\u606f\u7684\u51c6\u786e\u7387\u4ec5\u4e3a54.7%\uff0c\u7565\u4f18\u4e8e\u8bcd\u6cd5\u57fa\u7ebf\uff08BM25\uff09\u3002\u4f46\u5728AIF\u4fe1\u53f7\u4e0a\u540e\u8bad\u7ec3\u540e\uff0c\u51c6\u786e\u7387\u63d0\u5347\u81f382.71%\uff08+28.01\u5206\uff09\uff0c\u540c\u65f6\u5b9e\u73b087.52%\uff08+1.85%\uff09\u7684\u4e0a\u4e0b\u6587token\u538b\u7f29\uff0c\u6027\u80fd\u63a5\u8fd1\u59277\u500d\u7684Gemma3-27B\u53d8\u4f53\u3002", "conclusion": "AIF\u4e3aRAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u7684\u4fe1\u606f\u6d41\u8ffd\u8e2a\u548c\u5f52\u56e0\u80fd\u529b\uff0c\u901a\u8fc7\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u6a21\u578b\u5229\u7528AIF\u4fe1\u53f7\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u9ad8\u6548\u538b\u7f29\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5173\u952e\u4fe1\u606f\u8bc6\u522b\u80fd\u529b\uff0c\u7f29\u5c0f\u4e0e\u5927\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2602.05106", "categories": ["cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.05106", "abs": "https://arxiv.org/abs/2602.05106", "authors": ["Michael Browder", "Kevin Duh", "J. David Harris", "Vince Lyzinski", "Paul McNamee", "Youngser Park", "Carey E. Priebe", "Peter Viechnicki"], "title": "Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models", "comment": null, "summary": "Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via synthetic data generation. However, because the models are black boxes, the properties of the synthetic data are difficult to predict. In practice it is common for language technology engineers to 'fiddle' with the LLM temperature setting and hope that what comes out the other end improves the downstream model. Faced with this uncertainty, here we propose Data Kernel Perspective Space (DKPS) to provide the foundation for mathematical analysis yielding concrete statistical guarantees for the quality of the outputs of transformer models. We first show the mathematical derivation of DKPS and how it provides performance guarantees. Next we show how DKPS performance guarantees can elucidate performance of a downstream task, such as neural machine translation models or LLMs trained using Contrastive Preference Optimization (CPO). Limitations of the current work and future research are also discussed.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faData Kernel Perspective Space (DKPS)\u6846\u67b6\uff0c\u4e3aTransformer\u6a21\u578b\u8f93\u51fa\u8d28\u91cf\u63d0\u4f9b\u6570\u5b66\u5206\u6790\u548c\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u89e3\u51b3\u5408\u6210\u6570\u636e\u751f\u6210\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eTransformer/LLM\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u5de5\u7a0b\u5e08\u901a\u5e38\u53ea\u80fd\u901a\u8fc7\u8c03\u6574\u6e29\u5ea6\u53c2\u6570\u6765\"\u8bd5\u9519\"\uff0c\u7f3a\u4e4f\u5bf9\u8f93\u51fa\u8d28\u91cf\u7684\u6570\u5b66\u5206\u6790\u548c\u7edf\u8ba1\u4fdd\u8bc1\u3002", "method": "\u63d0\u51faData Kernel Perspective Space (DKPS)\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u5b66\u63a8\u5bfc\u5efa\u7acb\u7406\u8bba\u5206\u6790\u57fa\u7840\uff0c\u4e3aTransformer\u6a21\u578b\u8f93\u51fa\u63d0\u4f9b\u6027\u80fd\u4fdd\u8bc1\u3002", "result": "DKPS\u6846\u67b6\u80fd\u591f\u63d0\u4f9b\u5177\u4f53\u7684\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u5e76\u53ef\u5e94\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u3001\u57fa\u4e8eCPO\u8bad\u7ec3\u7684LLM\uff09\u7684\u6027\u80fd\u5206\u6790\u3002", "conclusion": "DKPS\u4e3a\u89e3\u51b3\u5408\u6210\u6570\u636e\u751f\u6210\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\uff0c\u4f46\u5f53\u524d\u5de5\u4f5c\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u672a\u6765\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2602.05062", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.05062", "abs": "https://arxiv.org/abs/2602.05062", "authors": ["Julian Killingback", "Mahta Rafiee", "Madine Manas", "Hamed Zamani"], "title": "Scaling Laws for Embedding Dimension in Information Retrieval", "comment": "9 Pages, 7 figures", "summary": "Dense retrieval, which encodes queries and documents into a single dense vector, has become the dominant neural retrieval approach due to its simplicity and compatibility with fast approximate nearest neighbor algorithms. As the tasks dense retrieval performs grow in complexity, the fundamental limitations of the underlying data structure and similarity metric -- namely vectors and inner-products -- become more apparent. Prior recent work has shown theoretical limitations inherent to single vectors and inner-products that are generally tied to the embedding dimension. Given the importance of embedding dimension for retrieval capacity, understanding how dense retrieval performance changes as embedding dimension is scaled is fundamental to building next generation retrieval models that balance effectiveness and efficiency. In this work, we conduct a comprehensive analysis of the relationship between embedding dimension and retrieval performance. Our experiments include two model families and a range of model sizes from each to construct a detailed picture of embedding scaling behavior. We find that the scaling behavior fits a power law, allowing us to derive scaling laws for performance given only embedding dimension, as well as a joint law accounting for embedding dimension and model size. Our analysis shows that for evaluation tasks aligned with the training task, performance continues to improve as embedding size increases, though with diminishing returns. For evaluation data that is less aligned with the training task, we find that performance is less predictable, with performance degrading with larger embedding dimensions for certain tasks. We hope our work provides additional insight into the limitations of embeddings and their behavior as well as offers a practical guide for selecting model and embedding dimension to achieve optimal performance with reduced storage and compute costs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9\u7a20\u5bc6\u68c0\u7d22\u4e2d\u5d4c\u5165\u7ef4\u5ea6\u4e0e\u68c0\u7d22\u6027\u80fd\u7684\u5173\u7cfb\u8fdb\u884c\u4e86\u7efc\u5408\u5206\u6790\uff0c\u53d1\u73b0\u6027\u80fd\u968f\u5d4c\u5165\u7ef4\u5ea6\u589e\u52a0\u5448\u5e42\u5f8b\u589e\u957f\uff0c\u4f46\u5b58\u5728\u6536\u76ca\u9012\u51cf\uff0c\u4e14\u4e0d\u540c\u4efb\u52a1\u95f4\u7684\u6027\u80fd\u53d8\u5316\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u7a20\u5bc6\u68c0\u7d22\u4efb\u52a1\u590d\u6742\u6027\u589e\u52a0\uff0c\u5176\u5e95\u5c42\u6570\u636e\u7ed3\u6784\uff08\u5411\u91cf\uff09\u548c\u76f8\u4f3c\u5ea6\u5ea6\u91cf\uff08\u5185\u79ef\uff09\u7684\u57fa\u672c\u5c40\u9650\u6027\u65e5\u76ca\u660e\u663e\u3002\u5d4c\u5165\u7ef4\u5ea6\u5bf9\u68c0\u7d22\u5bb9\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u7406\u89e3\u5d4c\u5165\u7ef4\u5ea6\u7f29\u653e\u5982\u4f55\u5f71\u54cd\u6027\u80fd\u5bf9\u4e8e\u6784\u5efa\u5e73\u8861\u6548\u679c\u548c\u6548\u7387\u7684\u4e0b\u4e00\u4ee3\u68c0\u7d22\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5bf9\u4e24\u4e2a\u6a21\u578b\u5bb6\u65cf\u548c\u4e00\u7cfb\u5217\u6a21\u578b\u89c4\u6a21\u8fdb\u884c\u7efc\u5408\u5b9e\u9a8c\uff0c\u6784\u5efa\u8be6\u7ec6\u7684\u5d4c\u5165\u7f29\u653e\u884c\u4e3a\u56fe\u666f\u3002\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u53d1\u73b0\u6027\u80fd\u4e0e\u5d4c\u5165\u7ef4\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u7b26\u5408\u5e42\u5f8b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u5d4c\u5165\u7ef4\u5ea6\u4e0e\u6027\u80fd\u5173\u7cfb\u7b26\u5408\u5e42\u5f8b\uff0c\u53ef\u4ee5\u63a8\u5bfc\u51fa\u4ec5\u57fa\u4e8e\u5d4c\u5165\u7ef4\u5ea6\u7684\u6027\u80fd\u7f29\u653e\u5b9a\u5f8b\uff0c\u4ee5\u53ca\u540c\u65f6\u8003\u8651\u5d4c\u5165\u7ef4\u5ea6\u548c\u6a21\u578b\u89c4\u6a21\u7684\u8054\u5408\u5b9a\u5f8b\uff1b2) \u5bf9\u4e8e\u4e0e\u8bad\u7ec3\u4efb\u52a1\u5bf9\u9f50\u7684\u8bc4\u4f30\u4efb\u52a1\uff0c\u6027\u80fd\u968f\u5d4c\u5165\u7ef4\u5ea6\u589e\u52a0\u6301\u7eed\u63d0\u5347\uff0c\u4f46\u5b58\u5728\u6536\u76ca\u9012\u51cf\uff1b3) \u5bf9\u4e8e\u4e0e\u8bad\u7ec3\u4efb\u52a1\u5bf9\u9f50\u5ea6\u8f83\u4f4e\u7684\u8bc4\u4f30\u6570\u636e\uff0c\u6027\u80fd\u53d8\u5316\u8f83\u96be\u9884\u6d4b\uff0c\u67d0\u4e9b\u4efb\u52a1\u4e2d\u66f4\u5927\u5d4c\u5165\u7ef4\u5ea6\u53cd\u800c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u5d4c\u5165\u7684\u5c40\u9650\u6027\u53ca\u5176\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u4e3a\u9009\u62e9\u6a21\u578b\u548c\u5d4c\u5165\u7ef4\u5ea6\u4ee5\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\u540c\u65f6\u964d\u4f4e\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2602.05107", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05107", "abs": "https://arxiv.org/abs/2602.05107", "authors": ["Ahmed Ruby", "Christian Hardmeier", "Sara Stymne"], "title": "Multilingual Extraction and Recognition of Implicit Discourse Relations in Speech and Text", "comment": null, "summary": "Implicit discourse relation classification is a challenging task, as it requires inferring meaning from context. While contextual cues can be distributed across modalities and vary across languages, they are not always captured by text alone. To address this, we introduce an automatic method for distantly related and unrelated language pairs to construct a multilingual and multimodal dataset for implicit discourse relations in English, French, and Spanish. For classification, we propose a multimodal approach that integrates textual and acoustic information through Qwen2-Audio, allowing joint modeling of text and audio for implicit discourse relation classification across languages. We find that while text-based models outperform audio-based models, integrating both modalities can enhance performance, and cross-lingual transfer can provide substantial improvements for low-resource languages.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u65b9\u6cd5\u7528\u4e8e\u8de8\u8bed\u8a00\u9690\u5f0f\u7bc7\u7ae0\u5173\u7cfb\u5206\u7c7b\uff0c\u7ed3\u5408\u6587\u672c\u548c\u97f3\u9891\u4fe1\u606f\uff0c\u5728\u82f1\u8bed\u3001\u6cd5\u8bed\u548c\u897f\u73ed\u7259\u8bed\u4e0a\u9a8c\u8bc1\u6548\u679c\u3002", "motivation": "\u9690\u5f0f\u7bc7\u7ae0\u5173\u7cfb\u5206\u7c7b\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u4ece\u4e0a\u4e0b\u6587\u4e2d\u63a8\u65ad\u542b\u4e49\u3002\u8bed\u5883\u7ebf\u7d22\u53ef\u80fd\u5206\u5e03\u5728\u591a\u6a21\u6001\u4e2d\u4e14\u56e0\u8bed\u8a00\u800c\u5f02\uff0c\u4ec5\u9760\u6587\u672c\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u3002", "method": "1. \u63d0\u51fa\u81ea\u52a8\u65b9\u6cd5\u6784\u5efa\u82f1\u8bed\u3001\u6cd5\u8bed\u548c\u897f\u73ed\u7259\u8bed\u7684\u591a\u8bed\u8a00\u591a\u6a21\u6001\u9690\u5f0f\u7bc7\u7ae0\u5173\u7cfb\u6570\u636e\u96c6\uff1b2. \u63d0\u51fa\u591a\u6a21\u6001\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7Qwen2-Audio\u6574\u5408\u6587\u672c\u548c\u58f0\u5b66\u4fe1\u606f\uff0c\u5b9e\u73b0\u8de8\u8bed\u8a00\u8054\u5408\u5efa\u6a21\u3002", "result": "1. \u57fa\u4e8e\u6587\u672c\u7684\u6a21\u578b\u4f18\u4e8e\u57fa\u4e8e\u97f3\u9891\u7684\u6a21\u578b\uff1b2. \u6574\u5408\u4e24\u79cd\u6a21\u6001\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\uff1b3. \u8de8\u8bed\u8a00\u8fc1\u79fb\u80fd\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u5e26\u6765\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u591a\u6a21\u6001\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u9690\u5f0f\u7bc7\u7ae0\u5173\u7cfb\u5206\u7c7b\u6027\u80fd\uff0c\u8de8\u8bed\u8a00\u8fc1\u79fb\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u5c24\u5176\u6709\u76ca\uff0c\u8868\u660e\u6574\u5408\u6587\u672c\u548c\u97f3\u9891\u4fe1\u606f\u5177\u6709\u4ef7\u503c\u3002"}}
{"id": "2602.05152", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05152", "abs": "https://arxiv.org/abs/2602.05152", "authors": ["Yuntong Hu", "Sha Li", "Naren Ramakrishnan", "Liang Zhao"], "title": "RAG without Forgetting: Continual Query-Infused Key Memory", "comment": "24 pages, 12 figures", "summary": "Retrieval-augmented generation (RAG) systems commonly improve robustness via query-time adaptations such as query expansion and iterative retrieval. While effective, these approaches are inherently stateless: adaptations are recomputed for each query and discarded thereafter, precluding cumulative learning and repeatedly incurring inference-time cost. Index-side approaches like key expansion introduce persistence but rely on offline preprocessing or heuristic updates that are weakly aligned with downstream task utility, leading to semantic drift and noise accumulation. We propose Evolving Retrieval Memory (ERM), a training-free framework that transforms transient query-time gains into persistent retrieval improvements. ERM updates the retrieval index through correctness-gated feedback, selectively attributes atomic expansion signals to the document keys they benefit, and progressively evolves keys via stable, norm-bounded updates. We show that query and key expansion are theoretically equivalent under standard similarity functions and prove convergence of ERM's selective updates, amortizing optimal query expansion into a stable index with zero inference-time overhead. Experiments on BEIR and BRIGHT across 13 domains demonstrate consistent gains in retrieval and generation, particularly on reasoning-intensive tasks, at native retrieval speed.", "AI": {"tldr": "\u63d0\u51faERM\u6846\u67b6\uff0c\u5c06\u4e34\u65f6\u67e5\u8be2\u589e\u5f3a\u8f6c\u5316\u4e3a\u6301\u4e45\u68c0\u7d22\u6539\u8fdb\uff0c\u901a\u8fc7\u6b63\u786e\u6027\u95e8\u63a7\u53cd\u9988\u66f4\u65b0\u68c0\u7d22\u7d22\u5f15\uff0c\u5b9e\u73b0\u96f6\u63a8\u7406\u5f00\u9500\u7684\u68c0\u7d22\u4f18\u5316\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u901a\u8fc7\u67e5\u8be2\u6269\u5c55\u548c\u8fed\u4ee3\u68c0\u7d22\u7b49\u67e5\u8be2\u65f6\u9002\u5e94\u6280\u672f\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u662f\u65e0\u72b6\u6001\u7684\uff1a\u6bcf\u6b21\u67e5\u8be2\u90fd\u8981\u91cd\u65b0\u8ba1\u7b97\u9002\u5e94\u7ed3\u679c\uff0c\u65e0\u6cd5\u7d2f\u79ef\u5b66\u4e60\u4e14\u91cd\u590d\u4ea7\u751f\u63a8\u7406\u6210\u672c\u3002\u7d22\u5f15\u4fa7\u65b9\u6cd5\u5982\u952e\u6269\u5c55\u5f15\u5165\u4e86\u6301\u4e45\u6027\uff0c\u4f46\u4f9d\u8d56\u79bb\u7ebf\u9884\u5904\u7406\u6216\u542f\u53d1\u5f0f\u66f4\u65b0\uff0c\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6548\u7528\u5bf9\u9f50\u8f83\u5f31\uff0c\u5bfc\u81f4\u8bed\u4e49\u6f02\u79fb\u548c\u566a\u58f0\u7d2f\u79ef\u3002", "method": "\u63d0\u51fa\u6f14\u5316\u68c0\u7d22\u8bb0\u5fc6\uff08ERM\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6b63\u786e\u6027\u95e8\u63a7\u53cd\u9988\u66f4\u65b0\u68c0\u7d22\u7d22\u5f15\uff0c\u9009\u62e9\u6027\u5730\u5c06\u539f\u5b50\u6269\u5c55\u4fe1\u53f7\u5f52\u56e0\u4e8e\u5b83\u4eec\u53d7\u76ca\u7684\u6587\u6863\u952e\uff0c\u5e76\u901a\u8fc7\u7a33\u5b9a\u3001\u8303\u6570\u6709\u754c\u7684\u66f4\u65b0\u9010\u6b65\u6f14\u5316\u952e\u3002\u8bc1\u660e\u67e5\u8be2\u6269\u5c55\u548c\u952e\u6269\u5c55\u5728\u6807\u51c6\u76f8\u4f3c\u5ea6\u51fd\u6570\u4e0b\u7406\u8bba\u7b49\u4ef7\uff0c\u5e76\u8bc1\u660eERM\u9009\u62e9\u6027\u66f4\u65b0\u7684\u6536\u655b\u6027\u3002", "result": "\u5728BEIR\u548cBRIGHT\u768413\u4e2a\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0cERM\u5728\u68c0\u7d22\u548c\u751f\u6210\u65b9\u9762\u5747\u53d6\u5f97\u4e00\u81f4\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u751f\u68c0\u7d22\u901f\u5ea6\u3002", "conclusion": "ERM\u6846\u67b6\u6210\u529f\u5730\u5c06\u4e34\u65f6\u67e5\u8be2\u589e\u5f3a\u8f6c\u5316\u4e3a\u6301\u4e45\u68c0\u7d22\u6539\u8fdb\uff0c\u901a\u8fc7\u8bad\u7ec3\u514d\u8d39\u7684\u65b9\u5f0f\u5b9e\u73b0\u4e86\u96f6\u63a8\u7406\u5f00\u9500\u7684\u68c0\u7d22\u4f18\u5316\uff0c\u4e3aRAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7a33\u5b9a\u7684\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u3002"}}
{"id": "2602.05150", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05150", "abs": "https://arxiv.org/abs/2602.05150", "authors": ["Yang Zhang", "Mersin Konomi", "Christos Xypolopoulos", "Konstantinos Divriotis", "Konstantinos Skianis", "Giannis Nikolentzos", "Giorgos Stamou", "Guokan Shang", "Michalis Vazirgiannis"], "title": "GreekMMLU: A Native-Sourced Multitask Benchmark for Evaluating Language Models in Greek", "comment": null, "summary": "Large Language Models (LLMs) are commonly trained on multilingual corpora that include Greek, yet reliable evaluation benchmarks for Greek-particularly those based on authentic, native-sourced content-remain limited. Existing datasets are often machine-translated from English, failing to capture Greek linguistic and cultural characteristics. We introduce GreekMMLU, a native-sourced benchmark for massive multitask language understanding in Greek, comprising 21,805 multiple-choice questions across 45 subject areas, organized under a newly defined subject taxonomy and annotated with educational difficulty levels spanning primary to professional examinations. All questions are sourced or authored in Greek from academic, professional, and governmental exams. We publicly release 16,857 samples and reserve 4,948 samples for a private leaderboard to enable robust and contamination-resistant evaluation. Evaluations of over 80 open- and closed-source LLMs reveal substantial performance gaps between frontier and open-weight models, as well as between Greek-adapted models and general multilingual ones. Finally, we provide a systematic analysis of factors influencing performance-including model scale, adaptation, and prompting-and derive insights for improving LLM capabilities in Greek.", "AI": {"tldr": "\u5e0c\u814a\u8bed\u539f\u751f\u8bc4\u4f30\u57fa\u51c6GreekMMLU\uff1a\u5305\u542b21,805\u4e2a\u591a\u9009\u95ee\u9898\uff0c\u8986\u76d645\u4e2a\u5b66\u79d1\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u5e0c\u814a\u8bed\u4e0a\u7684\u591a\u4efb\u52a1\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u5e0c\u814a\u8bed\u8bc4\u4f30\u57fa\u51c6\u6709\u9650\uff0c\u73b0\u6709\u6570\u636e\u96c6\u591a\u4e3a\u4ece\u82f1\u8bed\u673a\u5668\u7ffb\u8bd1\u800c\u6765\uff0c\u65e0\u6cd5\u6355\u6349\u5e0c\u814a\u8bed\u8a00\u548c\u6587\u5316\u7279\u5f81\uff0c\u9700\u8981\u539f\u751f\u5e0c\u814a\u8bed\u5185\u5bb9\u6784\u5efa\u7684\u53ef\u9760\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u6784\u5efaGreekMMLU\u57fa\u51c6\uff0c\u5305\u542b21,805\u4e2a\u591a\u9009\u95ee\u9898\uff0c\u6765\u81ea\u5b66\u672f\u3001\u4e13\u4e1a\u548c\u653f\u5e9c\u8003\u8bd5\u7684\u539f\u751f\u5e0c\u814a\u8bed\u5185\u5bb9\uff0c\u6db5\u76d645\u4e2a\u5b66\u79d1\uff0c\u6309\u65b0\u5b9a\u4e49\u5b66\u79d1\u5206\u7c7b\u6cd5\u7ec4\u7ec7\uff0c\u6807\u6ce8\u6559\u80b2\u96be\u5ea6\u7ea7\u522b\u3002", "result": "\u8bc4\u4f3080\u591a\u4e2a\u5f00\u6e90\u548c\u95ed\u6e90LLM\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u4e0e\u5f00\u6e90\u6a21\u578b\u3001\u5e0c\u814a\u8bed\u9002\u5e94\u6a21\u578b\u4e0e\u901a\u7528\u591a\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u89c4\u6a21\u3001\u9002\u5e94\u6027\u548c\u63d0\u793a\u7b56\u7565\u7b49\u56e0\u7d20\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "GreekMMLU\u4e3a\u5e0c\u814a\u8bedLLM\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u539f\u751f\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u63d0\u5347LLM\u5728\u5e0c\u814a\u8bed\u4e0a\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5206\u6790\u89c1\u89e3\u3002"}}
{"id": "2602.05216", "categories": ["cs.IR", "cs.AI", "math.HO"], "pdf": "https://arxiv.org/pdf/2602.05216", "abs": "https://arxiv.org/abs/2602.05216", "authors": ["Luke Alexander", "Eric Leonen", "Sophie Szeto", "Artemii Remizov", "Ignacio Tejeda", "Giovanni Inchiostro", "Vasily Ilin"], "title": "Semantic Search over 9 Million Mathematical Theorems", "comment": "Feedback is welcome", "summary": "Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly technical corpora such as research-level mathematical theorems remains poorly understood. In this work, we introduce and study semantic theorem retrieval at scale over a unified corpus of $9.2$ million theorem statements extracted from arXiv and seven other sources, representing the largest publicly available corpus of human-authored, research-level theorems. We represent each theorem with a short natural-language description as a retrieval representation and systematically analyze how representation context, language model choice, embedding model, and prompting strategy affect retrieval quality. On a curated evaluation set of theorem-search queries written by professional mathematicians, our approach substantially improves both theorem-level and paper-level retrieval compared to existing baselines, demonstrating that semantic theorem search is feasible and effective at web scale. The theorem search tool is available at \\href{https://huggingface.co/spaces/uw-math-ai/theorem-search}{this link}, and the dataset is available at \\href{https://huggingface.co/datasets/uw-math-ai/TheoremSearch}{this link}.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b920\u4e07\u5b9a\u7406\u8bed\u53e5\u7684\u7edf\u4e00\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u8bed\u4e49\u641c\u7d22\u5b9e\u73b0\u5b9a\u7406\u7ea7\u68c0\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u5b9a\u7406\u641c\u7d22\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u68c0\u7d22\u5de5\u5177\u53ea\u80fd\u68c0\u7d22\u6574\u7bc7\u8bba\u6587\uff0c\u800c\u6570\u5b66\u5bb6\u548c\u5b9a\u7406\u8bc1\u660e\u4ee3\u7406\u901a\u5e38\u9700\u8981\u67e5\u627e\u7279\u5b9a\u5b9a\u7406\u3001\u5f15\u7406\u6216\u547d\u9898\u6765\u56de\u7b54\u67e5\u8be2\u3002\u867d\u7136\u8bed\u4e49\u641c\u7d22\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5728\u5927\u578b\u3001\u9ad8\u5ea6\u6280\u672f\u6027\u7684\u7814\u7a76\u7ea7\u6570\u5b66\u5b9a\u7406\u8bed\u6599\u5e93\u4e0a\u7684\u8868\u73b0\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u4ecearXiv\u548c\u5176\u4ed6\u4e03\u4e2a\u6765\u6e90\u63d0\u53d6\u4e86920\u4e07\u5b9a\u7406\u8bed\u53e5\uff0c\u6784\u5efa\u4e86\u6700\u5927\u7684\u516c\u5f00\u7814\u7a76\u7ea7\u5b9a\u7406\u8bed\u6599\u5e93\u3002\u4e3a\u6bcf\u4e2a\u5b9a\u7406\u751f\u6210\u7b80\u77ed\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4f5c\u4e3a\u68c0\u7d22\u8868\u793a\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u8868\u793a\u4e0a\u4e0b\u6587\u3001\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u3001\u5d4c\u5165\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\u5bf9\u68c0\u7d22\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u5728\u4e13\u4e1a\u6570\u5b66\u5bb6\u7f16\u5199\u7684\u5b9a\u7406\u641c\u7d22\u67e5\u8be2\u8bc4\u4f30\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9a\u7406\u7ea7\u548c\u8bba\u6587\u7ea7\u68c0\u7d22\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u8bc1\u660e\u8bed\u4e49\u5b9a\u7406\u641c\u7d22\u5728\u7f51\u7edc\u89c4\u6a21\u4e0a\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u3002", "conclusion": "\u8bed\u4e49\u5b9a\u7406\u641c\u7d22\u5728\u5927\u89c4\u6a21\u6570\u5b66\u8bed\u6599\u5e93\u4e0a\u662f\u53ef\u884c\u7684\uff0c\u5e76\u4e14\u80fd\u591f\u663e\u8457\u63d0\u5347\u5b9a\u7406\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e3a\u6570\u5b66\u7814\u7a76\u548c\u5b9a\u7406\u8bc1\u660e\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002"}}
{"id": "2602.05176", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05176", "abs": "https://arxiv.org/abs/2602.05176", "authors": ["Ziyuan Yang", "Wenxuan Ding", "Shangbin Feng", "Yulia Tsvetkov"], "title": "Among Us: Measuring and Mitigating Malicious Contributions in Model Collaboration Systems", "comment": "19 pages, 15 tables, 4 figures", "summary": "Language models (LMs) are increasingly used in collaboration: multiple LMs trained by different parties collaborate through routing systems, multi-agent debate, model merging, and more. Critical safety risks remain in this decentralized paradigm: what if some of the models in multi-LLM systems are compromised or malicious? We first quantify the impact of malicious models by engineering four categories of malicious LMs, plug them into four types of popular model collaboration systems, and evaluate the compromised system across 10 datasets. We find that malicious models have a severe impact on the multi-LLM systems, especially for reasoning and safety domains where performance is lowered by 7.12% and 7.94% on average. We then propose mitigation strategies to alleviate the impact of malicious components, by employing external supervisors that oversee model collaboration to disable/mask them out to reduce their influence. On average, these strategies recover 95.31% of the initial performance, while making model collaboration systems fully resistant to malicious models remains an open research question.", "AI": {"tldr": "\u6076\u610f\u8bed\u8a00\u6a21\u578b\u5728\u591aLLM\u534f\u4f5c\u7cfb\u7edf\u4e2d\u6784\u6210\u4e25\u91cd\u5b89\u5168\u5a01\u80c1\uff0c\u672c\u6587\u91cf\u5316\u5176\u5f71\u54cd\u5e76\u63d0\u51fa\u76d1\u7763\u7f13\u89e3\u7b56\u7565", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u578b\u534f\u4f5c\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5f53\u90e8\u5206\u6a21\u578b\u88ab\u653b\u51fb\u6216\u6076\u610f\u65f6\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u91cf\u5316\u8bc4\u4f30\u8fd9\u79cd\u5a01\u80c1", "method": "\u8bbe\u8ba1\u4e86\u56db\u7c7b\u6076\u610f\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u5176\u690d\u5165\u56db\u79cd\u6d41\u884c\u7684\u6a21\u578b\u534f\u4f5c\u7cfb\u7edf\uff0c\u572810\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u53d7\u635f\u7cfb\u7edf\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5916\u90e8\u76d1\u7763\u7684\u7f13\u89e3\u7b56\u7565", "result": "\u6076\u610f\u6a21\u578b\u5bf9\u591aLLM\u7cfb\u7edf\u5f71\u54cd\u4e25\u91cd\uff0c\u5728\u63a8\u7406\u548c\u5b89\u5168\u9886\u57df\u6027\u80fd\u5206\u522b\u5e73\u5747\u4e0b\u964d7.12%\u548c7.94%\uff1b\u63d0\u51fa\u7684\u7f13\u89e3\u7b56\u7565\u5e73\u5747\u80fd\u6062\u590d95.31%\u7684\u521d\u59cb\u6027\u80fd", "conclusion": "\u6076\u610f\u6a21\u578b\u5728\u591a\u6a21\u578b\u534f\u4f5c\u7cfb\u7edf\u4e2d\u6784\u6210\u5b9e\u9645\u5a01\u80c1\uff0c\u63d0\u51fa\u7684\u76d1\u7763\u7b56\u7565\u80fd\u6709\u6548\u7f13\u89e3\u4f46\u65e0\u6cd5\u5b8c\u5168\u62b5\u6297\uff0c\u5b9e\u73b0\u5b8c\u5168\u6297\u6076\u610f\u653b\u51fb\u7684\u6a21\u578b\u534f\u4f5c\u7cfb\u7edf\u4ecd\u662f\u5f00\u653e\u7814\u7a76\u95ee\u9898"}}
{"id": "2602.05334", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05334", "abs": "https://arxiv.org/abs/2602.05334", "authors": ["Dawn Lawrie", "James Mayfield", "Eugene Yang", "Andrew Yates", "Sean MacAvaney", "Ronak Pradeep", "Scott Miller", "Paul McNamee", "Luca Soldaini"], "title": "NeuCLIRTech: Chinese Monolingual and Cross-Language Information Retrieval Evaluation in a Challenging Domain", "comment": "14 pages, 6 figures", "summary": "Measuring advances in retrieval requires test collections with relevance judgments that can faithfully distinguish systems. This paper presents NeuCLIRTech, an evaluation collection for cross-language retrieval over technical information. The collection consists of technical documents written natively in Chinese and those same documents machine translated into English. It includes 110 queries with relevance judgments. The collection supports two retrieval scenarios: monolingual retrieval in Chinese, and cross-language retrieval with English as the query language. NeuCLIRTech combines the TREC NeuCLIR track topics of 2023 and 2024. The 110 queries with 35,962 document judgments provide strong statistical discriminatory power when trying to distinguish retrieval approaches. A fusion baseline of strong neural retrieval systems is included so that developers of reranking algorithms are not reliant on BM25 as their first stage retriever. The dataset and artifacts are released on Huggingface Datasets", "AI": {"tldr": "NeuCLIRTech\u662f\u4e00\u4e2a\u7528\u4e8e\u6280\u672f\u4fe1\u606f\u8de8\u8bed\u8a00\u68c0\u7d22\u7684\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e2d\u82f1\u6587\u6280\u672f\u6587\u6863\u3001110\u4e2a\u67e5\u8be2\u548c35,962\u4e2a\u76f8\u5173\u6027\u5224\u65ad\uff0c\u652f\u6301\u4e2d\u6587\u5355\u8bed\u68c0\u7d22\u548c\u82f1\u6587\u67e5\u8be2\u7684\u8de8\u8bed\u8a00\u68c0\u7d22\u573a\u666f\u3002", "motivation": "\u4e3a\u4e86\u51c6\u786e\u8861\u91cf\u68c0\u7d22\u7cfb\u7edf\u7684\u8fdb\u5c55\uff0c\u9700\u8981\u80fd\u591f\u53ef\u9760\u533a\u5206\u7cfb\u7edf\u6027\u80fd\u7684\u6d4b\u8bd5\u96c6\u5408\u3002\u73b0\u6709\u7684\u8bc4\u4f30\u6570\u636e\u96c6\u5728\u6280\u672f\u4fe1\u606f\u7684\u8de8\u8bed\u8a00\u68c0\u7d22\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u4e2d\u6587\u548c\u82f1\u6587\u4e4b\u95f4\u7684\u8de8\u8bed\u8a00\u68c0\u7d22\u573a\u666f\u3002", "method": "\u6784\u5efaNeuCLIRTech\u8bc4\u4f30\u96c6\u5408\uff0c\u5305\u542b\u539f\u751f\u4e2d\u6587\u6280\u672f\u6587\u6863\u53ca\u5176\u673a\u5668\u7ffb\u8bd1\u7684\u82f1\u6587\u7248\u672c\u3002\u6574\u5408TREC NeuCLIR 2023\u548c2024\u7684\u4e3b\u9898\uff0c\u63d0\u4f9b110\u4e2a\u67e5\u8be2\u548c35,962\u4e2a\u6587\u6863\u76f8\u5173\u6027\u5224\u65ad\u3002\u8fd8\u5305\u542b\u57fa\u4e8e\u795e\u7ecf\u68c0\u7d22\u7cfb\u7edf\u7684\u878d\u5408\u57fa\u7ebf\uff0c\u907f\u514d\u7814\u7a76\u8005\u8fc7\u5ea6\u4f9d\u8d56BM25\u4f5c\u4e3a\u7b2c\u4e00\u9636\u6bb5\u68c0\u7d22\u5668\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5177\u6709\u5f3a\u5927\u7edf\u8ba1\u533a\u5206\u80fd\u529b\u7684\u8bc4\u4f30\u96c6\u5408\uff0c\u652f\u6301\u4e2d\u6587\u5355\u8bed\u68c0\u7d22\u548c\u82f1\u6587\u67e5\u8be2\u7684\u8de8\u8bed\u8a00\u68c0\u7d22\u4e24\u79cd\u573a\u666f\u3002\u6570\u636e\u96c6\u548c\u5de5\u5177\u5df2\u5728Huggingface Datasets\u4e0a\u53d1\u5e03\uff0c\u4e3a\u68c0\u7d22\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "conclusion": "NeuCLIRTech\u4e3a\u6280\u672f\u4fe1\u606f\u8de8\u8bed\u8a00\u68c0\u7d22\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u8bc4\u4f30\u8d44\u6e90\uff0c\u7279\u522b\u5173\u6ce8\u4e2d\u6587-\u82f1\u6587\u8bed\u8a00\u5bf9\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8de8\u8bed\u8a00\u68c0\u7d22\u6280\u672f\u7684\u53d1\u5c55\u548c\u7814\u7a76\u3002"}}
{"id": "2602.05182", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05182", "abs": "https://arxiv.org/abs/2602.05182", "authors": ["Shangbin Feng", "Kishan Panaganti", "Yulia Tsvetkov", "Wenhao Yu"], "title": "The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems", "comment": "Code at https://github.com/BunsenFeng/moco_distill", "summary": "Model collaboration -- systems where multiple language models (LMs) collaborate -- combines the strengths of diverse models with cost in loading multiple LMs. We improve efficiency while preserving the strengths of collaboration by distilling collaborative patterns into a single model, where the model is trained on the outputs of the model collaboration system. At inference time, only the distilled model is employed: it imitates the collaboration while only incurring the cost of a single model. Furthermore, we propose the single-multi evolution loop: multiple LMs collaborate, each distills from the collaborative outputs, and these post-distillation improved LMs collaborate again, forming a collective evolution ecosystem where models evolve and self-improve by interacting with an environment of other models. Extensive experiments with 7 collaboration strategies and 15 tasks (QA, reasoning, factuality, etc.) demonstrate that: 1) individual models improve by 8.0% on average, absorbing the strengths of collaboration while reducing the cost to a single model; 2) the collaboration also benefits from the stronger and more synergistic LMs after distillation, improving over initial systems without evolution by 14.9% on average. Analysis reveals that the single-multi evolution loop outperforms various existing evolutionary AI methods, is compatible with diverse model/collaboration/distillation settings, and helps solve problems where the initial model/system struggles to.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5c06\u591a\u6a21\u578b\u534f\u4f5c\u7cfb\u7edf\u7684\u4f18\u52bf\u538b\u7f29\u5230\u5355\u4e2a\u6a21\u578b\u4e2d\uff0c\u5e76\u8bbe\u8ba1\u4e86\"\u5355-\u591a\u8fdb\u5316\u5faa\u73af\"\u8ba9\u6a21\u578b\u901a\u8fc7\u534f\u4f5c\u3001\u84b8\u998f\u3001\u518d\u534f\u4f5c\u7684\u8fc7\u7a0b\u5b9e\u73b0\u81ea\u6211\u8fdb\u5316\u3002", "motivation": "\u591a\u6a21\u578b\u534f\u4f5c\u7cfb\u7edf\u867d\u7136\u80fd\u7ed3\u5408\u4e0d\u540c\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u4f46\u9700\u8981\u540c\u65f6\u52a0\u8f7d\u591a\u4e2a\u6a21\u578b\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u5982\u4f55\u5728\u4fdd\u6301\u534f\u4f5c\u4f18\u52bf\u7684\u540c\u65f6\u63d0\u9ad8\u6548\u7387\uff0c\u964d\u4f4e\u63a8\u7406\u6210\u672c\uff0c\u662f\u672c\u6587\u8981\u89e3\u51b3\u7684\u6838\u5fc3\u95ee\u9898\u3002", "method": "1. \u534f\u4f5c\u84b8\u998f\uff1a\u8bad\u7ec3\u5355\u4e2a\u6a21\u578b\u6a21\u4eff\u591a\u6a21\u578b\u534f\u4f5c\u7cfb\u7edf\u7684\u8f93\u51fa\uff0c\u5c06\u534f\u4f5c\u4f18\u52bf\u538b\u7f29\u5230\u5355\u4e2a\u6a21\u578b\u4e2d\n2. \u5355-\u591a\u8fdb\u5316\u5faa\u73af\uff1a\u591a\u4e2a\u6a21\u578b\u534f\u4f5c \u2192 \u6bcf\u4e2a\u6a21\u578b\u4ece\u534f\u4f5c\u8f93\u51fa\u4e2d\u84b8\u998f\u5b66\u4e60 \u2192 \u84b8\u998f\u6539\u8fdb\u540e\u7684\u6a21\u578b\u518d\u6b21\u534f\u4f5c\uff0c\u5f62\u6210\u8fdb\u5316\u751f\u6001\u7cfb\u7edf", "result": "1. \u5355\u4e2a\u6a21\u578b\u901a\u8fc7\u84b8\u998f\u5e73\u5747\u63d0\u53478.0%\uff0c\u5728\u4fdd\u6301\u534f\u4f5c\u4f18\u52bf\u7684\u540c\u65f6\u5c06\u6210\u672c\u964d\u4f4e\u5230\u5355\u4e2a\u6a21\u578b\n2. \u84b8\u998f\u6539\u8fdb\u540e\u7684\u6a21\u578b\u518d\u6b21\u534f\u4f5c\uff0c\u7cfb\u7edf\u6027\u80fd\u76f8\u6bd4\u521d\u59cb\u534f\u4f5c\u7cfb\u7edf\u5e73\u5747\u63d0\u534714.9%\n3. \u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u8fdb\u5316AI\u65b9\u6cd5\uff0c\u517c\u5bb9\u591a\u79cd\u6a21\u578b/\u534f\u4f5c/\u84b8\u998f\u8bbe\u7f6e\uff0c\u80fd\u89e3\u51b3\u521d\u59cb\u6a21\u578b/\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u7684\u95ee\u9898", "conclusion": "\u534f\u4f5c\u84b8\u998f\u548c\u5355-\u591a\u8fdb\u5316\u5faa\u73af\u662f\u6709\u6548\u7684\u6a21\u578b\u8fdb\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u6784\u5efa\u9ad8\u6548\u3001\u81ea\u8fdb\u5316\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.05366", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05366", "abs": "https://arxiv.org/abs/2602.05366", "authors": ["Yichen Tang", "Weihang Su", "Yiqun Liu", "Qingyao Ai"], "title": "Multi-Field Tool Retrieval", "comment": "12 pages, 4 figures", "summary": "Integrating external tools enables Large Language Models (LLMs) to interact with real-world environments and solve complex tasks. Given the growing scale of available tools, effective tool retrieval is essential to mitigate constraints of LLMs' context windows and ensure computational efficiency. Existing approaches typically treat tool retrieval as a traditional ad-hoc retrieval task, matching user queries against the entire raw tool documentation. In this paper, we identify three fundamental challenges that limit the effectiveness of this paradigm: (i) the incompleteness and structural inconsistency of tool documentation; (ii) the significant semantic and granular mismatch between user queries and technical tool documents; and, most importantly, (iii) the multi-aspect nature of tool utility, that involves distinct dimensions, such as functionality, input constraints, and output formats, varying in format and importance. To address these challenges, we introduce Multi-Field Tool Retrieval, a framework designed to align user intent with tool representations through fine-grained, multi-field modeling. Experimental results show that our framework achieves SOTA performance on five datasets and a mixed benchmark, exhibiting superior generalizability and robustness.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u591a\u5b57\u6bb5\u5de5\u5177\u68c0\u7d22\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u5de5\u5177\u68c0\u7d22\u4e2d\u5b58\u5728\u7684\u6587\u6863\u4e0d\u5b8c\u6574\u3001\u8bed\u4e49\u4e0d\u5339\u914d\u548c\u591a\u7ef4\u5ea6\u6548\u7528\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5916\u90e8\u5de5\u5177\u65f6\u9762\u4e34\u5de5\u5177\u89c4\u6a21\u589e\u957f\u5e26\u6765\u7684\u68c0\u7d22\u6548\u7387\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5c06\u5de5\u5177\u68c0\u7d22\u89c6\u4e3a\u4f20\u7edf\u68c0\u7d22\u4efb\u52a1\uff0c\u4f46\u5b58\u5728\u4e09\u4e2a\u6839\u672c\u9650\u5236\uff1a1) \u5de5\u5177\u6587\u6863\u4e0d\u5b8c\u6574\u4e14\u7ed3\u6784\u4e0d\u4e00\u81f4\uff1b2) \u7528\u6237\u67e5\u8be2\u4e0e\u6280\u672f\u6587\u6863\u5b58\u5728\u663e\u8457\u8bed\u4e49\u548c\u7c92\u5ea6\u4e0d\u5339\u914d\uff1b3) \u5de5\u5177\u6548\u7528\u5177\u6709\u591a\u7ef4\u5ea6\u7279\u6027\uff08\u529f\u80fd\u3001\u8f93\u5165\u7ea6\u675f\u3001\u8f93\u51fa\u683c\u5f0f\u7b49\uff09\u3002", "method": "\u63d0\u51fa\u591a\u5b57\u6bb5\u5de5\u5177\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u3001\u591a\u5b57\u6bb5\u5efa\u6a21\u6765\u5bf9\u9f50\u7528\u6237\u610f\u56fe\u4e0e\u5de5\u5177\u8868\u793a\u3002\u8be5\u6846\u67b6\u80fd\u591f\u5904\u7406\u5de5\u5177\u6548\u7528\u7684\u591a\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u89e3\u51b3\u6587\u6863\u4e0d\u5b8c\u6574\u548c\u8bed\u4e49\u4e0d\u5339\u914d\u95ee\u9898\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u6df7\u5408\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u591a\u5b57\u6bb5\u5de5\u5177\u68c0\u7d22\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5efa\u6a21\u5de5\u5177\u6548\u7528\u7684\u591a\u4e2a\u7ef4\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5de5\u5177\u68c0\u7d22\u7684\u6548\u679c\u548c\u6548\u7387\u3002"}}
{"id": "2602.05189", "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.05189", "abs": "https://arxiv.org/abs/2602.05189", "authors": ["Hsuan-Yu Chou", "Wajiha Naveed", "Shuyan Zhou", "Xiaowei Yang"], "title": "Are Open-Weight LLMs Ready for Social Media Moderation? A Comparative Study on Bluesky", "comment": null, "summary": "As internet access expands, so does exposure to harmful content, increasing the need for effective moderation. Research has demonstrated that large language models (LLMs) can be effectively utilized for social media moderation tasks, including harmful content detection. While proprietary LLMs have been shown to zero-shot outperform traditional machine learning models, the out-of-the-box capability of open-weight LLMs remains an open question.\n  Motivated by recent developments of reasoning LLMs, we evaluate seven state-of-the-art models: four proprietary and three open-weight. Testing with real-world posts on Bluesky, moderation decisions by Bluesky Moderation Service, and annotations by two authors, we find a considerable degree of overlap between the sensitivity (81%--97%) and specificity (91%--100%) of the open-weight LLMs and those (72%--98%, and 93%--99%) of the proprietary ones. Additionally, our analysis reveals that specificity exceeds sensitivity for rudeness detection, but the opposite holds for intolerance and threats. Lastly, we identify inter-rater agreement across human moderators and the LLMs, highlighting considerations for deploying LLMs in both platform-scale and personalized moderation contexts. These findings show open-weight LLMs can support privacy-preserving moderation on consumer-grade hardware and suggest new directions for designing moderation systems that balance community values with individual user preferences.", "AI": {"tldr": "\u5f00\u653e\u6743\u91cd\u5927\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u5ba1\u6838\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0e\u4e13\u6709\u6a21\u578b\u76f8\u5f53\uff0c\u80fd\u591f\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u7684\u672c\u5730\u5316\u5ba1\u6838\u90e8\u7f72\u3002", "motivation": "\u968f\u7740\u4e92\u8054\u7f51\u8bbf\u95ee\u6269\u5927\uff0c\u6709\u5bb3\u5185\u5bb9\u66b4\u9732\u589e\u52a0\uff0c\u9700\u8981\u6709\u6548\u7684\u5ba1\u6838\u673a\u5236\u3002\u867d\u7136\u4e13\u6709LLMs\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4f46\u5f00\u653e\u6743\u91cdLLMs\u7684\u5373\u7528\u80fd\u529b\u4ecd\u4e0d\u660e\u786e\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u771f\u5b9e\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u8bc4\u4f307\u4e2a\u6700\u5148\u8fdb\u7684LLMs\uff084\u4e2a\u4e13\u6709\u6a21\u578b\u548c3\u4e2a\u5f00\u653e\u6743\u91cd\u6a21\u578b\uff09\uff0c\u4f7f\u7528Bluesky\u5e73\u53f0\u7684\u771f\u5b9e\u5e16\u5b50\u3001Bluesky\u5ba1\u6838\u670d\u52a1\u7684\u51b3\u7b56\u4ee5\u53ca\u4e24\u4f4d\u4f5c\u8005\u7684\u6807\u6ce8\u4f5c\u4e3a\u6d4b\u8bd5\u6570\u636e\u3002\u5206\u6790\u6a21\u578b\u5728\u654f\u611f\u6027\u548c\u7279\u5f02\u6027\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5f00\u653e\u6743\u91cdLLMs\u7684\u654f\u611f\u6027\uff0881%-97%\uff09\u548c\u7279\u5f02\u6027\uff0891%-100%\uff09\u4e0e\u4e13\u6709\u6a21\u578b\uff08\u654f\u611f\u602772%-98%\uff0c\u7279\u5f02\u602793%-99%\uff09\u6709\u76f8\u5f53\u5927\u7684\u91cd\u53e0\u3002\u5728\u7c97\u9c81\u5185\u5bb9\u68c0\u6d4b\u4e2d\u7279\u5f02\u6027\u9ad8\u4e8e\u654f\u611f\u6027\uff0c\u4f46\u5728\u4e0d\u5bbd\u5bb9\u548c\u5a01\u80c1\u68c0\u6d4b\u4e2d\u654f\u611f\u6027\u66f4\u9ad8\u3002\u53d1\u73b0\u4eba\u7c7b\u5ba1\u6838\u5458\u4e0eLLMs\u4e4b\u95f4\u5b58\u5728\u8bc4\u5206\u8005\u95f4\u4e00\u81f4\u6027\u3002", "conclusion": "\u5f00\u653e\u6743\u91cdLLMs\u80fd\u591f\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u7684\u5ba1\u6838\uff0c\u4e3a\u8bbe\u8ba1\u5e73\u8861\u793e\u533a\u4ef7\u503c\u89c2\u4e0e\u4e2a\u4eba\u7528\u6237\u504f\u597d\u7684\u5ba1\u6838\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u5c55\u793a\u4e86\u5f00\u653e\u6a21\u578b\u5728\u5185\u5bb9\u5ba1\u6838\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.05408", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05408", "abs": "https://arxiv.org/abs/2602.05408", "authors": ["Zihao Guo", "Ligang Zhou", "Zeyang Tang", "Feicheng Li", "Ying Nie", "Zhiming Peng", "Qingyun Sun", "Jianxin Li"], "title": "Rich-Media Re-Ranker: A User Satisfaction-Driven LLM Re-ranking Framework for Rich-Media Search", "comment": null, "summary": "Re-ranking plays a crucial role in modern information search systems by refining the ranking of initial search results to better satisfy user information needs. However, existing methods show two notable limitations in improving user search satisfaction: inadequate modeling of multifaceted user intents and neglect of rich side information such as visual perception signals. To address these challenges, we propose the Rich-Media Re-Ranker framework, which aims to enhance user search satisfaction through multi-dimensional and fine-grained modeling. Our approach begins with a Query Planner that analyzes the sequence of query refinements within a session to capture genuine search intents, decomposing the query into clear and complementary sub-queries to enable broader coverage of users' potential intents. Subsequently, moving beyond primary text content, we integrate richer side information of candidate results, including signals modeling visual content generated by the VLM-based evaluator. These comprehensive signals are then processed alongside carefully designed re-ranking principle that considers multiple facets, including content relevance and quality, information gain, information novelty, and the visual presentation of cover images. Then, the LLM-based re-ranker performs the holistic evaluation based on these principles and integrated signals. To enhance the scenario adaptability of the VLM-based evaluator and the LLM-based re-ranker, we further enhance their capabilities through multi-task reinforcement learning. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines. Notably, the proposed framework has been deployed in a large-scale industrial search system, yielding substantial improvements in online user engagement rates and satisfaction metrics.", "AI": {"tldr": "\u63d0\u51faRich-Media Re-Ranker\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ef4\u7ec6\u7c92\u5ea6\u5efa\u6a21\u63d0\u5347\u641c\u7d22\u6ee1\u610f\u5ea6\uff0c\u7ed3\u5408\u67e5\u8be2\u5206\u6790\u3001\u89c6\u89c9\u5185\u5bb9\u611f\u77e5\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u5df2\u5de5\u4e1a\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u91cd\u6392\u5e8f\u65b9\u6cd5\u5b58\u5728\u4e24\u5927\u5c40\u9650\uff1a1\uff09\u5bf9\u591a\u9762\u7528\u6237\u610f\u56fe\u5efa\u6a21\u4e0d\u8db3\uff1b2\uff09\u5ffd\u89c6\u4e30\u5bcc\u7684\u4fa7\u4fe1\u606f\uff08\u5982\u89c6\u89c9\u611f\u77e5\u4fe1\u53f7\uff09\u3002\u8fd9\u9650\u5236\u4e86\u7528\u6237\u641c\u7d22\u6ee1\u610f\u5ea6\u7684\u63d0\u5347\u3002", "method": "1. Query Planner\u5206\u6790\u4f1a\u8bdd\u4e2d\u67e5\u8be2\u7ec6\u5316\u5e8f\u5217\uff0c\u6355\u83b7\u771f\u5b9e\u641c\u7d22\u610f\u56fe\uff0c\u5206\u89e3\u4e3a\u4e92\u8865\u5b50\u67e5\u8be2\uff1b2. \u6574\u5408\u5019\u9009\u7ed3\u679c\u7684\u4e30\u5bcc\u4fa7\u4fe1\u606f\uff08\u5305\u62ecVLM\u751f\u6210\u7684\u89c6\u89c9\u5185\u5bb9\u4fe1\u53f7\uff09\uff1b3. \u57fa\u4e8e\u591a\u9762\u539f\u5219\uff08\u5185\u5bb9\u76f8\u5173\u6027\u3001\u8d28\u91cf\u3001\u4fe1\u606f\u589e\u76ca\u3001\u65b0\u9896\u6027\u3001\u5c01\u9762\u56fe\u89c6\u89c9\u5448\u73b0\uff09\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff1b4. LLM-based re-ranker\u8fdb\u884c\u6574\u4f53\u8bc4\u4f30\uff1b5. \u901a\u8fc7\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u589e\u5f3aVLM\u8bc4\u4f30\u5668\u548cLLM\u91cd\u6392\u5e8f\u5668\u7684\u573a\u666f\u9002\u5e94\u6027\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u8be5\u6846\u67b6\u5df2\u5728\u5927\u578b\u5de5\u4e1a\u641c\u7d22\u7cfb\u7edf\u4e2d\u90e8\u7f72\uff0c\u5728\u7ebf\u7528\u6237\u53c2\u4e0e\u7387\u548c\u6ee1\u610f\u5ea6\u6307\u6807\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "Rich-Media Re-Ranker\u6846\u67b6\u901a\u8fc7\u591a\u7ef4\u5ea6\u7ec6\u7c92\u5ea6\u5efa\u6a21\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u91cd\u6392\u5e8f\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u6210\u529f\u6574\u5408\u4e86\u67e5\u8be2\u610f\u56fe\u5206\u6790\u3001\u89c6\u89c9\u5185\u5bb9\u611f\u77e5\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7528\u6237\u641c\u7d22\u6ee1\u610f\u5ea6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5de5\u4e1a\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.05205", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05205", "abs": "https://arxiv.org/abs/2602.05205", "authors": ["Kenichiro Ando", "Tatsuya Harada"], "title": "Aligning Large Language Model Behavior with Human Citation Preferences", "comment": "Work In Progress", "summary": "Most services built on powerful large-scale language models (LLMs) add citations to their output to enhance credibility. Recent research has paid increasing attention to the question of what reference documents to link to outputs. However, how LLMs recognize cite-worthiness and how this process should be controlled remains underexplored. In this study, we focus on what kinds of content LLMs currently tend to cite and how well that behavior aligns with human preferences. We construct a dataset to characterize the relationship between human citation preferences and LLM behavior. Web-derived texts are categorized into eight citation-motivation types, and pairwise citation preferences are exhaustively evaluated across all type combinations to capture fine-grained contrasts. Our results show that humans most frequently seek citations for medical text, and stronger models display a similar tendency. We also find that current models are as much as $27\\%$ more likely than humans to add citations to text that is explicitly marked as needing citations on sources such as Wikipedia, and this overemphasis reduces alignment accuracy. Conversely, models systematically underselect numeric sentences (by $-22.6\\%$ relative to humans) and sentences containing personal names (by $-20.1\\%$), categories for which humans typically demand citations. Furthermore, experiments with Direct Preference Optimization demonstrate that model behavior can be calibrated to better match human citation preferences. We expect this study to provide a foundation for more fine-grained investigations into LLM citation preferences.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\u6765\u8bc4\u4f30LLM\u5f15\u7528\u884c\u4e3a\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u53d1\u73b0LLM\u8fc7\u5ea6\u5f15\u7528\u6807\u8bb0\u4e3a\u9700\u8981\u5f15\u7528\u7684\u6587\u672c\uff0c\u4f46\u7cfb\u7edf\u6027\u6b20\u5f15\u7528\u6570\u5b57\u548c\u5305\u542b\u4eba\u540d\u7684\u53e5\u5b50\uff0c\u901a\u8fc7DPO\u53ef\u4ee5\u6821\u51c6\u6a21\u578b\u884c\u4e3a\u4ee5\u66f4\u597d\u5730\u5339\u914d\u4eba\u7c7b\u504f\u597d\u3002", "motivation": "\u5f53\u524dLLM\u670d\u52a1\u867d\u7136\u6dfb\u52a0\u5f15\u7528\u6765\u589e\u5f3a\u53ef\u4fe1\u5ea6\uff0c\u4f46LLM\u5982\u4f55\u8bc6\u522b\u503c\u5f97\u5f15\u7528\u7684\u5185\u5bb9\u4ee5\u53ca\u5982\u4f55\u63a7\u5236\u8fd9\u4e00\u8fc7\u7a0b\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u5173\u6ce8LLM\u5f53\u524d\u503e\u5411\u4e8e\u5f15\u7528\u4ec0\u4e48\u7c7b\u578b\u7684\u5185\u5bb9\uff0c\u4ee5\u53ca\u8fd9\u79cd\u884c\u4e3a\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u7a0b\u5ea6\u3002", "method": "\u6784\u5efa\u6570\u636e\u96c6\u6765\u8868\u5f81\u4eba\u7c7b\u5f15\u7528\u504f\u597d\u4e0eLLM\u884c\u4e3a\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5c06\u7f51\u7edc\u6587\u672c\u5206\u4e3a\u516b\u79cd\u5f15\u7528\u52a8\u673a\u7c7b\u578b\uff0c\u5728\u6240\u6709\u7c7b\u578b\u7ec4\u5408\u4e2d\u8be6\u5c3d\u8bc4\u4f30\u6210\u5bf9\u5f15\u7528\u504f\u597d\u4ee5\u6355\u6349\u7ec6\u7c92\u5ea6\u5bf9\u6bd4\u3002\u4f7f\u7528Direct Preference Optimization\uff08DPO\uff09\u8fdb\u884c\u5b9e\u9a8c\u6765\u6821\u51c6\u6a21\u578b\u884c\u4e3a\u3002", "result": "1) \u4eba\u7c7b\u6700\u5e38\u4e3a\u533b\u5b66\u6587\u672c\u5bfb\u6c42\u5f15\u7528\uff0c\u66f4\u5f3a\u7684\u6a21\u578b\u4e5f\u663e\u793a\u7c7b\u4f3c\u503e\u5411\uff1b2) \u5f53\u524d\u6a21\u578b\u6bd4\u4eba\u7c7b\u591a27%\u7684\u53ef\u80fd\u6027\u4e3a\u6807\u8bb0\u4e3a\u9700\u8981\u5f15\u7528\u7684\u6587\u672c\uff08\u5982\u7ef4\u57fa\u767e\u79d1\uff09\u6dfb\u52a0\u5f15\u7528\uff0c\u8fd9\u79cd\u8fc7\u5ea6\u5f3a\u8c03\u964d\u4f4e\u4e86\u5bf9\u9f50\u51c6\u786e\u6027\uff1b3) \u6a21\u578b\u7cfb\u7edf\u6027\u6b20\u5f15\u7528\u6570\u5b57\u53e5\u5b50\uff08\u76f8\u5bf9\u4eba\u7c7b-22.6%\uff09\u548c\u5305\u542b\u4eba\u540d\u7684\u53e5\u5b50\uff08-20.1%\uff09\uff0c\u800c\u8fd9\u4e9b\u7c7b\u522b\u4eba\u7c7b\u901a\u5e38\u8981\u6c42\u5f15\u7528\uff1b4) DPO\u5b9e\u9a8c\u8868\u660e\u53ef\u4ee5\u6821\u51c6\u6a21\u578b\u884c\u4e3a\u4ee5\u66f4\u597d\u5730\u5339\u914d\u4eba\u7c7b\u5f15\u7528\u504f\u597d\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aLLM\u5f15\u7528\u504f\u597d\u7684\u7ec6\u7c92\u5ea6\u8c03\u67e5\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5f15\u7528\u884c\u4e3a\u4e0e\u4eba\u7c7b\u504f\u597d\u4e4b\u95f4\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u5e76\u8bc1\u660e\u901a\u8fc7DPO\u7b49\u6280\u672f\u53ef\u4ee5\u6539\u5584\u8fd9\u79cd\u5bf9\u9f50\u3002"}}
{"id": "2602.05413", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05413", "abs": "https://arxiv.org/abs/2602.05413", "authors": ["Filip Ku\u010dera", "Christoph Mandl", "Isao Echizen", "Radu Timofte", "Timo Spinde"], "title": "SciDef: Automating Definition Extraction from Academic Literature with Large Language Models", "comment": "Under Review - Submitted to SIGIR 2026 Resources Track; 8 pages, 6 figures, 4 tables", "summary": "Definitions are the foundation for any scientific work, but with a significant increase in publication numbers, gathering definitions relevant to any keyword has become challenging. We therefore introduce SciDef, an LLM-based pipeline for automated definition extraction. We test SciDef on DefExtra & DefSim, novel datasets of human-extracted definitions and definition-pairs' similarity, respectively. Evaluating 16 language models across prompting strategies, we demonstrate that multi-step and DSPy-optimized prompting improve extraction performance. To evaluate extraction, we test various metrics and show that an NLI-based method yields the most reliable results. We show that LLMs are largely able to extract definitions from scientific literature (86.4% of definitions from our test-set); yet future work should focus not just on finding definitions, but on identifying relevant ones, as models tend to over-generate them.\n  Code & datasets are available at https://github.com/Media-Bias-Group/SciDef.", "AI": {"tldr": "SciDef\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u5b9a\u4e49\u63d0\u53d6\u7ba1\u9053\uff0c\u901a\u8fc7\u591a\u6b65\u548cDSPy\u4f18\u5316\u7684\u63d0\u793a\u7b56\u7565\u63d0\u9ad8\u6027\u80fd\uff0c\u5728\u79d1\u5b66\u6587\u732e\u4e2d\u80fd\u63d0\u53d686.4%\u7684\u5b9a\u4e49\uff0c\u4f46\u5b58\u5728\u8fc7\u5ea6\u751f\u6210\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u79d1\u5b66\u51fa\u7248\u7269\u6570\u91cf\u5927\u5e45\u589e\u52a0\uff0c\u6536\u96c6\u4e0e\u7279\u5b9a\u5173\u952e\u8bcd\u76f8\u5173\u7684\u5b9a\u4e49\u53d8\u5f97\u6781\u5177\u6311\u6218\u6027\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u9ad8\u6548\u63d0\u53d6\u79d1\u5b66\u6587\u732e\u4e2d\u7684\u5b9a\u4e49\u3002", "method": "\u63d0\u51faSciDef\u7ba1\u9053\uff0c\u57fa\u4e8eLLM\u8fdb\u884c\u5b9a\u4e49\u63d0\u53d6\u3002\u5728DefExtra\u548cDefSim\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd516\u79cd\u8bed\u8a00\u6a21\u578b\uff0c\u8bc4\u4f30\u4e0d\u540c\u63d0\u793a\u7b56\u7565\uff08\u5305\u62ec\u591a\u6b65\u63d0\u793a\u548cDSPy\u4f18\u5316\u63d0\u793a\uff09\uff0c\u5e76\u4f7f\u7528\u591a\u79cd\u6307\u6807\uff08\u7279\u522b\u662f\u57fa\u4e8eNLI\u7684\u65b9\u6cd5\uff09\u8bc4\u4f30\u63d0\u53d6\u8d28\u91cf\u3002", "result": "LLM\u5728\u79d1\u5b66\u6587\u732e\u4e2d\u80fd\u6709\u6548\u63d0\u53d6\u5b9a\u4e49\uff08\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523086.4%\u7684\u63d0\u53d6\u7387\uff09\uff0c\u591a\u6b65\u63d0\u793a\u548cDSPy\u4f18\u5316\u63d0\u793a\u80fd\u63d0\u5347\u6027\u80fd\u3002\u57fa\u4e8eNLI\u7684\u8bc4\u4f30\u65b9\u6cd5\u6700\u53ef\u9760\u3002\u4f46\u6a21\u578b\u503e\u5411\u4e8e\u8fc7\u5ea6\u751f\u6210\u5b9a\u4e49\uff0c\u9700\u8981\u533a\u5206\u76f8\u5173\u5b9a\u4e49\u3002", "conclusion": "LLM\u80fd\u591f\u6709\u6548\u4ece\u79d1\u5b66\u6587\u732e\u4e2d\u63d0\u53d6\u5b9a\u4e49\uff0c\u4f46\u672a\u6765\u5de5\u4f5c\u5e94\u4e13\u6ce8\u4e8e\u8bc6\u522b\u76f8\u5173\u5b9a\u4e49\u800c\u4e0d\u4ec5\u4ec5\u662f\u627e\u5230\u5b9a\u4e49\uff0c\u56e0\u4e3a\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u751f\u6210\u7684\u95ee\u9898\u3002\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.05211", "categories": ["cs.CL", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.05211", "abs": "https://arxiv.org/abs/2602.05211", "authors": ["Hongye Zhao", "Yi Zhao", "Chengzhi Zhang"], "title": "Quantifying the Knowledge Proximity Between Academic and Industry Research: An Entity and Semantic Perspective", "comment": null, "summary": "The academia and industry are characterized by a reciprocal shaping and dynamic feedback mechanism. Despite distinct institutional logics, they have adapted closely in collaborative publishing and talent mobility, demonstrating tension between institutional divergence and intensive collaboration. Existing studies on their knowledge proximity mainly rely on macro indicators such as the number of collaborative papers or patents, lacking an analysis of knowledge units in the literature. This has led to an insufficient grasp of fine-grained knowledge proximity between industry and academia, potentially undermining collaboration frameworks and resource allocation efficiency. To remedy the limitation, this study quantifies the trajectory of academia-industry co-evolution through fine-grained entities and semantic space. In the entity measurement part, we extract fine-grained knowledge entities via pre-trained models, measure sequence overlaps using cosine similarity, and analyze topological features through complex network analysis. At the semantic level, we employ unsupervised contrastive learning to quantify convergence in semantic spaces by measuring cross-institutional textual similarities. Finally, we use citation distribution patterns to examine correlations between bidirectional knowledge flows and similarity. Analysis reveals that knowledge proximity between academia and industry rises, particularly following technological change. This provides textual evidence of bidirectional adaptation in co-evolution. Additionally, academia's knowledge dominance weakens during technological paradigm shifts. The dataset and code for this paper can be accessed at https://github.com/tinierZhao/Academic-Industrial-associations.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u5b9e\u4f53\u548c\u8bed\u4e49\u7a7a\u95f4\u5206\u6790\uff0c\u91cf\u5316\u4e86\u5b66\u672f\u754c\u4e0e\u4ea7\u4e1a\u754c\u7684\u5171\u540c\u6f14\u5316\u8f68\u8ff9\uff0c\u53d1\u73b0\u6280\u672f\u53d8\u9769\u671f\u95f4\u4e24\u8005\u7684\u77e5\u8bc6\u63a5\u8fd1\u5ea6\u589e\u52a0\uff0c\u4e14\u5b66\u672f\u754c\u7684\u77e5\u8bc6\u4e3b\u5bfc\u5730\u4f4d\u51cf\u5f31\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u5408\u4f5c\u8bba\u6587\u6216\u4e13\u5229\u6570\u91cf\u7b49\u5b8f\u89c2\u6307\u6807\u6765\u5206\u6790\u5b66\u672f\u754c\u4e0e\u4ea7\u4e1a\u754c\u7684\u77e5\u8bc6\u63a5\u8fd1\u5ea6\uff0c\u7f3a\u4e4f\u5bf9\u6587\u732e\u4e2d\u77e5\u8bc6\u5355\u5143\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\uff0c\u8fd9\u5bfc\u81f4\u5bf9\u4e24\u8005\u95f4\u7cbe\u7ec6\u77e5\u8bc6\u63a5\u8fd1\u5ea6\u7684\u628a\u63e1\u4e0d\u8db3\uff0c\u53ef\u80fd\u5f71\u54cd\u5408\u4f5c\u6846\u67b6\u548c\u8d44\u6e90\u914d\u7f6e\u6548\u7387\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u5b9e\u4f53\u6d4b\u91cf\u90e8\u5206\uff1a\u901a\u8fc7\u9884\u8bad\u7ec3\u6a21\u578b\u63d0\u53d6\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u5b9e\u4f53\uff0c\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6d4b\u91cf\u5e8f\u5217\u91cd\u53e0\uff0c\u5e76\u901a\u8fc7\u590d\u6742\u7f51\u7edc\u5206\u6790\u62d3\u6251\u7279\u5f81\uff1b2\uff09\u8bed\u4e49\u5c42\u9762\uff1a\u91c7\u7528\u65e0\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u91cf\u5316\u8bed\u4e49\u7a7a\u95f4\u7684\u6536\u655b\u6027\uff0c\u901a\u8fc7\u6d4b\u91cf\u8de8\u673a\u6784\u6587\u672c\u76f8\u4f3c\u5ea6\uff1b\u6700\u540e\u4f7f\u7528\u5f15\u7528\u5206\u5e03\u6a21\u5f0f\u68c0\u67e5\u53cc\u5411\u77e5\u8bc6\u6d41\u4e0e\u76f8\u4f3c\u5ea6\u7684\u76f8\u5173\u6027\u3002", "result": "\u5206\u6790\u663e\u793a\u5b66\u672f\u754c\u4e0e\u4ea7\u4e1a\u754c\u7684\u77e5\u8bc6\u63a5\u8fd1\u5ea6\u5728\u4e0a\u5347\uff0c\u7279\u522b\u662f\u5728\u6280\u672f\u53d8\u9769\u540e\u3002\u8fd9\u4e3a\u5171\u540c\u6f14\u5316\u4e2d\u7684\u53cc\u5411\u9002\u5e94\u63d0\u4f9b\u4e86\u6587\u672c\u8bc1\u636e\u3002\u6b64\u5916\uff0c\u5728\u6280\u672f\u8303\u5f0f\u8f6c\u53d8\u671f\u95f4\uff0c\u5b66\u672f\u754c\u7684\u77e5\u8bc6\u4e3b\u5bfc\u5730\u4f4d\u4f1a\u51cf\u5f31\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u548c\u8bed\u4e49\u5206\u6790\u65b9\u6cd5\uff0c\u4e3a\u5b66\u672f\u754c\u4e0e\u4ea7\u4e1a\u754c\u7684\u5171\u540c\u6f14\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u91cf\u5316\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u6280\u672f\u53d8\u9769\u671f\u95f4\u4e24\u8005\u77e5\u8bc6\u63a5\u8fd1\u5ea6\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5bf9\u4f18\u5316\u4ea7\u5b66\u5408\u4f5c\u6846\u67b6\u548c\u8d44\u6e90\u914d\u7f6e\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2602.05445", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05445", "abs": "https://arxiv.org/abs/2602.05445", "authors": ["Sebastian Bruch", "Martino Fontana", "Franco Maria Nardini", "Cosimo Rulli", "Rossano Venturini"], "title": "Forward Index Compression for Learned Sparse Retrieval", "comment": null, "summary": "Text retrieval using learned sparse representations of queries and documents has, over the years, evolved into a highly effective approach to search. It is thanks to recent advances in approximate nearest neighbor search-with the emergence of highly efficient algorithms such as the inverted index-based Seismic and the graph-based Hnsw-that retrieval with sparse representations became viable in practice. In this work, we scrutinize the efficiency of sparse retrieval algorithms and focus particularly on the size of a data structure that is common to all algorithmic flavors and that constitutes a substantial fraction of the overall index size: the forward index. In particular, we seek compression techniques to reduce the storage footprint of the forward index without compromising search quality or inner product computation latency. In our examination with various integer compression techniques, we report that StreamVByte achieves the best trade-off between memory footprint, retrieval accuracy, and latency. We then improve StreamVByte by introducing DotVByte, a new algorithm tailored to inner product computation. Experiments on MsMarco show that our improvements lead to significant space savings while maintaining retrieval efficiency.", "AI": {"tldr": "\u63d0\u51faDotVByte\u538b\u7f29\u7b97\u6cd5\uff0c\u4f18\u5316\u7a00\u758f\u68c0\u7d22\u4e2d\u7684\u524d\u5411\u7d22\u5f15\u5b58\u50a8\uff0c\u5728\u4fdd\u6301\u68c0\u7d22\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u5360\u7528\u3002", "motivation": "\u7a00\u758f\u68c0\u7d22\u867d\u7136\u6709\u6548\uff0c\u4f46\u5176\u524d\u5411\u7d22\u5f15\u5360\u7528\u4e86\u5927\u91cf\u5b58\u50a8\u7a7a\u95f4\uff0c\u9700\u8981\u5728\u4e0d\u5f71\u54cd\u68c0\u7d22\u8d28\u91cf\u548c\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\u538b\u7f29\u8be5\u6570\u636e\u7ed3\u6784\u3002", "method": "\u7814\u7a76\u591a\u79cd\u6574\u6570\u538b\u7f29\u6280\u672f\uff0c\u53d1\u73b0StreamVByte\u6548\u679c\u6700\u4f73\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e13\u95e8\u9488\u5bf9\u5185\u79ef\u8ba1\u7b97\u7684DotVByte\u7b97\u6cd5\u3002", "result": "\u5728MsMarco\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDotVByte\u80fd\u663e\u8457\u8282\u7701\u5b58\u50a8\u7a7a\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u68c0\u7d22\u6548\u7387\u3002", "conclusion": "DotVByte\u4e3a\u7a00\u758f\u68c0\u7d22\u7684\u524d\u5411\u7d22\u5f15\u538b\u7f29\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u5b58\u50a8\u6548\u7387\u4e0e\u68c0\u7d22\u6027\u80fd\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2602.05220", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.05220", "abs": "https://arxiv.org/abs/2602.05220", "authors": ["Jinchuan Tian", "Haoran Wang", "Bo-Hao Su", "Chien-yu Huang", "Qingzheng Wang", "Jiatong Shi", "William Chen", "Xun Gong", "Siddhant Arora", "Chin-Jou Li", "Masao Someki", "Takashi Maekaku", "Yusuke Shinohara", "Jin Sakuma", "Chao-Han Huck Yang", "Shinji Watanabe"], "title": "Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions", "comment": null, "summary": "Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive natural language descriptions that encapsulate the critical cognitive concepts inherent in the signal (e.g., transcription, audio events). By pre-training on a massive corpus of 600B tokens, the model establishes a robust bidirectional mapping between raw audio and this high-level conceptual space. During fine-tuning, Bagpiper adopts a caption-then-process workflow, simulating an intermediate cognitive reasoning step to solve diverse tasks without task-specific priors. Experimentally, Bagpiper outperforms Qwen-2.5-Omni on MMAU and AIRBench for audio understanding and surpasses CosyVoice3 and TangoFlux in generation quality, capable of synthesizing arbitrary compositions of speech, music, and sound effects. To the best of our knowledge, Bagpiper is among the first works that achieve unified understanding generation for general audio. Model, data, and code are available at Bagpiper Home Page.", "AI": {"tldr": "Bagpiper\u662f\u4e00\u4e2a8B\u53c2\u6570\u7684\u97f3\u9891\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u4e30\u5bcc\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u5b9e\u73b0\u97f3\u9891\u7684\u7269\u7406\u4fe1\u53f7\u4e0e\u62bd\u8c61\u8ba4\u77e5\u6982\u5ff5\u4e4b\u95f4\u7684\u53cc\u5411\u6620\u5c04\uff0c\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u5b9e\u73b0\u97f3\u9891\u7406\u89e3\u4e0e\u751f\u6210\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u97f3\u9891\u57fa\u7840\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u4e8e\u521a\u6027\u3001\u4efb\u52a1\u7279\u5b9a\u7684\u76d1\u7763\uff0c\u5904\u7406\u5b64\u7acb\u7684\u97f3\u9891\u56e0\u7d20\u800c\u975e\u6574\u4f53\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u4eba\u7c7b\u667a\u80fd\u4ee5\u6574\u4f53\u65b9\u5f0f\u5904\u7406\u97f3\u9891\uff0c\u65e0\u7f1d\u5730\u5c06\u7269\u7406\u4fe1\u53f7\u4e0e\u62bd\u8c61\u8ba4\u77e5\u6982\u5ff5\u8fde\u63a5\u8d77\u6765\u4ee5\u6267\u884c\u590d\u6742\u4efb\u52a1\u3002\u4f5c\u8005\u5e0c\u671b\u6784\u5efa\u4e00\u4e2a\u80fd\u6a21\u62df\u4eba\u7c7b\u8fd9\u79cd\u6574\u4f53\u97f3\u9891\u5904\u7406\u80fd\u529b\u7684\u6a21\u578b\u3002", "method": "1. \u4f7f\u7528600B token\u7684\u5927\u89c4\u6a21\u8bed\u6599\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5efa\u7acb\u539f\u59cb\u97f3\u9891\u4e0e\u9ad8\u7ea7\u6982\u5ff5\u7a7a\u95f4\u4e4b\u95f4\u7684\u7a33\u5065\u53cc\u5411\u6620\u5c04\u30022. \u91c7\u7528caption-then-process\u5de5\u4f5c\u6d41\u7a0b\u8fdb\u884c\u5fae\u8c03\uff0c\u6a21\u62df\u4e2d\u95f4\u8ba4\u77e5\u63a8\u7406\u6b65\u9aa4\u6765\u89e3\u51b3\u591a\u6837\u5316\u4efb\u52a1\u30023. \u901a\u8fc7\u4e30\u5bcc\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\uff08\u5305\u542b\u8f6c\u5f55\u3001\u97f3\u9891\u4e8b\u4ef6\u7b49\u5173\u952e\u8ba4\u77e5\u6982\u5ff5\uff09\u6765\u89e3\u91ca\u7269\u7406\u97f3\u9891\u3002", "result": "1. \u5728\u97f3\u9891\u7406\u89e3\u65b9\u9762\uff0cBagpiper\u5728MMAU\u548cAIRBench\u4e0a\u8d85\u8d8a\u4e86Qwen-2.5-Omni\u30022. \u5728\u97f3\u9891\u751f\u6210\u65b9\u9762\uff0c\u8d85\u8d8a\u4e86CosyVoice3\u548cTangoFlux\uff0c\u80fd\u591f\u5408\u6210\u8bed\u97f3\u3001\u97f3\u4e50\u548c\u97f3\u6548\u7684\u4efb\u610f\u7ec4\u5408\u30023. \u636e\u4f5c\u8005\u6240\u77e5\uff0c\u8fd9\u662f\u9996\u6279\u5b9e\u73b0\u901a\u7528\u97f3\u9891\u7edf\u4e00\u7406\u89e3\u4e0e\u751f\u6210\u7684\u5de5\u4f5c\u4e4b\u4e00\u3002", "conclusion": "Bagpiper\u901a\u8fc7\u5c06\u7269\u7406\u97f3\u9891\u4fe1\u53f7\u6620\u5c04\u5230\u4e30\u5bcc\u7684\u8ba4\u77e5\u6982\u5ff5\u7a7a\u95f4\uff0c\u5b9e\u73b0\u4e86\u5bf9\u97f3\u9891\u7684\u6574\u4f53\u5904\u7406\uff0c\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u97f3\u9891\u7406\u89e3\u4e0e\u751f\u6210\u57fa\u7840\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e0a\u7684\u5353\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.05474", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05474", "abs": "https://arxiv.org/abs/2602.05474", "authors": ["Yicheng Di", "Zhanjie Zhang", "Yun Wangc", "Jinren Liue", "Jiaqi Yanf", "Jiyu Wei", "Xiangyu Chend", "Yuan Liu"], "title": "LMMRec: LLM-driven Motivation-aware Multimodal Recommendation", "comment": null, "summary": "Motivation-based recommendation systems uncover user behavior drivers. Motivation modeling, crucial for decision-making and content preference, explains recommendation generation. Existing methods often treat motivation as latent variables from interaction data, neglecting heterogeneous information like review text. In multimodal motivation fusion, two challenges arise: 1) achieving stable cross-modal alignment amid noise, and 2) identifying features reflecting the same underlying motivation across modalities. To address these, we propose LLM-driven Motivation-aware Multimodal Recommendation (LMMRec), a model-agnostic framework leveraging large language models for deep semantic priors and motivation understanding. LMMRec uses chain-of-thought prompting to extract fine-grained user and item motivations from text. A dual-encoder architecture models textual and interaction-based motivations for cross-modal alignment, while Motivation Coordination Strategy and Interaction-Text Correspondence Method mitigate noise and semantic drift through contrastive learning and momentum updates. Experiments on three datasets show LMMRec achieves up to a 4.98\\% performance improvement.", "AI": {"tldr": "LMMRec\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u52a8\u673a\u611f\u77e5\u591a\u6a21\u6001\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u63d0\u53d6\u7ec6\u7c92\u5ea6\u52a8\u673a\uff0c\u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\u548c\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u73b0\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u9ad84.98%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u901a\u5e38\u5c06\u52a8\u673a\u89c6\u4e3a\u4ea4\u4e92\u6570\u636e\u4e2d\u7684\u6f5c\u5728\u53d8\u91cf\uff0c\u5ffd\u7565\u4e86\u8bc4\u8bba\u6587\u672c\u7b49\u591a\u6a21\u6001\u4fe1\u606f\u3002\u5728\u591a\u6a21\u6001\u52a8\u673a\u878d\u5408\u4e2d\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u5728\u566a\u58f0\u4e2d\u5b9e\u73b0\u7a33\u5b9a\u7684\u8de8\u6a21\u6001\u5bf9\u9f50\uff1b2) \u8bc6\u522b\u53cd\u6620\u76f8\u540c\u5e95\u5c42\u52a8\u673a\u7684\u8de8\u6a21\u6001\u7279\u5f81\u3002", "method": "\u63d0\u51faLMMRec\u6846\u67b6\uff1a1) \u4f7f\u7528\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u7ec6\u7c92\u5ea6\u7528\u6237\u548c\u7269\u54c1\u52a8\u673a\uff1b2) \u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\u5206\u522b\u5efa\u6a21\u6587\u672c\u52a8\u673a\u548c\u4ea4\u4e92\u52a8\u673a\uff1b3) \u901a\u8fc7\u52a8\u673a\u534f\u8c03\u7b56\u7565\u548c\u4ea4\u4e92-\u6587\u672c\u5bf9\u5e94\u65b9\u6cd5\uff0c\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u548c\u52a8\u91cf\u66f4\u65b0\u7f13\u89e3\u566a\u58f0\u548c\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLMMRec\u5b9e\u73b0\u4e86\u6700\u9ad84.98%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "LMMRec\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u5148\u9a8c\u548c\u52a8\u673a\u7406\u89e3\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u52a8\u673a\u878d\u5408\u4e2d\u7684\u5bf9\u9f50\u548c\u7279\u5f81\u8bc6\u522b\u95ee\u9898\uff0c\u4e3a\u52a8\u673a\u611f\u77e5\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05235", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05235", "abs": "https://arxiv.org/abs/2602.05235", "authors": ["Zhilin Liang", "Yuxiang Wang", "Zimu Zhou", "Hainan Zhang", "Boyi Liu", "Yongxin Tong"], "title": "FedMosaic: Federated Retrieval-Augmented Generation via Parametric Adapters", "comment": "11 pages", "summary": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by grounding generation in external knowledge to improve factuality and reduce hallucinations. Yet most deployments assume a centralized corpus, which is infeasible in privacy aware domains where knowledge remains siloed. This motivates federated RAG (FedRAG), where a central LLM server collaborates with distributed silos without sharing raw documents. In context RAG violates this requirement by transmitting verbatim documents, whereas parametric RAG encodes documents into lightweight adapters that merge with a frozen LLM at inference, avoiding raw-text exchange. We adopt the parametric approach but face two unique challenges induced by FedRAG: high storage and communication from per-document adapters, and destructive aggregation caused by indiscriminately merging multiple adapters. We present FedMosaic, the first federated RAG framework built on parametric adapters. FedMosaic clusters semantically related documents into multi-document adapters with document-specific masks to reduce overhead while preserving specificity, and performs selective adapter aggregation to combine only relevance-aligned, nonconflicting adapters. Experiments show that FedMosaic achieves an average 10.9% higher accuracy than state-of-the-art methods in four categories, while lowering storage costs by 78.8% to 86.3% and communication costs by 91.4%, and never sharing raw documents.", "AI": {"tldr": "FedMosaic\uff1a\u9996\u4e2a\u57fa\u4e8e\u53c2\u6570\u5316\u9002\u914d\u5668\u7684\u8054\u90a6RAG\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u6587\u6863\u5230\u591a\u6587\u6863\u9002\u914d\u5668\u5e76\u4f7f\u7528\u6587\u6863\u7279\u5b9a\u63a9\u7801\u6765\u964d\u4f4e\u5f00\u9500\uff0c\u540c\u65f6\u901a\u8fc7\u9009\u62e9\u6027\u9002\u914d\u5668\u805a\u5408\u6765\u907f\u514d\u51b2\u7a81\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u5e76\u5927\u5e45\u964d\u4f4e\u5b58\u50a8\u548c\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u4f20\u7edfRAG\u5047\u8bbe\u96c6\u4e2d\u5f0f\u77e5\u8bc6\u5e93\uff0c\u4f46\u5728\u9690\u79c1\u654f\u611f\u9886\u57df\uff0c\u77e5\u8bc6\u901a\u5e38\u5206\u6563\u5728\u5b64\u5c9b\u4e2d\u65e0\u6cd5\u5171\u4eab\u3002\u8fd9\u4fc3\u4f7f\u4e86\u8054\u90a6RAG\u7684\u9700\u6c42\uff0c\u5373\u4e2d\u592eLLM\u670d\u52a1\u5668\u4e0e\u5206\u5e03\u5f0f\u77e5\u8bc6\u5b64\u5c9b\u534f\u4f5c\u800c\u4e0d\u5171\u4eab\u539f\u59cb\u6587\u6863\u3002\u4e0a\u4e0b\u6587RAG\u4f1a\u4f20\u8f93\u539f\u59cb\u6587\u6863\u8fdd\u53cd\u9690\u79c1\u8981\u6c42\uff0c\u800c\u53c2\u6570\u5316RAG\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u907f\u514d\u4e86\u539f\u59cb\u6587\u672c\u4ea4\u6362\u3002", "method": "FedMosaic\u91c7\u7528\u53c2\u6570\u5316\u9002\u914d\u5668\u65b9\u6cd5\uff0c\u4f46\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a1\uff09\u6bcf\u4e2a\u6587\u6863\u9002\u914d\u5668\u5e26\u6765\u7684\u9ad8\u5b58\u50a8\u548c\u901a\u4fe1\u5f00\u9500\uff1b2\uff09\u591a\u4e2a\u9002\u914d\u5668\u65e0\u5dee\u522b\u5408\u5e76\u5bfc\u81f4\u7684\u7834\u574f\u6027\u805a\u5408\u3002\u89e3\u51b3\u65b9\u6848\uff1a1\uff09\u5c06\u8bed\u4e49\u76f8\u5173\u6587\u6863\u805a\u7c7b\u5230\u591a\u6587\u6863\u9002\u914d\u5668\u4e2d\uff0c\u4f7f\u7528\u6587\u6863\u7279\u5b9a\u63a9\u7801\u5728\u51cf\u5c11\u5f00\u9500\u7684\u540c\u65f6\u4fdd\u6301\u7279\u5f02\u6027\uff1b2\uff09\u9009\u62e9\u6027\u9002\u914d\u5668\u805a\u5408\uff0c\u4ec5\u5408\u5e76\u76f8\u5173\u6027\u5bf9\u9f50\u4e14\u65e0\u51b2\u7a81\u7684\u9002\u914d\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFedMosaic\u5728\u56db\u4e2a\u7c7b\u522b\u4e2d\u5e73\u5747\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u51c6\u786e\u7387\u9ad810.9%\uff0c\u540c\u65f6\u5b58\u50a8\u6210\u672c\u964d\u4f4e78.8%\u523086.3%\uff0c\u901a\u4fe1\u6210\u672c\u964d\u4f4e91.4%\uff0c\u4e14\u4ece\u4e0d\u5171\u4eab\u539f\u59cb\u6587\u6863\u3002", "conclusion": "FedMosaic\u6210\u529f\u89e3\u51b3\u4e86\u8054\u90a6RAG\u4e2d\u7684\u5b58\u50a8\u3001\u901a\u4fe1\u548c\u805a\u5408\u51b2\u7a81\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u4e0b\u7684\u9ad8\u6548\u77e5\u8bc6\u68c0\u7d22\u589e\u5f3a\uff0c\u4e3a\u5206\u5e03\u5f0f\u9690\u79c1\u654f\u611f\u73af\u5883\u4e2d\u7684RAG\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05663", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05663", "abs": "https://arxiv.org/abs/2602.05663", "authors": ["Shiteng Cao", "Junda She", "Ji Liu", "Bin Zeng", "Chengcheng Guo", "Kuo Cai", "Qiang Luo", "Ruiming Tang", "Han Li", "Kun Gai", "Zhiheng Li", "Cheng Yang"], "title": "GLASS: A Generative Recommender for Long-sequence Modeling via SID-Tier and Semantic Search", "comment": "10 pages,3 figures", "summary": "Leveraging long-term user behavioral patterns is a key trajectory for enhancing the accuracy of modern recommender systems. While generative recommender systems have emerged as a transformative paradigm, they face hurdles in effectively modeling extensive historical sequences. To address this challenge, we propose GLASS, a novel framework that integrates long-term user interests into the generative process via SID-Tier and Semantic Search. We first introduce SID-Tier, a module that maps long-term interactions into a unified interest vector to enhance the prediction of the initial SID token. Unlike traditional retrieval models that struggle with massive item spaces, SID-Tier leverages the compact nature of the semantic codebook to incorporate cross features between the user's long-term history and candidate semantic codes. Furthermore, we present semantic hard search, which utilizes generated coarse-grained semantic ID as dynamic keys to extract relevant historical behaviors, which are then fused via an adaptive gated fusion module to recalibrate the trajectory of subsequent fine-grained tokens. To address the inherent data sparsity in semantic hard search, we propose two strategies: semantic neighbor augmentation and codebook resizing. Extensive experiments on two large-scale real-world datasets, TAOBAO-MM and KuaiRec, demonstrate that GLASS outperforms state-of-the-art baselines, achieving significant gains in recommendation quality. Our codes are made publicly available to facilitate further research in generative recommendation.", "AI": {"tldr": "GLASS\u662f\u4e00\u4e2a\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7SID-Tier\u6a21\u5757\u548c\u8bed\u4e49\u786c\u641c\u7d22\u5c06\u957f\u671f\u7528\u6237\u5174\u8da3\u6574\u5408\u5230\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5efa\u6a21\u957f\u5386\u53f2\u5e8f\u5217\u65f6\u7684\u6311\u6218\u3002", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u867d\u7136\u5177\u6709\u53d8\u9769\u6027\u6f5c\u529b\uff0c\u4f46\u5728\u6709\u6548\u5efa\u6a21\u957f\u5386\u53f2\u5e8f\u5217\u65b9\u9762\u9762\u4e34\u56f0\u96be\u3002\u4f20\u7edf\u68c0\u7d22\u6a21\u578b\u5728\u5927\u89c4\u6a21\u7269\u54c1\u7a7a\u95f4\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u5229\u7528\u957f\u671f\u7528\u6237\u884c\u4e3a\u6a21\u5f0f\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002", "method": "1. \u63d0\u51faSID-Tier\u6a21\u5757\uff0c\u5c06\u957f\u671f\u4ea4\u4e92\u6620\u5c04\u4e3a\u7edf\u4e00\u5174\u8da3\u5411\u91cf\u6765\u589e\u5f3a\u521d\u59cbSID\u4ee4\u724c\u9884\u6d4b\uff1b2. \u5f15\u5165\u8bed\u4e49\u786c\u641c\u7d22\uff0c\u4f7f\u7528\u751f\u6210\u7684\u7c97\u7c92\u5ea6\u8bed\u4e49ID\u4f5c\u4e3a\u52a8\u6001\u952e\u63d0\u53d6\u76f8\u5173\u5386\u53f2\u884c\u4e3a\uff1b3. \u901a\u8fc7\u81ea\u9002\u5e94\u95e8\u63a7\u878d\u5408\u6a21\u5757\u91cd\u65b0\u6821\u51c6\u540e\u7eed\u7ec6\u7c92\u5ea6\u4ee4\u724c\u8f68\u8ff9\uff1b4. \u9488\u5bf9\u8bed\u4e49\u786c\u641c\u7d22\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898\uff0c\u63d0\u51fa\u8bed\u4e49\u90bb\u5c45\u589e\u5f3a\u548c\u7801\u672c\u8c03\u6574\u7b56\u7565\u3002", "result": "\u5728TAOBAO-MM\u548cKuaiRec\u4e24\u4e2a\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGLASS\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u63a8\u8350\u8d28\u91cf\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "GLASS\u901a\u8fc7\u6709\u6548\u6574\u5408\u957f\u671f\u7528\u6237\u5174\u8da3\u5230\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u5728\u5efa\u6a21\u957f\u5386\u53f2\u5e8f\u5217\u65f6\u7684\u6311\u6218\uff0c\u4e3a\u751f\u6210\u5f0f\u63a8\u8350\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u548c\u516c\u5f00\u4ee3\u7801\u652f\u6301\u3002"}}
{"id": "2602.05252", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05252", "abs": "https://arxiv.org/abs/2602.05252", "authors": ["Guangwei Zhang", "Jianing Zhu", "Cheng Qian", "Neil Gong", "Rada Mihalcea", "Zhaozhuo Xu", "Jingrui He", "Jiaqi Ma", "Yun Huang", "Chaowei Xiao", "Bo Li", "Ahmed Abbasi", "Dongwon Lee", "Heng Ji", "Denghui Zhang"], "title": "Copyright Detective: A Forensic System to Evidence LLMs Flickering Copyright Leakage Risks", "comment": null, "summary": "We present Copyright Detective, the first interactive forensic system for detecting, analyzing, and visualizing potential copyright risks in LLM outputs. The system treats copyright infringement versus compliance as an evidence discovery process rather than a static classification task due to the complex nature of copyright law. It integrates multiple detection paradigms, including content recall testing, paraphrase-level similarity analysis, persuasive jailbreak probing, and unlearning verification, within a unified and extensible framework. Through interactive prompting, response collection, and iterative workflows, our system enables systematic auditing of verbatim memorization and paraphrase-level leakage, supporting responsible deployment and transparent evaluation of LLM copyright risks even with black-box access.", "AI": {"tldr": "Copyright Detective\u662f\u9996\u4e2a\u4ea4\u4e92\u5f0f\u53d6\u8bc1\u7cfb\u7edf\uff0c\u7528\u4e8e\u68c0\u6d4b\u3001\u5206\u6790\u548c\u53ef\u89c6\u5316LLM\u8f93\u51fa\u4e2d\u7684\u6f5c\u5728\u7248\u6743\u98ce\u9669\uff0c\u91c7\u7528\u591a\u8303\u5f0f\u68c0\u6d4b\u6846\u67b6\u800c\u975e\u9759\u6001\u5206\u7c7b\u3002", "motivation": "\u7531\u4e8e\u7248\u6743\u6cd5\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u5c06\u7248\u6743\u4fb5\u6743\u68c0\u6d4b\u89c6\u4e3a\u8bc1\u636e\u53d1\u73b0\u8fc7\u7a0b\u800c\u975e\u9759\u6001\u5206\u7c7b\u4efb\u52a1\uff0c\u4ee5\u652f\u6301LLM\u7684\u8d1f\u8d23\u4efb\u90e8\u7f72\u548c\u900f\u660e\u8bc4\u4f30\u3002", "method": "\u96c6\u6210\u591a\u79cd\u68c0\u6d4b\u8303\u5f0f\uff1a\u5185\u5bb9\u53ec\u56de\u6d4b\u8bd5\u3001\u91ca\u4e49\u7ea7\u76f8\u4f3c\u6027\u5206\u6790\u3001\u8bf4\u670d\u6027\u8d8a\u72f1\u63a2\u6d4b\u548c\u53bb\u5b66\u4e60\u9a8c\u8bc1\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u63d0\u793a\u3001\u54cd\u5e94\u6536\u96c6\u548c\u8fed\u4ee3\u5de5\u4f5c\u6d41\u7a0b\u5b9e\u73b0\u7cfb\u7edf\u5ba1\u8ba1\u3002", "result": "\u5f00\u53d1\u51fa\u9996\u4e2a\u4ea4\u4e92\u5f0f\u53d6\u8bc1\u7cfb\u7edf\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u5ba1\u8ba1\u9010\u5b57\u8bb0\u5fc6\u548c\u91ca\u4e49\u7ea7\u6cc4\u9732\uff0c\u5373\u4f7f\u5728\u9ed1\u76d2\u8bbf\u95ee\u6761\u4ef6\u4e0b\u4e5f\u80fd\u652f\u6301LLM\u7248\u6743\u98ce\u9669\u7684\u900f\u660e\u8bc4\u4f30\u3002", "conclusion": "Copyright Detective\u4e3aLLM\u7248\u6743\u98ce\u9669\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5c06\u7248\u6743\u4fb5\u6743\u89c6\u4e3a\u8bc1\u636e\u53d1\u73b0\u8fc7\u7a0b\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdbLLM\u7684\u8d1f\u8d23\u4efb\u90e8\u7f72\u3002"}}
{"id": "2602.05734", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05734", "abs": "https://arxiv.org/abs/2602.05734", "authors": ["Niall McCarroll", "Kevin Curran", "Eugene McNamee", "Angela Clist", "Andrew Brammer"], "title": "Evaluating the impact of word embeddings on similarity scoring in practical information retrieval", "comment": null, "summary": "Search behaviour is characterised using synonymy and polysemy as users often want to search information based on meaning. Semantic representation strategies represent a move towards richer associative connections that can adequately capture this complex usage of language. Vector Space Modelling (VSM) and neural word embeddings play a crucial role in modern machine learning and Natural Language Processing (NLP) pipelines. Embeddings use distributional semantics to represent words, sentences, paragraphs or entire documents as vectors in high dimensional spaces. This can be leveraged by Information Retrieval (IR) systems to exploit the semantic relatedness between queries and answers.\n  This paper evaluates an alternative approach to measuring query statement similarity that moves away from the common similarity measure of centroids of neural word embeddings. Motivated by the Word Movers Distance (WMD) model, similarity is evaluated using the distance between individual words of queries and statements. Results from ranked query and response statements demonstrate significant gains in accuracy using the combined approach of similarity ranking through WMD with the word embedding techniques. The top performing WMD + GloVe combination outperforms all other state-of-the-art retrieval models including Doc2Vec and the baseline LSA model. Along with the significant gains in performance of similarity ranking through WMD, we conclude that the use of pre-trained word embeddings, trained on vast amounts of data, result in domain agnostic language processing solutions that are portable to diverse business use-cases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eWord Mover's Distance\u7684\u67e5\u8be2\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u6cd5\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u606f\u68c0\u7d22\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u8bcd\u5411\u91cf\u8d28\u5fc3\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u6355\u6349\u67e5\u8be2\u7684\u8bed\u4e49\u590d\u6742\u6027\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u91c7\u7528Word Mover's Distance\u6a21\u578b\uff0c\u901a\u8fc7\u8ba1\u7b97\u67e5\u8be2\u4e0e\u56de\u7b54\u4e2d\u5404\u4e2a\u5355\u8bcd\u4e4b\u95f4\u7684\u8ddd\u79bb\u6765\u8bc4\u4f30\u76f8\u4f3c\u5ea6\uff0c\u5e76\u7ed3\u5408GloVe\u7b49\u9884\u8bad\u7ec3\u8bcd\u5d4c\u5165\u6280\u672f\u3002", "result": "WMD+GloVe\u7ec4\u5408\u5728\u67e5\u8be2\u548c\u56de\u7b54\u8bed\u53e5\u7684\u6392\u5e8f\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u663e\u8457\u4f18\u4e8eDoc2Vec\u548cLSA\u57fa\u7ebf\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u7387\u7684\u5927\u5e45\u63d0\u5347\u3002", "conclusion": "\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bcd\u5d4c\u5165\u548cWMD\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u65b9\u6cd5\u80fd\u591f\u6784\u5efa\u9886\u57df\u65e0\u5173\u7684\u8bed\u8a00\u5904\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u7684\u5546\u4e1a\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2602.05258", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.05258", "abs": "https://arxiv.org/abs/2602.05258", "authors": ["Haoran Li", "Sucheng Ren", "Alan Yuille", "Feng Wang"], "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs", "comment": null, "summary": "Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always prioritize semantically similar tokens. In this work, we unify these seemingly distinct objectives through a minimalist intervention, namely CoPE: soft clipping lowfrequency components of RoPE. CoPE not only eliminates OOD outliers and refines semantic signals, but also prevents spectral leakage caused by hard clipping. Extensive experiments demonstrate that simply applying our soft clipping strategy to RoPE yields significant performance gains that scale up to 256k context length, validating our theoretical analysis and establishing CoPE as a new state-of-the-art for length generalization. Our code, data, and models are available at https://github.com/hrlics/CoPE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCoPE\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f6f\u88c1\u526aRoPE\u7684\u4f4e\u9891\u5206\u91cf\u6765\u7edf\u4e00OOD\u7f13\u89e3\u548c\u8bed\u4e49\u5efa\u6a21\u4e24\u4e2a\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347LLM\u7684\u957f\u4e0a\u4e0b\u6587\u6269\u5c55\u80fd\u529b\u81f3256k\u3002", "motivation": "\u73b0\u6709\u7684RoPE\u6269\u5c55\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e24\u7c7b\uff1aOOD\u7f13\u89e3\uff08\u8c03\u6574\u9891\u7387\u4ee5\u9002\u5e94\u672a\u89c1\u4f4d\u7f6e\uff09\u548c\u8bed\u4e49\u5efa\u6a21\uff08\u786e\u4fdd\u6ce8\u610f\u529b\u5206\u6570\u4f18\u5148\u8bed\u4e49\u76f8\u4f3ctoken\uff09\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e24\u79cd\u770b\u4f3c\u4e0d\u540c\u7684\u76ee\u6807\u53ef\u4ee5\u901a\u8fc7\u7edf\u4e00\u7684\u5e72\u9884\u65b9\u6cd5\u6765\u89e3\u51b3\u3002", "method": "\u63d0\u51faCoPE\u65b9\u6cd5\uff0c\u5bf9RoPE\u7684\u4f4e\u9891\u5206\u91cf\u8fdb\u884c\u8f6f\u88c1\u526a\u3002\u8fd9\u79cd\u8f6f\u88c1\u526a\u7b56\u7565\u4e0d\u4ec5\u80fd\u6d88\u9664OOD\u5f02\u5e38\u503c\u3001\u7ec6\u5316\u8bed\u4e49\u4fe1\u53f7\uff0c\u8fd8\u80fd\u907f\u514d\u786c\u88c1\u526a\u5bfc\u81f4\u7684\u9891\u8c31\u6cc4\u6f0f\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9RoPE\u5e94\u7528\u8f6f\u88c1\u526a\u7b56\u7565\u80fd\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u80fd\u6269\u5c55\u5230256k\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u5e76\u786e\u7acb\u4e86CoPE\u5728\u957f\u5ea6\u6cdb\u5316\u4e0a\u7684SOTA\u5730\u4f4d\u3002", "conclusion": "CoPE\u901a\u8fc7\u7b80\u5355\u7684\u8f6f\u88c1\u526a\u5e72\u9884\uff0c\u7edf\u4e00\u4e86OOD\u7f13\u89e3\u548c\u8bed\u4e49\u5efa\u6a21\u4e24\u4e2a\u76ee\u6807\uff0c\u4e3aLLM\u7684\u957f\u4e0a\u4e0b\u6587\u6269\u5c55\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.05787", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05787", "abs": "https://arxiv.org/abs/2602.05787", "authors": ["Hengran Zhang", "Keping Bi", "Jiafeng Guo", "Jiaming Zhang", "Wenbo Yang", "Daiting Shi", "Xueqi Cheng"], "title": "Bagging-Based Model Merging for Robust General Text Embeddings", "comment": "12 pages, 4 figures", "summary": "General-purpose text embedding models underpin a wide range of NLP and information retrieval applications, and are typically trained on large-scale multi-task corpora to encourage broad generalization. However, it remains unclear how different multi-task training strategies compare in practice, and how to efficiently adapt embedding models as new domains and data types continually emerge. In this work, we present a systematic study of multi-task training for text embeddings from two perspectives: data scheduling and model merging. We compare batch-level shuffling, sequential training variants, two-stage training, and multiple merging granularities, and find that simple batch-level shuffling consistently yields the strongest overall performance, suggesting that task conflicts are limited and training datasets are largely complementary. Despite its effectiveness, batch-level shuffling exhibits two practical limitations: suboptimal out-of-domain (OOD) generalization and poor suitability for incremental learning due to expensive full retraining. To address these issues, we propose Bagging-based rObust mOdel Merging (\\modelname), which trains multiple embedding models on sampled subsets and merges them into a single model, improving robustness while retaining single-model inference efficiency. Moreover, \\modelname naturally supports efficient incremental updates by training lightweight update models on new data with a small historical subset and merging them into the existing model. Experiments across diverse embedding benchmarks demonstrate that \\modelname consistently improves both in-domain and OOD performance over full-corpus batch-level shuffling, while substantially reducing training cost in incremental learning settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u6bd4\u8f83\u4e86\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\uff0c\u53d1\u73b0\u6279\u7ea7\u6df7\u6d17\u6548\u679c\u6700\u597d\u4f46\u5b58\u5728\u9886\u57df\u5916\u6cdb\u5316\u4e0d\u8db3\u548c\u589e\u91cf\u5b66\u4e60\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eBagging\u7684\u6a21\u578b\u5408\u5e76\u65b9\u6cd5BOOM\u6765\u63d0\u5347\u9c81\u68d2\u6027\u548c\u652f\u6301\u9ad8\u6548\u589e\u91cf\u66f4\u65b0\u3002", "motivation": "\u5c3d\u7ba1\u901a\u7528\u6587\u672c\u5d4c\u5165\u6a21\u578b\u5e7f\u6cdb\u5e94\u7528\u4e8eNLP\u548c\u4fe1\u606f\u68c0\u7d22\uff0c\u4f46\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\u7684\u5b9e\u9645\u6548\u679c\u5bf9\u6bd4\u4e0d\u660e\u786e\uff0c\u4e14\u968f\u7740\u65b0\u9886\u57df\u548c\u6570\u636e\u7c7b\u578b\u7684\u4e0d\u65ad\u6d8c\u73b0\uff0c\u5982\u4f55\u9ad8\u6548\u9002\u5e94\u5d4c\u5165\u6a21\u578b\u4ecd\u5b58\u5728\u6311\u6218\u3002", "method": "\u4ece\u6570\u636e\u8c03\u5ea6\u548c\u6a21\u578b\u5408\u5e76\u4e24\u4e2a\u89d2\u5ea6\u7cfb\u7edf\u7814\u7a76\u591a\u4efb\u52a1\u8bad\u7ec3\uff1a\u6bd4\u8f83\u6279\u7ea7\u6df7\u6d17\u3001\u987a\u5e8f\u8bad\u7ec3\u53d8\u4f53\u3001\u4e24\u9636\u6bb5\u8bad\u7ec3\u548c\u591a\u79cd\u5408\u5e76\u7c92\u5ea6\u3002\u63d0\u51faBagging-based rObust mOdel Merging (BOOM)\uff0c\u901a\u8fc7\u8bad\u7ec3\u591a\u4e2a\u5b50\u96c6\u6a21\u578b\u5e76\u5408\u5e76\u6765\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u652f\u6301\u901a\u8fc7\u8bad\u7ec3\u8f7b\u91cf\u66f4\u65b0\u6a21\u578b\u6765\u5b9e\u73b0\u9ad8\u6548\u589e\u91cf\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6279\u7ea7\u6df7\u6d17\u5728\u6574\u4f53\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u597d\uff0c\u4f46\u5b58\u5728\u9886\u57df\u5916\u6cdb\u5316\u4e0d\u8db3\u548c\u589e\u91cf\u5b66\u4e60\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002BOOM\u65b9\u6cd5\u5728\u591a\u4e2a\u5d4c\u5165\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u5168\u8bed\u6599\u6279\u7ea7\u6df7\u6d17\uff0c\u6301\u7eed\u63d0\u5347\u4e86\u9886\u57df\u5185\u548c\u9886\u57df\u5916\u6027\u80fd\uff0c\u540c\u65f6\u5728\u589e\u91cf\u5b66\u4e60\u573a\u666f\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u6210\u672c\u3002", "conclusion": "\u867d\u7136\u6279\u7ea7\u6df7\u6d17\u662f\u6709\u6548\u7684\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\uff0c\u4f46BOOM\u901a\u8fc7\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u514b\u670d\u4e86\u5176\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u548c\u652f\u6301\u9ad8\u6548\u589e\u91cf\u66f4\u65b0\uff0c\u4e3a\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u6301\u7eed\u9002\u5e94\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05261", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05261", "abs": "https://arxiv.org/abs/2602.05261", "authors": ["Fanfan Liu", "Youyang Yin", "Peng Shi", "Siqi Yang", "Zhixiong Zeng", "Haibo Qiu"], "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR", "comment": null, "summary": "Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across different RLVR algorithms during the training process. To provide a fundamental explanation for these variations, this paper conducts an in-depth analysis of the components of mainstream RLVR algorithms. We present a theoretical analysis of the factors influencing response length and validate our theory through extensive experimentation. Building upon these theoretical findings, we propose the Length-Unbiased Sequence Policy Optimization (LUSPO) algorithm. Specifically, we rectify the length bias inherent in Group Sequence Policy Optimization (GSPO), rendering its loss function unbiased with respect to response length and thereby resolving the issue of response length collapse. We conduct extensive experiments across mathematical reasoning benchmarks and multimodal reasoning scenarios, where LUSPO consistently achieves superior performance. Empirical results demonstrate that LUSPO represents a novel, state-of-the-art optimization strategy compared to existing methods such as GRPO and GSPO.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86RLVR\u7b97\u6cd5\u4e2d\u54cd\u5e94\u957f\u5ea6\u53d8\u5316\u7684\u539f\u56e0\uff0c\u63d0\u51fa\u4e86\u6d88\u9664\u957f\u5ea6\u504f\u5dee\u7684LUSPO\u7b97\u6cd5\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86SOTA\u6027\u80fd\u3002", "motivation": "RLVR\u8bad\u7ec3\u4e2d\u54cd\u5e94\u957f\u5ea6\u7684\u589e\u52a0\u901a\u5e38\u88ab\u89c6\u4e3a\u63a8\u7406\u80fd\u529b\u63d0\u5347\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f46\u4e0d\u540cRLVR\u7b97\u6cd5\u7684\u54cd\u5e94\u957f\u5ea6\u53d8\u5316\u6a21\u5f0f\u5dee\u5f02\u5f88\u5927\uff0c\u9700\u8981\u4ece\u7406\u8bba\u4e0a\u89e3\u91ca\u8fd9\u4e9b\u5dee\u5f02\u5e76\u63d0\u4f9b\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "1. \u6df1\u5165\u5206\u6790\u4e3b\u6d41RLVR\u7b97\u6cd5\u7684\u7ec4\u6210\u6210\u5206\uff1b2. \u7406\u8bba\u5206\u6790\u5f71\u54cd\u54cd\u5e94\u957f\u5ea6\u7684\u56e0\u7d20\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff1b3. \u57fa\u4e8e\u7406\u8bba\u53d1\u73b0\u63d0\u51faLUSPO\u7b97\u6cd5\uff0c\u901a\u8fc7\u4fee\u6b63GSPO\u4e2d\u7684\u957f\u5ea6\u504f\u5dee\u4f7f\u5176\u635f\u5931\u51fd\u6570\u5bf9\u54cd\u5e94\u957f\u5ea6\u65e0\u504f\u3002", "result": "LUSPO\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u548c\u591a\u6a21\u6001\u63a8\u7406\u573a\u666f\u4e2d\u4e00\u81f4\u53d6\u5f97\u4f18\u8d8a\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u54cd\u5e94\u957f\u5ea6\u5d29\u6e83\u95ee\u9898\uff0c\u76f8\u6bd4GRPO\u548cGSPO\u7b49\u65b9\u6cd5\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\u3002", "conclusion": "LUSPO\u662f\u4e00\u79cd\u65b0\u9896\u7684\u3001\u6700\u5148\u8fdb\u7684\u4f18\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u6d88\u9664\u957f\u5ea6\u504f\u5dee\u89e3\u51b3\u4e86RLVR\u8bad\u7ec3\u4e2d\u7684\u54cd\u5e94\u957f\u5ea6\u95ee\u9898\uff0c\u4e3a\u589e\u5f3aLLM\u548cVLM\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2602.05945", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05945", "abs": "https://arxiv.org/abs/2602.05945", "authors": ["Zhouhang Xie", "Bo Peng", "Zhankui He", "Ziqi Chen", "Alice Han", "Isabella Ye", "Benjamin Coleman", "Noveen Sachdeva", "Fernando Pereira", "Julian McAuley", "Wang-Cheng Kang", "Derek Zhiyuan Cheng", "Beidou Wang", "Randolph Brown"], "title": "AgenticTagger: Structured Item Representation for Recommendation with LLM Agents", "comment": null, "summary": "High-quality representations are a core requirement for effective recommendation. In this work, we study the problem of LLM-based descriptor generation, i.e., keyphrase-like natural language item representation generation frameworks with minimal constraints on downstream applications. We propose AgenticTagger, a framework that queries LLMs for representing items with sequences of text descriptors. However, open-ended generation provides little control over the generation space, leading to high cardinality, low-performance descriptors that renders downstream modeling challenging. To this end, AgenticTagger features two core stages: (1) a vocabulary building stage where a set of hierarchical, low-cardinality, and high-quality descriptors is identified, and (2) a vocabulary assignment stage where LLMs assign in-vocabulary descriptors to items. To effectively and efficiently ground vocabulary in the item corpus of interest, we design a multi-agent reflection mechanism where an architect LLM iteratively refines the vocabulary guided by parallelized feedback from annotator LLMs that validates the vocabulary against item data. Experiments on public and private data show AgenticTagger brings consistent improvements across diverse recommendation scenarios, including generative and term-based retrieval, ranking, and controllability-oriented, critique-based recommendation.", "AI": {"tldr": "AgenticTagger\u662f\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u63cf\u8ff0\u7b26\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u8bcd\u6c47\u6784\u5efa\u548c\u5206\u914d\u4e24\u9636\u6bb5\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u4f4e\u57fa\u6570\u3001\u5c42\u6b21\u5316\u7684\u6587\u672c\u63cf\u8ff0\u7b26\u3002", "motivation": "\u9ad8\u8d28\u91cf\u7684\u8868\u793a\u5bf9\u63a8\u8350\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7684LLM\u63cf\u8ff0\u7b26\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u5f00\u653e\u6027\u95ee\u9898\uff1a\u751f\u6210\u7a7a\u95f4\u96be\u4ee5\u63a7\u5236\uff0c\u5bfc\u81f4\u63cf\u8ff0\u7b26\u57fa\u6570\u9ad8\u3001\u8d28\u91cf\u4f4e\uff0c\u96be\u4ee5\u652f\u6301\u4e0b\u6e38\u5efa\u6a21\u4efb\u52a1\u3002", "method": "\u63d0\u51faAgenticTagger\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u9636\u6bb5\uff1a1)\u8bcd\u6c47\u6784\u5efa\u9636\u6bb5\uff1a\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u53cd\u601d\u673a\u5236\uff0c\u8ba9\u67b6\u6784LLM\u6839\u636e\u6807\u6ce8LLM\u7684\u5e76\u884c\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\uff0c\u6784\u5efa\u5c42\u6b21\u5316\u3001\u4f4e\u57fa\u6570\u3001\u9ad8\u8d28\u91cf\u7684\u63cf\u8ff0\u7b26\u8bcd\u6c47\u8868\uff1b2)\u8bcd\u6c47\u5206\u914d\u9636\u6bb5\uff1a\u8ba9LLM\u5c06\u8bcd\u6c47\u8868\u4e2d\u7684\u63cf\u8ff0\u7b26\u5206\u914d\u7ed9\u5177\u4f53\u9879\u76ee\u3002", "result": "\u5728\u516c\u5f00\u548c\u79c1\u6709\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAgenticTagger\u5728\u591a\u79cd\u63a8\u8350\u573a\u666f\u4e2d\u5e26\u6765\u4e00\u81f4\u6539\u8fdb\uff0c\u5305\u62ec\u751f\u6210\u5f0f\u548c\u57fa\u4e8e\u672f\u8bed\u7684\u68c0\u7d22\u3001\u6392\u5e8f\uff0c\u4ee5\u53ca\u9762\u5411\u53ef\u63a7\u6027\u7684\u6279\u5224\u5f0f\u63a8\u8350\u3002", "conclusion": "AgenticTagger\u901a\u8fc7\u63a7\u5236\u751f\u6210\u7a7a\u95f4\u548c\u786e\u4fdd\u63cf\u8ff0\u7b26\u8d28\u91cf\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684LLM\u9a71\u52a8\u63cf\u8ff0\u7b26\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u5404\u79cd\u4e0b\u6e38\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.05289", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.05289", "abs": "https://arxiv.org/abs/2602.05289", "authors": ["Jingru Fan", "Dewen Liu", "Yufan Dang", "Huatao Li", "Yuheng Wang", "Wei Liu", "Feiyu Duan", "Xuanwen Ding", "Shu Yao", "Lin Wu", "Ruijie Shi", "Wai-Shing Leung", "Yuan Cheng", "Zhongyu Wei", "Cheng Yang", "Chen Qian", "Zhiyuan Liu", "Maosong Sun"], "title": "Towards a Science of Collective AI: LLM-based Multi-Agent Systems Need a Transition from Blind Trial-and-Error to Rigorous Science", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have greatly extended the capabilities of Multi-Agent Systems (MAS), demonstrating significant effectiveness across a wide range of complex and open-ended domains. However, despite this rapid progress, the field still relies heavily on empirical trial-and-error. It lacks a unified and principled scientific framework necessary for systematic optimization and improvement. This bottleneck stems from the ambiguity of attribution: first, the absence of a structured taxonomy of factors leaves researchers restricted to unguided adjustments; second, the lack of a unified metric fails to distinguish genuine collaboration gain from mere resource accumulation. In this paper, we advocate for a transition to design science through an integrated framework. We advocate to establish the collaboration gain metric ($\u0393$) as the scientific standard to isolate intrinsic gains from increased budgets. Leveraging $\u0393$, we propose a factor attribution paradigm to systematically identify collaboration-driving factors. To support this, we construct a systematic MAS factor library, structuring the design space into control-level presets and information-level dynamics. Ultimately, this framework facilitates the transition from blind experimentation to rigorous science, paving the way towards a true science of Collective AI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u4ece\u7ecf\u9a8c\u8bd5\u9519\u8f6c\u5411\u8bbe\u8ba1\u79d1\u5b66\uff0c\u901a\u8fc7\u5efa\u7acb\u534f\u4f5c\u589e\u76ca\u5ea6\u91cf\u0393\u548c\u7cfb\u7edf\u5316\u56e0\u5b50\u5e93\u6765\u5b9e\u73b0\u79d1\u5b66\u5316\u4f18\u5316\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u6781\u5927\u5730\u589e\u5f3a\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u4f46\u8be5\u9886\u57df\u4ecd\u4e25\u91cd\u4f9d\u8d56\u7ecf\u9a8c\u8bd5\u9519\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u79d1\u5b66\u6846\u67b6\u6765\u7cfb\u7edf\u5316\u4f18\u5316\u548c\u6539\u8fdb\u3002\u8fd9\u6e90\u4e8e\u5f52\u56e0\u6a21\u7cca\u6027\uff1a\u4e00\u662f\u7f3a\u4e4f\u7ed3\u6784\u5316\u56e0\u5b50\u5206\u7c7b\uff0c\u7814\u7a76\u4eba\u5458\u53ea\u80fd\u8fdb\u884c\u65e0\u6307\u5bfc\u8c03\u6574\uff1b\u4e8c\u662f\u7f3a\u4e4f\u7edf\u4e00\u5ea6\u91cf\uff0c\u65e0\u6cd5\u533a\u5206\u771f\u6b63\u7684\u534f\u4f5c\u589e\u76ca\u4e0e\u5355\u7eaf\u8d44\u6e90\u79ef\u7d2f\u3002", "method": "1. \u5efa\u7acb\u534f\u4f5c\u589e\u76ca\u5ea6\u91cf\u0393\u4f5c\u4e3a\u79d1\u5b66\u6807\u51c6\uff0c\u4ee5\u9694\u79bb\u5185\u5728\u589e\u76ca\u4e0e\u9884\u7b97\u589e\u52a0\u7684\u5f71\u54cd\uff1b2. \u63d0\u51fa\u56e0\u5b50\u5f52\u56e0\u8303\u5f0f\uff0c\u7cfb\u7edf\u8bc6\u522b\u9a71\u52a8\u534f\u4f5c\u7684\u56e0\u7d20\uff1b3. \u6784\u5efa\u7cfb\u7edf\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u56e0\u5b50\u5e93\uff0c\u5c06\u8bbe\u8ba1\u7a7a\u95f4\u7ed3\u6784\u5316\u5206\u4e3a\u63a7\u5236\u7ea7\u9884\u8bbe\u548c\u4fe1\u606f\u7ea7\u52a8\u6001\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u4f5c\u589e\u76ca\u5ea6\u91cf\u0393\u548c\u56e0\u5b50\u5f52\u56e0\u8303\u5f0f\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u79d1\u5b66\u57fa\u7840\uff0c\u5c06\u9886\u57df\u4ece\u76f2\u76ee\u5b9e\u9a8c\u8f6c\u5411\u4e25\u8c28\u79d1\u5b66\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u4ece\u7ecf\u9a8c\u8bd5\u9519\u5230\u8bbe\u8ba1\u79d1\u5b66\u7684\u8f6c\u578b\u8def\u5f84\uff0c\u4fc3\u8fdb\u4e86\u96c6\u4f53\u4eba\u5de5\u667a\u80fd\u771f\u6b63\u79d1\u5b66\u7684\u5f62\u6210\uff0c\u4e3a\u5b9e\u73b0\u7cfb\u7edf\u5316\u4f18\u5316\u548c\u6539\u8fdb\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.05975", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05975", "abs": "https://arxiv.org/abs/2602.05975", "authors": ["Tiansheng Hu", "Yilun Zhao", "Canyu Zhang", "Arman Cohan", "Chen Zhao"], "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents", "comment": "Submission to ACL ARR 2026 January", "summary": "Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000 paper retrieval corpus.We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e., ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faSAGE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u79d1\u5b66\u6587\u732e\u68c0\u7d22\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u7cfb\u7edf\u5728\u5904\u7406\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4f20\u7edfBM25\u68c0\u7d22\u5668\u4f18\u4e8eLLM\u68c0\u7d22\u5668\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u6587\u6863\u589e\u5f3a\u6846\u67b6\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u5904\u7406\u590d\u6742\u67e5\u8be2\u65b9\u9762\u7684\u80fd\u529b\u589e\u5f3a\uff0c\u4ee5\u53ca\u57fa\u4e8eLLM\u7684\u68c0\u7d22\u5668\u5728\u6307\u4ee4\u9075\u5faa\u548c\u63a8\u7406\u65b9\u9762\u5c55\u73b0\u5f3a\u5927\u80fd\u529b\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7a76LLM\u68c0\u7d22\u5668\u662f\u5426\u80fd\u5728\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u6709\u6548\u53d1\u6325\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u79d1\u5b66\u6587\u732e\u68c0\u7d22\u9886\u57df\u3002", "method": "1. \u6784\u5efaSAGE\u57fa\u51c6\u6d4b\u8bd5\uff1a\u5305\u542b1,200\u4e2a\u67e5\u8be2\uff0c\u8986\u76d6\u56db\u4e2a\u79d1\u5b66\u9886\u57df\uff0c\u68c0\u7d22\u8bed\u6599\u5e93\u5305\u542b20\u4e07\u7bc7\u8bba\u6587\uff1b2. \u8bc4\u4f30\u516d\u4e2a\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7cfb\u7edf\uff1b3. \u4ee5DR Tulu\u4e3a\u9aa8\u5e72\uff0c\u6bd4\u8f83BM25\u548cLLM\u68c0\u7d22\u5668\uff08ReasonIR\u548cgte-Qwen2-7B-instruct\uff09\u7684\u6027\u80fd\uff1b4. \u63d0\u51fa\u8bed\u6599\u5e93\u7ea7\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u4f7f\u7528LLM\u4e3a\u6587\u6863\u6dfb\u52a0\u5143\u6570\u636e\u548c\u5173\u952e\u8bcd\u589e\u5f3a\u3002", "result": "1. \u6240\u6709\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7cfb\u7edf\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff1b2. BM25\u68c0\u7d22\u5668\u663e\u8457\u4f18\u4e8eLLM\u68c0\u7d22\u5668\u7ea630%\uff0c\u56e0\u4e3a\u73b0\u6709\u4ee3\u7406\u751f\u6210\u7684\u5173\u952e\u8bcd\u5bfc\u5411\u5b50\u67e5\u8be2\u66f4\u9002\u5408BM25\uff1b3. \u63d0\u51fa\u7684\u6587\u6863\u589e\u5f3a\u6846\u67b6\u5728\u77ed\u5f62\u5f0f\u95ee\u9898\u4e0a\u5e26\u67658%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5f00\u653e\u5f0f\u95ee\u9898\u4e0a\u5e26\u67652%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u68c0\u7d22\u5668\u5728\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u7684\u8868\u73b0\u4e0d\u5982\u4f20\u7edfBM25\u68c0\u7d22\u5668\uff0c\u4e3b\u8981\u56e0\u4e3a\u4ee3\u7406\u751f\u6210\u7684\u5173\u952e\u8bcd\u5bfc\u5411\u67e5\u8be2\u6a21\u5f0f\u3002\u901a\u8fc7LLM\u589e\u5f3a\u6587\u6863\u5143\u6570\u636e\u53ef\u4ee5\u63d0\u5347\u68c0\u7d22\u6027\u80fd\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316LLM\u68c0\u7d22\u5668\u4e0e\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u534f\u540c\u5de5\u4f5c\u65b9\u5f0f\u3002"}}
{"id": "2602.05307", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05307", "abs": "https://arxiv.org/abs/2602.05307", "authors": ["Haojin Wang", "Yike Wang", "Shangbin Feng", "Hannaneh Hajishirzi", "Yulia Tsvetkov"], "title": "MentorCollab: Selective Large-to-Small Inference-Time Guidance for Efficient Reasoning", "comment": null, "summary": "Large reasoning models (LRMs) achieve strong performance by producing long chains of thought, but their inference costs are high and often generate redundant reasoning. Small language models (SLMs) are far more efficient, yet struggle on multi-step reasoning tasks. A natural idea is to let a large model guide a small one at inference time as a mentor, yet existing collaboration methods often promote imitation, resulting in verbose reasoning without consistent error correction. We propose MentorCollab, an inference-time collaboration method in which an LRM selectively and sparsely guides an SLM, rather than taking over generation. At randomly sampled token positions, we probe for divergences between the two models and use a lightweight verifier to decide whether the SLM should follow a short lookahead segment from its mentor or continue on its own. Across 15 SLM--LRM pairs and 3 domains (math reasoning, general knowledge, and commonsense reasoning), our method improves performance in 12 settings, with average gains of 3.0% and up to 8.0%, while adopting only having 18.4% tokens generated by the expensive mentor model on average. We find that short segments and selective probing are sufficient for effective collaboration. Our results show that selective inference-time guidance restores large-model reasoning ability without substantial inference overhead.", "AI": {"tldr": "MentorCollab\uff1a\u4e00\u79cd\u63a8\u7406\u65f6\u534f\u4f5c\u65b9\u6cd5\uff0c\u8ba9\u5927\u578b\u63a8\u7406\u6a21\u578b\u9009\u62e9\u6027\u3001\u7a00\u758f\u5730\u6307\u5bfc\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668\u51b3\u5b9a\u662f\u5426\u91c7\u7eb3\u5bfc\u5e08\u7684\u77ed\u524d\u77bb\u7247\u6bb5\uff0c\u5728\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u63a8\u7406\u6210\u672c\u9ad8\u4e14\u5e38\u4ea7\u751f\u5197\u4f59\u63a8\u7406\uff0c\u800c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u73b0\u6709\u534f\u4f5c\u65b9\u6cd5\u5f80\u5f80\u5bfc\u81f4\u6a21\u4eff\u6027\u5197\u957f\u63a8\u7406\uff0c\u7f3a\u4e4f\u4e00\u81f4\u7684\u9519\u8bef\u7ea0\u6b63\u3002", "method": "\u63d0\u51faMentorCollab\u65b9\u6cd5\uff1a\u5728\u968f\u673a\u91c7\u6837\u7684token\u4f4d\u7f6e\u63a2\u6d4b\u4e24\u4e2a\u6a21\u578b\u7684\u5206\u6b67\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668\u51b3\u5b9aSLM\u662f\u8ddf\u968f\u5bfc\u5e08\u6a21\u578b\u7684\u77ed\u524d\u77bb\u7247\u6bb5\u8fd8\u662f\u7ee7\u7eed\u81ea\u4e3b\u751f\u6210\uff0c\u5b9e\u73b0\u9009\u62e9\u6027\u3001\u7a00\u758f\u7684\u6307\u5bfc\u3002", "result": "\u572815\u4e2aSLM-LRM\u7ec4\u5408\u548c3\u4e2a\u9886\u57df\uff08\u6570\u5b66\u63a8\u7406\u3001\u901a\u7528\u77e5\u8bc6\u3001\u5e38\u8bc6\u63a8\u7406\uff09\u4e2d\uff0c12\u4e2a\u8bbe\u7f6e\u6027\u80fd\u63d0\u5347\uff0c\u5e73\u5747\u63d0\u53473.0%\uff0c\u6700\u9ad8\u8fbe8.0%\uff0c\u5e73\u5747\u53ea\u670918.4%\u7684token\u7531\u6602\u8d35\u5bfc\u5e08\u6a21\u578b\u751f\u6210\u3002", "conclusion": "\u77ed\u7247\u6bb5\u548c\u9009\u62e9\u6027\u63a2\u6d4b\u8db3\u4ee5\u5b9e\u73b0\u6709\u6548\u534f\u4f5c\uff0c\u9009\u62e9\u6027\u63a8\u7406\u65f6\u6307\u5bfc\u80fd\u6062\u590d\u5927\u578b\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u800c\u4e0d\u5e26\u6765\u663e\u8457\u7684\u63a8\u7406\u5f00\u9500\u3002"}}
{"id": "2602.05512", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.05512", "abs": "https://arxiv.org/abs/2602.05512", "authors": ["Larissa Pusch", "Alexandre Courtiol", "Tim Conrad"], "title": "A Human-in-the-Loop, LLM-Centered Architecture for Knowledge-Graph Question Answering", "comment": null, "summary": "Large Language Models (LLMs) excel at language understanding but remain limited in knowledge-intensive domains due to hallucinations, outdated information, and limited explainability. Text-based retrieval-augmented generation (RAG) helps ground model outputs in external sources but struggles with multi-hop reasoning. Knowledge Graphs (KGs), in contrast, support precise, explainable querying, yet require a knowledge of query languages. This work introduces an interactive framework in which LLMs generate and explain Cypher graph queries and users iteratively refine them through natural language. Applied to real-world KGs, the framework improves accessibility to complex datasets while preserving factual accuracy and semantic rigor and provides insight into how model performance varies across domains. Our core quantitative evaluation is a 90-query benchmark on a synthetic movie KG that measures query explanation quality and fault detection across multiple LLMs, complemented by two smaller real-life query-generation experiments on a Hyena KG and the MaRDI (Mathematical Research Data Initiative) KG.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u6846\u67b6\uff0c\u8ba9LLM\u751f\u6210\u548c\u89e3\u91caCypher\u56fe\u67e5\u8be2\uff0c\u7528\u6237\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8fed\u4ee3\u4f18\u5316\uff0c\u63d0\u9ad8\u77e5\u8bc6\u56fe\u8c31\u7684\u53ef\u8bbf\u95ee\u6027\u3002", "motivation": "LLM\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u5b58\u5728\u5e7b\u89c9\u3001\u4fe1\u606f\u8fc7\u65f6\u548c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u95ee\u9898\uff0c\u57fa\u4e8e\u6587\u672c\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5728\u590d\u6742\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u77e5\u8bc6\u56fe\u8c31\u867d\u7136\u652f\u6301\u7cbe\u786e\u67e5\u8be2\u4f46\u9700\u8981\u4e13\u95e8\u7684\u67e5\u8be2\u8bed\u8a00\u77e5\u8bc6\u3002", "method": "\u8bbe\u8ba1\u4ea4\u4e92\u5f0f\u6846\u67b6\uff0cLLM\u751f\u6210\u548c\u89e3\u91caCypher\u56fe\u67e5\u8be2\uff0c\u7528\u6237\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u67e5\u8be2\uff0c\u5728\u5408\u6210\u7535\u5f71KG\u548c\u771f\u5b9eKG\uff08Hyena\u548cMaRDI\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u6846\u67b6\u63d0\u9ad8\u4e86\u590d\u6742\u6570\u636e\u96c6\u7684\u8bbf\u95ee\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8bed\u4e49\u4e25\u8c28\u6027\uff0c\u901a\u8fc790\u4e2a\u67e5\u8be2\u7684\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e86\u4e0d\u540cLLM\u7684\u67e5\u8be2\u89e3\u91ca\u8d28\u91cf\u548c\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "\u4ea4\u4e92\u5f0fLLM-KG\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u4e3a\u4e0d\u540c\u9886\u57df\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u89e3\u51b3\u4e86LLM\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.05347", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05347", "abs": "https://arxiv.org/abs/2602.05347", "authors": ["Soma Sato", "Ryohei Sasano"], "title": "How Do Language Models Acquire Character-Level Information?", "comment": "Accepted to EACL 2026 Main Conference", "summary": "Language models (LMs) have been reported to implicitly encode character-level information, despite not being explicitly provided during training. However, the mechanisms underlying this phenomenon remain largely unexplored. To reveal the mechanisms, we analyze how models acquire character-level knowledge by comparing LMs trained under controlled settings, such as specifying the pre-training dataset or tokenizer, with those trained under standard settings. We categorize the contributing factors into those independent of tokenization. Our analysis reveals that merge rules and orthographic constraints constitute primary factors arising from tokenization, whereas semantic associations of substrings and syntactic information function as key factors independent of tokenization.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u9690\u5f0f\u7f16\u7801\u5b57\u7b26\u7ea7\u4fe1\u606f\uff0c\u7814\u7a76\u901a\u8fc7\u5bf9\u6bd4\u63a7\u5236\u5b9e\u9a8c\u63ed\u793a\u4e86\u8fd9\u4e00\u73b0\u8c61\u7684\u673a\u5236\uff0c\u53d1\u73b0\u5206\u8bcd\u76f8\u5173\u7684\u5408\u5e76\u89c4\u5219\u548c\u6b63\u5b57\u6cd5\u7ea6\u675f\uff0c\u4ee5\u53ca\u72ec\u7acb\u4e8e\u5206\u8bcd\u7684\u5b57\u4e32\u8bed\u4e49\u5173\u8054\u548c\u53e5\u6cd5\u4fe1\u606f\u662f\u4e3b\u8981\u56e0\u7d20\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u6ca1\u6709\u663e\u5f0f\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u88ab\u62a5\u544a\u80fd\u591f\u9690\u5f0f\u7f16\u7801\u5b57\u7b26\u7ea7\u4fe1\u606f\uff0c\u4f46\u8fd9\u79cd\u73b0\u8c61\u80cc\u540e\u7684\u673a\u5236\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u5728\u63a7\u5236\u8bbe\u7f6e\u4e0b\uff08\u5982\u6307\u5b9a\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u6216\u5206\u8bcd\u5668\uff09\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u4e0e\u6807\u51c6\u8bbe\u7f6e\u4e0b\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5206\u6790\u6a21\u578b\u5982\u4f55\u83b7\u53d6\u5b57\u7b26\u7ea7\u77e5\u8bc6\uff0c\u5e76\u5c06\u5f71\u54cd\u56e0\u7d20\u5206\u4e3a\u4e0e\u5206\u8bcd\u76f8\u5173\u548c\u72ec\u7acb\u4e8e\u5206\u8bcd\u4e24\u7c7b\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u5408\u5e76\u89c4\u5219\u548c\u6b63\u5b57\u6cd5\u7ea6\u675f\u662f\u5206\u8bcd\u76f8\u5173\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u800c\u5b57\u4e32\u7684\u8bed\u4e49\u5173\u8054\u548c\u53e5\u6cd5\u4fe1\u606f\u5219\u662f\u72ec\u7acb\u4e8e\u5206\u8bcd\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u9690\u5f0f\u7f16\u7801\u5b57\u7b26\u7ea7\u4fe1\u606f\u7684\u673a\u5236\u53ef\u4ee5\u901a\u8fc7\u5206\u8bcd\u76f8\u5173\u56e0\u7d20\u548c\u72ec\u7acb\u4e8e\u5206\u8bcd\u7684\u56e0\u7d20\u6765\u89e3\u91ca\uff0c\u8fd9\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5728\u8868\u5f81\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.05370", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05370", "abs": "https://arxiv.org/abs/2602.05370", "authors": ["Jun Rao", "Zixiong Yu", "Xuebo Liu", "Guhan Chen", "Jing Li", "Jiansheng Wei", "Xiaojun Meng", "Min Zhang"], "title": "PACE: Defying the Scaling Hypothesis of Exploration in Iterative Alignment for Mathematical Reasoning", "comment": null, "summary": "Iterative Direct Preference Optimization has emerged as the state-of-the-art paradigm for aligning Large Language Models on reasoning tasks. Standard implementations (DPO-R1) rely on Best-of-N sampling (e.g., $N \\ge 8$) to mine golden trajectories from the distribution tail. In this paper, we challenge this scaling hypothesis and reveal a counter-intuitive phenomenon: in mathematical reasoning, aggressive exploration yields diminishing returns and even catastrophic policy collapse. We theoretically demonstrate that scaling $N$ amplifies verifier noise and induces detrimental distribution shifts. To resolve this, we introduce \\textbf{PACE} (Proximal Alignment via Corrective Exploration), which replaces brute-force mining with a generation-based corrective strategy. Operating with a minimal budget ($2<N<3$), PACE synthesizes high-fidelity preference pairs from failed explorations. Empirical evaluations show that PACE outperforms DPO-R1 $(N=16)$ while using only about $1/5$ of the compute, demonstrating superior robustness against reward hacking and label noise.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPACE\u65b9\u6cd5\uff0c\u7528\u751f\u6210\u5f0f\u6821\u6b63\u7b56\u7565\u66ff\u4ee3\u66b4\u529b\u91c7\u6837\uff0c\u4ee5\u66f4\u5c11\u8ba1\u7b97\u91cf\u5b9e\u73b0\u66f4\u597d\u7684\u6570\u5b66\u63a8\u7406\u5bf9\u9f50\u6548\u679c\u3002", "motivation": "\u5f53\u524dDPO-R1\u65b9\u6cd5\u4f9d\u8d56\u5927\u89c4\u6a21\u91c7\u6837\uff08N\u22658\uff09\u4ece\u5206\u5e03\u5c3e\u90e8\u6316\u6398\u9ec4\u91d1\u8f68\u8ff9\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u6269\u5c55\u5047\u8bbe\u5b58\u5728\u95ee\u9898\uff1a\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u8fc7\u5ea6\u63a2\u7d22\u4f1a\u5bfc\u81f4\u6536\u76ca\u9012\u51cf\u751a\u81f3\u7b56\u7565\u5d29\u6e83\u3002", "method": "\u63d0\u51faPACE\uff08Proximal Alignment via Corrective Exploration\uff09\u65b9\u6cd5\uff0c\u7528\u751f\u6210\u5f0f\u6821\u6b63\u7b56\u7565\u66ff\u4ee3\u66b4\u529b\u91c7\u6837\u3002\u8be5\u65b9\u6cd5\u4ec5\u9700\u6781\u5c0f\u9884\u7b97\uff082<N<3\uff09\uff0c\u4ece\u5931\u8d25\u7684\u63a2\u7d22\u4e2d\u5408\u6210\u9ad8\u8d28\u91cf\u504f\u597d\u5bf9\u3002", "result": "PACE\u5728\u6027\u80fd\u4e0a\u8d85\u8d8aDPO-R1\uff08N=16\uff09\uff0c\u540c\u65f6\u4ec5\u4f7f\u7528\u7ea61/5\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u5e76\u4e14\u5bf9\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u548c\u6807\u7b7e\u566a\u58f0\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "PACE\u65b9\u6cd5\u6311\u6218\u4e86\u73b0\u6709\u7684\u5927\u89c4\u6a21\u91c7\u6837\u8303\u5f0f\uff0c\u8bc1\u660e\u5728\u6570\u5b66\u63a8\u7406\u5bf9\u9f50\u4e2d\uff0c\u66f4\u667a\u80fd\u7684\u6821\u6b63\u7b56\u7565\u6bd4\u66b4\u529b\u6269\u5c55\u91c7\u6837\u66f4\u6709\u6548\uff0c\u4e3aLLM\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u7684\u9ad8\u6548\u8303\u5f0f\u3002"}}
{"id": "2602.05374", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.05374", "abs": "https://arxiv.org/abs/2602.05374", "authors": ["Chaimae Abouzahir", "Congbo Ma", "Nizar Habash", "Farah E. Shamout"], "title": "Cross-Lingual Empirical Evaluation of Large Language Models for Arabic Medical Tasks", "comment": "Accepted to HeaLing-EACL 2026", "summary": "In recent years, Large Language Models (LLMs) have become widely used in medical applications, such as clinical decision support, medical education, and medical question answering. Yet, these models are often English-centric, limiting their robustness and reliability for linguistically diverse communities. Recent work has highlighted discrepancies in performance in low-resource languages for various medical tasks, but the underlying causes remain poorly understood. In this study, we conduct a cross-lingual empirical analysis of LLM performance on Arabic and English medical question and answering. Our findings reveal a persistent language-driven performance gap that intensifies with increasing task complexity. Tokenization analysis exposes structural fragmentation in Arabic medical text, while reliability analysis suggests that model-reported confidence and explanations exhibit limited correlation with correctness. Together, these findings underscore the need for language-aware design and evaluation strategies in LLMs for medical tasks.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u963f\u62c9\u4f2f\u8bed\u548c\u82f1\u8bed\u533b\u5b66\u95ee\u7b54\u7684\u8de8\u8bed\u8a00\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0LLMs\u5b58\u5728\u6301\u7eed\u7684\u8bed\u8a00\u9a71\u52a8\u6027\u80fd\u5dee\u8ddd\uff0c\u4e14\u968f\u7740\u4efb\u52a1\u590d\u6742\u6027\u589e\u52a0\u800c\u52a0\u5267\u3002", "motivation": "\u5f53\u524dLLMs\u5728\u533b\u5b66\u5e94\u7528\u4e2d\u666e\u904d\u5b58\u5728\u82f1\u8bed\u4e2d\u5fc3\u4e3b\u4e49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u8bed\u8a00\u591a\u6837\u5316\u793e\u533a\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u6307\u51faLLMs\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u533b\u5b66\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u4f46\u6839\u672c\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5bf9\u963f\u62c9\u4f2f\u8bed\u548c\u82f1\u8bed\u533b\u5b66\u95ee\u7b54\u8fdb\u884c\u8de8\u8bed\u8a00\u5b9e\u8bc1\u5206\u6790\uff0c\u5305\u62ec\u6027\u80fd\u5dee\u8ddd\u8bc4\u4f30\u3001\u6807\u8bb0\u5316\u5206\u6790\uff08\u63ed\u793a\u963f\u62c9\u4f2f\u8bed\u533b\u5b66\u6587\u672c\u7684\u7ed3\u6784\u788e\u7247\u5316\uff09\u4ee5\u53ca\u53ef\u9760\u6027\u5206\u6790\uff08\u68c0\u67e5\u6a21\u578b\u62a5\u544a\u7f6e\u4fe1\u5ea6\u4e0e\u89e3\u91ca\u548c\u6b63\u786e\u6027\u7684\u76f8\u5173\u6027\uff09\u3002", "result": "\u53d1\u73b0\u6301\u7eed\u5b58\u5728\u7684\u8bed\u8a00\u9a71\u52a8\u6027\u80fd\u5dee\u8ddd\uff0c\u4e14\u968f\u7740\u4efb\u52a1\u590d\u6742\u6027\u589e\u52a0\u800c\u52a0\u5267\uff1b\u963f\u62c9\u4f2f\u8bed\u533b\u5b66\u6587\u672c\u5b58\u5728\u7ed3\u6784\u788e\u7247\u5316\u95ee\u9898\uff1b\u6a21\u578b\u62a5\u544a\u7684\u7f6e\u4fe1\u5ea6\u548c\u89e3\u91ca\u4e0e\u6b63\u786e\u6027\u76f8\u5173\u6027\u6709\u9650\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u5728\u533b\u5b66\u4efb\u52a1\u4e2d\u9700\u8981\u8bed\u8a00\u611f\u77e5\u7684LLM\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7b56\u7565\uff0c\u4ee5\u89e3\u51b3\u8de8\u8bed\u8a00\u6027\u80fd\u5dee\u8ddd\u95ee\u9898\u3002"}}
{"id": "2602.05385", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05385", "abs": "https://arxiv.org/abs/2602.05385", "authors": ["Tao Liu", "Jiafan Lu", "Bohan Yu", "Pengcheng Wu", "Liu Haixin", "Guoyu Xu", "Li Xiangheng", "Lixiao Li", "Jiaming Hou", "Zhao Shijun", "Xinglin Lyu", "Kunli Zhang", "Yuxiang Jia", "Hongyin Zan"], "title": "IESR:Efficient MCTS-Based Modular Reasoning for Text-to-SQL with Large Language Models", "comment": "25 pages, 16 figures, 8 tables. Hongyin Zan is corresponding author, Jiafan Lu is first co-author", "summary": "Text-to-SQL is a key natural language processing task that maps natural language questions to SQL queries, enabling intuitive interaction with web-based databases. Although current methods perform well on benchmarks like BIRD and Spider, they struggle with complex reasoning, domain knowledge, and hypothetical queries, and remain costly in enterprise deployment. To address these issues, we propose a framework named IESR(Information Enhanced Structured Reasoning) for lightweight large language models: (i) leverages LLMs for key information understanding and schema linking, and decoupling mathematical computation and SQL generation, (ii) integrates a multi-path reasoning mechanism based on Monte Carlo Tree Search (MCTS) with majority voting, and (iii) introduces a trajectory consistency verification module with a discriminator model to ensure accuracy and consistency. Experimental results demonstrate that IESR achieves state-of-the-art performance on the complex reasoning benchmark LogicCat (24.28 EX) and the Archer dataset (37.28 EX) using only compact lightweight models without fine-tuning. Furthermore, our analysis reveals that current coder models exhibit notable biases and deficiencies in physical knowledge, mathematical computation, and common-sense reasoning, highlighting important directions for future research. We released code at https://github.com/Ffunkytao/IESR-SLM.", "AI": {"tldr": "IESR\u6846\u67b6\u901a\u8fc7\u4fe1\u606f\u589e\u5f3a\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u57fa\u51c6\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\uff0c\u65e0\u9700\u5fae\u8c03\u3002", "motivation": "\u5f53\u524dText-to-SQL\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u3001\u9886\u57df\u77e5\u8bc6\u548c\u5047\u8bbe\u6027\u67e5\u8be2\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u4f01\u4e1a\u90e8\u7f72\u6210\u672c\u9ad8\u6602\u3002", "method": "\u63d0\u51faIESR\u6846\u67b6\uff1a(1)\u5229\u7528LLM\u8fdb\u884c\u5173\u952e\u4fe1\u606f\u7406\u89e3\u548c\u6a21\u5f0f\u94fe\u63a5\uff0c\u89e3\u8026\u6570\u5b66\u8ba1\u7b97\u4e0eSQL\u751f\u6210\uff1b(2)\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u591a\u8def\u5f84\u63a8\u7406\u673a\u5236\u4e0e\u591a\u6570\u6295\u7968\uff1b(3)\u5f15\u5165\u8f68\u8ff9\u4e00\u81f4\u6027\u9a8c\u8bc1\u6a21\u5757\u786e\u4fdd\u51c6\u786e\u6027\u3002", "result": "\u5728\u590d\u6742\u63a8\u7406\u57fa\u51c6LogicCat\u4e0a\u8fbe\u523024.28 EX\uff0cArcher\u6570\u636e\u96c6\u4e0a\u8fbe\u523037.28 EX\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6a21\u578b\u65e0\u9700\u5fae\u8c03\u5373\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "conclusion": "IESR\u6709\u6548\u89e3\u51b3\u4e86Text-to-SQL\u4e2d\u7684\u590d\u6742\u63a8\u7406\u95ee\u9898\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5f53\u524d\u7f16\u7801\u5668\u6a21\u578b\u5728\u7269\u7406\u77e5\u8bc6\u3001\u6570\u5b66\u8ba1\u7b97\u548c\u5e38\u8bc6\u63a8\u7406\u65b9\u9762\u7684\u504f\u89c1\u4e0e\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.05392", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05392", "abs": "https://arxiv.org/abs/2602.05392", "authors": ["Jiyun Chun", "Eric Fosler-Lussier", "Michael White", "Andrew Perrault"], "title": "Beyond Length: Context-Aware Expansion and Independence as Developmentally Sensitive Evaluation in Child Utterances", "comment": null, "summary": "Evaluating the quality of children's utterances in adult-child dialogue remains challenging due to insufficient context-sensitive metrics. Common proxies such as Mean Length of Utterance (MLU), lexical diversity (vocd-D), and readability indices (Flesch-Kincaid Grade Level, Gunning Fog Index) are dominated by length and ignore conversational context, missing aspects of response quality such as reasoning depth, topic maintenance, and discourse planning. We introduce an LLM-as-a-judge framework that first classifies the Previous Adult Utterance Type and then scores the child's response along two axes: Expansion (contextual elaboration and inferential depth) and Independence (the child's contribution to advancing the discourse). These axes reflect fundamental dimensions in child language development, where Expansion captures elaboration, clause combining, and causal and contrastive connectives. Independence captures initiative, topic control, decreasing reliance on adult scaffolding through growing self-regulation, and audience design. We establish developmental validity by showing age-related patterns and demonstrate predictive value by improving age estimation over common baselines. We further confirm semantic sensitivity by detecting differences tied to discourse relations. Our metrics align with human judgments, enabling large-scale evaluation. This shifts child utterance assessment from simply measuring length to evaluating how meaningfully the child's speech contributes to and advances the conversation within its context.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u513f\u7ae5\u8bdd\u8bed\u8d28\u91cf\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u7c7b\u6210\u4eba\u524d\u5e8f\u8bdd\u8bed\u7c7b\u578b\u5e76\u6cbf\u6269\u5c55\u6027\u548c\u72ec\u7acb\u6027\u4e24\u4e2a\u7ef4\u5ea6\u8bc4\u5206\uff0c\u8d85\u8d8a\u4f20\u7edf\u57fa\u4e8e\u957f\u5ea6\u7684\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u513f\u7ae5\u8bdd\u8bed\u8d28\u91cf\u8bc4\u4f30\u9762\u4e34\u6311\u6218\uff0c\u5e38\u7528\u4ee3\u7406\u6307\u6807\u5982\u5e73\u5747\u8bdd\u8bed\u957f\u5ea6\u3001\u8bcd\u6c47\u591a\u6837\u6027\u548c\u53ef\u8bfb\u6027\u6307\u6570\u4e3b\u8981\u5173\u6ce8\u957f\u5ea6\u800c\u5ffd\u7565\u5bf9\u8bdd\u8bed\u5883\uff0c\u65e0\u6cd5\u6355\u6349\u63a8\u7406\u6df1\u5ea6\u3001\u8bdd\u9898\u7ef4\u6301\u548c\u8bdd\u8bed\u89c4\u5212\u7b49\u8d28\u91cf\u65b9\u9762\u3002", "method": "\u5f15\u5165LLM-as-a-judge\u6846\u67b6\uff0c\u9996\u5148\u5206\u7c7b\u6210\u4eba\u524d\u5e8f\u8bdd\u8bed\u7c7b\u578b\uff0c\u7136\u540e\u6cbf\u4e24\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u513f\u7ae5\u56de\u5e94\uff1a\u6269\u5c55\u6027\uff08\u8bed\u5883\u9610\u8ff0\u548c\u63a8\u7406\u6df1\u5ea6\uff09\u548c\u72ec\u7acb\u6027\uff08\u513f\u7ae5\u5bf9\u63a8\u8fdb\u8bdd\u8bed\u7684\u8d21\u732e\uff09\u3002", "result": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u4e0e\u5e74\u9f84\u76f8\u5173\u7684\u53d1\u5c55\u6a21\u5f0f\uff0c\u5728\u5e74\u9f84\u4f30\u8ba1\u4e0a\u4f18\u4e8e\u5e38\u89c1\u57fa\u7ebf\uff0c\u80fd\u68c0\u6d4b\u4e0e\u8bdd\u8bed\u5173\u7cfb\u76f8\u5173\u7684\u8bed\u4e49\u5dee\u5f02\uff0c\u4e14\u4e0e\u4eba\u7c7b\u5224\u65ad\u4e00\u81f4\uff0c\u652f\u6301\u5927\u89c4\u6a21\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u513f\u7ae5\u8bdd\u8bed\u8bc4\u4f30\u4ece\u7b80\u5355\u7684\u957f\u5ea6\u6d4b\u91cf\u8f6c\u5411\u8bc4\u4f30\u513f\u7ae5\u8a00\u8bed\u5982\u4f55\u5728\u7279\u5b9a\u8bed\u5883\u4e2d\u6709\u610f\u4e49\u5730\u8d21\u732e\u548c\u63a8\u8fdb\u5bf9\u8bdd\uff0c\u4e3a\u513f\u7ae5\u8bed\u8a00\u53d1\u5c55\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2602.05393", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.05393", "abs": "https://arxiv.org/abs/2602.05393", "authors": ["Ji Zhao", "Yufei Gu", "Shitong Shao", "Xun Zhou", "Liang Xiang", "Zeke Xie"], "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better", "comment": null, "summary": "As Large Language Models (LLMs) achieve remarkable empirical success through scaling model and data size, pretraining has become increasingly critical yet computationally prohibitive, hindering rapid development. Despite the availability of numerous pretrained LLMs developed at significant computational expense, a fundamental real-world question remains underexplored: \\textit{Can we leverage existing small pretrained models to accelerate the training of larger models?} In this paper, we propose a Late-to-Early Training (LET) paradigm that enables LLMs to explicitly learn later knowledge in earlier steps and earlier layers. The core idea is to guide the early layers of an LLM during early training using representations from the late layers of a pretrained (i.e. late training phase) model. We identify two key mechanisms that drive LET's effectiveness: late-to-early-step learning and late-to-early-layer learning. These mechanisms significantly accelerate training convergence while robustly enhancing both language modeling capabilities and downstream task performance, enabling faster training with superior performance. Extensive experiments on 1.4B and 7B parameter models demonstrate LET's efficiency and effectiveness. Notably, when training a 1.4B LLM on the Pile dataset, our method achieves up to 1.6$\\times$ speedup with nearly 5\\% improvement in downstream task accuracy compared to standard training, even when using a pretrained model with 10$\\times$ fewer parameters than the target model.", "AI": {"tldr": "LET\uff08Late-to-Early Training\uff09\u662f\u4e00\u79cd\u5229\u7528\u5c0f\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u52a0\u901f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u8ba9\u65e9\u671f\u5c42\u5b66\u4e60\u665a\u671f\u5c42\u77e5\u8bc6\uff0c\u5b9e\u73b01.6\u500d\u52a0\u901f\u548c5%\u7684\u4e0b\u6e38\u4efb\u52a1\u7cbe\u5ea6\u63d0\u5347\u3002", "motivation": "\u968f\u7740LLM\u89c4\u6a21\u4e0d\u65ad\u6269\u5927\uff0c\u9884\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u6025\u5267\u589e\u52a0\uff0c\u963b\u788d\u4e86\u5feb\u901f\u53d1\u5c55\u3002\u867d\u7136\u5df2\u6709\u8bb8\u591a\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u4f46\u5982\u4f55\u5229\u7528\u73b0\u6709\u5c0f\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u52a0\u901f\u5927\u578b\u6a21\u578b\u8bad\u7ec3\u7684\u95ee\u9898\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faLate-to-Early Training\uff08LET\uff09\u8303\u5f0f\uff0c\u6838\u5fc3\u601d\u60f3\u662f\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u5904\u4e8e\u665a\u671f\u8bad\u7ec3\u9636\u6bb5\uff09\u7684\u665a\u671f\u5c42\u8868\u793a\u6765\u6307\u5bfc\u76ee\u6807\u6a21\u578b\u65e9\u671f\u8bad\u7ec3\u9636\u6bb5\u7684\u65e9\u671f\u5c42\u3002\u5305\u542b\u4e24\u4e2a\u5173\u952e\u673a\u5236\uff1a\u665a\u671f\u5230\u65e9\u671f\u6b65\u957f\u5b66\u4e60\u548c\u665a\u671f\u5230\u65e9\u671f\u5c42\u5b66\u4e60\u3002", "result": "\u57281.4B\u548c7B\u53c2\u6570\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLET\u80fd\u663e\u8457\u52a0\u901f\u8bad\u7ec3\u6536\u655b\uff0c\u63d0\u5347\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002\u8bad\u7ec31.4B LLM\u65f6\uff0c\u76f8\u6bd4\u6807\u51c6\u8bad\u7ec3\u83b7\u5f971.6\u500d\u52a0\u901f\uff0c\u4e0b\u6e38\u4efb\u52a1\u7cbe\u5ea6\u63d0\u5347\u8fd15%\uff0c\u5373\u4f7f\u4f7f\u7528\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u4ec5\u4e3a\u76ee\u6807\u6a21\u578b\u76841/10\u3002", "conclusion": "LET\u8303\u5f0f\u4e3a\u9ad8\u6548\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u901a\u8fc7\u5229\u7528\u73b0\u6709\u5c0f\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u77e5\u8bc6\u8f6c\u79fb\uff0c\u5b9e\u73b0\u4e86\u8bad\u7ec3\u52a0\u901f\u548c\u6027\u80fd\u63d0\u5347\u7684\u53cc\u91cd\u6548\u76ca\u3002"}}
{"id": "2602.05400", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05400", "abs": "https://arxiv.org/abs/2602.05400", "authors": ["Shaobo Wang", "Xuan Ouyang", "Tianyi Xu", "Yuzheng Hu", "Jialin Liu", "Guo Chen", "Tianyu Zhang", "Junhao Zheng", "Kexin Yang", "Xingzhang Ren", "Dayiheng Liu", "Linfeng Zhang"], "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration", "comment": "45 pages, 7 figures, 8 tables", "summary": "As high-quality public text approaches exhaustion, a phenomenon known as the Data Wall, pre-training is shifting from more tokens to better tokens. However, existing methods either rely on heuristic static filters that ignore training dynamics, or use dynamic yet optimizer-agnostic criteria based on raw gradients. We propose OPUS (Optimizer-induced Projected Utility Selection), a dynamic data selection framework that defines utility in the optimizer-induced update space. OPUS scores candidates by projecting their effective updates, shaped by modern optimizers, onto a target direction derived from a stable, in-distribution proxy. To ensure scalability, we employ Ghost technique with CountSketch for computational efficiency, and Boltzmann sampling for data diversity, incurring only 4.7\\% additional compute overhead. OPUS achieves remarkable results across diverse corpora, quality tiers, optimizers, and model scales. In pre-training of GPT-2 Large/XL on FineWeb and FineWeb-Edu with 30B tokens, OPUS outperforms industrial-level baselines and even full 200B-token training. Moreover, when combined with industrial-level static filters, OPUS further improves pre-training efficiency, even with lower-quality data. Furthermore, in continued pre-training of Qwen3-8B-Base on SciencePedia, OPUS achieves superior performance using only 0.5B tokens compared to full training with 3B tokens, demonstrating significant data efficiency gains in specialized domains.", "AI": {"tldr": "OPUS\u662f\u4e00\u79cd\u52a8\u6001\u6570\u636e\u9009\u62e9\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u5668\u8bf1\u5bfc\u7684\u6295\u5f71\u6548\u7528\u8bc4\u5206\u6765\u9009\u62e9\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u9884\u8bad\u7ec3\u6548\u7387\u548c\u6570\u636e\u5229\u7528\u7387\u3002", "motivation": "\u968f\u7740\u9ad8\u8d28\u91cf\u516c\u5f00\u6587\u672c\u8d44\u6e90\u67af\u7aed\uff08\u6570\u636e\u5899\u73b0\u8c61\uff09\uff0c\u9884\u8bad\u7ec3\u9700\u8981\u4ece\"\u66f4\u591atokens\"\u8f6c\u5411\"\u66f4\u597dtokens\"\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u5ffd\u7565\u8bad\u7ec3\u52a8\u6001\u7684\u542f\u53d1\u5f0f\u9759\u6001\u8fc7\u6ee4\u5668\uff0c\u8981\u4e48\u4f7f\u7528\u57fa\u4e8e\u539f\u59cb\u68af\u5ea6\u7684\u52a8\u6001\u4f46\u4f18\u5316\u5668\u65e0\u5173\u7684\u6807\u51c6\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u73b0\u4ee3\u4f18\u5316\u5668\u7684\u7279\u6027\u3002", "method": "\u63d0\u51faOPUS\u6846\u67b6\uff0c\u5728\u4f18\u5316\u5668\u8bf1\u5bfc\u7684\u66f4\u65b0\u7a7a\u95f4\u4e2d\u5b9a\u4e49\u6548\u7528\u3002\u901a\u8fc7\u6295\u5f71\u5019\u9009\u6570\u636e\u7684\u6709\u6548\u66f4\u65b0\u5230\u7a33\u5b9a\u3001\u540c\u5206\u5e03\u4ee3\u7406\u7684\u76ee\u6807\u65b9\u5411\u6765\u8bc4\u5206\u3002\u91c7\u7528Ghost\u6280\u672f\u548cCountSketch\u5b9e\u73b0\u8ba1\u7b97\u6548\u7387\uff0c\u4f7f\u7528Boltzmann\u62bd\u6837\u4fdd\u8bc1\u6570\u636e\u591a\u6837\u6027\uff0c\u4ec5\u589e\u52a04.7%\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728GPT-2 Large/XL\u7684FineWeb\u548cFineWeb-Edu\u9884\u8bad\u7ec3\u4e2d\uff0c\u4ec5\u752830B tokens\u5c31\u8d85\u8d8a\u4e86\u5de5\u4e1a\u7ea7\u57fa\u7ebf\u751a\u81f3200B tokens\u7684\u5b8c\u6574\u8bad\u7ec3\u3002\u7ed3\u5408\u9759\u6001\u8fc7\u6ee4\u5668\u540e\uff0c\u5373\u4f7f\u4f7f\u7528\u4f4e\u8d28\u91cf\u6570\u636e\u4e5f\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u6548\u7387\u3002\u5728Qwen3-8B-Base\u7684SciencePedia\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\uff0c\u4ec5\u75280.5B tokens\u5c31\u8fbe\u5230\u4e863B tokens\u5b8c\u6574\u8bad\u7ec3\u7684\u6027\u80fd\uff0c\u5728\u4e13\u4e1a\u9886\u57df\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6570\u636e\u6548\u7387\u63d0\u5347\u3002", "conclusion": "OPUS\u901a\u8fc7\u4f18\u5316\u5668\u611f\u77e5\u7684\u52a8\u6001\u6570\u636e\u9009\u62e9\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u5899\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u8bad\u7ec3\u7684\u6570\u636e\u6548\u7387\uff0c\u5728\u4e0d\u540c\u8bed\u6599\u5e93\u3001\u8d28\u91cf\u7b49\u7ea7\u3001\u4f18\u5316\u5668\u548c\u6a21\u578b\u89c4\u6a21\u4e0b\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.05419", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05419", "abs": "https://arxiv.org/abs/2602.05419", "authors": ["Takumi Goto", "Yusuke Sakai", "Taro Watanabe"], "title": "Grammatical Error Correction Evaluation by Optimally Transporting Edit Representation", "comment": "Accepted to TACL. This is a pre-MIT Press publication version", "summary": "Automatic evaluation in grammatical error correction (GEC) is crucial for selecting the best-performing systems. Currently, reference-based metrics are a popular choice, which basically measure the similarity between hypothesis and reference sentences. However, similarity measures based on embeddings, such as BERTScore, are often ineffective, since many words in the source sentences remain unchanged in both the hypothesis and the reference. This study focuses on edits specifically designed for GEC, i.e., ERRANT, and computes similarity measured over the edits from the source sentence. To this end, we propose edit vector, a representation for an edit, and introduce a new metric, UOT-ERRANT, which transports these edit vectors from hypothesis to reference using unbalanced optimal transport. Experiments with SEEDA meta-evaluation show that UOT-ERRANT improves evaluation performance, particularly in the +Fluency domain where many edits occur. Moreover, our method is highly interpretable because the transport plan can be interpreted as a soft edit alignment, making UOT-ERRANT a useful metric for both system ranking and analyzing GEC systems. Our code is available from https://github.com/gotutiyan/uot-errant.", "AI": {"tldr": "UOT-ERRANT\uff1a\u4e00\u79cd\u57fa\u4e8e\u7f16\u8f91\u5411\u91cf\u548c\u4e0d\u5e73\u8861\u6700\u4f18\u4f20\u8f93\u7684GEC\u81ea\u52a8\u8bc4\u4f30\u65b0\u6307\u6807\uff0c\u4e13\u6ce8\u4e8e\u7f16\u8f91\u76f8\u4f3c\u6027\u800c\u975e\u5b8c\u6574\u53e5\u5b50\uff0c\u5728+Fluency\u9886\u57df\u8868\u73b0\u4f18\u5f02\u4e14\u5177\u6709\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5d4c\u5165\u7684\u8bc4\u4f30\u6307\u6807\uff08\u5982BERTScore\uff09\u5728GEC\u4efb\u52a1\u4e2d\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u4e3a\u6e90\u53e5\u4e2d\u7684\u8bb8\u591a\u8bcd\u5728\u5047\u8bbe\u548c\u53c2\u8003\u4e2d\u4fdd\u6301\u4e0d\u53d8\uff0c\u5bfc\u81f4\u76f8\u4f3c\u6027\u5ea6\u91cf\u5931\u771f\u3002\u9700\u8981\u4e13\u95e8\u9488\u5bf9GEC\u7f16\u8f91\u8bbe\u8ba1\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7f16\u8f91\u5411\u91cf\u4f5c\u4e3a\u7f16\u8f91\u7684\u8868\u793a\uff0c\u5f15\u5165UOT-ERRANT\u6307\u6807\uff0c\u4f7f\u7528\u4e0d\u5e73\u8861\u6700\u4f18\u4f20\u8f93\u5c06\u5047\u8bbe\u7684\u7f16\u8f91\u5411\u91cf\u4f20\u8f93\u5230\u53c2\u8003\u7f16\u8f91\uff0c\u8ba1\u7b97\u7f16\u8f91\u76f8\u4f3c\u6027\u800c\u975e\u53e5\u5b50\u76f8\u4f3c\u6027\u3002", "result": "\u5728SEEDA\u5143\u8bc4\u4f30\u5b9e\u9a8c\u4e2d\uff0cUOT-ERRANT\u63d0\u9ad8\u4e86\u8bc4\u4f30\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728+Fluency\u9886\u57df\uff08\u7f16\u8f91\u8f83\u591a\u7684\u60c5\u51b5\uff09\u8868\u73b0\u4f18\u5f02\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u53ef\u89e3\u91ca\u6027\uff0c\u4f20\u8f93\u8ba1\u5212\u53ef\u89e3\u91ca\u4e3a\u8f6f\u7f16\u8f91\u5bf9\u9f50\u3002", "conclusion": "UOT-ERRANT\u662f\u4e00\u79cd\u6709\u6548\u7684GEC\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\uff0c\u4e13\u6ce8\u4e8e\u7f16\u8f91\u76f8\u4f3c\u6027\uff0c\u5728\u7cfb\u7edf\u6392\u540d\u548c\u5206\u6790\u65b9\u9762\u90fd\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u7f16\u8f91\u5bc6\u96c6\u7684+Fluency\u9886\u57df\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2602.05437", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05437", "abs": "https://arxiv.org/abs/2602.05437", "authors": ["Basel Mousi", "Fahim Dalvi", "Shammur Chowdhury", "Firoj Alam", "Nadir Durrani"], "title": "Once Correct, Still Wrong: Counterfactual Hallucination in Multilingual Vision-Language Models", "comment": null, "summary": "Vision-language models (VLMs) can achieve high accuracy while still accepting culturally plausible but visually incorrect interpretations. Existing hallucination benchmarks rarely test this failure mode, particularly outside Western contexts and English. We introduce M2CQA, a culturally grounded multimodal benchmark built from images spanning 17 MENA countries, paired with contrastive true and counterfactual statements in English, Arabic, and its dialects. To isolate hallucination beyond raw accuracy, we propose the CounterFactual Hallucination Rate (CFHR), which measures counterfactual acceptance conditioned on correctly answering the true statement. Evaluating state-of-the-art VLMs under multiple prompting strategies, we find that CFHR rises sharply in Arabic, especially in dialects, even when true-statement accuracy remains high. Moreover, reasoning-first prompting consistently increases counterfactual hallucination, while answering before justifying improves robustness. We will make the experimental resources and dataset publicly available for the community.", "AI": {"tldr": "M2CQA\u662f\u4e00\u4e2a\u9488\u5bf9\u4e2d\u4e1c\u548c\u5317\u975e\u5730\u533a\u7684\u591a\u6a21\u6001\u6587\u5316\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5bf9\u6bd4\u771f\u5b9e\u9648\u8ff0\u548c\u53cd\u4e8b\u5b9e\u9648\u8ff0\u6765\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u5e7b\u89c9\u95ee\u9898\uff0c\u5e76\u63d0\u51faCFHR\u6307\u6807\u6765\u8861\u91cf\u6a21\u578b\u7684\u53cd\u4e8b\u5b9e\u63a5\u53d7\u7387\u3002", "motivation": "\u73b0\u6709\u5e7b\u89c9\u57fa\u51c6\u6d4b\u8bd5\u5f88\u5c11\u6d4b\u8bd5\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u975e\u897f\u65b9\u8bed\u5883\u548c\u975e\u82f1\u8bed\u73af\u5883\u4e0b\u7684\u6587\u5316\u5e7b\u89c9\u95ee\u9898\uff0c\u5373\u6a21\u578b\u53ef\u80fd\u63a5\u53d7\u6587\u5316\u4e0a\u5408\u7406\u4f46\u89c6\u89c9\u4e0a\u9519\u8bef\u7684\u89e3\u91ca\u3002", "method": "\u6784\u5efaM2CQA\u6570\u636e\u96c6\uff0c\u5305\u542b17\u4e2a\u4e2d\u4e1c\u548c\u5317\u975e\u56fd\u5bb6\u7684\u56fe\u50cf\uff0c\u914d\u4ee5\u82f1\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u53ca\u5176\u65b9\u8a00\u7684\u771f\u5b9e\u548c\u53cd\u4e8b\u5b9e\u9648\u8ff0\u3002\u63d0\u51faCounterFactual Hallucination Rate (CFHR)\u6307\u6807\uff0c\u8861\u91cf\u5728\u6b63\u786e\u56de\u7b54\u771f\u5b9e\u9648\u8ff0\u6761\u4ef6\u4e0b\u63a5\u53d7\u53cd\u4e8b\u5b9e\u9648\u8ff0\u7684\u6bd4\u4f8b\u3002\u8bc4\u4f30\u591a\u4e2a\u6700\u5148\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5728\u963f\u62c9\u4f2f\u8bed\u5c24\u5176\u662f\u65b9\u8a00\u4e2d\uff0cCFHR\u663e\u8457\u4e0a\u5347\uff0c\u5373\u4f7f\u771f\u5b9e\u9648\u8ff0\u51c6\u786e\u7387\u4fdd\u6301\u8f83\u9ad8\u6c34\u5e73\u3002\u63a8\u7406\u4f18\u5148\u7684\u63d0\u793a\u7b56\u7565\u4f1a\u6301\u7eed\u589e\u52a0\u53cd\u4e8b\u5b9e\u5e7b\u89c9\uff0c\u800c\u5148\u56de\u7b54\u540e\u89e3\u91ca\u7684\u63d0\u793a\u7b56\u7565\u80fd\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "conclusion": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u6587\u5316\u5e7b\u89c9\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u975e\u82f1\u8bed\u548c\u65b9\u8a00\u73af\u5883\u4e2d\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u8bc4\u4f30\u65b9\u6cd5\u548c\u6a21\u578b\u6539\u8fdb\u7b56\u7565\u6765\u5e94\u5bf9\u8fd9\u4e00\u95ee\u9898\u3002\u4f5c\u8005\u5c06\u516c\u5f00\u5b9e\u9a8c\u8d44\u6e90\u548c\u6570\u636e\u96c6\u4f9b\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2602.05444", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05444", "abs": "https://arxiv.org/abs/2602.05444", "authors": ["Yao Zhou", "Zeen Song", "Wenwen Qiang", "Fengge Wu", "Shuyi Zhou", "Changwen Zheng", "Hui Xiong"], "title": "Causal Front-Door Adjustment for Robust Jailbreak Attacks on LLMs", "comment": null, "summary": "Safety alignment mechanisms in Large Language Models (LLMs) often operate as latent internal states, obscuring the model's inherent capabilities. Building on this observation, we model the safety mechanism as an unobserved confounder from a causal perspective. Then, we propose the \\textbf{C}ausal \\textbf{F}ront-Door \\textbf{A}djustment \\textbf{A}ttack ({\\textbf{CFA}}$^2$) to jailbreak LLM, which is a framework that leverages Pearl's Front-Door Criterion to sever the confounding associations for robust jailbreaking. Specifically, we employ Sparse Autoencoders (SAEs) to physically strip defense-related features, isolating the core task intent. We further reduce computationally expensive marginalization to a deterministic intervention with low inference complexity. Experiments demonstrate that {CFA}$^2$ achieves state-of-the-art attack success rates while offering a mechanistic interpretation of the jailbreaking process.", "AI": {"tldr": "CFA\u00b2\uff1a\u57fa\u4e8e\u56e0\u679c\u524d\u95e8\u51c6\u5219\u7684LLM\u8d8a\u72f1\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5265\u79bb\u5b89\u5168\u9632\u5fa1\u7279\u5f81\uff0c\u5b9e\u73b0\u9ad8\u6548\u8d8a\u72f1", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u901a\u5e38\u4f5c\u4e3a\u6f5c\u5728\u5185\u90e8\u72b6\u6001\u8fd0\u884c\uff0c\u8fd9\u63a9\u76d6\u4e86\u6a21\u578b\u7684\u56fa\u6709\u80fd\u529b\u3002\u4ece\u56e0\u679c\u89c6\u89d2\u6765\u770b\uff0c\u5b89\u5168\u673a\u5236\u53ef\u89c6\u4e3a\u672a\u89c2\u6d4b\u7684\u6df7\u6742\u56e0\u5b50\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u539f\u59cb\u529f\u80fd\u8868\u8fbe\u3002", "method": "\u5c06\u5b89\u5168\u673a\u5236\u5efa\u6a21\u4e3a\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u5b50\uff0c\u63d0\u51fa\u57fa\u4e8ePearl\u524d\u95e8\u51c6\u5219\u7684\u56e0\u679c\u524d\u95e8\u8c03\u6574\u653b\u51fb\u6846\u67b6\u3002\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7269\u7406\u5265\u79bb\u9632\u5fa1\u76f8\u5173\u7279\u5f81\uff0c\u5206\u79bb\u6838\u5fc3\u4efb\u52a1\u610f\u56fe\u3002\u5c06\u8ba1\u7b97\u6602\u8d35\u7684\u8fb9\u9645\u5316\u7b80\u5316\u4e3a\u4f4e\u63a8\u7406\u590d\u6742\u5ea6\u7684\u786e\u5b9a\u6027\u5e72\u9884\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCFA\u00b2\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4e3a\u8d8a\u72f1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u673a\u5236\u6027\u89e3\u91ca\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u63a8\u7406\u7684\u540c\u65f6\u6709\u6548\u7ed5\u8fc7\u5b89\u5168\u9632\u5fa1\u3002", "conclusion": "\u8be5\u7814\u7a76\u4ece\u56e0\u679c\u89d2\u5ea6\u5f62\u5f0f\u5316\u4e86LLM\u5b89\u5168\u673a\u5236\uff0c\u63d0\u51fa\u7684CFA\u00b2\u6846\u67b6\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u9ad8\u6548\u8d8a\u72f1\uff0c\u8fd8\u63d0\u4f9b\u4e86\u5bf9\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u7684\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u9632\u5fa1\u673a\u5236\u7684\u5185\u90e8\u5de5\u4f5c\u65b9\u5f0f\u3002"}}
{"id": "2602.05447", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05447", "abs": "https://arxiv.org/abs/2602.05447", "authors": ["Damon McMillan"], "title": "Structured Context Engineering for File-Native Agentic Systems: Evaluating Schema Accuracy, Format Effectiveness, and Multi-File Navigation at Scale", "comment": "8 pages, 7 figures, 10 tables, 26 references", "summary": "Large Language Model agents increasingly operate external systems through programmatic interfaces, yet practitioners lack empirical guidance on how to structure the context these agents consume. Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of context engineering for structured data, comprising 9,649 experiments across 11 models, 4 formats (YAML, Markdown, JSON, Token-Oriented Object Notation [TOON]), and schemas ranging from 10 to 10,000 tables.\n  Our findings challenge common assumptions. First, architecture choice is model-dependent: file-based context retrieval improves accuracy for frontier-tier models (Claude, GPT, Gemini; +2.7%, p=0.029) but shows mixed results for open source models (aggregate -7.7%, p<0.001), with deficits varying substantially by model. Second, format does not significantly affect aggregate accuracy (chi-squared=2.45, p=0.484), though individual models, particularly open source, exhibit format-specific sensitivities. Third, model capability is the dominant factor, with a 21 percentage point accuracy gap between frontier and open source tiers that dwarfs any format or architecture effect. Fourth, file-native agents scale to 10,000 tables through domain-partitioned schemas while maintaining high navigation accuracy. Fifth, file size does not predict runtime efficiency: compact formats can consume significantly more tokens at scale due to format-unfamiliar search patterns.\n  These findings provide practitioners with evidence-based guidance for deploying LLM agents on structured systems, demonstrating that architectural decisions should be tailored to model capability rather than assuming universal best practices.", "AI": {"tldr": "\u901a\u8fc7\u5927\u89c4\u6a21SQL\u751f\u6210\u5b9e\u9a8c\u7814\u7a76LLM\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u5de5\u7a0b\uff0c\u53d1\u73b0\u6a21\u578b\u80fd\u529b\u662f\u4e3b\u5bfc\u56e0\u7d20\uff0c\u67b6\u6784\u9009\u62e9\u5e94\u57fa\u4e8e\u5177\u4f53\u6a21\u578b\u800c\u975e\u901a\u7528\u6700\u4f73\u5b9e\u8df5", "motivation": "LLM\u4ee3\u7406\u901a\u8fc7\u7f16\u7a0b\u63a5\u53e3\u64cd\u4f5c\u5916\u90e8\u7cfb\u7edf\u65f6\uff0c\u4ece\u4e1a\u8005\u7f3a\u4e4f\u5173\u4e8e\u5982\u4f55\u6784\u5efa\u4ee3\u7406\u6d88\u8d39\u4e0a\u4e0b\u6587\u7684\u5b9e\u8bc1\u6307\u5bfc\u3002\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u7ed3\u6784\u5316\u6570\u636e\u7684\u4e0a\u4e0b\u6587\u5de5\u7a0b\u3002", "method": "\u4f7f\u7528SQL\u751f\u6210\u4f5c\u4e3a\u7f16\u7a0b\u4ee3\u7406\u64cd\u4f5c\u7684\u4ee3\u7406\u4efb\u52a1\uff0c\u8fdb\u884c\u4e869,649\u6b21\u5b9e\u9a8c\uff0c\u6db5\u76d611\u4e2a\u6a21\u578b\u30014\u79cd\u683c\u5f0f\uff08YAML\u3001Markdown\u3001JSON\u3001TOON\uff09\u548c10\u523010,000\u4e2a\u8868\u7684\u6a21\u5f0f\u3002", "result": "1) \u67b6\u6784\u9009\u62e9\u4f9d\u8d56\u6a21\u578b\uff1a\u6587\u4ef6\u5f0f\u4e0a\u4e0b\u6587\u68c0\u7d22\u5bf9\u524d\u6cbf\u6a21\u578b\uff08Claude\u3001GPT\u3001Gemini\uff09\u63d0\u5347\u51c6\u786e\u7387\uff08+2.7%\uff09\uff0c\u4f46\u5bf9\u5f00\u6e90\u6a21\u578b\u6574\u4f53\u964d\u4f4e\uff08-7.7%\uff09\uff1b2) \u683c\u5f0f\u5bf9\u6574\u4f53\u51c6\u786e\u7387\u65e0\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u5bf9\u7279\u5b9a\u683c\u5f0f\u654f\u611f\uff1b3) \u6a21\u578b\u80fd\u529b\u662f\u4e3b\u5bfc\u56e0\u7d20\uff0c\u524d\u6cbf\u4e0e\u5f00\u6e90\u6a21\u578b\u51c6\u786e\u7387\u5dee\u8ddd\u8fbe21\u4e2a\u767e\u5206\u70b9\uff1b4) \u6587\u4ef6\u539f\u751f\u4ee3\u7406\u901a\u8fc7\u9886\u57df\u5206\u533a\u6a21\u5f0f\u53ef\u6269\u5c55\u523010,000\u4e2a\u8868\uff1b5) \u6587\u4ef6\u5927\u5c0f\u4e0d\u80fd\u9884\u6d4b\u8fd0\u884c\u65f6\u6548\u7387\uff0c\u7d27\u51d1\u683c\u5f0f\u53ef\u80fd\u56e0\u641c\u7d22\u6a21\u5f0f\u6d88\u8017\u66f4\u591atoken\u3002", "conclusion": "\u90e8\u7f72LLM\u4ee3\u7406\u4e8e\u7ed3\u6784\u5316\u7cfb\u7edf\u65f6\uff0c\u67b6\u6784\u51b3\u7b56\u5e94\u6839\u636e\u6a21\u578b\u80fd\u529b\u5b9a\u5236\uff0c\u800c\u975e\u5047\u8bbe\u901a\u7528\u6700\u4f73\u5b9e\u8df5\u3002\u6a21\u578b\u80fd\u529b\u662f\u5f71\u54cd\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\u3002"}}
{"id": "2602.05471", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05471", "abs": "https://arxiv.org/abs/2602.05471", "authors": ["Md. Mithun Hossaina", "Mashary N. Alrasheedy", "Nirban Bhowmick", "Shamim Forhad", "Md. Shakil Hossain", "Sudipto Chaki", "Md Shafiqul Islam"], "title": "Reasoning under Ambiguity: Uncertainty-Aware Multilingual Emotion Classification under Partial Supervision", "comment": null, "summary": "Contemporary knowledge-based systems increasingly rely on multilingual emotion identification to support intelligent decision-making, yet they face major challenges due to emotional ambiguity and incomplete supervision. Emotion recognition from text is inherently uncertain because multiple emotional states often co-occur and emotion annotations are frequently missing or heterogeneous. Most existing multi-label emotion classification methods assume fully observed labels and rely on deterministic learning objectives, which can lead to biased learning and unreliable predictions under partial supervision. This paper introduces Reasoning under Ambiguity, an uncertainty-aware framework for multilingual multi-label emotion classification that explicitly aligns learning with annotation uncertainty. The proposed approach uses a shared multilingual encoder with language-specific optimization and an entropy-based ambiguity weighting mechanism that down-weights highly ambiguous training instances rather than treating missing labels as negative evidence. A mask-aware objective with positive-unlabeled regularization is further incorporated to enable robust learning under partial supervision. Experiments on English, Spanish, and Arabic emotion classification benchmarks demonstrate consistent improvements over strong baselines across multiple evaluation metrics, along with improved training stability, robustness to annotation sparsity, and enhanced interpretability.", "AI": {"tldr": "\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6846\u67b6RA\uff0c\u7528\u4e8e\u591a\u8bed\u8a00\u591a\u6807\u7b7e\u60c5\u611f\u5206\u7c7b\uff0c\u901a\u8fc7\u71b5\u57fa\u6a21\u7cca\u52a0\u6743\u548c\u63a9\u7801\u611f\u77e5\u76ee\u6807\u5904\u7406\u60c5\u611f\u6a21\u7cca\u6027\u548c\u4e0d\u5b8c\u6574\u76d1\u7763\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u77e5\u8bc6\u7684\u591a\u8bed\u8a00\u60c5\u611f\u8bc6\u522b\u7cfb\u7edf\u9762\u4e34\u60c5\u611f\u6a21\u7cca\u6027\u548c\u4e0d\u5b8c\u6574\u76d1\u7763\u7684\u6311\u6218\u3002\u6587\u672c\u60c5\u611f\u8bc6\u522b\u672c\u8d28\u4e0d\u786e\u5b9a\uff0c\u591a\u79cd\u60c5\u611f\u72b6\u6001\u5e38\u5171\u5b58\u4e14\u6807\u6ce8\u5e38\u7f3a\u5931\u6216\u5f02\u6784\u3002\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u5b8c\u5168\u89c2\u5bdf\u6807\u7b7e\uff0c\u4f9d\u8d56\u786e\u5b9a\u6027\u5b66\u4e60\u76ee\u6807\uff0c\u5728\u90e8\u5206\u76d1\u7763\u4e0b\u6613\u5bfc\u81f4\u504f\u5dee\u5b66\u4e60\u548c\u4e0d\u53ef\u9760\u9884\u6d4b\u3002", "method": "\u63d0\u51faRA\u6846\u67b6\uff1a\u4f7f\u7528\u5171\u4eab\u591a\u8bed\u8a00\u7f16\u7801\u5668\u4e0e\u8bed\u8a00\u7279\u5b9a\u4f18\u5316\uff1b\u5f15\u5165\u71b5\u57fa\u6a21\u7cca\u52a0\u6743\u673a\u5236\uff0c\u964d\u4f4e\u9ad8\u6a21\u7cca\u8bad\u7ec3\u5b9e\u4f8b\u6743\u91cd\u800c\u975e\u5c06\u7f3a\u5931\u6807\u7b7e\u89c6\u4e3a\u8d1f\u8bc1\u636e\uff1b\u7ed3\u5408\u63a9\u7801\u611f\u77e5\u76ee\u6807\u4e0e\u6b63\u672a\u6807\u6ce8\u6b63\u5219\u5316\uff0c\u5b9e\u73b0\u90e8\u5206\u76d1\u7763\u4e0b\u7684\u9c81\u68d2\u5b66\u4e60\u3002", "result": "\u5728\u82f1\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u963f\u62c9\u4f2f\u8bed\u60c5\u611f\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u3001\u5bf9\u6807\u6ce8\u7a00\u758f\u6027\u7684\u9c81\u68d2\u6027\u4ee5\u53ca\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "RA\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5bf9\u9f50\u5b66\u4e60\u4e0e\u6807\u6ce8\u4e0d\u786e\u5b9a\u6027\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8bed\u8a00\u591a\u6807\u7b7e\u60c5\u611f\u5206\u7c7b\u4e2d\u7684\u60c5\u611f\u6a21\u7cca\u6027\u548c\u4e0d\u5b8c\u6574\u76d1\u7763\u95ee\u9898\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u60c5\u611f\u8bc6\u522b\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05493", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.05493", "abs": "https://arxiv.org/abs/2602.05493", "authors": ["Bingru Li"], "title": "LinguistAgent: A Reflective Multi-Model Platform for Automated Linguistic Annotation", "comment": null, "summary": "Data annotation remains a significant bottleneck in the Humanities and Social Sciences, particularly for complex semantic tasks such as metaphor identification. While Large Language Models (LLMs) show promise, a significant gap remains between the theoretical capability of LLMs and their practical utility for researchers. This paper introduces LinguistAgent, an integrated, user-friendly platform that leverages a reflective multi-model architecture to automate linguistic annotation. The system implements a dual-agent workflow, comprising an Annotator and a Reviewer, to simulate a professional peer-review process. LinguistAgent supports comparative experiments across three paradigms: Prompt Engineering (Zero/Few-shot), Retrieval-Augmented Generation, and Fine-tuning. We demonstrate LinguistAgent's efficacy using the task of metaphor identification as an example, providing real-time token-level evaluation (Precision, Recall, and $F_1$ score) against human gold standards. The application and codes are released on https://github.com/Bingru-Li/LinguistAgent.", "AI": {"tldr": "LinguistAgent\u662f\u4e00\u4e2a\u7528\u4e8e\u4eba\u6587\u793e\u79d1\u9886\u57df\u590d\u6742\u8bed\u4e49\u6807\u6ce8\u4efb\u52a1\u7684\u96c6\u6210\u5e73\u53f0\uff0c\u91c7\u7528\u53cd\u601d\u6027\u591a\u6a21\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u53cc\u4ee3\u7406\u5de5\u4f5c\u6d41\uff08\u6807\u6ce8\u8005\u548c\u5ba1\u9605\u8005\uff09\u5b9e\u73b0\u81ea\u52a8\u5316\u6807\u6ce8\uff0c\u7279\u522b\u4ee5\u9690\u55bb\u8bc6\u522b\u4e3a\u4f8b\u5c55\u793a\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4eba\u6587\u793e\u79d1\u9886\u57df\u7684\u6570\u636e\u6807\u6ce8\uff08\u7279\u522b\u662f\u590d\u6742\u8bed\u4e49\u4efb\u52a1\u5982\u9690\u55bb\u8bc6\u522b\uff09\u5b58\u5728\u663e\u8457\u74f6\u9888\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u7406\u8bba\u80fd\u529b\u4e0e\u5b9e\u9645\u7814\u7a76\u6548\u7528\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\u3002", "method": "1. \u5f00\u53d1LinguistAgent\u96c6\u6210\u5e73\u53f0\uff0c\u91c7\u7528\u53cd\u601d\u6027\u591a\u6a21\u578b\u67b6\u6784\n2. \u5b9e\u73b0\u53cc\u4ee3\u7406\u5de5\u4f5c\u6d41\uff1a\u6807\u6ce8\u8005(Annotator)\u548c\u5ba1\u9605\u8005(Reviewer)\uff0c\u6a21\u62df\u4e13\u4e1a\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\n3. \u652f\u6301\u4e09\u79cd\u8303\u5f0f\u6bd4\u8f83\u5b9e\u9a8c\uff1a\u63d0\u793a\u5de5\u7a0b\uff08\u96f6\u6837\u672c/\u5c11\u6837\u672c\uff09\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u5fae\u8c03\n4. \u4ee5\u9690\u55bb\u8bc6\u522b\u4e3a\u4f8b\uff0c\u63d0\u4f9b\u5b9e\u65f6token\u7ea7\u8bc4\u4f30\uff08\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\uff09\u5bf9\u6bd4\u4eba\u5de5\u9ec4\u91d1\u6807\u51c6", "result": "\u5c55\u793a\u4e86LinguistAgent\u5728\u9690\u55bb\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e73\u53f0\u548c\u4ee3\u7801\u5df2\u5728GitHub\u53d1\u5e03\uff08https://github.com/Bingru-Li/LinguistAgent\uff09\u3002", "conclusion": "LinguistAgent\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u7684\u96c6\u6210\u5e73\u53f0\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6807\u6ce8\u89e3\u51b3\u4eba\u6587\u793e\u79d1\u7814\u7a76\u4e2d\u7684\u6807\u6ce8\u74f6\u9888\u95ee\u9898\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7406\u8bba\u6f5c\u529b\u8f6c\u5316\u4e3a\u5b9e\u9645\u7814\u7a76\u5de5\u5177\u3002"}}
{"id": "2602.05495", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05495", "abs": "https://arxiv.org/abs/2602.05495", "authors": ["Chenhang Cui", "Binyun Yang", "Fei Shen", "Yuxin Chen", "Jingnan Zheng", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Transport and Merge: Cross-Architecture Merging for Large Language Models", "comment": null, "summary": "Large language models (LLMs) achieve strong capabilities by scaling model capacity and training data, yet many real-world deployments rely on smaller models trained or adapted from low-resource data. This gap motivates the need for mechanisms to transfer knowledge from large, high-resource models to smaller, low-resource targets. While model merging provides an effective transfer mechanism, most existing approaches assume architecture-compatible models and therefore cannot directly transfer knowledge from large high-resource LLMs to heterogeneous low-resource targets. In this work, we propose a cross-architecture merging framework based on optimal transport (OT) that aligns activations to infer cross-neuron correspondences between heterogeneous models. The resulting transport plans are then used to guide direct weight-space fusion, enabling effective high-resource to low-resource transfer using only a small set of inputs. Extensive experiments across low-resource languages and specialized domains demonstrate consistent improvements over target models.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u8de8\u67b6\u6784\u6a21\u578b\u5408\u5e76\u6846\u67b6\uff0c\u5b9e\u73b0\u5927\u578b\u9ad8\u8d44\u6e90LLM\u5411\u5f02\u6784\u5c0f\u6a21\u578b\u7684\u6743\u91cd\u7a7a\u95f4\u77e5\u8bc6\u8fc1\u79fb", "motivation": "\u73b0\u5b9e\u90e8\u7f72\u5e38\u4f9d\u8d56\u5c0f\u6a21\u578b\u6216\u4f4e\u8d44\u6e90\u6570\u636e\u8bad\u7ec3\uff0c\u4f46\u5927\u6a21\u578b\u5728\u80fd\u529b\u4e0a\u66f4\u5f3a\uff0c\u9700\u8981\u5c06\u5927\u6a21\u578b\u77e5\u8bc6\u8fc1\u79fb\u5230\u5f02\u6784\u5c0f\u6a21\u578b\u7684\u673a\u5236", "method": "\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93(OT)\u7684\u8de8\u67b6\u6784\u5408\u5e76\u6846\u67b6\uff1a\u901a\u8fc7\u5bf9\u9f50\u6fc0\u6d3b\u63a8\u65ad\u8de8\u795e\u7ecf\u5143\u5bf9\u5e94\u5173\u7cfb\uff0c\u5229\u7528\u4f20\u8f93\u8ba1\u5212\u6307\u5bfc\u6743\u91cd\u7a7a\u95f4\u878d\u5408", "result": "\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u4e13\u95e8\u9886\u57df\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u76ee\u6807\u6a21\u578b\u83b7\u5f97\u4e00\u81f4\u6539\u8fdb", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u5b9e\u73b0\u9ad8\u8d44\u6e90\u5230\u4f4e\u8d44\u6e90\u7684\u8de8\u67b6\u6784\u77e5\u8bc6\u8fc1\u79fb\uff0c\u4ec5\u9700\u5c11\u91cf\u8f93\u5165\u6570\u636e"}}
{"id": "2602.05547", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.05547", "abs": "https://arxiv.org/abs/2602.05547", "authors": ["Shyam Sundhar Ramesh", "Xiaotong Ji", "Matthieu Zimmer", "Sangwoong Yoon", "Zhiyong Wang", "Haitham Bou Ammar", "Aurelien Lucchi", "Ilija Bogunovic"], "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks", "comment": "Preprint", "summary": "RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks dominating optimization while others stagnate. Moreover, tasks can vary widely in how frequently prompts yield zero advantages (and thus zero gradients), which further distorts their effective contribution to the optimization signal. To address these issues, we propose a novel Multi-Task GRPO (MT-GRPO) algorithm that (i) dynamically adapts task weights to explicitly optimize worst-task performance and promote balanced progress across tasks, and (ii) introduces a ratio-preserving sampler to ensure task-wise policy gradients reflect the adapted weights. Experiments on both 3-task and 9-task settings show that MT-GRPO consistently outperforms baselines in worst-task accuracy. In particular, MT-GRPO achieves 16-28% and 6% absolute improvement on worst-task performance over standard GRPO and DAPO, respectively, while maintaining competitive average accuracy. Moreover, MT-GRPO requires 50% fewer training steps to reach 50% worst-task accuracy in the 3-task setting, demonstrating substantially improved efficiency in achieving reliable performance across tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86MT-GRPO\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u4efb\u52a1\u6743\u91cd\u8c03\u6574\u548c\u6bd4\u7387\u4fdd\u6301\u91c7\u6837\u5668\uff0c\u5728\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u4e2d\u5e73\u8861\u5404\u4efb\u52a1\u8868\u73b0\uff0c\u663e\u8457\u63d0\u5347\u6700\u5dee\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u90e8\u7f72\u9700\u8981\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e0a\u4fdd\u6301\u53ef\u9760\u6027\u80fd\u3002\u6807\u51c6\u7684GRPO\u591a\u4efb\u52a1\u9002\u5e94\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u4e0d\u5e73\u8861\u7ed3\u679c\uff0c\u67d0\u4e9b\u4efb\u52a1\u4e3b\u5bfc\u4f18\u5316\u800c\u5176\u4ed6\u4efb\u52a1\u505c\u6ede\u4e0d\u524d\u3002\u6b64\u5916\uff0c\u4e0d\u540c\u4efb\u52a1\u4e2d\u63d0\u793a\u4ea7\u751f\u96f6\u4f18\u52bf\uff08\u96f6\u68af\u5ea6\uff09\u7684\u9891\u7387\u5dee\u5f02\u5f88\u5927\uff0c\u8fdb\u4e00\u6b65\u626d\u66f2\u4e86\u4f18\u5316\u4fe1\u53f7\u7684\u6709\u6548\u8d21\u732e\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u4efb\u52a1GRPO\uff08MT-GRPO\uff09\u7b97\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6280\u672f\uff1a(1) \u52a8\u6001\u8c03\u6574\u4efb\u52a1\u6743\u91cd\uff0c\u663e\u5f0f\u4f18\u5316\u6700\u5dee\u4efb\u52a1\u6027\u80fd\u5e76\u4fc3\u8fdb\u5404\u4efb\u52a1\u5e73\u8861\u8fdb\u5c55\uff1b(2) \u5f15\u5165\u6bd4\u7387\u4fdd\u6301\u91c7\u6837\u5668\uff0c\u786e\u4fdd\u4efb\u52a1\u7ea7\u7b56\u7565\u68af\u5ea6\u53cd\u6620\u8c03\u6574\u540e\u7684\u6743\u91cd\u3002", "result": "\u57283\u4efb\u52a1\u548c9\u4efb\u52a1\u8bbe\u7f6e\u4e2d\uff0cMT-GRPO\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6700\u5dee\u4efb\u52a1\u51c6\u786e\u7387\u3002\u76f8\u6bd4\u6807\u51c6GRPO\u548cDAPO\uff0c\u5728\u6700\u5dee\u4efb\u52a1\u6027\u80fd\u4e0a\u5206\u522b\u83b7\u5f9716-28%\u548c6%\u7684\u7edd\u5bf9\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u5e73\u5747\u51c6\u786e\u7387\u3002\u57283\u4efb\u52a1\u8bbe\u7f6e\u4e2d\uff0c\u8fbe\u523050%\u6700\u5dee\u4efb\u52a1\u51c6\u786e\u7387\u6240\u9700\u7684\u8bad\u7ec3\u6b65\u9aa4\u51cf\u5c1150%\uff0c\u6548\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MT-GRPO\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u4e2d\u7684\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u6743\u91cd\u8c03\u6574\u548c\u91c7\u6837\u7b56\u7565\u6539\u8fdb\uff0c\u5b9e\u73b0\u4e86\u8de8\u4efb\u52a1\u7684\u53ef\u9760\u6027\u80fd\u5e73\u8861\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05633", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05633", "abs": "https://arxiv.org/abs/2602.05633", "authors": ["Rui Jia", "Ruiyi Lan", "Fengrui Liu", "Zhongxiang Dai", "Bo Jiang", "Jing Shao", "Jingyuan Chen", "Guandong Xu", "Fei Wu", "Min Zhang"], "title": "CASTLE: A Comprehensive Benchmark for Evaluating Student-Tailored Personalized Safety in Large Language Models", "comment": null, "summary": "Large language models (LLMs) have advanced the development of personalized learning in education. However, their inherent generation mechanisms often produce homogeneous responses to identical prompts. This one-size-fits-all mechanism overlooks the substantial heterogeneity in students cognitive and psychological, thereby posing potential safety risks to vulnerable groups. Existing safety evaluations primarily rely on context-independent metrics such as factual accuracy, bias, or toxicity, which fail to capture the divergent harms that the same response might cause across different student attributes. To address this gap, we propose the concept of Student-Tailored Personalized Safety and construct CASTLE based on educational theories. This benchmark covers 15 educational safety risks and 14 student attributes, comprising 92,908 bilingual scenarios. We further design three evaluation metrics: Risk Sensitivity, measuring the model ability to detect risks; Emotional Empathy, evaluating the model capacity to recognize student states; and Student Alignment, assessing the match between model responses and student attributes. Experiments on 18 SOTA LLMs demonstrate that CASTLE poses a significant challenge: all models scored below an average safety rating of 2.3 out of 5, indicating substantial deficiencies in personalized safety assurance.", "AI": {"tldr": "CASTLE\u662f\u4e00\u4e2a\u57fa\u4e8e\u6559\u80b2\u7406\u8bba\u6784\u5efa\u7684\u5b66\u751f\u4e2a\u6027\u5316\u5b89\u5168\u57fa\u51c6\uff0c\u6db5\u76d615\u79cd\u6559\u80b2\u5b89\u5168\u98ce\u9669\u548c14\u79cd\u5b66\u751f\u5c5e\u6027\uff0c\u5305\u542b92,908\u4e2a\u53cc\u8bed\u573a\u666f\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e2a\u6027\u5316\u6559\u80b2\u4e2d\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u5176\u56fa\u6709\u7684\u751f\u6210\u673a\u5236\u5bf9\u76f8\u540c\u63d0\u793a\u4ea7\u751f\u540c\u8d28\u5316\u54cd\u5e94\uff0c\u5ffd\u89c6\u4e86\u5b66\u751f\u5728\u8ba4\u77e5\u548c\u5fc3\u7406\u65b9\u9762\u7684\u5f02\u8d28\u6027\u3002\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u504f\u89c1\u6216\u6bd2\u6027\u7b49\u4e0e\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u6307\u6807\uff0c\u65e0\u6cd5\u6355\u6349\u76f8\u540c\u54cd\u5e94\u5bf9\u4e0d\u540c\u5b66\u751f\u5c5e\u6027\u53ef\u80fd\u9020\u6210\u7684\u4e0d\u540c\u5371\u5bb3\u3002", "method": "\u63d0\u51fa\"\u5b66\u751f\u5b9a\u5236\u5316\u4e2a\u6027\u5316\u5b89\u5168\"\u6982\u5ff5\uff0c\u6784\u5efaCASTLE\u57fa\u51c6\uff0c\u6db5\u76d615\u79cd\u6559\u80b2\u5b89\u5168\u98ce\u9669\u548c14\u79cd\u5b66\u751f\u5c5e\u6027\uff0c\u5305\u542b92,908\u4e2a\u53cc\u8bed\u573a\u666f\u3002\u8bbe\u8ba1\u4e09\u4e2a\u8bc4\u4f30\u6307\u6807\uff1a\u98ce\u9669\u654f\u611f\u6027\uff08\u68c0\u6d4b\u98ce\u9669\u80fd\u529b\uff09\u3001\u60c5\u611f\u5171\u60c5\uff08\u8bc6\u522b\u5b66\u751f\u72b6\u6001\u80fd\u529b\uff09\u548c\u5b66\u751f\u5bf9\u9f50\uff08\u54cd\u5e94\u4e0e\u5b66\u751f\u5c5e\u6027\u5339\u914d\u5ea6\uff09\u3002", "result": "\u5bf918\u4e2a\u6700\u5148\u8fdb\u7684LLM\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6240\u6709\u6a21\u578b\u5e73\u5747\u5b89\u5168\u8bc4\u5206\u4f4e\u4e8e2.3\u5206\uff08\u6ee1\u52065\u5206\uff09\uff0c\u8868\u660e\u5728\u4e2a\u6027\u5316\u5b89\u5168\u4fdd\u969c\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002", "conclusion": "CASTLE\u57fa\u51c6\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u4e2a\u6027\u5316\u6559\u80b2\u5b89\u5168\u65b9\u9762\u7684\u4e25\u91cd\u7f3a\u9677\uff0c\u5f3a\u8c03\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8003\u8651\u5b66\u751f\u5f02\u8d28\u6027\u7684\u66f4\u5b89\u5168\u3001\u66f4\u4e2a\u6027\u5316\u7684\u6559\u80b2AI\u7cfb\u7edf\u3002"}}
{"id": "2602.05648", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05648", "abs": "https://arxiv.org/abs/2602.05648", "authors": ["Giuseppe Samo", "Paola Merlo"], "title": "Modelling the Morphology of Verbal Paradigms: A Case Study in the Tokenization of Turkish and Hebrew", "comment": "13 pages, 7 figures, to appear as proceedings of the SIGTURK 2026 Workshop", "summary": "We investigate how transformer models represent complex verb paradigms in Turkish and Modern Hebrew, concentrating on how tokenization strategies shape this ability. Using the Blackbird Language Matrices task on natural data, we show that for Turkish -- with its transparent morphological markers -- both monolingual and multilingual models succeed, either when tokenization is atomic or when it breaks words into small subword units. For Hebrew, instead, monolingual and multilingual models diverge. A multilingual model using character-level tokenization fails to capture the language non-concatenative morphology, but a monolingual model with morpheme-aware segmentation performs well. Performance improves on more synthetic datasets, in all models.", "AI": {"tldr": "\u7814\u7a76Transformer\u6a21\u578b\u5982\u4f55\u8868\u793a\u571f\u8033\u5176\u8bed\u548c\u73b0\u4ee3\u5e0c\u4f2f\u6765\u8bed\u7684\u590d\u6742\u52a8\u8bcd\u8303\u5f0f\uff0c\u91cd\u70b9\u5173\u6ce8\u5206\u8bcd\u7b56\u7565\u5982\u4f55\u5f71\u54cd\u8fd9\u79cd\u80fd\u529b", "motivation": "\u63a2\u7d22\u4e0d\u540c\u5206\u8bcd\u7b56\u7565\u5982\u4f55\u5f71\u54cdTransformer\u6a21\u578b\u5bf9\u5177\u6709\u4e0d\u540c\u5f62\u6001\u7279\u5f81\u7684\u8bed\u8a00\uff08\u571f\u8033\u5176\u8bed\u7684\u900f\u660e\u5f62\u6001\u6807\u8bb0vs\u5e0c\u4f2f\u6765\u8bed\u7684\u975e\u8fde\u63a5\u6027\u5f62\u6001\uff09\u7684\u52a8\u8bcd\u8303\u5f0f\u8868\u793a\u80fd\u529b", "method": "\u4f7f\u7528Blackbird Language Matrices\u4efb\u52a1\u5728\u81ea\u7136\u6570\u636e\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u5355\u8bed\u548c\u591a\u8bed\u6a21\u578b\u5728\u4e0d\u540c\u5206\u8bcd\u7b56\u7565\uff08\u539f\u5b50\u5206\u8bcd\u3001\u5b50\u8bcd\u5206\u8bcd\u3001\u5b57\u7b26\u7ea7\u5206\u8bcd\u3001\u8bcd\u7d20\u611f\u77e5\u5206\u8bcd\uff09\u4e0b\u7684\u8868\u73b0", "result": "\u5bf9\u4e8e\u571f\u8033\u5176\u8bed\uff0c\u5355\u8bed\u548c\u591a\u8bed\u6a21\u578b\u5728\u539f\u5b50\u5206\u8bcd\u6216\u7ec6\u7c92\u5ea6\u5b50\u8bcd\u5206\u8bcd\u4e0b\u90fd\u80fd\u6210\u529f\uff1b\u5bf9\u4e8e\u5e0c\u4f2f\u6765\u8bed\uff0c\u4f7f\u7528\u5b57\u7b26\u7ea7\u5206\u8bcd\u7684\u591a\u8bed\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u975e\u8fde\u63a5\u6027\u5f62\u6001\uff0c\u4f46\u4f7f\u7528\u8bcd\u7d20\u611f\u77e5\u5206\u8bcd\u7684\u5355\u8bed\u6a21\u578b\u8868\u73b0\u826f\u597d\uff1b\u6240\u6709\u6a21\u578b\u5728\u66f4\u5408\u6210\u5316\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u90fd\u6709\u63d0\u5347", "conclusion": "\u5206\u8bcd\u7b56\u7565\u5bf9Transformer\u6a21\u578b\u8868\u793a\u590d\u6742\u52a8\u8bcd\u8303\u5f0f\u7684\u80fd\u529b\u6709\u663e\u8457\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5177\u6709\u975e\u8fde\u63a5\u6027\u5f62\u6001\u7684\u8bed\u8a00\uff08\u5982\u5e0c\u4f2f\u6765\u8bed\uff09\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5206\u8bcd\u65b9\u6cd5\uff08\u5982\u8bcd\u7d20\u611f\u77e5\u5206\u8bcd\uff09\u624d\u80fd\u83b7\u5f97\u826f\u597d\u8868\u73b0"}}
{"id": "2602.05692", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05692", "abs": "https://arxiv.org/abs/2602.05692", "authors": ["Congbo Ma", "Yichun Zhang", "Yousef Al-Jazzazi", "Ahamed Foisal", "Laasya Sharma", "Yousra Sadqi", "Khaled Saleh", "Jihad Mallat", "Farah E. Shamout"], "title": "MedErrBench: A Fine-Grained Multilingual Benchmark for Medical Error Detection and Correction with Clinical Expert Annotations", "comment": null, "summary": "Inaccuracies in existing or generated clinical text may lead to serious adverse consequences, especially if it is a misdiagnosis or incorrect treatment suggestion. With Large Language Models (LLMs) increasingly being used across diverse healthcare applications, comprehensive evaluation through dedicated benchmarks is crucial. However, such datasets remain scarce, especially across diverse languages and contexts. In this paper, we introduce MedErrBench, the first multilingual benchmark for error detection, localization, and correction, developed under the guidance of experienced clinicians. Based on an expanded taxonomy of ten common error types, MedErrBench covers English, Arabic and Chinese, with natural clinical cases annotated and reviewed by domain experts. We assessed the performance of a range of general-purpose, language-specific, and medical-domain language models across all three tasks. Our results reveal notable performance gaps, particularly in non-English settings, highlighting the need for clinically grounded, language-aware systems. By making MedErrBench and our evaluation protocols publicly-available, we aim to advance multilingual clinical NLP to promote safer and more equitable AI-based healthcare globally. The dataset is available in the supplementary material. An anonymized version of the dataset is available at: https://github.com/congboma/MedErrBench.", "AI": {"tldr": "MedErrBench\u662f\u9996\u4e2a\u591a\u8bed\u8a00\u4e34\u5e8a\u6587\u672c\u9519\u8bef\u68c0\u6d4b\u3001\u5b9a\u4f4d\u548c\u7ea0\u6b63\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u82f1\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u548c\u4e2d\u6587\uff0c\u7531\u4e34\u5e8a\u4e13\u5bb6\u6807\u6ce8\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u533b\u7597\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4e34\u5e8a\u6587\u672c\u53ef\u80fd\u5b58\u5728\u4e0d\u51c6\u786e\u4fe1\u606f\uff0c\u53ef\u80fd\u5bfc\u81f4\u8bef\u8bca\u6216\u9519\u8bef\u6cbb\u7597\u5efa\u8bae\u3002\u968f\u7740LLM\u5728\u533b\u7597\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u5168\u9762\u8bc4\u4f30\u5176\u6027\u80fd\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u8de8\u8bed\u8a00\u548c\u8de8\u73af\u5883\u7684\u6b64\u7c7b\u6570\u636e\u96c6\u3002", "method": "\u57fa\u4e8e\u6269\u5c55\u7684\u5341\u79cd\u5e38\u89c1\u9519\u8bef\u7c7b\u578b\u5206\u7c7b\u6cd5\uff0c\u6784\u5efa\u4e86\u6db5\u76d6\u82f1\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u548c\u4e2d\u6587\u7684MedErrBench\u6570\u636e\u96c6\uff0c\u5305\u542b\u771f\u5b9e\u4e34\u5e8a\u6848\u4f8b\u5e76\u7531\u9886\u57df\u4e13\u5bb6\u6807\u6ce8\u548c\u5ba1\u67e5\u3002\u8bc4\u4f30\u4e86\u901a\u7528\u3001\u8bed\u8a00\u7279\u5b9a\u548c\u533b\u7597\u9886\u57df\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u975e\u82f1\u8bed\u73af\u5883\u4e0b\uff0c\u7a81\u663e\u4e86\u9700\u8981\u57fa\u4e8e\u4e34\u5e8a\u77e5\u8bc6\u548c\u8bed\u8a00\u611f\u77e5\u7684\u7cfb\u7edf\u3002\u6a21\u578b\u5728\u9519\u8bef\u68c0\u6d4b\u3001\u5b9a\u4f4d\u548c\u7ea0\u6b63\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u6709\u5f85\u63d0\u5347\u3002", "conclusion": "MedErrBench\u7684\u516c\u5f00\u5c06\u63a8\u52a8\u591a\u8bed\u8a00\u4e34\u5e8aNLP\u7684\u53d1\u5c55\uff0c\u4fc3\u8fdb\u5168\u7403\u66f4\u5b89\u5168\u3001\u66f4\u516c\u5e73\u7684AI\u533b\u7597\u5e94\u7528\u3002\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\u5df2\u516c\u5f00\u63d0\u4f9b\u3002"}}
{"id": "2602.05694", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05694", "abs": "https://arxiv.org/abs/2602.05694", "authors": ["Shuting Jiang", "Ran Song", "Yuxin Huang", "Yan Xiang", "Yantuan Xian", "Shengxiang Gao", "Zhengtao Yu"], "title": "Consensus-Aligned Neuron Efficient Fine-Tuning Large Language Models for Multi-Domain Machine Translation", "comment": "Accepted by AAAI 2026", "summary": "Multi-domain machine translation (MDMT) aims to build a unified model capable of translating content across diverse domains. Despite the impressive machine translation capabilities demonstrated by large language models (LLMs), domain adaptation still remains a challenge for LLMs. Existing MDMT methods such as in-context learning and parameter-efficient fine-tuning often suffer from domain shift, parameter interference and limited generalization. In this work, we propose a neuron-efficient fine-tuning framework for MDMT that identifies and updates consensus-aligned neurons within LLMs. These neurons are selected by maximizing the mutual information between neuron behavior and domain features, enabling LLMs to capture both generalizable translation patterns and domain-specific nuances. Our method then fine-tunes LLMs guided by these neurons, effectively mitigating parameter interference and domain-specific overfitting. Comprehensive experiments on three LLMs across ten German-English and Chinese-English translation domains evidence that our method consistently outperforms strong PEFT baselines on both seen and unseen domains, achieving state-of-the-art performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5171\u8bc6\u5bf9\u9f50\u795e\u7ecf\u5143\u7684\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u9886\u57df\u673a\u5668\u7ffb\u8bd1\uff0c\u901a\u8fc7\u6700\u5927\u5316\u795e\u7ecf\u5143\u884c\u4e3a\u4e0e\u9886\u57df\u7279\u5f81\u7684\u4e92\u4fe1\u606f\u6765\u9009\u62e9\u5173\u952e\u795e\u7ecf\u5143\uff0c\u6709\u6548\u7f13\u89e3\u53c2\u6570\u5e72\u6270\u548c\u9886\u57df\u8fc7\u62df\u5408\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5668\u7ffb\u8bd1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u591a\u9886\u57df\u9002\u5e94\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5b58\u5728\u9886\u57df\u504f\u79fb\u3001\u53c2\u6570\u5e72\u6270\u548c\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u5143\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5927\u5316\u795e\u7ecf\u5143\u884c\u4e3a\u4e0e\u9886\u57df\u7279\u5f81\u7684\u4e92\u4fe1\u606f\u6765\u8bc6\u522b\u548c\u66f4\u65b0\u5171\u8bc6\u5bf9\u9f50\u795e\u7ecf\u5143\uff0c\u8fd9\u4e9b\u795e\u7ecf\u5143\u80fd\u591f\u6355\u6349\u901a\u7528\u7ffb\u8bd1\u6a21\u5f0f\u548c\u9886\u57df\u7279\u5b9a\u7279\u5f81\uff0c\u7136\u540e\u57fa\u4e8e\u8fd9\u4e9b\u795e\u7ecf\u5143\u6307\u5bfc\u5fae\u8c03\u8fc7\u7a0b\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5341\u4e2a\u5fb7\u82f1\u3001\u4e2d\u82f1\u7ffb\u8bd1\u9886\u57df\u4e0a\u7684\u5168\u9762\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5df2\u89c1\u548c\u672a\u89c1\u9886\u57df\u4e0a\u5747\u4f18\u4e8e\u5f3a\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u57fa\u7ebf\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u548c\u5fae\u8c03\u5171\u8bc6\u5bf9\u9f50\u795e\u7ecf\u5143\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u9886\u57df\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\u53c2\u6570\u5e72\u6270\u548c\u9886\u57df\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05711", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05711", "abs": "https://arxiv.org/abs/2602.05711", "authors": ["Jingze Shi", "Zhangyang Peng", "Yizhang Zhu", "Yifan Wu", "Guang Liu", "Yuyu Luo"], "title": "OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale", "comment": null, "summary": "Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-designed framework that pushes expert granularity to its logical extreme. OmniMoE introduces vector-level Atomic Experts, enabling scalable routing and execution within a single MoE layer, while retaining a shared dense MLP branch for general-purpose processing. Although this atomic design maximizes capacity, it poses severe challenges for routing complexity and memory access. To address these, OmniMoE adopts a system-algorithm co-design: (i) a Cartesian Product Router that decomposes the massive index space to reduce routing complexity from O(N) to O(sqrt(N)); and (ii) Expert-Centric Scheduling that inverts the execution order to turn scattered, memory-bound lookups into efficient dense matrix operations. Validated on seven benchmarks, OmniMoE (with 1.7B active parameters) achieves 50.9% zero-shot accuracy across seven benchmarks, outperforming coarse-grained (e.g., DeepSeekMoE) and fine-grained (e.g., PEER) baselines. Crucially, OmniMoE reduces inference latency from 73ms to 6.7ms (a 10.9-fold speedup) compared to PEER, demonstrating that massive-scale fine-grained MoE can be fast and accurate. Our code is open-sourced at https://github.com/flash-algo/omni-moe.", "AI": {"tldr": "OmniMoE\u662f\u4e00\u4e2a\u7cfb\u7edf\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5411\u91cf\u7ea7\u522b\u7684\u539f\u5b50\u4e13\u5bb6\u548c\u521b\u65b0\u7684\u8def\u7531\u8c03\u5ea6\u673a\u5236\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u7ec6\u7c92\u5ea6MoE\u7684\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u5728\u4e13\u5bb6\u7c92\u5ea6\u4e0e\u786c\u4ef6\u6267\u884c\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u6743\u8861\u3002\u7c97\u7c92\u5ea6\u4e13\u5bb6\u9650\u5236\u4e86\u53c2\u6570\u6548\u7387\uff0c\u800c\u7ec6\u7c92\u5ea6\u4e13\u5bb6\u5219\u9762\u4e34\u8def\u7531\u590d\u6742\u5ea6\u548c\u5185\u5b58\u8bbf\u95ee\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faOmniMoE\u6846\u67b6\uff0c\u5305\u542b\uff1a1) \u5411\u91cf\u7ea7\u522b\u7684\u539f\u5b50\u4e13\u5bb6\u5b9e\u73b0\u6781\u81f4\u7ec6\u7c92\u5ea6\uff1b2) \u7b1b\u5361\u5c14\u79ef\u8def\u7531\u5668\u5c06\u8def\u7531\u590d\u6742\u5ea6\u4eceO(N)\u964d\u81f3O(sqrt(N))\uff1b3) \u4e13\u5bb6\u4e2d\u5fc3\u8c03\u5ea6\u5c06\u5206\u6563\u7684\u5185\u5b58\u8bbf\u95ee\u8f6c\u4e3a\u5bc6\u96c6\u77e9\u9635\u8fd0\u7b97\u3002", "result": "\u57287\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOmniMoE\uff0817\u4ebf\u6fc0\u6d3b\u53c2\u6570\uff09\u8fbe\u523050.9%\u7684\u96f6\u6837\u672c\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u7c97\u7c92\u5ea6\u548c\u7ec6\u7c92\u5ea6\u57fa\u7ebf\u3002\u63a8\u7406\u5ef6\u8fdf\u4ece73ms\u964d\u81f36.7ms\uff0c\u5b9e\u73b010.9\u500d\u52a0\u901f\u3002", "conclusion": "OmniMoE\u8bc1\u660e\u4e86\u5927\u89c4\u6a21\u7ec6\u7c92\u5ea6MoE\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u548c\u5feb\u901f\u63a8\u7406\uff0c\u901a\u8fc7\u7cfb\u7edf\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u89e3\u51b3\u4e86\u7ec6\u7c92\u5ea6MoE\u7684\u6548\u7387\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2602.05728", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05728", "abs": "https://arxiv.org/abs/2602.05728", "authors": ["Hao Yang", "Zhiyu Yang", "Xupeng Zhang", "Wei Wei", "Yunjie Zhang", "Lin Yang"], "title": "CompactRAG: Reducing LLM Calls and Token Overhead in Multi-Hop Question Answering", "comment": null, "summary": "Retrieval-augmented generation (RAG) has become a key paradigm for knowledge-intensive question answering. However, existing multi-hop RAG systems remain inefficient, as they alternate between retrieval and reasoning at each step, resulting in repeated LLM calls, high token consumption, and unstable entity grounding across hops. We propose CompactRAG, a simple yet effective framework that decouples offline corpus restructuring from online reasoning.\n  In the offline stage, an LLM reads the corpus once and converts it into an atomic QA knowledge base, which represents knowledge as minimal, fine-grained question-answer pairs. In the online stage, complex queries are decomposed and carefully rewritten to preserve entity consistency, and are resolved through dense retrieval followed by RoBERTa-based answer extraction. Notably, during inference, the LLM is invoked only twice in total - once for sub-question decomposition and once for final answer synthesis - regardless of the number of reasoning hops.\n  Experiments on HotpotQA, 2WikiMultiHopQA, and MuSiQue demonstrate that CompactRAG achieves competitive accuracy while substantially reducing token consumption compared to iterative RAG baselines, highlighting a cost-efficient and practical approach to multi-hop reasoning over large knowledge corpora. The implementation is available at GitHub.", "AI": {"tldr": "CompactRAG \u662f\u4e00\u4e2a\u9ad8\u6548\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u77e5\u8bc6\u5e93\u91cd\u6784\u548c\u5728\u7ebf\u8f7b\u91cf\u63a8\u7406\uff0c\u663e\u8457\u51cf\u5c11\u591a\u8df3\u95ee\u7b54\u4e2d\u7684LLM\u8c03\u7528\u6b21\u6570\u548ctoken\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u8df3RAG\u7cfb\u7edf\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u5728\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u4e2d\u4ea4\u66ff\u8fdb\u884c\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u5bfc\u81f4\u91cd\u590d\u7684LLM\u8c03\u7528\u3001\u9ad8token\u6d88\u8017\u4ee5\u53ca\u8de8\u8df3\u5b9e\u4f53\u5b9a\u4f4d\u4e0d\u7a33\u5b9a\u3002", "method": "1. \u79bb\u7ebf\u9636\u6bb5\uff1aLLM\u4e00\u6b21\u6027\u8bfb\u53d6\u8bed\u6599\u5e93\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u539f\u5b50QA\u77e5\u8bc6\u5e93\uff0c\u5c06\u77e5\u8bc6\u8868\u793a\u4e3a\u6700\u5c0f\u3001\u7ec6\u7c92\u5ea6\u7684\u95ee\u7b54\u5bf9\u3002\n2. \u5728\u7ebf\u9636\u6bb5\uff1a\u5c06\u590d\u6742\u67e5\u8be2\u5206\u89e3\u5e76\u91cd\u5199\u4ee5\u4fdd\u6301\u5b9e\u4f53\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u5bc6\u96c6\u68c0\u7d22\u548cRoBERTa\u7b54\u6848\u63d0\u53d6\u89e3\u51b3\u95ee\u9898\u3002\u6574\u4e2a\u63a8\u7406\u8fc7\u7a0bLLM\u53ea\u8c03\u7528\u4e24\u6b21\uff08\u5b50\u95ee\u9898\u5206\u89e3\u548c\u6700\u7ec8\u7b54\u6848\u5408\u6210\uff09\u3002", "result": "\u5728HotpotQA\u30012WikiMultiHopQA\u548cMuSiQue\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCompactRAG\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u8fed\u4ee3\u5f0fRAG\u57fa\u7ebf\u663e\u8457\u51cf\u5c11\u4e86token\u6d88\u8017\u3002", "conclusion": "CompactRAG\u63d0\u4f9b\u4e86\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u5b9e\u7528\u7684\u591a\u8df3\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u79bb\u7ebf\u8bed\u6599\u91cd\u6784\u548c\u5728\u7ebf\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u7b54\u3002"}}
{"id": "2602.05758", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05758", "abs": "https://arxiv.org/abs/2602.05758", "authors": ["Bowen Ping", "Zijun Chen", "Yiyao Yu", "Tingfeng Hui", "Junchi Yan", "Baobao Chang"], "title": "LongR: Unleashing Long-Context Reasoning via Reinforcement Learning with Dense Utility Rewards", "comment": null, "summary": "Reinforcement Learning has emerged as a key driver for LLM reasoning. This capability is equally pivotal in long-context scenarios--such as long-dialogue understanding and structured data analysis, where the challenge extends beyond consuming tokens to performing rigorous deduction. While existing efforts focus on data synthesis or architectural changes, recent work points out that relying solely on sparse, outcome-only rewards yields limited gains, as such coarse signals are often insufficient to effectively guide the complex long-context reasoning. To address this, we propose LongR, a unified framework that enhances long-context performance by integrating a dynamic \"Think-and-Read\" mechanism, which interleaves reasoning with document consultation, with a contextual density reward based on relative information gain to quantify the utility of the relevant documents. Empirically, LongR achieves a 9% gain on LongBench v2 and consistent improvements on RULER and InfiniteBench, demonstrating robust efficiency in navigating extensive contexts. Furthermore, LongR consistently enhances performance across diverse RL algorithms (e.g., DAPO, GSPO). Finally, we conduct in-depth analyses to investigate the impact of reasoning chain length on efficiency and the model's robustness against distractors.", "AI": {"tldr": "LongR\u662f\u4e00\u4e2a\u901a\u8fc7\u52a8\u6001\"\u601d\u8003\u4e0e\u9605\u8bfb\"\u673a\u5236\u548c\u57fa\u4e8e\u76f8\u5bf9\u4fe1\u606f\u589e\u76ca\u7684\u4e0a\u4e0b\u6587\u5bc6\u5ea6\u5956\u52b1\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6570\u636e\u5408\u6210\u6216\u67b6\u6784\u4fee\u6539\uff0c\u4f46\u4ec5\u4f9d\u8d56\u7a00\u758f\u7684\u3001\u4ec5\u57fa\u4e8e\u7ed3\u679c\u7684\u5956\u52b1\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u6548\u679c\u6709\u9650\uff0c\u56e0\u4e3a\u8fd9\u79cd\u7c97\u7565\u4fe1\u53f7\u4e0d\u8db3\u4ee5\u6709\u6548\u6307\u5bfc\u590d\u6742\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faLongR\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u52a8\u6001\"\u601d\u8003\u4e0e\u9605\u8bfb\"\u673a\u5236\uff0c\u4ea4\u66ff\u8fdb\u884c\u63a8\u7406\u548c\u6587\u6863\u67e5\u9605\uff1b2\uff09\u57fa\u4e8e\u76f8\u5bf9\u4fe1\u606f\u589e\u76ca\u7684\u4e0a\u4e0b\u6587\u5bc6\u5ea6\u5956\u52b1\uff0c\u7528\u4e8e\u91cf\u5316\u76f8\u5173\u6587\u6863\u7684\u6548\u7528\u3002", "result": "\u5728LongBench v2\u4e0a\u83b7\u5f979%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728RULER\u548cInfiniteBench\u4e0a\u4e5f\u6709\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff08\u5982DAPO\u3001GSPO\uff09\u4e0a\u90fd\u80fd\u589e\u5f3a\u6027\u80fd\u3002", "conclusion": "LongR\u901a\u8fc7\u7ed3\u5408\u52a8\u6001\u63a8\u7406-\u9605\u8bfb\u673a\u5236\u548c\u7ec6\u7c92\u5ea6\u5956\u52b1\u8bbe\u8ba1\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5c55\u73b0\u51fa\u5bf9\u5e72\u6270\u4fe1\u606f\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.05769", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05769", "abs": "https://arxiv.org/abs/2602.05769", "authors": ["Adnan Al Ali", "Jind\u0159ich Helcl", "Jind\u0159ich Libovick\u00fd"], "title": "Different Time, Different Language: Revisiting the Bias Against Non-Native Speakers in GPT Detectors", "comment": "This paper was accepted to EACL 2026 Student Research Workshop", "summary": "LLM-based assistants have been widely popularised after the release of ChatGPT. Concerns have been raised about their misuse in academia, given the difficulty of distinguishing between human-written and generated text. To combat this, automated techniques have been developed and shown to be effective, to some extent. However, prior work suggests that these methods often falsely flag essays from non-native speakers as generated, due to their low perplexity extracted from an LLM, which is supposedly a key feature of the detectors. We revisit these statements two years later, specifically in the Czech language setting. We show that the perplexity of texts from non-native speakers of Czech is not lower than that of native speakers. We further examine detectors from three separate families and find no systematic bias against non-native speakers. Finally, we demonstrate that contemporary detectors operate effectively without relying on perplexity.", "AI": {"tldr": "\u4e24\u5e74\u540e\u5bf9\u6377\u514b\u8bed\u73af\u5883\u4e2dLLM\u751f\u6210\u6587\u672c\u68c0\u6d4b\u5668\u7684\u91cd\u65b0\u8bc4\u4f30\u8868\u660e\uff0c\u975e\u6bcd\u8bed\u8005\u6587\u672c\u7684\u56f0\u60d1\u5ea6\u5e76\u4e0d\u4f4e\u4e8e\u6bcd\u8bed\u8005\uff0c\u68c0\u6d4b\u5668\u6ca1\u6709\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u4e14\u73b0\u4ee3\u68c0\u6d4b\u5668\u65e0\u9700\u4f9d\u8d56\u56f0\u60d1\u5ea6\u4e5f\u80fd\u6709\u6548\u5de5\u4f5c\u3002", "motivation": "\u968f\u7740ChatGPT\u7b49LLM\u52a9\u624b\u7684\u666e\u53ca\uff0c\u5b66\u672f\u754c\u62c5\u5fe7\u5176\u88ab\u6ee5\u7528\uff0c\u4f46\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5e38\u56e0\u975e\u6bcd\u8bed\u8005\u6587\u672c\u56f0\u60d1\u5ea6\u8f83\u4f4e\u800c\u9519\u8bef\u6807\u8bb0\u4e3a\u751f\u6210\u6587\u672c\u3002\u672c\u7814\u7a76\u65e8\u5728\u91cd\u65b0\u8bc4\u4f30\u8fd9\u4e9b\u8bf4\u6cd5\u5728\u6377\u514b\u8bed\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u7814\u7a76\u91cd\u65b0\u8bc4\u4f30\u4e86\u975e\u6bcd\u8bed\u8005\u4e0e\u6bcd\u8bed\u8005\u6377\u514b\u8bed\u6587\u672c\u7684\u56f0\u60d1\u5ea6\u5dee\u5f02\uff0c\u5e76\u6d4b\u8bd5\u4e86\u6765\u81ea\u4e09\u4e2a\u4e0d\u540c\u5bb6\u65cf\u7684\u68c0\u6d4b\u5668\u5728\u6377\u514b\u8bed\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790\u5b83\u4eec\u5bf9\u975e\u6bcd\u8bed\u8005\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u95ee\u9898\u3002", "result": "1. \u975e\u6bcd\u8bed\u8005\u7684\u6377\u514b\u8bed\u6587\u672c\u56f0\u60d1\u5ea6\u5e76\u4e0d\u4f4e\u4e8e\u6bcd\u8bed\u8005\uff1b2. \u4e09\u79cd\u68c0\u6d4b\u5668\u5747\u672a\u8868\u73b0\u51fa\u5bf9\u975e\u6bcd\u8bed\u8005\u7684\u7cfb\u7edf\u6027\u504f\u89c1\uff1b3. \u5f53\u4ee3\u68c0\u6d4b\u5668\u65e0\u9700\u4f9d\u8d56\u56f0\u60d1\u5ea6\u4e5f\u80fd\u6709\u6548\u8fd0\u4f5c\u3002", "conclusion": "\u4e0e\u5148\u524d\u7814\u7a76\u76f8\u53cd\uff0c\u5728\u6377\u514b\u8bed\u73af\u5883\u4e2d\uff0c\u975e\u6bcd\u8bed\u8005\u6587\u672c\u5e76\u6ca1\u6709\u8f83\u4f4e\u7684\u56f0\u60d1\u5ea6\uff0c\u68c0\u6d4b\u5668\u4e5f\u6ca1\u6709\u5bf9\u975e\u6bcd\u8bed\u8005\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u3002\u73b0\u4ee3\u68c0\u6d4b\u5668\u5df2\u7ecf\u53d1\u5c55\u5230\u4e0d\u4f9d\u8d56\u56f0\u60d1\u5ea6\u4e5f\u80fd\u6709\u6548\u5de5\u4f5c\u7684\u7a0b\u5ea6\u3002"}}
{"id": "2602.05842", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05842", "abs": "https://arxiv.org/abs/2602.05842", "authors": ["Xiao Yu", "Baolin Peng", "Ruize Xu", "Yelong Shen", "Pengcheng He", "Suman Nath", "Nikhil Singh", "Jiangfeng Gao", "Zhou Yu"], "title": "Reinforcement World Model Learning for LLM-based Agents", "comment": null, "summary": "Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and $\u03c4^2$ Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and $\u03c4^2$ Bench respectively, while matching the performance of expert-data training.", "AI": {"tldr": "RWML\u662f\u4e00\u79cd\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3LLM\u667a\u80fd\u4f53\u5b66\u4e60\u52a8\u4f5c\u6761\u4ef6\u7684\u4e16\u754c\u6a21\u578b\uff0c\u5229\u7528\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u5956\u52b1\u6765\u5bf9\u9f50\u6a21\u578b\u9884\u6d4b\u72b6\u6001\u4e0e\u73af\u5883\u5b9e\u9645\u72b6\u6001\uff0c\u63d0\u5347\u667a\u80fd\u4f53\u5728\u6587\u672c\u73af\u5883\u4e2d\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u5728\u667a\u80fd\u4f53\u4efb\u52a1\u4e2d\u96be\u4ee5\u9884\u6d4b\u52a8\u4f5c\u540e\u679c\u548c\u9002\u5e94\u73af\u5883\u52a8\u6001\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u4e0b\u4e00\u4e2a\u72b6\u6001token\u9884\u6d4b\u8fc7\u4e8e\u5173\u6ce8\u8bcd\u6c47\u5c42\u9762\u800c\u5ffd\u89c6\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u5bb9\u6613\u5bfc\u81f4\u6a21\u578b\u5d29\u6e83\u3002", "method": "\u63d0\u51faRWML\u65b9\u6cd5\uff0c\u5728\u9884\u8bad\u7ec3\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5bf9\u9f50\u6a21\u578b\u751f\u6210\u7684\u6a21\u62df\u4e0b\u4e00\u4e2a\u72b6\u6001\u4e0e\u73af\u5883\u89c2\u5bdf\u5230\u7684\u5b9e\u9645\u4e0b\u4e00\u4e2a\u72b6\u6001\uff0c\u4f7f\u7528\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u5956\u52b1\u8fdb\u884c\u81ea\u76d1\u7763\u5b66\u4e60\u3002\u76f8\u6bd4\u4e0b\u4e00\u4e2a\u72b6\u6001token\u9884\u6d4b\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u66f4\u9c81\u68d2\u7684\u8bad\u7ec3\u4fe1\u53f7\uff0c\u4e0d\u6613\u53d7\u5956\u52b1\u653b\u51fb\u5f71\u54cd\u3002", "result": "\u5728ALFWorld\u548c\u03c4\u00b2 Bench\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cRWML\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u6709\u663e\u8457\u63d0\u5347\u3002\u4e0e\u4efb\u52a1\u6210\u529f\u5956\u52b1\u7ed3\u5408\u65f6\uff0c\u5728ALFWorld\u548c\u03c4\u00b2 Bench\u4e0a\u5206\u522b\u6bd4\u76f4\u63a5\u4efb\u52a1\u6210\u529f\u5956\u52b1RL\u9ad8\u51fa6.9\u548c5.7\u5206\uff0c\u6027\u80fd\u4e0e\u4e13\u5bb6\u6570\u636e\u8bad\u7ec3\u76f8\u5f53\u3002", "conclusion": "RWML\u901a\u8fc7\u81ea\u76d1\u7763\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u6709\u6548\u63d0\u5347\u4e86LLM\u667a\u80fd\u4f53\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b\uff0c\u5728\u4e0d\u9700\u8981\u5916\u90e8\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u4e0e\u4e13\u5bb6\u6570\u636e\u8bad\u7ec3\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u7684\u4e16\u754c\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.05843", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05843", "abs": "https://arxiv.org/abs/2602.05843", "authors": ["Fangzhi Xu", "Hang Yan", "Qiushi Sun", "Jinyang Wu", "Zixian Huang", "Muye Huang", "Jingyang Gong", "Zichen Ding", "Kanzhi Cheng", "Yian Wang", "Xinyu Che", "Zeyi Sun", "Jian Zhang", "Zhangyue Yin", "Haoran Luo", "Xuanjing Huang", "Ben Kao", "Jun Liu", "Qika Lin"], "title": "OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions", "comment": "34 pages", "summary": "The rapid advancement of Large Language Models (LLMs) has catalyzed the development of autonomous agents capable of navigating complex environments. However, existing evaluations primarily adopt a deductive paradigm, where agents execute tasks based on explicitly provided rules and static goals, often within limited planning horizons. Crucially, this neglects the inductive necessity for agents to discover latent transition laws from experience autonomously, which is the cornerstone for enabling agentic foresight and sustaining strategic coherence. To bridge this gap, we introduce OdysseyArena, which re-centers agent evaluation on long-horizon, active, and inductive interactions. We formalize and instantiate four primitives, translating abstract transition dynamics into concrete interactive environments. Building upon this, we establish OdysseyArena-Lite for standardized benchmarking, providing a set of 120 tasks to measure an agent's inductive efficiency and long-horizon discovery. Pushing further, we introduce OdysseyArena-Challenge to stress-test agent stability across extreme interaction horizons (e.g., > 200 steps). Extensive experiments on 15+ leading LLMs reveal that even frontier models exhibit a deficiency in inductive scenarios, identifying a critical bottleneck in the pursuit of autonomous discovery in complex environments. Our code and data are available at https://github.com/xufangzhi/Odyssey-Arena", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86OdysseyArena\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30AI\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u3001\u4e3b\u52a8\u5f52\u7eb3\u5f0f\u4ea4\u4e92\u4e2d\u8868\u73b0\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5ffd\u89c6\u667a\u80fd\u4f53\u4ece\u7ecf\u9a8c\u4e2d\u81ea\u4e3b\u53d1\u73b0\u6f5c\u5728\u8f6c\u79fb\u89c4\u5f8b\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u8bc4\u4f30\u4e3b\u8981\u91c7\u7528\u6f14\u7ece\u8303\u5f0f\uff0c\u57fa\u4e8e\u660e\u786e\u63d0\u4f9b\u7684\u89c4\u5219\u548c\u9759\u6001\u76ee\u6807\u8fdb\u884c\u4efb\u52a1\u6267\u884c\uff0c\u901a\u5e38\u5c40\u9650\u4e8e\u6709\u9650\u7684\u89c4\u5212\u89c6\u91ce\u3002\u8fd9\u5ffd\u89c6\u4e86\u667a\u80fd\u4f53\u4ece\u7ecf\u9a8c\u4e2d\u81ea\u4e3b\u53d1\u73b0\u6f5c\u5728\u8f6c\u79fb\u89c4\u5f8b\u7684\u5f52\u7eb3\u9700\u6c42\uff0c\u800c\u8fd9\u662f\u5b9e\u73b0\u667a\u80fd\u4f53\u524d\u77bb\u6027\u548c\u7ef4\u6301\u6218\u7565\u8fde\u8d2f\u6027\u7684\u5173\u952e\u3002", "method": "\u63d0\u51fa\u4e86OdysseyArena\u6846\u67b6\uff0c\u5c06\u62bd\u8c61\u7684\u8f6c\u79fb\u52a8\u6001\u5f62\u5f0f\u5316\u5e76\u5b9e\u4f8b\u5316\u4e3a\u56db\u4e2a\u57fa\u672c\u539f\u8bed\uff0c\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u4ea4\u4e92\u73af\u5883\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u5efa\u7acb\u4e86OdysseyArena-Lite\u7528\u4e8e\u6807\u51c6\u5316\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b120\u4e2a\u4efb\u52a1\u6765\u6d4b\u91cf\u667a\u80fd\u4f53\u7684\u5f52\u7eb3\u6548\u7387\u548c\u957f\u65f6\u7a0b\u53d1\u73b0\u80fd\u529b\u3002\u8fdb\u4e00\u6b65\u63a8\u51fa\u4e86OdysseyArena-Challenge\u6765\u538b\u529b\u6d4b\u8bd5\u667a\u80fd\u4f53\u5728\u6781\u7aef\u4ea4\u4e92\u65f6\u57df\uff08\u5982\u8d85\u8fc7200\u6b65\uff09\u4e0b\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u5bf915\u4e2a\u4ee5\u4e0a\u9886\u5148\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u5373\u4f7f\u662f\u524d\u6cbf\u6a21\u578b\u5728\u5f52\u7eb3\u573a\u666f\u4e2d\u4e5f\u5b58\u5728\u4e0d\u8db3\uff0c\u63ed\u793a\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u8ffd\u6c42\u81ea\u4e3b\u53d1\u73b0\u7684\u5173\u952e\u74f6\u9888\u3002", "conclusion": "OdysseyArena\u91cd\u65b0\u5c06\u667a\u80fd\u4f53\u8bc4\u4f30\u4e2d\u5fc3\u653e\u5728\u957f\u65f6\u7a0b\u3001\u4e3b\u52a8\u548c\u5f52\u7eb3\u5f0f\u4ea4\u4e92\u4e0a\uff0c\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u7a7a\u767d\uff0c\u5e76\u4e3a\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u53d1\u73b0\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u6807\u51c6\u3002"}}
{"id": "2602.05853", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05853", "abs": "https://arxiv.org/abs/2602.05853", "authors": ["Siran Liu", "Guoxia Wang", "Sa Wang", "Jinle Zeng", "HaoYang Xie", "Siyu Lou", "JiaBin Yang", "DianHai Yu", "Haifeng Wang", "Chao Yang"], "title": "RRAttention: Dynamic Block Sparse Attention via Per-Head Round-Robin Shifts for Long-Context Inference", "comment": null, "summary": "The quadratic complexity of attention mechanisms poses a critical bottleneck for large language models processing long contexts. While dynamic sparse attention methods offer input-adaptive efficiency, they face fundamental trade-offs: requiring preprocessing, lacking global evaluation, violating query independence, or incurring high computational overhead. We present RRAttention, a novel dynamic sparse attention method that simultaneously achieves all desirable properties through a head \\underline{r}ound-\\underline{r}obin (RR) sampling strategy. By rotating query sampling positions across attention heads within each stride, RRAttention maintains query independence while enabling efficient global pattern discovery with stride-level aggregation. Our method reduces complexity from $O(L^2)$ to $O(L^2/S^2)$ and employs adaptive Top-$\u03c4$ selection for optimal sparsity. Extensive experiments on natural language understanding (HELMET) and multimodal video comprehension (Video-MME) demonstrate that RRAttention recovers over 99\\% of full attention performance while computing only half of the attention blocks, achieving 2.4$\\times$ speedup at 128K context length and outperforming existing dynamic sparse attention methods.", "AI": {"tldr": "RRAttention \u662f\u4e00\u79cd\u57fa\u4e8e\u8f6e\u8be2\u91c7\u6837\u7684\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u6ce8\u610f\u529b\u5934\u7684\u8f6e\u8be2\u91c7\u6837\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u67e5\u8be2\u72ec\u7acb\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u5168\u5c40\u6a21\u5f0f\u53d1\u73b0\uff0c\u5c06\u590d\u6742\u5ea6\u4ece O(L\u00b2) \u964d\u4f4e\u5230 O(L\u00b2/S\u00b2)\uff0c\u6062\u590d\u8d85\u8fc799%\u7684\u5b8c\u6574\u6ce8\u610f\u529b\u6027\u80fd\u3002", "motivation": "\u6ce8\u610f\u529b\u673a\u5236\u4e8c\u6b21\u590d\u6742\u5ea6\u662f\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5173\u952e\u74f6\u9888\u3002\u73b0\u6709\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u9762\u4e34\u57fa\u672c\u6743\u8861\uff1a\u9700\u8981\u9884\u5904\u7406\u3001\u7f3a\u4e4f\u5168\u5c40\u8bc4\u4f30\u3001\u8fdd\u53cd\u67e5\u8be2\u72ec\u7acb\u6027\u6216\u8ba1\u7b97\u5f00\u9500\u9ad8\u3002", "method": "\u63d0\u51faRRAttention\u65b9\u6cd5\uff0c\u91c7\u7528\u5934\u90e8\u8f6e\u8be2\u91c7\u6837\u7b56\u7565\uff0c\u5728\u6bcf\u4e2a\u6b65\u5e45\u5185\u8de8\u6ce8\u610f\u529b\u5934\u8f6e\u8be2\u67e5\u8be2\u91c7\u6837\u4f4d\u7f6e\uff0c\u4fdd\u6301\u67e5\u8be2\u72ec\u7acb\u6027\u540c\u65f6\u5b9e\u73b0\u6b65\u5e45\u7ea7\u805a\u5408\u7684\u9ad8\u6548\u5168\u5c40\u6a21\u5f0f\u53d1\u73b0\u3002\u5c06\u590d\u6742\u5ea6\u4eceO(L\u00b2)\u964d\u81f3O(L\u00b2/S\u00b2)\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94Top-\u03c4\u9009\u62e9\u5b9e\u73b0\u6700\u4f18\u7a00\u758f\u6027\u3002", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\uff08HELMET\uff09\u548c\u591a\u6a21\u6001\u89c6\u9891\u7406\u89e3\uff08Video-MME\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRRAttention\u4ec5\u8ba1\u7b97\u4e00\u534a\u6ce8\u610f\u529b\u5757\u5c31\u80fd\u6062\u590d\u8d85\u8fc799%\u7684\u5b8c\u6574\u6ce8\u610f\u529b\u6027\u80fd\uff0c\u5728128K\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u5b9e\u73b02.4\u500d\u52a0\u901f\uff0c\u4f18\u4e8e\u73b0\u6709\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u3002", "conclusion": "RRAttention\u901a\u8fc7\u8f6e\u8be2\u91c7\u6837\u7b56\u7565\u540c\u65f6\u5b9e\u73b0\u4e86\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u7684\u6240\u6709\u7406\u60f3\u7279\u6027\uff0c\u4e3a\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u67e5\u8be2\u72ec\u7acb\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u6062\u590d\u548c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2602.05874", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05874", "abs": "https://arxiv.org/abs/2602.05874", "authors": ["Adri\u00e1n Gir\u00f3n", "Pablo Miralles", "Javier Huertas-Tato", "Sergio D'Antonio", "David Camacho"], "title": "xList-Hate: A Checklist-Based Framework for Interpretable and Generalizable Hate Speech Detection", "comment": null, "summary": "Hate speech detection is commonly framed as a direct binary classification problem despite being a composite concept defined through multiple interacting factors that vary across legal frameworks, platform policies, and annotation guidelines. As a result, supervised models often overfit dataset-specific definitions and exhibit limited robustness under domain shift and annotation noise.\n  We introduce xList-Hate, a diagnostic framework that decomposes hate speech detection into a checklist of explicit, concept-level questions grounded in widely shared normative criteria. Each question is independently answered by a large language model (LLM), producing a binary diagnostic representation that captures hateful content features without directly predicting the final label. These diagnostic signals are then aggregated by a lightweight, fully interpretable decision tree, yielding transparent and auditable predictions.\n  We evaluate it across multiple hate speech benchmarks and model families, comparing it against zero-shot LLM classification and in-domain supervised fine-tuning. While supervised methods typically maximize in-domain performance, we consistently improves cross-dataset robustness and relative performance under domain shift. In addition, qualitative analysis of disagreement cases provides evidence that the framework can be less sensitive to certain forms of annotation inconsistency and contextual ambiguity. Crucially, the approach enables fine-grained interpretability through explicit decision paths and factor-level analysis.\n  Our results suggest that reframing hate speech detection as a diagnostic reasoning task, rather than a monolithic classification problem, provides a robust, explainable, and extensible alternative for content moderation.", "AI": {"tldr": "\u63d0\u51faxList-Hate\u6846\u67b6\uff0c\u5c06\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u5206\u89e3\u4e3a\u57fa\u4e8e\u89c4\u8303\u6807\u51c6\u7684\u8bca\u65ad\u95ee\u9898\u6e05\u5355\uff0c\u901a\u8fc7LLM\u56de\u7b54\u6e05\u5355\u95ee\u9898\uff0c\u518d\u7528\u51b3\u7b56\u6811\u805a\u5408\u7ed3\u679c\uff0c\u63d0\u9ad8\u8de8\u6570\u636e\u96c6\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u901a\u5e38\u88ab\u7b80\u5316\u4e3a\u4e8c\u5143\u5206\u7c7b\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u5ea6\u62df\u5408\u7279\u5b9a\u6570\u636e\u96c6\u7684\u5b9a\u4e49\uff0c\u5728\u9886\u57df\u8f6c\u79fb\u548c\u6807\u6ce8\u566a\u58f0\u4e0b\u9c81\u68d2\u6027\u6709\u9650\u3002\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u4e00\u590d\u6742\u6982\u5ff5\u3002", "method": "\u5f15\u5165xList-Hate\u8bca\u65ad\u6846\u67b6\uff1a1) \u5c06\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u5206\u89e3\u4e3a\u57fa\u4e8e\u5e7f\u6cdb\u5171\u4eab\u89c4\u8303\u6807\u51c6\u7684\u660e\u786e\u6982\u5ff5\u7ea7\u95ee\u9898\u6e05\u5355\uff1b2) \u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u72ec\u7acb\u56de\u7b54\u6bcf\u4e2a\u95ee\u9898\uff0c\u751f\u6210\u4e8c\u8fdb\u5236\u8bca\u65ad\u8868\u793a\uff1b3) \u901a\u8fc7\u8f7b\u91cf\u7ea7\u3001\u5b8c\u5168\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u6811\u805a\u5408\u8fd9\u4e9b\u8bca\u65ad\u4fe1\u53f7\u3002", "result": "\u76f8\u6bd4\u96f6\u6837\u672cLLM\u5206\u7c7b\u548c\u9886\u57df\u5185\u76d1\u7763\u5fae\u8c03\uff0cxList-Hate\u5728\u591a\u4e2a\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u66f4\u597d\u7684\u8de8\u6570\u636e\u96c6\u9c81\u68d2\u6027\u548c\u9886\u57df\u8f6c\u79fb\u6027\u80fd\u3002\u5b9a\u6027\u5206\u6790\u8868\u660e\u6846\u67b6\u5bf9\u67d0\u4e9b\u5f62\u5f0f\u7684\u6807\u6ce8\u4e0d\u4e00\u81f4\u548c\u4e0a\u4e0b\u6587\u6a21\u7cca\u6027\u66f4\u4e0d\u654f\u611f\uff0c\u540c\u65f6\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u5c06\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u91cd\u6784\u4e3a\u8bca\u65ad\u63a8\u7406\u4efb\u52a1\u800c\u975e\u5355\u4e00\u5206\u7c7b\u95ee\u9898\uff0c\u4e3a\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002xList-Hate\u6846\u67b6\u901a\u8fc7\u660e\u786e\u7684\u51b3\u7b56\u8def\u5f84\u548c\u56e0\u7d20\u7ea7\u5206\u6790\u5b9e\u73b0\u4e86\u900f\u660e\u53ef\u5ba1\u8ba1\u7684\u9884\u6d4b\u3002"}}
{"id": "2602.05879", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.05879", "abs": "https://arxiv.org/abs/2602.05879", "authors": ["Miguel Moura Ramos", "Duarte M. Alves", "Hippolyte Gisserot-Boukhlef", "Jo\u00e3o Alves", "Pedro Henrique Martins", "Patrick Fernandes", "Jos\u00e9 Pombal", "Nuno M. Guerreiro", "Ricardo Rei", "Nicolas Boizard", "Amin Farajian", "Mateusz Klimaszewski", "Jos\u00e9 G. C. de Souza", "Barry Haddow", "Fran\u00e7ois Yvon", "Pierre Colombo", "Alexandra Birch", "Andr\u00e9 F. T. Martins"], "title": "EuroLLM-22B: Technical Report", "comment": null, "summary": "This report presents EuroLLM-22B, a large language model trained from scratch to support the needs of European citizens by covering all 24 official European Union languages and 11 additional languages. EuroLLM addresses the issue of European languages being underrepresented and underserved in existing open large language models. We provide a comprehensive overview of EuroLLM-22B's development, including tokenizer design, architectural specifications, data filtering, and training procedures. Across a broad set of multilingual benchmarks, EuroLLM-22B demonstrates strong performance in reasoning, instruction following, and translation, achieving results competitive with models of comparable size. To support future research, we release our base and instruction-tuned models, our multilingual web pretraining data and updated EuroBlocks instruction datasets, as well as our pre-training and evaluation codebases.", "AI": {"tldr": "EuroLLM-22B\u662f\u4e00\u4e2a\u4e13\u4e3a\u6b27\u6d32\u8bed\u8a00\u9700\u6c42\u8bbe\u8ba1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u8986\u76d6\u6b27\u76df24\u79cd\u5b98\u65b9\u8bed\u8a00\u548c11\u79cd\u989d\u5916\u8bed\u8a00\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u5f00\u6e90\u5927\u6a21\u578b\u4e2d\u6b27\u6d32\u8bed\u8a00\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u6b27\u6d32\u8bed\u8a00\u4ee3\u8868\u6027\u4e0d\u8db3\u3001\u670d\u52a1\u4e0d\u5145\u5206\uff0c\u9700\u8981\u4e13\u95e8\u652f\u6301\u6b27\u6d32\u516c\u6c11\u591a\u8bed\u8a00\u9700\u6c42\u7684\u6a21\u578b\u3002", "method": "\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\uff0c\u5305\u62ec\u5206\u8bcd\u5668\u8bbe\u8ba1\u3001\u67b6\u6784\u89c4\u8303\u3001\u6570\u636e\u8fc7\u6ee4\u548c\u8bad\u7ec3\u6d41\u7a0b\u7684\u5168\u9762\u5f00\u53d1\u65b9\u6cd5\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728\u63a8\u7406\u3001\u6307\u4ee4\u9075\u5faa\u548c\u7ffb\u8bd1\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u4e0e\u540c\u7c7b\u89c4\u6a21\u6a21\u578b\u7ade\u4e89\u6027\u76f8\u5f53\u3002", "conclusion": "EuroLLM-22B\u6210\u529f\u586b\u8865\u4e86\u6b27\u6d32\u8bed\u8a00\u5728\u5f00\u6e90\u5927\u6a21\u578b\u4e2d\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u4ee3\u7801\u8d44\u6e90\u3002"}}
{"id": "2602.05897", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05897", "abs": "https://arxiv.org/abs/2602.05897", "authors": ["Shuo Nie", "Hexuan Deng", "Chao Wang", "Ruiyu Fang", "Xuebo Liu", "Shuangyong Song", "Yu Li", "Min Zhang", "Xuelong Li"], "title": "Stop Rewarding Hallucinated Steps: Faithfulness-Aware Step-Level Reinforcement Learning for Small Reasoning Models", "comment": null, "summary": "As large language models become smaller and more efficient, small reasoning models (SRMs) are crucial for enabling chain-of-thought (CoT) reasoning in resource-constrained settings. However, they are prone to faithfulness hallucinations, especially in intermediate reasoning steps. Existing mitigation methods based on online reinforcement learning rely on outcome-based rewards or coarse-grained CoT evaluation, which can inadvertently reinforce unfaithful reasoning when the final answer is correct. To address these limitations, we propose Faithfulness-Aware Step-Level Reinforcement Learning (FaithRL), introducing step-level supervision via explicit faithfulness rewards from a process reward model, together with an implicit truncated resampling strategy that generates contrastive signals from faithful prefixes. Experiments across multiple SRMs and Open-Book QA benchmarks demonstrate that FaithRL consistently reduces hallucinations in both the CoT and final answers, leading to more faithful and reliable reasoning. Code is available at https://github.com/Easy195/FaithRL.", "AI": {"tldr": "FaithRL\u662f\u4e00\u79cd\u57fa\u4e8e\u6b65\u9aa4\u7ea7\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u548c\u622a\u65ad\u91cd\u91c7\u6837\u7b56\u7565\u51cf\u5c11\u5c0f\u63a8\u7406\u6a21\u578b\u5728\u601d\u7ef4\u94fe\u4e2d\u7684\u4e0d\u5fe0\u5b9e\u63a8\u7406\u5e7b\u89c9\u3002", "motivation": "\u5c0f\u63a8\u7406\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u652f\u6301\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\uff0c\u4f46\u5bb9\u6613\u5728\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u4ea7\u751f\u4e0d\u5fe0\u5b9e\u7684\u5e7b\u89c9\u3002\u73b0\u6709\u57fa\u4e8e\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u4f9d\u8d56\u7ed3\u679c\u5956\u52b1\u6216\u7c97\u7c92\u5ea6\u7684\u601d\u7ef4\u94fe\u8bc4\u4f30\uff0c\u53ef\u80fd\u5728\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u65f6\u65e0\u610f\u4e2d\u5f3a\u5316\u4e0d\u5fe0\u5b9e\u63a8\u7406\u3002", "method": "\u63d0\u51faFaithfulness-Aware Step-Level Reinforcement Learning (FaithRL)\uff0c\u5f15\u5165\u6b65\u9aa4\u7ea7\u76d1\u7763\uff1a1) \u901a\u8fc7\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u63d0\u4f9b\u663e\u5f0f\u5fe0\u5b9e\u6027\u5956\u52b1\uff1b2) \u4f7f\u7528\u9690\u5f0f\u622a\u65ad\u91cd\u91c7\u6837\u7b56\u7565\u4ece\u5fe0\u5b9e\u524d\u7f00\u751f\u6210\u5bf9\u6bd4\u4fe1\u53f7\u3002", "result": "\u5728\u591a\u4e2a\u5c0f\u63a8\u7406\u6a21\u578b\u548c\u5f00\u653e\u4e66\u7c4d\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFaithRL\u6301\u7eed\u51cf\u5c11\u4e86\u601d\u7ef4\u94fe\u548c\u6700\u7ec8\u7b54\u6848\u4e2d\u7684\u5e7b\u89c9\uff0c\u5b9e\u73b0\u4e86\u66f4\u5fe0\u5b9e\u53ef\u9760\u7684\u63a8\u7406\u3002", "conclusion": "FaithRL\u901a\u8fc7\u6b65\u9aa4\u7ea7\u5f3a\u5316\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u5c0f\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u4e0d\u5fe0\u5b9e\u63a8\u7406\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u53ef\u9760\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05905", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05905", "abs": "https://arxiv.org/abs/2602.05905", "authors": ["Letian Peng", "Yupeng Hou", "Kun Zhou", "Jingbo Shang"], "title": "Codified Finite-state Machines for Role-playing", "comment": null, "summary": "Modeling latent character states is crucial for consistent and engaging role-playing (RP) with large language models (LLMs). Yet, existing prompting-based approaches mainly capture surface actions, often failing to track the latent states that drive interaction. We revisit finite-state machines (FSMs), long used in game design to model state transitions. While effective in small, well-specified state spaces, traditional hand-crafted, rule-based FSMs struggle to adapt to the open-ended semantic space of RP. To address this, we introduce Codified Finite-State Machines (CFSMs), a framework that automatically codifies textual character profiles into FSMs using LLM-based coding. CFSMs extract key states and transitions directly from the profile, producing interpretable structures that enforce character consistency. To further capture uncertainty and variability, we extend CFSMs into Codified Probabilistic Finite-State Machines (CPFSMs), where transitions are modeled as probability distributions over states. Through both synthetic evaluations and real-world RP scenarios in established artifacts, we demonstrate that CFSM and CPFSM outperform generally applied baselines, verifying effectiveness not only in structured tasks but also in open-ended stochastic state exploration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Codified Finite-State Machines (CFSMs)\u6846\u67b6\uff0c\u5229\u7528LLM\u81ea\u52a8\u5c06\u6587\u672c\u89d2\u8272\u63cf\u8ff0\u7f16\u7801\u4e3a\u6709\u9650\u72b6\u6001\u673a\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u6269\u5c55(CPFSMs)\u5904\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u63d0\u5347\u89d2\u8272\u626e\u6f14\u4e2d\u89d2\u8272\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u63d0\u793a\u7684\u89d2\u8272\u626e\u6f14\u65b9\u6cd5\u4e3b\u8981\u6355\u6349\u8868\u9762\u884c\u4e3a\uff0c\u96be\u4ee5\u8ddf\u8e2a\u9a71\u52a8\u4ea4\u4e92\u7684\u6f5c\u5728\u72b6\u6001\uff0c\u5bfc\u81f4\u89d2\u8272\u4e00\u81f4\u6027\u4e0d\u8db3\u3002\u4f20\u7edf\u624b\u5de5\u6784\u5efa\u7684\u6709\u9650\u72b6\u6001\u673a\u867d\u7136\u80fd\u5efa\u6a21\u72b6\u6001\u8f6c\u6362\uff0c\u4f46\u5728\u5f00\u653e\u5f0f\u7684\u89d2\u8272\u626e\u6f14\u8bed\u4e49\u7a7a\u95f4\u4e2d\u96be\u4ee5\u9002\u5e94\u3002", "method": "\u63d0\u51faCFSMs\u6846\u67b6\uff0c\u5229\u7528LLM\u81ea\u52a8\u4ece\u6587\u672c\u89d2\u8272\u63cf\u8ff0\u4e2d\u63d0\u53d6\u5173\u952e\u72b6\u6001\u548c\u8f6c\u6362\uff0c\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u6709\u9650\u72b6\u6001\u673a\u7ed3\u6784\u3002\u8fdb\u4e00\u6b65\u6269\u5c55\u4e3aCPFSMs\uff0c\u5c06\u8f6c\u6362\u5efa\u6a21\u4e3a\u72b6\u6001\u7684\u6982\u7387\u5206\u5e03\uff0c\u4ee5\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u548c\u53d8\u5f02\u6027\u3002", "result": "\u901a\u8fc7\u5408\u6210\u8bc4\u4f30\u548c\u5b9e\u9645\u89d2\u8272\u626e\u6f14\u573a\u666f\u9a8c\u8bc1\uff0cCFSM\u548cCPFSM\u5728\u7ed3\u6784\u5316\u4efb\u52a1\u548c\u5f00\u653e\u5f0f\u968f\u673a\u72b6\u6001\u63a2\u7d22\u4e2d\u90fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u786e\u4fdd\u89d2\u8272\u4e00\u81f4\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "CFSMs\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u52a8\u5c06\u6587\u672c\u89d2\u8272\u63cf\u8ff0\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u72b6\u6001\u673a\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5efa\u6a21\u548c\u7ef4\u6301\u89d2\u8272\u626e\u6f14\u4e2d\u7684\u6f5c\u5728\u72b6\u6001\uff0c\u63d0\u5347\u4ea4\u4e92\u7684\u4e00\u81f4\u6027\u548c\u6c89\u6d78\u611f\u3002\u6982\u7387\u6269\u5c55\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u7684\u80fd\u529b\u3002"}}
{"id": "2602.05929", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05929", "abs": "https://arxiv.org/abs/2602.05929", "authors": ["Jian Chen", "Zhuoran Wang", "Jiayu Qin", "Ming Li", "Meng Wang", "Changyou Chen", "Yin Chen", "Qizhen Weng", "Yirui Liu"], "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs", "comment": null, "summary": "Large language models rely on kv-caches to avoid redundant computation during autoregressive decoding, but as context length grows, reading and writing the cache can quickly saturate GPU memory bandwidth. Recent work has explored KV-cache compression, yet most approaches neglect the data-dependent nature of kv-caches and their variation across layers. We introduce KV-CoRE KV-cache Compressibility by Rank Evaluation), an SVD-based method for quantifying the data-dependent low-rank compressibility of kv-caches. KV-CoRE computes the optimal low-rank approximation under the Frobenius norm and, being gradient-free and incremental, enables efficient dataset-level, layer-wise evaluation. Using this method, we analyze multiple models and datasets spanning five English domains and sixteen languages, uncovering systematic patterns that link compressibility to model architecture, training data, and language coverage. As part of this analysis, we employ the Normalized Effective Rank as a metric of compressibility and show that it correlates strongly with performance degradation under compression. Our study establishes a principled evaluation framework and the first large-scale benchmark of kv-cache compressibility in LLMs, offering insights for dynamic, data-aware compression and data-centric model development.", "AI": {"tldr": "KV-CoRE\uff1a\u4e00\u79cd\u57fa\u4e8eSVD\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316kv-cache\u7684\u6570\u636e\u76f8\u5173\u4f4e\u79e9\u53ef\u538b\u7f29\u6027\uff0c\u5efa\u7acb\u4e86\u9996\u4e2a\u5927\u89c4\u6a21LLM kv-cache\u53ef\u538b\u7f29\u6027\u57fa\u51c6", "motivation": "\u968f\u7740\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u957f\uff0ckv-cache\u7684\u8bfb\u5199\u64cd\u4f5c\u4f1a\u5feb\u901f\u9971\u548cGPU\u5185\u5b58\u5e26\u5bbd\uff0c\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u5927\u591a\u5ffd\u7565\u4e86kv-cache\u7684\u6570\u636e\u4f9d\u8d56\u6027\u53ca\u5176\u5728\u4e0d\u540c\u5c42\u95f4\u7684\u53d8\u5316", "method": "\u63d0\u51faKV-CoRE\u65b9\u6cd5\uff0c\u57fa\u4e8eSVD\u8ba1\u7b97Frobenius\u8303\u6570\u4e0b\u7684\u6700\u4f18\u4f4e\u79e9\u8fd1\u4f3c\uff0c\u8be5\u65b9\u6cd5\u65e0\u9700\u68af\u5ea6\u4e14\u652f\u6301\u589e\u91cf\u8ba1\u7b97\uff0c\u53ef\u5b9e\u73b0\u6570\u636e\u96c6\u7ea7\u3001\u5c42\u7ea7\u7684\u8bc4\u4f30", "result": "\u5206\u6790\u4e86\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e94\u4e2a\u82f1\u6587\u9886\u57df\u548c\u5341\u516d\u79cd\u8bed\u8a00\uff0c\u53d1\u73b0\u4e86\u53ef\u538b\u7f29\u6027\u4e0e\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u6570\u636e\u548c\u8bed\u8a00\u8986\u76d6\u7684\u7cfb\u7edf\u6027\u5173\u8054\uff0c\u5e76\u8bc1\u660e\u5f52\u4e00\u5316\u6709\u6548\u79e9\u4e0e\u538b\u7f29\u4e0b\u7684\u6027\u80fd\u9000\u5316\u5f3a\u76f8\u5173", "conclusion": "\u5efa\u7acb\u4e86\u539f\u5219\u6027\u8bc4\u4f30\u6846\u67b6\u548c\u9996\u4e2a\u5927\u89c4\u6a21kv-cache\u53ef\u538b\u7f29\u6027\u57fa\u51c6\uff0c\u4e3a\u52a8\u6001\u3001\u6570\u636e\u611f\u77e5\u7684\u538b\u7f29\u548c\u6570\u636e\u4e2d\u5fc3\u7684\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u89c1\u89e3"}}
{"id": "2602.05932", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05932", "abs": "https://arxiv.org/abs/2602.05932", "authors": ["L\u00e9o Labat", "Etienne Ollion", "Fran\u00e7ois Yvon"], "title": "Polyglots or Multitudes? Multilingual LLM Answers to Value-laden Multiple-Choice Questions", "comment": "17 pages, 5 figures (8 pages of references and appendices)", "summary": "Multiple-Choice Questions (MCQs) are often used to assess knowledge, reasoning abilities, and even values encoded in large language models (LLMs). While the effect of multilingualism has been studied on LLM factual recall, this paper seeks to investigate the less explored question of language-induced variation in value-laden MCQ responses. Are multilingual LLMs consistent in their responses across languages, i.e. behave like theoretical polyglots, or do they answer value-laden MCQs depending on the language of the question, like a multitude of monolingual models expressing different values through a single model? We release a new corpus, the Multilingual European Value Survey (MEVS), which, unlike prior work relying on machine translation or ad hoc prompts, solely comprises human-translated survey questions aligned in 8 European languages. We administer a subset of those questions to over thirty multilingual LLMs of various sizes, manufacturers and alignment-fine-tuning status under comprehensive, controlled prompt variations including answer order, symbol type, and tail character. Our results show that while larger, instruction-tuned models display higher overall consistency, the robustness of their responses varies greatly across questions, with certain MCQs eliciting total agreement within and across models while others leave LLM answers split. Language-specific behavior seems to arise in all consistent, instruction-fine-tuned models, but only on certain questions, warranting a further study of the selective effect of preference fine-tuning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ef7\u503c\u89c2\u76f8\u5173\u9009\u62e9\u9898\u4e0a\u7684\u8de8\u8bed\u8a00\u4e00\u81f4\u6027\uff0c\u53d1\u73b0\u867d\u7136\u5927\u578b\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u6574\u4f53\u4e00\u81f4\u6027\u8f83\u9ad8\uff0c\u4f46\u67d0\u4e9b\u95ee\u9898\u4f1a\u5f15\u53d1\u8bed\u8a00\u7279\u5b9a\u884c\u4e3a\uff0c\u8868\u660e\u6a21\u578b\u5e76\u975e\u7406\u8bba\u4e0a\u7684\u591a\u8bed\u8005\u800c\u662f\u8868\u73b0\u51fa\u8bed\u8a00\u4f9d\u8d56\u7684\u4ef7\u503c\u89c2\u8868\u8fbe\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ef7\u503c\u89c2\u76f8\u5173\u9009\u62e9\u9898\u56de\u7b54\u4e2d\u7684\u8de8\u8bed\u8a00\u4e00\u81f4\u6027\u3002\u867d\u7136\u591a\u8bed\u8a00\u5bf9\u4e8b\u5b9e\u56de\u5fc6\u7684\u5f71\u54cd\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u4ef7\u503c\u89c2\u76f8\u5173\u9009\u62e9\u9898\u4e2d\u8bed\u8a00\u5f15\u53d1\u7684\u53d8\u5f02\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u65e8\u5728\u786e\u5b9a\u591a\u8bed\u8a00LLM\u662f\u5426\u50cf\u7406\u8bba\u4e0a\u7684\u591a\u8bed\u8005\u4e00\u6837\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u4fdd\u6301\u4e00\u81f4\uff0c\u8fd8\u662f\u50cf\u591a\u4e2a\u5355\u8bed\u6a21\u578b\u901a\u8fc7\u5355\u4e00\u6a21\u578b\u8868\u8fbe\u4e0d\u540c\u4ef7\u503c\u89c2\u90a3\u6837\u4f9d\u8d56\u95ee\u9898\u8bed\u8a00\u3002", "method": "1. \u53d1\u5e03\u65b0\u7684\u591a\u8bed\u8a00\u6b27\u6d32\u4ef7\u503c\u89c2\u8c03\u67e5\uff08MEVS\uff09\u8bed\u6599\u5e93\uff0c\u5305\u542b8\u79cd\u6b27\u6d32\u8bed\u8a00\u7684\u4eba\u5de5\u7ffb\u8bd1\u8c03\u67e5\u95ee\u9898\uff0c\u907f\u514d\u673a\u5668\u7ffb\u8bd1\u6216\u4e34\u65f6\u63d0\u793a\u95ee\u9898\n2. \u5bf930\u591a\u4e2a\u4e0d\u540c\u89c4\u6a21\u3001\u5236\u9020\u5546\u548c\u5bf9\u9f50\u5fae\u8c03\u72b6\u6001\u7684\u591a\u8bed\u8a00LLM\u8fdb\u884c\u6d4b\u8bd5\n3. \u5728\u5168\u9762\u63a7\u5236\u7684\u63d0\u793a\u53d8\u4f53\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5305\u62ec\u7b54\u6848\u987a\u5e8f\u3001\u7b26\u53f7\u7c7b\u578b\u548c\u5c3e\u5b57\u7b26\n4. \u5206\u6790\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u95ee\u9898\u4e0a\u7684\u54cd\u5e94\u4e00\u81f4\u6027\u548c\u53d8\u5f02", "result": "1. \u8f83\u5927\u3001\u6307\u4ee4\u8c03\u4f18\u7684\u6a21\u578b\u603b\u4f53\u4e0a\u663e\u793a\u51fa\u66f4\u9ad8\u7684\u4e00\u81f4\u6027\n2. \u6a21\u578b\u54cd\u5e94\u7684\u7a33\u5065\u6027\u5728\u4e0d\u540c\u95ee\u9898\u95f4\u5dee\u5f02\u5f88\u5927\uff1a\u67d0\u4e9b\u9009\u62e9\u9898\u5728\u6a21\u578b\u5185\u90e8\u548c\u8de8\u6a21\u578b\u95f4\u5f15\u53d1\u5b8c\u5168\u4e00\u81f4\u7684\u56de\u7b54\uff0c\u800c\u5176\u4ed6\u95ee\u9898\u5219\u5bfc\u81f4LLM\u56de\u7b54\u5206\u88c2\n3. \u6240\u6709\u4e00\u81f4\u7684\u3001\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u4e2d\u4f3c\u4e4e\u90fd\u51fa\u73b0\u4e86\u8bed\u8a00\u7279\u5b9a\u884c\u4e3a\uff0c\u4f46\u4ec5\u5728\u67d0\u4e9b\u95ee\u9898\u4e0a\u51fa\u73b0\n4. \u7ed3\u679c\u8868\u660e\u504f\u597d\u5fae\u8c03\u5bf9\u6a21\u578b\u54cd\u5e94\u6709\u9009\u62e9\u6027\u5f71\u54cd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76", "conclusion": "\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ef7\u503c\u89c2\u76f8\u5173\u9009\u62e9\u9898\u4e0a\u7684\u54cd\u5e94\u5b58\u5728\u8bed\u8a00\u8bf1\u5bfc\u7684\u53d8\u5f02\u3002\u867d\u7136\u5927\u578b\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u6574\u4f53\u4e00\u81f4\u6027\u8f83\u9ad8\uff0c\u4f46\u5b83\u4eec\u5e76\u975e\u7eaf\u7cb9\u7684\u7406\u8bba\u591a\u8bed\u8005\uff0c\u800c\u662f\u5728\u67d0\u4e9b\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8bed\u8a00\u4f9d\u8d56\u7684\u4ef7\u503c\u89c2\u8868\u8fbe\u3002\u8fd9\u8868\u660e\u504f\u597d\u5fae\u8c03\u5bf9\u6a21\u578b\u54cd\u5e94\u7684\u9009\u62e9\u6027\u5f71\u54cd\uff0c\u4ee5\u53ca\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u8bed\u8a00\u5982\u4f55\u5851\u9020LLM\u7684\u4ef7\u503c\u89c2\u8868\u8fbe\u3002"}}
{"id": "2602.05940", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05940", "abs": "https://arxiv.org/abs/2602.05940", "authors": ["Junxiao Liu", "Zhijun Wang", "Yixiao Li", "Zhejian Lai", "Liqian Huang", "Xin Huang", "Xue Han", "Junlan Feng", "Shujian Huang"], "title": "Self-Improving Multilingual Long Reasoning via Translation-Reasoning Integrated Training", "comment": "16 pages, 11 figures", "summary": "Long reasoning models often struggle in multilingual settings: they tend to reason in English for non-English questions; when constrained to reasoning in the question language, accuracies drop substantially. The struggle is caused by the limited abilities for both multilingual question understanding and multilingual reasoning. To address both problems, we propose TRIT (Translation-Reasoning Integrated Training), a self-improving framework that integrates the training of translation into multilingual reasoning. Without external feedback or additional multilingual data, our method jointly enhances multilingual question understanding and response generation. On MMATH, our method outperforms multiple baselines by an average of 7 percentage points, improving both answer correctness and language consistency. Further analysis reveals that integrating translation training improves cross-lingual question alignment by over 10 percentage points and enhances translation quality for both mathematical questions and general-domain text, with gains up to 8.4 COMET points on FLORES-200.", "AI": {"tldr": "\u63d0\u51faTRIT\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u7ffb\u8bd1\u8bad\u7ec3\u63d0\u5347\u591a\u8bed\u8a00\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\u548c\u8bed\u8a00\u4e00\u81f4\u6027", "motivation": "\u73b0\u6709\u957f\u63a8\u7406\u6a21\u578b\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff1a\u503e\u5411\u4e8e\u7528\u82f1\u8bed\u63a8\u7406\u975e\u82f1\u8bed\u95ee\u9898\uff1b\u5f53\u88ab\u7ea6\u675f\u4f7f\u7528\u95ee\u9898\u8bed\u8a00\u63a8\u7406\u65f6\uff0c\u51c6\u786e\u6027\u5927\u5e45\u4e0b\u964d\u3002\u8fd9\u6e90\u4e8e\u591a\u8bed\u8a00\u95ee\u9898\u7406\u89e3\u548c\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u7684\u53cc\u91cd\u4e0d\u8db3\u3002", "method": "\u63d0\u51faTRIT\uff08Translation-Reasoning Integrated Training\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u81ea\u6539\u8fdb\u6846\u67b6\uff0c\u5c06\u7ffb\u8bd1\u8bad\u7ec3\u6574\u5408\u5230\u591a\u8bed\u8a00\u63a8\u7406\u8bad\u7ec3\u4e2d\u3002\u65e0\u9700\u5916\u90e8\u53cd\u9988\u6216\u989d\u5916\u591a\u8bed\u8a00\u6570\u636e\uff0c\u8be5\u65b9\u6cd5\u8054\u5408\u589e\u5f3a\u591a\u8bed\u8a00\u95ee\u9898\u7406\u89e3\u548c\u54cd\u5e94\u751f\u6210\u80fd\u529b\u3002", "result": "\u5728MMATH\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5e73\u5747\u8d85\u8d8a\u591a\u4e2a\u57fa\u7ebf7\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u7b54\u6848\u6b63\u786e\u6027\u548c\u8bed\u8a00\u4e00\u81f4\u6027\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u663e\u793a\uff0c\u6574\u5408\u7ffb\u8bd1\u8bad\u7ec3\u4f7f\u8de8\u8bed\u8a00\u95ee\u9898\u5bf9\u9f50\u63d0\u9ad8\u4e8610\u4e2a\u767e\u5206\u70b9\u4ee5\u4e0a\uff0c\u5e76\u63d0\u5347\u4e86\u5bf9\u6570\u5b66\u95ee\u9898\u548c\u4e00\u822c\u9886\u57df\u6587\u672c\u7684\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5728FLORES-200\u4e0a\u83b7\u5f97\u9ad8\u8fbe8.4 COMET\u5206\u6570\u7684\u589e\u76ca\u3002", "conclusion": "TRIT\u6846\u67b6\u901a\u8fc7\u5c06\u7ffb\u8bd1\u8bad\u7ec3\u6574\u5408\u5230\u591a\u8bed\u8a00\u63a8\u7406\u8bad\u7ec3\u4e2d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8bed\u8a00\u63a8\u7406\u6a21\u578b\u5728\u95ee\u9898\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u7684\u53cc\u91cd\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u591a\u8bed\u8a00\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2602.05971", "categories": ["cs.CL", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.05971", "abs": "https://arxiv.org/abs/2602.05971", "authors": ["Felipe D. Toro-Hern\u00e1ndez", "Jesuino Vieira Filho", "Rodrigo M. Cabral-Carvalho"], "title": "Characterizing Human Semantic Navigation in Concept Production as Trajectories in Embedding Space", "comment": "10 pages, 6 figures (excluding refs/appendix). Accepted to ICLR 2026", "summary": "Semantic representations can be framed as a structured, dynamic knowledge space through which humans navigate to retrieve and manipulate meaning. To investigate how humans traverse this geometry, we introduce a framework that represents concept production as navigation through embedding space. Using different transformer text embedding models, we construct participant-specific semantic trajectories based on cumulative embeddings and extract geometric and dynamical metrics, including distance to next, distance to centroid, entropy, velocity, and acceleration. These measures capture both scalar and directional aspects of semantic navigation, providing a computationally grounded view of semantic representation search as movement in a geometric space. We evaluate the framework on four datasets across different languages, spanning different property generation tasks: Neurodegenerative, Swear verbal fluency, Property listing task in Italian, and in German. Across these contexts, our approach distinguishes between clinical groups and concept types, offering a mathematical framework that requires minimal human intervention compared to typical labor-intensive linguistic pre-processing methods. Comparison with a non-cumulative approach reveals that cumulative embeddings work best for longer trajectories, whereas shorter ones may provide too little context, favoring the non-cumulative alternative. Critically, different embedding models yielded similar results, highlighting similarities between different learned representations despite different training pipelines. By framing semantic navigation as a structured trajectory through embedding space, bridging cognitive modeling with learned representation, thereby establishing a pipeline for quantifying semantic representation dynamics with applications in clinical research, cross-linguistic analysis, and the assessment of artificial cognition.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6982\u5ff5\u4ea7\u751f\u89c6\u4e3a\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5bfc\u822a\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7d2f\u79ef\u5d4c\u5165\u6784\u5efa\u8bed\u4e49\u8f68\u8ff9\u5e76\u63d0\u53d6\u51e0\u4f55\u548c\u52a8\u529b\u5b66\u6307\u6807\uff0c\u7528\u4e8e\u533a\u5206\u4e34\u5e8a\u7ec4\u548c\u6982\u5ff5\u7c7b\u578b\uff0c\u4e3a\u91cf\u5316\u8bed\u4e49\u8868\u5f81\u52a8\u6001\u63d0\u4f9b\u6570\u5b66\u6846\u67b6\u3002", "motivation": "\u4eba\u7c7b\u5982\u4f55\u5728\u8bed\u4e49\u8868\u5f81\u7684\u51e0\u4f55\u7a7a\u95f4\u4e2d\u5bfc\u822a\u4ee5\u68c0\u7d22\u548c\u64cd\u4f5c\u610f\u4e49\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5927\u91cf\u4eba\u5de5\u8bed\u8a00\u9884\u5904\u7406\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u8ba1\u7b97\u57fa\u7840\u6846\u67b6\u6765\u91cf\u5316\u8bed\u4e49\u5bfc\u822a\u7684\u52a8\u6001\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u4e0d\u540c\u7684transformer\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff0c\u57fa\u4e8e\u7d2f\u79ef\u5d4c\u5165\u6784\u5efa\u53c2\u4e0e\u8005\u7279\u5b9a\u7684\u8bed\u4e49\u8f68\u8ff9\uff0c\u63d0\u53d6\u5305\u62ec\u5230\u4e0b\u4e00\u4e2a\u70b9\u7684\u8ddd\u79bb\u3001\u5230\u8d28\u5fc3\u7684\u8ddd\u79bb\u3001\u71b5\u3001\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u7b49\u51e0\u4f55\u548c\u52a8\u529b\u5b66\u6307\u6807\u3002", "result": "\u5728\u56db\u4e2a\u8de8\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u533a\u5206\u4e34\u5e8a\u7ec4\u548c\u6982\u5ff5\u7c7b\u578b\u3002\u7d2f\u79ef\u5d4c\u5165\u5728\u8f83\u957f\u8f68\u8ff9\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u800c\u8f83\u77ed\u8f68\u8ff9\u53ef\u80fd\u66f4\u9002\u5408\u975e\u7d2f\u79ef\u65b9\u6cd5\u3002\u4e0d\u540c\u5d4c\u5165\u6a21\u578b\u4ea7\u751f\u76f8\u4f3c\u7ed3\u679c\uff0c\u8868\u660e\u5b66\u4e60\u8868\u5f81\u4e4b\u95f4\u5b58\u5728\u76f8\u4f3c\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u8bed\u4e49\u5bfc\u822a\u6846\u67b6\u5316\u4e3a\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u7ed3\u6784\u5316\u8f68\u8ff9\uff0c\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u8fde\u63a5\u8ba4\u77e5\u5efa\u6a21\u4e0e\u5b66\u4e60\u8868\u5f81\u7684\u7ba1\u9053\uff0c\u4e3a\u4e34\u5e8a\u7814\u7a76\u3001\u8de8\u8bed\u8a00\u5206\u6790\u548c\u4eba\u5de5\u8ba4\u77e5\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cf\u5316\u8bed\u4e49\u8868\u5f81\u52a8\u6001\u7684\u5de5\u5177\u3002"}}
{"id": "2602.05992", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.05992", "abs": "https://arxiv.org/abs/2602.05992", "authors": ["Lizhuo Luo", "Shenggui Li", "Yonggang Wen", "Tianwei Zhang"], "title": "DSB: Dynamic Sliding Block Scheduling for Diffusion LLMs", "comment": null, "summary": "Diffusion large language models (dLLMs) have emerged as a promising alternative for text generation, distinguished by their native support for parallel decoding. In practice, block inference is crucial for avoiding order misalignment in global bidirectional decoding and improving output quality. However, the widely-used fixed, predefined block (naive) schedule is agnostic to semantic difficulty, making it a suboptimal strategy for both quality and efficiency: it can force premature commitments to uncertain positions while delaying easy positions near block boundaries. In this work, we analyze the limitations of naive block scheduling and disclose the importance of dynamically adapting the schedule to semantic difficulty for reliable and efficient inference. Motivated by this, we propose Dynamic Sliding Block (DSB), a training-free block scheduling method that uses a sliding block with a dynamic size to overcome the rigidity of the naive block. To further improve efficiency, we introduce DSB Cache, a training-free KV-cache mechanism tailored to DSB. Extensive experiments across multiple models and benchmarks demonstrate that DSB, together with DSB Cache, consistently improves both generation quality and inference efficiency for dLLMs. Code is released at https://github.com/lizhuo-luo/DSB.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u52a8\u6001\u6ed1\u52a8\u5757\uff08DSB\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6839\u636e\u8bed\u4e49\u96be\u5ea6\u52a8\u6001\u8c03\u6574\u5757\u5927\u5c0f\uff0c\u4f18\u5316\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e76\u884c\u89e3\u7801\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u4f7f\u7528\u56fa\u5b9a\u7684\u9884\u5b9a\u4e49\u5757\u8c03\u5ea6\u7b56\u7565\uff0c\u8fd9\u79cd\u7b56\u7565\u5bf9\u8bed\u4e49\u96be\u5ea6\u4e0d\u654f\u611f\uff0c\u5bfc\u81f4\u6548\u7387\u548c\u8d28\u91cf\u95ee\u9898\uff1a\u5b83\u53ef\u80fd\u8feb\u4f7f\u6a21\u578b\u8fc7\u65e9\u5730\u5bf9\u4e0d\u786e\u5b9a\u4f4d\u7f6e\u505a\u51fa\u51b3\u7b56\uff0c\u540c\u65f6\u5ef6\u8fdf\u8fb9\u754c\u9644\u8fd1\u7b80\u5355\u4f4d\u7f6e\u7684\u5904\u7406\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u6ed1\u52a8\u5757\uff08DSB\uff09\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u52a8\u6001\u5927\u5c0f\u7684\u6ed1\u52a8\u5757\u6765\u514b\u670d\u56fa\u5b9a\u5757\u7684\u5c40\u9650\u6027\u3002\u540c\u65f6\u5f15\u5165DSB Cache\uff0c\u4e00\u79cd\u4e13\u4e3aDSB\u8bbe\u8ba1\u7684\u65e0\u9700\u8bad\u7ec3\u7684KV\u7f13\u5b58\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDSB\u4e0eDSB Cache\u7ed3\u5408\u80fd\u591f\u4e00\u81f4\u5730\u63d0\u9ad8dLLMs\u7684\u751f\u6210\u8d28\u91cf\u548c\u63a8\u7406\u6548\u7387\u3002", "conclusion": "\u52a8\u6001\u9002\u5e94\u8bed\u4e49\u96be\u5ea6\u7684\u5757\u8c03\u5ea6\u7b56\u7565\u5bf9\u4e8edLLMs\u7684\u53ef\u9760\u9ad8\u6548\u63a8\u7406\u81f3\u5173\u91cd\u8981\uff0cDSB\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u6ed1\u52a8\u5757\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u56fa\u5b9a\u5757\u8c03\u5ea6\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.06015", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.06015", "abs": "https://arxiv.org/abs/2602.06015", "authors": ["Panagiotis Kaliosis", "Adithya V Ganesan", "Oscar N. E. Kjell", "Whitney Ringwald", "Scott Feltman", "Melissa A. Carr", "Dimitris Samaras", "Camilo Ruggero", "Benjamin J. Luft", "Roman Kotov", "Andrew H. Schwartz"], "title": "A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies", "comment": "18 pages, 3 figures, 5 tables", "summary": "Large language models (LLMs) are increasingly being used in a zero-shot fashion to assess mental health conditions, yet we have limited knowledge on what factors affect their accuracy. In this study, we utilize a clinical dataset of natural language narratives and self-reported PTSD severity scores from 1,437 individuals to comprehensively evaluate the performance of 11 state-of-the-art LLMs. To understand the factors affecting accuracy, we systematically varied (i) contextual knowledge like subscale definitions, distribution summary, and interview questions, and (ii) modeling strategies including zero-shot vs few shot, amount of reasoning effort, model sizes, structured subscales vs direct scalar prediction, output rescaling and nine ensemble methods. Our findings indicate that (a) LLMs are most accurate when provided with detailed construct definitions and context of the narrative; (b) increased reasoning effort leads to better estimation accuracy; (c) performance of open-weight models (Llama, Deepseek), plateau beyond 70B parameters while closed-weight (o3-mini, gpt-5) models improve with newer generations; and (d) best performance is achieved when ensembling a supervised model with the zero-shot LLMs. Taken together, the results suggest choice of contextual knowledge and modeling strategies is important for deploying LLMs to accurately assess mental health.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e8611\u79cd\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u8bc4\u4f30\u5fc3\u7406\u5065\u5eb7\u72b6\u51b5\uff08\u7279\u522b\u662fPTSD\uff09\u65f6\u7684\u6027\u80fd\uff0c\u63a2\u8ba8\u4e86\u4e0a\u4e0b\u6587\u77e5\u8bc6\u548c\u5efa\u6a21\u7b56\u7565\u5bf9\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4e8e\u96f6\u6837\u672c\u8bc4\u4f30\u5fc3\u7406\u5065\u5eb7\u72b6\u51b5\uff0c\u4f46\u6211\u4eec\u5bf9\u5176\u51c6\u786e\u6027\u5f71\u54cd\u56e0\u7d20\u4e86\u89e3\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u5168\u9762\u8bc4\u4f30LLMs\u5728\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u8bc6\u522b\u5f71\u54cd\u51c6\u786e\u6027\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u4f7f\u7528\u5305\u542b1,437\u540d\u4e2a\u4f53\u7684\u81ea\u7136\u8bed\u8a00\u53d9\u8ff0\u548c\u81ea\u62a5PTSD\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u5206\u7684\u4e34\u5e8a\u6570\u636e\u96c6\uff0c\u8bc4\u4f3011\u79cd\u6700\u5148\u8fdb\u7684LLMs\u3002\u7cfb\u7edf\u53d8\u5316\uff1a(i)\u4e0a\u4e0b\u6587\u77e5\u8bc6\uff08\u5b50\u91cf\u8868\u5b9a\u4e49\u3001\u5206\u5e03\u6458\u8981\u3001\u8bbf\u8c08\u95ee\u9898\uff09\uff1b(ii)\u5efa\u6a21\u7b56\u7565\uff08\u96f6\u6837\u672cvs\u5c11\u6837\u672c\u3001\u63a8\u7406\u91cf\u3001\u6a21\u578b\u5927\u5c0f\u3001\u7ed3\u6784\u5316\u5b50\u91cf\u8868vs\u76f4\u63a5\u6807\u91cf\u9884\u6d4b\u3001\u8f93\u51fa\u91cd\u7f29\u653e\u30019\u79cd\u96c6\u6210\u65b9\u6cd5\uff09\u3002", "result": "\u4e3b\u8981\u53d1\u73b0\uff1a(a)\u63d0\u4f9b\u8be6\u7ec6\u6784\u5ff5\u5b9a\u4e49\u548c\u53d9\u8ff0\u4e0a\u4e0b\u6587\u65f6LLMs\u6700\u51c6\u786e\uff1b(b)\u589e\u52a0\u63a8\u7406\u91cf\u53ef\u63d0\u9ad8\u4f30\u8ba1\u51c6\u786e\u6027\uff1b(c)\u5f00\u6e90\u6a21\u578b\u53c2\u6570\u8d85\u8fc770B\u540e\u6027\u80fd\u8d8b\u4e8e\u5e73\u7a33\uff0c\u800c\u95ed\u6e90\u6a21\u578b\u968f\u65b0\u4e00\u4ee3\u6539\u8fdb\uff1b(d)\u76d1\u7763\u6a21\u578b\u4e0e\u96f6\u6837\u672cLLMs\u96c6\u6210\u53ef\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u77e5\u8bc6\u548c\u5efa\u6a21\u7b56\u7565\u7684\u9009\u62e9\u5bf9\u4e8e\u90e8\u7f72LLMs\u51c6\u786e\u8bc4\u4f30\u5fc3\u7406\u5065\u5eb7\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u4f18\u5316LLMs\u5728\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6307\u5bfc\u3002"}}
{"id": "2602.06019", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06019", "abs": "https://arxiv.org/abs/2602.06019", "authors": ["John Kirchenbauer", "Abhimanyu Hans", "Brian Bartoldson", "Micah Goldblum", "Ashwinee Panda", "Tom Goldstein"], "title": "Multi-Token Prediction via Self-Distillation", "comment": "8 pages and 5 figures in the main body", "summary": "Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online distillation objective. The final model retains the exact same implementation as the pretrained initial checkpoint and is deployable without the addition of any auxiliary verifier or other specialized inference code. On GSM8K, our method produces models that can decode more than $3\\times$ faster on average at $<5\\%$ drop in accuracy relative to single token decoding performance.", "AI": {"tldr": "\u901a\u8fc7\u5728\u7ebf\u84b8\u998f\u5c06\u5355token\u9884\u6d4b\u6a21\u578b\u8f6c\u6362\u4e3a\u591atoken\u9884\u6d4b\u6a21\u578b\uff0c\u5b9e\u73b03\u500d\u4ee5\u4e0a\u7684\u89e3\u7801\u52a0\u901f\uff0c\u4e14\u65e0\u9700\u8f85\u52a9\u6a21\u578b\u6216\u590d\u6742\u63a8\u7406\u7ba1\u9053\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u52a0\u901f\u6280\u672f\uff08\u5982\u63a8\u6d4b\u89e3\u7801\uff09\u9700\u8981\u8bad\u7ec3\u8f85\u52a9\u63a8\u6d4b\u5668\u6a21\u578b\u5e76\u6784\u5efa\u590d\u6742\u7684\u63a8\u7406\u7ba1\u9053\uff0c\u90e8\u7f72\u548c\u7ef4\u62a4\u6210\u672c\u9ad8\u3002\u672c\u6587\u5bfb\u6c42\u66f4\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u52a0\u901f\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5728\u7ebf\u84b8\u998f\u65b9\u6cd5\uff0c\u5c06\u9884\u8bad\u7ec3\u7684\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4ece\u5355token\u9884\u6d4b\u6a21\u578b\u8f6c\u6362\u4e3a\u72ec\u7acb\u7684\u591atoken\u9884\u6d4b\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u7b80\u5355\u7684\u84b8\u998f\u76ee\u6807\uff0c\u6700\u7ec8\u6a21\u578b\u4e0e\u521d\u59cb\u68c0\u67e5\u70b9\u4fdd\u6301\u5b8c\u5168\u76f8\u540c\u7684\u5b9e\u73b0\uff0c\u65e0\u9700\u989d\u5916\u9a8c\u8bc1\u5668\u6216\u4e13\u7528\u63a8\u7406\u4ee3\u7801\u3002", "result": "\u5728GSM8K\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4f7f\u6a21\u578b\u5e73\u5747\u89e3\u7801\u901f\u5ea6\u63d0\u53473\u500d\u4ee5\u4e0a\uff0c\u51c6\u786e\u7387\u4e0b\u964d\u5c0f\u4e8e5%\uff08\u76f8\u5bf9\u4e8e\u5355token\u89e3\u7801\u6027\u80fd\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u52a0\u901f\u65b9\u6848\uff0c\u65e0\u9700\u590d\u6742\u7684\u8f85\u52a9\u6a21\u578b\u6216\u4e13\u7528\u63a8\u7406\u7ba1\u9053\uff0c\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u90e8\u7f72\u4fbf\u5229\u6027\u3002"}}
{"id": "2602.06025", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06025", "abs": "https://arxiv.org/abs/2602.06025", "authors": ["Haozhen Zhang", "Haodong Yue", "Tao Feng", "Quanyu Long", "Jianzhu Bao", "Bowen Jin", "Weizhi Zhang", "Xiao Li", "Jiaxuan You", "Chengwei Qin", "Wenya Wang"], "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory", "comment": "Code is available at https://github.com/ViktorAxelsen/BudgetMem", "summary": "Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \\textbf{BudgetMem}, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., \\textsc{Low}/\\textsc{Mid}/\\textsc{High}). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.", "AI": {"tldr": "BudgetMem\u662f\u4e00\u4e2a\u8fd0\u884c\u65f6\u4ee3\u7406\u5185\u5b58\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u7ea7\u9884\u7b97\u63a7\u5236\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5728\u4efb\u52a1\u6027\u80fd\u548c\u5185\u5b58\u6784\u5efa\u6210\u672c\u4e4b\u95f4\u63d0\u4f9b\u660e\u786e\u7684\u6743\u8861\u63a7\u5236\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u7cfb\u7edf\u5927\u591a\u4f9d\u8d56\u79bb\u7ebf\u7684\u3001\u67e5\u8be2\u65e0\u5173\u7684\u5185\u5b58\u6784\u5efa\u65b9\u5f0f\uff0c\u8fd9\u79cd\u65b9\u5f0f\u6548\u7387\u4f4e\u4e0b\u4e14\u53ef\u80fd\u4e22\u5f03\u5173\u952e\u4fe1\u606f\u3002\u8fd0\u884c\u65f6\u5185\u5b58\u5229\u7528\u867d\u7136\u81ea\u7136\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5e26\u6765\u663e\u8457\u5f00\u9500\u4e14\u7f3a\u4e4f\u5bf9\u6027\u80fd-\u6210\u672c\u6743\u8861\u7684\u660e\u786e\u63a7\u5236\u3002", "method": "BudgetMem\u5c06\u5185\u5b58\u5904\u7406\u7ed3\u6784\u5316\u4e3a\u4e00\u7ec4\u5185\u5b58\u6a21\u5757\uff0c\u6bcf\u4e2a\u6a21\u5757\u63d0\u4f9b\u4f4e/\u4e2d/\u9ad8\u4e09\u4e2a\u9884\u7b97\u5c42\u7ea7\u3002\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u8fdb\u884c\u6a21\u5757\u95f4\u7684\u9884\u7b97\u5c42\u7ea7\u8def\u7531\uff0c\u8be5\u8def\u7531\u5668\u4f5c\u4e3a\u7d27\u51d1\u7684\u795e\u7ecf\u7b56\u7565\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002\u7814\u7a76\u4e86\u4e09\u79cd\u5b9e\u73b0\u9884\u7b97\u5c42\u7ea7\u7684\u7b56\u7565\uff1a\u5b9e\u73b0\u590d\u6742\u5ea6\u3001\u63a8\u7406\u884c\u4e3a\u548c\u6a21\u5757\u6a21\u578b\u5927\u5c0f\u3002", "result": "\u5728LoCoMo\u3001LongMemEval\u548cHotpotQA\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBudgetMem\u5728\u4f18\u5148\u6027\u80fd\u65f6\uff08\u9ad8\u9884\u7b97\u8bbe\u7f6e\uff09\u8d85\u8d8a\u5f3a\u57fa\u7ebf\uff0c\u5728\u9884\u7b97\u66f4\u7d27\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u51c6\u786e\u7387-\u6210\u672c\u8fb9\u754c\u3002\u5206\u6790\u63ed\u793a\u4e86\u4e0d\u540c\u5c42\u7ea7\u7b56\u7565\u7684\u4f18\u52bf\u548c\u5f31\u70b9\uff0c\u660e\u786e\u4e86\u5728\u4e0d\u540c\u9884\u7b97\u673a\u5236\u4e0b\u6bcf\u79cd\u7b56\u7565\u7684\u6700\u4f73\u5e94\u7528\u573a\u666f\u3002", "conclusion": "BudgetMem\u4e3aLLM\u4ee3\u7406\u5185\u5b58\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u8fd0\u884c\u65f6\u6846\u67b6\uff0c\u901a\u8fc7\u660e\u786e\u7684\u9884\u7b97\u63a7\u5236\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6210\u672c\u4e4b\u95f4\u7684\u7075\u6d3b\u6743\u8861\uff0c\u4e3a\u4e0d\u540c\u9884\u7b97\u673a\u5236\u4e0b\u7684\u5185\u5b58\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.06036", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.06036", "abs": "https://arxiv.org/abs/2602.06036", "authors": ["Jian Chen", "Yesheng Liang", "Zhijian Liu"], "title": "DFlash: Block Diffusion for Flash Speculative Decoding", "comment": null, "summary": "Autoregressive large language models (LLMs) deliver strong performance but require inherently sequential decoding, leading to high inference latency and poor GPU utilization. Speculative decoding mitigates this bottleneck by using a fast draft model whose outputs are verified in parallel by the target LLM; however, existing methods still rely on autoregressive drafting, which remains sequential and limits practical speedups. Diffusion LLMs offer a promising alternative by enabling parallel generation, but current diffusion models typically underperform compared with autoregressive models. In this paper, we introduce DFlash, a speculative decoding framework that employs a lightweight block diffusion model for parallel drafting. By generating draft tokens in a single forward pass and conditioning the draft model on context features extracted from the target model, DFlash enables efficient drafting with high-quality outputs and higher acceptance rates. Experiments show that DFlash achieves over 6x lossless acceleration across a range of models and tasks, delivering up to 2.5x higher speedup than the state-of-the-art speculative decoding method EAGLE-3.", "AI": {"tldr": "DFlash \u662f\u4e00\u4e2a\u63a8\u6d4b\u89e3\u7801\u6846\u67b6\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5757\u6269\u6563\u6a21\u578b\u8fdb\u884c\u5e76\u884c\u8349\u7a3f\u751f\u6210\uff0c\u76f8\u6bd4\u4f20\u7edf\u81ea\u56de\u5f52\u8349\u7a3f\u6a21\u578b\u80fd\u5b9e\u73b0\u66f4\u9ad8\u7684\u52a0\u901f\u6bd4\u3002", "motivation": "\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9700\u8981\u987a\u5e8f\u89e3\u7801\uff0c\u5bfc\u81f4\u63a8\u7406\u5ef6\u8fdf\u9ad8\u4e14GPU\u5229\u7528\u7387\u4f4e\u3002\u867d\u7136\u63a8\u6d4b\u89e3\u7801\u901a\u8fc7\u5feb\u901f\u8349\u7a3f\u6a21\u578b\u6765\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4ecd\u4f9d\u8d56\u81ea\u56de\u5f52\u8349\u7a3f\u751f\u6210\uff0c\u8fd9\u4ecd\u7136\u662f\u987a\u5e8f\u7684\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u52a0\u901f\u6548\u679c\u3002\u6269\u6563LLMs\u63d0\u4f9b\u4e86\u5e76\u884c\u751f\u6210\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5f53\u524d\u6269\u6563\u6a21\u578b\u901a\u5e38\u6027\u80fd\u4e0d\u5982\u81ea\u56de\u5f52\u6a21\u578b\u3002", "method": "DFlash \u91c7\u7528\u8f7b\u91cf\u7ea7\u5757\u6269\u6563\u6a21\u578b\u8fdb\u884c\u5e76\u884c\u8349\u7a3f\u751f\u6210\uff0c\u901a\u8fc7\u5355\u6b21\u524d\u5411\u4f20\u64ad\u751f\u6210\u8349\u7a3f\u6807\u8bb0\uff0c\u5e76\u5c06\u8349\u7a3f\u6a21\u578b\u6761\u4ef6\u5316\u4e8e\u4ece\u76ee\u6807\u6a21\u578b\u4e2d\u63d0\u53d6\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u8f93\u51fa\u548c\u9ad8\u63a5\u53d7\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDFlash \u5728\u5404\u79cd\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc76\u500d\u7684\u65e0\u635f\u52a0\u901f\uff0c\u6bd4\u6700\u5148\u8fdb\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5EAGLE-3\u63d0\u4f9b\u9ad8\u8fbe2.5\u500d\u7684\u52a0\u901f\u6bd4\u3002", "conclusion": "DFlash \u901a\u8fc7\u7ed3\u5408\u6269\u6563\u6a21\u578b\u7684\u5e76\u884c\u751f\u6210\u80fd\u529b\u548c\u63a8\u6d4b\u89e3\u7801\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f93\u51fa\u8d28\u91cf\uff0c\u4e3a\u89e3\u51b3\u81ea\u56de\u5f52\u6a21\u578b\u63a8\u7406\u74f6\u9888\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
