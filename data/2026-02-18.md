<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.IR](#cs.IR) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: EduResearchBench是首个专门评估教育领域学术写作能力的平台，通过HATD框架将完整研究流程分解为6个模块24个原子任务，提供细粒度诊断，并采用课程学习策略训练EduWrite模型，在垂直领域超越更大规模通用模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在社会科学领域的评估主要关注单次、整体生成，缺乏对复杂学术研究流程的细粒度评估，无法反映具体能力瓶颈，需要更精细的评估平台。

Method: 提出EduResearchBench评估平台，基于HATD框架将端到端研究流程分解为6个专业研究模块和24个细粒度原子任务；采用课程学习策略从基础技能逐步构建复杂方法论推理能力；利用55K原始学术样本，构建11K高质量指令对训练EduWrite模型。

Result: EduWrite（30B参数）在多个核心指标上显著超越更大规模的通用模型（72B参数），证明在垂直领域中，数据质量密度和分层训练课程比参数规模更具决定性。

Conclusion: 在垂直领域如教育学术写作中，细粒度的任务分解、自动化的评估管道、课程学习策略以及高质量数据比单纯的模型参数规模更重要，EduResearchBench为LLM在学术写作能力的评估提供了新范式。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [2] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: Indic-TunedLens是针对印度语言的多语言大语言模型可解释性框架，通过学习共享仿射变换，比标准Logit Lens更准确地解码模型中间表示，特别是在形态丰富、资源匮乏的语言上表现优异。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型在印度等语言多样化地区部署越来越多，但现有可解释性工具主要针对英语设计。研究发现LLMs通常在英语中心表示空间中操作，跨语言可解释性成为紧迫问题。

Method: 提出Indic-TunedLens框架，专门为印度语言学习共享仿射变换。与直接解码中间激活的标准Logit Lens不同，该框架调整每个目标语言的隐藏状态，使其与目标输出分布对齐，从而实现更忠实的模型表示解码。

Result: 在10种印度语言上使用MMLU基准进行评估，发现该方法显著优于现有最先进的可解释性方法，特别是在形态丰富、资源匮乏的语言上表现突出。结果提供了对多语言变压器层间语义编码的重要见解。

Conclusion: Indic-TunedLens为解决多语言LLMs在非英语语言上的可解释性挑战提供了有效解决方案，通过语言特定的表示对齐改善了跨语言解释的准确性，为理解多语言模型内部表示机制提供了新视角。

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at https://huggingface.co/spaces/AnonymousAccountACL/IndicTunedLens. Our code is available at https://github.com/AnonymousAccountACL/IndicTunedLens.

</details>


### [3] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: CGRA DeBERTa：一种面向伊斯兰教圣训问答的概念引导残差域增强Transformer框架，在保持计算效率的同时显著提升了神学QA的准确性


<details>
  <summary>Details</summary>
Motivation: 传统的伊斯兰经典文本问答面临领域特定语义、长上下文依赖和概念敏感推理的挑战，需要更精准的神学理解能力

Method: 基于定制化DeBERTa Transformer骨干网络，结合轻量级LoRA适配和残差概念感知门控机制，利用包含12个核心术语的伊斯兰概念词典融入神学先验知识

Result: 在42,591个圣训QA对数据集上，CGRA DeBERTa获得97.85的EM分数，显著优于BERT（75.87）和DeBERTa（89.77），仅增加约8%的推理开销

Conclusion: CGRA DeBERTa为伊斯兰圣训问答提供了高效、可解释且准确的解决方案，能够为教育材料提供必要的神学细微差别

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [4] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 提出一个结合检索增强生成和反向图像搜索的系统，在AVerImaTeC任务中获第3名，成本低且易复现


<details>
  <summary>Details</summary>
Motivation: 构建一个简单、经济且易于复现的多模态事实核查系统，为后续研究提供可访问的起点

Method: 结合去年的RAG流水线与反向图像搜索模块，包含三个解耦模块：基于相似性搜索的文本检索、基于API访问的RIS图像检索、使用GPT5.1的生成模块

Result: 系统在AVerImaTeC任务中获第3名，每次事实核查仅需一次多模态LLM调用，平均成本约0.013美元，性能具有竞争力

Conclusion: 该系统提供了一个简单、经济、易复现的事实核查框架，适合作为进一步实验的基础，作者开源了代码、提示词和向量存储

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [5] [OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction](https://arxiv.org/abs/2602.15197)
*Skyler Hallinan,Thejas Venkatesh,Xiang Ren,Sai Praneeth Karimireddy,Ashwin Paranjape,Yuhao Zhang,Jack Hessel*

Main category: cs.CL

TL;DR: 该论文提出了OpaqueToolsBench基准测试来评估LLM在模糊工具环境中的表现，并开发了ToolObserver框架通过迭代观察执行反馈来改进工具文档，显著提升了性能并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试假设工具简单且文档完善，但现实世界中的工具（如通用"搜索"API）往往是模糊不清的，缺乏明确的最佳实践和失败模式说明。需要研究LLM智能体能否通过与模糊工具的交互来改进文档并提升性能。

Method: 1. 创建OpaqueToolsBench基准测试，包含三个任务导向环境：通用函数调用、交互式象棋对弈、长轨迹智能体搜索，每个环境都提供规范不明确的工具；2. 提出ToolObserver框架，通过迭代观察工具调用轨迹的执行反馈来优化工具文档；3. 在基准测试上评估现有方法和提出的方法。

Result: 1. 现有自动文档生成方法在模糊工具环境中昂贵且不可靠；2. ToolObserver框架在OpaqueToolsBench所有数据集上优于现有方法，即使在相对困难的环境中；3. 在测试时工具探索设置中，该方法效率高，比最佳基线消耗少3.5-7.5倍的总tokens。

Conclusion: ToolObserver框架通过迭代观察执行反馈来改进模糊工具的文档，有效提升了LLM智能体在现实世界任务中的性能，同时显著降低了计算成本，为解决模糊工具环境中的挑战提供了实用解决方案。

Abstract: Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.

</details>


### [6] [Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement](https://arxiv.org/abs/2602.15312)
*Stephan Ludwig,Peter J. Danaher,Xiaohao Yang,Yu-Ting Lin,Ehsan Abedin,Dhruv Grewal,Lan Du*

Main category: cs.CL

TL;DR: 开发了基于大语言模型的消费者情感提取器LX，在消费者文本情感分析上超越GPT-4等主流模型，准确率超80%，并应用于在线零售数据分析


<details>
  <summary>Details</summary>
Motivation: 从非结构化文本中准确测量消费者情感和评价是营销研究的核心挑战，需要更精确的测量工具

Method: 开发了Linguistic eXtractor (LX)，这是一个基于消费者撰写文本微调的大语言模型，训练数据包含消费者自我报告的16种消费相关情感和4种评价构念（信任、承诺、推荐、情感）

Result: LX在开放式调查回复中达到81%的宏观F1准确率，在第三方标注的亚马逊和Yelp评论中准确率超过95%，优于GPT-4 Turbo、RoBERTa和DeepSeek等主流模型

Conclusion: LX为消费者感知测量建立了新的方法论基础，通过无代码、免费的网络应用支持大规模消费者文本分析，证明情感分析能提供超越星级评分的有效信号

Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.

</details>


### [7] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: Mnemis是一个结合系统1相似性检索和系统2全局选择的新型记忆框架，通过双层图结构实现语义和结构相关的记忆检索，在长期记忆基准测试中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有记忆检索方法（如RAG和Graph-RAG）主要依赖相似性机制，这种系统1风格的检索在处理需要全局推理或全面覆盖相关信息的场景时存在局限。

Method: Mnemis将记忆组织为基础图用于相似性检索，同时构建分层图支持自上而下的语义层次遍历。结合系统1相似性搜索和系统2全局选择机制，实现语义和结构相关的记忆检索。

Result: Mnemis在所有对比方法中实现了最先进的性能，在LoCoMo基准上得分93.9，在LongMemEval-S基准上使用GPT-4.1-mini得分91.6。

Conclusion: Mnemis通过整合系统1和系统2检索机制，有效解决了现有相似性检索方法的局限性，为LLMs提供了更全面、更智能的记忆检索能力。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [8] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: NeuroSymActive是一个用于知识图谱问答的模块化框架，结合了可微神经符号推理层和主动价值引导探索控制器，在保持高准确率的同时减少了昂贵的图查询和模型调用。


<details>
  <summary>Details</summary>
Motivation: 尽管大型预训练语言模型和神经推理系统在许多自然语言任务上取得了进展，但在需要精确、结构化多跳推理的知识密集型查询上仍然面临挑战。知识图谱提供了紧凑的符号化事实基础，但将图结构与神经模型集成并非易事：简单地将图事实嵌入提示会导致效率低下和脆弱性，而纯符号或搜索密集型方法在检索上成本高昂且缺乏基于梯度的优化。

Method: NeuroSymActive是一个模块化框架，结合了可微神经符号推理层和主动价值引导探索控制器。该方法将软统一风格的符号模块与神经路径评估器以及蒙特卡洛风格的探索策略相结合，优先考虑高价值路径扩展。

Result: 在标准KGQA基准测试上的实证结果表明，NeuroSymActive在保持强答案准确率的同时，相比常见的检索增强基线方法，减少了昂贵的图查找和模型调用次数。

Conclusion: NeuroSymActive通过将神经符号推理与主动探索相结合，为知识图谱问答提供了一个有效的解决方案，在准确性和效率之间取得了良好的平衡，克服了现有方法在集成图结构和神经模型方面的局限性。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [9] [Far Out: Evaluating Language Models on Slang in Australian and Indian English](https://arxiv.org/abs/2602.15373)
*Deniz Kaya Dilsiz,Dipankar Srirag,Aditya Joshi*

Main category: cs.CL

TL;DR: 该研究评估了语言模型对印度英语和澳大利亚英语中俚语的识别能力，发现模型在判别任务上表现优于生成任务，且对印度英语俚语的理解优于澳大利亚英语。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理非标准语言变体时存在系统性性能差距，但对特定语言变体中俚语的理解能力尚未得到充分探索，特别是在印度英语和澳大利亚英语等变体中的俚语理解。

Method: 研究构建了两个互补数据集：web数据集（从Urban Dictionary收集的377个真实使用示例）和gen数据集（1,492个合成生成的俚语使用场景）。评估了7个最先进的语言模型在三个任务上的表现：目标词预测（TWP）、引导目标词预测（TWP*）和目标词选择（TWS）。

Result: 研究发现：(1) TWS任务的平均性能优于TWP和TWP*，平均准确率从0.03提升到0.49；(2) web数据集的平均性能优于gen数据集，TWP和TWP*任务的平均相似度分别提高0.03和0.05；(3) 印度英语任务在所有模型和数据集上的平均表现优于澳大利亚英语，TWS任务差异最大，平均准确率从0.44提升到0.54。

Conclusion: 研究揭示了语言模型在生成和判别能力方面对特定语言变体俚语理解存在根本性不对称，即使在英语这样技术丰富的语言中，模型对俚语的理解仍有显著差距。

Abstract: Language models exhibit systematic performance gaps when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang remains underexplored for several languages. We present a comprehensive evaluation of slang awareness in Indian English (en-IN) and Australian English (en-AU) across seven state-of-the-art language models. We construct two complementary datasets: \textsc{web}, containing 377 web-sourced usage examples from Urban Dictionary, and \textsc{gen}, featuring 1,492 synthetically generated usages of these slang terms, across diverse scenarios. We assess language models on three tasks: target word prediction (TWP), guided target word prediction (TWP$^*$) and target word selection (TWS). Our results reveal four key findings: (1) Higher average model performance TWS versus TWP and TWP$^*$, with average accuracy score increasing from 0.03 to 0.49 respectively (2) Stronger average model performance on \textsc{web} versus \textsc{gen} datasets, with average similarity score increasing by 0.03 and 0.05 across TWP and TWP$^*$ tasks respectively (3) en-IN tasks outperform en-AU when averaged across all models and datasets, with TWS demonstrating the largest disparity, increasing average accuracy from 0.44 to 0.54. These findings underscore fundamental asymmetries between generative and discriminative competencies for variety-specific language, particularly in the context of slang expressions despite being in a technologically rich language such as English.

</details>


### [10] [Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework](https://arxiv.org/abs/2602.15377)
*Mengze Hong,Chen Jason Zhang,Zichang Guo,Hanlin Gu,Di Jiang,Li Qing*

Main category: cs.CL

TL;DR: 提出基于任务导向流程图的无编排框架，实现端到端客服自动化，通过流程图构建算法从对话中提取知识，并采用本地部署小模型和去中心化蒸馏解决数据隐私问题。


<details>
  <summary>Details</summary>
Motivation: 当前客服自动化方法存在局限性：模块化系统需要大量智能体编排，而简化指令模式指导有限且泛化能力差，需要一种无需手动干预的端到端自动化方案。

Method: 1) 定义任务导向流程图组件和评估指标；2) 提出成本高效的流程图构建算法，从服务对话中提取程序性知识；3) 强调小语言模型的本地部署；4) 提出基于流程图的去中心化蒸馏方法解决训练数据稀缺和隐私问题。

Result: 在各种服务任务上的广泛实验验证了有效性，相比强基线方法和市场产品，在量化指标和应用性能上都表现出优越性。发布了基于Web的系统演示和案例研究。

Conclusion: 该框架通过任务导向流程图实现了无需编排的端到端客服自动化，解决了现有方法的局限性，并促进了未来服务自动化的简化创建。

Abstract: Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance and poor generalizability. This paper introduces an orchestration-free framework using Task-Oriented Flowcharts (TOFs) to enable end-to-end automation without manual intervention. We first define the components and evaluation metrics for TOFs, then formalize a cost-efficient flowchart construction algorithm to abstract procedural knowledge from service dialogues. We emphasize local deployment of small language models and propose decentralized distillation with flowcharts to mitigate data scarcity and privacy issues in model training. Extensive experiments validate the effectiveness in various service tasks, with superior quantitative and application performance compared to strong baselines and market products. By releasing a web-based system demonstration with case studies, we aim to promote streamlined creation of future service automation.

</details>


### [11] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 该研究探索了大型语言模型是否能在缺乏训练数据的语言（以图鲁语为例）中实现基本对话能力，通过结构化提示而非微调，结合语法文档、负约束、罗马化标准化和质量控制的合成数据生成，显著减少了词汇污染并提高了语法准确性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究大型语言模型能否在训练数据极少或缺失的语言（如图鲁语）中实现基本对话能力，这涉及对LLM跨语言泛化能力的测试，特别是在资源匮乏语言场景下的应用潜力。

Method: 研究方法包括：1）使用结构化提示而非模型微调；2）结合显式语法文档；3）应用负约束来抑制相关语言的高概率标记；4）罗马化标准化；5）通过自我游戏生成质量控制的合成数据；6）在三个LLM（Gemini 2.0 Flash、GPT-4o、Llama 3.1 70B）上评估，并由母语者验证。

Result: 研究结果：词汇污染从80%降至5%，语法准确率达到85%。负约束带来12-18个百分点的稳定提升，语法文档的效果因模型架构而异（8-22个百分点）。跨模型分析显示方法在不同LLM上均有效。

Conclusion: 结论表明，即使训练数据缺失，通过精心设计的结构化提示方法，大型语言模型仍能在资源匮乏语言中实现基本对话能力。负约束是稳定有效的技术，而语法文档的效果受模型架构影响。这为LLM在低资源语言应用提供了可行路径。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [12] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: Vision Wormhole框架通过VLM的视觉接口实现模型无关的无文本通信，利用通用视觉编解码器将异构推理轨迹映射到共享连续潜空间，显著降低多智能体系统通信开销


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体系统受限于离散文本通信的低效率，存在运行时开销大和信息量化损失问题。现有潜状态传输方法要么假设同构架构，要么依赖特定配对的翻译器，限制了在异构模型家族间的可扩展性和模块化

Method: 提出Vision Wormhole框架：1) 引入通用视觉编解码器，将异构推理轨迹映射到共享连续潜空间；2) 采用中心辐射拓扑将成对对齐复杂度从O(N²)降至O(N)；3) 使用无标签的师生蒸馏目标，将高速视觉通道与文本推理模式对齐；4) 通过视觉编码器作为通用端口实现智能体间的"心灵感应"

Result: 在异构模型家族（如Qwen-VL、Gemma）上的广泛实验表明，Vision Wormhole在受控比较中显著减少了端到端运行时间，同时保持了与标准文本多智能体系统相当的推理保真度

Conclusion: Vision Wormhole为异构大语言模型间的协作提供了一种高效、模型无关的通信范式，通过视觉接口作为通用端口解决了传统文本通信的瓶颈，在保持推理质量的同时显著提升了通信效率

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec, we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway, effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at https://github.com/xz-liu/heterogeneous-latent-mas

</details>


### [13] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 利用大语言模型对二战芬兰卡累利阿难民访谈中的35万条休闲活动和组织成员信息进行分类，为历史社会学研究提供结构化数据


<details>
  <summary>Details</summary>
Motivation: 数字化历史档案虽然提供了大规模研究日常社会生活的可能性，但从文本中直接提取的信息往往无法直接用于历史学家或社会学家的定量研究。针对芬兰二战卡累利阿难民家庭访谈中提取的35万条活动和组织提及（涉及7.1万个不同名称），数量过多无法直接分析，需要系统分类框架。

Method: 1. 开发包含关键参与维度的分类框架：活动/组织类型、社交性、规律性、体力需求；2. 创建人工标注的金标准数据集用于可靠评估；3. 测试大语言模型能否在规模上应用相同分类模式；4. 采用多模型运行的简单投票方法提高分类准确性。

Result: 研究发现，开源权重的大语言模型通过投票方法能够与专家判断高度匹配。该方法成功应用于标注35万个实体，为后续社会融合及相关结果的研究提供了结构化资源。

Conclusion: 大语言模型能够有效应用于历史档案文本的分类任务，将非结构化信息转化为可用于定量社会学研究的结构化数据，为历史社会学研究提供了新的技术路径。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly.
  We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [14] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: 提出TAROT方法，通过构建四层测试套件并解耦课程进度与奖励分数，根据模型能力自适应调整课程设计，提升代码生成的功能正确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法忽视了测试用例的异质难度和粒度，导致奖励信号分布不均和梯度更新偏差，影响算法复杂且鲁棒的代码生成。

Method: TAROT为每个问题构建四层测试套件（基础、中级、复杂、边缘），解耦课程进度与原始奖励分数，实现能力条件评估，并从课程策略组合中原则性选择。

Result: 实验表明，代码生成RFT的最佳课程与模型内在能力紧密相关：能力较弱的模型从易到难课程获益更多，而能力较强的模型在难到易课程下表现更优。

Conclusion: TAROT提供了一种可复现方法，能自适应地根据模型能力定制课程设计，持续提升生成代码的功能正确性和鲁棒性。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.

</details>


### [15] [In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456)
*Mohammad Aflah Khan,Mahsa Amani,Soumi Das,Bishwamittra Ghosh,Qinyuan Wu,Krishna P. Gummadi,Manish Gupta,Abhilasha Ravichander*

Main category: cs.CL

TL;DR: LLM代理在呈现信息时存在系统性的来源偏好，这些偏好会影响信息选择，且难以通过提示消除。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注LLM生成内容中的偏见，但对LLM在筛选和呈现信息时的偏好因素关注不足。研究假设LLM在信息归因于特定来源时，会表现出系统性的来源偏好。

Method: 对6个提供商的12个LLM进行控制实验，涵盖合成和真实世界任务，测试模型在不同上下文框架下的来源偏好。

Result: 多个模型表现出强烈且可预测的来源偏好，这些偏好对上下文框架敏感，有时甚至超过内容本身的影响，且无法通过明确提示消除。这些偏好能解释先前研究中观察到的新闻推荐左倾偏斜现象。

Conclusion: 需要深入研究这些偏好的起源，并开发机制为用户提供透明度和对LLM代理偏见的控制权。

Abstract: Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs themselves generate, less attention has been paid to the factors that influence what information LLMs select and present to users. We hypothesize that when information is attributed to specific sources (e.g., particular publishers, journals, or platforms), current LLMs exhibit systematic latent source preferences- that is, they prioritize information from some sources over others. Through controlled experiments on twelve LLMs from six model providers, spanning both synthetic and real-world tasks, we find that several models consistently exhibit strong and predictable source preferences. These preferences are sensitive to contextual framing, can outweigh the influence of content itself, and persist despite explicit prompting to avoid them. They also help explain phenomena such as the observed left-leaning skew in news recommendations in prior work. Our findings advocate for deeper investigation into the origins of these preferences, as well as for mechanisms that provide users with transparency and control over the biases guiding LLM-powered agents.

</details>


### [16] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 该研究提出了"期望检测"任务，创建了RedHOTExpect语料库（4.5K条Reddit帖子），使用LLM进行银标注，分析了医疗环境中患者在线讨论的治疗期望特征。


<details>
  <summary>Details</summary>
Motivation: 患者对治疗的期望对治疗效果有重要影响。虽然临床环境已有研究，但线上患者平台（如医疗subreddits）可能包含患者不愿在其他地方分享的补充见解。目前尚无研究探讨用户在线上讨论的期望类型及表达方式，且NLP领域尚未研究过期望检测。

Method: 1. 引入期望检测任务；2. 以医疗领域为案例研究；3. 创建RedHOTExpect语料库（4.5K条Reddit帖子）；4. 使用大语言模型进行银标注；5. 手动验证标注质量（准确率约78%）；6. 分析期望的语言模式特征。

Result: 1. 构建了可用于研究期望的RedHOTExpect语料库；2. 发现乐观和主动表达的倾向在身体或治疗相关疾病帖子中比心理健康帖子更明显；3. 患者主要讨论治疗的益处而非负面结果；4. 确定了期望的语言特征模式。

Conclusion: 期望检测是NLP中一个相关且未充分探索的任务，特别是在医疗领域。RedHOTExpect语料库为研究线上患者期望提供了有价值资源，揭示了不同医疗背景下期望表达的差异，为意见挖掘和产品设计等应用提供了基础。

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect

</details>


### [17] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: LuxMT是基于Gemma 3 27B构建的卢森堡语到法语/英语的机器翻译系统，使用LuxAlign平行语料和议会转录数据训练，通过LuxEmbedder过滤低质量句对，在LB-FR和LB-EN翻译上相比基线有显著提升。


<details>
  <summary>Details</summary>
Motivation: 卢森堡语作为资源稀缺语言，缺乏高质量的机器翻译系统。需要构建专门针对卢森堡语到法语和英语的翻译系统，并建立评估基准来准确衡量性能。

Method: 1) 基于Gemma 3 27B模型进行微调；2) 使用LuxAlign平行语料库（多语言卢森堡新闻）和议会转录数据（经Google Translate增强）；3) 通过LuxEmbedder（卢森堡语句子嵌入模型）过滤低等价性句对；4) 构建基于Luci旅游杂志人工翻译数据的新基准进行评估。

Result: 1) LuxMT在LB-FR和LB-EN翻译上相比Gemma 3基线有显著改进；2) 即使在训练数据不含德语的情况下，LB-DE翻译也有提升；3) LuxEmbedder作为质量评估指标与其他参考指标有强相关性，但需谨慎使用。

Conclusion: LuxMT系统在卢森堡语翻译任务上表现出色，LuxEmbedder在质量评估方面有潜力，但需要进一步研究来充分验证其效用，建议谨慎使用该指标。

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [18] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: Fine-Refine 框架通过将回复分解为原子单元、验证每个单元的事实性、评估流畅度，并迭代修正细粒度错误，显著提升对话系统的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在对话系统中容易产生幻觉，生成事实错误的回复误导用户并损害系统信任。现有的细化方法通常在回复层面操作，忽略了单个回复可能包含多个可验证或不可验证的事实。

Method: 提出 Fine-Refine 细粒度细化框架：1) 将回复分解为原子单元；2) 使用外部知识验证每个单元的事实性；3) 通过困惑度评估流畅度；4) 迭代修正细粒度错误。

Result: 在 HybriDialogue 和 OpendialKG 数据集上的评估显示，Fine-Refine 显著提升了事实性，对话事实得分最高提升 7.63 分，仅在对话质量上略有牺牲。

Conclusion: Fine-Refine 框架通过细粒度的单元级验证和修正，有效减少了对话系统中的幻觉问题，在事实准确性和覆盖范围方面都取得了显著改进，为对话系统的事实性提升提供了实用方案。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [19] [DependencyAI: Detecting AI Generated Text through Dependency Parsing](https://arxiv.org/abs/2602.15514)
*Sara Ahmed,Tracy Hammond*

Main category: cs.CL

TL;DR: DependencyAI：一种仅使用语言依存关系标签检测AI生成文本的简单可解释方法，在多种设置中表现优异


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型日益普及，需要可靠的AI生成文本检测方法来缓解潜在风险

Method: 仅使用语言依存关系标签的简单可解释方法，通过分析特征重要性揭示区分AI生成与人类文本的句法结构

Result: 在单语言、多生成器和多语言设置中均取得竞争性性能；发现特定模型在未见领域存在系统性过预测，表明生成器特定写作风格可能影响跨领域泛化

Conclusion: 依存关系本身为AI生成文本检测提供了稳健信号，DependencyAI成为基于语言学、可解释且不依赖神经网络的强基线方法

Abstract: As large language models (LLMs) become increasingly prevalent, reliable methods for detecting AI-generated text are critical for mitigating potential risks. We introduce DependencyAI, a simple and interpretable approach for detecting AI-generated text using only the labels of linguistic dependency relations. Our method achieves competitive performance across monolingual, multi-generator, and multilingual settings. To increase interpretability, we analyze feature importance to reveal syntactic structures that distinguish AI-generated from human-written text. We also observe a systematic overprediction of certain models on unseen domains, suggesting that generator-specific writing styles may affect cross-domain generalization. Overall, our results demonstrate that dependency relations alone provide a robust signal for AI-generated text detection, establishing DependencyAI as a strong linguistically grounded, interpretable, and non-neural network baseline.

</details>


### [20] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: 本文提出ExpertWeaver，一种无需训练的框架，利用GLU激活模式将预训练稠密模型转换为稀疏MoE架构，在性能和推理效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从零训练MoE成本过高，现有稠密转MoE方法破坏了稠密模型的内在激活模式，导致专家构建不理想。作者发现GLU机制为稠密到MoE转换提供了天然蓝图。

Method: 基于GLU的细粒度激活模式揭示粗粒度结构，发现固有MoE架构由一致激活的通用神经元和动态激活的专用神经元组成。提出ExpertWeaver框架，根据激活模式划分神经元，构建共享专家和专用路由专家，具有层自适应配置。

Result: 实验表明，ExpertWeaver显著优于现有方法，既可作为无需训练的动态结构剪枝技术，也可作为高质量MoE初始化的降循环策略。

Conclusion: GLU激活模式揭示了稠密模型中的固有MoE结构，ExpertWeaver利用这一发现实现了高效、无需训练的稠密到MoE转换，在性能和效率上取得优越结果。

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [21] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: ZeroSyl是一种无需训练的简单方法，通过分析WavLM中间层特征的L2范数直接提取音节边界和嵌入，用于训练语音语言模型，在多个基准测试中优于现有音节分词器。


<details>
  <summary>Details</summary>
Motivation: 纯语音语言模型直接从原始音频学习语言，但自监督语音编码器的离散标记会导致序列过长。现有音节方法如Sylber和SyllableLM需要复杂的多阶段训练流程，因此需要更简单高效的解决方案。

Method: 使用冻结的WavLM模型，通过分析中间层特征的L2范数来检测音节边界，然后将分段特征进行平均池化，使用K-means离散化，最后用于训练语言模型。

Result: ZeroSyl在音节分割性能上具有竞争力，在词汇、句法和叙事基准测试中优于先前的音节分词器。扩展实验表明，更细粒度的单元对词汇任务有益，而发现的音节单元在句法建模方面表现出更好的扩展性。

Conclusion: ZeroSyl提供了一种简单且无需训练的方法来提取音节单元，为纯语音语言模型提供了一种有效的中间表示，在保持性能的同时简化了训练流程。

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [22] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: Perspectives是一个交互式文档分析工具，通过基于提示重写和指令嵌入的文档聚类管道，帮助数字人文学者探索大规模非结构化文档集合。


<details>
  <summary>Details</summary>
Motivation: 数字人文学者需要处理大量非结构化文档集合，传统分析方法难以有效探索和组织这些数据，需要能够支持人类参与的可交互工具来发现主题、情感和其他相关类别。

Method: 1. 实现灵活的、面向方面的文档聚类管道；2. 通过文档重写提示定义分析视角；3. 使用基于指令的嵌入技术；4. 提供人类参与循环的细化功能；5. 支持聚类细化和嵌入模型微调机制。

Result: 开发了Perspectives工具，展示了典型工作流程，使数字人文学者能够利用交互式文档地图发现主题、情感等类别，获得洞察并为后续深入分析准备数据。

Conclusion: Perspectives通过结合人类专业知识和自动化聚类技术，为数字人文学者提供了有效的文档探索工具，支持灵活的分析视角定义和用户意图对齐，有助于从大规模文档集合中提取有价值的见解。

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [23] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: 结合模型蒸馏与任务特定对比损失训练紧凑高性能嵌入模型，超越同类尺寸SOTA


<details>
  <summary>Details</summary>
Motivation: 现有通用嵌入模型通常使用单阶段或多阶段对比损失训练，但小型模型的训练效果有限，需要更有效的训练方法

Method: 提出新颖训练方案：结合模型蒸馏技术与任务特定对比损失，用于训练紧凑的嵌入模型

Result: jina-embeddings-v5-text-small和nano模型在同类尺寸模型中达到或超越SOTA，支持32k长文本、多语言，嵌入在截断和二进制量化下保持鲁棒

Conclusion: 该训练方案比纯对比或纯蒸馏训练更有效，公开模型权重有望推动嵌入模型发展

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [24] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: 本文提出SquRL强化学习框架，通过动态构建工作流提升Text-to-SQL系统的适应性，相比静态工作流在复杂和分布外查询上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法依赖单一静态工作流，难以适应现实场景中的分布外和长尾情况，限制了系统的可扩展性和实际应用效果。

Method: 提出SquRL强化学习框架，增强LLM在自适应工作流构建中的推理能力。设计了基于规则的奖励函数，并引入两种训练机制：动态演员掩码以鼓励广泛探索，伪奖励以提高训练效率。

Result: 在广泛使用的Text-to-SQL基准测试中，动态工作流构建始终优于最佳静态工作流方法，特别是在复杂和分布外查询上表现提升尤为显著。

Conclusion: 通过理论分析和实验证明，最优动态策略能够持续超越最佳静态工作流，性能提升主要源于候选工作流间的异质性。SquRL框架为Text-to-SQL系统的实际应用提供了更有效的解决方案。

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL

</details>


### [25] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 提出一种症状特异性且临床启发的框架，用于从语音中估计抑郁严重程度，通过症状引导的交叉注意力机制和可学习的症状特定参数来改进预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作大多将抑郁预测视为二元标签或总体严重程度评分，而没有明确建模症状特异性信息，这限制了提供与临床筛查相关的症状级分析的能力。

Method: 使用症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知的语音表征对齐，识别哪些语音片段对每个症状更重要；引入可学习的症状特定参数，自适应控制注意力分布的锐度。

Result: 在标准临床风格数据集EDAIC上展示了优于先前工作的性能提升；注意力分析显示，较高注意力被分配给包含多个抑郁症状线索的话语，突出了方法的可解释性。

Conclusion: 症状引导和情感感知建模对于基于语音的抑郁筛查具有重要意义，提出的框架提供了改进的性能和临床相关的可解释性。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [26] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: 提出STAPO方法解决RL微调中的性能崩溃问题，通过识别并屏蔽异常梯度更新的虚假token，在数学推理基准上实现稳定训练和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有RL微调方法依赖启发式技术（如熵正则化和重加权）来保持稳定性，但在实践中经常出现后期性能崩溃，导致推理质量下降和训练不稳定。作者发现训练不稳定性由极少部分token（约0.01%）驱动，称为"虚假token"。

Method: 首先推导出token-wise策略梯度的大小与token概率和局部策略熵负相关。基于此证明训练不稳定性由虚假token驱动。提出STAPO方法，选择性屏蔽这些token的更新，并在有效token上重新归一化损失。

Result: 在六个数学推理基准上使用Qwen 1.7B、8B和14B基础模型进行测试，STAPO展现出优异的熵稳定性，平均性能相比GRPO、20-Entropy和JustRL提升7.13%。

Conclusion: STAPO通过识别和处理虚假token，有效解决了RL微调中的训练不稳定问题，为大规模模型精调提供了更稳定的方法，显著提升了推理性能。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [27] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 首个公开的埃及阿拉伯语TTS数据集NileTTS，包含38小时转录语音，通过LLM生成内容+音频合成+自动转录+人工验证的合成流程构建，并基于XTTS v2微调发布了开源模型。


<details>
  <summary>Details</summary>
Motivation: 尽管神经文本转语音技术有所进展，但大多数阿拉伯语资源集中在现代标准阿拉伯语和海湾方言，埃及阿拉伯语作为最广泛理解的阿拉伯语方言，资源严重不足。

Method: 1) 构建NileTTS数据集：使用大型语言模型生成埃及阿拉伯语内容，通过音频合成工具转换为自然语音，然后进行自动转录和说话人分割，最后人工质量验证。2) 在XTTS v2（最先进的多语言TTS模型）上微调该数据集。

Result: 1) 创建了首个公开的埃及阿拉伯语TTS数据集（38小时，2位说话人，涵盖医疗、销售、一般对话等多个领域）。2) 开发了可复现的方言TTS合成数据生成流程。3) 发布了开源微调模型。所有资源均已公开以推动埃及阿拉伯语语音合成研究。

Conclusion: 该研究填补了埃及阿拉伯语TTS资源空白，通过创新的合成数据生成流程创建了高质量数据集，并提供了开源模型，将显著推动埃及阿拉伯语语音合成研究进展。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [28] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 本研究基于弗莱的叙事四类型理论，提出一个结合荣格原型理论的角色功能框架，并用大语言模型验证了角色-类型对应关系的系统性模式。


<details>
  <summary>Details</summary>
Motivation: 现有基于弗莱理论的叙事计算研究主要关注叙事模式而非角色功能，因此需要开发一个能够分析原型角色在不同叙事类型中如何体现的角色功能框架。

Method: 结合荣格原型理论，推导出四个通用角色功能（主角、导师、反派、同伴），并将其细化为16个类型特定角色。使用6个先进大语言模型对40部叙事作品进行多模型验证，采用正负样本评估角色-类型对应关系。

Result: 大语言模型在验证角色-类型对应关系方面表现良好（平均平衡准确率82.5%），模型间一致性高（Fleiss' κ=0.600）。不同类型（72.7%-89.9%）和角色（52.5%-99.2%）的表现存在差异，定性分析显示这些差异反映了真实的叙事特性。

Conclusion: 这一基于角色的方法展示了大语言模型支持的计算叙事学潜力，为未来叙事生成方法和交互式讲故事应用的发展奠定了基础。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $κ$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [29] [A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models](https://arxiv.org/abs/2602.15689)
*Meirav Segal,Noa Linder,Omer Antverg,Gil Gekker,Tomer Fichman,Omri Bodenheimer,Edan Maor,Omer Nevo*

Main category: cs.CL

TL;DR: 提出基于内容分析的网络安全拒绝框架，通过显式建模攻击风险与防御收益的权衡，解决现有基于意图或分类方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在网络安全任务中采用的拒绝机制通常基于广泛的主题禁令或攻击导向的分类法，导致决策不一致、过度限制合法防御者，且在混淆或请求分段下表现脆弱。需要更有效的拒绝框架来平衡攻击风险与防御收益。

Method: 引入基于内容的网络安全拒绝策略框架，从五个维度对请求进行特征分析：攻击行动贡献度、攻击风险、技术复杂度、防御收益、合法用户预期频率。这些维度基于请求的技术实质而非陈述意图。

Result: 该内容导向方法解决了当前前沿模型行为的不一致性问题，使组织能够构建可调节、风险感知的拒绝策略，实现更精准的攻击防御权衡。

Conclusion: 通过显式建模攻击风险与防御收益的权衡，基于内容的拒绝框架能够提供更一致、更灵活的网络安全决策机制，优于传统的基于意图或分类的方法。

Abstract: Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate defenders, and behave brittlely under obfuscation or request segmentation. We argue that effective refusal requires explicitly modeling the trade-off between offensive risk and defensive benefit, rather than relying solely on intent or offensive classification. In this paper, we introduce a content-based framework for designing and auditing cyber refusal policies that makes offense-defense tradeoffs explicit. The framework characterizes requests along five dimensions: Offensive Action Contribution, Offensive Risk, Technical Complexity, Defensive Benefit, and Expected Frequency for Legitimate Users, grounded in the technical substance of the request rather than stated intent. We demonstrate that this content-grounded approach resolves inconsistencies in current frontier model behavior and allows organizations to construct tunable, risk-aware refusal policies.

</details>


### [30] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 论文提出了两种新的词汇语义变化检测指标AMD和SAMD，通过跨时间段的词汇使用局部对应关系来量化语义变化，相比传统指标APD和PRT在某些情况下表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前词汇语义变化检测主要依赖APD和PRT等少数语义变化度量指标，这些方法存在局限性，需要探索更多样化的度量方法。

Method: 提出了两种新指标：平均最小距离（AMD）和对称平均最小距离（SAMD），通过计算跨时间段词汇使用之间的局部对应关系来量化语义变化。

Result: 在多种语言、编码器模型和表示空间中，AMD在降维和非专用编码器下表现更稳健，SAMD在专用编码器下表现优异，新指标优于传统APD和PRT方法。

Conclusion: 词汇语义变化检测应考虑APD和PRT之外的替代语义变化度量指标，AMD为基于上下文嵌入的分析提供了稳健的选择。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [31] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: 本文提出一个端到端流程，用于生成文本干预并进行因果效应估计，通过稀疏自编码器生成假设和引导，结合协变量残差化方法解决文本作为治疗时的估计偏差问题。


<details>
  <summary>Details</summary>
Motivation: 文本对下游结果的因果效应估计在许多应用中至关重要，但大型语言模型生成受控变体文本存在挑战。文本固有的治疗信息和协变量信息混杂，导致朴素因果效应估计存在显著偏差。

Method: 1. 使用稀疏自编码器进行假设生成和引导；2. 提出基于协变量残差化的解决方案来减少估计偏差；3. 构建端到端流程处理文本作为治疗实验中的计算和统计挑战。

Result: 实证结果表明，该流程能有效诱导目标特征的变化，并显著减轻估计误差，为文本作为治疗场景下的因果效应估计提供了稳健基础。

Conclusion: 该研究提供了一个全面的端到端解决方案，通过稀疏自编码器和协变量残差化方法，有效解决了文本干预生成和因果效应估计中的关键挑战，为文本因果推断提供了可靠框架。

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [32] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（GPT-4变体和Mistral模型）在少量样本和零样本设置下对四种低资源语言（古希腊语、古典亚美尼亚语、古格鲁吉亚语和叙利亚语）进行词形还原和词性标注的能力，发现LLMs在这些任务上表现出竞争力甚至优于特定任务的RNN基线。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在自然语言处理任务（如词形还原和词性标注）中一直面临挑战，特别是在数据稀缺的情况下。本文旨在探索最近的大型语言模型（LLMs）在少量样本和零样本设置下处理这些任务的能力，重点关注四种历史上和语言上多样化的低资源语言。

Method: 研究使用了一个新颖的基准测试，包含对齐的训练数据和领域外测试数据。评估了GPT-4变体和开源Mistral模型在少量样本和零样本设置下的表现，并与特定任务的RNN基线模型PIE进行了比较。实验覆盖了四种低资源语言：古希腊语、古典亚美尼亚语、古格鲁吉亚语和叙利亚语。

Result: 结果显示，即使没有微调，大型语言模型在少量样本设置下，在大多数语言的词性标注和词形还原任务上都能达到竞争性或更优的性能。对于具有复杂形态和非拉丁文字的语言仍然存在显著挑战，但LLMs被证明是在缺乏数据的情况下启动语言标注任务的一个可信且相关的选择。

Conclusion: 大型语言模型可以作为在没有数据的情况下启动语言标注任务的有效工具，特别是在少量样本设置下。尽管对于形态复杂和非拉丁文字的语言仍然存在挑战，但LLMs为低资源语言的NLP任务提供了一个有前景的解决方案。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [33] [Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos](https://arxiv.org/abs/2602.15757)
*Laura De Grazia,Danae Sánchez Villegas,Desmond Elliott,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 该研究提出了一个包含细粒度标注的西班牙语多模态性别歧视检测数据集FineMuSe，并评估了LLM在检测细微性别歧视方面的表现。


<details>
  <summary>Details</summary>
Motivation: 在线性别歧视表现形式多样，现有自动化工具大多局限于二元分类，难以检测更细微、上下文敏感的性别歧视内容。

Method: 1)创建FineMuSe数据集，包含西班牙语多模态内容及二元/细粒度标注；2)提出包含性别歧视形式、非性别歧视、讽刺和幽默修辞的层次分类法；3)评估多种LLM在二元和细粒度性别歧视检测上的表现。

Result: 多模态LLM在识别细微性别歧视方面表现与人类标注者相当，但在通过视觉线索传达的并发性别歧视类型识别上存在困难。

Conclusion: 多模态LLM在性别歧视检测方面具有潜力，但需要改进对视觉线索中并发性别歧视类型的识别能力。

Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.

</details>


### [34] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: ChartEditBench：一个用于评估MLLMs在多轮交互中增量式图表编辑能力的基准，包含5000个难度可控的修改链，并提出了结合执行保真度、像素级视觉相似性和逻辑代码验证的评估框架。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在单轮图表生成上表现良好，但其支持真实世界探索性数据分析的能力仍未被充分探索。实际应用中，用户通过多轮交互迭代优化可视化，这需要维护共同背景、跟踪先前编辑并适应不断变化的偏好。

Method: 引入ChartEditBench基准，包含5000个难度可控的修改链和人工验证子集。提出一个稳健的评估框架，整合了执行保真度检查、像素级视觉相似性和逻辑代码验证，以减轻LLM-as-a-Judge指标的局限性。

Result: 实验表明，最先进的MLLMs在多轮设置中性能显著下降，主要由于错误累积和共享背景的崩溃。在样式编辑上表现良好，但在数据为中心的转换上经常出现执行失败。

Conclusion: ChartEditBench为基于意图感知的多模态编程建立了一个具有挑战性的测试平台，揭示了当前MLLMs在支持真实世界探索性数据分析方面的局限性，特别是在多轮交互和上下文保持方面。

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [35] [ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution](https://arxiv.org/abs/2602.15769)
*Yahia Alqurnawi,Preetom Biswas,Anmol Rao,Tejas Anvekar,Chitta Baral,Vivek Gupta*

Main category: cs.CL

TL;DR: 多模态大语言模型在结构化数据引用方面表现不佳，答案溯源能力远低于问题回答准确性


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型能够回答结构化数据（如表格）的问题，但用户需要知道答案的来源，而当前模型在提供细粒度、可信的引用方面存在不足，限制了在需要透明度和可追溯性的应用中的使用。

Method: 评估多个多模态大语言模型在不同表格格式（Markdown、JSON、图像）和提示策略下的表现，研究模型在引用具体行列数据支持答案的能力。

Result: 1. 问题回答准确率与证据引用准确率存在明显差距；2. 虽然问题回答准确率保持中等水平，但引用准确率低得多，对于JSON输入接近随机水平；3. 模型在引用行方面比列更可靠；4. 模型在文本格式上的表现比图像格式更差；5. 不同模型家族之间存在显著差异。

Conclusion: 当前多模态大语言模型在提供结构化数据的细粒度、可信引用方面不可靠，这限制了它们在需要透明度和可追溯性的应用中的使用。

Abstract: Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. We evaluate several mLLMs across different table formats and prompting strategies. Our results show a clear gap between question answering and evidence attribution. Although question answering accuracy remains moderate, attribution accuracy is much lower, near random for JSON inputs, across all models. We also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. Finally, we observe notable differences across model families. Overall, our findings show that current mLLMs are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.

</details>


### [36] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 提出*-PLUIE方法，在ParaPLUIE基础上通过任务特定提示变体改进基于困惑度的LLM评估指标，实现与人类判断更好对齐且计算成本低


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-judge方法虽然有效，但计算开销大且需要后处理，需要更高效且低成本的自动文本质量评估方法

Method: 在ParaPLUIE（基于困惑度的LLM评估指标）基础上，引入*-PLUIE任务特定提示变体，通过个性化提示策略估计"Yes/No"答案的置信度而无需生成文本

Result: 个性化*-PLUIE在实验中展现出与人类评分更强的相关性，同时保持了较低的计算成本

Conclusion: *-PLUIE通过任务特定提示变体改进了基于困惑度的LLM评估方法，在保持计算效率的同时更好地与人类判断对齐，为自动文本质量评估提供了有效替代方案

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [37] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 论文将Avey架构重新设计为仅编码器模型，通过解耦参数化、稳定性归一化和神经压缩等技术，在保持紧凑性的同时超越了传统Transformer编码器的性能。


<details>
  <summary>Details</summary>
Motivation: 紧凑的预训练双向编码器在工业NLP中至关重要，但传统Transformer的自注意力机制存在计算和内存限制。虽然Avey作为无注意力的自回归模型被提出，但需要适应仅编码器范式以提高双向上下文建模能力。

Method: 1. 将Avey架构重新设计为仅编码器范式；2. 引入解耦的静态和动态参数化；3. 采用稳定性导向的归一化方法；4. 应用神经压缩技术；5. 在标准token分类和信息检索基准上进行评估。

Result: 重新设计的Avey编码器在标准token分类和信息检索基准上持续优于四种广泛使用的基于Transformer的编码器，同时在长上下文场景中具有更好的扩展效率。

Conclusion: 通过架构创新，Avey可以成功适应仅编码器范式，在保持紧凑性的同时提供比传统Transformer编码器更优越的性能和扩展性，为工业NLP应用提供了有前景的替代方案。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [38] [ScrapeGraphAI-100k: A Large-Scale Dataset for LLM-Based Web Information Extraction](https://arxiv.org/abs/2602.15189)
*William Brach,Francesco Zuppichini,Marco Vinciguerra,Lorenzo Padoan*

Main category: cs.IR

TL;DR: 研究者推出了ScrapeGraphAI-100k数据集，包含近10万真实网页信息提取事件，用于提升大语言模型在结构化网页信息提取中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有网页信息提取数据集规模小、合成或仅含文本，缺乏网页结构上下文，限制了LLM在真实网页信息提取中的应用。

Method: 通过ScrapeGraphAI工具收集2025年第二、三季度900万次真实提取事件，经去重和模式平衡处理，得到93,695个多样化实例，包含Markdown内容、提示词、JSON模式、LLM响应及复杂度元数据。

Result: 创建了大规模多样化数据集，分析了模式复杂度增加时的失败模式。微调实验显示，17亿参数小模型在数据集子集上训练后，性能接近300亿参数基线模型。

Conclusion: ScrapeGraphAI-100k数据集支持小模型微调、结构化提取基准测试和网页信息检索索引的模式归纳研究，已公开在HuggingFace平台。

Abstract: The use of large language models for web information extraction is becoming increasingly fundamental to modern web information retrieval pipelines. However, existing datasets tend to be small, synthetic or text-only, failing to capture the structural context of the web. We introduce ScrapeGraphAI-100k, a large-scale dataset comprising real-world LLM extraction events, collected via opt-in ScrapeGraphAI telemetry during Q2 and Q3 of 2025. Starting from 9M events, we deduplicate and balance by schema to produce 93,695 examples spanning diverse domains and languages. Each instance includes Markdown content, a prompt, a JSON schema, the LLM response, and complexity/validation metadata. We characterize the datasets structural diversity and its failure modes as schema complexity increases. We also provide a fine-tuning experiment showing that a small language model (1.7B) trained on a subset narrows the gap to larger baselines (30B), underscoring the datasets utility for efficient extraction. ScrapeGraphAI-100k enables fine-tuning small models, benchmarking structured extraction, and studying schema induction for web IR indexing, and is publicly available on HuggingFace.

</details>


### [39] [Semantics-Aware Denoising: A PLM-Guided Sample Reweighting Strategy for Robust Recommendation](https://arxiv.org/abs/2602.15359)
*Xikai Yang,Yang Wang,Yilin Li,Sebastian Sun*

Main category: cs.IR

TL;DR: SAID框架利用用户兴趣与物品内容的语义一致性来识别和降权隐式反馈中的噪声点击，仅修改损失函数即可提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 隐式反馈（如用户点击）是推荐系统的主要数据源，但包含大量噪声（如误点击、点击诱饵、探索性浏览），这些噪声不能反映真实用户偏好，导致模型预测准确性下降和推荐不可靠。

Method: 构建基于历史行为的文本用户兴趣画像，使用预训练语言模型编码器计算用户兴趣与目标物品描述的语义相似度，将相似度转换为样本权重来调整训练损失，降低语义不一致点击的影响。

Result: 在两个真实数据集上的实验表明，SAID能持续提升推荐性能，相比强基线在AUC指标上获得最高2.2%的相对提升，在高噪声条件下表现出显著鲁棒性。

Conclusion: SAID是一个简单有效的隐式反馈去噪框架，通过语义一致性识别噪声点击，仅修改损失函数而不改变推荐模型主干，实现了性能提升和噪声鲁棒性。

Abstract: Implicit feedback, such as user clicks, serves as the primary data source for modern recommender systems. However, click interactions inherently contain substantial noise, including accidental clicks, clickbait-induced interactions, and exploratory browsing behaviors that do not reflect genuine user preferences. Training recommendation models with such noisy positive samples leads to degraded prediction accuracy and unreliable recommendations. In this paper, we propose SAID (Semantics-Aware Implicit Denoising), a simple yet effective framework that leverages semantic consistency between user interests and item content to identify and downweight potentially noisy interactions. Our approach constructs textual user interest profiles from historical behaviors and computes semantic similarity with target item descriptions using pre-trained language model (PLM) based text encoders. The similarity scores are then transformed into sample weights that modulate the training loss, effectively reducing the impact of semantically inconsistent clicks. Unlike existing denoising methods that require complex auxiliary networks or multi-stage training procedures, SAID only modifies the loss function while keeping the backbone recommendation model unchanged. Extensive experiments on two real-world datasets demonstrate that SAID consistently improves recommendation performance, achieving up to 2.2% relative improvement in AUC over strong baselines, with particularly notable robustness under high noise conditions.

</details>


### [40] [Automatic Funny Scene Extraction from Long-form Cinematic Videos](https://arxiv.org/abs/2602.15381)
*Sibendu Paul,Haotian Jiang,Caren Chen*

Main category: cs.IR

TL;DR: 提出一个端到端系统，用于从长视频中自动识别和排名幽默场景，通过多模态方法提升场景定位和幽默检测效果


<details>
  <summary>Details</summary>
Motivation: 从长视频中自动提取高质量幽默场景对于制作吸引人的视频预览和短视频内容至关重要，但长视频的时长、复杂叙事以及幽默的多模态特性使得场景定位和识别变得困难。

Method: 采用端到端系统，包括镜头检测、多模态场景定位和幽默标注。创新点包括：结合视觉和文本线索的场景分割方法、通过引导三元组挖掘改进镜头表示、以及利用音频和文本的多模态幽默标注框架。

Result: 在OVSD数据集上，场景检测比现有最佳方法提升18.3% AP；长文本幽默检测F1分数达0.834；在五个电影标题上的评估显示，87%提取的片段是幽默的，98%场景定位准确；系统能成功推广到预告片。

Conclusion: 该系统能够有效提升内容创作流程、改善用户参与度，并为多种电影媒体格式的短视频生成提供支持，展示了其在实际应用中的潜力。

Abstract: Automatically extracting engaging and high-quality humorous scenes from cinematic titles is pivotal for creating captivating video previews and snackable content, boosting user engagement on streaming platforms. Long-form cinematic titles, with their extended duration and complex narratives, challenge scene localization, while humor's reliance on diverse modalities and its nuanced style add further complexity. This paper introduces an end-to-end system for automatically identifying and ranking humorous scenes from long-form cinematic titles, featuring shot detection, multimodal scene localization, and humor tagging optimized for cinematic content. Key innovations include a novel scene segmentation approach combining visual and textual cues, improved shot representations via guided triplet mining, and a multimodal humor tagging framework leveraging both audio and text. Our system achieves an 18.3% AP improvement over state-of-the-art scene detection on the OVSD dataset and an F1 score of 0.834 for detecting humor in long text. Extensive evaluations across five cinematic titles demonstrate 87% of clips extracted by our pipeline are intended to be funny, while 98% of scenes are accurately localized. With successful generalization to trailers, these results showcase the pipeline's potential to enhance content creation workflows, improve user engagement, and streamline snackable content generation for diverse cinematic media formats.

</details>


### [41] [GaiaFlow: Semantic-Guided Diffusion Tuning for Carbon-Frugal Search](https://arxiv.org/abs/2602.15423)
*Rong Fu,Wenxin Zhang,Jia Yee Tan,Chunlei Meng,Shuo Yin,Xiaowen Ma,Wangyu Wu,Muge Qi,Guangzhen Yao,Zhaolu Kang,Zeli Su,Simon Fong*

Main category: cs.IR

TL;DR: GaiaFlow是一个用于实现碳节约搜索的创新框架，通过语义引导的扩散调优来平衡搜索精度与环境保护。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络架构的功率需求不断增长，信息检索领域认识到生态可持续性是一个关键优先事项，需要在模型设计上进行根本性范式转变。虽然当代神经排序器达到了前所未有的准确性，但其计算强度带来的重大环境外部性在大规模部署中常常被忽视。

Method: GaiaFlow框架采用语义引导的扩散调优，结合检索引导的Langevin动力学和硬件无关的性能建模策略来优化搜索精度与环境保护之间的权衡。该架构包含自适应早期退出协议和精度感知量化推理。

Result: 广泛的实验评估表明，GaiaFlow在效果和能源效率之间实现了优越的平衡，为下一代神经搜索系统提供了可扩展且可持续的路径。

Conclusion: GaiaFlow框架通过创新的方法显著降低了操作碳足迹，同时在不同计算基础设施上保持了稳健的检索质量，为可持续的神经搜索系统提供了可行方案。

Abstract: As the burgeoning power requirements of sophisticated neural architectures escalate, the information retrieval community has recognized ecological sustainability as a pivotal priority that necessitates a fundamental paradigm shift in model design. While contemporary neural rankers have attained unprecedented accuracy, the substantial environmental externalities associated with their computational intensity often remain overlooked in large-scale deployments. We present GaiaFlow, an innovative framework engineered to facilitate carbon-frugal search by operationalizing semantic-guided diffusion tuning. Our methodology orchestrates the convergence of retrieval-guided Langevin dynamics and a hardware-independent performance modeling strategy to optimize the trade-off between search precision and environmental preservation. By incorporating adaptive early exit protocols and precision-aware quantized inference, the proposed architecture significantly mitigates operational carbon footprints while maintaining robust retrieval quality across heterogeneous computing infrastructures. Extensive experimental evaluations demonstrate that GaiaFlow achieves a superior equilibrium between effectiveness and energy efficiency, offering a scalable and sustainable pathway for next-generation neural search systems.

</details>


### [42] [Binge Watch: Reproducible Multimodal Benchmarks Datasets for Large-Scale Movie Recommendation on MovieLens-10M and 20M](https://arxiv.org/abs/2602.15505)
*Giuseppe Spillo,Alessandro Petruzzelli,Cataldo Musto,Marco de Gemmis,Pasquale Lops,Giovanni Semeraro*

Main category: cs.IR

TL;DR: 本文发布了两个大规模、可复现的多模态电影推荐数据集M3L-10M和M3L-20M，通过为MovieLens数据集添加多模态特征（剧情、海报、预告片）并提取文本、视觉、音频和视频特征，解决了当前多模态推荐系统缺乏高质量公开数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推荐系统研究大多依赖小规模或未公开的数据集，或者使用未文档化的流程构建数据集，这阻碍了研究的可复现性和领域发展。

Method: 通过完全文档化的流程，在MovieLens-10M和MovieLens-20M基础上收集电影的剧情、海报和预告片，并使用多种最先进的编码器提取文本、视觉、音频和视频特征。

Result: 成功构建并公开发布了M3L-10M和M3L-20M两个大规模多模态数据集，包括原始数据映射、提取的特征以及多种格式的完整数据集，同时进行了定性和定量分析验证数据集质量。

Conclusion: 这项工作为大规模多模态电影推荐领域提供了可复现和可重复研究的基础资源，将推动多模态推荐系统领域的发展。

Abstract: With the growing interest in Multimodal Recommender Systems (MRSs), collecting high-quality datasets provided with multimedia side information (text, images, audio, video) has become a fundamental step. However, most of the current literature in the field relies on small- or medium-scale datasets that are either not publicly released or built using undocumented processes.
  In this paper, we aim to fill this gap by releasing M3L-10M and M3L-20M, two large-scale, reproducible, multimodal datasets for the movie domain, obtained by enriching with multimodal features the popular MovieLens-10M and MovieLens-20M, respectively. By following a fully documented pipeline, we collect movie plots, posters, and trailers, from which textual, visual, acoustic, and video features are extracted using several state-of-the-art encoders. We publicly release mappings to download the original raw data, the extracted features, and the complete datasets in multiple formats, fostering reproducibility and advancing the field of MRSs. In addition, we conduct qualitative and quantitative analyses that showcase our datasets across several perspectives.
  This work represents a foundational step to ensure reproducibility and replicability in the large-scale, multimodal movie recommendation domain. Our resource can be fully accessed at the following link: https://zenodo.org/records/18499145, while the source code is accessible at https://github.com/giuspillo/M3L_10M_20M.

</details>


### [43] [Eco-Amazon: Enriching E-commerce Datasets with Product Carbon Footprint for Sustainable Recommendations](https://arxiv.org/abs/2602.15508)
*Giuseppe Spillo,Allegra De Filippo,Cataldo Musto,Michela Milano,Giovanni Semeraro*

Main category: cs.IR

TL;DR: Eco-Amazon数据集在三个亚马逊数据集基础上添加了产品碳足迹元数据，为开发可持续检索和推荐系统提供资源支持


<details>
  <summary>Details</summary>
Motivation: 当前负责任和可持续AI研究中，信息检索和推荐系统需要超越传统准确度指标，纳入环境可持续性考量，但标准基准中缺乏项目级环境影响数据限制了这一研究方向

Method: 使用零样本框架，利用大型语言模型基于产品属性估计项目级产品碳足迹，为三个广泛使用的亚马逊数据集（家居、服装、电子产品）生成CO2e排放分数

Result: 发布了Eco-Amazon数据集，包含产品碳足迹信号；提供了LLM基础的PCF估计脚本；展示了如何利用PCF估计促进更可持续产品的用例

Conclusion: Eco-Amazon通过提供环境信号，使研究社区能够开发、基准测试和评估新一代可持续检索和推荐模型，推动AI向更环保方向发展

Abstract: In the era of responsible and sustainable AI, information retrieval and recommender systems must expand their scope beyond traditional accuracy metrics to incorporate environmental sustainability. However, this research line is severely limited by the lack of item-level environmental impact data in standard benchmarks. This paper introduces Eco-Amazon, a novel resource designed to bridge this gap. Our resource consists of an enriched version of three widely used Amazon datasets (i.e., Home, Clothing, and Electronics) augmented with Product Carbon Footprint (PCF) metadata. CO2e emission scores were generated using a zero-shot framework that leverages Large Language Models (LLMs) to estimate item-level PCF based on product attributes. Our contribution is three-fold: (i) the release of the Eco-Amazon datasets, enriching item metadata with PCF signals; (ii) the LLM-based PCF estimation script, which allows researchers to enrich any product catalogue and reproduce our results; (iii) a use case demonstrating how PCF estimates can be exploited to promote more sustainable products. By providing these environmental signals, Eco-Amazon enables the community to develop, benchmark, and evaluate the next generation of sustainable retrieval and recommendation models. Our resource is available at https://doi.org/10.5281/zenodo.18549130, while our source code is available at: http://github.com/giuspillo/EcoAmazon/.

</details>


### [44] [Can Recommender Systems Teach Themselves? A Recursive Self-Improving Framework with Fidelity Control](https://arxiv.org/abs/2602.15659)
*Luankang Zhang,Hao Wang,Zhongzhou Liu,Mingjia Yin,Yonghao Huang,Jiaqi Li,Wei Guo,Yong Liu,Huifeng Guo,Defu Lian,Enhong Chen*

Main category: cs.IR

TL;DR: 提出RSIR框架，通过模型自我生成高质量训练数据来缓解推荐系统中的数据稀疏问题，实现无需外部数据或教师模型的递归自我提升。


<details>
  <summary>Details</summary>
Motivation: 高质量训练数据的稀缺是机器学习模型扩展的根本瓶颈，在推荐系统中尤为严重。用户交互的极端稀疏性导致优化地形崎岖和泛化能力差。

Method: 提出递归自我改进推荐（RSIR）框架，采用闭环操作：当前模型生成可信的用户交互序列，基于保真度的质量控制机制筛选符合用户近似偏好流形的序列，然后在增强的数据集上训练后续模型。

Result: RSIR在多个基准测试和架构中带来一致、累积的增益。较小的模型也能受益，弱模型可以为强模型生成有效的训练课程。RSIR作为数据驱动的隐式正则化器，平滑优化地形并引导模型获得更稳健的解决方案。

Conclusion: 递归自我改进是一种通用、模型无关的方法，能够克服数据稀疏性，为推荐系统及其他领域提供了可扩展的前进路径。

Abstract: The scarcity of high-quality training data presents a fundamental bottleneck to scaling machine learning models. This challenge is particularly acute in recommendation systems, where extreme sparsity in user interactions leads to rugged optimization landscapes and poor generalization. We propose the Recursive Self-Improving Recommendation (RSIR) framework, a paradigm in which a model bootstraps its own performance without reliance on external data or teacher models. RSIR operates in a closed loop: the current model generates plausible user interaction sequences, a fidelity-based quality control mechanism filters them for consistency with user's approximate preference manifold, and a successor model is augmented on the enriched dataset. Our theoretical analysis shows that RSIR acts as a data-driven implicit regularizer, smoothing the optimization landscape and guiding models toward more robust solutions. Empirically, RSIR yields consistent, cumulative gains across multiple benchmarks and architectures. Notably, even smaller models benefit, and weak models can generate effective training curricula for stronger ones. These results demonstrate that recursive self-improvement is a general, model-agnostic approach to overcoming data sparsity, suggesting a scalable path forward for recommender systems and beyond. Our anonymized code is available at https://anonymous.4open.science/r/RSIR-7C5B .

</details>


### [45] [The Next Paradigm Is User-Centric Agent, Not Platform-Centric Service](https://arxiv.org/abs/2602.15682)
*Luankang Zhang,Hang Lv,Qiushi Pan,Kefen Wang,Yonghao Huang,Xinrui Miao,Yin Xu,Wei Guo,Yong Liu,Hao Wang,Enhong Chen*

Main category: cs.IR

TL;DR: 该论文主张数字服务应从平台中心模式转向用户中心代理模式，利用LLM和端侧智能技术实现真正以用户利益为导向的服务体系。


<details>
  <summary>Details</summary>
Motivation: 当前数字服务普遍采用平台中心模式，过度关注平台驱动的指标（如参与度、转化率），往往忽视用户的真实需求，导致平台目标与用户利益之间存在冲突。

Method: 提出向用户中心智能转型的框架，包括：1）探索转型的机遇与挑战；2）设计实用的端-云协同实现管道；3）讨论支持该转型的治理与生态系统结构。

Result: 论证了用户中心代理的可行性，强调其应具备隐私保护、用户目标对齐、用户控制权等核心特征，并指出LLM和端侧智能技术的发展使这一愿景成为可能。

Conclusion: 数字服务的未来应当从平台中心转向用户中心代理模式，这需要技术实现、治理框架和生态系统结构的协同变革，以实现真正以用户利益为导向的服务体系。

Abstract: Modern digital services have evolved into indispensable tools, driving the present large-scale information systems. Yet, the prevailing platform-centric model, where services are optimized for platform-driven metrics such as engagement and conversion, often fails to align with users' true needs. While platform technologies have advanced significantly-especially with the integration of large language models (LLMs)-we argue that improvements in platform service quality do not necessarily translate to genuine user benefit. Instead, platform-centric services prioritize provider objectives over user welfare, resulting in conflicts against user interests. This paper argues that the future of digital services should shift from a platform-centric to a user-centric agent. These user-centric agents prioritize privacy, align with user-defined goals, and grant users control over their preferences and actions. With advancements in LLMs and on-device intelligence, the realization of this vision is now feasible. This paper explores the opportunities and challenges in transitioning to user-centric intelligence, presents a practical device-cloud pipeline for its implementation, and discusses the necessary governance and ecosystem structures for its adoption.

</details>
