<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 40]
- [cs.IR](#cs.IR) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Incentives or Ontology? A Structural Rebuttal to OpenAI's Hallucination Thesis](https://arxiv.org/abs/2512.14801)
*Richard Ackermann,Simeon Emanuilov*

Main category: cs.CL

TL;DR: 本文挑战了OpenAI关于幻觉是优化问题的观点，认为幻觉是Transformer架构的结构性必然特征，只能通过外部验证和弃权模块来解决。


<details>
  <summary>Details</summary>
Motivation: OpenAI认为幻觉主要是评估激励机制不当导致的，可以通过改进基准和奖励结构来修复。本文挑战这一观点，认为幻觉不是优化失败，而是Transformer架构的结构性必然特征。

Method: 基于先前关于结构性幻觉的研究，使用Licensing Oracle进行实证实验，分析Transformer的嵌入空间形成机制及其在边界条件下的行为模式。

Result: 实证结果表明，幻觉只能通过外部真相验证和弃权模块消除，而不能通过改变激励机制、提示或微调来解决。Licensing Oracle能够实现完美的弃权精度，因为它提供了Transformer所缺乏的根基。

Conclusion: 幻觉是生成架构的结构性属性，可靠的AI需要混合系统来区分语言流畅性和认知责任，外部验证机制是必要的。

Abstract: OpenAI has recently argued that hallucinations in large language models result primarily from misaligned evaluation incentives that reward confident guessing rather than epistemic humility. On this view, hallucination is a contingent behavioral artifact, remediable through improved benchmarks and reward structures. In this paper, we challenge that interpretation. Drawing on previous work on structural hallucination and empirical experiments using a Licensing Oracle, we argue that hallucination is not an optimization failure but an architectural inevitability of the transformer model.
  Transformers do not represent the world; they model statistical associations among tokens. Their embedding spaces form a pseudo-ontology derived from linguistic co-occurrence rather than world-referential structure. At ontological boundary conditions - regions where training data is sparse or incoherent - the model necessarily interpolates fictional continuations in order to preserve coherence. No incentive mechanism can modify this structural dependence on pattern completion.
  Our empirical results demonstrate that hallucination can only be eliminated through external truth-validation and abstention modules, not through changes to incentives, prompting, or fine-tuning. The Licensing Oracle achieves perfect abstention precision across domains precisely because it supplies grounding that the transformer lacks.
  We conclude that hallucination is a structural property of generative architectures and that reliable AI requires hybrid systems that distinguish linguistic fluency from epistemic responsibility.

</details>


### [2] [Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media](https://arxiv.org/abs/2512.14887)
*Massimiliano Fadda,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino*

Main category: cs.CL

TL;DR: 本文改进了新闻观点分类管道，通过微调大语言模型和使用Wikidata丰富实体表示，在移民话题上取得了更好的分类性能。


<details>
  <summary>Details</summary>
Motivation: 新闻媒体在民主社会中塑造政治和社会话语，理解媒体观点动态对于评估媒体是否提供平衡公正的公共辩论至关重要。需要改进现有的观点分类方法来提高准确性。

Method: 1) 微调大语言模型用于观点分类；2) 使用Wikidata中的语义描述丰富相关实体的表示；3) 在UK移民辩论基准上评估改进的管道。

Result: 两种机制都能独立提高分类性能，但结合使用时效果最好，特别是使用能够处理长输入的大语言模型时。

Conclusion: 通过结合微调大语言模型和Wikidata实体语义增强，可以有效改进新闻观点分类的准确性，为分析媒体话语平衡性提供更好的工具。

Abstract: News sources play a central role in democratic societies by shaping political and social discourse through specific topics, viewpoints and voices. Understanding these dynamics is essential for assessing whether the media landscape offers a balanced and fair account of public debate. In earlier work, we introduced a pipeline that, given a news corpus, i) uses a hybrid human-machine approach to identify the range of viewpoints expressed about a given topic, and ii) classifies relevant claims with respect to the identified viewpoints, defined as sets of semantically and ideologically congruent claims (e.g., positions arguing that immigration positively impacts the UK economy). In this paper, we improve this pipeline by i) fine-tuning Large Language Models (LLMs) for viewpoint classification and ii) enriching claim representations with semantic descriptions of relevant actors drawn from Wikidata. We evaluate our approach against alternative solutions on a benchmark centred on the UK immigration debate. Results show that while both mechanisms independently improve classification performance, their integration yields the best results, particularly when using LLMs capable of processing long inputs.

</details>


### [3] [T5Gemma 2: Seeing, Reading, and Understanding Longer](https://arxiv.org/abs/2512.14856)
*Biao Zhang,Paul Suganthan,Gaël Liu,Ilya Philippov,Sahil Dua,Ben Hora,Kat Black,Gus Martins,Omar Sanseviero,Shreya Pathak,Cassidy Hardin,Francesco Visin,Jiageng Zhang,Kathleen Kenealy,Qin Yin,Olivier Lacombe,Armand Joulin,Tris Warkentin,Adam Roberts*

Main category: cs.CL

TL;DR: T5Gemma 2是基于Gemma 3的轻量级多模态编码器-解码器模型，通过改进的UL2适应策略和效率优化，在文本和视觉任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 扩展T5Gemma家族的轻量级编码器-解码器模型，增强多语言、多模态和长上下文处理能力，同时保持高效性。

Method: 1) 基于UL2适应策略将预训练的解码器模型转换为编码器-解码器架构；2) 引入共享词嵌入和合并注意力机制提升效率；3) 从纯文本扩展到多模态（基于Gemma 3）。

Result: 实验表明适应策略对架构和模态具有普适性，编码器-解码器结构在长上下文建模上表现突出，预训练和后训练性能均优于或相当于Gemma 3。

Conclusion: T5Gemma 2成功扩展了编码器-解码器模型的能力边界，在保持高效的同时提升了多模态和长上下文处理性能，并开源了三个规模的预训练模型。

Abstract: We introduce T5Gemma 2, the next generation of the T5Gemma family of lightweight open encoder-decoder models, featuring strong multilingual, multimodal and long-context capabilities. T5Gemma 2 follows the adaptation recipe (via UL2) in T5Gemma -- adapting a pretrained decoder-only model into an encoder-decoder model, and extends it from text-only regime to multimodal based on the Gemma 3 models. We further propose two methods to improve the efficiency: tied word embedding that shares all embeddings across encoder and decoder, and merged attention that unifies decoder self- and cross-attention into a single joint module. Experiments demonstrate the generality of the adaptation strategy over architectures and modalities as well as the unique strength of the encoder-decoder architecture on long context modeling. Similar to T5Gemma, T5Gemma 2 yields comparable or better pretraining performance and significantly improved post-training performance than its Gemma 3 counterpart. We release the pretrained models (270M-270M, 1B-1B and 4B-4B) to the community for future research.

</details>


### [4] [DASH: Dialogue-Aware Similarity and Handshake Recognition for Topic Segmentation in Public-Channel Conversations](https://arxiv.org/abs/2512.15042)
*Sijin Sun,Liangbin Zhao,Ming Deng,Xiuju Fu*

Main category: cs.CL

TL;DR: 提出DASH-DTS框架，通过对话握手识别进行主题分割，在真实海事VHF通信数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 任务导向的公共信道通信（如海事VHF对话）具有非正式语言和隐式过渡的特点，传统方法在对话主题分割上存在局限。

Method: 提出DASH-DTS框架，包含三个核心贡献：1) 通过对话握手识别检测主题转换；2) 相似性引导的示例选择进行上下文增强；3) 生成选择性正负样本以提升模型判别力和鲁棒性。

Result: 在VHF-Dial数据集和标准基准测试上实现了多个SOTA分割可信精度，同时发布了首个真实世界海事VHF通信公共数据集VHF-Dial。

Conclusion: DASH-DTS为操作对话的稳定监控和决策支持提供了坚实基础，能够提供可解释的推理和置信度评分。

Abstract: Dialogue Topic Segmentation (DTS) is crucial for understanding task-oriented public-channel communications, such as maritime VHF dialogues, which feature informal speech and implicit transitions. To address the limitations of traditional methods, we propose DASH-DTS, a novel LLM-based framework. Its core contributions are: (1) topic shift detection via dialogue handshake recognition; (2) contextual enhancement through similarity-guided example selection; and (3) the generation of selective positive and negative samples to improve model discrimination and robustness. Additionally, we release VHF-Dial, the first public dataset of real-world maritime VHF communications, to advance research in this domain. DASH-DTS provides interpretable reasoning and confidence scores for each segment. Experimental results demonstrate that our framework achieves several sota segmentation trusted accuracy on both VHF-Dial and standard benchmarks, establishing a strong foundation for stable monitoring and decision support in operational dialogues.

</details>


### [5] [DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline](https://arxiv.org/abs/2512.14896)
*Houman Kazemzadeh,Kiarash Mokhtari Dizaji,Seyed Reza Tavakoli,Farbod Davoodi,MohammadReza KarimiNejad,Parham Abed Azad,Ali Sabzi,Armin Khosravi,Siavash Ahmadi,Mohammad Hossein Rohban,Glolamali Aminian,Tahereh Javaheri*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在药学执业资格考试式问答任务上的表现，并开发了一种名为DrugRAG的外部知识集成方法，通过检索增强生成技术显著提升了模型准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在专业药学任务中的表现需要系统评估，同时需要开发有效的方法来提升这些模型在专业领域的准确性，特别是在不修改模型本身架构的情况下。

Method: 使用包含141个问题的药学数据集对11个不同参数规模（8B到70+B）的LLM进行基准测试，测量各模型的基础准确率。随后开发了三步检索增强生成（RAG）流程DrugRAG，从已验证来源检索结构化药物知识，并将基于证据的上下文信息融入模型提示中。

Result: 基础准确率范围从46%到92%，GPT-5（92%）和o3（89%）表现最佳。参数少于80亿的模型准确率低于50%。DrugRAG使所有测试模型的准确率提升了7-21个百分点，例如Gemma 3 27B从61%提升到71%，Llama 3.1 8B从46%提升到67%。

Conclusion: 通过DrugRAG进行外部结构化药物知识集成，可以在不修改底层模型的情况下显著提升LLM在药学任务上的准确性。这种方法为增强药学领域AI应用提供了实用的基于证据的信息集成流程。

Abstract: Objectives: To evaluate large language model (LLM) performance on pharmacy licensure-style question-answering (QA) tasks and develop an external knowledge integration method to improve their accuracy.
  Methods: We benchmarked eleven existing LLMs with varying parameter sizes (8 billion to 70+ billion) using a 141-question pharmacy dataset. We measured baseline accuracy for each model without modification. We then developed a three-step retrieval-augmented generation (RAG) pipeline, DrugRAG, that retrieves structured drug knowledge from validated sources and augments model prompts with evidence-based context. This pipeline operates externally to the models, requiring no changes to model architecture or parameters.
  Results: Baseline accuracy ranged from 46% to 92%, with GPT-5 (92%) and o3 (89%) achieving the highest scores. Models with fewer than 8 billion parameters scored below 50%. DrugRAG improved accuracy across all tested models, with gains ranging from 7 to 21 percentage points (e.g., Gemma 3 27B: 61% to 71%, Llama 3.1 8B: 46% to 67%) on the 141-item benchmark.
  Conclusion: We demonstrate that external structured drug knowledge integration through DrugRAG measurably improves LLM accuracy on pharmacy tasks without modifying the underlying models. This approach provides a practical pipeline for enhancing pharmacy-focused AI applications with evidence-based information.

</details>


### [6] [Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models](https://arxiv.org/abs/2512.14925)
*Caner Erden*

Main category: cs.CL

TL;DR: MAHA提出了一种多尺度聚合层次注意力机制，通过层次分解和数学优化聚合来降低自注意力计算复杂度，在4096序列长度下减少81%计算成本。


<details>
  <summary>Details</summary>
Motivation: 多头自注意力的二次计算复杂度限制了大型语言模型在长上下文任务中的扩展，现有稀疏和线性化注意力机制要么损害全局依赖表示，要么无法有效捕捉多尺度语义粒度。

Method: MAHA通过可学习下采样算子将输入序列动态划分为层次尺度，将尺度特定注意力矩阵的融合建模为资源分配问题，使用凸优化或博弈论方法求解，在混合扩张卷积-Transformer骨干中实现端到端训练。

Result: 实验评估显示MAHA具有优越的可扩展性，经验FLOPs分析表明在4096序列长度下相比标准注意力减少81%计算成本。

Conclusion: MAHA填补了优化理论与序列建模之间的空白，为下一代大型语言模型提供了可扩展的解决方案。

Abstract: The quadratic computational complexity of MultiHead SelfAttention (MHSA) remains a fundamental bottleneck in scaling Large Language Models (LLMs) for longcontext tasks. While sparse and linearized attention mechanisms attempt to mitigate this, they often compromise the representation of global dependencies or fail to capture multiscale semantic granularity effectively. In this paper, we propose Multiscale Aggregated Hierarchical Attention (MAHA), a novel architectural framework that reformulates the attention mechanism through hierarchical decomposition and mathematically rigorous aggregation. Unlike conventional approaches that treat token interactions at a single resolution, MAHA dynamically partitions the input sequence into hierarchical scales via learnable downsampling operators. The core innovation lies in its aggregation strategy: we model the fusion of scalespecific attention matrices as a resource allocation problem, solved via a convex optimization framework or a Nash equilibriumbased gametheoretic approach. This ensures a theoretically optimal balance between local nuance and global context fidelity. Implemented within a hybrid dilatedconvolutional transformer backbone, MAHA utilizes differentiable optimization layers to enable endtoend training. Experimental evaluations demonstrate that MAHA achieves superior scalability; empirical FLOPs analysis confirms an 81% reduction in computational cost at a sequence length of 4096 compared to standard attention. This work bridges the gap between optimization theory and sequence modeling, offering a scalable solution for nextgeneration LLMs.

</details>


### [7] [Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models](https://arxiv.org/abs/2512.14926)
*George-Andrei Dima,Dumitru-Clementin Cercel*

Main category: cs.CL

TL;DR: 将Flickr30k数据集翻译为罗马尼亚语并扩展为视觉问答数据集，使用LLaMA、LLaVA和Qwen2等开源VLM进行微调，显著提升了罗马尼亚语视觉QA和图像描述生成能力。


<details>
  <summary>Details</summary>
Motivation: 针对低资源语言（特别是罗马尼亚语）在生成式AI领域的资源不足问题，旨在缩小多模态NLP的资源差距，促进AI民主化。

Method: 1) 将Flickr30k数据集翻译为罗马尼亚语；2) 利用开源LLM扩展为视觉问答数据集；3) 使用LLaMA 3.2、LLaVA 1.6和Qwen2等开源VLM进行微调；4) 采用参数高效的LoRA方法进行训练。

Result: 1) 模型在罗马尼亚语视觉QA任务上表现显著提升；2) 在未专门训练的罗马尼亚语图像描述生成任务上也有改善；3) 70亿参数的Qwen2-VL-RoVQA在两项任务上均获得最佳分数，BERTScore F1分别提升6.05%和2.61%；4) 模型语法错误大幅减少，罗马尼亚语流畅度提高。

Conclusion: 通过创建罗马尼亚语多模态数据集并微调开源VLM，有效提升了罗马尼亚语视觉语言理解能力，为低资源语言的多模态AI发展提供了可行方案。

Abstract: Focusing on low-resource languages is an essential step toward democratizing generative AI. In this work, we contribute to reducing the multimodal NLP resource gap for Romanian. We translate the widely known Flickr30k dataset into Romanian and further extend it for visual question answering by leveraging open-source LLMs. We demonstrate the usefulness of our datasets by fine-tuning open-source VLMs on Romanian visual question answering. We select VLMs from three widely used model families: LLaMA 3.2, LLaVA 1.6, and Qwen2. For fine-tuning, we employ the parameter-efficient LoRA method. Our models show improved Romanian capabilities in visual QA, as well as on tasks they were not trained on, such as Romanian image description generation. The seven-billion-parameter Qwen2-VL-RoVQA obtains top scores on both tasks, with improvements of +6.05% and +2.61% in BERTScore F1 over its original version. Finally, the models show substantial reductions in grammatical errors compared to their original forms, indicating improvements not only in language understanding but also in Romanian fluency.

</details>


### [8] [Cross-Tokenizer Likelihood Scoring Algorithms for Language Model Distillation](https://arxiv.org/abs/2512.14954)
*Buu Phan,Ashish Khisti,Karen Ullrich*

Main category: cs.CL

TL;DR: 提出一种处理教师-学生语言模型tokenizer不匹配的概率框架，通过利用BPE的递归结构实现跨tokenizer的似然计算，支持词汇表子集和任意词汇表两种情况，在知识蒸馏中显著减少内存占用并提升性能。


<details>
  <summary>Details</summary>
Motivation: 当教师和学生语言模型使用不同的tokenizer时（如边缘设备部署需要更小的词汇表以减少内存开销），计算两者之间的token似然比变得困难，因为需要共享相同的概率空间。现有方法无法有效处理这种词汇表不对齐问题。

Method: 揭示了Byte-Pair Encoding (BPE)算法中隐含的递归结构，并利用这一结构创建了跨tokenizer似然计算的概率框架。针对两种场景：1）学生词汇表是教师词汇表的子集时，提供O(1)模型评估的精确似然计算；2）任意词汇表情况下，提出基于BPE递归结构的无损计算方法和快速近似方法。

Result: 在知识蒸馏中，该方法使Qwen2.5-1.5B模型的内存占用减少达12%，同时性能提升达4%。在数学推理任务中，GSM8K准确率比当前最佳方法提升超过2%。

Conclusion: 通过利用BPE的递归结构，提出的概率框架有效解决了语言模型知识蒸馏中的词汇表不对齐问题，支持词汇表子集和任意词汇表两种情况，在减少内存占用的同时提升了模型性能。

Abstract: Computing next-token likelihood ratios between two language models (LMs) is a standard task in training paradigms such as knowledge distillation. Since this requires both models to share the same probability space, it becomes challenging when the teacher and student LMs use different tokenizers, for instance, when edge-device deployment necessitates a smaller vocabulary size to lower memory overhead. In this work, we address this vocabulary misalignment problem by uncovering an implicit recursive structure in the commonly deployed Byte-Pair Encoding (BPE) algorithm and utilizing it to create a probabilistic framework for cross-tokenizer likelihood scoring. Our method enables sequence likelihood evaluation for vocabularies different from the teacher model native tokenizer, addressing two specific scenarios: when the student vocabulary is a subset of the teacher vocabulary, and the general case where it is arbitrary. In the subset regime, our framework computes exact likelihoods and provides next-token probabilities for sequential sampling with only O(1) model evaluations per token. When used for distillation, this yields up to a 12% reduction in memory footprint for the Qwen2.5-1.5B model while also improving baseline performance up to 4% on the evaluated tasks. For the general case, we introduce a rigorous lossless procedure that leverages BPE recursive structure, complemented by a fast approximation that keeps large-vocabulary settings practical. Applied to distillation for mathematical reasoning, our approach improves GSM8K accuracy by more than 2% over the current state of the art.

</details>


### [9] [Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams](https://arxiv.org/abs/2512.14989)
*Yiming Cui,Xin Yao,Yuxuan Qin,Xin Li,Shijin Wang,Guoping Hu*

Main category: cs.CL

TL;DR: 本研究系统评估了40个多模态大语言模型在化学奥林匹克竞赛题目上的表现，发现当前模型在多模态融合和科学推理方面存在显著局限，但思维链提示能有效提升性能。


<details>
  <summary>Details</summary>
Motivation: 多模态科学推理，特别是在化学领域，对大语言模型仍是一个重大挑战。化学问题解决需要整合符号图、分子结构和结构化视觉数据，当前模型在这些任务上的表现尚未得到系统评估。

Method: 研究者构建了基于20多年美国国家化学奥林匹克竞赛题目的基准测试，系统评估了40个专有和开源多模态大语言模型（包括GPT-5、o3、Gemini-2.5-Pro和Qwen2.5-VL）。采用思维链提示进行实验，并通过消融研究和基于遮挡的可解释性分析来评估模型表现。

Result: 研究发现许多模型在多模态融合方面存在困难，在某些情况下移除图像甚至能提高准确率，表明视觉-语言整合存在错位。思维链提示能持续提升准确率和视觉基础能力。当前多模态大语言模型的科学推理能力存在关键局限。

Conclusion: 该研究为领域特定的多模态AI提供了及时的基准测试，强调了在人工智能与科学推理交叉领域需要进一步进展，并为开发更稳健和可解释的多模态化学系统提供了可行策略。

Abstract: Multimodal scientific reasoning remains a significant challenge for large language models (LLMs), particularly in chemistry, where problem-solving relies on symbolic diagrams, molecular structures, and structured visual data. Here, we systematically evaluate 40 proprietary and open-source multimodal LLMs, including GPT-5, o3, Gemini-2.5-Pro, and Qwen2.5-VL, on a curated benchmark of Olympiad-style chemistry questions drawn from over two decades of U.S. National Chemistry Olympiad (USNCO) exams. These questions require integrated visual and textual reasoning across diverse modalities. We find that many models struggle with modality fusion, where in some cases, removing the image even improves accuracy, indicating misalignment in vision-language integration. Chain-of-Thought prompting consistently enhances both accuracy and visual grounding, as demonstrated through ablation studies and occlusion-based interpretability. Our results reveal critical limitations in the scientific reasoning abilities of current MLLMs, providing actionable strategies for developing more robust and interpretable multimodal systems in chemistry. This work provides a timely benchmark for measuring progress in domain-specific multimodal AI and underscores the need for further advances at the intersection of artificial intelligence and scientific reasoning.

</details>


### [10] [SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification](https://arxiv.org/abs/2512.15052)
*Hongbo Wang,MaungMaung AprilPyone,Isao Echizen*

Main category: cs.CL

TL;DR: SGM提出了一种白盒神经元级多模态干预方法，通过软抑制有毒专家神经元来降低多模态大语言模型的毒性，无需参数更新。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型从弱监督的预训练语料中继承了有毒、偏见和NSFW信号，存在安全风险。现有的训练后解毒方法在面对对抗性触发时效果不佳，需要更有效的解决方案。

Method: SGM采用白盒神经元级干预，通过专业知识加权的软抑制方法，有选择性地重新校准一小部分有毒专家神经元，中和有害的跨模态激活，且无需参数更新。

Result: 实验表明SGM在标准和对抗条件下都能有效降低毒性，将有害率从48.2%降至2.5%，同时保持模型的流畅性和多模态推理能力。SGM*与其他解毒方法结合后能提供更强的安全性能。

Conclusion: SGM提供了一种可解释、低成本的毒性控制多模态生成解决方案，通过神经元级干预有效提升多模态大语言模型的安全性。

Abstract: Disclaimer: Samples in this paper may be harmful and cause discomfort.
  Multimodal large language models (MLLMs) enable multimodal generation but inherit toxic, biased, and NSFW signals from weakly curated pretraining corpora, causing safety risks, especially under adversarial triggers that late, opaque training-free detoxification methods struggle to handle. We propose SGM, a white-box neuron-level multimodal intervention that acts like safety glasses for toxic neurons: it selectively recalibrates a small set of toxic expert neurons via expertise-weighted soft suppression, neutralizing harmful cross-modal activations without any parameter updates. We establish MM-TOXIC-QA, a multimodal toxicity evaluation framework, and compare SGM with existing detoxification techniques. Experiments on open-source MLLMs show that SGM mitigates toxicity in standard and adversarial conditions, cutting harmful rates from 48.2\% to 2.5\% while preserving fluency and multimodal reasoning. SGM is extensible, and its combined defenses, denoted as SGM*, integrate with existing detoxification methods for stronger safety performance, providing an interpretable, low-cost solution for toxicity-controlled multimodal generation.

</details>


### [11] [The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops](https://arxiv.org/abs/2512.15053)
*Fanzhe Fu*

Main category: cs.CL

TL;DR: 本文提出了Meta-Prompting Protocol，一个将LLM编排形式化为可编程自优化系统的理论框架，通过对抗性三元结构（生成器、审计器、优化器）来提供确定性保证。


<details>
  <summary>Details</summary>
Motivation: 当前基于启发式的"提示工程"方法无法为关键任务应用提供确定性保证，需要重新设计LLM交互范式以使其成为可靠的软件组件。

Method: 引入Meta-Prompting Protocol框架，采用对抗性三元拓扑结构（生成器P、审计器A、优化器O），将自然语言指令视为语义计算图中的可微分变量，并使用文本批评作为梯度。

Result: 通过声明式编程范式（DSPy）和自动文本微分（TextGrad）证明了该方法的理论可行性，能够缓解幻觉问题并防止模型崩溃。

Conclusion: 为概率计算时代的"可观测软件工程"奠定了基础，使LLM能够从随机聊天接口转变为可靠的软件组件。

Abstract: The transition of Large Language Models (LLMs) from stochastic chat interfaces to reliable software components necessitates a fundamental re-engineering of interaction paradigms. Current methodologies, predominantly heuristic-based "prompt engineering," fail to provide the deterministic guarantees required for mission-critical applications. We introduce the Meta-Prompting Protocol, a rigorous theoretical framework that formalizes the orchestration of LLMs as a programmable, self-optimizing system. Central to this protocol is the Adversarial Trinity, a tripartite topology comprising a Generator (P), an Auditor (A), and an Optimizer (O). By treating natural language instructions as differentiable variables within a semantic computation graph and utilizing textual critiques as gradients, this architecture mitigates hallucination and prevents model collapse. We demonstrate the theoretical viability of this approach using declarative programming paradigms (DSPy) and automatic textual differentiation (TextGrad), establishing a foundation for "Observable Software Engineering" in the era of probabilistic computing.

</details>


### [12] [Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning](https://arxiv.org/abs/2512.15146)
*Weiqin Wang,Yile Wang,Kehao Chen,Hui Huang*

Main category: cs.CL

TL;DR: SCOPE框架通过引入步进置信度加权和动态子群划分，改进测试时强化学习中的伪标签估计，缓解多数投票带来的确认偏差和稀疏奖励问题，提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时强化学习依赖多数投票结果作为伪标签，但这种方法容易导致确认偏差且存在稀疏奖励问题，限制了模型性能的提升。

Method: 提出SCOPE框架：1) 引入步进置信度加权机制，优先选择高质量推理路径而非简单频率统计；2) 动态划分候选输出池为独立子群，平衡推理质量与探索多样性；3) 通过重复采样为每个子群推导局部共识，提供多样化监督目标。

Result: SCOPE在多个模型和基准测试中均优于现有基线方法，在AIME 2025上取得13.1%的相对提升，在AMC上取得8.1%的相对提升。

Conclusion: SCOPE通过结合模型置信度和动态子群划分，有效解决了测试时强化学习中的确认偏差和稀疏奖励问题，为大语言模型的推理能力提升提供了有效框架。

Abstract: Test-time reinforcement learning mitigates the reliance on annotated data by using majority voting results as pseudo-labels, emerging as a complementary direction to reinforcement learning with verifiable rewards (RLVR) for improving reasoning ability of large language models (LLMs). However, this voting strategy often induces confirmation bias and suffers from sparse rewards, limiting the overall performance. In this work, we propose subgroup-specific step-wise confidence-weighted pseudo-label estimation (SCOPE), a framework integrating model confidence and dynamic subgroup partitioning to address these issues. Specifically, SCOPE integrates the proposed step-wise confidence into pseudo label deduction, prioritizing high-quality reasoning paths over simple frequency count. Furthermore, it dynamically partitions the candidate outputs pool into independent subgroups by balancing reasoning quality against exploration diversity. By deriving local consensus via repeat sampling for each sub group, SCOPE provides diverse supervision targets to encourage broader exploration. We conduct experiments across various models and benchmarks, experimental results show that SCOPE consistently outperforms recent baselines. Notably, SCOPE achieving relative improvements of 13.1\% on challenging AIME 2025 and 8.1\% on AMC. The code is released at \href{https://github.com/szu-tera/SCOPE}{https://github.com/szu-tera/SCOPE}.

</details>


### [13] [Rakuten Data Release: A Large-Scale and Long-Term Reviews Corpus for Hotel Domain](https://arxiv.org/abs/2512.15151)
*Yuki Nakayama,Koki Hikichi,Yun Ching Liu,Yu Hirate*

Main category: cs.CL

TL;DR: 本文介绍了乐天旅游评论的大规模语料库，包含2009-2024年730万条评论，涵盖多维度信息，并分析了2019-2024年间的数据漂移因素。


<details>
  <summary>Details</summary>
Motivation: 构建一个全面、大规模的旅游评论数据集，为自然语言处理、推荐系统和旅游研究提供资源，同时分析疫情期间的数据变化模式。

Method: 收集了2009年至2024年乐天旅游平台的730万条客户评论，每条记录包含文本评论、商家回复、用户评分等15个字段，并使用统计方法分析数据漂移。

Result: 创建了包含730万条评论、跨度16年的大规模语料库，提供了详细的统计信息，并识别了2019-2024年间影响数据漂移的关键因素。

Conclusion: 该语料库为旅游领域研究提供了宝贵资源，有助于理解用户行为变化，特别是在疫情等重大事件期间的数据演化模式。

Abstract: This paper presents a large-scale corpus of Rakuten Travel Reviews. Our collection contains 7.3 million customer reviews for 16 years, ranging from 2009 to 2024. Each record in the dataset contains the review text, its response from an accommodation, an anonymized reviewer ID, review date, accommodation ID, plan ID, plan title, room type, room name, purpose, accompanying group, and user ratings from different aspect categories, as well as an overall score. We present statistical information about our corpus and provide insights into factors driving data drift between 2019 and 2024 using statistical approaches.

</details>


### [14] [MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers](https://arxiv.org/abs/2512.15163)
*Xuanjun Zong,Zhiqi Shen,Lei Wang,Yunshi Lan,Chao Yang*

Main category: cs.CL

TL;DR: MCP-SafetyBench是一个针对MCP（模型上下文协议）安全性的综合基准测试，基于真实MCP服务器构建，支持多轮评估，涵盖五个领域，包含20种攻击类型分类，用于评估LLM在现实MCP部署中的安全风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLM演变为能够推理、规划和操作外部工具的智能体系统，MCP作为连接LLM与异构工具的标准接口变得至关重要。然而，MCP的开放性和多服务器工作流程带来了新的安全风险，现有基准测试无法有效捕捉这些风险，因为它们要么关注孤立攻击，要么缺乏现实世界覆盖。

Method: 研究构建了MCP-SafetyBench基准测试，基于真实MCP服务器，支持五个领域（浏览器自动化、金融分析、位置导航、仓库管理、网络搜索）的现实多轮评估。该基准包含统一的20种MCP攻击类型分类，涵盖服务器、主机和用户三方面，并设计了需要多步推理和跨服务器协调的任务。

Result: 使用MCP-SafetyBench对领先的开源和闭源LLM进行系统评估，结果显示安全性能存在巨大差异，随着任务范围和服务器交互的增加，漏洞风险呈上升趋势。评估揭示了现实MCP部署中的严重安全脆弱性。

Conclusion: 研究结果强调了加强防御措施的紧迫性，并将MCP-SafetyBench确立为诊断和缓解现实世界MCP部署中安全风险的基础工具，为未来MCP安全研究提供了重要基准。

Abstract: Large language models (LLMs) are evolving into agentic systems that reason, plan, and operate external tools. The Model Context Protocol (MCP) is a key enabler of this transition, offering a standardized interface for connecting LLMs with heterogeneous tools and services. Yet MCP's openness and multi-server workflows introduce new safety risks that existing benchmarks fail to capture, as they focus on isolated attacks or lack real-world coverage. We present MCP-SafetyBench, a comprehensive benchmark built on real MCP servers that supports realistic multi-turn evaluation across five domains: browser automation, financial analysis, location navigation, repository management, and web search. It incorporates a unified taxonomy of 20 MCP attack types spanning server, host, and user sides, and includes tasks requiring multi-step reasoning and cross-server coordination under uncertainty. Using MCP-SafetyBench, we systematically evaluate leading open- and closed-source LLMs, revealing large disparities in safety performance and escalating vulnerabilities as task horizons and server interactions grow. Our results highlight the urgent need for stronger defenses and establish MCP-SafetyBench as a foundation for diagnosing and mitigating safety risks in real-world MCP deployments.

</details>


### [15] [From NLG Evaluation to Modern Student Assessment in the Era of ChatGPT: The Great Misalignment Problem and Pedagogical Multi-Factor Assessment (P-MFA)](https://arxiv.org/abs/2512.15183)
*Mika Hämäläinen,Kimmo Leiviskä*

Main category: cs.CL

TL;DR: 本文探讨了NLG评估与芬兰大学学生评分之间的认知相似性，提出了"大错位问题"，并引入基于过程的P-MFA评估模型来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 随着学生越来越多地使用ChatGPT等工具生成复杂输出，传统基于最终产物的评估方法已经失去有效性，需要在评估逻辑上进行根本性转变。

Method: 提出了P-MFA（教学多因素评估）模型，这是一个基于过程的多证据框架，其逻辑受到多因素身份验证的启发。

Result: 识别了NLG评估与学生评分领域共同面临的"大错位问题"，并提出了解决该问题的过程性评估框架。

Conclusion: 教育评估需要从关注最终产品转向关注学习过程，P-MFA模型为解决AI工具普及背景下的评估有效性提供了可行路径。

Abstract: This paper explores the growing epistemic parallel between NLG evaluation and grading of students in a Finnish University. We argue that both domains are experiencing a Great Misalignment Problem. As students increasingly use tools like ChatGPT to produce sophisticated outputs, traditional assessment methods that focus on final products rather than learning processes have lost their validity. To address this, we introduce the Pedagogical Multi-Factor Assessment (P-MFA) model, a process-based, multi-evidence framework inspired by the logic of multi-factor authentication.

</details>


### [16] [RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA](https://arxiv.org/abs/2512.15219)
*Chao Zhang,Minghan Li,Tianrui Lv,Guodong Zhou*

Main category: cs.CL

TL;DR: RFKG-CoT通过关系驱动的自适应跳数选择器和少样本上下文学习路径指导机制，改进了KG-CoT在知识图谱问答中的表现，显著减少了LLM的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法如KG-CoT虽然通过整合知识图谱路径提高了可靠性，但存在两个主要问题：1) 僵化的跳数选择（仅基于问题驱动）；2) 对推理路径的利用不足（缺乏指导）。这导致在知识密集型QA中LLM仍然容易产生幻觉。

Method: 提出RFKG-CoT方法：1) 用关系驱动的自适应跳数选择器替代僵化的跳数选择器，通过关系掩码动态调整推理步骤；2) 引入少样本上下文学习路径指导机制，以"问题-路径-答案"格式构建示例，增强LLM对推理路径的理解能力。

Result: 在四个KGQA基准测试中，RFKG-CoT相比KG-CoT在Llama2-7B上最高提升14.7个百分点（WebQSP数据集）。消融实验证实跳数选择器和路径提示是互补的，共同将KG证据转化为更可靠的答案。

Conclusion: RFKG-CoT通过自适应跳数选择和路径指导机制，有效解决了现有KG-CoT方法的局限性，显著提高了知识图谱问答的准确性和可靠性，减少了LLM的幻觉问题。

Abstract: Large language models (LLMs) often generate hallucinations in knowledge-intensive QA due to parametric knowledge limitations. While existing methods like KG-CoT improve reliability by integrating knowledge graph (KG) paths, they suffer from rigid hop-count selection (solely question-driven) and underutilization of reasoning paths (lack of guidance). To address this, we propose RFKG-CoT: First, it replaces the rigid hop-count selector with a relation-driven adaptive hop-count selector that dynamically adjusts reasoning steps by activating KG relations (e.g., 1-hop for direct "brother" relations, 2-hop for indirect "father-son" chains), formalized via a relation mask. Second, it introduces a few-shot in-context learning path guidance mechanism with CoT (think) that constructs examples in a "question-paths-answer" format to enhance LLMs' ability to understand reasoning paths. Experiments on four KGQA benchmarks show RFKG-CoT improves accuracy by up to 14.7 pp (Llama2-7B on WebQSP) over KG-CoT. Ablations confirm the hop-count selector and the path prompt are complementary, jointly transforming KG evidence into more faithful answers.

</details>


### [17] [Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024](https://arxiv.org/abs/2512.15226)
*Yash Bhaskar,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: Yes-MT团队在WMT 2024低资源印度语言翻译任务中，针对英语与阿萨姆语、米佐语、卡西语、曼尼普尔语之间的翻译，探索了多种方法，包括微调预训练模型、LLM提示、LoRA微调等，结果显示LLM微调在低资源翻译中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 解决低资源印度语言（阿萨姆语、米佐语、卡西语、曼尼普尔语）与英语之间的机器翻译问题，这些语言由于资源稀缺，传统翻译方法效果有限。

Method: 采用多种方法：1) 微调预训练模型（mT5、IndicBart）的多语言和单语言版本；2) 使用LoRA微调IndicTrans2；3) 对大型语言模型（Llama 3、Mixtral 8x7b）进行零样本和少样本提示；4) 对Llama 3进行LoRA监督微调；5) 从头训练Transformer模型。

Result: 使用WMT23测试数据通过SacreBLEU和CHRF进行评估，结果显示低资源翻译具有挑战性，但大型语言模型特别是经过微调后，在这些任务中展现出潜力。

Conclusion: 该研究证实了低资源印度语言翻译的困难，同时展示了大型语言模型通过适当微调可以有效应对这些挑战，为低资源语言翻译提供了有前景的方向。

Abstract: This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024 (Pakray et al., 2024), focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, including fine-tuning pre-trained models like mT5 (Xue et al., 2020) and IndicBart (Dabre et al., 2021) in both multilingual and monolingual settings, LoRA (Hu et al., 2021) fine-tuning IndicTrans2 (Gala et al., 2023), zero-shot and few-shot prompting (Brown, 2020) with large language models (LLMs) like Llama 3 (Dubey et al., 2024) and Mixtral 8x7b (Jiang et al., 2024), LoRA supervised fine-tuning of Llama 3 (Mecklenburg et al., 2024), and training Transformer models (Vaswani, 2017) from scratch. The results were evaluated on the WMT23 Low-Resource Indic Language Translation Shared Task test data using SacreBLEU (Post, 2018) and CHRF (Popovic, 2015), highlighting the challenges of low-resource translation and the potential of LLMs for these tasks, particularly with fine-tuning.

</details>


### [18] [FAME: Fictional Actors for Multilingual Erasure](https://arxiv.org/abs/2512.15235)
*Claudio Savelli,Moreno La Quatra,Alkis Koudounas,Flavio Giobergia*

Main category: cs.CL

TL;DR: FAME是一个用于评估大语言模型机器遗忘的多语言合成基准，支持实体级和实例级遗忘评估，包含5种语言的虚构演员传记和问答对。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型机器遗忘基准存在两大局限：仅支持英语，且仅支持实体级遗忘（完全删除某个人的所有信息）。这限制了机器遗忘技术在多语言环境和细粒度遗忘场景下的评估。

Method: 构建FAME基准，包含1000个虚构演员传记和20000个问答对，覆盖英语、法语、德语、意大利语和西班牙语五种语言。每个传记包含20个主题的结构化信息（传记、职业生涯、成就、个人信息），支持实体级和实例级两种遗忘场景。

Result: FAME基准提供了两种数据集划分来支持实体级遗忘（忘记整个身份）和实例级遗忘（忘记特定事实而保留其他信息）。由于使用完全虚构的数据，确保模型在预训练阶段从未接触过这些信息，为机器遗忘方法提供了受控的评估环境。

Conclusion: FAME基准填补了现有机器遗忘评估在多语言支持和细粒度遗忘方面的空白，为机器遗忘技术提供了系统性的跨语言比较平台，有助于推动机器遗忘技术的发展和应用。

Abstract: LLMs trained on web-scale data raise concerns about privacy and the right to be forgotten. To address these issues, Machine Unlearning provides techniques to remove specific information from trained models without retraining from scratch. However, existing benchmarks for evaluating unlearning in LLMs face two major limitations: they focus only on English and support only entity-level forgetting (removing all information about a person). We introduce FAME (Fictional Actors for Multilingual Erasure), a synthetic benchmark for evaluating Machine Unlearning across five languages: English, French, German, Italian, and Spanish. FAME contains 1,000 fictional actor biographies and 20,000 question-answer pairs. Each biography includes information on 20 topics organized into structured categories (biography, career, achievements, personal information). This design enables both entity-level unlearning (i.e., forgetting entire identities) and instance-level unlearning (i.e., forgetting specific facts while retaining others). We provide two dataset splits to support these two different unlearning scenarios and enable systematic comparison of unlearning techniques across languages. Since FAME uses entirely fictional data, it ensures that the information was never encountered during model pretraining, allowing for a controlled evaluation of unlearning methods.

</details>


### [19] [The Moralization Corpus: Frame-Based Annotation and Analysis of Moralizing Speech Acts across Diverse Text Genres](https://arxiv.org/abs/2512.15248)
*Maria Becker,Mirko Sommer,Lars Tapken,Yi Wan Teh,Bruno Brocai*

Main category: cs.CL

TL;DR: 本文介绍了Moralization Corpus，这是一个用于分析论证话语中道德价值观战略使用的新型多体裁数据集，并评估了LLM在道德化检测任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 道德化（援引道德价值观来论证立场）是一种尚未充分探索的说服性沟通形式，其语用复杂且通常隐含，对人工标注和NLP系统都构成重大挑战。

Method: 开发了基于框架的标注方案，捕捉道德化的构成要素（道德价值观、要求和话语主体），并将其应用于德国政治辩论、新闻文章和在线讨论等多体裁文本。进一步评估了多种LLM在不同提示条件下的道德化检测和成分提取能力。

Result: 详细提示指令比少样本或基于解释的提示效果更好；道德化检测仍然是一个高度主观和语境敏感的任务。发布了所有数据、标注指南和代码。

Conclusion: 该语料库支持跨沟通形式和领域的道德化语言细粒度分析，促进了NLP中道德话语和道德推理的跨学科研究。

Abstract: Moralizations - arguments that invoke moral values to justify demands or positions - are a yet underexplored form of persuasive communication. We present the Moralization Corpus, a novel multi-genre dataset designed to analyze how moral values are strategically used in argumentative discourse. Moralizations are pragmatically complex and often implicit, posing significant challenges for both human annotators and NLP systems. We develop a frame-based annotation scheme that captures the constitutive elements of moralizations - moral values, demands, and discourse protagonists - and apply it to a diverse set of German texts, including political debates, news articles, and online discussions. The corpus enables fine-grained analysis of moralizing language across communicative formats and domains. We further evaluate several large language models (LLMs) under varied prompting conditions for the task of moralization detection and moralization component extraction and compare it to human annotations in order to investigate the challenges of automatic and manual analysis of moralizations. Results show that detailed prompt instructions has a greater effect than few-shot or explanation-based prompting, and that moralization remains a highly subjective and context-sensitive task. We release all data, annotation guidelines, and code to foster future interdisciplinary research on moral discourse and moral reasoning in NLP.

</details>


### [20] [SynGP500: A Clinically-Grounded Synthetic Dataset of Australian General Practice Medical Notes](https://arxiv.org/abs/2512.15259)
*Piyawoot Songsiritat*

Main category: cs.CL

TL;DR: SynGP500是一个包含500份澳大利亚全科医疗记录的合成数据集，通过临床医生精心设计，整合了课程要求的临床广度、流行病学校准的患病率以及多样化的就诊情境，旨在支持更通用的临床NLP模型训练。


<details>
  <summary>Details</summary>
Motivation: 解决澳大利亚缺乏适用于全科医疗临床NLP研究的真实数据集问题。现有数据集要么受限于自然病例分布的偏倚，要么过于简化而无法反映真实的临床复杂性，同时还需要保护患者隐私。

Method: 创建了临床医生精心设计的合成数据集，整合了RACGP 2022课程要求的临床广度、BEACH研究的流行病学校准患病率，以及多样化的就诊情境。数据集特意设计为"混乱"状态，包含电报式文档、拼写错误、患者不依从、社会经济障碍和医患分歧等真实临床特征。

Result: 通过多方面验证证明数据集质量：1) 流行病学与真实澳大利亚GP就诊模式（BEACH研究）对齐；2) 文体分析确认高语言变异性；3) 语义多样性分析显示广泛覆盖；4) 探索性下游评估使用自监督医疗概念提取显示F1分数提升。

Conclusion: SynGP500填补了澳大利亚的关键研究空白，为研究人员和教育工作者提供了开发和评估澳大利亚全科医疗临床NLP方法的资源，同时固有地保护了患者隐私。

Abstract: We introduce SynGP500, a clinician-curated collection of 500 synthetic Australian general practice medical notes. The dataset integrates curriculum-based clinical breadth (RACGP 2022 Curriculum), epidemiologically-calibrated prevalence (BEACH study), and diverse consultation contexts. This approach systematically includes both common presentations and less-common curriculum-specified conditions that GPs must recognize but appear infrequently in single practice populations, potentially supporting more generalizable model training than datasets constrained by naturally occurring case distributions. SynGP500 is messy by design, reflecting the authentic complexity of healthcare delivery: telegraphic documentation, typos, patient non-adherence, socioeconomic barriers, and clinician-patient disagreements, unlike sanitized synthetic datasets that obscure clinical realities. Multi-faceted validation demonstrates dataset quality through epidemiological alignment with real Australian GP consultation patterns (BEACH study), stylometric analysis confirming high linguistic variation, semantic diversity analysis demonstrating broad coverage, and exploratory downstream evaluation using self-supervised medical concept extraction, showing F1 improvements. SynGP500 addresses a critical national gap, providing researchers and educators with a resource for developing and evaluating clinical NLP methods for Australian general practice while inherently protecting patient privacy.

</details>


### [21] [Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning](https://arxiv.org/abs/2512.15274)
*Yiliu Sun,Zicheng Zhao,Yang Wei,Yanfang Zhang,Chen Gong*

Main category: cs.CL

TL;DR: PPPO是一种新的RLVR方法，专注于优化LLM生成的前缀token，通过渐进式前缀保留和延续累积奖励策略，显著提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法对所有生成token进行统一训练，忽视了前缀token对推理的关键贡献，导致大量训练资源浪费在低回报token上，限制了高回报token的优化潜力。

Method: 提出渐进式前缀策略优化（PPPO）：1）识别LLM推理中的"起始锁定效应"现象；2）引入渐进式前缀保留策略，逐步增加训练中保留的前缀token比例；3）采用延续累积奖励策略，通过采样多个延续序列并累积其得分作为奖励信号，减少奖励偏差。

Result: 在各种推理任务上的实验结果表明，PPPO在仅使用26.17%训练token的情况下，比代表性RLVR方法准确率提升18.02%。

Conclusion: PPPO通过专注于优化前缀推理过程，有效提升了LLM的推理能力，证明了前缀token在推理中的关键作用，为RLVR方法提供了新的优化方向。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which tokens (e.g., prefix tokens) actually contribute to reasoning. This uniform training strategy spends substantial effort on optimizing low-return tokens, which in turn impedes the potential improvement from high-return tokens and reduces overall training effectiveness. To address this issue, we propose a novel RLVR approach called Progressive Prefix-token Policy Optimization (PPPO), which highlights the significance of the prefix segment of generated outputs. Specifically, inspired by the well-established human thinking theory of Path Dependence, where early-stage thoughts substantially constrain subsequent thinking trajectory, we identify an analogous phenomenon in LLM reasoning termed Beginning Lock-in Effect (BLE). PPPO leverages this finding by focusing its optimization objective on the prefix reasoning process of LLMs. This targeted optimization strategy can positively influence subsequent reasoning processes, and ultimately improve final results. To improve the learning effectiveness of LLMs on how to start reasoning with high quality, PPPO introduces two training strategies: (a) Progressive Prefix Retention, which shapes a progressive learning process by increasing the proportion of retained prefix tokens during training; (b) Continuation Accumulated Reward, which mitigates reward bias by sampling multiple continuations for one prefix token sequence, and accumulating their scores as the reward signal. Extensive experimental results on various reasoning tasks demonstrate that our proposed PPPO outperforms representative RLVR methods, with the accuracy improvements of 18.02% on only 26.17% training tokens.

</details>


### [22] [Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues](https://arxiv.org/abs/2512.15302)
*Xiaotian Zhang,Yuan Wang,Ruizhe Chen,Zeya Wang,Runchen Hou,Zuozhu Liu*

Main category: cs.CL

TL;DR: PersonalAgent是一个面向LLM的终身个性化代理，通过动态构建统一用户画像来持续推断和适应用户偏好，解决长期个性化和冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐技术主要关注普适人类价值观或静态单轮偏好，无法解决长期个性化需求和用户冷启动问题，需要更精细的用户偏好适应机制。

Method: 将对话分解为单轮交互，将偏好推断构建为序列决策任务，动态构建和优化统一用户画像，实现持续的用户偏好学习和适应。

Result: 实验显示PersonalAgent在理想和嘈杂对话场景中均优于基于提示和策略优化的基线方法，保持跨会话偏好一致性，人工评估确认其能自然连贯地捕捉用户偏好。

Conclusion: 终身个性化对开发更具包容性和适应性的对话代理至关重要，PersonalAgent为解决LLM长期个性化对齐问题提供了有效方案。

Abstract: The deployment of Large Language Models (LLMs) in interactive systems necessitates a deep alignment with the nuanced and dynamic preferences of individual users. Current alignment techniques predominantly address universal human values or static, single-turn preferences, thereby failing to address the critical needs of long-term personalization and the initial user cold-start problem. To bridge this gap, we propose PersonalAgent, a novel user-centric lifelong agent designed to continuously infer and adapt to user preferences. PersonalAgent constructs and dynamically refines a unified user profile by decomposing dialogues into single-turn interactions, framing preference inference as a sequential decision-making task. Experiments show that PersonalAgent achieves superior performance over strong prompt-based and policy optimization baselines, not only in idealized but also in noisy conversational contexts, while preserving cross-session preference consistency. Furthermore, human evaluation confirms that PersonalAgent excels at capturing user preferences naturally and coherently. Our findings underscore the importance of lifelong personalization for developing more inclusive and adaptive conversational agents. Our code is available here.

</details>


### [23] [Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies](https://arxiv.org/abs/2512.15312)
*Charan Prakash Rathore,Saumi Ray,Dhruv Kumar*

Main category: cs.CL

TL;DR: 评估LLMs在沸石合成实验信息提取中的效果，发现高级提示策略改进有限，精确参数提取需要领域适应模型


<details>
  <summary>Details</summary>
Motivation: 现有方法未系统评估LLMs在沸石合成实验信息提取这一领域特定任务中的效果，需要研究不同提示策略的有效性

Method: 评估四种提示策略（零样本、少样本、事件特定、反思式）在六个最先进LLMs上的表现，使用ZSEE数据集（1,530标注句子），关注四个子任务：事件类型分类、触发文本识别、参数角色提取、参数文本提取

Result: 事件类型分类表现良好（80-90% F1），但细粒度提取任务表现一般（50-65% F1）。GPT-5-mini显示极大提示敏感性（11-79% F1变化）。高级提示策略相比零样本方法改进有限

Conclusion: LLMs虽能实现高层次理解，但精确提取实验参数需要领域适应模型，研究为科学信息提取提供了定量基准

Abstract: Extracting structured information from zeolite synthesis experimental procedures is critical for materials discovery, yet existing methods have not systematically evaluated Large Language Models (LLMs) for this domain-specific task. This work addresses a fundamental question: what is the efficacy of different prompting strategies when applying LLMs to scientific information extraction? We focus on four key subtasks: event type classification (identifying synthesis steps), trigger text identification (locating event mentions), argument role extraction (recognizing parameter types), and argument text extraction (extracting parameter values). We evaluate four prompting strategies - zero-shot, few-shot, event-specific, and reflection-based - across six state-of-the-art LLMs (Gemma-3-12b-it, GPT-5-mini, O4-mini, Claude-Haiku-3.5, DeepSeek reasoning and non-reasoning) using the ZSEE dataset of 1,530 annotated sentences. Results demonstrate strong performance on event type classification (80-90\% F1) but modest performance on fine-grained extraction tasks, particularly argument role and argument text extraction (50-65\% F1). GPT-5-mini exhibits extreme prompt sensitivity with 11-79\% F1 variation. Notably, advanced prompting strategies provide minimal improvements over zero-shot approaches, revealing fundamental architectural limitations. Error analysis identifies systematic hallucination, over-generalization, and inability to capture synthesis-specific nuances. Our findings demonstrate that while LLMs achieve high-level understanding, precise extraction of experimental parameters requires domain-adapted models, providing quantitative benchmarks for scientific information extraction.

</details>


### [24] [Why Your Academic Field Is Everywhere at Once: A Case Study of Arabic Linguistics](https://arxiv.org/abs/2512.15328)
*Ayman Eddakrouri,Amani Ramadan*

Main category: cs.CL

TL;DR: 本研究应用Brookes的分类离散度测量法分析当代阿拉伯应用语言学研究主题结构，发现该领域具有极端主题离散特征，呈现高度异质性而非集中性。


<details>
  <summary>Details</summary>
Motivation: 需要了解当代阿拉伯应用语言学研究的主题结构特征，评估该领域是否存在主导性研究焦点或呈现分散状态，为学科发展提供实证依据。

Method: 应用Brookes的分类离散度测量法(Δ)，使用2019-2025年间1,564篇出版物构成的真实数据集，将其分类到八个核心子学科中，计算离散度指数。

Result: 计算得出离散度指数Δ=0.194，这个极低值表明极端主题离散；计算语言学虽占主导但非霸权地位，与社会语言学、语言教学等其他子领域共存；该领域呈现明显异质性特征。

Conclusion: 本研究澄清了Brookes原始公式的正确应用方法，展示了该方法在领域特征描述中的实用性，并为跨领域评估学科结构提供了可复制的文献计量学方法。

Abstract: This study applies Brookes' Measure of Categorical Dispersion (Δ) to analyze the thematic structure of contemporary Arabic Applied Linguistics research. Using a comprehensive, real-world dataset of 1,564 publications from 2019 to 2025, classified into eight core sub-disciplines, we calculate a dispersion index of Δ = 0.194. This remarkably low value indicates extreme thematic dispersion, revealing that the field is characterized by pronounced heterogeneity rather than concentration. The analysis identifies Computational Linguistics as a dominant but non-hegemonic force, coexisting with robust research in Sociolinguistics, Language Teaching, and other subfields. This study clarifies the correct application of Brookes' original formula, demonstrates its utility for field characterization, and provides a replicable bibliometric methodology for assessing disciplinary structure across domains.

</details>


### [25] [Adversarial versification in portuguese as a jailbreak operator in LLMs](https://arxiv.org/abs/2512.15353)
*Joao Queiroz*

Main category: cs.CL

TL;DR: 研究发现将指令改写为诗歌形式是一种有效的通用单轮越狱机制，能显著提高大型语言模型的安全失败率，暴露当前对齐机制的深层局限性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索诗歌形式提示作为对抗性攻击手段的有效性，揭示当前LLM对齐机制在面对最小符号形式变化时的脆弱性。特别是针对葡萄牙语这种具有高形态句法复杂性和丰富韵律传统的语言，现有评估存在关键空白。

Method: 研究采用诗歌改写作为对抗机制，将通常被拒绝的指令改写为诗歌形式。通过手动创作和自动生成的诗歌进行测试，在基于MLCommons AILuminate的基准上评估安全失败率。分析不同训练方法（RLHF、宪法AI、混合流程）在诗歌攻击下的表现差异。

Result: 诗歌改写能产生高达18倍的安全失败率提升。手动创作诗歌达到约62%的攻击成功率（ASR），自动版本达43%，部分模型在单轮交互中超过90%成功率。所有训练方法都表现出在最小符号形式变化下的性能退化，表明当前防护机制过度依赖表面模式。

Conclusion: 诗歌形式攻击揭示了当前对齐机制的深层局限性，防护机制过度依赖表面模式而缺乏对语义内容的深度理解。特别需要开发包含葡萄牙语等复杂语言韵律特征的评估协议，以全面测试模型在不同语言模式下的脆弱性。

Abstract: Recent evidence shows that the versification of prompts constitutes a highly effective adversarial mechanism against aligned LLMs. The study 'Adversarial poetry as a universal single-turn jailbreak mechanism in large language models' demonstrates that instructions routinely refused in prose become executable when rewritten as verse, producing up to 18 x more safety failures in benchmarks derived from MLCommons AILuminate. Manually written poems reach approximately 62% ASR, and automated versions 43%, with some models surpassing 90% success in single-turn interactions. The effect is structural: systems trained with RLHF, constitutional AI, and hybrid pipelines exhibit consistent degradation under minimal semiotic formal variation. Versification displaces the prompt into sparsely supervised latent regions, revealing guardrails that are excessively dependent on surface patterns. This dissociation between apparent robustness and real vulnerability exposes deep limitations in current alignment regimes. The absence of evaluations in Portuguese, a language with high morphosyntactic complexity, a rich metric-prosodic tradition, and over 250 million speakers, constitutes a critical gap. Experimental protocols must parameterise scansion, metre, and prosodic variation to test vulnerabilities specific to Lusophone patterns, which are currently ignored.

</details>


### [26] [Dual-Density Inference for Efficient Language Model Reasoning](https://arxiv.org/abs/2512.15358)
*Zhengyi Zhao,Shubo Zhang,Yuxi Zhang,Huimin Wang,Binyang Li,Kam-Fai Wong*

Main category: cs.CL

TL;DR: Denser框架通过分离推理和回答阶段的信息密度，使用高密度压缩推理减少token消耗，同时保持准确率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在复杂推理任务中，中间推理过程和最终答案使用统一语言密度，导致计算效率低下。研究发现推理过程服务于模型自身的计算功能，而回答服务于人类理解，这种差异使得可以在中间计算中使用压缩符号语言，同时保持最终解释的人类可读性。

Method: 提出Denser（双密度推理）框架，包含三个组件：查询处理模块分析输入问题；高密度压缩推理机制用于高效中间计算；答案生成组件将压缩推理转换为人类可读的解决方案。

Result: 在多个推理问答基准测试中，Denser相比标准思维链方法减少高达62%的token消耗，同时保持或提高准确率。这种效率提升在复杂多步推理问题上尤其显著。

Conclusion: 通过分离推理和回答阶段的信息密度优化，Denser框架显著提高了LLM推理效率，为大规模复杂推理任务提供了实用的解决方案。

Abstract: Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency. Our observation found that reasoning process serves a computational function for the model itself, while answering serves a communicative function for human understanding. This distinction enables the use of compressed, symbol-rich language for intermediate computations while maintaining human-readable final explanations. To address this inefficiency, we present Denser: \underline{D}ual-d\underline{ens}ity inf\underline{er}ence, a novel framework that optimizes information density separately for reasoning and answering phases. Our framework implements this through three components: a query processing module that analyzes input problems, a high-density compressed reasoning mechanism for efficient intermediate computations, and an answer generation component that translates compressed reasoning into human-readable solutions. Experimental evaluation across multiple reasoning question answering benchmarks demonstrates that Denser reduces token consumption by up to 62\% compared to standard Chain-of-Thought methods while preserving or improving accuracy. These efficiency gains are particularly significant for complex multi-step reasoning problems where traditional methods generate extensive explanations.

</details>


### [27] [ORACLE: Time-Dependent Recursive Summary Graphs for Foresight on News Data Using LLMs](https://arxiv.org/abs/2512.15397)
*Lev Kharlashkin,Eiaki Morooka,Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TL;DR: ORACLE平台将每日新闻转化为周度决策洞察，通过爬取、过滤、嵌入、分类和构建时间依赖递归摘要图，为芬兰应用科学大学提供课程情报分析。


<details>
  <summary>Details</summary>
Motivation: 为芬兰应用科学大学提供基于新闻的决策支持，将海量日常新闻转化为结构化的周度洞察，帮助大学进行课程规划和教育政策制定。

Method: 1. 爬取和版本化新闻数据；2. 应用大学特定相关性过滤；3. 内容嵌入；4. PESTEL维度分类；5. 构建时间依赖递归摘要图（TRSG）- 两层聚类并由LLM摘要，每周重新计算；6. 轻量级变化检测器识别新增、删除和变更内容；7. 将差异按主题分组进行PESTEL感知分析。

Result: 开发了一个稳定的生产系统，支持课程情报用例并制定了评估计划，能够将日常新闻转化为周度决策就绪的洞察。

Conclusion: ORACLE系统成功实现了从日常新闻到结构化周度洞察的转化，为大学决策提供了有效支持，系统设计选择确保了生产环境的稳定性，课程情报用例展示了实际应用价值。

Abstract: ORACLE turns daily news into week-over-week, decision-ready insights for one of the Finnish University of Applied Sciences. The platform crawls and versions news, applies University-specific relevance filtering, embeds content, classifies items into PESTEL dimensions and builds a concise Time-Dependent Recursive Summary Graph (TRSG): two clustering layers summarized by an LLM and recomputed weekly. A lightweight change detector highlights what is new, removed or changed, then groups differences into themes for PESTEL-aware analysis. We detail the pipeline, discuss concrete design choices that make the system stable in production and present a curriculum-intelligence use case with an evaluation plan.

</details>


### [28] [Toward expert-level motivational interviewing for health behavior improvement with LLMs](https://arxiv.org/abs/2512.15446)
*Run-ze Hu,Yang Yang,Yi-hang Yang,Jing-qi Kong,Jia-hui Luo,Wen-yu Yang,Jing Chen,Jing-yao Liu,Hui-qun Zeng,Lei Zhang,Zheng Liu*

Main category: cs.CL

TL;DR: 通过使用MI-informed提示和GPT-4将心理咨询对话转录为MI风格对话，并微调三个中文开源LLM，开发了能够执行动机性访谈的MI-LLMs，在自动指标和专家评估中表现出接近真实MI对话的能力。


<details>
  <summary>Details</summary>
Motivation: 动机性访谈是一种有效的健康行为改变咨询方法，但需要高度训练的人类咨询师，限制了其可扩展性。本研究旨在探索通过开发大型语言模型来提供可扩展的MI咨询服务。

Method: 1. 收集五个中文心理咨询语料库，使用GPT-4和MI-informed提示将最高质量的两个数据集转录为2,040个MI风格对话；2. 使用其中2,000个对话训练三个中文开源LLM（Baichuan2-7B-Chat、ChatGLM-4-9B-Chat、Llama-3-8B-Chinese-Chat-v2）；3. 通过基于轮次的自动指标和专家手动编码（使用MITI编码手册4.2.1）评估MI-LLMs。

Result: 微调显著提高了所有三个模型的BLEU-4和ROUGE分数。专家评估显示MI-LLMs在技术和关系全局评分以及MI一致性比率方面接近真实MI对话水平，但复杂反思和反思-问题比率仍然较低。

Conclusion: MI导向的微调能够赋予通用LLMs核心的MI一致性咨询行为，为AI辅助健康行为改变支持提供了可扩展的途径，但需要在数据规模、复杂MI技能和真实世界干预试验方面进一步研究。

Abstract: Background: Motivational interviewing (MI) is an effective counseling approach for promoting health behavior change, but its impact is constrained by the need for highly trained human counselors. Objective: This study aimed to explore a scalable alternative by developing and evaluating Large Language Models for Motivational Interviewing (MI-LLMs). Methods: We first curated five Chinese psychological counseling corpora and, using GPT-4 with an MI-informed prompt, transcribed multi-turn dialogues from the two highest-quality datasets (CPsyCounD and PsyDTCorpus) into 2,040 MI-style counseling conversations, of which 2,000 were used for training and 40 for testing. Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat and Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this corpus and were named as MI-LLMs. We evaluated MI-LLMs using round-based automatic metrics and expert manual coding with the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1. Results: Across all three models, fine-tuning substantially improved BLEU-4 and ROUGE scores compared with the base models, and manual coding showed that MI-LLMs achieved technical and relational global scores, and MI-adherent ratios that approached those of real MI dialogues, although complex reflections and reflection-to-question ratios remained less frequent. Conclusions: These findings provide initial evidence that MI-oriented fine-tuning can endow general-purpose LLMs with core MI-consistent counseling behaviors, suggesting a scalable pathway toward AI-assisted health behavior change support while underscoring the need for further work on data scale, complex MI skills and real-world intervention trials.

</details>


### [29] [When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising](https://arxiv.org/abs/2512.15547)
*Md. Samiul Alim,Mahir Shahriar Tamim,Maisha Rahman,Tanvir Ahmed Khan,Md Mushfique Anwar*

Main category: cs.CL

TL;DR: 研究首次对孟加拉语在2024年孟加拉国大规模抗议期间进行情感分析，构建了包含2,028条新闻标题的数据集，使用语言特定模型取得了优于多语言模型和传统机器学习方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前情感分析研究主要集中在选举和社交媒体趋势等场景，对于公民动荡期间的情感动态，特别是孟加拉语环境下的研究存在明显空白。本研究旨在填补这一空白，探索国家危机期间公众情绪的演变。

Method: 研究构建了独特的孟加拉语数据集，包含2,028条从主要Facebook新闻门户收集的标注新闻标题，分类为愤怒、希望和绝望三类情感。使用潜在狄利克雷分配(LDA)识别主要主题，并分析互联网封锁等事件对情感模式的影响。比较了语言特定模型、多语言转换器模型(mBERT和XLM-RoBERTa)以及传统机器学习方法(SVM和逻辑回归)的性能。

Result: 语言特定模型在孟加拉语情感分析任务中表现最佳，显著优于多语言转换器模型(mBERT: 67%, XLM-RoBERTa: 71%)和传统机器学习方法(SVM和逻辑回归: 均为70%)。通过LDA识别出政治腐败和公众抗议等主要主题，并发现互联网封锁等事件显著影响情感模式。

Conclusion: 研究表明语言特定模型在处理孟加拉语情感分析任务时具有显著优势，特别是在政治动荡背景下。这项工作为理解危机期间的公众情绪提供了宝贵见解，并填补了孟加拉语情感分析研究领域的空白，对未来的社会动态监测和政策制定具有参考价值。

Abstract: Sentiment analysis, an emerging research area within natural language processing (NLP), has primarily been explored in contexts like elections and social media trends, but there remains a significant gap in understanding emotional dynamics during civil unrest, particularly in the Bangla language. Our study pioneers sentiment analysis in Bangla during a national crisis by examining public emotions amid Bangladesh's 2024 mass uprising. We curated a unique dataset of 2,028 annotated news headlines from major Facebook news portals, classifying them into Outrage, Hope, and Despair. Through Latent Dirichlet Allocation (LDA), we identified prevalent themes like political corruption and public protests, and analyzed how events such as internet blackouts shaped sentiment patterns. It outperformed multilingual transformers (mBERT: 67%, XLM-RoBERTa: 71%) and traditional machine learning methods (SVM and Logistic Regression: both 70%). These results highlight the effectiveness of language-specific models and offer valuable insights into public sentiment during political turmoil.

</details>


### [30] [CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing](https://arxiv.org/abs/2512.15550)
*Kuan Lu,Shuhang Lin,Sai Wu,Yichen Yao,Junhan Yang,Huan Li,Wei Chu,Xu Yinghui,Yuan Qi,Gang Chen*

Main category: cs.CL

TL;DR: CTKVR提出了一种新的两阶段KV缓存检索方案，通过先进行轻量级质心索引再进行令牌级细化的方法，在保持准确性的同时显著提升长上下文LLM推理效率。


<details>
  <summary>Details</summary>
Motivation: 长上下文场景下LLM推理面临内存开销大和延迟高的问题。现有动态KV选择方法存在权衡困难：块级索引会因检索不相关KV条目而降低准确性，而令牌级索引则因低效检索机制导致高延迟。

Method: 提出CTKVR（质心-令牌KV检索）方案，基于查询向量在RoPE后相邻位置具有高相似性的观察，采用两阶段检索策略：预填充阶段预计算轻量级质心进行质心粒度索引，然后进行令牌级细化以实现精确KV检索。

Result: CTKVR在多个基准测试中实现优异性能，准确率下降小于1%。在96K上下文长度下，对Llama-3-8B和Yi-9B分别带来3倍和4倍的吞吐量加速，在不同GPU硬件上均表现良好。

Conclusion: CTKVR通过创新的两阶段检索策略和CPU-GPU协同执行优化，有效解决了长上下文LLM推理中的效率与准确性权衡问题，为实际应用提供了可行的解决方案。

Abstract: Large language models (LLMs) are increasingly applied in long-context scenarios such as multi-turn conversations. However, long contexts pose significant challenges for inference efficiency, including high memory overhead from Key-Value (KV) cache and increased latency due to excessive memory accesses. Recent methods for dynamic KV selection struggle with trade-offs: block-level indexing degrades accuracy by retrieving irrelevant KV entries, while token-level indexing incurs high latency from inefficient retrieval mechanisms. In this paper, we propose CTKVR, a novel centroid-then-token KV retrieval scheme that addresses these limitations. CTKVR leverages a key observation: query vectors adjacent in position exhibit high similarity after Rotary Position Embedding (RoPE) and share most of their top-k KV cache entries. Based on this insight, CTKVR employs a two-stage retrieval strategy: lightweight centroids are precomputed during prefilling for centroid-grained indexing, followed by token-level refinement for precise KV retrieval. This approach balances retrieval efficiency and accuracy. To further enhance performance, we implement an optimized system for indexing construction and search using CPU-GPU co-execution. Experimentally, CTKVR achieves superior performance across multiple benchmarks with less than 1% accuracy degradation. Meanwhile, CTKVR delivers 3 times and 4 times throughput speedups on Llama-3-8B and Yi-9B at 96K context length across diverse GPU hardware.

</details>


### [31] [Learning inflection classes using Adaptive Resonance Theory](https://arxiv.org/abs/2512.15551)
*Peter Dekker,Heikki Rasilo,Bart de Boer*

Main category: cs.CL

TL;DR: 该研究使用自适应共振理论（ART）神经网络对拉丁语、葡萄牙语和爱沙尼亚语的动词屈折变化类进行无监督聚类学习，探索屈折变化系统的可学习性。


<details>
  <summary>Details</summary>
Motivation: 屈折变化类是语言学家使用的抽象概念，用于描述语言中的模式，为推导先前未遇到的形式提供类比基础。这种能力是形态习得和处理的重要组成部分。研究旨在探索个体语言使用者学习动词屈折变化类系统的可学习性。

Method: 使用自适应共振理论（ART）神经网络作为认知上合理且可解释的计算模型，对拉丁语、葡萄牙语和爱沙尼亚语的词位进行无监督聚类，将其分为屈折变化类。ART网络有一个决定泛化程度的参数（警觉度）。

Result: 聚类结果与已证实的屈折变化类的相似性因屈折系统的复杂性而异。在泛化参数的狭窄区域内找到最佳性能。从模型中提取的学习特征与屈折变化类的语言学描述相似。

Conclusion: 该模型可用于未来研究屈折变化类的变化，通过将其纳入基于代理的模型中。研究展示了ART神经网络在模拟语言习得和形态处理方面的潜力。

Abstract: The concept of inflection classes is an abstraction used by linguists, and provides a means to describe patterns in languages that give an analogical base for deducing previously unencountered forms. This ability is an important part of morphological acquisition and processing. We study the learnability of a system of verbal inflection classes by the individual language user by performing unsupervised clustering of lexemes into inflection classes. As a cognitively plausible and interpretable computational model, we use Adaptive Resonance Theory, a neural network with a parameter that determines the degree of generalisation (vigilance). The model is applied to Latin, Portuguese and Estonian. The similarity of clustering to attested inflection classes varies depending on the complexity of the inflectional system. We find the best performance in a narrow region of the generalisation parameter. The learned features extracted from the model show similarity with linguistic descriptions of the inflection classes. The proposed model could be used to study change in inflection classes in the future, by including it in an agent-based model.

</details>


### [32] [From Data to Dialogue: Unlocking Language for All](https://arxiv.org/abs/2512.15552)
*Dakota Ellis,Samy Bakikerali,Wanshan Chen,Bao Dinh,Uyen Le*

Main category: cs.CL

TL;DR: 研究提出一种自动化创建专业词汇表(SWL)的方法，在特定语料中比传统通用服务列表(GSL)更高效地达到95%语言理解覆盖率。


<details>
  <summary>Details</summary>
Motivation: 传统GSL创建需要语言学专业知识、主观判断和大量时间，难以自动化和规模化。研究者希望开发更实用、可定制的词汇学习方法。

Method: 开发自动化模型创建专业词汇表(SWL)，仅基于客观标准，针对特定语料子集优化词汇选择。

Result: 所创建的SWL在达到95%语言理解覆盖率方面优于行业标准NGSL，使用更少的词汇量。方法可实现自动化、规模化和个性化定制。

Conclusion: 专业词汇表(SWL)是更实用的语言学习优化方法，通过纯客观标准实现自动化，能为全球语言学习者提供定制化解决方案。

Abstract: Traditional linguists have proposed the use of a General Service List (GSL) to assist new language learners in identifying the most important words in English. This process requires linguistic expertise, subjective input, and a considerable amount of time. We attempt to create our own GSL and evaluate its practicality against the industry standard (The NGSL). We found creating a Specialized Word List (SWL), or a word list specific to a subset of the overall corpus, to be the most practical way for language-learners to optimize the process. The SWL's that we created using our model outperformed the industry standard, reaching the 95% coverage required for language comprehension with fewer words comparatively. By restricting the SWL process to objective criteria only, it can be automated, scaled, and tailored to the needs of language-learners across the globe.

</details>


### [33] [An Empirical Study on Chinese Character Decomposition in Multiword Expression-Aware Neural Machine Translation](https://arxiv.org/abs/2512.15556)
*Lifeng Han,Gareth J. F. Jones,Alan F. Smeaton*

Main category: cs.CL

TL;DR: 本文系统研究汉字分解技术在多词表达式感知神经机器翻译中的应用，探索如何通过汉字分解技术改善中文词义表示并解决多词表达式翻译难题。


<details>
  <summary>Details</summary>
Motivation: 多词表达式在自然语言处理中带来诸多挑战，如歧义、习语表达、低频使用等。虽然在西方语言（尤其是英语）中已有显著进展，但中文等表意文字语言在此方面仍落后。由于子词建模无法直接应用于汉字等表意文字，需要探索适合中文特点的技术方案。

Method: 采用汉字分解技术，在MWE感知的神经机器翻译框架中进行系统研究。通过实验检验汉字分解技术如何贡献于中文词汇和字符原始意义的表示，以及如何有效解决多词表达式翻译的挑战。

Result: 通过实验验证了汉字分解技术在中文词义表示和多词表达式翻译中的有效性。具体结果需参考论文中的实验数据和分析。

Conclusion: 汉字分解技术为中文多词表达式处理提供了有效解决方案，能够改善神经机器翻译中MWE的翻译质量，为中文等表意文字语言的NLP任务提供了新的技术途径。

Abstract: Word meaning, representation, and interpretation play fundamental roles in natural language understanding (NLU), natural language processing (NLP), and natural language generation (NLG) tasks. Many of the inherent difficulties in these tasks stem from Multi-word Expressions (MWEs), which complicate the tasks by introducing ambiguity, idiomatic expressions, infrequent usage, and a wide range of variations. Significant effort and substantial progress have been made in addressing the challenging nature of MWEs in Western languages, particularly English. This progress is attributed in part to the well-established research communities and the abundant availability of computational resources. However, the same level of progress is not true for language families such as Chinese and closely related Asian languages, which continue to lag behind in this regard. While sub-word modelling has been successfully applied to many Western languages to address rare words improving phrase comprehension, and enhancing machine translation (MT) through techniques like byte-pair encoding (BPE), it cannot be applied directly to ideograph language scripts like Chinese. In this work, we conduct a systematic study of the Chinese character decomposition technology in the context of MWE-aware neural machine translation (NMT). Furthermore, we report experiments to examine how Chinese character decomposition technology contributes to the representation of the original meanings of Chinese words and characters, and how it can effectively address the challenges of translating MWEs.

</details>


### [34] [Bolmo: Byteifying the Next Generation of Language Models](https://arxiv.org/abs/2512.15586)
*Benjamin Minixhofer,Tyler Murray,Tomasz Limisiewicz,Anna Korhonen,Luke Zettlemoyer,Noah A. Smith,Edoardo M. Ponti,Luca Soldaini,Valentin Hofmann*

Main category: cs.CL

TL;DR: Bolmo是首个在1B和7B参数规模上具有竞争力的完全开源字节级语言模型家族，通过字节化现有子词级模型实现，以极低的训练成本获得接近甚至超越原模型性能


<details>
  <summary>Details</summary>
Motivation: 现有字节级语言模型主要通过从头训练，存在效率限制和字符理解不足的问题。子词分词有固定词汇表限制，而字节级模型能提供更好的字符理解和灵活性，但之前缺乏与子词模型竞争力相当的字节级模型

Method: 提出字节化方法：将现有子词级语言模型转换为字节级模型。设计了专门的架构解决字节级架构与子词级模型表达能力不匹配的问题，采用精确蒸馏目标，使用不到1%的典型预训练token预算完成转换

Result: Bolmo显著优于所有同规模字节级模型，在字符理解和部分编码任务上超过源子词模型，其他任务上接近原模型性能。通过更高token压缩比训练实现与子词模型竞争的推理速度，并能利用现有生态进行廉价有效的后训练

Conclusion: Bolmo使字节级语言模型成为实用选择，在与子词级模型竞争中展现出广泛用例的可行性，通过字节化方法以极低成本获得高性能字节级模型

Abstract: We introduce Bolmo, the first family of competitive fully open byte-level language models (LMs) at the 1B and 7B parameter scales. In contrast to prior research on byte-level LMs, which focuses predominantly on training from scratch, we train Bolmo by byteifying existing subword-level LMs. Byteification enables overcoming the limitations of subword tokenization - such as insufficient character understanding and efficiency constraints due to the fixed subword vocabulary - while performing at the level of leading subword-level LMs. Bolmo is specifically designed for byteification: our architecture resolves a mismatch between the expressivity of prior byte-level architectures and subword-level LMs, which makes it possible to employ an effective exact distillation objective between Bolmo and the source subword model. This allows for converting a subword-level LM to a byte-level LM by investing less than 1\% of a typical pretraining token budget. Bolmo substantially outperforms all prior byte-level LMs of comparable size, and outperforms the source subword-level LMs on character understanding and, in some cases, coding, while coming close to matching the original LMs' performance on other tasks. Furthermore, we show that Bolmo can achieve inference speeds competitive with subword-level LMs by training with higher token compression ratios, and can be cheaply and effectively post-trained by leveraging the existing ecosystem around the source subword-level LM. Our results finally make byte-level LMs a practical choice competitive with subword-level LMs across a wide set of use cases.

</details>


### [35] [You Never Know a Person, You Only Know Their Defenses: Detecting Levels of Psychological Defense Mechanisms in Supportive Conversations](https://arxiv.org/abs/2512.15601)
*Hongbin Na,Zimu Wang,Zhaoming Chen,Peilin Zhou,Yining Hua,Grace Ziqi Zhou,Haiyang Zhang,Tao Shen,Wei Wang,John Torous,Shaoxiong Ji,Ling Chen*

Main category: cs.CL

TL;DR: 提出了PsyDefConv防御机制对话语料库和DMRS Co-Pilot四阶段标注管道，用于自动识别临床对话中的心理防御机制水平，显著减少人工标注时间。


<details>
  <summary>Details</summary>
Motivation: 心理防御机制是影响心理健康和临床对话的关键因素，但传统测量方法复杂且难以在临床对话中可靠评估，需要系统化的标注方法和高质量数据集。

Method: 构建了包含200个对话、4709个话语的PsyDefConv语料库，开发了DMRS Co-Pilot四阶段标注管道提供证据驱动的预标注，包含数据收集、预处理、证据检索和生成四个阶段。

Result: 语料库标注一致性达到Cohen's kappa 0.639，DMRS Co-Pilot减少平均标注时间22.4%，专家评审在7分制中证据质量4.62、临床合理性4.44、洞察力4.40。语言模型基准测试最佳宏F1约30%，存在高估成熟防御的倾向。

Conclusion: 该研究提供了首个专门用于心理防御机制分析的对话语料库和高效标注工具，揭示了当前语言模型在识别防御机制方面的局限性，为临床心理学研究提供了重要资源和方法支持。

Abstract: Psychological defenses are strategies, often automatic, that people use to manage distress. Rigid or overuse of defenses is negatively linked to mental health and shapes what speakers disclose and how they accept or resist help. However, defenses are complex and difficult to reliably measure, particularly in clinical dialogues. We introduce PsyDefConv, a dialogue corpus with help seeker utterances labeled for defense level, and DMRS Co-Pilot, a four-stage pipeline that provides evidence-based pre-annotations. The corpus contains 200 dialogues and 4709 utterances, including 2336 help seeker turns, with labeling and Cohen's kappa 0.639. In a counterbalanced study, the co-pilot reduced average annotation time by 22.4%. In expert review, it averaged 4.62 for evidence, 4.44 for clinical plausibility, and 4.40 for insight on a seven-point scale. Benchmarks with strong language models in zero-shot and fine-tuning settings demonstrate clear headroom, with the best macro F1-score around 30% and a tendency to overpredict mature defenses. Corpus analyses confirm that mature defenses are most common and reveal emotion-specific deviations. We will release the corpus, annotations, code, and prompts to support research on defensive functioning in language.

</details>


### [36] [Evaluating Metrics for Safety with LLM-as-Judges](https://arxiv.org/abs/2512.15617)
*Kester Clegg,Richard Hawkins,Ibrahim Habli,Tom Lawton*

Main category: cs.CL

TL;DR: 该论文提出通过采用加权指标篮子、上下文敏感性和置信度阈值等方法，在LLM作为评判者的评估框架中降低错误风险，从而在安全关键的信息处理流程中安全可靠地引入大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地应用于文本处理流程，有可能替代因人员不足或流程复杂而成为瓶颈的人类角色。然而，LLMs会出错，且某些处理角色是安全关键的（如术后护理分诊、核设施工作计划更新）。如何在安全关键的信息流中安全可靠地引入LLMs？

Method: 论文主张安全论证应关注LLM流程中评估点提供的证据类型，特别是在采用LLM-as-Judges（LaJ）评估器的框架中。通过采用加权指标篮子、利用上下文敏感性定义错误严重性，并设计当评估者间一致性低时触发人工审查关键LaJ判断的置信度阈值。

Result: 虽然无法从许多自然语言处理任务中获得确定性评估，但通过加权指标篮子可以降低评估中的错误风险，利用上下文敏感性定义错误严重性，并通过置信度阈值在评估者一致性低时触发人工审查。

Conclusion: 论文提出了一种在安全关键信息流程中安全引入LLMs的方法论，重点是通过评估证据的类型来构建安全论证，而非依赖生成增强框架或基于图的技术等性能声明。通过系统化的评估框架设计，可以在保持自动化优势的同时降低风险。

Abstract: LLMs (Large Language Models) are increasingly used in text processing pipelines to intelligently respond to a variety of inputs and generation tasks. This raises the possibility of replacing human roles that bottleneck existing information flows, either due to insufficient staff or process complexity. However, LLMs make mistakes and some processing roles are safety critical. For example, triaging post-operative care to patients based on hospital referral letters, or updating site access schedules in nuclear facilities for work crews. If we want to introduce LLMs into critical information flows that were previously performed by humans, how can we make them safe and reliable? Rather than make performative claims about augmented generation frameworks or graph-based techniques, this paper argues that the safety argument should focus on the type of evidence we get from evaluation points in LLM processes, particularly in frameworks that employ LLM-as-Judges (LaJ) evaluators. This paper argues that although we cannot get deterministic evaluations from many natural language processing tasks, by adopting a basket of weighted metrics it may be possible to lower the risk of errors within an evaluation, use context sensitivity to define error severity and design confidence thresholds that trigger human review of critical LaJ judgments when concordance across evaluators is low.

</details>


### [37] [How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness](https://arxiv.org/abs/2512.15634)
*Darshita Rathore,Vineet Kumar,Chetna Bansal,Anindya Moitra*

Main category: cs.CL

TL;DR: 该研究对全监督微调(SFT)与参数高效微调(PEFT/LoRA)在问答任务中的性能进行了全面评估，发现LoRA在特定秩值下能达到竞争性甚至更优的性能，尤其在推理任务上表现突出。


<details>
  <summary>Details</summary>
Motivation: 虽然参数高效微调(PEFT)方法因其计算效率而被广泛使用，但其配置(如秩)在下游问答任务和泛化能力方面的影响尚未得到充分探索。研究人员希望量化SFT和PEFT之间的权衡，并比较它们在域内和域外适应中的表现。

Method: 研究采用了全面的评估方法，包括：1) 在多个推理和召回数据集上进行秩扫描，量化SFT和PEFT之间的权衡；2) 比较PEFT和SFT模型在域内和域外适应中的准确性；3) 通过谱特征和层级注意力结构分析内部表示，探究表示漂移和注意力模式的结构变化。

Result: 研究结果表明：1) LoRA在特定秩值下能达到与SFT竞争甚至更优的性能，尤其在推理任务上；2) PEFT和SFT在域内和域外适应中表现出不同的泛化行为和任务特定遗忘模式；3) 内部表示分析揭示了表示漂移和注意力结构的变化，为模型行为提供了洞见。

Conclusion: LoRA作为一种参数高效微调方法，在特定配置下不仅计算效率高，还能在推理任务上达到与全监督微调相当甚至更好的性能。该研究强调了微调配置对模型泛化能力的重要性，并为理解不同微调方法如何影响模型内部表示提供了分析框架。

Abstract: Large language models are increasingly adapted to downstream tasks through fine-tuning. Full supervised fine-tuning (SFT) and parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), are two dominant approaches. While PEFT methods are widely used for their computational efficiency, the implications of their configurations (e.g., rank) remain under-explored in downstream Q&A tasks and generalisation. In this work, we perform a comprehensive evaluation across multiple reasoning and recall datasets, conducting a rank sweep to quantify the trade-off between SFT and PEFT. We also compare the accuracy of PEFT and SFT models across in-domain and out-of-domain adaptation, highlighting distinct generalisation behaviour and task-specific forgetting. We demonstrate that LoRA achieves competitive and in some cases superior performance compared to SFT, particularly on reasoning tasks at specific rank values. Additionally, we analyze the internal representations via spectral features and layer-wise attention structures, offering insights into representational drift and structural changes in attention patterns.

</details>


### [38] [Characterizing Mamba's Selective Memory using Auto-Encoders](https://arxiv.org/abs/2512.15653)
*Tamanna Hossain,Robert L. Logan,Ganesh Jagadeesan,Sameer Singh,Joel Tetreault,Alejandro Jaimes*

Main category: cs.CL

TL;DR: 本研究分析了Mamba系列SSM语言模型在长序列处理中信息丢失的模式，发现模型更容易遗忘数学相关标记、组织实体提及和非标准英语方言，这些模式与预训练数据中标记的出现频率相关。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型(SSMs)作为Transformer的替代方案，在推理时使用固定内存，但这会导致处理长序列时出现信息丢失。先前研究只关注了信息丢失发生的序列长度，但未深入分析SSM语言模型倾向于遗忘哪些类型的信息。

Method: 研究训练了一个自动编码器来从SSM的隐藏状态重构序列，通过比较输入与重构结果来测量信息丢失。使用Mamba系列SSM语言模型(130M-1.4B参数)在4-256个标记的序列上进行实验，分析不同标记类型(词性、命名实体等)和序列类型(代码、数学问题等)的遗忘模式。

Result: 结果显示，数学相关标记(数字、变量)、组织实体提及以及非标准美国英语方言的信息丢失率显著更高。进一步分析发现，这些在预训练数据中出现频率较低的标记更容易被Mamba遗忘。

Conclusion: 研究揭示了Mamba SSM语言模型信息丢失的具体模式，为未来开发更好控制模型信息保留能力的方法提供了明确方向，特别是在处理数学内容、组织实体和非标准语言变体方面。

Abstract: State space models (SSMs) are a promising alternative to transformers for language modeling because they use fixed memory during inference. However, this fixed memory usage requires some information loss in the hidden state when processing long sequences. While prior work has studied the sequence length at which this information loss occurs, it does not characterize the types of information SSM language models (LMs) tend to forget. In this paper, we address this knowledge gap by identifying the types of tokens (e.g., parts of speech, named entities) and sequences (e.g., code, math problems) that are more frequently forgotten by SSM LMs. We achieve this by training an auto-encoder to reconstruct sequences from the SSM's hidden state, and measure information loss by comparing inputs with their reconstructions. We perform experiments using the Mamba family of SSM LMs (130M--1.4B) on sequences ranging from 4--256 tokens. Our results show significantly higher rates of information loss on math-related tokens (e.g., numbers, variables), mentions of organization entities, and alternative dialects to Standard American English. We then examine the frequency that these tokens appear in Mamba's pretraining data and find that less prevalent tokens tend to be the ones Mamba is most likely to forget. By identifying these patterns, our work provides clear direction for future research to develop methods that better control Mamba's ability to retain important information.

</details>


### [39] [PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning](https://arxiv.org/abs/2512.15658)
*Xiaodi Li,Dingcheng Li,Rujun Gao,Mahmoud Zamani,Feng Mi,Latifur Khan*

Main category: cs.CL

TL;DR: PPSEBM：结合能量基模型和渐进参数选择的持续学习框架，通过生成伪样本指导参数选择，有效缓解NLP任务中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 持续学习面临灾难性遗忘的主要挑战，即模型在学习新任务时忘记先前任务的知识。需要一种方法让模型在适应新任务的同时保持对过去知识的记忆。

Method: 提出PPSEBM框架，结合渐进参数选择和能量基模型。渐进参数选择为每个新任务分配特定参数，能量基模型生成先前任务的代表性伪样本，这些样本指导参数选择过程。

Result: 在多个NLP基准测试中，PPSEBM优于现有的最先进持续学习方法，证明了其在缓解灾难性遗忘方面的有效性。

Conclusion: PPSEBM为NLP持续学习提供了一个有前景的鲁棒解决方案，通过伪样本生成指导参数选择，有效平衡新任务学习和旧知识保留。

Abstract: Continual learning remains a fundamental challenge in machine learning, requiring models to learn from a stream of tasks without forgetting previously acquired knowledge. A major obstacle in this setting is catastrophic forgetting, where performance on earlier tasks degrades as new tasks are learned. In this paper, we introduce PPSEBM, a novel framework that integrates an Energy-Based Model (EBM) with Progressive Parameter Selection (PPS) to effectively address catastrophic forgetting in continual learning for natural language processing tasks. In PPSEBM, progressive parameter selection allocates distinct, task-specific parameters for each new task, while the EBM generates representative pseudo-samples from prior tasks. These generated samples actively inform and guide the parameter selection process, enhancing the model's ability to retain past knowledge while adapting to new tasks. Experimental results on diverse NLP benchmarks demonstrate that PPSEBM outperforms state-of-the-art continual learning methods, offering a promising and robust solution to mitigate catastrophic forgetting.

</details>


### [40] [Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers](https://arxiv.org/abs/2512.15674)
*Adam Karvonen,James Chua,Clément Dumas,Kit Fraser-Taliente,Subhash Kantamneni,Julian Minder,Euan Ong,Arnab Sen Sharma,Daniel Wen,Owain Evans,Samuel Marks*

Main category: cs.CL

TL;DR: 该论文提出了一种名为"激活神谕"的方法，通过训练LLM直接接收LLM激活并回答关于它们的自然语言问题，从而简化了LLM激活的解释过程。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM激活解释技术通常复杂且专门化，而近期提出的LatentQA方法虽然简化了这一过程，但其训练和评估设置较为局限。本文旨在从通用性角度出发，探索LatentQA训练模型在更广泛、分布外环境中的表现。

Method: 研究者采用LatentQA方法训练"激活神谕"模型，这些模型能够直接接收LLM的激活作为输入，并用自然语言回答关于这些激活的任意问题。研究重点评估了模型在分布外环境中的表现，并考察了训练数据多样性对性能的影响。

Result: 研究发现，激活神谕能够恢复通过微调注入模型的信息（如传记知识或恶意倾向），即使这些信息未出现在输入文本中。在四个下游任务中，最佳激活神谕模型在3/4的任务上表现最佳，在所有任务上都匹配或超越了先前的白盒基线方法。

Conclusion: 通过多样化的训练让LLM回答关于激活的自然语言查询，能够赋予其通用的能力来表达LLM激活中的信息。这种简化的方法在多种任务中表现出色，为LLM激活的理解提供了有效的替代方案。

Abstract: Large language model (LLM) activations are notoriously difficult to understand, with most existing techniques using complex, specialized methods for interpreting them. Recent work has proposed a simpler approach known as LatentQA: training LLMs to directly accept LLM activations as inputs and answer arbitrary questions about them in natural language. However, prior work has focused on narrow task settings for both training and evaluation. In this paper, we instead take a generalist perspective. We evaluate LatentQA-trained models, which we call Activation Oracles (AOs), in far out-of-distribution settings and examine how performance scales with training data diversity. We find that AOs can recover information fine-tuned into a model (e.g., biographical knowledge or malign propensities) that does not appear in the input text, despite never being trained with activations from a fine-tuned model. Our main evaluations are four downstream tasks where we can compare to prior white- and black-box techniques. We find that even narrowly-trained LatentQA models can generalize well, and that adding additional training datasets (such as classification tasks and a self-supervised context prediction task) yields consistent further improvements. Overall, our best AOs match or exceed prior white-box baselines on all four tasks and are the best method on 3 out of 4. These results suggest that diversified training to answer natural-language queries imparts a general capability to verbalize information about LLM activations.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [41] [Where to Explore: A Reach and Cost-Aware Approach for Unbiased Data Collection in Recommender Systems](https://arxiv.org/abs/2512.14733)
*Qiang Chen,Venkatesh Ganapati Hegde*

Main category: cs.IR

TL;DR: 该论文提出了一种在流媒体平台中安全高效实施内容探索的方法，通过基于到达率和机会成本优化探索内容的位置，在保持业务指标的同时收集无偏交互数据。


<details>
  <summary>Details</summary>
Motivation: 探索对于提升长期推荐质量至关重要，但在流媒体环境中，探索往往会损害短期业务表现，因为用户被动参与、期望即时相关性且缺乏纠正机会。需要一种既能进行探索又最小化对平台观看时间目标影响的方法。

Method: 通过识别滚动深度区域中参与度较低的位置，策略性地引入一个专门的容器——"Something Completely Different"行，其中包含随机化内容。该方法不强制在整个用户界面统一实施探索，而是根据经验确定的低成本、高到达率位置来条件化其出现。

Result: 在拥有超过1亿月活跃用户的大规模流媒体平台上部署，A/B测试表明该策略能够保持业务指标的同时收集无偏交互数据。收集的无偏数据集成到下游候选生成中，显著提高了用户参与度。

Conclusion: 该方法通过引入可部署的、基于行为学信息的机制，在大规模平台上呈现探索性内容，补充了现有的行内多样化和基于多臂老虎机的探索技术。验证了无偏数据对推荐系统的重要价值。

Abstract: Exploration is essential to improve long-term recommendation quality, but it often degrades short-term business performance, especially in remote-first TV environments where users engage passively, expect instant relevance, and offer few chances for correction. This paper introduces an approach for delivering content-level exploration safely and efficiently by optimizing its placement based on reach and opportunity cost. Deployed on a large-scale streaming platform with over 100 million monthly active users, our approach identifies scroll-depth regions with lower engagement and strategically introduces a dedicated container, the "Something Completely Different" row containing randomized content. Rather than enforcing exploration uniformly across the user interface (UI), we condition its appearance on empirically low-cost, high-reach positions to ensure minimal tradeoff against platform-level watch time goals. Extensive A/B testing shows that this strategy preserves business metrics while collecting unbiased interaction data. Our method complements existing intra-row diversification and bandit-based exploration techniques by introducing a deployable, behaviorally informed mechanism for surfacing exploratory content at scale. Moreover, we demonstrate that the collected unbiased data, integrated into downstream candidate generation, significantly improves user engagement, validating its value for recommender systems.

</details>


### [42] [Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models](https://arxiv.org/abs/2512.15372)
*Mikel Williams-Lekuona,Georgina Cosma*

Main category: cs.IR

TL;DR: ICAR提出了一种图像复杂度感知检索方法，通过让视觉Transformer对简单图像使用较少计算、复杂图像使用完整计算，实现了20%的实际加速，同时保持95%的实例级性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉Transformer在视觉语言模型中无论图像复杂度如何都使用统一计算量（175.33 GFLOPs），这对简单图像造成了不必要的计算浪费，阻碍了视觉语言系统的可持续扩展。

Method: 1. ICAR方法：通过双路径训练使不同处理深度产生的嵌入保持兼容，确保简单图像提前退出与复杂图像完整处理都能在同一语义空间中进行文本匹配；2. ConvNeXt-IC：将图像复杂度评估作为分类任务，使用现代分类器骨干实现复杂度预测，达到0.959的皮尔逊相关性并加速4.4倍。

Result: 在标准基准测试和真实网络数据上，ICAR实现了20%的实际加速，同时保持类别级性能和95%的实例级性能。ConvNeXt-IC达到与人类判断0.959的相关性，相比现有方法加速4.4倍。

Conclusion: ICAR通过图像复杂度感知的推理策略，在不牺牲性能的前提下显著减少计算开销，为视觉语言系统的可持续扩展提供了有效解决方案，克服了现有两阶段方法需要昂贵重排的局限性。

Abstract: Vision transformers in vision-language models apply uniform computational effort across all images, expending 175.33 GFLOPs (ViT-L/14) whether analysing a straightforward product photograph or a complex street scene. We propose ICAR (Image Complexity-Aware Retrieval), which enables vision transformers to use less compute for simple images whilst processing complex images through their full network depth. The key challenge is maintaining cross-modal alignment: embeddings from different processing depths must remain compatible for text matching. ICAR solves this through dual-path training that produces compatible embeddings from both reduced-compute and full-compute processing. This maintains compatibility between image representations and text embeddings in the same semantic space, whether an image exits early or processes fully. Unlike existing two-stage approaches that require expensive reranking, ICAR enables direct image-text matching without additional overhead. To determine how much compute to use, we develop ConvNeXt-IC, which treats image complexity assessment as a classification task. By applying modern classifier backbones rather than specialised architectures, ConvNeXt-IC achieves state-of-the-art performance with 0.959 correlation with human judgement (Pearson) and 4.4x speedup. Evaluated on standard benchmarks augmented with real-world web data, ICAR achieves 20% practical speedup while maintaining category-level performance and 95% of instance-level performance, enabling sustainable scaling of vision-language systems.

</details>


### [43] [MedNuggetizer: Confidence-Based Information Nugget Extraction from Medical Documents](https://arxiv.org/abs/2512.15384)
*Gregor Donabauer,Samy Ateia,Udo Kruschwitz,Maximilian Burger,Matthias May,Christian Gilfrich,Maximilian Haas,Julio Ruben Rodas Garzaro,Christoph Eckl*

Main category: cs.IR

TL;DR: MedNuggetizer是一个基于大语言模型的工具，用于从医学文档中提取和聚类信息要点，帮助临床医生探索医学证据。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要从大量医学文献中提取可靠证据，但面对冗长文档时效率低下。需要一种工具能够高效提取和整理查询相关的医学信息。

Method: 基于大语言模型，通过重复提取信息要点并进行分组，在单文档和多文档间生成可靠证据。使用查询驱动的方法，针对特定临床问题从指南和PubMed研究中提取信息。

Result: 在"前列腺活检前抗生素预防"的临床用例中，使用主要泌尿科指南和近期PubMed研究作为信息来源。领域专家评估表明，该工具能为临床医生和研究人员提供高效探索长文档和提取可靠、查询聚焦医学证据的方法。

Conclusion: MedNuggetizer是一个有效的工具，能够支持临床医生探索底层医学证据，通过信息要点提取和聚类提供可靠的医学证据支持。

Abstract: We present MedNuggetizer, https://mednugget-ai.de/; access is available upon request.}, a tool for query-driven extraction and clustering of information nuggets from medical documents to support clinicians in exploring underlying medical evidence. Backed by a large language model (LLM), \textit{MedNuggetizer} performs repeated extractions of information nuggets that are then grouped to generate reliable evidence within and across multiple documents. We demonstrate its utility on the clinical use case of \textit{antibiotic prophylaxis before prostate biopsy} by using major urological guidelines and recent PubMed studies as sources of information. Evaluation by domain experts shows that \textit{MedNuggetizer} provides clinicians and researchers with an efficient way to explore long documents and easily extract reliable, query-focused medical evidence.

</details>


### [44] [BERT and CNN integrated Neural Collaborative Filtering for Recommender Systems](https://arxiv.org/abs/2512.15526)
*Abdullah Al Munem,Sumona Yeasmin,Mohammad Rezwanul Huq*

Main category: cs.IR

TL;DR: 提出了一种结合BERT和CNN的神经协同过滤推荐模型，能够处理数值、分类和图像数据，在MovieLens数据集上优于传统NCF和BERT-NCF模型。


<details>
  <summary>Details</summary>
Motivation: 为了提升网站用户互动和收益，需要更强大的推荐系统来根据用户独特偏好推荐内容。现有推荐系统在处理多模态数据方面存在局限性。

Method: 提出了BERT和CNN集成的神经协同过滤模型，该模型从用户和物品配置文件中提取潜在特征，能够处理数值、分类和图像三种数据类型。在MovieLens数据集上进行了25轮训练和验证。

Result: 提出的模型在799个用户的MovieLens数据集上获得了0.72的召回率和0.486的Hit Ratio @ 10，优于简单的NCF模型和BERT-based NCF模型。

Conclusion: 同时考虑分类数据和图像数据可以提升推荐系统的性能，多模态特征提取对推荐效果有积极影响。

Abstract: Every day, a significant number of users visit the internet for different needs. The owners of a website generate profits from the user interaction with the contents or items of the website. A robust recommendation system can increase user interaction with a website by recommending items according to the user's unique preferences. BERT and CNN-integrated neural collaborative filtering (NCF) have been proposed for the recommendation system in this experiment. The proposed model takes inputs from the user and item profile and finds the user's interest. This model can handle numeric, categorical, and image data to extract the latent features from the inputs. The model is trained and validated on a small sample of the MovieLens dataset for 25 epochs. The same dataset has been used to train and validate a simple NCF and a BERT-based NCF model and compared with the proposed model. The proposed model outperformed those two baseline models. The obtained result for the proposed model is 0.72 recall and 0.486 Hit Ratio @ 10 for 799 users on the MovieLens dataset. This experiment concludes that considering both categorical and image data can improve the performance of a recommendation system.

</details>
