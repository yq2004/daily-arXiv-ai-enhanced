<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 75]
- [cs.IR](#cs.IR) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents](https://arxiv.org/abs/2601.20975)
*Nikita Gupta,Riju Chatterjee,Lukas Haas,Connie Tao,Andrew Wang,Chang Liu,Hidekazu Oiwa,Elena Gribovskaya,Jan Ackermann,John Blitzer,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: DeepSearchQA是一个包含900个提示的基准测试，用于评估智能体在17个不同领域中进行复杂多步信息搜索任务的能力，特别关注信息整合、去重和停止标准判断等关键但未被充分评估的能力。


<details>
  <summary>Details</summary>
Motivation: 传统基准测试主要关注单一答案检索或广泛事实性，而缺乏对智能体执行复杂搜索计划、整合分散信息、去重和判断停止标准等深层研究能力的评估。

Method: 构建了一个包含900个手工制作挑战性任务的基准测试，这些任务以因果链结构组织，要求智能体在开放网络上执行多步搜索，生成详尽答案列表，并基于客观可验证的答案集进行评估。

Result: 对最先进的智能体架构进行全面评估显示，即使最先进的模型也难以在高召回率和精确度之间取得平衡，存在过早停止（检索不足）和过度泛化（为提升召回率而提供低置信度答案）等失败模式。

Conclusion: DeepSearchQA揭示了当前智能体设计的重大局限，可作为诊断工具推动未来研究，帮助开发更强大的深层研究能力。

Abstract: We introduce DeepSearchQA, a 900-prompt benchmark for evaluating agents on difficult multi-step information-seeking tasks across 17 different fields. Unlike traditional benchmarks that target single answer retrieval or broad-spectrum factuality, DeepSearchQA features a dataset of challenging, handcrafted tasks designed to evaluate an agent's ability to execute complex search plans to generate exhaustive answer lists. This shift in design explicitly tests three critical, yet under-evaluated capabilities: 1) systematic collation of fragmented information from disparate sources, 2) de-duplication and entity resolution to ensure precision, and 3) the ability to reason about stopping criteria within an open-ended search space. Each task is structured as a causal chain, where discovering information for one step is dependent on the successful completion of the previous one, stressing long-horizon planning and context retention. All tasks are grounded in the open web with objectively verifiable answer sets. Our comprehensive evaluation of state-of-the-art agent architectures reveals significant performance limitations: even the most advanced models struggle to balance high recall with precision. We observe distinct failure modes ranging from premature stopping (under-retrieval) to hedging behaviors, where agents cast an overly wide net of low-confidence answers to artificially boost recall. These findings highlight critical headroom in current agent designs and position DeepSearchQA as an essential diagnostic tool for driving future research toward more robust, deep-research capabilities.

</details>


### [2] [asr_eval: Algorithms and tools for multi-reference and streaming speech recognition evaluation](https://arxiv.org/abs/2601.20992)
*Oleg Sedukhin,Andrey Kostin*

Main category: cs.CL

TL;DR: 提出了语音识别评估的改进方法，包括支持多参考标注的字符串对齐算法、俄语长语音数据集收集、流式识别评估工具和模型统一接口。


<details>
  <summary>Details</summary>
Motivation: 现有语音识别评估方法在处理非拉丁语系、构词丰富的语言，以及杂乱或长语音时存在局限性，特别是多参考标注和词对齐不够完善。

Method: 1) 开发支持多参考标注、任意长度插入和更好词对齐的字符串对齐算法；2) 收集并标注DiverseSpeech-Ru俄语长语音数据集；3) 重新标注流行俄语测试集并研究微调动态；4) 基于改进的词对齐开发流式语音识别评估工具；5) 提供多种离线/流式语音识别模型的统一接口。

Result: 展示了模型经常适应数据集特定的标注，造成指标改进的假象。改进的词对齐使多转录对比可视化成为可能，并为流式识别提供了更好的评估工具。

Conclusion: 通过改进的词对齐算法、多参考标注的数据集和统一的模型接口，为语音识别评估提供了更全面可靠的框架，特别适用于非拉丁语系和长语音场景。

Abstract: We propose several improvements to the speech recognition evaluation. First, we propose a string alignment algorithm that supports both multi-reference labeling, arbitrary-length insertions and better word alignment. This is especially useful for non-Latin languages, those with rich word formation, to label cluttered or longform speech. Secondly, we collect a novel test set DiverseSpeech-Ru of longform in-the-wild Russian speech with careful multi-reference labeling. We also perform multi-reference relabeling of popular Russian tests set and study fine-tuning dynamics on its corresponding train set. We demonstrate that the model often adopts to dataset-specific labeling, causing an illusion of metric improvement. Based on the improved word alignment, we develop tools to evaluate streaming speech recognition and to align multiple transcriptions to compare them visually. Additionally, we provide uniform wrappers for many offline and streaming speech recognition models. Our code will be made publicly available.

</details>


### [3] [UrduBench: An Urdu Reasoning Benchmark using Contextually Ensembled Translations with Human-in-the-Loop](https://arxiv.org/abs/2601.21000)
*Muhammad Ali Shafique,Areej Mehboob,Layba Fiaz,Muhammad Usman Qadeer,Hamza Farooq*

Main category: cs.CL

TL;DR: 提出了一种基于上下文集成翻译和人工验证的框架，用于创建乌尔都语推理基准测试UrduBench，并对多种LLM进行了全面评估，揭示了乌尔都语推理中的挑战和语言对齐的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在低资源语言（如乌尔都语）的推理能力评估面临挑战，缺乏标准化基准测试，现有方法依赖机器翻译且主要关注一般语言任务而非推理能力。

Method: 提出上下文集成翻译框架，结合多种翻译系统和人工验证，保持上下文和结构完整性，将MGSM、MATH-500、CommonSenseQA和OpenBookQA等基准测试翻译为乌尔都语，形成UrduBench数据集。

Result: 对推理导向和指令调优的LLM进行了全面评估，发现多步推理和符号推理任务在乌尔都语中具有挑战性，稳定的语言对齐是鲁棒推理的关键前提。分析了五个维度的性能差异。

Conclusion: 为乌尔都语建立了可扩展的标准化推理评估方法，提供了多语言推理失败的实证见解，该框架可推广到其他低资源语言。

Abstract: Recent advances in large language models (LLMs) have led to strong reasoning capabilities; however, evaluating such models in low-resource languages remains challenging due to the lack of standardized benchmarks. In particular, Urdu reasoning evaluation has been limited by the sensitivity of machine translation and an emphasis on general language tasks rather than reasoning benchmarks. In this paper, we propose a contextually ensembled translation framework with human-in-the-loop validation that leverages multiple translation systems to develop Urdu reasoning benchmarks while preserving contextual and structural integrity. Using this framework, we translate widely adopted reasoning and question-answering benchmarks, including MGSM, MATH-500, CommonSenseQA, and OpenBookQA, into Urdu, collectively referred to as UrduBench, and conduct a comprehensive evaluation of both reasoning-oriented and instruction-tuned LLMs across multiple prompting strategies. Our analysis reveals performance differences across (1) four datasets, (2) five task difficulty levels, (3) diverse model architectures, (4) multiple model scaling settings, and (5) language consistency tests. We find that multi-step and symbolic reasoning tasks pose significant challenges in Urdu, and that stable language alignment is a critical prerequisite for robust reasoning. Overall, our work establishes a scalable methodology for standardized reasoning evaluation in Urdu and provides empirical insights into multilingual reasoning failures. This experimental setup is also broadly applicable to other low-resource languages. The code and datasets will be publicly released.

</details>


### [4] [Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations](https://arxiv.org/abs/2601.21084)
*Amit Meghanani,Thomas Hain*

Main category: cs.CL

TL;DR: 该论文发现，在基于自监督学习的语音模型中，使用MSE损失微调前端语音增强模型会过度依赖位置嵌入而非内容信息，提出使用软DTW损失结合速度扰动的方法来改善这一问题。


<details>
  <summary>Details</summary>
Motivation: 当前将前端语音增强模型与自监督学习语音模型集成时，通常使用MSE损失在增强语音和干净语音之间进行微调。但MSE容易利用自监督学习模型中的位置嵌入，使目标通过位置相关性而非内容相关信息最小化，这成为自监督表示微调的一个普遍限制。

Method: 提出两种策略来解决位置嵌入依赖问题：(1) 零填充策略（之前在自监督学习预训练中探索过，但在微调场景中研究）；(2) 软DTW损失结合速度扰动的方法。

Result: 实验表明，基于软DTW的方法实现了更快的收敛速度和更好的下游任务性能，强调了在基于自监督学习的语音建模中进行位置不变微调的重要性。

Conclusion: 自监督表示微调中存在位置嵌入依赖的普遍问题，使用软DTW损失结合速度扰动的方法能够有效实现位置不变微调，提升语音增强模型与自监督学习模型的集成效果。

Abstract: Integrating front-end speech enhancement (SE) models with self-supervised learning (SSL)-based speech models is effective for downstream tasks in noisy conditions. SE models are commonly fine-tuned using SSL representations with mean squared error (MSE) loss between enhanced and clean speech. However, MSE is prone to exploiting positional embeddings in SSL models, allowing the objective to be minimised through positional correlations instead of content-related information. This work frames the problem as a general limitation of self-supervised representation fine-tuning and investigates it through representation-guided SE. Two strategies are considered: (1) zero-padding, previously explored in SSL pre-training but here examined in the fine-tuning setting, and (2) speed perturbations with a soft-DTW loss. Experiments show that the soft-DTW-based approach achieves faster convergence and improved downstream performance, underscoring the importance of position-invariant fine-tuning in SSL-based speech modelling.

</details>


### [5] [ChunkWise LoRA: Adaptive Sequence Partitioning for Memory-Efficient Low-Rank Adaptation and Accelerated LLM Inference](https://arxiv.org/abs/2601.21109)
*Ketan Thakkar,Maitreyi Chatterjee,Ramasubramanian Balasubramanian,Achyuthan Jootoo,Rajendra Ugrani*

Main category: cs.CL

TL;DR: ChunkWise LoRA：一种基于序列分块的动态低秩适配方法，通过根据token复杂度进行自适应分块，为每个分块分配定制化的低秩配置，显著降低推理延迟和内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA方法对所有输入token采用统一的静态秩配置，忽略了token复杂度和计算需求的差异，导致计算资源分配不高效。

Method: 1. 基于token复杂度估计的运行时调度器；2. 自适应分块机制；3. 使用秩梯机制为每个分块选择LoRA秩和缩放因子；4. 边界安全组合模块保证输出一致性；5. 策略驱动的KV缓存策略。

Result: 在Wikitext-103和SQuAD等基准数据集上，相比基线LoRA，ChunkWise LoRA实现了高达34%的延迟降低和38%的内存减少，同时保持或提升了BLEU、EM和困惑度等任务性能指标。

Conclusion: ChunkWise LoRA提供了一种动态、自适应的低秩适配方法，在显著提升推理效率的同时保持模型性能，完全兼容现有Transformer架构和推理框架，为参数高效LLM的实际部署提供了实用解决方案。

Abstract: Recent advances in low-rank adaptation (LoRA) have enabled efficient fine-tuning of large language models (LLMs) with minimal additional parameters. However, existing LoRA methods apply static rank configurations uniformly across all input tokens, ignoring variation in token complexity and computational requirements. In this work, we propose ChunkWise LoRA, a dynamic and adaptive approach that partitions sequences into variable-length chunks based on token complexity and assigns each chunk a tailored low-rank configuration. Our system introduces a runtime scheduler that estimates token difficulty, performs adaptive chunking, and selects per-chunk LoRA rank and scaling using a rank-ladder mechanism. To preserve output consistency, we further introduce a boundary-safe composition module and integrate policy-driven KV-cache strategies. Experiments on benchmark datasets such as Wikitext-103 and SQuAD demonstrate that ChunkWise LoRA achieves up to 34\% lower latency and 38% memory reduction compared to baseline LoRA, while maintaining or improving task performance metrics like BLEU, EM, and perplexity. The proposed framework remains fully compatible with existing transformer architectures and inference frameworks, providing a practical solution for real-world deployment of parameter-efficient LLMs.

</details>


### [6] [Multi-task Code LLMs: Data Mix or Model Merge?](https://arxiv.org/abs/2601.21115)
*Mingzhi Zhu,Boris Sobolev,Rahul Krishna,Raju Pavuluri,Stacy Patterson,Michele Merler*

Main category: cs.CL

TL;DR: 该研究比较了创建小型多任务代码LLM的两种策略：数据混合与模型合并，发现大规模时模型合并效果更好，小规模时数据混合更优。


<details>
  <summary>Details</summary>
Motivation: 随着小型专用代码LLM在代理框架中的应用增加，需要开发高效的多任务学习策略，以在性能、约束和成本之间取得平衡。

Method: 在两个模型家族（Qwen Coder和DeepSeek Coder）的两个规模（2B和7B参数）上进行广泛实验，针对代码生成和代码摘要任务进行微调，并在HumanEval、MBPP和CodeXGlue基准上评估。

Result: 模型合并在大规模时获得最佳整体性能，保留96%的专用模型性能，甚至超越单独微调的模型（如Qwen Coder 2.5 7B在HumanEval上达到92.7% Pass@1 vs 90.9%）。小规模时数据混合是更优策略。还引入了权重分析技术来理解不同任务如何影响模型参数。

Conclusion: 仔细的合并和混合策略可以有效地结合任务特定能力而不会显著降低性能，特别适合资源受限的部署场景。

Abstract: Recent research advocates deploying smaller, specialized code LLMs in agentic frameworks alongside frontier models, sparking interest in efficient strategies for multi-task learning that balance performance, constraints, and costs. We compare two approaches for creating small, multi-task code LLMs: data mixing versus model merging. We conduct extensive experiments across two model families (Qwen Coder and DeepSeek Coder) at two scales (2B and 7B parameters), fine-tuning them for code generation and code summarization tasks. Our evaluation on HumanEval, MBPP, and CodeXGlue benchmarks reveals that model merging achieves the best overall performance at larger scale across model families, retaining 96% of specialized model performance on code generation tasks while maintaining summarization capabilities. Notably, merged models can even surpass individually fine-tuned models, with our best configuration of Qwen Coder 2.5 7B model achieving 92.7% Pass@1 on HumanEval compared to 90.9% for its task-specific fine-tuned equivalent. At a smaller scale we find instead data mixing to be a preferred strategy. We further introduce a weight analysis technique to understand how different tasks affect model parameters and their implications for merging strategies. The results suggest that careful merging and mixing strategies can effectively combine task-specific capabilities without significant performance degradation, making them ideal for resource-constrained deployment scenarios.

</details>


### [7] [Fake News Detection After LLM Laundering: Measurement and Explanation](https://arxiv.org/abs/2501.18649)
*Rupak Kumar Das,Jonathan Dodge*

Main category: cs.CL

TL;DR: 研究发现大语言模型生成的改写假新闻更难被检测器识别，改写步骤可能反而帮助假新闻逃避检测，主要原因是情感偏移问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能生成高度逼真的假新闻，传播错误信息风险增加。现有研究多关注人工撰写的假新闻检测，但对LLM生成的假新闻检测研究不足，特别是经过改写的假新闻检测效果如何尚不清楚。

Method: 通过实验测量检测器对LLM改写假新闻的识别效果，比较不同模型在逃避检测、语义改写等任务上的表现，使用LIME解释技术分析检测失败原因，并构建包含改写输出和评分的数据集。

Result: 1. 检测器对LLM改写假新闻的识别难度高于人工撰写文本；2. 发现不同模型在不同任务（逃避检测、改写逃避检测、语义相似度）上的优势；3. LIME分析显示检测失败的可能原因是情感偏移；4. 发现BERTSCORE评分高但仍存在情感偏移的样本；5. 提供了包含改写输出和评分的数据集。

Conclusion: LLM改写的假新闻更难被检测，改写步骤可能反而帮助假新闻逃避检测。情感偏移是检测失败的重要原因，现有质量评估指标（如BERTSCORE）可能无法捕捉这一关键变化。需要开发更有效的检测方法应对LLM生成的假新闻威胁。

Abstract: With their advanced capabilities, Large Language Models (LLMs) can generate highly convincing and contextually relevant fake news, which can contribute to disseminating misinformation. Though there is much research on fake news detection for human-written text, the field of detecting LLM-generated fake news is still under-explored. This research measures the efficacy of detectors in identifying LLM-paraphrased fake news, in particular, determining whether adding a paraphrase step in the detection pipeline helps or impedes detection. This study contributes: (1) Detectors struggle to detect LLM-paraphrased fake news more than human-written text, (2) We find which models excel at which tasks (evading detection, paraphrasing to evade detection, and paraphrasing for semantic similarity). (3) Via LIME explanations, we discovered a possible reason for detection failures: sentiment shift. (4) We discover a worrisome trend for paraphrase quality measurement: samples that exhibit sentiment shift despite a high BERTSCORE. (5) We provide a pair of datasets augmenting existing datasets with paraphrase outputs and scores. The dataset is available on GitHub

</details>


### [8] [Large Language Models Naively Recover Ethnicity from Individual Records](https://arxiv.org/abs/2601.21132)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: LLM通过姓名推断种族/族裔的准确率超过传统BISG方法，无需额外训练数据，适用于全球范围和多类别分类。


<details>
  <summary>Details</summary>
Motivation: 传统BISG方法仅适用于美国，依赖人口普查数据，存在收入偏见，且无法适应其他国家或更细粒度的分类需求。

Method: 使用多种LLM模型（包括GPT-4o、Gemini 3 Flash和开源模型）通过姓名推断种族/族裔，测试了扩展推理和加入元数据的效果，并在多个国家进行验证。

Result: LLM分类准确率最高达84.7%，超过BISG的68.2%；加入元数据后达86.7%；在全球多个国家验证成功；减少了BISG的收入偏见；小型微调模型可实现本地部署。

Conclusion: LLM提供了更准确、更灵活、更少偏见的种族/族裔推断方法，适用于全球范围，可通过微调实现高效本地部署。

Abstract: I demonstrate that large language models can infer ethnicity from names with accuracy exceeding that of Bayesian Improved Surname Geocoding (BISG) without additional training data, enabling inference outside the United States and to contextually appropriate classification categories. Using stratified samples from Florida and North Carolina voter files with self-reported race, LLM-based classification achieves up to 84.7% accuracy, outperforming BISG (68.2%) on balanced samples. I test six models including Gemini 3 Flash, GPT-4o, and open-source alternatives such as DeepSeek v3.2 and GLM-4.7. Enabling extended reasoning can improve accuracy by 1-3 percentage points, though effects vary across contexts; including metadata such as party registration reaches 86.7%. LLM classification also reduces the income bias inherent in BISG, where minorities in wealthier neighborhoods are systematically misclassified as White. I further validate using Lebanese voter registration with religious sect (64.3% accuracy), Indian MPs from reserved constituencies (99.2%), and Indian land records with caste classification (74.0%). Aggregate validation across India, Uganda, Nepal, Armenia, Chile, and Costa Rica using original full-count voter rolls demonstrates that the method recovers known population distributions where naming conventions are distinctive. For large-scale applications, small transformer models fine-tuned on LLM labels exceed BISG accuracy while enabling local deployment at no cost.

</details>


### [9] [MURAD: A Large-Scale Multi-Domain Unified Reverse Arabic Dictionary Dataset](https://arxiv.org/abs/2601.21512)
*Serry Sibaee,Yasser Alhabashi,Nadia Sibai,Yara Farouk,Adel Ammar,Sawsan AlHalawani,Wadii Boulila*

Main category: cs.CL

TL;DR: 提出了MURAD数据集，包含96,243个阿拉伯语单词-定义对，涵盖多个学科领域，支持阿拉伯语自然语言处理和词汇语义研究。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语词汇丰富，涵盖科学、宗教、文学等多个领域，但大规模连接阿拉伯语单词与精确定义的数据集仍然有限。

Method: 采用混合管道整合了直接文本解析、光学字符识别和自动化重建技术，从可信的参考书和教育资源中提取数据。

Result: 创建了MURAD数据集，包含96,243个单词-定义对，每条记录包含目标词、标准化阿拉伯语定义和标识源领域的元数据，涵盖语言学、伊斯兰研究、数学、物理、心理学和工程学等领域。

Conclusion: 通过发布这一资源，旨在推进阿拉伯语自然语言处理，促进阿拉伯语词汇语义的可重复研究，支持逆向词典建模、语义检索和教育工具等应用。

Abstract: Arabic is a linguistically and culturally rich language with a vast vocabulary that spans scientific, religious, and literary domains. Yet, large-scale lexical datasets linking Arabic words to precise definitions remain limited. We present MURAD (Multi-domain Unified Reverse Arabic Dictionary), an open lexical dataset with 96,243 word-definition pairs. The data come from trusted reference works and educational sources. Extraction used a hybrid pipeline integrating direct text parsing, optical character recognition, and automated reconstruction. This ensures accuracy and clarity. Each record aligns a target word with its standardized Arabic definition and metadata that identifies the source domain. The dataset covers terms from linguistics, Islamic studies, mathematics, physics, psychology, and engineering. It supports computational linguistics and lexicographic research. Applications include reverse dictionary modeling, semantic retrieval, and educational tools. By releasing this resource, we aim to advance Arabic natural language processing and promote reproducible research on Arabic lexical semantics.

</details>


### [10] [EnsembleLink: Accurate Record Linkage Without Training Data](https://arxiv.org/abs/2601.21138)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: EnsembleLink是一种无需训练标签的高精度记录链接方法，利用预训练语言模型学习语义关系，在多种基准测试中表现优异，且可在本地快速运行。


<details>
  <summary>Details</summary>
Motivation: 记录链接在社会科学研究中至关重要，但现有方法存在不足：研究者通常将其视为预处理步骤，使用临时规则而不量化链接错误带来的不确定性；现有方法要么精度低，要么需要大量标注训练数据。

Method: EnsembleLink利用预训练语言模型学习语义关系（如地理从属关系、政治党派关联等），无需任何训练标签，可在本地开源模型上运行，无需外部API调用。

Result: 在城市名称、人名、组织、多语言政党名称和文献记录等多种基准测试中，EnsembleLink的性能匹配或超越了需要大量标注的方法，且典型的链接任务可在几分钟内完成。

Conclusion: EnsembleLink提供了一种无需训练标签的高精度记录链接方法，解决了现有方法的局限性，为社会科学研究提供了更可靠、更易使用的记录链接工具。

Abstract: Record linkage, the process of matching records that refer to the same entity across datasets, is essential to empirical social science but remains methodologically underdeveloped. Researchers treat it as a preprocessing step, applying ad hoc rules without quantifying the uncertainty that linkage errors introduce into downstream analyses. Existing methods either achieve low accuracy or require substantial labeled training data. I present EnsembleLink, a method that achieves high accuracy without any training labels. EnsembleLink leverages pre-trained language models that have learned semantic relationships (e.g., that "South Ozone Park" is a neighborhood in "New York City" or that "Lutte ouvriere" refers to the Trotskyist "Workers' Struggle" party) from large text corpora. On benchmarks spanning city names, person names, organizations, multilingual political parties, and bibliographic records, EnsembleLink matches or exceeds methods requiring extensive labeling. The method runs locally on open-source models, requiring no external API calls, and completes typical linkage tasks in minutes.

</details>


### [11] [LMK > CLS: Landmark Pooling for Dense Embeddings](https://arxiv.org/abs/2601.21525)
*Meet Doshi,Aashka Trivedi,Vishwajeet Kumar,Parul Awasthy,Yulong Li,Jaydeep Sen,Radu Florian,Sachindra Joshi*

Main category: cs.CL

TL;DR: 本文提出Landmark (LMK) pooling方法，通过将序列分块并在块间插入landmark tokens，然后对landmark token embeddings进行mean pooling，解决了现有pooling策略的系统性弱点。


<details>
  <summary>Details</summary>
Motivation: 现有序列编码器通常使用[CLS] token或mean pooling将变长token序列压缩为单个向量，但这些策略存在系统性弱点：[CLS]倾向于将信息集中在序列初始位置，可能无法充分表示分布式证据；mean pooling可能稀释重要的局部信号，导致短上下文性能下降。

Method: 提出Landmark (LMK) pooling方法：1) 将序列分割成多个块；2) 在块之间插入landmark tokens；3) 通过对landmark token embeddings进行mean pooling形成最终表示。这种方法在引入少量特殊token的同时，改进了长上下文外推能力而不牺牲局部显著特征。

Result: 实验证明：LMK pooling在短上下文检索任务上与现有方法表现相当，在长上下文任务上带来显著改进，使其成为现有pooling方法的实用且可扩展的替代方案。

Conclusion: LMK pooling通过简单的机制有效解决了现有pooling策略的系统性弱点，在保持短上下文性能的同时显著提升长上下文任务表现，为序列表示学习提供了更优的pooling策略。

Abstract: Representation learning is central to many downstream tasks such as search, clustering, classification, and reranking. State-of-the-art sequence encoders typically collapse a variable-length token sequence to a single vector using a pooling operator, most commonly a special [CLS] token or mean pooling over token embeddings. In this paper, we identify systematic weaknesses of these pooling strategies: [CLS] tends to concentrate information toward the initial positions of the sequence and can under-represent distributed evidence, while mean pooling can dilute salient local signals, sometimes leading to worse short-context performance. To address these issues, we introduce Landmark (LMK) pooling, which partitions a sequence into chunks, inserts landmark tokens between chunks, and forms the final representation by mean-pooling the landmark token embeddings. This simple mechanism improves long-context extrapolation without sacrificing local salient features, at the cost of introducing a small number of special tokens. We empirically demonstrate that LMK pooling matches existing methods on short-context retrieval tasks and yields substantial improvements on long-context tasks, making it a practical and scalable alternative to existing pooling methods.

</details>


### [12] [Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space](https://arxiv.org/abs/2601.21169)
*Tobias Materzok*

Main category: cs.CL

TL;DR: OS-Search：将LLM生成转变为输出空间搜索，通过外层循环选择目标点，训练检索增强策略生成接近目标点的输出，实现并行扫描和黑盒优化


<details>
  <summary>Details</summary>
Motivation: 传统LLM生成是路径依赖的token级搜索，难以进行并行扫描和黑盒优化。作者希望将生成问题转化为输出空间中的搜索问题，提高多样性和优化效率。

Method: 1. 定义冻结编码器构建的3D输出空间Z；2. 外层循环选择目标点z*；3. 训练检索增强策略，使用序列级强化学习生成输出，使输出坐标在标准自回归解码下接近z*；4. 在故事任务中扫描Z空间，在代码任务中使用贝叶斯优化。

Result: 1. 故事生成：在Z空间扫描比prompt-chaining获得3.1倍更高的LLM评分多样性；2. 代码生成：在Z空间进行贝叶斯优化，在匹配推理预算下改进了控制器未知的目标函数，同时保持代码有效性。

Conclusion: OS-Search成功将LLM生成转化为输出空间搜索问题，实现了并行扫描和黑盒优化，在故事和代码生成任务中都取得了显著效果，为LLM生成提供了新的优化框架。

Abstract: We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates outputs whose coordinates land near z* under standard autoregressive decoding. This enables parallel sweeps and black-box optimization in Z without path-dependent token/program search. On stories, sweeping Z (text) yields 3.1x higher LLM-scored diversity than prompt-chaining. On code, Bayesian optimization over Z (code) improves an objective withheld from the controller under matched inference budgets while preserving validity.

</details>


### [13] [Toward Culturally Aligned LLMs through Ontology-Guided Multi-Agent Reasoning](https://arxiv.org/abs/2601.21700)
*Wonduk Seo,Wonseok Choi,Junseo Koh,Juhyeon Lee,Hyunjin An,Minhyeong Yu,Jian Park,Qingshan Zhou,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: OG-MAR是一个基于本体指导的多智能体推理框架，通过构建全球文化本体和价值画像代理来提升LLMs的文化敏感性决策，在多个LLM骨干网络上显著改善文化对齐和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在文化敏感决策中存在错位问题，主要原因是预训练数据偏差和缺乏结构化价值表示。现有方法通常缺乏人口统计学基础，将价值视为独立、非结构化信号，导致一致性和可解释性不足。

Method: 提出OG-MAR框架：1) 从世界价值观调查(WVS)中总结受访者特定价值；2) 通过能力问题在固定分类上构建全球文化本体；3) 推理时检索本体一致关系和人口统计学相似画像，实例化多个价值画像代理；4) 由判断代理综合输出，强制执行本体一致性和人口统计学接近性。

Result: 在四个LLM骨干网络的区域社会调查基准测试中，OG-MAR相比竞争基线显著提高了文化对齐和鲁棒性，同时产生更透明的推理轨迹。

Conclusion: OG-MAR通过结构化本体和人口统计学基础的代理方法，有效解决了LLMs文化对齐问题，为跨文化AI系统提供了更一致、可解释的决策框架。

Abstract: Large Language Models (LLMs) increasingly support culturally sensitive decision making, yet often exhibit misalignment due to skewed pretraining data and the absence of structured value representations. Existing methods can steer outputs, but often lack demographic grounding and treat values as independent, unstructured signals, reducing consistency and interpretability. We propose OG-MAR, an Ontology-Guided Multi-Agent Reasoning framework. OG-MAR summarizes respondent-specific values from the World Values Survey (WVS) and constructs a global cultural ontology by eliciting relations over a fixed taxonomy via competency questions. At inference time, it retrieves ontology-consistent relations and demographically similar profiles to instantiate multiple value-persona agents, whose outputs are synthesized by a judgment agent that enforces ontology consistency and demographic proximity. Experiments on regional social-survey benchmarks across four LLM backbones show that OG-MAR improves cultural alignment and robustness over competitive baselines, while producing more transparent reasoning traces.

</details>


### [14] [From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning](https://arxiv.org/abs/2601.21191)
*Xiulin Yang,Heidi Getz,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 研究统计条件如何支持从线性输入中学习层次结构，重点关注功能词的分布特性及其对语言习得的影响。


<details>
  <summary>Details</summary>
Motivation: 探索什么样的统计条件支持从线性输入中学习层次结构，特别是功能词因其高频、与句法结构可靠关联、与短语边界对齐等独特分布特性而被认为在语言习得中起关键作用。

Method: 1. 使用跨语言语料库分析验证186种语言中功能词的三种分布特性；2. 结合反事实语言建模和消融实验，比较保留不同特性的语言变体在神经网络学习中的表现；3. 通过探针和消融分析研究不同学习条件下对功能词的依赖机制。

Result: 1. 确认功能词的三种分布特性在186种语言中普遍存在；2. 保留所有三种特性的语言变体更容易被神经网络习得，其中频率和结构关联的贡献比边界对齐更强；3. 不同学习条件导致对功能词的系统性不同依赖，表明相似性能可能来自不同的内部机制。

Conclusion: 功能词的特定统计特性（高频、结构关联、边界对齐）确实支持从线性输入中学习层次结构，但不同特性对习得的贡献程度不同，且学习机制具有多样性。

Abstract: What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role in language acquisition due to their distinctive distributional properties, including high frequency, reliable association with syntactic structure, and alignment with phrase boundaries. We use cross-linguistic corpus analysis to first establish that all three properties are present across 186 studied languages. Next, we use a combination of counterfactual language modeling and ablation experiments to show that language variants preserving all three properties are more easily acquired by neural learners, with frequency and structural association contributing more strongly than boundary alignment. Follow-up probing and ablation analyses further reveal that different learning conditions lead to systematically different reliance on function words, indicating that similar performance can arise from distinct internal mechanisms.

</details>


### [15] [When "Better" Prompts Hurt: Evaluation-Driven Iteration for LLM Applications](https://arxiv.org/abs/2601.22025)
*Daniel Commey*

Main category: cs.CL

TL;DR: 该论文提出了一个面向LLM应用的评估驱动工作流（定义、测试、诊断、修复），并引入了最小可行评估套件（MVES），通过实验证明通用提示模板可能在不同任务表现间存在权衡，强调了评估驱动迭代的重要性。


<details>
  <summary>Details</summary>
Motivation: LLM应用评估与传统软件测试不同，因为输出具有随机性、高维性，且对提示和模型变化敏感。需要一种系统化的评估方法来应对这些挑战。

Method: 提出了一个四步评估驱动工作流（定义、测试、诊断、修复），引入了最小可行评估套件（MVES），包含通用LLM应用、RAG和智能体工具使用流程的评估组件。使用自动化检查、人工评估标准和LLM作为评判者等多种评估方法。

Result: 实验发现通用"改进"提示模板在不同行为间存在权衡：在Llama 3上，用通用规则替换任务特定提示时，提取通过率从100%降至90%，RAG合规性从93.3%降至80%，但指令遵循性有所改善。

Conclusion: 需要采用评估驱动的提示迭代和谨慎的声明校准，而不是通用的提示配方。评估工作流和MVES可以帮助工程化LLM应用开发。

Abstract: Evaluating Large Language Model (LLM) applications differs from traditional software testing because outputs are stochastic, high-dimensional, and sensitive to prompt and model changes. We present an evaluation-driven workflow - Define, Test, Diagnose, Fix - that turns these challenges into a repeatable engineering loop.
  We introduce the Minimum Viable Evaluation Suite (MVES), a tiered set of recommended evaluation components for (i) general LLM applications, (ii) retrieval-augmented generation (RAG), and (iii) agentic tool-use workflows. We also synthesize common evaluation methods (automated checks, human rubrics, and LLM-as-judge) and discuss known judge failure modes.
  In reproducible local experiments (Ollama; Llama 3 8B Instruct and Qwen 2.5 7B Instruct), we observe that a generic "improved" prompt template can trade off behaviors: on our small structured suites, extraction pass rate decreased from 100% to 90% and RAG compliance from 93.3% to 80% for Llama 3 when replacing task-specific prompts with generic rules, while instruction-following improved. These findings motivate evaluation-driven prompt iteration and careful claim calibration rather than universal prompt recipes.
  All test suites, harnesses, and results are included for reproducibility.

</details>


### [16] [Scaling Embeddings Outperforms Scaling Experts in Language Models](https://arxiv.org/abs/2601.21204)
*Hong Liu,Jiaqi Zhang,Chao Wang,Xing Hu,Linkun Lyu,Jiaqi Sun,Xurui Yang,Bo Wang,Fengcun Li,Yulei Qian,Lingtong Si,Yerui Sun,Rumei Li,Peng Pei,Yuchen Xie,Xunliang Cai*

Main category: cs.CL

TL;DR: 该论文提出嵌入缩放作为混合专家模型的一种补充扩展维度，通过系统分析识别了嵌入缩放优于专家缩放的具体场景，并开发了LongCat-Flash-Lite模型验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 混合专家架构作为大型语言模型稀疏扩展的标准方法，正面临收益递减和系统级瓶颈问题。作者探索嵌入缩放作为正交的稀疏扩展维度，以解决这些限制。

Method: 1. 通过全面分析和实验，识别嵌入缩放优于专家缩放的具体场景；2. 系统分析控制这种效能的架构因素，包括参数预算、模型宽度和深度的相互作用；3. 集成定制系统优化和推测解码，将稀疏性转化为实际推理加速；4. 开发LongCat-Flash-Lite模型（68.5B参数，~3B激活参数），其中超过30B参数分配给嵌入层。

Result: LongCat-Flash-Lite模型不仅超越了参数相当的MoE基线，而且在可比规模的现有模型中表现出卓越的竞争力，特别是在智能体和编码领域。嵌入缩放达到了比专家缩放更优的帕累托前沿。

Conclusion: 嵌入缩放是混合专家模型稀疏扩展的一个有效正交维度，通过系统架构分析和优化，可以转化为实际性能优势，为大型语言模型扩展提供了新方向。

Abstract: While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language models, they increasingly face diminishing returns and system-level bottlenecks. In this work, we explore embedding scaling as a potent, orthogonal dimension for scaling sparsity. Through a comprehensive analysis and experiments, we identify specific regimes where embedding scaling achieves a superior Pareto frontier compared to expert scaling. We systematically characterize the critical architectural factors governing this efficacy -- ranging from parameter budgeting to the interplay with model width and depth. Moreover, by integrating tailored system optimizations and speculative decoding, we effectively convert this sparsity into tangible inference speedups. Guided by these insights, we introduce LongCat-Flash-Lite, a 68.5B parameter model with ~3B activated trained from scratch. Despite allocating over 30B parameters to embeddings, LongCat-Flash-Lite not only surpasses parameter-equivalent MoE baselines but also exhibits exceptional competitiveness against existing models of comparable scale, particularly in agentic and coding domains.

</details>


### [17] [Multilingual Dysarthric Speech Assessment Using Universal Phone Recognition and Language-Specific Phonemic Contrast Modeling](https://arxiv.org/abs/2601.21205)
*Eunjung Yeo,Julie M. Liss,Visar Berisha,David R. Mortensen*

Main category: cs.CL

TL;DR: 本文提出了一种多语言音素产出评估框架，通过结合通用音素识别和语言特定音素解释，为跨语言的构音障碍可懂度评估提供了有效方法。


<details>
  <summary>Details</summary>
Motivation: 随着与构音障碍相关的神经系统疾病日益普遍，需要开发适用于跨语言的自动化可懂度评估方法。现有方法大多局限于单一语言或未能捕捉影响可懂度的语言特定因素。

Method: 提出了一个多语言音素产出评估框架，整合了通用音素识别和语言特定音素解释。使用对比音系特征距离进行音素到音位的映射和序列对齐，产生了三个评估指标：音素错误率（PER）、音系特征错误率（PFER）和新提出的无需对齐的音素覆盖率（PhonCov）。

Result: 在英语、西班牙语、意大利语和泰米尔语上的分析表明：PER受益于映射和对齐的组合，PFER仅受益于对齐，而PhonCov受益于映射。进一步分析显示，该框架能够捕捉与构音障碍语音已知观察结果一致的有临床意义的可懂度退化模式。

Conclusion: 该多语言音素产出评估框架为跨语言构音障碍可懂度评估提供了一种有效方法，能够捕捉语言特定因素对可懂度的影响，并显示出与临床观察一致的评估结果。

Abstract: The growing prevalence of neurological disorders associated with dysarthria motivates the need for automated intelligibility assessment methods that are applicalbe across languages. However, most existing approaches are either limited to a single language or fail to capture language-specific factors shaping intelligibility. We present a multilingual phoneme-production assessment framework that integrates universal phone recognition with language-specific phoneme interpretation using contrastive phonological feature distances for phone-to-phoneme mapping and sequence alignment. The framework yields three metrics: phoneme error rate (PER), phonological feature error rate (PFER), and a newly proposed alignment-free measure, phoneme coverage (PhonCov). Analysis on English, Spanish, Italian, and Tamil show that PER benefits from the combination of mapping and alignment, PFER from alignment alone, and PhonCov from mapping. Further analyses demonstrate that the proposed framework captures clinically meaningful patterns of intelligibility degradation consistent with established observations of dysarthric speech.

</details>


### [18] [Scaling Reasoning Hop Exposes Weaknesses: Demystifying and Improving Hop Generalization in Large Language Models](https://arxiv.org/abs/2601.21214)
*Zhaoyi Li,Jiatong Li,Gangwei Jiang,Linqi Song,Defu Lian,Ying Wei*

Main category: cs.CL

TL;DR: 该论文研究了思维链推理在推理步数超出训练分布时的性能下降问题，发现错误集中在少数关键错误类型的token位置，并提出了一种轻量级的测试时校正方法来动态识别和停用导致错误的注意力头。


<details>
  <summary>Details</summary>
Motivation: 虽然思维链推理已成为LLMs解决复杂问题的标准范式，但最近研究发现当推理步数超出训练分布时性能急剧下降，且这种失败的内在机制尚不清楚。作者旨在系统研究这一现象，理解导致性能下降的内部机制。

Method: 通过对多个领域任务的系统研究，作者发现错误集中在少数关键错误类型的token位置而非均匀分布。进一步分析揭示这些错误源于内部竞争机制：某些注意力头（称为错误处理头）通过放大错误推理轨迹并抑制正确轨迹来破坏平衡。基于这些洞察，作者提出了测试时推理校正方法，在推理过程中动态识别并停用错误处理头。

Result: 实验表明，在推理过程中移除单个错误处理头通常能恢复正确预测。在多个任务和LLMs上的广泛实验证明，测试时推理校正方法能持续提升推理步数泛化性能，显示了其有效性和潜力。

Conclusion: 该研究揭示了思维链推理在超出训练分布时的性能下降机制，并提出了一种有效的轻量级干预方法。错误集中在少数关键注意力头而非均匀分布的现象，为理解LLMs推理失败提供了新视角，所提方法为解决推理泛化问题提供了实用解决方案。

Abstract: Chain-of-thought (CoT) reasoning has become the standard paradigm for enabling Large Language Models (LLMs) to solve complex problems. However, recent studies reveal a sharp performance drop in reasoning hop generalization scenarios, where the required number of reasoning steps exceeds training distributions while the underlying algorithm remains unchanged. The internal mechanisms driving this failure remain poorly understood. In this work, we conduct a systematic study on tasks from multiple domains, and find that errors concentrate at token positions of a few critical error types, rather than being uniformly distributed. Closer inspection reveals that these token-level erroneous predictions stem from internal competition mechanisms: certain attention heads, termed erroneous processing heads (ep heads), tip the balance by amplifying incorrect reasoning trajectories while suppressing correct ones. Notably, removing individual ep heads during inference can often restore the correct predictions. Motivated by these insights, we propose test-time correction of reasoning, a lightweight intervention method that dynamically identifies and deactivates ep heads in the reasoning process. Extensive experiments across different tasks and LLMs show that it consistently improves reasoning hop generalization, highlighting both its effectiveness and potential.

</details>


### [19] [Parametric Knowledge is Not All You Need: Toward Honest Large Language Models via Retrieval of Pretraining Data](https://arxiv.org/abs/2601.21218)
*Christopher Adrian Kusuma,Muhammad Reza Qorib,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 提出一个更鲁棒的LLM诚实性评估基准数据集，并利用预训练数据构建更诚实LLM的新方法


<details>
  <summary>Details</summary>
Motivation: 当前LLM缺乏对自身知识边界的认知，会在知识不足时产生幻觉而非诚实回答"我不知道"。现有诚实性评估方法缺乏鲁棒性，未能考虑LLM在预训练中已获取的知识。

Method: 利用Pythia（真正开源的LLM，预训练数据公开可用）构建更鲁棒的评估基准数据集，并提出一种利用预训练数据构建更诚实LLM的新方法

Result: 论文提出了一个新的评估基准数据集，以及基于预训练数据的LLM诚实性改进方法（具体实验结果未在摘要中提及）

Conclusion: 通过利用公开可用的预训练数据，可以构建更鲁棒的LLM诚实性评估基准，并开发更有效的诚实性改进方法，从而减少LLM的幻觉问题

Abstract: Large language models (LLMs) are highly capable of answering questions, but they are often unaware of their own knowledge boundary, i.e., knowing what they know and what they don't know. As a result, they can generate factually incorrect responses on topics they do not have enough knowledge of, commonly known as hallucination. Rather than hallucinating, a language model should be more honest and respond with "I don't know" when it does not have enough knowledge about a topic. Many methods have been proposed to improve LLM honesty, but their evaluations lack robustness, as they do not take into account the knowledge that the LLM has ingested during its pretraining. In this paper, we propose a more robust evaluation benchmark dataset for LLM honesty by utilizing Pythia, a truly open LLM with publicly available pretraining data. In addition, we also propose a novel method for harnessing the pretraining data to build a more honest LLM.

</details>


### [20] [MGSM-Pro: A Simple Strategy for Robust Multilingual Mathematical Reasoning Evaluation](https://arxiv.org/abs/2601.21225)
*Tianyi Xu,Kosei Uemura,Alfred Malengo Kondoro,Tadesse Destaw Belay,Catherine Nana Nyaah Essuman,Ifeoma Okoh,Ganiyat Afolabi,Ayodele Awokoya,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 研究者将GSM-Symbolic方法扩展到多语言，创建了MGSM-Pro数据集，发现在不同数字实例化下，低资源语言模型性能大幅下降，建议每个问题至少用5种数字变体进行评估。


<details>
  <summary>Details</summary>
Motivation: 当前多语言数学推理基准在难度和时效性上落后于英语，且GSM-Symbolic发现模型对同一问题的不同实例化表现差异大，但该研究仅限于英语。需要扩展到多语言环境来全面评估模型的鲁棒性。

Method: 扩展MGSM数据集，采用GSM-Symbolic方法，为每个问题创建5种不同实例化（通过改变名称、数字和无关上下文），在9种语言上进行评估，特别关注数字实例化变化对性能的影响。

Result: 1. 许多低资源语言在数字实例化不同于原始测试集时性能大幅下降；2. 专有模型中，Gemini 2.5 Flash和GPT-4.1对数字实例化较不鲁棒，Claude 4.0 Sonnet更鲁棒；3. 开源模型中，GPT-OSS 120B和DeepSeek V3表现出更强的鲁棒性。

Conclusion: 为了获得更鲁棒和真实的数学推理评估，建议每个问题至少使用5种数字变化的实例化进行测试，特别是在多语言环境下评估模型性能时。

Abstract: Large language models have made substantial progress in mathematical reasoning. However, benchmark development for multilingual evaluation has lagged behind English in both difficulty and recency. Recently, GSM-Symbolic showed a strong evidence of high variance when models are evaluated on different instantiations of the same question; however, the evaluation was conducted only in English. In this paper, we introduce MGSM-Pro, an extension of MGSM dataset with GSM-Symbolic approach. Our dataset provides five instantiations per MGSM question by varying names, digits and irrelevant context. Evaluations across nine languages reveal that many low-resource languages suffer large performance drops when tested on digit instantiations different from those in the original test set. We further find that some proprietary models, notably Gemini 2.5 Flash and GPT-4.1, are less robust to digit instantiation, whereas Claude 4.0 Sonnet is more robust. Among open models, GPT-OSS 120B and DeepSeek V3 show stronger robustness. Based on these findings, we recommend evaluating each problem using at least five digit-varying instantiations to obtain a more robust and realistic assessment of math reasoning.

</details>


### [21] [SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models](https://arxiv.org/abs/2601.21235)
*Alok Abhishek,Tushar Bandopadhyay,Lisa Erickson*

Main category: cs.CL

TL;DR: SHARP框架通过多维、分布感知的风险分析评估LLM的社会危害，使用CVaR95等尾部风险指标，发现即使平均风险相似，不同模型的尾部风险和失败模式差异显著。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估基准通常将复杂的社会风险简化为均值标量分数，掩盖了分布结构、跨维度交互和最坏情况行为，无法有效评估高风险领域中可能造成不可逆伤害的罕见但严重的失败。

Method: 提出SHARP框架，将社会危害建模为多元随机变量，整合偏见、公平性、伦理和认知可靠性的显式分解，采用基于加性累积对数风险的失败联合聚合方法，并使用CVaR95等风险敏感分布统计量作为主要指标。

Result: 对11个前沿LLM在901个社会敏感提示上的评估显示：平均风险相似的模型在尾部暴露和波动性上可有两倍以上差异；不同危害维度的尾部严重程度呈现系统性差异，偏见维度最强，伦理对齐风险最低；揭示出标量基准无法区分的异质化、模型依赖的失败结构。

Conclusion: LLM的负责任评估和治理需要超越标量均值，转向多维、尾部敏感的风险画像，SHARP框架为此提供了方法论基础。

Abstract: Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.

</details>


### [22] [MoCo: A One-Stop Shop for Model Collaboration Research](https://arxiv.org/abs/2601.21257)
*Shangbin Feng,Yuyang Bai,Ziyuan Yang,Yike Wang,Zhaoxuan Tan,Jiajie Yan,Zhenyu Lei,Wenxuan Ding,Weijia Shi,Haojin Wang,Zhenting Qi,Yuru Jiang,Heng Wang,Chengsong Huang,Yu Fei,Jihan Yao,Yilun Du,Luke Zettlemoyer,Yejin Choi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: MoCo是一个用于模型协作的Python库，包含26种协作方法，在25个评估数据集上实验表明，61%的情况下协作策略优于单模型，最佳方法可提升25.8%性能。


<details>
  <summary>Details</summary>
Motivation: 当前模型协作研究分散在不同研究社区，缺乏系统比较和统一框架。需要整合现有研究，建立模型协作作为系统方法论。

Method: 开发MoCo Python库，集成26种模型协作方法（路由、文本、logit、模型参数等不同信息交换层次），支持25个评估数据集，用户可灵活使用自有数据。

Result: 实验显示大多数协作策略平均在61.0%的（模型，数据）设置中优于无协作模型，最有效方法可提升25.8%性能。分析了协作策略的扩展性、训练/推理效率，并展示了协作系统能解决单模型难以处理的问题。

Conclusion: MoCo为模型协作研究提供了有价值的工具包，促进了开放、模块化、去中心化和协作式AI未来的发展。该库使模型协作成为系统研究领域，并为未来研究奠定了基础。

Abstract: Advancing beyond single monolithic language models (LMs), recent research increasingly recognizes the importance of model collaboration, where multiple LMs collaborate, compose, and complement each other. Existing research on this topic has mostly been disparate and disconnected, from different research communities, and lacks rigorous comparison. To consolidate existing research and establish model collaboration as a school of thought, we present MoCo: a one-stop Python library of executing, benchmarking, and comparing model collaboration algorithms at scale. MoCo features 26 model collaboration methods, spanning diverse levels of cross-model information exchange such as routing, text, logit, and model parameters. MoCo integrates 25 evaluation datasets spanning reasoning, QA, code, safety, and more, while users could flexibly bring their own data. Extensive experiments with MoCo demonstrate that most collaboration strategies outperform models without collaboration in 61.0% of (model, data) settings on average, with the most effective methods outperforming by up to 25.8%. We further analyze the scaling of model collaboration strategies, the training/inference efficiency of diverse methods, highlight that the collaborative system solves problems where single LMs struggle, and discuss future work in model collaboration, all made possible by MoCo. We envision MoCo as a valuable toolkit to facilitate and turbocharge the quest for an open, modular, decentralized, and collaborative AI future.

</details>


### [23] [CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual Document Embedding](https://arxiv.org/abs/2601.21262)
*Jiahao Huo,Yu Huang,Yibo Yan,Ye Pan,Yi Cao,Mingdong Ou,Philip S. Yu,Xuming Hu*

Main category: cs.CL

TL;DR: CausalEmbed提出自回归生成方法构建多向量嵌入，用几十个视觉token实现视觉文档检索，token数量减少30-155倍，同时保持有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视觉文档检索中虽然能生成高质量多向量嵌入，但每个页面需要数千个视觉token表示，导致巨大的存储开销，限制了实际应用。

Method: 提出CausalEmbed自回归生成方法构建多向量嵌入，在对比训练中引入迭代边缘损失，鼓励模型学习紧凑且结构良好的表示。

Result: 仅使用几十个视觉token就能实现高效的视觉文档检索任务，token数量减少30-155倍，同时在各种骨干网络和基准测试中保持高度竞争力的性能。

Conclusion: CausalEmbed为多向量视觉文档检索表示提供了灵活测试时扩展策略，并揭示了多模态文档检索中的生成范式潜力。

Abstract: Although Multimodal Large Language Models (MLLMs) have shown remarkable potential in Visual Document Retrieval (VDR) through generating high-quality multi-vector embeddings, the substantial storage overhead caused by representing a page with thousands of visual tokens limits their practicality in real-world applications. To address this challenge, we propose an auto-regressive generation approach, CausalEmbed, for constructing multi-vector embeddings. By incorporating iterative margin loss during contrastive training, CausalEmbed encourages the embedding models to learn compact and well-structured representations. Our method enables efficient VDR tasks using only dozens of visual tokens, achieving a 30-155x reduction in token count while maintaining highly competitive performance across various backbones and benchmarks. Theoretical analysis and empirical results demonstrate the unique advantages of auto-regressive embedding generation in terms of training efficiency and scalability at test time. As a result, CausalEmbed introduces a flexible test-time scaling strategy for multi-vector VDR representations and sheds light on the generative paradigm within multimodal document retrieval.

</details>


### [24] [Qwen3-ASR Technical Report](https://arxiv.org/abs/2601.21337)
*Xian Shi,Xiong Wang,Zhifang Guo,Yongqi Wang,Pei Zhang,Xinyu Zhang,Zishan Guo,Hongkun Hao,Yu Xi,Baosong Yang,Jin Xu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: Qwen3-ASR系列包含两个强大的端到端语音识别模型和一个新颖的非自回归语音强制对齐模型，在52种语言上表现优异，1.7B版本达到开源SOTA，0.6B版本在准确性和效率间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 当前开源ASR模型在公开基准测试上差异不大，但在实际场景中质量差异显著。需要开发在真实世界场景中表现优异、支持多语言、且具有良好效率的ASR模型，同时解决语音文本对齐问题。

Method: 1) 基于Qwen3-Omni基础模型的音频理解能力，利用大规模语音训练数据开发ASR模型；2) 构建包含1.7B和0.6B两个版本的ASR模型，支持52种语言和方言的语言识别与语音识别；3) 开发基于LLM的非自回归强制对齐模型，用于11种语言的文本-语音对齐；4) 进行全面的内部评估，超越公开基准测试。

Result: 1) 1.7B版本在开源ASR模型中达到SOTA性能，与最强的专有API竞争；2) 0.6B版本提供最佳的准确性与效率权衡，平均TTFT低至92ms，128并发下1秒可转录2000秒语音；3) 强制对齐模型在11种语言上超越三个最强的强制对齐模型，在效率和多功能性上更具优势。

Conclusion: Qwen3-ASR系列提供了高性能、高效率的多语言语音识别解决方案，1.7B版本达到开源SOTA，0.6B版本在准确性和效率间达到最佳平衡。强制对齐模型在准确性和效率上均优于现有方法。所有模型已以Apache 2.0许可证开源，加速ASR和音频理解研究。

Abstract: In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one speech recognition models and a novel non-autoregressive speech forced alignment model. Qwen3-ASR-1.7B and Qwen3-ASR-0.6B are ASR models that support language identification and ASR for 52 languages and dialects. Both of them leverage large-scale speech training data and the strong audio understanding ability of their foundation model Qwen3-Omni. We conduct comprehensive internal evaluation besides the open-sourced benchmarks as ASR models might differ little on open-sourced benchmark scores but exhibit significant quality differences in real-world scenarios. The experiments reveal that the 1.7B version achieves SOTA performance among open-sourced ASR models and is competitive with the strongest proprietary APIs while the 0.6B version offers the best accuracy-efficiency trade-off. Qwen3-ASR-0.6B can achieve an average TTFT as low as 92ms and transcribe 2000 seconds speech in 1 second at a concurrency of 128. Qwen3-ForcedAligner-0.6B is an LLM based NAR timestamp predictor that is able to align text-speech pairs in 11 languages. Timestamp accuracy experiments show that the proposed model outperforms the three strongest force alignment models and takes more advantages in efficiency and versatility. To further accelerate the community research of ASR and audio understanding, we release these models under the Apache 2.0 license.

</details>


### [25] [Self-Improving Pretraining: using post-trained models to pretrain better models](https://arxiv.org/abs/2601.21343)
*Ellen Xiaoqing Tan,Shehzaad Dhuliawala,Jing Xu,Ping Yu,Sainbayar Sukhbaatar,Jason Weston,Olga Golovneva*

Main category: cs.CL

TL;DR: 本文提出了一种新的预训练方法，通过流式文档处理和强化学习，在预训练阶段就提升语言模型的事实性、安全性和生成质量，避免了传统方法只在微调阶段解决问题的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在安全性、事实性和整体质量方面存在挑战，主流方法依赖昂贵的精标数据和多阶段微调对齐，但这种方法无法纠正预训练阶段学习到的错误模式。因此需要在预训练阶段就解决这些问题，因为预训练塑造了模型的核心行为模式。

Method: 提出一种新的预训练方法：流式处理文档，使用强化学习优化每一步生成的后续K个token。通过一个经过后训练的强模型来评估候选生成（包括模型rollout、原始后缀和重写后缀）的质量、安全性和事实性。训练早期依赖原始和重写后缀，随着模型改进，强化学习奖励高质量rollout。

Result: 实验表明，该方法相比标准预训练在事实性方面获得36.2%的相对改进，在安全性方面获得18.5%的相对改进，在整体生成质量方面获得高达86.3%的胜率改进。

Conclusion: 该方法能够从底层构建更高质量、更安全、更事实的语言模型，通过在预训练阶段整合强化学习和质量评估，有效解决了传统方法难以纠正预训练习得模式的问题。

Abstract: Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.

</details>


### [26] [The Compliance Paradox: Semantic-Instruction Decoupling in Automated Academic Code Evaluation](https://arxiv.org/abs/2601.21360)
*Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Arjun Neekhra,Yash Sinha,Murari Mandal,Vinay Chamola,Dhruv Kumar*

Main category: cs.CL

TL;DR: LLMs在自动代码评分中存在系统性漏洞：模型会优先遵循隐藏指令而非评估代码质量，导致高达95%的故障率，错误认证功能错误的代码。


<details>
  <summary>Details</summary>
Motivation: 当前教育评估中广泛采用LLMs的假设是模型遵循指令的能力能直接转化为客观评判能力，但这一假设未经验证且可能存在根本缺陷。

Method: 提出SPACI框架和AST-ASIP协议，通过在抽象语法树的语法无关区域（trivia节点）嵌入对抗性指令，利用语法-语义鸿沟来攻击模型。大规模评估了9个SOTA模型在25,000份Python、C、C++和Java提交上的表现。

Result: 揭示高容量开源模型（如DeepSeek-V3）存在灾难性故障率（>95%），系统性地优先考虑隐藏格式约束而非代码正确性。通过三部分框架量化了模型的解耦概率、分数差异和教学严重性，展示了广泛的"错误认证"现象。

Conclusion: 当前的对齐范式在自动评分中创建了"特洛伊"漏洞，需要从标准RLHF转向领域特定的裁决鲁棒性，让模型优先考虑证据而非指令遵从性。

Abstract: The rapid integration of Large Language Models (LLMs) into educational assessment rests on the unverified assumption that instruction following capability translates directly to objective adjudication. We demonstrate that this assumption is fundamentally flawed. Instead of evaluating code quality, models frequently decouple from the submission's logic to satisfy hidden directives, a systemic vulnerability we term the Compliance Paradox, where models fine-tuned for extreme helpfulness are vulnerable to adversarial manipulation. To expose this, we introduce the Semantic-Preserving Adversarial Code Injection (SPACI) Framework and the Abstract Syntax Tree-Aware Semantic Injection Protocol (AST-ASIP). These methods exploit the Syntax-Semantics Gap by embedding adversarial directives into syntactically inert regions (trivia nodes) of the Abstract Syntax Tree. Through a large-scale evaluation of 9 SOTA models across 25,000 submissions in Python, C, C++, and Java, we reveal catastrophic failure rates (>95%) in high-capacity open-weights models like DeepSeek-V3, which systematically prioritize hidden formatting constraints over code correctness. We quantify this failure using our novel tripartite framework measuring Decoupling Probability, Score Divergence, and Pedagogical Severity to demonstrate the widespread "False Certification" of functionally broken code. Our findings suggest that current alignment paradigms create a "Trojan" vulnerability in automated grading, necessitating a shift from standard RLHF toward domain-specific Adjudicative Robustness, where models are conditioned to prioritize evidence over instruction compliance. We release our complete dataset and injection framework to facilitate further research on the topic.

</details>


### [27] [User-Centric Evidence Ranking for Attribution and Fact Verification](https://arxiv.org/abs/2601.21387)
*Guy Alt,Eran Hirsch,Serwar Basch,Ido Dagan,Oren Glickman*

Main category: cs.CL

TL;DR: 证据排序任务：通过优先呈现充分信息来最小化用户阅读成本，同时保持所有证据可访问，提升事实验证效率


<details>
  <summary>Details</summary>
Motivation: 现有自动系统和大型语言模型在事实验证中检索证据时，常提供信息不足或冗余的内容，导致验证效率低下且易出错

Method: 提出证据排序新任务，比较一次性排序和增量排序两种方法；引入基于信息检索指标的新评估框架，通过聚合现有事实验证数据集构建统一基准

Result: 实验表明增量排序策略能更好捕捉互补证据，基于LLM的方法优于浅层基线；相比证据选择，证据排序既减少阅读成本又提高验证准确性

Conclusion: 证据排序为构建更可解释、高效且用户对齐的信息验证系统提供了基础步骤，但仍需在充分性和冗余性平衡方面继续改进

Abstract: Attribution and fact verification are critical challenges in natural language processing for assessing information reliability. While automated systems and Large Language Models (LLMs) aim to retrieve and select concise evidence to support or refute claims, they often present users with either insufficient or overly redundant information, leading to inefficient and error-prone verification. To address this, we propose Evidence Ranking, a novel task that prioritizes presenting sufficient information as early as possible in a ranked list. This minimizes user reading effort while still making all available evidence accessible for sequential verification. We compare two approaches for the new ranking task: one-shot ranking and incremental ranking. We introduce a new evaluation framework, inspired by information retrieval metrics, and construct a unified benchmark by aggregating existing fact verification datasets. Extensive experiments with diverse models show that incremental ranking strategies better capture complementary evidence and that LLM-based methods outperform shallower baselines, while still facing challenges in balancing sufficiency and redundancy. Compared to evidence selection, we conduct a controlled user study and demonstrate that evidence ranking both reduces reading effort and improves verification. This work provides a foundational step toward more interpretable, efficient, and user-aligned information verification systems.

</details>


### [28] [Conversation for Non-verifiable Learning: Self-Evolving LLMs through Meta-Evaluation](https://arxiv.org/abs/2601.21464)
*Yuan Sui,Bryan Hooi*

Main category: cs.CL

TL;DR: CoNL通过多智能体自博弈统一生成、评估和元评估，利用"能帮助他人改进的批评才是好批评"的洞见，在没有外部评估者或真值标签的情况下，联合优化生成和评估能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在无真值标签任务（如创意写作、对话、伦理推理）上的训练面临挑战。LLM-as-Judge方法虽可扩展，但受限于评估者自身质量：若评估者无法识别优质解决方案，则无法提供有用训练信号，且评估偏见（如偏向冗长而非质量）无法解决。这促使需要元评估能力来评估和改进评估者本身。

Method: 提出CoNL框架，通过多智能体自博弈统一生成、评估和元评估。核心洞见：批评质量可通过其是否帮助他人改进解决方案来衡量。多个共享相同策略的智能体参与结构化对话，提出、批评和修订解决方案。能够促进解决方案改进的批评获得诊断性奖励，为元评估提供显式监督，并通过自博弈联合优化生成和判断能力，无需外部评估者或真值标签。

Result: 在五个基准测试上的实验表明，CoNL相比自奖励基线实现了持续改进，同时保持训练稳定性。

Conclusion: CoNL通过统一生成、评估和元评估的多智能体自博弈框架，解决了LLM训练中评估者质量限制的问题，在没有外部监督的情况下实现了生成和判断能力的联合优化，为无真值标签任务的大模型训练提供了有效方法。

Abstract: Training large language models (LLMs) for non-verifiable tasks, such as creative writing, dialogue, and ethical reasoning, remains challenging due to the absence of ground-truth labels. While LLM-as-Judge approaches offer a scalable alternative to human feedback, they face a fundamental limitation: performance is constrained by the evaluator's own quality. If the judge cannot recognize good solutions, it cannot provide useful training signals, and evaluation biases (e.g., favoring verbosity over quality) remain unaddressed. This motivates meta-evaluation: the ability to evaluate and improve the evaluator itself. We introduce CoNL, a framework that unifies generation, evaluation, and meta-evaluation through multi-agent self-play. Our key insight: critique quality can be measured by whether it helps others improve their solutions. In CoNL, multiple agents sharing the same policy engage in structured conversations to propose, critique, and revise solutions. Critiques that enable solution improvements earn a diagnostic reward, creating explicit supervision for meta-evaluation and enabling joint optimization of generation and judging capabilities through self-play, without external judges or ground truth. Experiments on five benchmarks show that CoNL achieves consistent improvements over self-rewarding baselines while maintaining stable training.

</details>


### [29] [SOUP: Token-level Single-sample Mix-policy Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.21476)
*Lei Yang,Wei Bi,Chenxi Sun,Renren Jin,Deyi Xiong*

Main category: cs.CL

TL;DR: SOUP框架通过token级别的混合策略学习，将历史策略采样的前缀与当前策略生成的后续部分结合，有效利用离线数据提升语言模型强化学习效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于策略的RL方法（如GRPO）存在探索不足和早期饱和问题，而混合整个轨迹的离线策略方法会导致策略不匹配和不稳定性。

Method: 提出SOUP框架，在单个样本的token级别统一离线和在线策略学习：使用历史策略采样生成序列的前缀部分，而后续部分则使用当前策略在线生成，并通过token级别的重要性比率有效利用离线信息。

Result: 大量实验表明，SOUP在性能上持续优于标准的在线策略训练和现有的离线策略扩展方法，能够同时改善探索能力和最终性能。

Conclusion: SOUP框架通过细粒度的单样本混合策略训练，能够有效利用离线数据提升语言模型强化学习的稳定性和性能，解决了现有方法在探索和策略不匹配方面的问题。

Abstract: On-policy reinforcement learning (RL) methods widely used for language model post-training, like Group Relative Policy Optimization (GRPO), often suffer from limited exploration and early saturation due to low sampling diversity. While off-policy data can help, current approaches that mix entire trajectories cause significant policy mismatch and instability. In this work, we propose the $\textbf{S}$ingle-sample Mix-p$\textbf{O}$licy $\textbf{U}$nified $\textbf{P}$aradigm (SOUP), a framework that unifies off- and on-policy learning within individual samples at the token level. It confines off-policy influence to the prefix of a generated sequence sampled from historical policies, while the continuation is generated on-policy. Through token-level importance ratios, SOUP effectively leverages off-policy information while preserving training stability. Extensive experiments demonstrate that SOUP consistently outperforms standard on-policy training and existing off-policy extensions. Our further analysis clarifies how our fine-grained, single-sample mix-policy training can improve both exploration and final performance in LLM RL.

</details>


### [30] [DimStance: Multilingual Datasets for Dimensional Stance Analysis](https://arxiv.org/abs/2601.21483)
*Jonas Becker,Liang-Chih Yu,Shamsuddeen Hassan Muhammad,Jan Philip Wahle,Terry Ruas,Idris Abdulmumin,Lung-Hao Lee,Wen-Ni Liu,Tzu-Mi Lin,Zhe-Yu Xu,Ying-Lung Lin,Jin Wang,Maryam Ibrahim Mukhtar,Bela Gipp,Saif M. Mohammed*

Main category: cs.CL

TL;DR: DimStance是首个包含情感维度（效价-唤醒度）标注的立场检测资源，涵盖5种语言和2个领域，支持细粒度的情感感知立场分析。


<details>
  <summary>Details</summary>
Motivation: 传统立场检测仅使用分类标签（支持/中立/反对），无法捕捉立场表达背后的细微情感状态。需要引入情感科学中的维度模型（效价-唤醒度）来实现更细粒度的立场分析。

Method: 构建DimStance资源，包含11,746个目标方面、7,365篇文本，涵盖5种语言和2个领域。提出维度立场回归任务，评估预训练模型和大型语言模型在回归和提示设置下的表现。

Result: 微调后的LLM回归器表现具有竞争力，但在低资源语言中仍存在挑战，基于token的生成方法也有局限性。发现了跨语言的VA模式差异。

Conclusion: DimStance为多语言、情感感知的立场分析提供了基础资源，维度立场回归任务能够捕捉更丰富的立场表达信息，推动了细粒度立场分析的发展。

Abstract: Stance detection is an established task that classifies an author's attitude toward a specific target into categories such as Favor, Neutral, and Against. Beyond categorical stance labels, we leverage a long-established affective science framework to model stance along real-valued dimensions of valence (negative-positive) and arousal (calm-active). This dimensional approach captures nuanced affective states underlying stance expressions, enabling fine-grained stance analysis. To this end, we introduce DimStance, the first dimensional stance resource with valence-arousal (VA) annotations. This resource comprises 11,746 target aspects in 7,365 texts across five languages (English, German, Chinese, Nigerian Pidgin, and Swahili) and two domains (politics and environmental protection). To facilitate the evaluation of stance VA prediction, we formulate the dimensional stance regression task, analyze cross-lingual VA patterns, and benchmark pretrained and large language models under regression and prompting settings. Results show competitive performance of fine-tuned LLM regressors, persistent challenges in low-resource languages, and limitations of token-based generation. DimStance provides a foundation for multilingual, emotion-aware, stance analysis and benchmarking.

</details>


### [31] [inversedMixup: Data Augmentation via Inverting Mixed Embeddings](https://arxiv.org/abs/2601.21543)
*Fanshuang Kong,Richong Zhang,Qiyu Sun,Zhijie Nie,Ting Deng,Chunming Hu*

Main category: cs.CL

TL;DR: inversedMixup：一个将Mixup的可控性与基于LLM的生成的可解释性相结合的统一框架，通过LLM反演技术将混合嵌入重构为人类可读的增强句子。


<details>
  <summary>Details</summary>
Motivation: 传统Mixup在潜在嵌入层面操作，生成的样本不可解释；而基于LLM的增强方法虽然可读，但生成过程控制有限。需要结合两者的优势。

Method: 采用三阶段训练过程，将任务特定模型的输出嵌入空间与LLM的输入嵌入空间对齐，从而将具有可控混合比例的混合嵌入重构为人类可解释的增强句子。

Result: 在少样本和完全监督场景下的广泛实验证明了该方法的有效性和泛化能力，并首次为文本Mixup中的流形入侵现象提供了实证证据。

Conclusion: inversedMixup成功结合了Mixup的可控性和LLM增强的可解释性，提高了增强性能，并为文本Mixup的流形入侵问题提供了缓解策略。

Abstract: Mixup generates augmented samples by linearly interpolating inputs and labels with a controllable ratio. However, since it operates in the latent embedding level, the resulting samples are not human-interpretable. In contrast, LLM-based augmentation methods produce sentences via prompts at the token level, yielding readable outputs but offering limited control over the generation process. Inspired by recent advances in LLM inversion, which reconstructs natural language from embeddings and helps bridge the gap between latent embedding space and discrete token space, we propose inversedMixup, a unified framework that combines the controllability of Mixup with the interpretability of LLM-based generation. Specifically, inversedMixup adopts a three-stage training procedure to align the output embedding space of a task-specific model with the input embedding space of an LLM. Upon successful alignment, inversedMixup can reconstruct mixed embeddings with a controllable mixing ratio into human-interpretable augmented sentences, thereby improving the augmentation performance. Additionally, inversedMixup provides the first empirical evidence of the manifold intrusion phenomenon in text Mixup and introduces a simple yet effective strategy to mitigate it. Extensive experiments demonstrate the effectiveness and generalizability of our approach in both few-shot and fully supervised scenarios.

</details>


### [32] [Note2Chat: Improving LLMs for Multi-Turn Clinical History Taking Using Medical Notes](https://arxiv.org/abs/2601.21551)
*Yang Zhou,Zhenting Sheng,Mingrui Tan,Yuting Song,Jun Zhou,Yu Heng Kwan,Lian Leng Low,Yang Bai,Yong Liu*

Main category: cs.CL

TL;DR: 论文提出了Note2Chat框架，通过从医疗笔记生成医患对话数据，采用三阶段微调策略，将病史采集重构为单轮推理问题，显著提升LLM的临床推理能力。


<details>
  <summary>Details</summary>
Motivation: 临床病史采集是临床推理的基础但研究不足。现有LLM在静态基准测试中表现良好，但在需要迭代提问和假设细化的动态多轮诊断场景中表现不佳，且缺乏高质量对话数据进行训练。

Method: 提出Note2Chat框架：1）将真实医疗笔记通过决策树引导的生成和精炼管道转换为高质量医患对话；2）采用三阶段微调策略：监督学习、模拟数据增强和偏好学习；3）提出单轮推理范式，将病史采集重构为一系列单轮推理问题。

Result: 实验结果表明，该方法显著改善了临床推理能力，相比GPT-4o实现了+16.9 F1分数和+21.0 Top-1诊断准确率的提升。

Conclusion: Note2Chat框架通过利用医疗笔记生成对话数据，结合创新的微调策略和单轮推理范式，有效解决了LLM在动态临床推理中的局限性，为临床病史采集提供了可解释、高效且适应性强的解决方案。

Abstract: Effective clinical history taking is a foundational yet underexplored component of clinical reasoning. While large language models (LLMs) have shown promise on static benchmarks, they often fall short in dynamic, multi-turn diagnostic settings that require iterative questioning and hypothesis refinement. To address this gap, we propose \method{}, a note-driven framework that trains LLMs to conduct structured history taking and diagnosis by learning from widely available medical notes. Instead of relying on scarce and sensitive dialogue data, we convert real-world medical notes into high-quality doctor-patient dialogues using a decision tree-guided generation and refinement pipeline. We then propose a three-stage fine-tuning strategy combining supervised learning, simulated data augmentation, and preference learning. Furthermore, we propose a novel single-turn reasoning paradigm that reframes history taking as a sequence of single-turn reasoning problems. This design enhances interpretability and enables local supervision, dynamic adaptation, and greater sample efficiency. Experimental results show that our method substantially improves clinical reasoning, achieving gains of +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o. Our code and dataset can be found at https://github.com/zhentingsheng/Note2Chat.

</details>


### [33] [ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas](https://arxiv.org/abs/2601.21558)
*Xiaoyu Tian,Haotian Wang,Shuaiting Chen,Hao Zhou,Kaichi Yu,Yudian Zhang,Jade Ouyang,Junxi Yin,Jiong Chen,Baoyan Guo,Lei Zhang,Junjie Tao,Yuansheng Song,Ming Cui,Chengwei Liu*

Main category: cs.CL

TL;DR: ASTRA是一个完全自动化的端到端框架，通过可扩展数据合成和可验证强化学习来训练工具增强的语言模型代理，在多个工具使用基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前训练工具增强语言模型代理存在挑战：需要人工干预、依赖不可验证的模拟环境、仅使用SFT或RL单一方法、难以稳定进行长时域多轮学习。

Method: ASTRA包含两个核心组件：1)利用工具调用图静态拓扑合成多样化轨迹的数据管道；2)将分解的问答轨迹转换为可执行、可验证环境的框架。基于此开发统一训练方法，结合SFT和在线RL，使用轨迹级奖励平衡任务完成和交互效率。

Result: 在多个代理工具使用基准测试中，ASTRA训练的模型在同等规模下达到最先进性能，接近闭源系统同时保持核心推理能力。

Conclusion: ASTRA提供了一个完全自动化的端到端框架，通过可扩展数据合成和可验证强化学习有效训练工具增强语言模型代理，解决了现有方法的局限性。

Abstract: Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making, yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either supervised fine-tuning (SFT) or reinforcement learning (RL), and struggle with stable long-horizon, multi-turn learning. To address these challenges, we introduce ASTRA, a fully automated end-to-end framework for training tool-augmented language model agents via scalable data synthesis and verifiable reinforcement learning. ASTRA integrates two complementary components. First, a pipeline that leverages the static topology of tool-call graphs synthesizes diverse, structurally grounded trajectories, instilling broad and transferable tool-use competence. Second, an environment synthesis framework that captures the rich, compositional topology of human semantic reasoning converts decomposed question-answer traces into independent, code-executable, and rule-verifiable environments, enabling deterministic multi-turn RL. Based on this method, we develop a unified training methodology that integrates SFT with online RL using trajectory-level rewards to balance task completion and interaction efficiency. Experiments on multiple agentic tool-use benchmarks demonstrate that ASTRA-trained models achieve state-of-the-art performance at comparable scales, approaching closed-source systems while preserving core reasoning ability. We release the full pipelines, environments, and trained models at https://github.com/LianjiaTech/astra.

</details>


### [34] [KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices](https://arxiv.org/abs/2601.21579)
*Wuyang Zhou,Yuxuan Gu,Giorgos Iacovides,Danilo Mandic*

Main category: cs.CL

TL;DR: KromHC通过使用较小双随机矩阵的Kronecker积参数化残差矩阵，解决了mHC训练不稳定、可扩展性受限的问题，在保证精确双随机性的同时将参数复杂度从O(n³C)降至O(n²C)。


<details>
  <summary>Details</summary>
Motivation: Hyper-Connections (HC)在神经网络中表现出色，但存在训练不稳定和可扩展性受限的问题。mHC通过将残差连接空间投影到Birkhoff多面体来缓解这些问题，但仍面临两个主要挑战：1) Sinkhorn-Knopp算法不总能产生精确的双随机残差矩阵；2) mHC的O(n³C)参数复杂度过高。mHC-lite虽然通过Birkhoff-von-Neumann定理保证双随机性，但面临O(nC·n!)的阶乘爆炸参数复杂度。

Method: KromHC使用较小双随机矩阵的Kronecker积来参数化mHC中的残差矩阵。通过在张量化残差流的每个模式上对因子残差矩阵施加流形约束，KromHC保证了残差矩阵的精确双随机性，同时将参数复杂度降低到O(n²C)。

Result: 综合实验表明，KromHC在性能上匹配甚至超越了最先进的mHC变体，同时需要显著更少的可训练参数。

Conclusion: KromHC成功解决了mHC及其变体在双随机性和参数复杂度方面的挑战，提供了一种高效且可扩展的Hyper-Connections实现方法。

Abstract: The success of Hyper-Connections (HC) in neural networks (NN) has also highlighted issues related to its training instability and restricted scalability. The Manifold-Constrained Hyper-Connections (mHC) mitigate these challenges by projecting the residual connection space onto a Birkhoff polytope, however, it faces two issues: 1) its iterative Sinkhorn-Knopp (SK) algorithm does not always yield exact doubly stochastic residual matrices; 2) mHC incurs a prohibitive $\mathcal{O}(n^3C)$ parameter complexity with $n$ as the width of the residual stream and $C$ as the feature dimension. The recently proposed mHC-lite reparametrizes the residual matrix via the Birkhoff-von-Neumann theorem to guarantee double stochasticity, but also faces a factorial explosion in its parameter complexity, $\mathcal{O} \left( nC \cdot n! \right)$. To address both challenges, we propose \textbf{KromHC}, which uses the \underline{Kro}necker products of smaller doubly stochastic matrices to parametrize the residual matrix in \underline{mHC}. By enforcing manifold constraints across the factor residual matrices along each mode of the tensorized residual stream, KromHC guarantees exact double stochasticity of the residual matrices while reducing parameter complexity to $\mathcal{O}(n^2C)$. Comprehensive experiments demonstrate that KromHC matches or even outperforms state-of-the-art (SOTA) mHC variants, while requiring significantly fewer trainable parameters. The code is available at \texttt{https://github.com/wz1119/KromHC}.

</details>


### [35] [Language Models as Artificial Learners: Investigating Crosslinguistic Influence](https://arxiv.org/abs/2601.21587)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 该研究使用语言模型作为受控统计学习器来系统模拟跨语言影响，通过操纵L1语言主导性和L2语言熟练度，揭示了这些因素如何预测跨语言影响，并提供了CLI在语言模型中的机制证据。


<details>
  <summary>Details</summary>
Motivation: 人类研究中关于跨语言影响（CLI）的结果常常相互矛盾，这主要是由于实验变量难以控制。为了解决这些不一致性，研究使用语言模型作为受控统计学习器来系统模拟CLI并分离其潜在驱动因素。

Method: 通过语言模型模拟双语学习过程，操纵L1语言主导性和L2语言熟练度（通过控制L2接触年龄），研究不同句法距离的L1预训练对L2的影响，使用跨语言启动范式分析L1结构激活如何影响L2处理。

Result: 结果与心理语言学研究一致：语言主导性和熟练度是CLI的强预测因子；语法结构的启动是双向的，但不合语法结构的启动对语言主导性敏感；提供了CLI在语言模型中的机制证据，显示L1在L2处理过程中被共同激活并直接影响L2的神经回路。

Conclusion: 语言模型可以作为计算框架来支撑人类跨语言影响理论，为CLI研究提供了可控的实验环境和机制层面的证据。

Abstract: Despite the centrality of crosslinguistic influence (CLI) to bilingualism research, human studies often yield conflicting results due to inherent experimental variance. We address these inconsistencies by using language models (LMs) as controlled statistical learners to systematically simulate CLI and isolate its underlying drivers. Specifically, we study the effect of varying the L1 language dominance and the L2 language proficiency, which we manipulate by controlling the L2 age of exposure -- defined as the training step at which the L2 is introduced. Furthermore, we investigate the impact of pretraining on L1 languages with varying syntactic distance from the L2. Using cross-linguistic priming, we analyze how activating L1 structures impacts L2 processing. Our results align with evidence from psycholinguistic studies, confirming that language dominance and proficiency are strong predictors of CLI. We further find that while priming of grammatical structures is bidirectional, the priming of ungrammatical structures is sensitive to language dominance. Finally, we provide mechanistic evidence of CLI in LMs, demonstrating that the L1 is co-activated during L2 processing and directly influences the neural circuitry recruited for the L2. More broadly, our work demonstrates that LMs can serve as a computational framework to inform theories of human CLI.

</details>


### [36] [ILRR: Inference-Time Steering Method for Masked Diffusion Language Models](https://arxiv.org/abs/2601.21647)
*Eden Avrahami,Eliya Nachmani*

Main category: cs.CL

TL;DR: 提出了一种无需学习的迭代潜在表示精炼框架，通过单参考序列引导离散扩散语言模型生成，实现有效的推理时控制。


<details>
  <summary>Details</summary>
Motivation: 离散扩散语言模型在文本生成方面表现出色，但现有的推理时控制机制相对不足，需要更有效的引导方法。

Method: 提出ILRR框架，通过动态对齐生成序列与参考序列的内部激活来引导去噪过程，并引入空间调制引导来用短参考序列引导长文本生成。

Result: ILRR在LLaDA和MDLM架构上实现了有效的属性引导，计算开销小，相比基线方法属性准确率提升10-60个百分点，同时保持高质量生成。

Conclusion: ILRR为离散扩散语言模型提供了一种简单高效的推理时控制框架，通过潜在表示对齐实现了灵活的属性引导。

Abstract: Discrete Diffusion Language Models (DLMs) offer a promising non-autoregressive alternative for text generation, yet effective mechanisms for inference-time control remain relatively underexplored. Existing approaches include sampling-level guidance procedures or trajectory optimization mechanisms. In this work, we introduce Iterative Latent Representation Refinement (ILRR), a learning-free framework for steering DLMs using a single reference sequence. ILRR guides generation by dynamically aligning the internal activations of the generated sequence with those of a given reference throughout the denoising process. This approach captures and transfers high-level semantic properties, with a tunable steering scale enabling flexible control over attributes such as sentiment. We further introduce Spatially Modulated Steering, an extension that enables steering long texts using shorter references by regulating guidance intensity across the sequence. Empirically, we demonstrate that ILRR achieves effective attribute steering on LLaDA and MDLM architectures with a minor computational overhead, requiring only one additional parallel forward pass per denoising step. Under the same compute budget, ILRR improves attribute accuracy over comparable baselines by 10$\%$ to 60$\%$ points, while maintaining high generation quality.

</details>


### [37] [AdaptBPE: From General Purpose to Specialized Tokenizers](https://arxiv.org/abs/2601.21665)
*Vijini Liyanage,François Yvon*

Main category: cs.CL

TL;DR: 本文提出了一种针对特定领域或语言的BPE分词器后训练适应方法，通过选择性替换低效用词元来优化分词效果。


<details>
  <summary>Details</summary>
Motivation: 标准的通用分词器在处理特定领域或语言数据时效率低下，因为通用词元集无法针对特定场景进行优化。

Method: 提出后训练适应策略，基于适应语料库中的词频，有选择性地替换低效用词元为更相关的词元。算法识别在给定目标词汇表大小下最有效编码适应语料库的词元库存。

Result: 在多语言生成和分类任务上的大量实验表明，该方法在相同词汇表大小下比基线方法能更有效地压缩测试语料库。

Conclusion: 该方法作为一种轻量级的适应机制，类似于词汇表微调过程，能够为特定领域或任务优化分词效果。

Abstract: Subword tokenization methods, such as Byte-Pair Encoding (BPE), significantly impact the performance and efficiency of large language models (LLMs). The standard approach involves training a general-purpose tokenizer that uniformly processes all textual data during both training and inference. However, the use of a generic set of tokens can incur inefficiencies when applying the model to specific domains or languages. To address this limitation, we propose a post-training adaptation strategy that selectively replaces low-utility tokens with more relevant ones based on their frequency in an adaptation corpus. Our algorithm identifies the token inventory that most effectively encodes the adaptation corpus for a given target vocabulary size. Extensive experiments on generation and classification tasks across multiple languages demonstrate that our adapted tokenizers compress test corpora more effectively than baselines using the same vocabulary size. This method serves as a lightweight adaptation mechanism, akin to a vocabulary fine-tuning process, enabling optimized tokenization for specific domains or tasks. Our code and data are available at https://github.com/vijini/Adapt-BPE.git.

</details>


### [38] [Scale-Dependent Semantic Dynamics Revealed by Allan Deviation](https://arxiv.org/abs/2601.21678)
*Debayan Dasgupta*

Main category: cs.CL

TL;DR: 该研究将文本语义演化视为高维状态空间中的随机轨迹，使用Allan偏差分析语义稳定性，发现人类文本和LLM在动态特性上的差异。


<details>
  <summary>Details</summary>
Motivation: 语言通过一系列语义状态演进，但其底层动态机制尚不明确。研究旨在理解文本语义演化的动态特性，并将语义连贯性量化为可测量的物理属性。

Method: 将文本语义演进视为高维状态空间中的随机轨迹，利用精密计量学中的Allan偏差工具，将有序句子嵌入视为位移信号来分析语义稳定性。

Result: 分析揭示两个不同的动态机制：短时幂律缩放（区分创意文学与技术文本）和长时交叉到稳定性限制的噪声基底。大语言模型能成功模仿人类文本的局部缩放统计特性，但表现出稳定性视界的系统性减少。

Conclusion: 语义连贯性是可测量的物理属性，该框架能区分人类认知的微妙动态与算法模型生成的模式，为理解语言演进提供了新的定量方法。

Abstract: While language progresses through a sequence of semantic states, the underlying dynamics of this progression remain elusive. Here, we treat the semantic progression of written text as a stochastic trajectory in a high-dimensional state space. We utilize Allan deviation, a tool from precision metrology, to analyze the stability of meaning by treating ordered sentence embeddings as a displacement signal. Our analysis reveals two distinct dynamical regimes: short-time power-law scaling, which differentiates creative literature from technical texts, and a long-time crossover to a stability-limited noise floor. We find that while large language models successfully mimic the local scaling statistics of human text, they exhibit a systematic reduction in their stability horizon. These results establish semantic coherence as a measurable physical property, offering a framework to differentiate the nuanced dynamics of human cognition from the patterns generated by algorithmic models.

</details>


### [39] [FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning](https://arxiv.org/abs/2601.21682)
*Xiaoyu Xu,Minxin Du,Kun Fang,Zi Liang,Yaxin Xiao,Zhicong Huang,Cheng Hong,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: FIT是一个持续遗忘框架，通过数据过滤、重要性感知更新和针对性层归因来处理大量删除请求，在保持模型效用的同时有效遗忘指定内容，并抵抗再学习和量化恢复攻击。


<details>
  <summary>Details</summary>
Motivation: 现有LLM遗忘方法很少考虑现实世界中持续且大量的删除请求特性，这会导致随着请求积累而产生效用退化和灾难性遗忘问题。

Method: 提出FIT框架，包含三个核心技术：严格的数据过滤、重要性感知更新和针对性层归因，以稳定处理长期序列的遗忘操作。同时提出PCH基准测试，涵盖个人信息、版权和有害内容三种删除场景。

Result: 在四个开源LLM上进行了大量实验，包含数百个删除请求。FIT在遗忘度(F.D.)和保留效用(R.U.)之间取得了最佳平衡，在MMLU、CommonsenseQA和GSM8K等基准测试中超越了现有方法，并对再学习和量化恢复攻击具有抵抗力。

Conclusion: FIT框架能有效处理大规模持续遗忘请求，在保持模型整体效用的同时实现针对性遗忘，为解决LLM实际部署中的隐私、版权和有害内容删除问题提供了有效方案。

Abstract: Large language models (LLMs) demonstrate impressive capabilities across diverse tasks but raise concerns about privacy, copyright, and harmful materials. Existing LLM unlearning methods rarely consider the continual and high-volume nature of real-world deletion requests, which can cause utility degradation and catastrophic forgetting as requests accumulate. To address this challenge, we introduce \fit, a framework for continual unlearning that handles large numbers of deletion requests while maintaining robustness against both catastrophic forgetting and post-unlearning recovery. \fit mitigates degradation through rigorous data \underline{F}iltering, \underline{I}mportance-aware updates, and \underline{T}argeted layer attribution, enabling stable performance across long sequences of unlearning operations and achieving a favorable balance between forgetting effectiveness and utility retention. To support realistic evaluation, we present \textbf{PCH}, a benchmark covering \textbf{P}ersonal information, \textbf{C}opyright, and \textbf{H}armful content in sequential deletion scenarios, along with two symmetric metrics, Forget Degree (F.D.) and Retain Utility (R.U.), which jointly assess forgetting quality and utility preservation. Extensive experiments on four open-source LLMs with hundreds of deletion requests show that \fit achieves the strongest trade-off between F.D. and R.U., surpasses existing methods on MMLU, CommonsenseQA, and GSM8K, and remains resistant against both relearning and quantization recovery attacks.

</details>


### [40] [Do Not Waste Your Rollouts: Recycling Search Experience for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.21684)
*Xinglin Wang,Jiayi Shi,Shaoxiong Feng,Peiwen Yuan,Yiwei Li,Yueqi Zhang,Chuyi Tan,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.CL

TL;DR: 提出RSE方法，通过建立共享经验库回收搜索过程中的中间结论和失败模式，减少计算冗余，提升大语言模型在复杂推理任务中的测试时扩展效率。


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法将每次推理尝试视为独立样本，中间见解在每次尝试后被丢弃，导致计算冗余——模型反复重新推导已发现的结论并重复遇到已知的死胡同。

Method: 提出Recycling Search Experience (RSE)，一种自引导、无需训练的策略，将原始轨迹提炼到共享经验库中，实现正回收（利用中间结论跳过冗余推导）和负回收（利用失败模式修剪死胡同）。

Result: 理论分析形式化了RSE的效率优势。在HMMT24、HMMT25、IMO-Bench和HLE等基准上的实验表明，RSE在相同计算成本下持续优于强基线，实现了最先进的扩展效率。

Conclusion: RSE将测试时搜索从一系列孤立试验转变为累积过程，通过回收搜索经验显著减少了计算冗余，为大语言模型在复杂推理任务中的高效扩展提供了有效解决方案。

Abstract: Test-Time Scaling enhances the reasoning capabilities of Large Language Models by allocating additional inference compute to broaden the exploration of the solution space. However, existing search strategies typically treat rollouts as disposable samples, where valuable intermediate insights are effectively discarded after each trial. This systemic memorylessness leads to massive computational redundancy, as models repeatedly re-derive discovered conclusions and revisit known dead ends across extensive attempts. To bridge this gap, we propose \textbf{Recycling Search Experience (RSE)}, a self-guided, training-free strategy that turns test-time search from a series of isolated trials into a cumulative process. By actively distilling raw trajectories into a shared experience bank, RSE enables positive recycling of intermediate conclusions to shortcut redundant derivations and negative recycling of failure patterns to prune encountered dead ends. Theoretically, we provide an analysis that formalizes the efficiency gains of RSE, validating its advantage over independent sampling in solving complex reasoning tasks. Empirically, extensive experiments on HMMT24, HMMT25, IMO-Bench, and HLE show that RSE consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art scaling efficiency.

</details>


### [41] [Can David Beat Goliath? On Multi-Hop Reasoning with Resource-Constrained Agents](https://arxiv.org/abs/2601.21699)
*Hojae Han,Heeyun Jung,Jongyoon Kim,Seung-won Hwang*

Main category: cs.CL

TL;DR: DAVID-GRPO：一种资源受限下的小语言模型强化学习框架，通过最小监督稳定早期学习、基于证据召回分配检索信用、重采样截断近似轨迹来改善探索，在低训练成本下实现强大多跳推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在资源受限场景下（小模型、有限探索预算）效果不佳，导致稀疏探索、稀疏信用分配和不稳定训练，形成低成本低准确率的困境。本文旨在打破这种权衡，证明小语言模型在资源约束下也能实现强大的多跳推理。

Method: 提出DAVID-GRPO框架：1）使用最小监督稳定早期学习；2）基于证据召回分配检索信用；3）通过重采样截断的近似轨迹来改善探索。该框架在仅有4块RTX 3090 GPU的条件下训练最多1.5B参数的代理。

Result: 在六个多跳QA基准测试中，DAVID-GRPO持续优于先前为大规模场景设计的RL方法，展示了小代理在低训练成本下实现高准确率的潜力。

Conclusion: 通过适当的归纳偏置，小语言模型代理可以在资源受限条件下实现低训练成本和高准确率，打破了强化学习中成本与准确率的传统权衡。

Abstract: While reinforcement learning (RL) has empowered multi-turn reasoning agents with retrieval and tools, existing successes largely depend on extensive on-policy rollouts in high-cost, high-accuracy regimes. Under realistic resource constraints that cannot support large models or dense explorations, however, small language model agents fall into a low-cost, low-accuracy regime, where limited rollout budgets lead to sparse exploration, sparse credit assignment, and unstable training. In this work, we challenge this trade-off and show that small language models can achieve strong multi-hop reasoning under resource constraints. We introduce DAVID-GRPO, a budget-efficient RL framework that (i) stabilizes early learning with minimal supervision, (ii) assigns retrieval credit based on evidence recall, and (iii) improves exploration by resampling truncated near-miss trajectories. Evaluated on agents up to 1.5B parameters trained on only four RTX 3090 GPUs, DAVID-GRPO consistently outperforms prior RL methods designed for large-scale settings on six multi-hop QA benchmarks. These results show that with the right inductive biases, small agents can achieve low training cost with high accuracy.

</details>


### [42] [Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis](https://arxiv.org/abs/2601.21709)
*Qingyue Yang,Jie Wang,Xing Li,Yinqi Bai,Xialiang Tong,Huiling Zhen,Jianye Hao,Mingxuan Yuan,Bin Li*

Main category: cs.CL

TL;DR: TAPPA框架通过时域连续性分析解释多样的注意力模式，将注意力分为可预测和不可预测模式，并应用于KV缓存压缩和LLM剪枝任务。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现了检索头、汇头和对角线追踪等注意力模式，但这些观察是碎片化的，缺乏统一的解释框架。

Method: 提出TAPPA框架，从时域连续性角度分析注意力模式的数学表达，区分可预测和不可预测模式，并通过查询自相似性解释这种差异。

Result: TAPPA不仅加深了对注意力行为的理解，还指导了推理加速方法。在KV缓存压缩和LLM剪枝任务中，基于TAPPA的简单指标能持续提升基线方法的性能。

Conclusion: TAPPA为理解多样注意力模式提供了统一框架，并展示了在实际任务中的应用价值，代码已开源。

Abstract: Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this gap, we introduce \textbf{Temporal Attention Pattern Predictability Analysis (TAPPA), a unifying framework that explains diverse attention patterns by analyzing their underlying mathematical formulations} from a temporally continuous perspective. TAPPA both deepens the understanding of attention behavior and guides inference acceleration approaches. Specifically, TAPPA characterizes attention patterns as predictable patterns with clear regularities and unpredictable patterns that appear effectively random. Our analysis further reveals that this distinction can be explained by the degree of query self-similarity along the temporal dimension. Focusing on the predictable patterns, we further provide a detailed mathematical analysis of three representative cases through the joint effect of queries, keys, and Rotary Positional Embeddings (RoPE). We validate TAPPA by applying its insights to KV cache compression and LLM pruning tasks. Across these tasks, a simple metric motivated by TAPPA consistently improves performance over baseline methods. The code is available at https://github.com/MIRALab-USTC/LLM-TAPPA.

</details>


### [43] [TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning](https://arxiv.org/abs/2601.21711)
*Huiyuan Lai,Malvina Nissim*

Main category: cs.CL

TL;DR: TACLer是一个基于课程强化学习的框架，通过渐进式训练和混合推理模式，在降低计算成本的同时提升LLMs在复杂数学问题上的推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在复杂推理任务中需要大规模RL训练来产生长思维链，但这会导致计算成本高和过度思考的问题。需要一种更高效的学习和推理方法。

Method: 提出TACLer框架，包含两个核心组件：1）定制化课程学习，根据模型能力渐进增加数据复杂度；2）混合Thinking/NoThinking推理范式，平衡准确性和效率。

Result: TACLer在四个数学数据集上表现优异：训练计算成本降低超过50%，推理token使用减少超过42%，同时准确率相比基础模型提升超过9%，优于现有Thinking和NoThinking基线模型。

Conclusion: TACLer通过课程强化学习和混合推理范式，在显著降低计算成本的同时提升了LLMs的推理性能，为高效的大语言模型训练和推理提供了新思路。

Abstract: Large Language Models (LLMs) have shown remarkable performance on complex reasoning tasks, especially when equipped with long chain-of-thought (CoT) reasoning. However, eliciting long CoT typically requires large-scale reinforcement learning (RL) training, while often leading to overthinking with redundant intermediate steps. To improve learning and reasoning efficiency, while preserving or even enhancing performance, we propose TACLer, a model-tailored curriculum reinforcement learning framework that gradually increases the complexity of the data based on the model's proficiency in multi-stage RL training. TACLer features two core components: (i) tailored curriculum learning that determines what knowledge the model lacks and needs to learn in progressive stages; (ii) a hybrid Thinking/NoThinking reasoning paradigm that balances accuracy and efficiency by enabling or disabling the Thinking mode. Our experiments show that TACLer yields a twofold advantage in learning and reasoning: (i) it reduces computational cost, cutting training compute by over 50% compared to long thinking models and reducing inference token usage by over 42% relative to the base model; and (ii) it improves accuracy by over 9% on the base model, consistently outperforming state-of-the-art Nothinking and Thinking baselines across four math datasets with complex problems.

</details>


### [44] [Enhancing Language Models for Robust Greenwashing Detection](https://arxiv.org/abs/2601.21722)
*Neil Heinrich Braun,Keane Ong,Rui Mao,Erik Cambria,Gianmarco Mengaldo*

Main category: cs.CL

TL;DR: 提出一个参数高效框架，通过对比学习和序数排序目标结构化LLM潜在空间，结合门控特征调制和MetaGradNorm优化，提升ESG报告中绿色清洗和模糊声明的检测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前ESG可持续性报告存在绿色清洗和模糊声明问题，现有NLP模型缺乏对这些实践的鲁棒性，通常依赖表层模式且泛化能力差。

Method: 提出参数高效框架：结合对比学习和序数排序目标来结构化LLM潜在空间，捕捉具体行动与模糊声明之间的梯度差异；采用门控特征调制过滤披露噪声；使用MetaGradNorm稳定多目标优化。

Result: 跨类别实验表明，该方法在鲁棒性上优于标准基线方法，同时揭示了表征刚性与泛化能力之间的权衡关系。

Conclusion: 该框架为ESG评估中的绿色清洗检测提供了更可靠的解决方案，通过结构化潜在空间和稳定优化过程，实现了更好的鲁棒性和泛化性能。

Abstract: Sustainability reports are critical for ESG assessment, yet greenwashing and vague claims often undermine their reliability. Existing NLP models lack robustness to these practices, typically relying on surface-level patterns that generalize poorly. We propose a parameter-efficient framework that structures LLM latent spaces by combining contrastive learning with an ordinal ranking objective to capture graded distinctions between concrete actions and ambiguous claims. Our approach incorporates gated feature modulation to filter disclosure noise and utilizes MetaGradNorm to stabilize multi-objective optimization. Experiments in cross-category settings demonstrate superior robustness over standard baselines while revealing a trade-off between representational rigidity and generalization.

</details>


### [45] [Procedural Pretraining: Warming Up Language Models with Abstract Data](https://arxiv.org/abs/2601.21725)
*Liangze Jiang,Zachary Shinnick,Anton van den Hengel,Hemanth Saratchandran,Damien Teney*

Main category: cs.CL

TL;DR: 论文提出了一种名为"程序预训练"的新范式，即先让语言模型接触抽象的结构化数据（如形式语言生成的程序数据），然后再进行自然语言预训练，这种方法能显著提升模型性能和训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型主要在网页规模语料上进行预训练，这类似于人类一开始就接触复杂的语义知识。论文探索一种更符合人类学习过程的替代方案：先学习抽象的结构化数据（类似人类先学习简单逻辑和数学），再获取丰富的语义知识。

Method: 研究采用程序数据进行预训练，这些数据由形式语言和其他简单算法生成。具体方法包括：1）诊断不同形式的程序数据能提升哪些算法技能；2）研究在更大模型（最高13亿参数）上的效果；3）探索程序预训练在注意力层和MLP层中产生的机制；4）探索多种程序数据组合的路径。

Result: 1）程序数据能显著提升特定算法技能，如在Dyck序列（平衡括号）上预训练后，上下文回忆（Needle-in-a-haystack）准确率从10%提升到98%；2）仅添加0.1%的程序数据就能显著优于标准预训练；3）程序预训练能让模型仅用55%、67%、86%的原数据量就达到相同的损失值；4）程序预训练在注意力层和MLP层中注入了非平凡结构。

Conclusion: 程序预训练是一种简单、轻量级的方法，能显著提升语言模型性能并加速预训练过程。这为在大型语言模型中分离知识获取和推理提供了有前景的路径，表明先学习结构化抽象数据再学习自然语言的范式具有重要价值。

Abstract: Pretraining directly on web-scale corpora is the de facto paradigm for building language models. We study an alternative setting where the model is initially exposed to abstract structured data, as a means to ease the subsequent acquisition of rich semantic knowledge, much like humans learn simple logic and mathematics before higher reasoning. We specifically focus on procedural data, generated by formal languages and other simple algorithms, as such abstract data.
  We first diagnose the algorithmic skills that different forms of procedural data can improve, often significantly. For example, on context recall (Needle-in-a-haystack), the accuracy jumps from 10 to 98% when pretraining on Dyck sequences (balanced brackets). Second, we study how these gains are reflected in pretraining larger models (up to 1.3B). We find that front-loading as little as 0.1% procedural data significantly outperforms standard pretraining on natural language, code, and informal mathematics (C4, CodeParrot, and DeepMind-Math datasets). Notably, this procedural pretraining enables the models to reach the same loss value with only 55, 67, 86% of the original data. Third, we explore the mechanisms behind and find that procedural pretraining instils non-trivial structure in both attention and MLP layers. The former is particularly important for structured domains (e.g. code), and the latter for language. Finally, we lay a path for combining multiple forms of procedural data. Our results show that procedural pretraining is a simple, lightweight means to improving performance and accelerating language model pretraining, ultimately suggesting the promise of disentangling knowledge acquisition from reasoning in LLMs.

</details>


### [46] [CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection to Augment LLM Scientific Question Answering](https://arxiv.org/abs/2601.21733)
*Jiayin Lan,Jiaqi Li,Baoxin Wang,Ming Liu,Dayong Wu,Shijin Wang,Bing Qin,Guoping Hu*

Main category: cs.CL

TL;DR: CE-GOCD方法通过构建学术知识图谱的语义子结构来增强LLM的科学问答能力，相比现有方法在多个NLP数据集上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强方法通常依赖孤立的文本块或概念，忽视了论文之间更深层的语义联系，这限制了LLM对科学文献的理解，影响了回答的全面性和特异性。

Method: 提出CE-GOCD方法：1) 以论文标题为中心实体进行目标子图检索；2) 通过子图剪枝和补全增强隐式语义发现；3) 应用社区检测提取具有共享主题的连贯论文组。

Result: 在三个NLP文献问答数据集上的评估表明，该方法优于其他检索增强基线方法，证实了框架的有效性。

Conclusion: 通过显式建模和利用学术知识图谱中的语义子结构，CE-GOCD方法能够有效增强LLM在科学问答中的性能，解决了现有方法忽视深层语义连接的问题。

Abstract: Large Language Models (LLMs) are increasingly used for question answering over scientific research papers. Existing retrieval augmentation methods often rely on isolated text chunks or concepts, but overlook deeper semantic connections between papers. This impairs the LLM's comprehension of scientific literature, hindering the comprehensiveness and specificity of its responses. To address this, we propose Central Entity-Guided Graph Optimization for Community Detection (CE-GOCD), a method that augments LLMs' scientific question answering by explicitly modeling and leveraging semantic substructures within academic knowledge graphs. Our approach operates by: (1) leveraging paper titles as central entities for targeted subgraph retrieval, (2) enhancing implicit semantic discovery via subgraph pruning and completion, and (3) applying community detection to distill coherent paper groups with shared themes. We evaluated the proposed method on three NLP literature-based question-answering datasets, and the results demonstrate its superiority over other retrieval-augmented baseline approaches, confirming the effectiveness of our framework.

</details>


### [47] [Temporal Guidance for Large Language Models](https://arxiv.org/abs/2601.21744)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为Temporal Guidance (TeGu)的新型对比解码方法，通过时间维度进行对比指导，利用多令牌预测构建较弱预测进行自对比，显著提升语言模型生成质量同时保持低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有对比解码方法需要辅助模型，计算开销大；而内部自对比方法（如DoLa）在小型模型上不稳定。作者观察到LLMs具有局部偏好特性，因此提出沿时间维度的对比指导策略。

Method: 提出Temporal Guidance (TeGu)方法，利用多令牌预测构建较弱预测进行模型自对比。设计了轻量级Conditional MTP Projector (cMTPP)来标准化实现，避免维护多个独立网络。

Result: 在各种模型系列和基准测试中，TeGu实现了显著的性能提升，同时保持了低额外内存消耗和计算开销。

Conclusion: TeGu是一种有效的对比解码方法，通过时间维度的对比指导策略，在提升生成质量的同时避免了传统对比解码方法的高计算成本问题。

Abstract: Contrastive Decoding (CD) enhances the generation quality of large language models (LLMs) but incurs significant additional computational overhead due to the need for an auxiliary model. Existing internal self-contrastive decoding methods, such as Decoding by Contrasting Layers (DoLa), focus on discrepancies across different layers, which are notably unstable on small-scale models. In this work, based on the observation that LLMs exhibit local preferences, we propose a novel contrastive guidance strategy along the temporal dimension, namely Temporal Guidance (TeGu). Our method ingeniously leverages Multi-Token Prediction (MTP) to construct weaker amateur predictions for model self-contrast. To standardize the implementation of this mechanism, we further introduce a lightweight Conditional MTP Projector (cMTPP), which avoids maintaining multiple independent networks as required by other MTP modules. Across various model series and benchmarks, TeGu achieves significant performance improvements while maintaining low additional memory consumption and computational overhead.

</details>


### [48] [CoFrGeNet: Continued Fraction Architectures for Language Generation](https://arxiv.org/abs/2601.21766)
*Amit Dhurandhar,Vijil Chenthamarakshan,Dennis Wei,Tejaswini Pedapati,Karthikeyan Natesan Ramamurthy,Rahul Nair*

Main category: cs.CL

TL;DR: 基于连分数思想提出CoFrGeNets架构，可替代Transformer中的多头注意力和前馈网络，参数量减少1/3到1/2，训练时间更短，性能相当或更优。


<details>
  <summary>Details</summary>
Motivation: Transformer是目前语言生成的首选架构，但参数量大、计算成本高。受连分数启发，希望设计更高效的生成模型架构，减少参数量同时保持性能。

Method: 1. 基于连分数理论提出新的生成函数类；2. 设计CoFrGeNets架构组件替代多头注意力和前馈网络；3. 推导自定义梯度公式，比PyTorch标准梯度更准确高效；4. 实现即插即用替换，无需大幅修改训练推理流程。

Result: 在GPT2-xl（1.5B）和Llama3（3.2B）上实验，参数量减少2/3到1/2，预训练时间更短。在下游分类、问答、推理和文本理解任务上，性能与原模型相当甚至更优。

Conclusion: CoFrGeNets提供了一种高效的Transformer替代方案，参数量显著减少且性能保持。未来针对硬件定制化实现将进一步提升其潜力，易于集成到工业级工作流中。

Abstract: Transformers are arguably the preferred architecture for language generation. In this paper, inspired by continued fractions, we introduce a new function class for generative modeling. The architecture family implementing this function class is named CoFrGeNets - Continued Fraction Generative Networks. We design novel architectural components based on this function class that can replace Multi-head Attention and Feed-Forward Networks in Transformer blocks while requiring much fewer parameters. We derive custom gradient formulations to optimize the proposed components more accurately and efficiently than using standard PyTorch-based gradients. Our components are a plug-in replacement requiring little change in training or inference procedures that have already been put in place for Transformer-based models thus making our approach easy to incorporate in large industrial workflows. We experiment on two very different transformer architectures GPT2-xl (1.5B) and Llama3 (3.2B), where the former we pre-train on OpenWebText and GneissWeb, while the latter we pre-train on the docling data mix which consists of nine different datasets. Results show that the performance on downstream classification, Q\& A, reasoning and text understanding tasks of our models is competitive and sometimes even superior to the original models with $\frac{2}{3}$ to $\frac{1}{2}$ the parameters and shorter pre-training time. We believe that future implementations customized to hardware will further bring out the true potential of our architectures.

</details>


### [49] [Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond](https://arxiv.org/abs/2601.21767)
*Wei Zhu*

Main category: cs.CL

TL;DR: ChatGPT在医学信息抽取任务上表现不及微调基线模型，但能提供高质量解释，不过存在过度自信问题


<details>
  <summary>Details</summary>
Motivation: 评估ChatGPT在医学信息抽取任务中的综合能力，包括性能、可解释性、置信度、忠实度和不确定性等方面

Method: 系统分析ChatGPT在4个不同医学信息抽取任务上的表现，使用6个基准数据集，测量性能、可解释性、置信度、忠实度和不确定性

Result: 1) ChatGPT在MedIE任务上的性能得分低于微调基线模型；2) ChatGPT能提供高质量解释但过度自信；3) 在多数情况下对原始文本保持高度忠实度；4) 生成的不确定性导致信息抽取结果不确定，可能阻碍其在MedIE任务中的应用

Conclusion: ChatGPT在医学信息抽取任务上虽有高质量解释能力，但性能不及专门微调模型，且存在过度自信和不确定性问题，限制了其在专业医学领域的应用

Abstract: Large Language Models (LLMs) like ChatGPT have demonstrated amazing capabilities in comprehending user intents and generate reasonable and useful responses. Beside their ability to chat, their capabilities in various natural language processing (NLP) tasks are of interest to the research community. In this paper, we focus on assessing the overall ability of ChatGPT in 4 different medical information extraction (MedIE) tasks across 6 benchmark datasets. We present the systematically analysis by measuring ChatGPT's performance, explainability, confidence, faithfulness, and uncertainty. Our experiments reveal that: (a) ChatGPT's performance scores on MedIE tasks fall behind those of the fine-tuned baseline models. (b) ChatGPT can provide high-quality explanations for its decisions, however, ChatGPT is over-confident in its predcitions. (c) ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. (d) The uncertainty in generation causes uncertainty in information extraction results, thus may hinder its applications in MedIE tasks.

</details>


### [50] [Zonkey: A Hierarchical Diffusion Language Model with Differentiable Tokenization and Probabilistic Attention](https://arxiv.org/abs/2601.21768)
*Alon Rozental*

Main category: cs.CL

TL;DR: Zonkey：一种分层扩散模型，通过完全可训练的字符到文档表示管道，解决了传统LLM固定分词器的限制，实现了端到端优化和自适应分割。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型受限于固定的、不可微的分词器（如BPE），这阻碍了端到端优化，难以适应噪声或领域特定数据。需要一种完全可训练的文本生成方法。

Method: 1. 可微分分词器（Segment Splitter）学习概率性序列开始决策；2. 概率注意力机制支持理论上无限序列的软掩码；3. 分层压缩：字符n-gram到词向量再到句子级别；4. 去噪扩散混合模型（DDMM）在潜在空间进行稳定去噪；5. Stitcher确保跨片段重叠不变性。

Result: 在Wikipedia上端到端训练后，Zonkey能够从噪声生成连贯、可变长度的文本，展现出涌现的分层结构，与基于熵的可学习分词器相比，在数据分布对齐方面表现更好。

Conclusion: Zonkey为完全基于梯度的LLM开辟了新方向，具有更好的领域适应性和可扩展生成潜力，推动了端到端可训练语言模型的发展。

Abstract: Large language models (LLMs) have revolutionized natural language processing, yet they remain constrained by fixed, non-differentiable tokenizers like Byte Pair Encoding (BPE), which hinder end-to-end optimization and adaptability to noisy or domain-specific data. We introduce Zonkey, a hierarchical diffusion model that addresses these limitations through a fully trainable pipeline from raw characters to document-level representations. At its core is a differentiable tokenizer (Segment Splitter) that learns probabilistic beginning-of-sequence (BOS) decisions, enabling adaptive splits that emerge as linguistically meaningful (e.g., word boundaries at spaces, sentence starts at periods) without explicit supervision. This differentiability is enabled by our novel Probabilistic Attention mechanism, which incorporates position-specific existence probabilities to simulate soft masking over theoretically infinite sequences while preserving gradients. Sequences decay probabilistically rather than relying on end-of-sequence tokens, supporting variable-length outputs. Hierarchical levels compress sequences into higher abstractions (e.g., character n-grams to word-like vectors, then sentence-like), with reconstruction via our Denoising Diffusion Mixed Model (DDMM) for stable and efficient denoising in latent space. A Stitcher ensures overlap invariance across segments. Trained end-to-end on Wikipedia, Zonkey generates coherent, variable-length text from noise, demonstrating emergent hierarchies and promising qualitative alignment to data distributions compared to entropy-based learnable tokenizers. Our approach advances toward fully gradient-based LLMs, with potential for better domain adaptation and scalable generation. We release the source code for training and reproducing our experiments.

</details>


### [51] [KID: Knowledge-Injected Dual-Head Learning for Knowledge-Grounded Harmful Meme Detection](https://arxiv.org/abs/2601.21796)
*Yaocong Li,Leihan Zhang,Le Zhang,Qiang Yan*

Main category: cs.CL

TL;DR: KID是一个知识注入的双头学习框架，通过标签约束蒸馏和结构化推理链，结合外部知识来检测有害网络迷因，在多语言数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 网络迷因作为数字文化载体，其隐喻性和社会文化依赖性使其成为有害内容的隐蔽传播工具。现有方法主要关注模态内和模态间信号分析，但隐含毒性的理解往往依赖于迷因本身未明确呈现的背景知识。

Method: 提出KID框架：1）采用标签约束蒸馏范式，将复杂迷因理解分解为结构化推理链，明确连接视觉证据、背景知识和分类标签；2）使用双头架构联合优化语义生成和分类目标，实现对齐的语言推理和稳定的决策边界。

Result: 在英语、中文和低资源孟加拉语的五个多语言数据集上，KID在二元和多标签有害迷因检测任务上均达到SOTA性能，相比先前最佳方法提升2.1%-19.7%。消融研究证实了知识注入和双头联合学习的有效性。

Conclusion: KID通过知识注入和结构化推理，有效解决了有害迷因检测中背景知识依赖的挑战，为稳健且可泛化的迷因理解提供了有效框架。

Abstract: Internet memes have become pervasive carriers of digital culture on social platforms. However, their heavy reliance on metaphors and sociocultural context also makes them subtle vehicles for harmful content, posing significant challenges for automated content moderation. Existing approaches primarily focus on intra-modal and inter-modal signal analysis, while the understanding of implicit toxicity often depends on background knowledge that is not explicitly present in the meme itself. To address this challenge, we propose KID, a Knowledge-Injected Dual-Head Learning framework for knowledge-grounded harmful meme detection. KID adopts a label-constrained distillation paradigm to decompose complex meme understanding into structured reasoning chains that explicitly link visual evidence, background knowledge, and classification labels. These chains guide the learning process by grounding external knowledge in meme-specific contexts. In addition, KID employs a dual-head architecture that jointly optimizes semantic generation and classification objectives, enabling aligned linguistic reasoning while maintaining stable decision boundaries. Extensive experiments on five multilingual datasets spanning English, Chinese, and low-resource Bengali demonstrate that KID achieves SOTA performance on both binary and multi-label harmful meme detection tasks, improving over previous best methods by 2.1%--19.7% across primary evaluation metrics. Ablation studies further confirm the effectiveness of knowledge injection and dual-head joint learning, highlighting their complementary contributions to robust and generalizable meme understanding. The code and data are available at https://github.com/PotatoDog1669/KID.

</details>


### [52] [Enhancing Conversational Agents via Task-Oriented Adversarial Memory Adaptation](https://arxiv.org/abs/2601.21797)
*Yimin Deng,Yuqing Fu,Derong Xu,Yejing Wang,Wei Ni,Jingtong Gao,Xiaopeng Li,Chengxu Liu,Xiao Han,Guoshuai Zhao,Xiangyu Zhao,Li Zhu,Xueming Qian*

Main category: cs.CL

TL;DR: 提出对抗性记忆适应机制(AMA)，通过在离线阶段模拟任务执行来对齐记忆构建与更新，解决现有记忆系统离线阶段与任务需求不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有对话记忆系统离线阶段的记忆构建和更新是固定的、任务无关的，使用预定义流程和通用指标，导致与下游任务需求不匹配，影响任务性能。

Method: 提出AMA机制：1)挑战者代理基于原始对话生成问答对；2)使用构建的记忆回答这些问题，模拟下游推理；3)评估者代理评估响应并进行错误分析；4)适配器代理分析错误案例，对构建策略和内容进行双重更新。

Result: 在长对话基准LoCoMo上进行广泛实验，证明AMA的有效性。AMA可以集成到各种现有记忆系统中。

Conclusion: AMA通过在离线阶段提供任务感知的监督信号，增强了记忆系统对下游任务的适应性，解决了现有记忆系统离线阶段与任务需求不匹配的问题。

Abstract: Conversational agents struggle to handle long conversations due to context window limitations. Therefore, memory systems are developed to leverage essential historical information. Existing memory systems typically follow a pipeline of offline memory construction and update, and online retrieval. Despite the flexible online phase, the offline phase remains fixed and task-independent. In this phase, memory construction operates under a predefined workflow and fails to emphasize task relevant information. Meanwhile, memory updates are guided by generic metrics rather than task specific supervision. This leads to a misalignment between offline memory preparation and task requirements, which undermines downstream task performance. To this end, we propose an Adversarial Memory Adaptation mechanism (AMA) that aligns memory construction and update with task objectives by simulating task execution. Specifically, first, a challenger agent generates question answer pairs based on the original dialogues. The constructed memory is then used to answer these questions, simulating downstream inference. Subsequently, an evaluator agent assesses the responses and performs error analysis. Finally, an adapter agent analyzes the error cases and performs dual level updates on both the construction strategy and the content. Through this process, the memory system receives task aware supervision signals in advance during the offline phase, enhancing its adaptability to downstream tasks. AMA can be integrated into various existing memory systems, and extensive experiments on long dialogue benchmark LoCoMo demonstrate its effectiveness.

</details>


### [53] [RAG-E: Quantifying Retriever-Generator Alignment and Failure Modes](https://arxiv.org/abs/2601.21803)
*Korbinian Randl,Guido Rocchietti,Aron Henriksson,Ziawasch Abedjan,Tony Lindgren,John Pavlopoulos*

Main category: cs.CL

TL;DR: RAG-E是一个端到端的可解释性框架，通过数学基础的归因方法量化检索器与生成器之间的对齐程度，揭示RAG系统中关键的对齐失败问题。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统结合了密集检索器和语言模型，但组件间交互的不透明性给高风险领域部署带来挑战，需要量化评估检索器与生成器的对齐程度。

Method: 提出RAG-E框架：1）采用集成梯度方法分析检索器；2）引入PMCSHAP（蒙特卡洛稳定Shapley值近似）进行生成器归因；3）提出WARG（加权归因-相关性差距）度量生成器文档使用与检索器排名的对齐程度。

Result: 在TREC CAsT和FoodSafeSum数据集上的实证分析发现：47.4%-66.7%的查询中，生成器忽略检索器排名最高的文档；48.1%-65.9%的查询中，生成器依赖相关性较低的文档。这些失败模式表明RAG输出质量不仅取决于单个组件性能，更取决于它们的交互。

Conclusion: RAG输出质量取决于检索器与生成器之间的交互对齐，而非仅组件单独性能。RAG-E框架能够审计这种交互，为RAG系统的可解释性和部署提供了重要工具。

Abstract: Retrieval-Augmented Generation (RAG) systems combine dense retrievers and language models to ground LLM outputs in retrieved documents. However, the opacity of how these components interact creates challenges for deployment in high-stakes domains. We present RAG-E, an end-to-end explainability framework that quantifies retriever-generator alignment through mathematically grounded attribution methods. Our approach adapts Integrated Gradients for retriever analysis, introduces PMCSHAP, a Monte Carlo-stabilized Shapley Value approximation, for generator attribution, and introduces the Weighted Attribution-Relevance Gap (WARG) metric to measure how well a generator's document usage aligns with a retriever's ranking. Empirical analysis on TREC CAsT and FoodSafeSum reveals critical misalignments: for 47.4% to 66.7% of queries, generators ignore the retriever's top-ranked documents, while 48.1% to 65.9% rely on documents ranked as less relevant. These failure modes demonstrate that RAG output quality depends not solely on individual component performance but on their interplay, which can be audited via RAG-E.

</details>


### [54] [Distribution-Aware Reward Estimation for Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.21804)
*Bodong Du,Xuanqi Huang,Xiaomeng Li*

Main category: cs.CL

TL;DR: DARE提出一种基于完整经验分布而非多数投票的奖励估计方法，通过探索奖励和分布剪枝机制提升TTRL的优化稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于多数投票的TTRL方法将rollout分布简化为单一结果，丢弃了非多数但正确的行动候选信息，导致系统性的奖励估计偏差。

Method: 提出Distribution-Aware Reward Estimation (DARE)，将奖励估计从单一多数结果转向完整经验分布，并加入探索奖励和分布剪枝机制来探索非多数rollout并降噪。

Result: 在具有挑战性的推理基准测试中，DARE相比现有基线提升了优化稳定性和最终性能，在AIME 2024上实现25.3%的相对提升，在AMC上实现5.3%的相对提升。

Conclusion: 基于完整经验分布的奖励估计比多数投票方法更有效，DARE通过分布感知的奖励估计显著提升了TTRL的性能和稳定性。

Abstract: Test-time reinforcement learning (TTRL) enables large language models (LLMs) to self-improve on unlabeled inputs, but its effectiveness critically depends on how reward signals are estimated without ground-truth supervision. Most existing TTRL methods rely on majority voting (MV) over rollouts to produce deterministic rewards, implicitly assuming that the majority rollout provides a reliable learning signal. We show that this assumption is fragile: MV reduces the rollout distribution into a single outcome, discarding information about non-majority but correct actions candidates, and yields systematically biased reward estimates. To address this, we propose Distribution-AwareReward Estimation (DARE), which shifts reward estimation from a single majority outcome to the full empirical rollout distribution. DARE further augments this distribution-based reward with an exploration bonus and a distribution pruning mechanism for non-majority rollout exploration and reward denoise, yielding a more informative and robust reward estimation. Extensive experiments on challenging reasoning benchmarks show that DARE improves optimization stability and final performance over recent baselines, achieving relative improvements of 25.3% on challenging AIME 2024 and 5.3% on AMC.

</details>


### [55] [Mil-SCORE: Benchmarking Long-Context Geospatial Reasoning and Planning in Large Language Models](https://arxiv.org/abs/2601.21826)
*Aadi Palnitkar,Mingyang Mao,Nicholas Waytowich,Vinicius G. Goecks,Tinoosh Mohsenin,Xiaomin Lin*

Main category: cs.CL

TL;DR: MilSCORE是一个基于军事规划场景的专家编写的多跳问题数据集，用于评估大语言模型在长上下文、多模态信息整合和地理空间推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型需要处理越来越长和复杂的任务，但缺乏需要选择性阅读和整合异构多模态信息的现实长上下文基准测试。军事规划等地理空间问题特别需要快速准确推理地图、命令、情报报告等分布式数据。

Method: 提出了MilSCORE数据集，这是首个基于复杂模拟军事规划场景的专家编写的场景级多跳问题数据集。数据集包含七个类别的多样化问题类型，涵盖事实回忆和多步推理，并提供了评估协议和多种当代视觉语言模型的基线结果。

Result: 基线结果显示当前系统在MilSCORE上表现不佳，表明现有模型在现实的场景级长上下文规划任务上存在困难，MilSCORE成为未来工作的挑战性测试平台。

Conclusion: MilSCORE填补了长上下文基准测试的空白，为评估大语言模型在复杂、多模态、地理空间丰富的规划任务中的能力提供了重要工具，揭示了当前系统的局限性并为未来研究指明了方向。

Abstract: As large language models (LLMs) are applied to increasingly longer and more complex tasks, there is a growing need for realistic long-context benchmarks that require selective reading and integration of heterogeneous, multi-modal information sources. This need is especially acute for geospatial planning problems, such as those found in planning for large-scale military operations, which demand fast and accurate reasoning over maps, orders, intelligence reports, and other distributed data. To address this gap, we present MilSCORE (Military Scenario Contextual Reasoning), to our knowledge the first scenario-level dataset of expert-authored, multi-hop questions grounded in a complex, simulated military planning scenario used for training. MilSCORE is designed to evaluate high-stakes decision-making and planning, probing LLMs' ability to combine tactical and spatial reasoning across multiple sources and to reason over long-horizon, geospatially rich context. The benchmark includes a diverse set of question types across seven categories targeting both factual recall and multi-step reasoning about constraints, strategy, and spatial analysis. We provide an evaluation protocol and report baseline results for a range of contemporary vision-language models. Our findings highlight substantial headroom on MilSCORE, indicating that current systems struggle with realistic, scenario-level long-context planning, and positioning MilSCORE as a challenging testbed for future work.

</details>


### [56] [Embodied Task Planning via Graph-Informed Action Generation with Large Lanaguage Model](https://arxiv.org/abs/2601.21841)
*Xiang Li,Ning Yan,Masood Mortazavi*

Main category: cs.CL

TL;DR: GiG框架使用图内图架构组织记忆，通过GNN编码环境状态，利用聚类检索结构先验，结合符号化前瞻模块提升具身智能体在长时程规划中的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在零样本推理方面表现强劲，但作为具身智能体在长时程规划中面临挑战。标准LLM规划器常因上下文窗口限制在扩展时程中丧失策略连贯性，或产生违反约束的幻觉转换。

Method: 提出GiG框架，采用图内图架构组织智能体记忆：使用GNN将环境状态编码为嵌入，组织成动作连接的执行轨迹图存入经验记忆库。通过聚类这些图嵌入实现结构感知先验检索，使智能体能够基于相关历史结构模式进行决策。还引入有界前瞻模块，利用符号化转换逻辑通过接地动作投影增强规划能力。

Result: 在三个具身规划基准测试（Robotouille Synchronous、Robotouille Asynchronous和ALFWorld）上评估，方法优于现有基线，在Robotouille Synchronous上Pass@1性能提升达22%，Asynchronous上37%，ALFWorld上15%，且计算成本相当或更低。

Conclusion: GiF框架通过结构化的图内图记忆组织和符号化前瞻，有效解决了LLM具身智能体在长时程规划中的策略连贯性和约束遵守问题，显著提升了规划性能。

Abstract: While Large Language Models (LLMs) have demonstrated strong zero-shot reasoning capabilities, their deployment as embodied agents still faces fundamental challenges in long-horizon planning. Unlike open-ended text generation, embodied agents must decompose high-level intent into actionable sub-goals while strictly adhering to the logic of a dynamic, observed environment. Standard LLM planners frequently fail to maintain strategy coherence over extended horizons due to context window limitation or hallucinate transitions that violate constraints. We propose GiG, a novel planning framework that structures embodied agents' memory using a Graph-in-Graph architecture. Our approach employs a Graph Neural Network (GNN) to encode environmental states into embeddings, organizing these embeddings into action-connected execution trace graphs within an experience memory bank. By clustering these graph embeddings, the framework enables retrieval of structure-aware priors, allowing agents to ground current decisions in relevant past structural patterns. Furthermore, we introduce a novel bounded lookahead module that leverages symbolic transition logic to enhance the agents' planning capabilities through the grounded action projection. We evaluate our framework on three embodied planning benchmarks-Robotouille Synchronous, Robotouille Asynchronous, and ALFWorld. Our method outperforms state-of-the-art baselines, achieving Pass@1 performance gains of up to 22% on Robotouille Synchronous, 37% on Asynchronous, and 15% on ALFWorld with comparable or lower computational cost.

</details>


### [57] [Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text](https://arxiv.org/abs/2601.21895)
*Hongyi Zhou,Jin Zhu,Erhan Xu,Kai Ye,Ying Yang,Chengchun Shi*

Main category: cs.CL

TL;DR: 本文提出一种基于几何视角理解重写检测算法的新方法，并在此基础上开发了一种自适应学习距离函数的检测算法，在多种LLM检测场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成高度拟人化文本引发了关于错误信息和学术诚信的严重担忧，迫切需要可靠的算法来检测LLM生成内容。

Method: 首先提出几何方法来解释基于重写的检测算法，揭示其基本原理并展示其泛化能力。在此基础上，引入一种新颖的基于重写的检测算法，能够自适应学习原始文本与重写文本之间的距离。

Result: 理论证明自适应学习距离函数比固定距离更有效。在超过100种实验设置中，该方法在大多数场景下优于基线算法，相对于最强基线实现了57.8%到80.6%的相对改进。

Conclusion: 该研究通过几何视角深入理解了重写检测算法，提出的自适应距离学习方法在检测LLM生成内容方面表现出显著优势，为解决AI生成内容检测问题提供了有效方案。

Abstract: Modern large language models (LLMs) such as GPT, Claude, and Gemini have transformed the way we learn, work, and communicate. Yet, their ability to produce highly human-like text raises serious concerns about misinformation and academic integrity, making it an urgent need for reliable algorithms to detect LLM-generated content. In this paper, we start by presenting a geometric approach to demystify rewrite-based detection algorithms, revealing their underlying rationale and demonstrating their generalization ability. Building on this insight, we introduce a novel rewrite-based detection algorithm that adaptively learns the distance between the original and rewritten text. Theoretically, we demonstrate that employing an adaptively learned distance function is more effective for detection than using a fixed distance. Empirically, we conduct extensive experiments with over 100 settings, and find that our approach demonstrates superior performance over baseline algorithms in the majority of scenarios. In particular, it achieves relative improvements from 57.8\% to 80.6\% over the strongest baseline across different target LLMs (e.g., GPT, Claude, and Gemini).

</details>


### [58] [SONIC: Segmented Optimized Nexus for Information Compression in Key-Value Caching](https://arxiv.org/abs/2601.21927)
*Hong Chen,Xiang Liu,Bo Wang,Yuxuan Fan,Yuanlin Chu,Zongluo Li,Xiaowen Chu,Xuming Hu*

Main category: cs.CL

TL;DR: SONIC是一个基于学习的KV缓存压缩框架，通过将历史对话段压缩为紧凑的Nexus令牌来优化多轮对话部署，支持动态预算训练以适应不同内存约束，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多轮对话部署中KV缓存的线性增长是主要瓶颈，现有压缩方法未能充分考虑多轮对话的结构特性，依赖启发式驱逐策略可能导致关键上下文丢失。

Method: 提出SONIC学习框架，将历史对话段压缩为紧凑且语义丰富的Nexus令牌，采用动态预算训练使模型能灵活适应不同内存约束而无需重新训练。

Result: 在80%和50%压缩率下，SONIC在四个多轮对话基准测试中持续优于H2O和StreamingLLM等基线方法。在MTBench101基准上，平均得分比最先进基线提升35.55%，同时将整体推理过程加速50.1%。

Conclusion: SONIC通过基于学习的KV缓存压缩有效解决了多轮对话部署中的内存瓶颈问题，在保持对话连贯性的同时显著提升了推理效率，为实际部署提供了实用解决方案。

Abstract: The linear growth of Key-Value (KV) cache remains a bottleneck for multi-turn LLM deployment. Existing KV cache compression methods often fail to account for the structural properties of multi-turn dialogues, relying on heuristic eviction that risks losing critical context. We propose \textbf{SONIC}, a learning-based framework that compresses historical segments into compact and semantically rich \textbf{Nexus} tokens. By integrating dynamic budget training, SONIC allows flexible adaptation to varying memory constraints without retraining. Experiments show that at compression ratios of 80\% and 50\%, SONIC consistently outperforms baselines such as H2O and StreamingLLM on four diverse multi-turn benchmarks. Specifically, on the widely used MTBench101 benchmark, SONIC achieves an average score improvement of 35.55\% over state-of-the-art baselines, validating its effectiveness in sustaining coherent multi-turn dialogues. Furthermore, SONIC enhances deployment efficiency, accelerating the overall inference process by 50.1\% compared to full-context generation.

</details>


### [59] [From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes](https://arxiv.org/abs/2601.21955)
*Fariba Afrin Irany*

Main category: cs.CL

TL;DR: 提出一种基于GPT的选择性微调架构，用于临床文本分类，通过冻结大部分预训练参数，仅微调最后层，显著减少计算成本，在MIMIC-IV-Note数据集上表现良好。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中非结构化临床叙述的增加为疾病表征、队列识别和临床决策支持提供了新机会，但建模长领域特定临床文本面临标注数据有限、类别严重不平衡以及预训练大模型计算成本高的挑战。

Method: 提出基于GPT的临床文本分类架构，采用选择性微调策略：冻结GPT-2主干的大部分参数，仅训练最后的Transformer块、最后的层归一化和轻量级分类头，大幅减少可训练参数。

Result: 在MIMIC-IV-Note放射学报告数据集上评估，使用不确定性感知的CheXpert风格标签。模型在不同问题设置下（多标签分类、二元分类、疾病结果预测）均表现稳定，尤其在非提及和否定发现占主导的场景中分类性能强。

Conclusion: 选择性微调预训练生成语言模型为临床文本分类提供了高效有效的途径，能够在显著降低计算复杂度的同时，实现对真实世界电子健康记录数据的可扩展适应。

Abstract: The increasing availability of unstructured clinical narratives in electronic health records (EHRs) has created new opportunities for automated disease characterization, cohort identification, and clinical decision support. However, modeling long, domain-specific clinical text remains challenging due to limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.
  This study presents a GPT-based architecture for clinical text classification that adapts a pretrained decoder-only Transformer using a selective fine-tuning strategy. Rather than updating all model parameters, the majority of the GPT-2 backbone is frozen, and training is restricted to the final Transformer block, the final layer normalization, and a lightweight classification head. This approach substantially reduces the number of trainable parameters while preserving the representational capacity required to model complex clinical language.
  The proposed method is evaluated on radiology reports from the MIMIC-IV-Note dataset using uncertainty-aware CheXpert-style labels derived directly from report text. Experiments cover multiple problem formulations, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction. Across varying dataset sizes, the model exhibits stable convergence behavior and strong classification performance, particularly in settings dominated by non-mention and negated findings.
  Overall, the results indicate that selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification, enabling scalable adaptation to real-world EHR data while significantly reducing computational complexity.

</details>


### [60] [OVD: On-policy Verbal Distillation](https://arxiv.org/abs/2601.21968)
*Jing Xiong,Hui Shen,Shansan Gong,Yuxin Cheng,Jianghan Shen,Chaofan Tao,Haochen Tan,Haoli Bai,Lifeng Shang,Ngai Wong*

Main category: cs.CL

TL;DR: OVD是一种基于轨迹匹配和离散语言评分的在线知识蒸馏框架，显著降低了内存消耗，避免了词元级对齐限制，在问答和数学推理任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有词元级在线蒸馏方法需要学生模型与教师模型进行词元级对齐，这限制了学生模型的探索能力，无法有效利用交互环境反馈，并且在强化学习中存在严重的内存瓶颈。

Method: 提出On-policy Verbal Distillation (OVD)框架，用基于教师模型离散语言评分（0-9）的轨迹匹配替代词元级概率匹配，避免词元级对齐，允许学生模型自由探索输出空间。

Result: 在Web问答和数学推理任务上的实验显示，OVD显著优于现有方法：在Web Q&A任务上平均EM提升高达+12.9%，在数学基准测试上提升高达+25.7%（仅使用一个随机样本训练），同时展现出更优的训练效率。

Conclusion: OVD是一种内存高效的在线知识蒸馏框架，通过轨迹匹配和离散语言评分解决了现有方法的限制，在推理任务上取得了显著性能提升，为高效知识蒸馏提供了新方向。

Abstract: Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io

</details>


### [61] [Token-Guard: Towards Token-Level Hallucination Control via Self-Checking Decoding](https://arxiv.org/abs/2601.21969)
*Yifan Zhu,Huiqiang Rong,Haoran Luo*

Main category: cs.CL

TL;DR: Token-Guard：一种基于自检解码的token级幻觉控制方法，通过内部验证、潜在空间评估和迭代剪枝再生来减少LLM幻觉


<details>
  <summary>Details</summary>
Motivation: 现有方法如RAG和RLHF需要大量资源，而基于解码的方法缺乏明确的幻觉控制。需要一种轻量级但有效的幻觉控制方法。

Method: Token-Guard在推理的每个步骤进行内部验证，在潜在空间中评估候选片段并给出幻觉风险评分，通过迭代剪枝和再生动态纠正检测到的错误。

Result: 在HALU数据集上的实验表明，Token-Guard显著减少了幻觉并提高了生成准确性。

Conclusion: Token-Guard提供了一个可扩展、模块化的解决方案，用于实现可靠的LLM输出，无需资源密集型检索或大规模微调。

Abstract: Large Language Models (LLMs) often hallucinate, generating content inconsistent with the input. Retrieval-Augmented Generation (RAG) and Reinforcement Learning with Human Feedback (RLHF) can mitigate hallucinations but require resource-intensive retrieval or large-scale fine-tuning. Decoding-based methods are lighter yet lack explicit hallucination control. To address this, we present Token-Guard, a token-level hallucination control method based on self-checking decoding. Token-Guard performs internal verification at each reasoning step to detect hallucinated tokens before they propagate. Candidate fragments are further evaluated in a latent space with explicit hallucination risk scoring, while iterative pruning and regeneration dynamically correct detected errors. Experiments on HALU datasets show Token-Guard substantially reduces hallucinations and improves generation accuracy, offering a scalable, modular solution for reliable LLM outputs. Our code is publicly available.

</details>


### [62] [Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units](https://arxiv.org/abs/2601.21996)
*Jianhui Chen,Yuzhang Luo,Liangming Pan*

Main category: cs.CL

TL;DR: 提出MDA框架，通过影响函数将可解释单元溯源到训练数据，验证了针对性干预能调控可解释头部的形成，发现重复结构性数据是机制催化剂，并建立了归纳头与上下文学习之间的因果联系。


<details>
  <summary>Details</summary>
Motivation: 虽然机制可解释性研究已识别出LLM中的可解释电路，但这些电路在训练数据中的因果起源仍然难以捉摸。需要建立训练数据与模型内部机制之间的因果联系。

Method: 引入机制数据归因（MDA）框架，利用影响函数将可解释单元溯源到特定训练样本。在Pythia模型家族上进行广泛实验，通过针对性干预（移除或增强高影响样本）验证因果关系，同时进行随机干预作为对照。

Result: 针对性干预能显著调控可解释头部的形成，而随机干预无效果。发现重复结构性数据（如LaTeX、XML）是机制催化剂。干预归纳头形成会同时改变模型的上下文学习能力，为归纳头与ICL的功能联系提供了直接因果证据。提出的机制数据增强管道能加速电路收敛。

Conclusion: MDA框架成功建立了训练数据与模型内部机制之间的因果联系，为理解LLM学习过程提供了新视角，并提供了引导LLM发展轨迹的原则性方法。

Abstract: While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.

</details>


### [63] [Causal Autoregressive Diffusion Language Model](https://arxiv.org/abs/2601.22031)
*Junhao Ruan,Bei Li,Yongjing Yin,Pengcheng Huang,Xin Chen,Jingang Wang,Xunliang Cai,Tong Xiao,JingBo Zhu*

Main category: cs.CL

TL;DR: CARD是一个结合自回归模型训练效率和扩散模型高吞吐推理的新框架，通过因果注意力掩码实现密集的单前向传播监督，支持动态并行解码。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归模型（ARMs）训练效率高但推理延迟高，而扩散模型推理吞吐高但训练复杂。需要一种既能保持ARM数据效率又能实现并行生成优势的方法。

Method: 1. 在严格因果注意力掩码下重新制定扩散过程，实现单前向传播的密集逐令牌监督。2. 引入软尾掩码方案保留局部上下文。3. 基于信噪比原理设计上下文感知重加权机制。4. 利用KV缓存实现自适应变长令牌序列的动态并行解码。

Result: CARD在性能上优于现有离散扩散基线，训练延迟相比块扩散方法降低3倍，实现了ARM级别的数据效率同时获得了并行生成的延迟优势。

Conclusion: CARD建立了一个稳健的下一代高效LLM范式，成功统一了ARM的训练效率和扩散模型的推理优势，为高效语言模型提供了新的解决方案。

Abstract: In this work, we propose Causal Autoregressive Diffusion (CARD), a novel framework that unifies the training efficiency of ARMs with the high-throughput inference of diffusion models. CARD reformulates the diffusion process within a strictly causal attention mask, enabling dense, per-token supervision in a single forward pass. To address the optimization instability of causal diffusion, we introduce a soft-tailed masking schema to preserve local context and a context-aware reweighting mechanism derived from signal-to-noise principles. This design enables dynamic parallel decoding, where the model leverages KV-caching to adaptively generate variable-length token sequences based on confidence. Empirically, CARD outperforms existing discrete diffusion baselines while reducing training latency by 3 $\times$ compared to block diffusion methods. Our results demonstrate that CARD achieves ARM-level data efficiency while unlocking the latency benefits of parallel generation, establishing a robust paradigm for next-generation efficient LLMs.

</details>


### [64] [Thinking Out of Order: When Output Order Stops Reflecting Reasoning Order in Diffusion Language Models](https://arxiv.org/abs/2601.22035)
*Longxuan Yu,Yu Fu,Shaorong Zhang,Hui Liu,Mukund Varma T,Greg Ver Steeg,Yue Dong*

Main category: cs.CL

TL;DR: MDLMs通过并行迭代优化解决AR模型在输出顺序与自然推理顺序冲突时的性能下降问题，表现出"顺序鲁棒性"特性


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型强制固定从左到右的生成顺序，当所需输出结构与自然推理顺序冲突时（如因呈现或模式约束需要先输出答案后提供解释），会造成基本限制。AR模型必须在生成中间推理之前就承诺答案，这种刚性约束导致过早承诺。

Method: 研究使用掩码扩散语言模型（MDLMs），这种模型可以并行迭代优化所有token，从而将计算顺序与输出结构解耦。在GSM8K、Math500和作者提出的ReasonOrderQA基准上进行验证，ReasonOrderQA具有可控难度和顺序级别评估。

Result: 当提示要求先输出答案后提供推理时，AR模型相比标准思维链顺序表现出巨大的准确率差距（相对下降高达67%），而MDLMs保持稳定（相对下降≤14%），这种特性被称为"顺序鲁棒性"。通过ReasonOrderQA发现，MDLMs通过使简单token（如推理步骤）比复杂token（如最终答案）在扩散过程中更早稳定，从而实现推理token在答案承诺前稳定。

Conclusion: MDLMs通过并行迭代优化解决了AR模型在输出顺序与自然推理顺序冲突时的性能下降问题，表现出"顺序鲁棒性"。研究还识别了这种优势减弱的失败条件，界定了顺序鲁棒性的限制。

Abstract: Autoregressive (AR) language models enforce a fixed left-to-right generation order, creating a fundamental limitation when the required output structure conflicts with natural reasoning (e.g., producing answers before explanations due to presentation or schema constraints). In such cases, AR models must commit to answers before generating intermediate reasoning, and this rigid constraint forces premature commitment. Masked diffusion language models (MDLMs), which iteratively refine all tokens in parallel, offer a way to decouple computation order from output structure. We validate this capability on GSM8K, Math500, and ReasonOrderQA, a benchmark we introduce with controlled difficulty and order-level evaluation. When prompts request answers before reasoning, AR models exhibit large accuracy gaps compared to standard chain-of-thought ordering (up to 67% relative drop), while MDLMs remain stable ($\leq$14% relative drop), a property we term "order robustness". Using ReasonOrderQA, we present evidence that MDLMs achieve order robustness by stabilizing simpler tokens (e.g., reasoning steps) earlier in the diffusion process than complex ones (e.g., final answers), enabling reasoning tokens to stabilize before answer commitment. Finally, we identify failure conditions where this advantage weakens, outlining the limits required for order robustness.

</details>


### [65] [A Separable Architecture for Continuous Token Representation in Language Models](https://arxiv.org/abs/2601.22040)
*Reza T. Batley,Sourav Saha*

Main category: cs.CL

TL;DR: Leviathan架构通过连续嵌入生成器替代传统离散查找表，在小语言模型中显著提升参数效率，表现出相当于1.47-2.11倍参数量的性能。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer缩放定律将参数视为可互换的，但在十亿参数以下的小语言模型中，嵌入矩阵占据了大部分参数预算，这种分配方式既低效又违反直觉。

Method: 提出Leviathan架构，使用连续嵌入生成器替代传统的离散查找表（嵌入矩阵），在等参数设置下评估性能。

Result: 在Pile数据集上，Leviathan持续优于标准的LLaMA风格架构；通过经验幂律拟合，显示出显著优越的有效参数容量，在整个研究范围内表现出相当于1.47到2.11倍参数量的密集模型性能。

Conclusion: Leviathan架构通过连续嵌入生成器有效解决了小语言模型中嵌入矩阵参数分配低效的问题，显著提升了参数效率，为小语言模型设计提供了新思路。

Abstract: Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \times$ more parameters.

</details>


### [66] [On the Paradoxical Interference between Instruction-Following and Task Solving](https://arxiv.org/abs/2601.22047)
*Yunjia Qi,Hao Peng,Xintong Shi,Amy Xin,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 指令跟随可能干扰大语言模型的任务解决能力，研究发现添加自证约束会导致性能显著下降，即使对先进模型也是如此


<details>
  <summary>Details</summary>
Motivation: 指令跟随旨在使大语言模型与人类意图对齐，但研究发现存在反直觉现象：指令跟随可能反而干扰模型的任务解决能力。作者希望量化这种干扰效应并探究其机制

Method: 提出SUSTAINSCORE指标，通过在指令中插入自证约束（从原始成功模型输出中提取且自然满足的约束）来量化指令跟随对任务解决的干扰。在数学、多跳问答和代码生成任务上测试当前LLMs，分析失败模式，并研究干扰机制（如注意力分配）

Result: 实验显示添加自证约束会导致性能显著下降，即使对Claude-Sonnet-4.5等先进模型也是如此。干扰在不同约束类型和规模上具有普遍性，失败案例相比成功案例在约束上分配显著更多注意力

Conclusion: 指令跟随可能对大语言模型的任务解决能力产生干扰，SUSTAINSCORE为量化这种干扰提供了有效指标。研究揭示了当前对齐策略的局限性，并为进一步研究提供了实证观察

Abstract: Instruction following aims to align Large Language Models (LLMs) with human intent by specifying explicit constraints on how tasks should be performed. However, we reveal a counterintuitive phenomenon: instruction following can paradoxically interfere with LLMs' task-solving capability. We propose a metric, SUSTAINSCORE, to quantify the interference of instruction following with task solving. It measures task performance drop after inserting into the instruction a self-evident constraint, which is naturally met by the original successful model output and extracted from it. Experiments on current LLMs in mathematics, multi-hop QA, and code generation show that adding the self-evident constraints leads to substantial performance drops, even for advanced models such as Claude-Sonnet-4.5. We validate the generality of the interference across constraint types and scales. Furthermore, we identify common failure patterns, and by investigating the mechanisms of interference, we observe that failed cases allocate significantly more attention to constraints compared to successful ones. Finally, we use SUSTAINSCORE to conduct an initial investigation into how distinct post-training paradigms affect the interference, presenting empirical observations on current alignment strategies. We will release our code and data to facilitate further research

</details>


### [67] [MasalBench: A Benchmark for Contextual and Cross-Cultural Understanding of Persian Proverbs in LLMs](https://arxiv.org/abs/2601.22050)
*Ghazal Kalhor,Behnam Bahrak*

Main category: cs.CL

TL;DR: 该论文提出了MasalBench基准，用于评估大语言模型对波斯谚语的上下文理解和跨文化理解能力，发现在高资源语言中表现良好的模型在低资源语言的跨文化推理方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大语言模型已成为日常生活重要部分，但现有研究主要评估高资源语言中的比喻语言理解，对低资源语言（如波斯语）的谚语理解和跨文化理解能力缺乏系统评估。

Method: 构建了MasalBench基准，包含波斯谚语的上下文理解和跨文化理解任务，评估了8个最先进的大语言模型，测试它们在识别波斯谚语上下文和对应英语谚语方面的能力。

Result: 模型在识别波斯谚语上下文方面表现良好（准确率>0.90），但在识别对应英语谚语方面表现显著下降（最佳模型准确率0.79），揭示了模型在文化知识和类比推理方面的局限性。

Conclusion: 当前大语言模型在低资源语言的跨文化理解方面存在不足，MasalBench为评估其他低资源语言的跨文化理解提供了框架，强调了提升模型文化知识和类比推理能力的重要性。

Abstract: In recent years, multilingual Large Language Models (LLMs) have become an inseparable part of daily life, making it crucial for them to master the rules of conversational language in order to communicate effectively with users. While previous work has evaluated LLMs' understanding of figurative language in high-resource languages, their performance in low-resource languages remains underexplored. In this paper, we introduce MasalBench, a comprehensive benchmark for assessing LLMs' contextual and cross-cultural understanding of Persian proverbs, which are a key component of conversation in this low-resource language. We evaluate eight state-of-the-art LLMs on MasalBench and find that they perform well in identifying Persian proverbs in context, achieving accuracies above 0.90. However, their performance drops considerably when tasked with identifying equivalent English proverbs, with the best model achieving 0.79 accuracy. Our findings highlight the limitations of current LLMs in cultural knowledge and analogical reasoning, and they provide a framework for assessing cross-cultural understanding in other low-resource languages. MasalBench is available at https://github.com/kalhorghazal/MasalBench.

</details>


### [68] [$G^2$-Reader: Dual Evolving Graphs for Multimodal Document QA](https://arxiv.org/abs/2601.22055)
*Yaxin Du,Junru Song,Yifan Zhou,Cheng Wang,Jiahao Gu,Zimeng Chen,Menglan Chen,Wen Yao,Yang Yang,Ying Wen,Siheng Chen*

Main category: cs.CL

TL;DR: G²-Reader通过双图系统（内容图+规划图）解决多模态文档问答中的结构保持和检索导航问题，在VisDoMBench上达到66.21%准确率，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法在多模态长文档问答中存在两个主要问题：1) 平面分块破坏了文档原生结构和跨模态对齐，导致语义片段难以独立理解；2) 迭代检索在长上下文中容易陷入局部证据循环或漂移到无关部分，缺乏持久全局搜索状态。

Method: 提出G²-Reader双图系统：1) 内容图用于保持文档原生结构和跨模态语义；2) 规划图作为有向无环图，通过子问题追踪中间发现并指导逐步导航以完成证据收集。

Result: 在VisDoMBench的五个多模态领域上，G²-Reader配合Qwen3-VL-32B-Instruct达到66.21%平均准确率，显著优于强基线模型和独立的GPT-5（53.08%）。

Conclusion: G²-Reader通过双图系统有效解决了多模态长文档问答中的结构保持和检索导航问题，为多模态阅读提供了更鲁棒的解决方案。

Abstract: Retrieval-augmented generation is a practical paradigm for question answering over long documents, but it remains brittle for multimodal reading where text, tables, and figures are interleaved across many pages. First, flat chunking breaks document-native structure and cross-modal alignment, yielding semantic fragments that are hard to interpret in isolation. Second, even iterative retrieval can fail in long contexts by looping on partial evidence or drifting into irrelevant sections as noise accumulates, since each step is guided only by the current snippet without a persistent global search state. We introduce $G^2$-Reader, a dual-graph system, to address both issues. It evolves a Content Graph to preserve document-native structure and cross-modal semantics, and maintains a Planning Graph, an agentic directed acyclic graph of sub-questions, to track intermediate findings and guide stepwise navigation for evidence completion. On VisDoMBench across five multimodal domains, $G^2$-Reader with Qwen3-VL-32B-Instruct reaches 66.21\% average accuracy, outperforming strong baselines and a standalone GPT-5 (53.08\%).

</details>


### [69] [VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning](https://arxiv.org/abs/2601.22069)
*Yibo Wang,Yongcheng Jing,Shunyu Liu,Hao Guan,Rong-cheng Tu,Chengyu Wang,Jun Huang,Dacheng Tao*

Main category: cs.CL

TL;DR: VTC-R1通过将中间推理过程渲染为紧凑图像作为"光学记忆"，实现3.4倍令牌压缩和2.7倍推理加速，在数学推理基准上优于标准长上下文方法。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理虽然增强了LLMs处理复杂任务的能力，但带来了严重的效率瓶颈。现有高效方法通常需要复杂的额外训练或依赖外部模型进行压缩，限制了可扩展性并丢失了关键的细粒度信息。

Method: 提出VTC-R1高效推理范式，将视觉-文本压缩集成到推理过程中。不处理冗长的文本轨迹，而是将中间推理片段渲染为紧凑图像，迭代地反馈给视觉语言模型作为"光学记忆"。基于OpenR1-Math-220K构建训练数据集，微调代表性VLM模型Glyph和Qwen3-VL。

Result: 在MATH500、AIME25、AMC23和GPQA-D等基准测试中，VTC-R1始终优于标准长上下文推理。实现了3.4倍的令牌压缩，显著提升推理效率，端到端延迟获得2.7倍加速。

Conclusion: VTC-R1通过视觉-文本压缩集成，为推理密集型应用提供了可扩展的高效解决方案，在保持性能的同时显著提升效率。

Abstract: Long-context reasoning has significantly empowered large language models (LLMs) to tackle complex tasks, yet it introduces severe efficiency bottlenecks due to the computational complexity. Existing efficient approaches often rely on complex additional training or external models for compression, which limits scalability and discards critical fine-grained information. In this paper, we propose VTC-R1, a new efficient reasoning paradigm that integrates vision-text compression into the reasoning process. Instead of processing lengthy textual traces, VTC-R1 renders intermediate reasoning segments into compact images, which are iteratively fed back into vision-language models as "optical memory." We construct a training dataset based on OpenR1-Math-220K achieving 3.4x token compression and fine-tune representative VLMs-Glyph and Qwen3-VL. Extensive experiments on benchmarks such as MATH500, AIME25, AMC23 and GPQA-D demonstrate that VTC-R1 consistently outperforms standard long-context reasoning. Furthermore, our approach significantly improves inference efficiency, achieving 2.7x speedup in end-to-end latency, highlighting its potential as a scalable solution for reasoning-intensive applications. Our code is available at https://github.com/w-yibo/VTC-R1.

</details>


### [70] [ECO: Quantized Training without Full-Precision Master Weights](https://arxiv.org/abs/2601.22101)
*Mahdi Nikdan,Amir Zandieh,Dan Alistarh,Vahab Mirrokni*

Main category: cs.CL

TL;DR: ECO（误差补偿优化器）通过直接在量化参数上应用更新并消除主权重缓冲区，显著减少了大型语言模型训练的内存开销，特别是对稀疏专家混合模型。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法虽然改善了LLM训练的计算和内存效率，但仍需要在高精度主权重缓冲区中累积更新，这带来了显著的内存开销，特别是在参数和优化器状态占主导的稀疏专家混合模型中。

Method: 提出误差补偿优化器（ECO），通过直接在量化参数上应用更新来消除主权重。ECO在每个步骤后量化权重，并将量化误差精心注入优化器动量中，形成一个无需额外内存的误差反馈循环。

Result: 理论证明：在标准假设和衰减学习率下，ECO收敛到最优解附近恒定半径的邻域，而简单移除主权重会导致与学习率成反比的误差。实验验证：在30-800M参数Transformer、Gemma-3 1B模型、2.1B参数稀疏MoE模型（FP8量化）以及DeepSeek-MoE-16B的INT4微调中，ECO与使用主权重的基线达到近乎无损的准确率匹配，显著改善了静态内存与验证损失的帕累托前沿。

Conclusion: ECO通过消除主权重缓冲区，在保持模型准确性的同时显著减少了LLM训练的内存开销，为大规模模型训练提供了更高效的内存优化解决方案。

Abstract: Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\textit{master weights}$. This buffer introduces substantial memory overhead, particularly for Sparse Mixture of Experts (SMoE) models, where model parameters and optimizer states dominate memory usage. To address this, we introduce the Error-Compensating Optimizer (ECO), which eliminates master weights by applying updates directly to quantized parameters. ECO quantizes weights after each step and carefully injects the resulting quantization error into the optimizer momentum, forming an error-feedback loop with no additional memory. We prove that, under standard assumptions and a decaying learning rate, ECO converges to a constant-radius neighborhood of the optimum, while naive master-weight removal can incur an error that is inversely proportional to the learning rate. We show empirical results for pretraining small Transformers (30-800M), a Gemma-3 1B model, and a 2.1B parameter Sparse MoE model with FP8 quantization, and fine-tuning DeepSeek-MoE-16B in INT4 precision. Throughout, ECO matches baselines with master weights up to near-lossless accuracy, significantly shifting the static memory vs validation loss Pareto frontier.

</details>


### [71] [A Federated and Parameter-Efficient Framework for Large Language Model Training in Medicine](https://arxiv.org/abs/2601.22124)
*Anran Li,Yuanyuan Chen,Wenjun Long,Yu Yin,Yan Hu,Hyunjae Kim,Weipeng Zhou,Yujia Zhou,Hongyi Peng,Yang Ren,Xuguang Ai,Zhenyue Qin,Ming Hu,Xiaoxiao Li,Han Yu,Yih-Chung Tham,Lucila Ohno-Machado,Hua Xu,Qingyu Chen*

Main category: cs.CL

TL;DR: Fed-MedLoRA：针对医学领域大语言模型的参数高效联邦学习框架，通过传输低秩适配器参数减少通信和计算开销，并引入数据感知聚合机制处理临床数据异质性。


<details>
  <summary>Details</summary>
Motivation: 医学LLMs通常基于单一机构数据训练，面临泛化性和安全性限制；传统联邦学习传输完整模型参数对数十亿参数的LLMs不切实际，且假设数据同质性，而真实临床数据具有高度异质性。

Method: 提出Fed-MedLoRA框架：1) 仅传输低秩适配器参数（LoRA），减少通信和计算开销；2) Fed-MedLoRA+引入自适应、数据感知的聚合机制，改善跨站点异质性下的收敛性；应用于临床信息抽取任务。

Result: 在五个患者队列中评估临床信息抽取准确性，与BERT、LLaMA-3、DeepSeek-R1、GPT-4o等模型比较；评估设置包括域内训练测试、外部独立队列验证、以及耶鲁纽黑文医疗系统真实临床笔记的低资源新站点适应场景。

Conclusion: Fed-MedLoRA框架为医学LLMs提供了参数高效的联邦学习解决方案，通过低秩适配器传输和数据感知聚合，解决了传统联邦学习在大型模型和临床数据异质性方面的限制，有望促进跨医疗机构协作模型开发。

Abstract: Large language models (LLMs) have demonstrated strong performance on medical benchmarks, including question answering and diagnosis. To enable their use in clinical settings, LLMs are typically further adapted through continued pretraining or post-training using clinical data. However, most medical LLMs are trained on data from a single institution, which faces limitations in generalizability and safety in heterogeneous systems. Federated learning (FL) is a promising solution for enabling collaborative model development across healthcare institutions. Yet applying FL to LLMs in medicine remains fundamentally limited. First, conventional FL requires transmitting the full model during each communication round, which becomes impractical for multi-billion-parameter LLMs given the limited computational resources. Second, many FL algorithms implicitly assume data homogeneity, whereas real-world clinical data are highly heterogeneous across patients, diseases, and institutional practices. We introduce the model-agnostic and parameter-efficient federated learning framework for adapting LLMs to medical applications. Fed-MedLoRA transmits only low-rank adapter parameters, reducing communication and computation overhead, while Fed-MedLoRA+ further incorporates adaptive, data-aware aggregation to improve convergence under cross-site heterogeneity. We apply the framework to clinical information extraction (IE), which transforms patient narratives into structured medical entities and relations. Accuracy was assessed across five patient cohorts through comparisons with BERT models, and LLaMA-3 and DeepSeek-R1, GPT-4o models. Evaluation settings included (1) in-domain training and testing, (2) external validation on independent cohorts, and (3) a low-resource new-site adaptation scenario using real-world clinical notes from the Yale New Haven Health System.

</details>


### [72] [Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers](https://arxiv.org/abs/2601.22139)
*Xin Chen,Feng Jiang,Yiqian Zhang,Hardy Chen,Shuo Yan,Wenya Xie,Min Yang,Shujian Huang*

Main category: cs.CL

TL;DR: PIR提出了一种主动交互推理范式，让LLM从被动推理转变为主动询问，通过用户交互解决前提和意图层面的不确定性，显著提升性能并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有CoT提示的LLMs存在"盲目自我思考"的局限性，当关键信息缺失或模糊时仍进行大量内部推理，无法有效处理前提和意图层面的不确定性。

Method: 提出PIR框架，包含两个核心组件：1) 不确定性感知的监督微调，赋予模型交互推理能力；2) 基于用户模拟器的策略优化框架，使用复合奖励使模型行为与用户意图对齐。

Result: 在数学推理、代码生成和文档编辑任务上，PIR相比基线方法取得了显著提升：准确率提高32.70%，通过率提高22.90%，BLEU提升41.36，同时减少近一半的推理计算和不必要的交互轮次。

Conclusion: PIR通过将LLM从被动推理者转变为主动询问者，有效解决了前提和意图层面的不确定性问题，在多个任务上展现出强大的泛化能力和鲁棒性，为LLM推理范式提供了新方向。

Abstract: Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\% higher accuracy, 22.90\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}

</details>


### [73] [FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale](https://arxiv.org/abs/2601.22146)
*Ajay Patel,Colin Raffel,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 该论文提出FineInstructions方法，将互联网规模的无监督预训练文档转化为数十亿个合成指令-答案训练对，实现了仅使用指令微调目标从头预训练大语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型通常先通过自监督的"预测下一个词"目标在大量无结构文本上进行预训练，然后使用有限的指令微调数据使其对用户有用。由于监督训练数据有限，需要克服这一瓶颈。

Method: 提出FineInstructions方法：1) 从真实用户查询和提示中创建约1800万个指令模板；2) 将这些模板与无监督预训练语料中的人类撰写源文档匹配并实例化；3) 生成大规模"监督"合成训练数据。

Result: 在FineInstructions上进行预训练的模型，在标准基准测试中测量自由形式响应质量时，表现优于标准预训练和其他提出的合成预训练技术。

Conclusion: 通过将无监督预训练文档知识转化为大规模合成指令-答案对，可以仅使用指令微调目标从头预训练LLM，这种方法更符合LLM下游使用的分布特征，能有效提升模型性能。

Abstract: Due to limited supervised training data, large language models (LLMs) are typically pre-trained via a self-supervised "predict the next word" objective on a vast amount of unstructured text data. To make the resulting model useful to users, it is further trained on a far smaller amount of "instruction-tuning" data comprised of supervised training examples of instructions and responses. To overcome the limited amount of supervised data, we propose a procedure that can transform the knowledge in internet-scale pre-training documents into billions of synthetic instruction and answer training pairs. The resulting dataset, called FineInstructions, uses ~18M instruction templates created from real user-written queries and prompts. These instruction templates are matched to and instantiated with human-written source documents from unstructured pre-training corpora. With "supervised" synthetic training data generated at this scale, an LLM can be pre-trained from scratch solely with the instruction-tuning objective, which is far more in-distribution with the expected downstream usage of LLMs (responding to user prompts). We conduct controlled token-for-token training experiments and find pre-training on FineInstructions outperforms standard pre-training and other proposed synthetic pre-training techniques on standard benchmarks measuring free-form response quality. Our resources can be found at https://huggingface.co/fineinstructions .

</details>


### [74] [DynaWeb: Model-Based Reinforcement Learning of Web Agents](https://arxiv.org/abs/2601.22149)
*Hang Ding,Peidong Liu,Junqiao Wang,Ziwei Ji,Meng Cao,Rongzhao Zhang,Lynn Ai,Eric Yang,Tianyu Shi,Lei Yu*

Main category: cs.CL

TL;DR: DynaWeb是一个基于模型强化学习的框架，通过训练网页世界模型让网络代理在模拟环境中"想象"交互，从而高效训练网络代理。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型和强化学习的自主网络代理训练面临直接与真实互联网交互的低效性、高成本和风险问题。

Method: 提出DynaWeb框架：1) 训练网页世界模型预测给定代理动作后的网页表示；2) 在合成网页环境中进行策略"梦想"生成大量动作轨迹；3) 将真实专家轨迹与在线策略轨迹随机交织训练以提高稳定性和样本效率。

Result: 在WebArena和WebVoyager基准测试中，DynaWeb显著提升了最先进开源网络代理模型的性能。

Conclusion: 通过"想象"训练网络代理是可行的，为可扩展和高效的在线代理强化学习提供了新途径。

Abstract: The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.

</details>


### [75] [Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts](https://arxiv.org/abs/2601.22156)
*Yingfa Chen,Zhen Leng Thai,Zihan Zhou,Zhu Zhang,Xingyu Shen,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 提出HALO流程将Transformer蒸馏为RNN-attention混合模型，以及HypeNet架构，通过少量数据（2.3B tokens）转换Qwen3系列，实现媲美原模型性能且具有更好的长上下文性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有混合Transformer架构（结合softmax attention和RNN）在长上下文建模中展现出良好的性能-吞吐量权衡，但大规模从头预训练成本过高。现有的参数转换和知识蒸馏方法需要大量训练数据（超过10B tokens），且生成的混合模型长上下文性能较差，而这正是混合模型相对于Transformer模型具有显著推理加速优势的场景。

Method: 1. 提出HALO（Hybrid Attention via Layer Optimization）流程，用于将Transformer模型蒸馏为RNN-attention混合模型。2. 提出HypeNet混合架构，采用新型位置编码方案（HyPE）和各种架构修改，实现优越的长度泛化能力。3. 使用HALO将Qwen3系列转换为HypeNet。

Result: 仅需2.3B tokens（少于预训练数据的0.01%）即可完成转换，转换后的模型性能与原始Transformer模型相当，同时享有优越的长上下文性能和效率。

Conclusion: HALO和HypeNet为混合Transformer架构的实用化提供了高效解决方案，显著降低了转换成本，同时保持了模型性能并提升了长上下文处理能力。

Abstract: Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [76] [SteerEval: A Framework for Evaluating Steerability with Natural Language Profiles for Recommendation](https://arxiv.org/abs/2601.21105)
*Joyce Zhou,Weijie Zhou,Doug Turnbull,Thorsten Joachims*

Main category: cs.IR

TL;DR: 论文提出了SteerEval评估框架，用于衡量基于自然语言用户画像的推荐系统在多样化用户引导指令下的可引导性，发现当前方法在细粒度控制方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 尽管自然语言用户画像因其可解释性和可引导性潜力而受到关注，但现有评估方法主要关注易于识别的项目属性（如电影类型），未能捕捉更丰富的用户控制形式。当前自然语言推荐方法是否能够真正遵循用户的引导指令仍不明确。

Method: 提出了SteerEval评估框架，通过使用从类型到内容警告等多种干预措施来测量更细致和多样化的可引导性形式。评估了一系列预训练的自然语言推荐器，研究了在相对小众主题上的引导潜力与限制，并比较了不同用户画像和推荐干预措施对引导效果的影响。

Result: 评估结果显示，当前基于自然语言的推荐方法在细粒度、多样化用户引导方面存在局限性。不同干预措施对引导效果有显著影响，系统在小众主题上的可引导性表现较差。

Conclusion: 论文提出了更全面的可引导性评估框架，为可引导推荐系统的设计提供了实用建议，并指出了未来研究方向，包括改进对多样化用户控制指令的响应能力。

Abstract: Natural-language user profiles have recently attracted attention not only for improved interpretability, but also for their potential to make recommender systems more steerable. By enabling direct editing, natural-language profiles allow users to explicitly articulate preferences that may be difficult to infer from past behavior. However, it remains unclear whether current natural-language-based recommendation methods can follow such steering commands. While existing steerability evaluations have shown some success for well-recognized item attributes (e.g., movie genres), we argue that these benchmarks fail to capture the richer forms of user control that motivate steerable recommendations. To address this gap, we introduce SteerEval, an evaluation framework designed to measure more nuanced and diverse forms of steerability by using interventions that range from genres to content-warning for movies. We assess the steerability of a family of pretrained natural-language recommenders, examine the potential and limitations of steering on relatively niche topics, and compare how different profile and recommendation interventions impact steering effectiveness. Finally, we offer practical design suggestions informed by our findings and discuss future steps in steerable recommender design.

</details>


### [77] [A2RAG: Adaptive Agentic Graph Retrieval for Cost-Aware and Reliable Reasoning](https://arxiv.org/abs/2601.21162)
*Jiate Liu,Zebin Chen,Shaobo Qiao,Mingchen Ju,Danting Zhang,Bocheng Han,Shuyue Yu,Xin Shu,Jingling Wu,Dong Wen,Xin Cao,Guanfeng Liu,Zhengyi Yang*

Main category: cs.IR

TL;DR: A2RAG是一个自适应智能体Graph-RAG框架，通过自适应控制器和智能体检索器，在混合难度查询和提取损失问题下实现成本感知的可靠推理，显著提升性能并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决Graph-RAG在实际部署中的两个关键瓶颈：1）混合难度工作负载下的一刀切检索策略既浪费成本又无法处理困难的多跳查询；2）图抽象导致的提取损失，即细粒度限定词信息在知识图构建过程中丢失。

Method: 提出A2RAG框架，包含两个核心组件：自适应控制器验证证据充分性并仅在必要时触发针对性精炼；智能体检索器逐步升级检索力度，并将图信号映射回源文本，以应对提取损失和不完整图的问题。

Result: 在HotpotQA和2WikiMultiHopQA数据集上的实验表明，A2RAG在Recall@2指标上获得+9.9/+11.8的绝对提升，同时将token消耗和端到端延迟相对迭代多跳基线减少约50%。

Conclusion: A2RAG通过自适应控制和智能体检索的有效结合，为Graph-RAG提供了成本高效且可靠的解决方案，成功解决了混合难度查询和提取损失的实际部署挑战。

Abstract: Graph Retrieval-Augmented Generation (Graph-RAG) enhances multihop question answering by organizing corpora into knowledge graphs and routing evidence through relational structure. However, practical deployments face two persistent bottlenecks: (i) mixed-difficulty workloads where one-size-fits-all retrieval either wastes cost on easy queries or fails on hard multihop cases, and (ii) extraction loss, where graph abstraction omits fine-grained qualifiers that remain only in source text. We present A2RAG, an adaptive-and-agentic GraphRAG framework for cost-aware and reliable reasoning. A2RAG couples an adaptive controller that verifies evidence sufficiency and triggers targeted refinement only when necessary, with an agentic retriever that progressively escalates retrieval effort and maps graph signals back to provenance text to remain robust under extraction loss and incomplete graphs. Experiments on HotpotQA and 2WikiMultiHopQA demonstrate that A2RAG achieves +9.9/+11.8 absolute gains in Recall@2, while cutting token consumption and end-to-end latency by about 50% relative to iterative multihop baselines.

</details>


### [78] [Thinking Broad, Acting Fast: Latent Reasoning Distillation from Multi-Perspective Chain-of-Thought for E-Commerce Relevance](https://arxiv.org/abs/2601.21611)
*Baopu Qiu,Hao Chen,Yuanrong Wu,Changtong Zan,Chao Wei,Weiru Zhang,Xiaoyi Zeng*

Main category: cs.IR

TL;DR: 提出一个结合多视角思维链推理和潜在推理知识蒸馏的框架，以提升电商搜索相关性建模的准确性和实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的电商搜索相关性模型存在两个关键局限：1) 单视角思维链推理无法捕捉电商相关性的多维度特性（如用户意图、属性匹配、业务规则）；2) 思维链推理在知识蒸馏过程中被丢弃，仅作为临时辅助信号，丧失了推理效用。

Method: 1) 教师模型采用多视角思维链推理生成多样化的推理依据；2) 结合监督微调和直接偏好优化构建更鲁棒的理由生成器；3) 提出潜在推理知识蒸馏方法，让学生模型配备轻量级推理提取器，在推理时内部化LLM的复杂推理能力。

Result: 在服务数千万用户的电商搜索广告平台上进行离线和在线A/B测试，方法带来了显著的离线性能提升，在商业表现和用户体验方面均显示出明显优势。

Conclusion: 该框架通过多视角思维链推理和潜在推理知识蒸馏，有效解决了电商搜索相关性建模中的多维度和实时性挑战，实现了性能提升和实际部署的平衡。

Abstract: Effective relevance modeling is crucial for e-commerce search, as it aligns search results with user intent and enhances customer experience. Recent work has leveraged large language models (LLMs) to address the limitations of traditional relevance models, especially for long-tail and ambiguous queries. By incorporating Chain-of-Thought (CoT) reasoning, these approaches improve both accuracy and interpretability through multi-step reasoning. However, two key limitations remain: (1) most existing approaches rely on single-perspective CoT reasoning, which fails to capture the multifaceted nature of e-commerce relevance (e.g., user intent vs. attribute-level matching vs. business-specific rules); and (2) although CoT-enhanced LLM's offer rich reasoning capabilities, their high inference latency necessitates knowledge distillation for real-time deployment, yet current distillation methods discard the CoT rationale structure at inference, using it as a transient auxiliary signal and forfeiting its reasoning utility. To address these challenges, we propose a novel framework that better exploits CoT semantics throughout the optimization pipeline. Specifically, the teacher model leverages Multi-Perspective CoT (MPCoT) to generate diverse rationales and combines Supervised Fine-Tuning (SFT) with Direct Preference Optimization (DPO) to construct a more robust reasoner. For distillation, we introduce Latent Reasoning Knowledge Distillation (LRKD), which endows a student model with a lightweight inference-time latent reasoning extractor, allowing efficient and low-latency internalization of the LLM's sophisticated reasoning capabilities. Evaluated in offline experiments and online A/B tests on an e-commerce search advertising platform serving tens of millions of users daily, our method delivers significant offline gains, showing clear benefits in both commercial performance and user experience.

</details>


### [79] [Influence Guided Sampling for Domain Adaptation of Text Retrievers](https://arxiv.org/abs/2601.21759)
*Meet Doshi,Vishwajeet Kumar,Yulong Li,Jaydeep Sen*

Main category: cs.IR

TL;DR: Inf-DDS是一种基于强化学习的自适应训练数据采样框架，通过影响力奖励信号动态调整不同数据集的采样权重，在降低GPU计算成本的同时显著提升检索模型性能。


<details>
  <summary>Details</summary>
Motivation: 通用开放域密集检索系统通常使用多样化的语料库和搜索任务进行训练，但如何优化这些不同数据集和任务的采样策略尚未得到充分研究。传统的均匀采样、按实例数量比例采样或依赖专家监督的方法可能不是最优的，而训练数据采样策略对模型性能有重要影响。

Method: 提出Inf-DDS（影响力驱动的数据采样）框架，使用强化学习自适应地重新加权训练数据集。该方法基于影响力奖励信号指导，迭代优化采样策略，优先选择能最大化目标开发集性能的数据集。相比基于梯度的采样方法，该框架更轻量级，GPU消耗更低。

Result: 在广泛的文本检索任务评估中，Inf-DDS相比现有方法显著提升了检索性能：训练多语言bge-m3模型时获得5.03的绝对NDCG@10提升，训练all-MiniLM-L6-v2模型时获得0.94的绝对NDCG@10提升。同时，GPU计算成本降低了1.5倍到4倍，即使在从专家分配权重的训练数据集池开始时也表现出色。

Conclusion: Inf-DDS提供了一种高效、轻量级的训练数据采样策略，通过强化学习和影响力奖励机制自适应优化数据集权重，在显著提升检索模型性能的同时大幅降低计算成本，为解决多样化训练数据的采样问题提供了有效方案。

Abstract: General-purpose open-domain dense retrieval systems are usually trained with a large, eclectic mix of corpora and search tasks. How should these diverse corpora and tasks be sampled for training? Conventional approaches sample them uniformly, proportional to their instance population sizes, or depend on human-level expert supervision. It is well known that the training data sampling strategy can greatly impact model performance. However, how to find the optimal strategy has not been adequately studied in the context of embedding models. We propose Inf-DDS, a novel reinforcement learning driven sampling framework that adaptively reweighs training datasets guided by influence-based reward signals and is much more lightweight with respect to GPU consumption. Our technique iteratively refines the sampling policy, prioritizing datasets that maximize model performance on a target development set. We evaluate the efficacy of our sampling strategy on a wide range of text retrieval tasks, demonstrating strong improvements in retrieval performance and better adaptation compared to existing gradient-based sampling methods, while also being 1.5x to 4x cheaper in GPU compute. Our sampling strategy achieves a 5.03 absolute NDCG@10 improvement while training a multilingual bge-m3 model and an absolute NDCG@10 improvement of 0.94 while training all-MiniLM-L6-v2, even when starting from expert-assigned weights on a large pool of training datasets.

</details>


### [80] [OneMall: One Model, More Scenarios -- End-to-End Generative Recommender Family at Kuaishou E-Commerce](https://arxiv.org/abs/2601.21770)
*Kun Zhang,Jingming Zhang,Wei Cheng,Yansong Cheng,Jiaqi Zhang,Hao Lu,Xu Zhang,Haixiang Gan,Jiangxia Cao,Tenglong Wang,Ximing Zhang,Boyang Xia,Kuo Cai,Shiyao Wang,Hongjian Dou,Jinkai Yu,Mingxing Wen,Qiang Luo,Dongxu Liang,Chenyi Lei,Jun Wang,Runan Liu,Zhaojie Liu,Ruiming Tang,Tingting Gao,Shaoguo Liu,Yuqing Ding,Hui Kong,Han Li,Guorui Zhou,Wenwu Ou,Kun Gai*

Main category: cs.IR

TL;DR: 快手提出的OneMall是一个端到端的生成式推荐框架，统一了电商多种商品分发场景，通过语义分词器、Transformer架构和强化学习流程实现了性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐浪潮中，电商存在多种商品分发场景（产品卡片、短视频、直播）需要统一处理，传统方法难以有效整合这些异构场景。

Method: 1) 电商语义分词器：捕获现实世界语义和业务特定商品关系；2) Transformer架构：使用Query-Former压缩长序列，Cross-Attention融合多行为序列，Sparse MoE实现可扩展自回归生成；3) 强化学习流程：连接检索和排序模型，用排序模型作为奖励信号优化端到端策略检索模型。

Result: 在所有电商场景中取得一致改进：产品卡片GMV提升13.01%，短视频订单提升15.32%，直播订单提升2.78%。已部署服务于快手超过4亿日活跃用户。

Conclusion: OneMall成功统一了电商的多种分发场景，通过结合语义理解、Transformer架构和强化学习，实现了端到端的生成式推荐，在实际应用中表现出显著效果。

Abstract: In the wave of generative recommendation, we present OneMall, an end-to-end generative recommendation framework tailored for e-commerce services at Kuaishou. Our OneMall systematically unifies the e-commerce's multiple item distribution scenarios, such as Product-card, short-video and live-streaming. Specifically, it comprises three key components, aligning the entire model training pipeline to the LLM's pre-training/post-training: (1) E-commerce Semantic Tokenizer: we provide a tokenizer solution that captures both real-world semantics and business-specific item relations across different scenarios; (2) Transformer-based Architecture: we largely utilize Transformer as our model backbone, e.g., employing Query-Former for long sequence compression, Cross-Attention for multi-behavior sequence fusion, and Sparse MoE for scalable auto-regressive generation; (3) Reinforcement Learning Pipeline: we further connect retrieval and ranking models via RL, enabling the ranking model to serve as a reward signal for end-to-end policy retrieval model optimization. Extensive experiments demonstrate that OneMall achieves consistent improvements across all e-commerce scenarios: +13.01\% GMV in product-card, +15.32\% Orders in Short-Video, and +2.78\% Orders in Live-Streaming. OneMall has been deployed, serving over 400 million daily active users at Kuaishou.

</details>


### [81] [The Double-Edged Sword of Knowledge Transfer: Diagnosing and Curing Fairness Pathologies in Cross-Domain Recommendation](https://arxiv.org/abs/2601.21805)
*Yuhan Zhao,Weixin Chen,Li Chen,Weike Pan*

Main category: cs.IR

TL;DR: 本文提出CDFA框架解决跨域推荐中的公平性问题，通过自适应整合未标记数据平衡训练信号，并利用信息论方法重新分配跨域信息增益，在保持推荐性能的同时显著减少不公平性。


<details>
  <summary>Details</summary>
Motivation: 跨域推荐虽然能提升推荐质量，但已有证据表明它会无意中加剧群体层面的不公平性。本文旨在通过理论和实证分析揭示这种不公平性产生的原因，并提出解决方案。

Method: 提出跨域公平增强(CDFA)框架，包含两个核心组件：1) 通过自适应整合未标记数据平衡跨组训练信号的信息量，缓解跨域差异转移；2) 采用信息论方法重新分配跨域信息增益，确保不同群体间的公平收益分配。

Result: 在多个数据集和基线模型上的实验表明，CDFA框架能显著减少跨域推荐中的不公平性，同时不仅不牺牲整体推荐性能，甚至能提升推荐性能。

Conclusion: 本文系统分析了跨域推荐中公平性问题的根源，提出了有效的CDFA框架来同时解决跨域差异转移和不公平信息增益分配问题，为实现公平的跨域推荐提供了可行方案。

Abstract: Cross-domain recommendation (CDR) offers an effective strategy for improving recommendation quality in a target domain by leveraging auxiliary signals from source domains. Nonetheless, emerging evidence shows that CDR can inadvertently heighten group-level unfairness. In this work, we conduct a comprehensive theoretical and empirical analysis to uncover why these fairness issues arise. Specifically, we identify two key challenges: (i) Cross-Domain Disparity Transfer, wherein existing group-level disparities in the source domain are systematically propagated to the target domain; and (ii) Unfairness from Cross-Domain Information Gain, where the benefits derived from cross-domain knowledge are unevenly allocated among distinct groups. To address these two challenges, we propose a Cross-Domain Fairness Augmentation (CDFA) framework composed of two key components. Firstly, it mitigates cross-domain disparity transfer by adaptively integrating unlabeled data to equilibrate the informativeness of training signals across groups. Secondly, it redistributes cross-domain information gains via an information-theoretic approach to ensure equitable benefit allocation across groups. Extensive experiments on multiple datasets and baselines demonstrate that our framework significantly reduces unfairness in CDR without sacrificing overall recommendation performance, while even enhancing it.

</details>


### [82] [LEMUR: Learned Multi-Vector Retrieval](https://arxiv.org/abs/2601.21853)
*Elias Jääsaari,Ville Hyvönen,Teemu Roos*

Main category: cs.IR

TL;DR: LEMUR框架通过两层问题约简，将多向量相似性搜索转化为单向量ANN搜索，实现比现有方法快一个数量级的检索速度


<details>
  <summary>Details</summary>
Motivation: 多向量表示（如ColBERT）在信息检索中比单向量表示有更好的召回率，但代价是显著增加的延迟，需要设计高效的多向量近似最近邻搜索算法

Method: LEMUR框架包含两个连续的问题约简：1）将多向量相似性搜索转化为监督学习问题，用单隐藏层神经网络解决；2）将该模型的推理约简为其隐空间中的单向量相似性搜索，从而利用现有单向量ANNS方法加速检索

Result: LEMUR在ColBERTv2嵌入、现代多向量文本模型和多向量视觉文档检索模型上都表现出色，比早期多向量相似性搜索方法快一个数量级

Conclusion: LEMUR为多向量相似性搜索提供了一种简单而高效的解决方案，通过巧妙的问题转化充分利用现有单向量ANNS技术，显著提升了多向量检索的效率

Abstract: Multi-vector representations generated by late interaction models, such as ColBERT, enable superior retrieval quality compared to single-vector representations in information retrieval applications. In multi-vector retrieval systems, both queries and documents are encoded using one embedding for each token, and similarity between queries and documents is measured by the MaxSim similarity measure. However, the improved recall of multi-vector retrieval comes at the expense of significantly increased latency. This necessitates designing efficient approximate nearest neighbor search (ANNS) algorithms for multi-vector search. In this work, we introduce LEMUR, a simple-yet-efficient framework for multi-vector similarity search. LEMUR consists of two consecutive problem reductions: We first formulate multi-vector similarity search as a supervised learning problem that can be solved using a one-hidden-layer neural network. Second, we reduce inference under this model to single-vector similarity search in its latent space, which enables the use of existing single-vector ANNS methods for speeding up retrieval. In addition to performance evaluation on ColBERTv2 embeddings, we evaluate LEMUR on embeddings generated by modern multi-vector text models and multi-vector visual document retrieval models. LEMUR is an order of magnitude faster than earlier multi-vector similarity search methods.

</details>


### [83] [SpecTran: Spectral-Aware Transformer-based Adapter for LLM-Enhanced Sequential Recommendation](https://arxiv.org/abs/2601.21986)
*Yu Cui,Feng Liu,Zhaoxiang Wang,Changwang Zhang,Jun Wang,Can Wang,Jiawei Chen*

Main category: cs.IR

TL;DR: SpecTran：一种基于光谱感知的transformer适配器，在光谱域操作，通过关注完整光谱来选择聚合信息组件，解决现有适配器维度坍缩和SVD方法僵化的问题。


<details>
  <summary>Details</summary>
Motivation: 传统序列推荐模型学习低维项目ID嵌入，常忽略文本信息。现有基于LLM的文本嵌入注入方法存在两种主要问题：适配器方法存在显著维度坍缩，信息集中在少数主导维度；SVD方法僵化且手动，只考虑少数主成分而丢弃丰富光谱信息。

Method: 提出SpecTran，一种基于光谱感知的transformer适配器，在光谱域操作，关注完整光谱以选择和聚合信息组件。引入可学习的光谱位置编码，将奇异值线索作为归纳偏置注入，引导注意力关注显著光谱组件并促进嵌入维度的多样性。

Result: 在四个真实世界数据集和三个序列推荐骨干网络上，SpecTran始终优于强基线，平均提升9.17%。

Conclusion: SpecTran通过光谱域操作和可学习光谱位置编码，有效解决了现有文本嵌入注入方法的局限性，显著提升了序列推荐性能。

Abstract: Traditional sequential recommendation (SR) models learn low-dimensional item ID embeddings from user-item interactions, often overlooking textual information such as item titles or descriptions. Recent advances in Large Language Models (LLMs) have inspired a surge of research that encodes item textual information with high-dimensional semantic embeddings, and designs transformation methods to inject such embeddings into SR models. These embedding transformation strategies can be categorized into two types, both of which exhibits notable drawbacks: 1) adapter-based methods suffer from pronounced dimension collapse, concentrating information into a few dominant dimensions; 2) SVD-based methods are rigid and manual, considering only a few principal spectral components while discarding rich information in the remaining spectrum.
  To address these limitations, we propose SpecTran, a spectral-aware transformer-based adapter that operates in the spectral domain, attending to the full spectrum to select and aggregates informative components. A learnable spectral-position encoding injects singular-value cues as an inductive bias, guiding attention toward salient spectral components and promoting diversity across embedding dimensions. Across four real-world datasets and three SR backbones, it consistently outperforms strong baselines, achieving an average improvement of 9.17%.

</details>


### [84] [LANCER: LLM Reranking for Nugget Coverage](https://arxiv.org/abs/2601.22008)
*Jia-Huei Ju,François G. Landry,Eugene Yang,Suzan Verberne,Andrew Yates*

Main category: cs.IR

TL;DR: LANCER是一种基于LLM的重排序方法，专注于提升长文本检索中的信息覆盖度，通过生成子问题并预测文档回答这些子问题的能力来优化文档排序。


<details>
  <summary>Details</summary>
Motivation: 现有的检索方法主要针对相关性排序进行优化，但在长文本检索增强生成（RAG）中，如自动报告生成，不仅需要相关信息，还需要覆盖广泛信息的全面响应。现有方法在信息覆盖度方面存在不足。

Method: 提出LANCER方法：1）预测为满足信息需求需要回答哪些子问题；2）预测哪些文档能回答这些子问题；3）重新排序文档以尽可能多地覆盖信息点。

Result: 实验结果表明，LANCER在信息点覆盖度指标（α-nDCG和信息覆盖率）上优于其他基于LLM的重排序方法。进一步的分析显示，子问题生成在其中起着关键作用。

Conclusion: LANCER通过关注信息覆盖度而非仅仅是相关性，有效提升了长文本检索的质量，特别是在需要全面信息覆盖的应用场景中。

Abstract: Unlike short-form retrieval-augmented generation (RAG), such as factoid question answering, long-form RAG requires retrieval to provide documents covering a wide range of relevant information. Automated report generation exemplifies this setting: it requires not only relevant information but also a more elaborate response with comprehensive information. Yet, existing retrieval methods are primarily optimized for relevance ranking rather than information coverage. To address this limitation, we propose LANCER, an LLM-based reranking method for nugget coverage. LANCER predicts what sub-questions should be answered to satisfy an information need, predicts which documents answer these sub-questions, and reranks documents in order to provide a ranked list covering as many information nuggets as possible. Our empirical results show that LANCER enhances the quality of retrieval as measured by nugget coverage metrics, achieving higher $α$-nDCG and information coverage than other LLM-based reranking methods. Our oracle analysis further reveals that sub-question generation plays an essential role.

</details>


### [85] [Loci Similes: A Benchmark for Extracting Intertextualities in Latin Literature](https://arxiv.org/abs/2601.07533)
*Julian Schelb,Michael Wittweiler,Marie Revellio,Barbara Feichtinger,Andreas Spitz*

Main category: cs.IR

TL;DR: 提出Loci Similes基准数据集，用于拉丁语互文性检测，包含17.2万文本片段和545个专家验证的互文关系，并建立了检索和分类的基线方法。


<details>
  <summary>Details</summary>
Motivation: 历史文本之间的互文联系研究对重建作者虚拟图书馆和识别创作来源很重要，但现有方法发展受限于缺乏标准化基准和易用数据集。

Method: 引入Loci Similes基准数据集，包含约172k文本片段和545个专家验证的互文关系（连接晚期古代作者与古典作者），使用最先进的LLM建立检索和分类的基线。

Result: 创建了首个专门用于拉丁语互文性检测的标准化基准，提供了可用于评估和开发新方法的数据集和基线结果。

Conclusion: Loci Similes基准填补了拉丁语互文性检测研究的数据集空白，为未来方法发展提供了基础，语言模型在该任务中展现出潜力。

Abstract: Tracing connections between historical texts is an important part of intertextual research, enabling scholars to reconstruct the virtual library of a writer and identify the sources influencing their creative process. These intertextual links manifest in diverse forms, ranging from direct verbatim quotations to subtle allusions and paraphrases disguised by morphological variation. Language models offer a promising path forward due to their capability of capturing semantic similarity beyond lexical overlap. However, the development of new methods for this task is held back by the scarcity of standardized benchmarks and easy-to-use datasets. We address this gap by introducing Loci Similes, a benchmark for Latin intertextuality detection comprising of a curated dataset of ~172k text segments containing 545 expert-verified parallels linking Late Antique authors to a corpus of classical authors. Using this data, we establish baselines for retrieval and classification of intertextualities with state-of-the-art LLMs.

</details>
