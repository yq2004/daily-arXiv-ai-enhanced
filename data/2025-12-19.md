<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 24]
- [cs.IR](#cs.IR) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [TabReX : Tabular Referenceless eXplainable Evaluation](https://arxiv.org/abs/2512.15907)
*Tejas Anvekar,Juhna Park,Aparna Garimella,Vivek Gupta*

Main category: cs.CL

TL;DR: TabReX是一个无参考、基于属性的表格生成评估框架，通过图推理评估LLM生成的表格质量，比现有方法更准确且可解释。


<details>
  <summary>Details</summary>
Motivation: 现有表格评估方法存在局限性：要么将表格扁平化为文本忽略结构信息，要么依赖固定参考限制了泛化能力。需要一种更准确、可解释的表格生成评估方法。

Method: TabReX将源文本和生成的表格转换为规范知识图，通过LLM引导的匹配过程对齐它们，并计算可解释的、基于规则的分数来量化结构和事实保真度。

Result: TabReX在专家排名相关性方面表现最佳，在更难的扰动下保持稳定，支持细粒度的模型与提示分析，为结构化生成系统提供了可信赖、可解释的评估新范式。

Conclusion: TabReX框架通过图推理方法实现了无参考、基于属性的表格生成评估，提供了可控的敏感度-特异性权衡，能够生成与人类判断一致的评估结果和单元格级错误追踪。

Abstract: Evaluating the quality of tables generated by large language models (LLMs) remains an open challenge: existing metrics either flatten tables into text, ignoring structure, or rely on fixed references that limit generalization. We present TabReX, a reference-less, property-driven framework for evaluating tabular generation via graph-based reasoning. TabReX converts both source text and generated tables into canonical knowledge graphs, aligns them through an LLM-guided matching process, and computes interpretable, rubric-aware scores that quantify structural and factual fidelity. The resulting metric provides controllable trade-offs between sensitivity and specificity, yielding human-aligned judgments and cell-level error traces. To systematically asses metric robustness, we introduce TabReX-Bench, a large-scale benchmark spanning six domains and twelve planner-driven perturbation types across three difficulty tiers. Empirical results show that TabReX achieves the highest correlation with expert rankings, remains stable under harder perturbations, and enables fine-grained model-vs-prompt analysis establishing a new paradigm for trustworthy, explainable evaluation of structured generation systems.

</details>


### [2] [Social Story Frames: Contextual Reasoning about Narrative Intent and Reception](https://arxiv.org/abs/2512.15925)
*Joel Mire,Maria Antoniak,Steven R. Wilson,Zexin Ma,Achyutarama R. Ganti,Andrew Piper,Maarten Sap*

Main category: cs.CL

TL;DR: 该研究提出了SocialStoryFrames框架，用于计算建模读者对故事的复杂反应，包括意图推断、情感响应和价值判断，并开发了相应模型，在社交媒体故事数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有计算模型无法捕捉读者对故事的丰富解释性、情感性和评价性反应，如对叙事意图的推断或对角色的判断，这限制了大规模故事分析的深度。

Method: 1. 提出SocialStoryFrames形式化框架，基于叙事理论、语言语用学和心理学构建读者反应分类法；2. 开发SSF-Generator和SSF-Classifier两个模型；3. 通过人类调查（382名参与者）和专家标注进行验证；4. 在SSF-Corpus数据集（6,140个社交媒体故事）上进行试点分析。

Result: 1. 模型在人类调查和专家标注中得到验证；2. 在社交媒体故事分析中，成功刻画了不同社区中故事意图的频率和相互依赖性；3. 比较并对比了不同社区的叙事实践及其多样性；4. 展示了该框架支持在线社区故事研究的新能力。

Conclusion: SocialStoryFrames通过将细粒度、上下文敏感的建模与通用的读者反应分类法相结合，为在线社区中的故事讲述研究开辟了新途径，实现了大规模故事分析的可能性。

Abstract: Reading stories evokes rich interpretive, affective, and evaluative responses, such as inferences about narrative intent or judgments about characters. Yet, computational models of reader response are limited, preventing nuanced analyses. To address this gap, we introduce SocialStoryFrames, a formalism for distilling plausible inferences about reader response, such as perceived author intent, explanatory and predictive reasoning, affective responses, and value judgments, using conversational context and a taxonomy grounded in narrative theory, linguistic pragmatics, and psychology. We develop two models, SSF-Generator and SSF-Classifier, validated through human surveys (N=382 participants) and expert annotations, respectively. We conduct pilot analyses to showcase the utility of the formalism for studying storytelling at scale. Specifically, applying our models to SSF-Corpus, a curated dataset of 6,140 social media stories from diverse contexts, we characterize the frequency and interdependence of storytelling intents, and we compare and contrast narrative practices (and their diversity) across communities. By linking fine-grained, context-sensitive modeling with a generic taxonomy of reader responses, SocialStoryFrames enable new research into storytelling in online communities.

</details>


### [3] [BRAID: Bounded Reasoning for Autonomous Inference and Decisions](https://arxiv.org/abs/2512.15959)
*Armağan Amcalar,Eyup Cinar*

Main category: cs.CL

TL;DR: BRAID框架通过结构化提示显著提升LLM推理准确性和成本效率


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在性能、成本和token使用之间存在非线性关系，当前推理方法通常依赖无限制的自然语言token扩展，效率较低

Method: 提出BRAID框架，使用Mermaid-based指令图实现有界推理，使模型能够进行结构化推理而非无限制的自然语言token扩展

Result: 在AdvancedIF、GSM-Hard和SCALE MultiChallenge基准测试中，结构化机器可读提示显著提高了推理准确性和成本效率

Conclusion: BRAID是一种有效且可扩展的技术，能够优化自主代理系统中的推理效率

Abstract: Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the AdvancedIF, GSM-Hard, and the SCALE MultiChallenge benchmark datasets. BRAID introduces a bounded reasoning framework using Mermaid-based instruction graphs that enable models to reason struc turally rather than through unbounded natural-language token expansion. We show that structured machine-readable prompts substantially increase reasoning accuracy and cost efficiency for agents in production systems. The findings establish BRAID as an effective and scalable technique for optimizing inference efficiency in autonomous agent systems. All datasets and detailed result logs are available at https://benchmark.openserv.ai.

</details>


### [4] [From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs](https://arxiv.org/abs/2512.16795)
*Shubham Mishra,Samyek Jain,Gorang Mehrishi,Shiv Tiwari,Harsh Sharma,Pratik Narang,Dhruv Kumar*

Main category: cs.CL

TL;DR: 提出推理轨迹增强的RAG框架，通过三阶段结构化推理解决检索信息冲突、过时或主观问题，显著提升答案正确性和行为一致性。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统在处理检索到的冲突、过时或主观信息时表现不佳，现有工作缺乏统一的推理监督机制，需要更好的解决方案。

Method: 提出推理轨迹增强的RAG框架，包含文档级裁决、冲突分析和基于证据的合成三阶段结构化推理，并引入冲突感知信任分数（CATS）评估管道。

Result: 实验显示该方法显著优于基线，特别是在Qwen模型上，监督微调使端到端答案正确率从0.069提升到0.883，行为一致性从0.074提升到0.722。

Conclusion: 该框架为冲突感知、可解释的RAG系统奠定了基础，通过结构化推理和评估管道有效解决了检索信息质量问题。

Abstract: Retrieval-Augmented Generation (RAG) grounds large language models (LLMs) in external evidence, but fails when retrieved sources conflict or contain outdated or subjective information. Prior work address these issues independently but lack unified reasoning supervision. We propose a reasoning-trace-augmented RAG framework that adds structured, interpretable reasoning across three stages : (1) document-level adjudication, (2) conflict analysis, and (3) grounded synthesis, producing citation-linked answers or justified refusals. A Conflict-Aware Trust-Score (CATS) pipeline is introduced which evaluates groundedness, factual correctness, refusal accuracy, and conflict-behavior alignment using an LLM-as-a-Judge. Our 539-query reasoning dataset and evaluation pipeline establish a foundation for conflict-aware, interpretable RAG systems. Experimental results demonstrate substantial gains over baselines, most notably with Qwen, where Supervised Fine-Tuning improved End-to-End answer correctness from 0.069 to 0.883 and behavioral adherence from 0.074 to 0.722.

</details>


### [5] [Examining the Utility of Self-disclosure Types for Modeling Annotators of Social Norms](https://arxiv.org/abs/2512.16034)
*Kieran Henderson,Kian Omoomi,Vasudha Varadarajan,Allison Lahnala,Charles Welch*

Main category: cs.CL

TL;DR: 通过分类自我披露信息并构建标注者模型，研究发现人口统计信息比态度、关系和经历对预测社会规范判断更有效，理论方法优于自动聚类，少量相关评论即可，多样性样本表现最佳。


<details>
  <summary>Details</summary>
Motivation: 以往研究使用个人信息（如人物描述或自我披露）来改进个体特征建模和主观任务标注预测，但信息量有限，缺乏对何种信息最有效的深入探索。本研究旨在探究不同类型自我披露信息对预测标注者社会规范判断的影响。

Method: 对自我披露句子进行分类，构建标注者模型预测社会规范判断。通过多种消融实验和分析，检验不同类型信息对预测标注模式的影响。

Result: 人口统计信息比态度、关系和经历更具影响力；理论方法优于自动聚类；与先前研究不同，仅需少量相关评论即可；拥有更多样化的标注者自我披露样本能获得最佳性能。

Conclusion: 研究揭示了在预测社会规范标注时，不同类型自我披露信息的相对重要性，强调了人口统计信息的核心作用、理论方法的有效性、信息效率以及样本多样性的价值，为未来个性化标注建模提供了重要指导。

Abstract: Recent work has explored the use of personal information in the form of persona sentences or self-disclosures to improve modeling of individual characteristics and prediction of annotator labels for subjective tasks. The volume of personal information has historically been restricted and thus little exploration has gone into understanding what kind of information is most informative for predicting annotator labels. In this work, we categorize self-disclosure sentences and use them to build annotator models for predicting judgments of social norms. We perform several ablations and analyses to examine the impact of the type of information on our ability to predict annotation patterns. We find that demographics are more impactful than attitudes, relationships, and experiences. Generally, theory-based approaches worked better than automatic clusters. Contrary to previous work, only a small number of related comments are needed. Lastly, having a more diverse sample of annotator self-disclosures leads to the best performance.

</details>


### [6] [Are We on the Right Way to Assessing LLM-as-a-Judge?](https://arxiv.org/abs/2512.16041)
*Yuanning Feng,Sinan Wang,Zhengxiang Cheng,Yao Wan,Dongping Chen*

Main category: cs.CL

TL;DR: Sage是一个无需人工标注的LLM-as-a-Judge评估套件，通过局部自一致性和全局逻辑一致性来评估LLM法官的可靠性，发现当前顶尖LLM在近四分之一困难案例中存在显著一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-Judge评估基准依赖人工标注，这引入了人类偏见，限制了评估的可扩展性和可靠性。需要一种无需人工标注的方法来评估LLM法官的质量。

Method: 基于理性选择理论，提出两个评估维度：局部自一致性（成对偏好稳定性）和全局逻辑一致性（跨完整偏好集的传递性）。构建包含650个问题的数据集，结合结构化基准问题和真实用户查询。

Result: Sage的指标具有稳定性，且与LLMBar和RewardBench2等监督基准高度相关。实验发现当前最先进的LLM（包括Gemini-2.5-Pro和GPT-5）在近四分之一困难案例中无法保持一致的偏好。发现了"情境偏好"现象，并验证了微调LLM法官、小组法官和深度推理可以提升一致性。

Conclusion: Sage为LLM-as-a-Judge提供了无需人工标注的可靠评估框架，揭示了当前LLM法官的显著一致性问题，并发现人类标注本身也存在不一致性，表明其可能不是可靠的金标准。

Abstract: LLM-as-a-Judge has been widely adopted as an evaluation method and served as supervised rewards in model training. However, existing benchmarks for LLM-as-a-Judge are mainly relying on human-annotated ground truth, which introduces human bias that undermines the assessment of reliability and imposes scalability constraints. To overcome these limitations, we introduce Sage, a novel evaluation suite that assesses the quality of LLM judges without necessitating any human annotation. Inspired by axioms of rational choice theory, Sage introduces two new lenses for measuring LLM-as-a-Judge: local self-consistency (pair-wise preference stability) and global logical consistency (transitivity across a full set of preferences). We curate a dataset of 650 questions by combining structured benchmark problems with real-world user queries. Our experiments demonstrate both the stability of our metrics and their high correlation with supervised benchmarks like LLMBar and RewardBench2, confirming Sage's reliability as an evaluation suite for the robustness and accuracy of LLM-as-a-Judge. Based on Sage, we reveal that current state-of-the-art LLMs exhibit significant reliability problems when acting as judges in both scoring and pairwise settings; even the top-performing models, Gemini-2.5-Pro and GPT-5, fail to maintain consistent preferences in nearly a quarter of difficult cases. We attribute this to a new phenomenon called situational preference, which explains why explicit rubrics or criteria can help the model judge consistently across answer pairs. Our further analysis shows that finetuned LLM-as-a-Judge is a feasible method to boost performance, and the panel-based judge as well as deep reasoning can enhance the judging consistency. We also find substantial inconsistency in human judgments, which indicates that human annotation may not be a reliable gold standard.

</details>


### [7] [Convolutional Lie Operator for Sentence Classification](https://arxiv.org/abs/2512.16125)
*Daniela N. Rim,Heeyoul Choi*

Main category: cs.CL

TL;DR: 将李卷积集成到基于卷积的句子分类器中，通过捕捉语言中的复杂非欧几里得对称性来提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统CNN在捕捉文本局部特征方面成功，但对语言中复杂变换的建模能力有待进一步探索。李群操作能捕捉复杂的非欧几里得对称性，这为语言建模提供了新思路。

Method: 提出SCLie和DPCLie模型，将李卷积集成到基于卷积的句子分类器中，利用李群操作捕捉语言中的复杂变换。

Result: SCLie和DPCLie模型在实验上优于传统的基于卷积的句子分类器，表明李基模型通过捕捉语言中不常见的变换相对提高了准确性。

Conclusion: 李卷积为语言建模提供了有前景的新范式，研究结果激励进一步探索语言建模的新方法。

Abstract: Traditional Convolutional Neural Networks have been successful in capturing local, position-invariant features in text, but their capacity to model complex transformation within language can be further explored. In this work, we explore a novel approach by integrating Lie Convolutions into Convolutional-based sentence classifiers, inspired by the ability of Lie group operations to capture complex, non-Euclidean symmetries. Our proposed models SCLie and DPCLie empirically outperform traditional Convolutional-based sentence classifiers, suggesting that Lie-based models relatively improve the accuracy by capturing transformations not commonly associated with language. Our findings motivate more exploration of new paradigms in language modeling.

</details>


### [8] [MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation](https://arxiv.org/abs/2512.16145)
*Pengyu Wang,Shuchang Ye,Usman Naseem,Jinman Kim*

Main category: cs.CL

TL;DR: 提出语义驱动的强化学习方法MRG-R1，通过报告级奖励优化医学报告生成的临床正确性，而非传统词级监督。


<details>
  <summary>Details</summary>
Motivation: 现有医学报告生成方法虽然能模仿放射科医生的语言风格，但无法保证临床正确性，因为传统训练基于词级目标，关注词汇选择和句子结构而非实际医学准确性。

Method: 提出语义驱动的强化学习方法，采用组相对策略优化来超越语言风格模仿，优化报告级奖励：基于关键放射学发现的边缘余弦相似度，直接对齐临床标签一致性。同时引入轻量级推理格式约束，引导模型生成结构化的"思考报告"输出。

Result: 在IU X-Ray和MIMIC-CXR数据集上，MRG-R1实现了最先进的性能：CE-F1分别为51.88和40.39。结果表明标签语义强化优于传统的词级监督。

Conclusion: 优化基于临床的报告级奖励而非词级重叠，能显著提高临床正确性。这是探索语义强化监督医学大型视觉语言模型训练中医学正确性的先驱工作。

Abstract: Medical report generation (MRG) aims to automatically derive radiology-style reports from medical images to aid in clinical decision-making. However, existing methods often generate text that mimics the linguistic style of radiologists but fails to guarantee clinical correctness, because they are trained on token-level objectives which focus on word-choice and sentence structure rather than actual medical accuracy. We propose a semantic-driven reinforcement learning (SRL) method for medical report generation, adopted on a large vision-language model (LVLM). SRL adopts Group Relative Policy Optimization (GRPO) to encourage clinical-correctness-guided learning beyond imitation of language style. Specifically, we optimise a report-level reward: a margin-based cosine similarity (MCCS) computed between key radiological findings extracted from generated and reference reports, thereby directly aligning clinical-label agreement and improving semantic correctness. A lightweight reasoning format constraint further guides the model to generate structured "thinking report" outputs. We evaluate Medical Report Generation with Sematic-driven Reinforment Learning (MRG-R1), on two datasets: IU X-Ray and MIMIC-CXR using clinical efficacy (CE) metrics. MRG-R1 achieves state-of-the-art performance with CE-F1 51.88 on IU X-Ray and 40.39 on MIMIC-CXR. We found that the label-semantic reinforcement is better than conventional token-level supervision. These results indicate that optimizing a clinically grounded, report-level reward rather than token overlap,meaningfully improves clinical correctness. This work is a prior to explore semantic-reinforcement in supervising medical correctness in medical Large vision-language model(Med-LVLM) training.

</details>


### [9] [Decoding Fake Narratives in Spreading Hateful Stories: A Dual-Head RoBERTa Model with Multi-Task Learning](https://arxiv.org/abs/2512.16147)
*Yash Bhaskar,Sankalp Bahad,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 该论文介绍了一个用于检测印地语-英语混合社交媒体文本中由虚假叙事驱动的仇恨言论的系统，在Faux-Hate共享任务中取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台虽然促进了全球连接，但也成为了有害内容（包括仇恨言论和虚假叙事）快速传播的中心。需要检测一种特定现象：由虚假叙事驱动的仇恨言论生成，称为"Faux-Hate"。

Method: 结合先进的自然语言处理技术与领域特定的预训练方法，采用多任务学习框架来处理两个子任务：二元Faux-Hate检测（虚假和仇恨言论分类）以及目标和严重性预测。

Result: 系统在两个子任务上都取得了有竞争力的结果，证明了多任务学习在这种复杂问题上的有效性。

Conclusion: 该系统展示了利用多任务学习和领域特定预训练来检测由虚假叙事驱动的仇恨言论的可行性，为解决社交媒体上的有害内容传播问题提供了有效方法。

Abstract: Social media platforms, while enabling global connectivity, have become hubs for the rapid spread of harmful content, including hate speech and fake narratives \cite{davidson2017automated, shu2017fake}. The Faux-Hate shared task focuses on detecting a specific phenomenon: the generation of hate speech driven by fake narratives, termed Faux-Hate. Participants are challenged to identify such instances in code-mixed Hindi-English social media text. This paper describes our system developed for the shared task, addressing two primary sub-tasks: (a) Binary Faux-Hate detection, involving fake and hate speech classification, and (b) Target and Severity prediction, categorizing the intended target and severity of hateful content. Our approach combines advanced natural language processing techniques with domain-specific pretraining to enhance performance across both tasks. The system achieved competitive results, demonstrating the efficacy of leveraging multi-task learning for this complex problem.

</details>


### [10] [A Domain-Adapted Pipeline for Structured Information Extraction from Police Incident Announcements on Social Media](https://arxiv.org/abs/2512.16183)
*Mengfan Shen,Kangqi Song,Xindi Wang,Wei Jia,Tao Wang,Ziqiang Han*

Main category: cs.CL

TL;DR: 基于Qwen2.5-7B模型，通过LoRA微调和提示工程，构建了一个从微博警情通报中提取15个关键字段的信息抽取管道，在噪声文本上实现了高精度提取。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的警情通报文本具有多样性和非正式性，传统方法难以准确提取结构化信息，需要专门针对噪声文本的解决方案。

Method: 使用LoRA参数高效微调Qwen2.5-7B模型，结合针对性的提示工程，从27,822条微博警情通报中构建4,933条人工标注数据集，提取15个关键字段。

Result: LoRA微调显著优于基础模型和指令微调模型，死亡率检测准确率超过98.36%，死亡人数精确匹配率达95.31%，省级位置提取精确匹配率达95.54%。

Conclusion: 该管道为专业领域多任务结构化信息抽取提供了验证有效的解决方案，能将非结构化文本转化为社会科学研究中的可靠结构化数据。

Abstract: Structured information extraction from police incident announcements is crucial for timely and accurate data processing, yet presents considerable challenges due to the variability and informal nature of textual sources such as social media posts. To address these challenges, we developed a domain-adapted extraction pipeline that leverages targeted prompt engineering with parameter-efficient fine-tuning of the Qwen2.5-7B model using Low-Rank Adaptation (LoRA). This approach enables the model to handle noisy, heterogeneous text while reliably extracting 15 key fields, including location, event characteristics, and impact assessment, from a high-quality, manually annotated dataset of 4,933 instances derived from 27,822 police briefing posts on Chinese Weibo (2019-2020). Experimental results demonstrated that LoRA-based fine-tuning significantly improved performance over both the base and instruction-tuned models, achieving an accuracy exceeding 98.36% for mortality detection and Exact Match Rates of 95.31% for fatality counts and 95.54% for province-level location extraction. The proposed pipeline thus provides a validated and efficient solution for multi-task structured information extraction in specialized domains, offering a practical framework for transforming unstructured text into reliable structured data in social science research.

</details>


### [11] [Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation](https://arxiv.org/abs/2512.16189)
*Musarrat Zeba,Abdullah Al Mamun,Kishoar Jahan Tithee,Debopom Sutradhar,Mohaimenul Azam Khan Raiaan,Saddam Mukta,Reem E. Mohamed,Md Rafiqul Islam,Yakub Sebastian,Mukhtar Hussain,Sami Azam*

Main category: cs.CL

TL;DR: 该研究提出一个用于医疗领域的事实核查模块和领域特定摘要模型，以减少LLM幻觉，通过LoRa微调MIMIC III数据集，实现高精度的事实核查和摘要质量。


<details>
  <summary>Details</summary>
Motivation: 医疗领域LLM生成的输出需要高度可靠和准确，特别是在决策和患者安全方面，但当前LLM存在幻觉输出风险，需要解决这一问题。

Method: 提出独立于LLM的事实核查模块和领域特定摘要模型。使用LoRa在MIMIC III数据集上微调模型，事实核查模块通过数值测试和自然语言处理中的离散逻辑进行细粒度逻辑检查，验证事实与电子健康记录的一致性。

Result: 事实核查模块在3,786个命题上达到精度0.8904、召回率0.8234、F1分数0.8556；LLM摘要模型在摘要质量上获得ROUGE-1分数0.5797和BERTScore 0.9120。

Conclusion: 提出的方法能有效减少医疗领域LLM幻觉，提高输出可靠性，事实核查模块和摘要模型的结合为医疗决策提供了更安全可靠的支持。

Abstract: In healthcare, it is essential for any LLM-generated output to be reliable and accurate, particularly in cases involving decision-making and patient safety. However, the outputs are often unreliable in such critical areas due to the risk of hallucinated outputs from the LLMs. To address this issue, we propose a fact-checking module that operates independently of any LLM, along with a domain-specific summarization model designed to minimize hallucination rates. Our model is fine-tuned using Low-Rank Adaptation (LoRa) on the MIMIC III dataset and is paired with the fact-checking module, which uses numerical tests for correctness and logical checks at a granular level through discrete logic in natural language processing (NLP) to validate facts against electronic health records (EHRs). We trained the LLM model on the full MIMIC-III dataset. For evaluation of the fact-checking module, we sampled 104 summaries, extracted them into 3,786 propositions, and used these as facts. The fact-checking module achieves a precision of 0.8904, a recall of 0.8234, and an F1-score of 0.8556. Additionally, the LLM summary model achieves a ROUGE-1 score of 0.5797 and a BERTScore of 0.9120 for summary quality.

</details>


### [12] [An Information-Theoretic Framework for Robust Large Language Model Editing](https://arxiv.org/abs/2512.16227)
*Qizhou Chen,Chengyu Wang,Taolin Zhang,Xiaofeng He*

Main category: cs.CL

TL;DR: IBKE：基于信息瓶颈理论的新LLM知识编辑框架，通过紧凑潜在表征实现可泛化、高精度的模型更新


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型知识更新面临两大挑战：1）完全重训练成本高且破坏性强；2）现有编辑方法泛化能力有限，容易产生意外后果，限制了实际应用

Method: 提出基于信息瓶颈理论的编辑框架，压缩并隔离知识修正所需的关键信息，最小化对无关模型行为的影响。具体实现IBKE方法，利用紧凑潜在表征指导基于梯度的更新

Result: 在多种LLM架构和标准基准任务上验证，IBKE实现了最先进的准确性，并显著提升了编辑的泛化性和特异性

Conclusion: IBKE为开放领域知识编辑建立了理论基础和实践范式，提高了LLM在实际应用中的实用性和可信度

Abstract: Large Language Models (LLMs) have become indispensable tools in science, technology, and society, enabling transformative advances across diverse fields. However, errors or outdated information within these models can undermine their accuracy and restrict their safe deployment. Developing efficient strategies for updating model knowledge without the expense and disruption of full retraining remains a critical challenge. Current model editing techniques frequently struggle to generalize corrections beyond narrow domains, leading to unintended consequences and limiting their practical impact. Here, we introduce a novel framework for editing LLMs, grounded in information bottleneck theory. This approach precisely compresses and isolates the essential information required for generalizable knowledge correction while minimizing disruption to unrelated model behaviors. Building upon this foundation, we present the Information Bottleneck Knowledge Editor (IBKE), which leverages compact latent representations to guide gradient-based updates, enabling robust and broadly applicable model editing. We validate IBKE's effectiveness across multiple LLM architectures and standard benchmark tasks, demonstrating state-of-the-art accuracy and improved generality and specificity of edits. These findings establish a theoretically principled and practical paradigm for open-domain knowledge editing, advancing the utility and trustworthiness of LLMs in real-world applications.

</details>


### [13] [LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding](https://arxiv.org/abs/2512.16229)
*Chenkai Xu,Yijie Jin,Jiajun Li,Yi Tu,Guoping Long,Dandan Tu,Tianqi Hou,Junchi Yan,Zhijie Deng*

Main category: cs.CL

TL;DR: LoPA是一种无需训练、即插即用的算法，通过优化Token填充顺序显著提升扩散大语言模型的并行推理速度，将D2F-Dream模型的每前向传递令牌数提升至10.1，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 当前扩散大语言模型的置信度驱动解码策略并行性有限，通常每前向传递只能生成1-3个令牌，限制了推理速度的提升。

Method: 提出LoPA算法，通过并行分支探索不同的候选Token填充顺序，基于分支置信度选择具有最高未来并行潜力的顺序，并开发了支持分支并行的多设备推理系统。

Result: 在D2F模型上应用LoPA后，D2F-Dream在GSM8K数据集上的每前向传递令牌数提升至10.1，性能优于Dream基线，多GPU部署下单样本吞吐量达到1073.9令牌/秒。

Conclusion: LoPA通过优化Token填充顺序有效提升了扩散大语言模型的推理并行性，实现了显著的加速效果，为高效推理提供了新思路。

Abstract: Diffusion Large Language Models (dLLMs) have demonstrated significant potential for high-speed inference. However, current confidence-driven decoding strategies are constrained by limited parallelism, typically achieving only 1--3 tokens per forward pass (TPF). In this work, we identify that the degree of parallelism during dLLM inference is highly sensitive to the Token Filling Order (TFO). Then, we introduce Lookahead PArallel Decoding LoPA, a training-free, plug-and-play algorithm, to identify a superior TFO and hence accelerate inference. LoPA concurrently explores distinct candidate TFOs via parallel branches, and selects the one with the highest potential for future parallelism based on branch confidence. We apply LoPA to the state-of-the-art D2F model and observe a substantial enhancement in decoding efficiency. Notably, LoPA increases the TPF of D2F-Dream to 10.1 on the GSM8K while maintaining performance superior to the Dream baseline. Furthermore, to facilitate this unprecedented degree of parallelism, we develop a specialized multi-device inference system featuring Branch Parallelism (BP), which achieves a single-sample throughput of 1073.9 tokens per second under multi-GPU deployment. The code is available at https://github.com/zhijie-group/LoPA.

</details>


### [14] [Sigma-Moe-Tiny Technical Report](https://arxiv.org/abs/2512.16248)
*Qingguo Hu,Zhenghao Lin,Ziyue Yang,Yucheng Ding,Xiao Liu,Yuting Jiang,Ruizhe Wang,Tianyu Chen,Zhongxin Guo,Yifan Xiong,Rui Gao,Lei Qu,Jinsong Su,Peng Cheng,Yeyun Gong*

Main category: cs.CL

TL;DR: Sigma-MoE-Tiny 是一个极度稀疏的混合专家语言模型，在每层使用最多96个专家但每个token只激活一个专家，总参数200亿但仅激活5亿，在保持训练稳定的同时实现了顶尖性能。


<details>
  <summary>Details</summary>
Motivation: 混合专家模型因其高效可扩展性成为基础模型的有前景范式，但现有开源模型在稀疏度方面仍有提升空间。本文旨在探索更高稀疏度的MoE模型，同时解决由此带来的专家负载均衡挑战。

Method: 1. 采用细粒度专家分割，每层最多96个专家，每个token只激活一个专家；2. 提出渐进稀疏化调度策略解决深度稀疏下的专家负载均衡问题；3. 在多样化高质量语料上进行预训练，随后进行后训练；4. 提供对高度稀疏MoE模型中负载均衡的深入分析。

Result: 1. 实现了当前开源模型中最高的稀疏度（200亿总参数，仅激活5亿）；2. 训练过程异常稳定，未出现不可恢复的损失尖峰；3. 在仅激活5亿参数的情况下，在同等规模或更大规模模型中实现了顶尖性能；4. 提供了高度稀疏MoE模型负载平衡的深入见解。

Conclusion: Sigma-MoE-Tiny展示了在保持训练稳定性的前提下实现极高稀疏度的可行性，为未来MoE架构的稀疏化发展提供了有价值的见解和方法。该模型在性能与效率之间取得了良好平衡，为大规模语言模型的资源高效部署提供了新思路。

Abstract: Mixture-of-Experts (MoE) has emerged as a promising paradigm for foundation models due to its efficient and powerful scalability. In this work, we present Sigma-MoE-Tiny, an MoE language model that achieves the highest sparsity compared to existing open-source models. Sigma-MoE-Tiny employs fine-grained expert segmentation with up to 96 experts per layer, while activating only one expert for each token, resulting in 20B total parameters with just 0.5B activated. The major challenge introduced by such extreme sparsity lies in expert load balancing. We find that the widely-used load balancing loss tends to become ineffective in the lower layers under this setting. To address this issue, we propose a progressive sparsification schedule aiming to balance expert utilization and training stability. Sigma-MoE-Tiny is pre-trained on a diverse and high-quality corpus, followed by post-training to further unlock its capabilities. The entire training process remains remarkably stable, with no occurrence of irrecoverable loss spikes. Comprehensive evaluations reveal that, despite activating only 0.5B parameters, Sigma-MoE-Tiny achieves top-tier performance among counterparts of comparable or significantly larger scale. In addition, we provide an in-depth discussion of load balancing in highly sparse MoE models, offering insights for advancing sparsity in future MoE architectures.
  Project page: https://qghuxmu.github.io/Sigma-MoE-Tiny
  Code: https://github.com/microsoft/ltp-megatron-lm

</details>


### [15] [Evaluating OpenAI GPT Models for Translation of Endangered Uralic Languages: A Comparison of Reasoning and Non-Reasoning Architectures](https://arxiv.org/abs/2512.16287)
*Yehor Tereshchenko,Mika Hämäläinen,Svitlana Myroniuk*

Main category: cs.CL

TL;DR: 本研究比较了OpenAI GPT模型在芬兰语与四种低资源乌拉尔语（科米-兹良语、莫克沙语、埃尔齐亚语、乌德穆尔特语）翻译任务中推理与非推理架构的性能差异，发现推理模型拒绝翻译率降低16个百分点。


<details>
  <summary>Details</summary>
Motivation: 当前LLM翻译评估主要关注高资源语言，对低资源和濒危语言的性能了解存在显著空白，需要填补这一研究缺口。

Method: 使用文学文本平行语料库，分析OpenAI GPT模型在芬兰语与四种低资源乌拉尔语翻译任务中的拒绝率，比较推理与非推理架构的差异。

Result: 推理模型相比非推理模型表现出16个百分点的拒绝率降低，显示推理架构在低资源语言翻译任务中具有明显优势。

Conclusion: 研究为乌拉尔语研究者和实践者提供了宝贵见解，并推进了对推理模型在濒危语言保护中能力的理解，强调需要专门评估低资源语言翻译性能。

Abstract: The evaluation of Large Language Models (LLMs) for translation tasks has primarily focused on high-resource languages, leaving a significant gap in understanding their performance on low-resource and endangered languages. This study presents a comprehensive comparison of OpenAI's GPT models, specifically examining the differences between reasoning and non-reasoning architectures for translating between Finnish and four low-resource Uralic languages: Komi-Zyrian, Moksha, Erzya, and Udmurt. Using a parallel corpus of literary texts, we evaluate model willingness to attempt translation through refusal rate analysis across different model architectures. Our findings reveal significant performance variations between reasoning and non-reasoning models, with reasoning models showing 16 percentage points lower refusal rates. The results provide valuable insights for researchers and practitioners working with Uralic languages and contribute to the broader understanding of reasoning model capabilities for endangered language preservation.

</details>


### [16] [Hacking Neural Evaluation Metrics with Single Hub Text](https://arxiv.org/abs/2512.16323)
*Hiroyuki Deguchi,Katsuki Chousa,Yusuke Sakai*

Main category: cs.CL

TL;DR: 本文提出了一种方法，通过寻找单个对抗性文本（hub text）来暴露基于嵌入的神经文本评估指标（如COMET）的脆弱性，该文本无论测试用例如何都被一致评估为高质量，从而揭示评估指标的可信度问题。


<details>
  <summary>Details</summary>
Motivation: 尽管基于嵌入的神经文本评估指标（如COMET）在机器翻译等领域被广泛使用，但由于神经网络的"黑箱"特性，无法保证这些指标能提供可靠和稳健的评估结果。作者担心这类评估指标的可信度和安全性，因此需要揭示其潜在的脆弱性。

Method: 作者提出了一种在离散空间中寻找单个对抗性文本（hub text）的方法。这个文本无论面对何种测试用例，都能被评估指标一致地判定为高质量翻译。该方法旨在系统性地识别评估指标的漏洞。

Result: 在WMT'24的英日（En-Ja）和英德（En-De）翻译任务中，通过该方法找到的hub text分别获得了79.1%和67.8%的COMET分数，甚至超过了使用通用翻译模型M2M100为每个源句子单独生成的翻译质量。此外，该方法找到的hub text在多个语言对（如日英Ja-En和德英De-En）上也具有泛化性。

Conclusion: 该研究成功揭示了基于嵌入的神经文本评估指标（如COMET）存在严重的脆弱性，一个精心构造的对抗性文本就能被错误地一致评估为高质量翻译。这引发了对当前广泛使用的评估指标可信度和安全性的重大担忧，强调了需要更可靠和稳健的评估方法。

Abstract: Strongly human-correlated evaluation metrics serve as an essential compass for the development and improvement of generation models and must be highly reliable and robust. Recent embedding-based neural text evaluation metrics, such as COMET for translation tasks, are widely used in both research and development fields. However, there is no guarantee that they yield reliable evaluation results due to the black-box nature of neural networks. To raise concerns about the reliability and safety of such metrics, we propose a method for finding a single adversarial text in the discrete space that is consistently evaluated as high-quality, regardless of the test cases, to identify the vulnerabilities in evaluation metrics. The single hub text found with our method achieved 79.1 COMET% and 67.8 COMET% in the WMT'24 English-to-Japanese (En--Ja) and English-to-German (En--De) translation tasks, respectively, outperforming translations generated individually for each source sentence by using M2M100, a general translation model. Furthermore, we also confirmed that the hub text found with our method generalizes across multiple language pairs such as Ja--En and De--En.

</details>


### [17] [Hearing to Translate: The Effectiveness of Speech Modality Integration into LLMs](https://arxiv.org/abs/2512.16378)
*Sara Papi,Javier Garcia Gilabert,Zachary Hopton,Vilém Zouhar,Carlos Escolano,Gerard I. Gállego,Jorge Iranzo-Sánchez,Ahrii Kim,Dominik Macháček,Patricia Schmidtova,Maike Züfle*

Main category: cs.CL

TL;DR: 该研究首次全面评估了5种先进SpeechLLM与16种直接/级联系统在语音翻译任务上的性能，发现级联系统整体最可靠，SpeechLLM仅在特定场景下能匹配级联系统，而语音基础模型表现最差。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型扩展到多模态，将语音作为原生模态集成的SpeechLLM可以直接翻译口语，绕过传统的转录-翻译级联流程。但这种方式是否真的比成熟的级联架构提升语音到文本的翻译质量，仍是一个开放性问题。

Method: 研究提出了"Hearing to Translate"测试套件，首次系统性地对5种最先进的SpeechLLM与16种强大的直接和级联系统进行基准测试。这些级联系统结合了领先的语音基础模型和多语言大语言模型。评估覆盖16个基准测试、13种语言对和9种具有挑战性的条件（包括不流利、嘈杂和长语音）。

Result: 在广泛的评估中，级联系统整体上仍然是最可靠的。当前的SpeechLLM仅在特定设置下能与级联系统相匹配。语音基础模型的表现落后于前两者，这突显了无论是将LLM集成到模型中还是作为流程的一部分，对于实现高质量语音翻译都是至关重要的。

Conclusion: 研究表明，虽然SpeechLLM作为新兴技术具有潜力，但成熟的级联架构在语音翻译任务中仍然保持整体优势。集成大语言模型（无论是内部集成还是作为流程的一部分）对获得高质量的语音翻译结果至关重要，而单纯的语音基础模型无法达到相同的性能水平。

Abstract: As Large Language Models (LLMs) expand beyond text, integrating speech as a native modality has given rise to SpeechLLMs, which aim to translate spoken language directly, thereby bypassing traditional transcription-based pipelines. Whether this integration improves speech-to-text translation quality over established cascaded architectures, however, remains an open question. We present Hearing to Translate, the first comprehensive test suite rigorously benchmarking 5 state-of-the-art SpeechLLMs against 16 strong direct and cascade systems that couple leading speech foundation models (SFM), with multilingual LLMs. Our analysis spans 16 benchmarks, 13 language pairs, and 9 challenging conditions, including disfluent, noisy, and long-form speech. Across this extensive evaluation, we find that cascaded systems remain the most reliable overall, while current SpeechLLMs only match cascades in selected settings and SFMs lag behind both, highlighting that integrating an LLM, either within the model or in a pipeline, is essential for high-quality speech translation.

</details>


### [18] [Bridging the Reality Gap: Efficient Adaptation of ASR systems for Challenging Low-Resource Domains](https://arxiv.org/abs/2512.16401)
*Darshil Chauhan,Adityasinh Solanki,Vansh Patel,Kanav Kapoor,Ritvik Jain,Aditya Bansal,Dhruv Kumar,Prateek Narang*

Main category: cs.CL

TL;DR: 提出了一种高效、保护隐私的语音识别自适应框架，用于解决临床环境中的技术障碍，在边缘设备上实现持续学习，显著降低了词错误率并减少了灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别在临床文档记录中具有巨大潜力，但面临数据隐私限制、计算资源有限和声学领域偏移等技术障碍。现有模型在真实临床音频上的词错误率高达40.94%，无法实际应用。

Method: 提出基于低秩自适应（LoRA）的高效隐私保护自适应框架，在边缘设备上实现从数据流的持续学习，并结合多领域经验回放来减少灾难性遗忘。

Result: 目标领域的词错误率相对改善了17.1%，与朴素自适应相比，灾难性遗忘减少了47%。

Conclusion: 该研究展示了一条可行路径，可以在高影响力的真实环境中构建可靠、自我改进的语音识别系统，满足资源受限环境的需求。

Abstract: Automatic Speech Recognition (ASR) holds immense potential to streamline clinical documentation, such as digitizing handwritten prescriptions and reports, thereby increasing patient throughput and reducing costs in resource-constrained sectors like rural healthcare. However, realizing this utility is currently obstructed by significant technical barriers: strict data privacy constraints, limited computational resources, and severe acoustic domain shifts. We quantify this gap by showing that a robust multilingual model (IndicWav2Vec) degrades to a stark 40.94% Word Error Rate (WER) when deployed on real-world clinical audio (Gram Vaani), rendering it unusable for practical applications. To address these challenges and bring ASR closer to deployment, we propose an efficient, privacy-preserving adaptation framework. We employ Low-Rank Adaptation (LoRA) to enable continual learning from incoming data streams directly on edge devices, ensuring patient data confidentiality. Our strategy yields a 17.1% relative improvement in WER on the target domain. Furthermore, by integrating multi-domain experience replay, we reduce catastrophic forgetting by 47% compared to naive adaptation. These results demonstrate a viable pathway for building reliable, self-improving ASR systems that can operate effectively within the constraints of high-impact real-world environments.

</details>


### [19] [Plain language adaptations of biomedical text using LLMs: Comparision of evaluation metrics](https://arxiv.org/abs/2512.16530)
*Primoz Kocbek,Leon Kopitar,Gregor Stiglic*

Main category: cs.CL

TL;DR: 本研究探索使用大型语言模型简化生物医学文本以提高健康素养，比较了提示模板、双AI代理和微调三种方法，发现gpt-4o-mini表现最佳，微调方法表现欠佳。


<details>
  <summary>Details</summary>
Motivation: 提高健康素养需要将复杂的生物医学文本简化为易于理解的语言，大型语言模型为此提供了潜在解决方案。

Method: 使用公开数据集（包含生物医学摘要的通俗语言改编版），开发并评估了三种方法：基于提示模板的基线方法、双AI代理方法和微调方法，使用OpenAI的gpt-4o和gpt-4o-mini模型作为基准。

Result: gpt-4o-mini表现最佳，微调方法表现最差。基于LLM的定量评估指标G-Eval与定性指标（5点李克特量表）对方法排名的结果一致。

Conclusion: 大型语言模型可以有效简化生物医学文本，gpt-4o-mini表现优异，微调方法需要改进。G-Eval作为评估指标显示出潜力。

Abstract: This study investigated the application of Large Language Models (LLMs) for simplifying biomedical texts to enhance health literacy. Using a public dataset, which included plain language adaptations of biomedical abstracts, we developed and evaluated several approaches, specifically a baseline approach using a prompt template, a two AI agent approach, and a fine-tuning approach. We selected OpenAI gpt-4o and gpt-4o mini models as baselines for further research. We evaluated our approaches with quantitative metrics, such as Flesch-Kincaid grade level, SMOG Index, SARI, and BERTScore, G-Eval, as well as with qualitative metric, more precisely 5-point Likert scales for simplicity, accuracy, completeness, brevity. Results showed a superior performance of gpt-4o-mini and an underperformance of FT approaches. G-Eval, a LLM based quantitative metric, showed promising results, ranking the approaches similarly as the qualitative metric.

</details>


### [20] [UM_FHS at the CLEF 2025 SimpleText Track: Comparing No-Context and Fine-Tune Approaches for GPT-4.1 Models in Sentence and Document-Level Text Simplification](https://arxiv.org/abs/2512.16541)
*Primoz Kocbek,Gregor Stiglic*

Main category: cs.CL

TL;DR: 在CLEF 2025 SimpleText Track Task 1中，使用OpenAI的GPT-4.1系列模型进行科学文本简化，比较了无上下文提示工程和微调两种方法。


<details>
  <summary>Details</summary>
Motivation: 解决科学文本在句子和文档两个层次上的简化问题，以适应不同读者的理解需求，促进科学知识的普及。

Method: 使用GPT-4.1、GPT-4.1-mini和GPT-4.1-nano模型，采用两种策略：1）无上下文方法（仅靠提示工程）；2）微调方法。在句子和文档两个粒度上进行比较实验。

Result: GPT-4.1-mini模型在无上下文方法中在句子和文档级别都表现稳健；微调模型结果参差不齐，其中GPT-4.1-nano-ft在文档级简化中表现突出。

Conclusion: 不同粒度（句子vs文档）的文本简化具有不同复杂性，需要针对性的方法；无上下文方法在某些情况下可能优于微调方法；选择合适的模型和策略对科学文本简化至关重要。

Abstract: This work describes our submission to the CLEF 2025 SimpleText track Task 1, addressing both sentenceand document-level simplification of scientific texts. The methodology centered on using the gpt-4.1, gpt-4.1mini, and gpt-4.1-nano models from OpenAI. Two distinct approaches were compared: a no-context method relying on prompt engineering and a fine-tuned (FT) method across models. The gpt-4.1-mini model with no-context demonstrated robust performance at both levels of simplification, while the fine-tuned models showed mixed results, highlighting the complexities of simplifying text at different granularities, where gpt-4.1-nano-ft performance stands out at document-level simplification in one case.

</details>


### [21] [Refusal Steering: Fine-grained Control over LLM Refusal Behaviour for Sensitive Topics](https://arxiv.org/abs/2512.16602)
*Iker García-Ferrero,David Montero,Roman Orus*

Main category: cs.CL

TL;DR: 提出Refusal Steering方法，通过推理时激活向量调整，在不重新训练的情况下精细控制大语言模型在政治敏感话题上的拒绝行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖脆弱的基于模式的拒绝检测，难以对政治敏感话题进行精细控制。需要一种能在推理时控制模型拒绝行为而不损害安全性的方法。

Method: 使用LLM作为评判器分配拒绝置信度分数，提出岭正则化变体计算更好的拒绝-遵从方向隔离的引导向量，通过激活向量调整控制模型行为。

Result: 在Qwen3-Next-80B-A3B-Thinking模型上成功移除了政治敏感话题的拒绝行为，同时在JailbreakBench上保持安全性，在通用基准测试中性能接近基线。方法在4B和80B模型上通用，也可诱导目标拒绝。

Conclusion: 激活向量引导可以有效移除政治拒绝行为同时保留有害内容的安全对齐，为推理时可控、透明的审核提供了实用路径。

Abstract: We introduce Refusal Steering, an inference-time method to exercise fine-grained control over Large Language Models refusal behaviour on politically sensitive topics without retraining. We replace fragile pattern-based refusal detection with an LLM-as-a-judge that assigns refusal confidence scores and we propose a ridge-regularized variant to compute steering vectors that better isolate the refusal--compliance direction. On Qwen3-Next-80B-A3B-Thinking, our method removes the refusal behaviour of the model around politically sensitive topics while maintaining safety on JailbreakBench and near-baseline performance on general benchmarks. The approach generalizes across 4B and 80B models and can also induce targeted refusals when desired. We analize the steering vectors and show that refusal signals concentrate in deeper layers of the transformer and are distributed across many dimensions. Together, these results demonstrate that activation steering can remove political refusal behaviour while retaining safety alignment for harmful content, offering a practical path to controllable, transparent moderation at inference time.

</details>


### [22] [JustRL: Scaling a 1.5B LLM with a Simple RL Recipe](https://arxiv.org/abs/2512.16649)
*Bingxiang He,Zekai Qu,Zeyuan Liu,Yinghao Chen,Yuxin Zuo,Cheng Qian,Kaiyan Zhang,Weize Chen,Chaojun Xiao,Ganqu Cui,Ning Ding,Zhiyuan Liu*

Main category: cs.CL

TL;DR: JustRL：一种极简的强化学习方法，通过单阶段训练和固定超参数，在1.5B推理模型上实现了SOTA性能，计算量减半，表明当前复杂的RL训练方法可能不必要。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的强化学习方法越来越复杂，包括多阶段训练、动态超参数调度和课程学习策略。研究者质疑这种复杂性是否必要，希望通过一个极简方法验证简单方法的有效性。

Method: 提出JustRL方法，采用单阶段训练、固定超参数，不使用复杂的训练技巧。在两个1.5B推理模型上进行验证，超参数在两个模型间无需调整即可迁移。

Result: 在九个数学基准测试中，两个模型分别达到54.9%和64.3%的平均准确率，计算量比复杂方法减少2倍。训练过程平稳单调，没有崩溃或平台期。消融实验显示传统技巧如长度惩罚和鲁棒验证器反而会降低性能。

Conclusion: 复杂方法试图解决的问题在稳定、规模化的基线方法中可能根本不存在。研究为社区提供了一个简单、经过验证的基线，挑战了当前RL训练复杂化的趋势。

Abstract: Recent advances in reinforcement learning for large language models have converged on increasing complexity: multi-stage training pipelines, dynamic hyperparameter schedules, and curriculum learning strategies. This raises a fundamental question: \textbf{Is this complexity necessary?} We present \textbf{JustRL}, a minimal approach using single-stage training with fixed hyperparameters that achieves state-of-the-art performance on two 1.5B reasoning models (54.9\% and 64.3\% average accuracy across nine mathematical benchmarks) while using 2$\times$ less compute than sophisticated approaches. The same hyperparameters transfer across both models without tuning, and training exhibits smooth, monotonic improvement over 4,000+ steps without the collapses or plateaus that typically motivate interventions. Critically, ablations reveal that adding ``standard tricks'' like explicit length penalties and robust verifiers may degrade performance by collapsing exploration. These results suggest that the field may be adding complexity to solve problems that disappear with a stable, scaled-up baseline. We release our models and code to establish a simple, validated baseline for the community.

</details>


### [23] [GinSign: Grounding Natural Language Into System Signatures for Temporal Logic Translation](https://arxiv.org/abs/2512.16770)
*William English,Chase Walker,Dominic Simon,Rickard Ewetz*

Main category: cs.CL

TL;DR: 提出GinSign框架，通过学习将自然语言映射到系统签名的抽象任务，将自然语言转换为时序逻辑，解决了现有方法在原子命题落地方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有自然语言到时序逻辑的翻译框架要么假设可以准确获取原子命题落地，要么存在落地翻译准确率低的问题，这限制了在构建可信自主系统中的应用。

Method: 提出GinSign框架，引入一个学习将自然语言片段映射到给定系统签名的落地模型。该框架将落地任务分层分解：首先预测谓词标签，然后选择适当类型的常量参数。将这一任务从自由形式生成问题转化为结构化分类问题。

Result: 实验表明，忽略落地的框架倾向于产生语法正确但语义不等价的时序逻辑表达式，而GinSign框架支持下游模型检查，实现了95.5%的落地逻辑等价分数，比现有最佳方法提高了1.4倍。

Conclusion: GinSign框架通过将自然语言落地到系统签名，显著提高了自然语言到时序逻辑翻译的准确性和实用性，为构建可信自主系统提供了更好的规范验证能力。

Abstract: Natural language (NL) to temporal logic (TL) translation enables engineers to specify, verify, and enforce system behaviors without manually crafting formal specifications-an essential capability for building trustworthy autonomous systems. While existing NL-to-TL translation frameworks have demonstrated encouraging initial results, these systems either explicitly assume access to accurate atom grounding or suffer from low grounded translation accuracy. In this paper, we propose a framework for Grounding Natural Language Into System Signatures for Temporal Logic translation called GinSign. The framework introduces a grounding model that learns the abstract task of mapping NL spans onto a given system signature: given a lifted NL specification and a system signature $\mathcal{S}$, the classifier must assign each lifted atomic proposition to an element of the set of signature-defined atoms $\mathcal{P}$. We decompose the grounding task hierarchically- first predicting predicate labels, then selecting the appropriately typed constant arguments. Decomposing this task from a free-form generation problem into a structured classification problem permits the use of smaller masked language models and eliminates the reliance on expensive LLMs. Experiments across multiple domains show that frameworks which omit grounding tend to produce syntactically correct lifted LTL that is semantically nonequivalent to grounded target expressions, whereas our framework supports downstream model checking and achieves grounded logical-equivalence scores of $95.5\%$, a $1.4\times$ improvement over SOTA.

</details>


### [24] [Exploration of Augmentation Strategies in Multi-modal Retrieval-Augmented Generation for the Biomedical Domain: A Case Study Evaluating Question Answering in Glycobiology](https://arxiv.org/abs/2512.16802)
*Primož Kocbek,Azra Frkatović-Hodžić,Dora Lalić,Vivian Hui,Gordan Lauc,Gregor Štiglic*

Main category: cs.CL

TL;DR: 研究比较了多模态检索增强生成中两种处理视觉内容的方法：将图表转换为文本vs. OCR-free视觉检索，发现在糖生物学领域，方法选择取决于模型能力，中等模型更适合转换方法，前沿模型则能有效利用视觉检索。


<details>
  <summary>Details</summary>
Motivation: 多模态检索增强生成在生物医学QA中有潜力，但不确定何时应该将图表转换为文本，何时应该使用OCR-free视觉检索（返回页面图像，由生成器解释）。本研究在视觉密集的糖生物学领域探讨这一权衡。

Method: 构建了包含120个多选题的基准测试，来自25篇论文，按检索难度分层。实现了四种增强方法：无增强、文本RAG、多模态转换、以及late-interaction视觉检索（ColPali），使用Docling解析和Qdrant索引。评估了中等规模开源模型和前沿专有模型。

Result: 对于Gemma-3-27B-IT，文本和多模态增强优于OCR-free检索（0.722-0.740 vs. 0.510平均准确率）。对于GPT-4o，多模态达到0.808，文本0.782，ColPali 0.745。在GPT-5系列中，ColPali和ColFlor的最佳结果提高了约2%至0.828。ColPali、ColQwen和ColFlor在统计上无显著差异。

Conclusion: 管道选择取决于模型能力：将视觉内容转换为文本降低了阅读负担，对中等规模模型更可靠；而OCR-free视觉检索在前沿模型下变得有竞争力。在检索器中，ColFlor以较小计算代价提供与较重选项相当的性能，是强生成器可用时的有效默认选择。

Abstract: Multi-modal retrieval-augmented generation (MM-RAG) promises grounded biomedical QA, but it is unclear when to (i) convert figures/tables into text versus (ii) use optical character recognition (OCR)-free visual retrieval that returns page images and leaves interpretation to the generator. We study this trade-off in glycobiology, a visually dense domain. We built a benchmark of 120 multiple-choice questions (MCQs) from 25 papers, stratified by retrieval difficulty (easy text, medium figures/tables, hard cross-evidence). We implemented four augmentations-None, Text RAG, Multi-modal conversion, and late-interaction visual retrieval (ColPali)-using Docling parsing and Qdrant indexing. We evaluated mid-size open-source and frontier proprietary models (e.g., Gemma-3-27B-IT, GPT-4o family). Additional testing used the GPT-5 family and multiple visual retrievers (ColPali/ColQwen/ColFlor). Accuracy with Agresti-Coull 95% confidence intervals (CIs) was computed over 5 runs per configuration. With Gemma-3-27B-IT, Text and Multi-modal augmentation outperformed OCR-free retrieval (0.722-0.740 vs. 0.510 average accuracy). With GPT-4o, Multi-modal achieved 0.808, with Text 0.782 and ColPali 0.745 close behind; within-model differences were small. In follow-on experiments with the GPT-5 family, the best results with ColPali and ColFlor improved by ~2% to 0.828 in both cases. In general, across the GPT-5 family, ColPali, ColQwen, and ColFlor were statistically indistinguishable. GPT-5-nano trailed larger GPT-5 variants by roughly 8-10%. Pipeline choice is capacity-dependent: converting visuals to text lowers the reader burden and is more reliable for mid-size models, whereas OCR-free visual retrieval becomes competitive under frontier models. Among retrievers, ColFlor offers parity with heavier options at a smaller footprint, making it an efficient default when strong generators are available.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [25] [On Recommending Category: A Cascading Approach](https://arxiv.org/abs/2512.16033)
*Qihao Wang,Pritom Saha Akash,Varvara Kollia,Kevin Chen-Chuan Chang,Biwei Jiang,Vadim Von Brzeski*

Main category: cs.IR

TL;DR: 该论文提出了一种基于变分自编码器的级联类别推荐模型CCRec，用于解决电商平台中的类别级推荐问题，相比传统的项目级推荐方法有显著优势。


<details>
  <summary>Details</summary>
Motivation: 电商平台开始关注类别级推荐来探索用户的潜在兴趣，这能提升用户参与度、补充项目级推荐在用户信息不足时的不足，并辅助项目级推荐。然而现有研究大多直接应用项目级模型，忽略了类别级推荐的关键差异。

Method: 提出CCRec模型，使用变分自编码器编码项目级信息来执行类别级推荐，采用级联结构处理类别级推荐的特殊性。

Result: 实验表明该模型在类别级推荐任务上优于为项目级推荐设计的方法。

Conclusion: CCRec模型有效解决了类别级推荐问题，考虑了与项目级推荐的差异，在电商推荐场景中具有实际应用价值。

Abstract: Recommendation plays a key role in e-commerce, enhancing user experience and boosting commercial success. Existing works mainly focus on recommending a set of items, but online e-commerce platforms have recently begun to pay attention to exploring users' potential interests at the category level. Category-level recommendation allows e-commerce platforms to promote users' engagements by expanding their interests to different types of items. In addition, it complements item-level recommendations when the latter becomes extremely challenging for users with little-known information and past interactions. Furthermore, it facilitates item-level recommendations in existing works. The predicted category, which is called intention in those works, aids the exploration of item-level preference. However, such category-level preference prediction has mostly been accomplished through applying item-level models. Some key differences between item-level recommendations and category-level recommendations are ignored in such a simplistic adaptation. In this paper, we propose a cascading category recommender (CCRec) model with a variational autoencoder (VAE) to encode item-level information to perform category-level recommendations. Experiments show the advantages of this model over methods designed for item-level recommendations.

</details>


### [26] [The Evolution of Reranking Models in Information Retrieval: From Heuristic Methods to Large Language Models](https://arxiv.org/abs/2512.16236)
*Tejul Pandit,Sakshi Mahendru,Meet Raval,Dhvani Upadhyay*

Main category: cs.IR

TL;DR: 这篇论文是关于信息检索中重排序技术的全面综述，系统梳理了从传统方法到现代神经网络的演进历程，特别关注了在RAG框架中的应用。


<details>
  <summary>Details</summary>
Motivation: 重排序在信息检索系统中至关重要，能够提升最终结果的相关性。随着检索增强生成(RAG)等现代技术的发展，重排序方法变得更加多样和复杂，需要一个系统性的综述来梳理这一领域的发展脉络和技术进展。

Method: 采用历史演进的时间线方法，从基础方法开始，系统研究了交叉编码器、序列生成模型(T5)、图神经网络等神经网络架构。同时分析了知识蒸馏等效率提升技术，以及大语言模型在重排序中的集成应用。

Result: 提供了重排序领域的结构化综合，涵盖了各种重排序范式的基本思想、相对有效性、计算特征和实际权衡。特别强调了不同方法在RAG管道中的表现和影响。

Conclusion: 这篇综述为信息检索重排序领域提供了全面的技术路线图，帮助研究人员和实践者理解不同方法的原理、优势和局限性，为该领域的未来发展提供了参考框架。

Abstract: Reranking is a critical stage in contemporary information retrieval (IR) systems, improving the relevance of the user-presented final results by honing initial candidate sets. This paper is a thorough guide to examine the changing reranker landscape and offer a clear view of the advancements made in reranking methods. We present a comprehensive survey of reranking models employed in IR, particularly within modern Retrieval Augmented Generation (RAG) pipelines, where retrieved documents notably influence output quality.
  We embark on a chronological journey through the historical trajectory of reranking techniques, starting with foundational approaches, before exploring the wide range of sophisticated neural network architectures such as cross-encoders, sequence-generation models like T5, and Graph Neural Networks (GNNs) utilized for structural information. Recognizing the computational cost of advancing neural rerankers, we analyze techniques for enhancing efficiency, notably knowledge distillation for creating competitive, lighter alternatives. Furthermore, we map the emerging territory of integrating Large Language Models (LLMs) in reranking, examining novel prompting strategies and fine-tuning tactics. This survey seeks to elucidate the fundamental ideas, relative effectiveness, computational features, and real-world trade-offs of various reranking strategies. The survey provides a structured synthesis of the diverse reranking paradigms, highlighting their underlying principles and comparative strengths and weaknesses.

</details>


### [27] [From Flows to Functions: Macroscopic Behavioral Fingerprinting of IoT Devices via Network Services](https://arxiv.org/abs/2512.16348)
*Shayan Azizi,Norihiro Okui,Masataka Nakahara,Ayumu Kubota,Hassan Habibi Gharakheili*

Main category: cs.IR

TL;DR: 该论文提出了一种基于网络服务使用模式的宏观、轻量级、可解释的IoT设备指纹识别方法，替代传统的细粒度流量分析。


<details>
  <summary>Details</summary>
Motivation: 现有的IoT设备识别方法通常基于细粒度的网络流量特征（数据包/流），存在计算成本高、对测量误差敏感、推理不透明等问题。需要一种更高效、可靠且可解释的设备识别方案来管理IoT设备带来的网络安全风险。

Method: 提出服务级指纹识别方法：1）证明IoT设备在长时间内使用网络服务（如TCP/80、UDP/53）具有稳定且可区分的模式；2）形式化服务级指纹概念，使用可配置的粒度参数表示网络行为；3）开发指纹提取程序，在实验室测试床中应用于13种消费级IoT设备类型；4）评估指纹的收敛性和重复性；5）在封闭集和开放集场景下验证设备识别效果。

Result: 基于在1.5年期间收集的约1000万条IPFIX流记录的大规模数据集，验证了服务级指纹的有效性。该方法能够：1）识别IoT设备在长时间内稳定的服务使用模式；2）在封闭集和开放集场景下有效识别设备；3）相比传统方法具有计算轻量、可解释性强等优势。

Conclusion: 服务级指纹识别为IoT设备识别提供了一种宏观、轻量级、可解释的替代方案，能够有效应对传统细粒度流量分析方法存在的问题，为网络安全管理提供了实用工具。

Abstract: Identifying devices such as cameras, printers, voice assistants, or health monitoring sensors, collectively known as the Internet of Things (IoT), within a network is a critical operational task, particularly to manage the cyber risks they introduce. While behavioral fingerprinting based on network traffic analysis has shown promise, most existing approaches rely on machine learning (ML) techniques applied to fine-grained features of short-lived traffic units (packets and/or flows). These methods tend to be computationally expensive, sensitive to traffic measurement errors, and often produce opaque inferences. In this paper, we propose a macroscopic, lightweight, and explainable alternative to behavioral fingerprinting focusing on the network services (e.g., TCP/80, UDP/53) that IoT devices use to perform their intended functions over extended periods. Our contributions are threefold. (1) We demonstrate that IoT devices exhibit stable and distinguishable patterns in their use of network services over a period of time. We formalize the notion of service-level fingerprints and derive a generalized method to represent network behaviors using a configurable granularity parameter. (2) We develop a procedure to extract service-level fingerprints, apply it to traffic from 13 consumer IoT device types in a lab testbed, and evaluate the resulting representations in terms of their convergence and recurrence properties. (3) We validate the efficacy of service-level fingerprints for device identification in closed-set and open-set scenarios. Our findings are based on a large dataset comprising about 10 million IPFIX flow records collected over a 1.5-year period.

</details>


### [28] [Introducing ORKG ASK: an AI-driven Scholarly Literature Search and Exploration System Taking a Neuro-Symbolic Approach](https://arxiv.org/abs/2512.16425)
*Allard Oelen,Mohamad Yaser Jaradeh,Sören Auer*

Main category: cs.IR

TL;DR: ASK是一个基于神经符号方法的AI驱动学术文献搜索与探索系统，结合向量搜索、大语言模型和知识图谱，通过RAG方法帮助研究者用自然语言提问获取相关文献和答案。


<details>
  <summary>Details</summary>
Motivation: 随着学术文献数量持续增长，寻找相关文献变得越来越困难。生成式AI和大语言模型的兴起为文献发现和探索提供了新的可能性。

Method: 采用神经符号方法，结合向量搜索、大语言模型和知识图谱。系统允许用户用自然语言输入研究问题，通过检索增强生成(RAG)方法自动提取关键信息并生成答案。

Result: 评估显示系统用户友好，用户在使用过程中普遍感到满意，表明系统具有实用性和可用性。

Conclusion: ASK系统成功展示了AI驱动学术文献搜索的潜力，通过神经符号方法有效支持研究者发现和探索相关学术文献。

Abstract: As the volume of published scholarly literature continues to grow, finding relevant literature becomes increasingly difficult. With the rise of generative Artificial Intelligence (AI), and particularly Large Language Models (LLMs), new possibilities emerge to find and explore literature. We introduce ASK (Assistant for Scientific Knowledge), an AI-driven scholarly literature search and exploration system that follows a neuro-symbolic approach. ASK aims to provide active support to researchers in finding relevant scholarly literature by leveraging vector search, LLMs, and knowledge graphs. The system allows users to input research questions in natural language and retrieve relevant articles. ASK automatically extracts key information and generates answers to research questions using a Retrieval-Augmented Generation (RAG) approach. We present an evaluation of ASK, assessing the system's usability and usefulness. Findings indicate that the system is user-friendly and users are generally satisfied while using the system.

</details>


### [29] [InfoDCL: Informative Noise Enhanced Diffusion Based Contrastive Learning](https://arxiv.org/abs/2512.16576)
*Xufeng Liang,Zhida Qin,Chong Zhang,Tianyu Huang,Gangyi Ding*

Main category: cs.IR

TL;DR: InfoDCL是一种基于扩散的对比学习推荐框架，通过整合辅助语义信息生成对比视图，并采用协同训练策略提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法通常通过随机扰动原始交互图构建稀疏视图，但由于推荐数据的稀疏性，这种方法只能捕获不足的语义信息，无法准确反映真实用户偏好。

Method: 1. 使用单步扩散过程整合噪声与辅助语义信息生成信号，然后输入标准扩散过程生成真实用户偏好作为对比视图；2. 基于生成与偏好学习相互影响的分析，构建协同训练目标策略；3. 仅在推理阶段使用多层GCN融入高阶共现信息以保持训练效率。

Result: 在五个真实世界数据集上的实验表明，InfoDCL显著优于现有最先进方法，有效提升了推荐性能。

Conclusion: InfoDCL为提升推荐性能提供了有效解决方案，并为在对比学习框架中应用扩散方法提出了新范式。

Abstract: Contrastive learning has demonstrated promising potential in recommender systems. Existing methods typically construct sparser views by randomly perturbing the original interaction graph, as they have no idea about the authentic user preferences. Owing to the sparse nature of recommendation data, this paradigm can only capture insufficient semantic information. To address the issue, we propose InfoDCL, a novel diffusion-based contrastive learning framework for recommendation. Rather than injecting randomly sampled Gaussian noise, we employ a single-step diffusion process that integrates noise with auxiliary semantic information to generate signals and feed them to the standard diffusion process to generate authentic user preferences as contrastive views. Besides, based on a comprehensive analysis of the mutual influence between generation and preference learning in InfoDCL, we build a collaborative training objective strategy to transform the interference between them into mutual collaboration. Additionally, we employ multiple GCN layers only during inference stage to incorporate higher-order co-occurrence information while maintaining training efficiency. Extensive experiments on five real-world datasets demonstrate that InfoDCL significantly outperforms state-of-the-art methods. Our InfoDCL offers an effective solution for enhancing recommendation performance and suggests a novel paradigm for applying diffusion method in contrastive learning frameworks.

</details>


### [30] [Microsoft Academic Graph Information Retrieval for Research Recommendation and Assistance](https://arxiv.org/abs/2512.16661)
*Jacob Reiss,Shikshya Shiwakoti,Samuel Goldsmith,Ujjwal Pandit*

Main category: cs.IR

TL;DR: 提出基于注意力机制的子图检索器，结合图神经网络与大语言模型进行知识推理


<details>
  <summary>Details</summary>
Motivation: 在信息爆炸时代，虽然科学文献获取更容易，但从海量研究中筛选有效信息变得更具挑战性。图神经网络和注意力机制在大型信息数据库搜索中表现出色，尤其与现代大语言模型结合时。

Method: 提出基于注意力的子图检索器，这是一个GNN-as-retriever模型，应用基于注意力的剪枝技术提取精炼子图，然后将该子图传递给大语言模型进行高级知识推理。

Result: 论文未提供具体实验结果数据，但提出了一个结合图神经网络注意力机制与大语言模型的检索推理框架。

Conclusion: 通过注意力机制的子图检索器能够有效从大规模信息数据库中提取精炼子图，为大语言模型提供结构化输入，实现更高效的知识推理。

Abstract: In today's information-driven world, access to scientific publications has become increasingly easy. At the same time, filtering through the massive volume of available research has become more challenging than ever. Graph Neural Networks (GNNs) and graph attention mechanisms have shown strong effectiveness in searching large-scale information databases, particularly when combined with modern large language models. In this paper, we propose an Attention-Based Subgraph Retriever, a GNN-as-retriever model that applies attention-based pruning to extract a refined subgraph, which is then passed to a large language model for advanced knowledge reasoning.

</details>
