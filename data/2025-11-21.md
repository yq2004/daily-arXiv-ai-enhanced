<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning](https://arxiv.org/abs/2511.15886)
*Jeremias Ferrao,Ezgi Basar,Khondoker Ittehadul Islam,Mahrokh Hassani*

Main category: cs.CL

TL;DR: 本研究调查了多语言大语言模型中思维链推理的归因模式，发现归因分数过度强调最终推理步骤、结构化CoT提示主要对高资源拉丁语系语言有效、受控扰动会降低模型准确性和归因一致性。


<details>
  <summary>Details</summary>
Motivation: 尽管先前研究证明了CoT提示在提高任务性能方面的作用，但人们对生成的推理链的忠实性和可解释性存在担忧，特别是在多语言环境中评估这些属性。

Method: 使用ContextCite进行步骤级归因和Inseq进行令牌级归因，在Qwen2.5 1.5B-Instruct模型上应用MGSM基准测试，并通过否定和干扰句进行受控扰动。

Result: 实验结果显示：(1)归因分数过度强调最终推理步骤，特别是在错误生成中；(2)结构化CoT提示显著提高准确性，但主要限于高资源拉丁语系语言；(3)受控扰动降低了模型准确性和归因一致性。

Conclusion: 这些发现凸显了CoT提示的局限性，特别是在多语言鲁棒性和解释透明度方面。

Abstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.

</details>


### [2] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: Motion2Mind是一个评估机器通过非语言线索理解他人心理状态能力的框架，包含精心策划的视频数据集，涵盖222种非语言线索和397种心理状态。研究发现当前AI系统在非语言线索解释方面存在显著困难。


<details>
  <summary>Details</summary>
Motivation: 现有的心理理论基准主要关注错误信念任务和不对称信息推理，忽视了信念之外的其他心理状态和丰富的非语言交流。需要评估机器通过非语言线索理解心理状态的能力。

Method: 利用专家策划的身体语言参考作为知识库，构建Motion2Mind数据集，包含细粒度非语言线索标注和手动验证的心理解释。数据集涵盖222种非语言线索和397种心理状态。

Result: 评估显示当前AI系统在非语言线索解释方面表现显著不足，在检测任务上存在巨大性能差距，在解释任务中表现出过度解释的模式。

Conclusion: 机器在理解非语言线索方面仍面临重大挑战，需要开发更先进的模型来准确解释人类非语言交流中的心理状态。

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [3] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 提出了TOD-ProcBench基准，用于系统评估LLM在多轮任务导向对话中遵循复杂过程指令的能力，包含三个任务：相关语句检索与动作预测、违规响应识别和条件生成指令遵循响应。


<details>
  <summary>Details</summary>
Motivation: 现有任务导向对话基准将复杂指令过度简化为简单模式，无法真实反映现实世界中需要严格遵循复杂约束的对话场景。

Method: 基于高质量ABCD数据集构建包含复杂过程指令的对话数据集，将细粒度约束和动作程序表述为多级条件-动作指令语句，设计三个评估任务。

Result: 构建了包含复杂约束的指令文档和对话数据集，设计了系统评估框架，并研究了多语言设置和不同指令文本格式对性能的影响。

Conclusion: TOD-ProcBench填补了现有基准在评估LLM复杂指令遵循能力方面的空白，为系统评估多轮任务导向对话中的指令遵循性能提供了挑战性基准。

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [4] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: LIARS' BENCH是一个包含72,863个谎言和诚实回答的测试平台，用于评估大语言模型的谎言检测技术，发现现有技术在检测某些类型的谎言时存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型谎言检测技术通常在狭窄的设置中验证，无法捕捉模型可能生成的各种谎言类型，需要更全面的评估框架。

Method: 创建LIARS' BENCH测试平台，包含四个开源模型在七个数据集上生成的72,863个谎言和诚实回答，涵盖不同谎言类型，按说谎原因和信念目标两个维度变化。

Result: 评估三种黑白盒谎言检测技术后发现，现有技术在某些类型的谎言检测上系统性失败，特别是在仅从文本转录无法确定模型是否说谎的情况下。

Conclusion: LIARS' BENCH揭示了现有技术的局限性，为谎言检测领域的进展提供了实用的测试平台。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [5] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: LTLA是一种混合方法，将基础语言模型与可处理的代理模型结合，通过单次批量HMM更新和固定代理解码器来高效处理序列级约束生成，提高约束满足度且推理开销最小。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用可处理的代理模型（如HMM）来近似延续概率，但这些代理模型通常上下文感知能力较弱，降低了查询质量。需要一种既能利用语言模型的丰富上下文编码，又能高效计算延续概率的方法。

Method: LTLA将基础语言模型用于丰富的前缀编码，与固定的可处理代理模型配对计算精确的延续概率。通过单次批量HMM更新处理所有下一个token候选，并仅将代理模型的潜在状态先验条件于LM的隐藏表示，同时保持代理解码器固定以实现跨前缀的计算重用。

Result: LTLA获得了比无条件HMM更高的条件似然，能够近似视觉语言模型的延续分布（独立HMM无法编码视觉上下文），在受控生成任务中以相当的流畅度提高了约束满足度，且推理开销最小。

Conclusion: LTLA通过有效结合语言模型的上下文编码能力和代理模型的精确概率计算，解决了受控语言生成中的效率问题，在保持流畅度的同时显著提高了约束满足能力。

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [6] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: GPT-5在数学、物理、天文学、计算机科学、生物学和材料科学等多个科学领域的研究中提供了新的具体步骤，帮助科学家加速研究，包括在数学领域产生了四个经过验证的新结果。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型如GPT-5是科学家的重要工具，但许多科学家对其能力了解不足。本文旨在通过案例研究展示GPT-5如何帮助科学家推进研究，特别是在解决未解决问题方面。

Method: 收集了多个科学领域的短案例研究，记录了人类作者与GPT-5的互动过程，展示了富有成效的人机协作模式。

Result: GPT-5在多个科学领域产生了新的研究步骤，特别是在数学领域帮助解决了四个此前未解决的问题，这些结果都经过了人类作者的仔细验证。

Conclusion: GPT-5能够显著加速科学研究，在人类专家的指导下可以产生实质性贡献。虽然AI仍有局限性，但前沿AI的快速发展预示着其在科学研究中的巨大潜力。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [7] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 提出了一种基于集成学习的自动提示优化框架ELPO，通过投票机制和多种搜索方法提升提示优化的准确性和鲁棒性，在多个任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法通常采用单一模型或算法，在处理复杂任务时性能受限，手动提示工程又过于耗时，成为LLMs实际应用的主要瓶颈。

Method: ELPO框架借鉴集成学习思想，采用投票机制，结合共享生成策略和不同搜索方法来寻找更优提示，并提出了更高效的提示生成和搜索算法。

Result: 实验结果表明ELPO在多个任务上优于最先进的提示优化方法，如在ArSarcasm数据集上F1分数提高了7.6分。

Conclusion: ELPO框架通过集成学习方法有效提升了提示优化的性能，为复杂任务下的自动提示优化提供了更优解决方案。

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [8] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 本文提出了一种新的参数高效微调范式TS-PEFT，通过选择性对部分位置索引应用PEFT修改，挑战了传统对所有索引都应用PEFT的必要性。


<details>
  <summary>Details</summary>
Motivation: 传统PEFT方法对所有位置索引都应用修改，作者质疑这种做法的必要性，认为可能过度且适得其反。

Method: 提出Token-Selective PEFT (TS-PEFT)方法，使用函数S选择性地对位置索引子集应用PEFT修改。

Result: 实验结果表明，对所有索引不加选择地应用PEFT不仅多余，而且可能适得其反。

Conclusion: 为PEFT提供了新视角，主张更针对性的修改方法，为未来优化大型模型微调过程提供了框架。

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [9] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: SemanticCite是一个AI驱动的系统，通过全文分析验证引文准确性，提供详细推理和相关文本片段，解决语义引用错误、AI生成幻觉引用等学术文献挑战。


<details>
  <summary>Details</summary>
Motivation: 学术文献面临语义引用错误、AI生成幻觉引用以及传统引用格式无法指示具体支持段落的挑战，需要准确验证引文以维护研究完整性。

Method: 结合多种检索方法与四类分类系统（支持、部分支持、不支持、不确定），使用微调的轻量级语言模型进行全文源分析，提供透明、基于证据的解释。

Result: 实验显示微调的轻量级语言模型性能与大型商业系统相当，但计算需求显著降低，使大规模引文验证实际可行。贡献了包含1000多个引文的综合数据集和开源验证框架。

Conclusion: SemanticCite通过可扩展的引文验证、简化同行评审和AI生成内容质量控制，为大规模维护引文准确性提供了开源基础，解决了研究完整性的关键挑战。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [10] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出了语义结构熵（SeSE）框架，通过建模语义空间的结构信息来量化大语言模型的不确定性，用于幻觉检测。该方法构建自适应稀疏的有向语义图，并通过层次抽象计算结构熵，能显著优于现有不确定性量化方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法主要依赖语义概率分布或成对距离，忽略了潜在的语义结构信息，而这些信息可能实现更精确的不确定性估计。

Method: 1. 开发自适应稀疏有向语义图构建算法，捕捉方向性语义依赖并自动剪枝干扰连接；2. 通过层次抽象利用潜在语义结构信息，定义SeSE为最优语义编码树的结构熵；3. 扩展SeSE到长文本生成，通过建模随机语义交互来量化单个声明的不确定性。

Result: 在29个模型-数据集组合上的广泛实验表明，SeSE显著优于先进的不确定性量化基线方法，包括强监督方法和最近提出的KLE方法。

Conclusion: SeSE框架通过从结构信息角度量化LLMs的固有语义不确定性，为幻觉检测提供了原则性的不确定性量化方法，在安全关键场景中具有重要应用价值。

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [11] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 提出SDA框架，无需训练即可动态调整LLM输出概率分布，提升模型与人类意图的对齐性能，在8个开源LLM上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在真实应用中的广泛部署，确保模型响应与人类意图对齐成为关键挑战，特别是在不进行昂贵重训练或大量监督的情况下实现推理阶段的有效对齐。

Method: 提出SDA框架，基于用户定义的对齐指令动态重新分布模型输出概率，无需微调即可增强模型行为与人类意图的对齐。该方法轻量、资源高效且与多种开源LLM兼容。

Result: 在8个不同规模和来源的开源LLM上测试，SDA在帮助性、无害性和诚实性三个对齐维度上均取得显著提升，平均增益分别为64.4%、30%和11.5%。

Conclusion: SDA是一种无需训练、模型无关的对齐框架，能够有效提升LLM与人类意图的对齐性能，具有良好的泛化能力和实际应用价值。

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [12] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: ESGBench是一个用于评估可解释ESG问答系统的基准数据集和评估框架，包含跨多个ESG主题的领域基础问题、人工策划的答案和支持证据，以支持模型推理的细粒度评估。


<details>
  <summary>Details</summary>
Motivation: 需要评估可解释ESG问答系统在事实一致性、可追溯性和领域对齐方面的表现，推动透明和负责任的ESG导向AI系统研究。

Method: 构建包含领域基础问题、人工策划答案和支持证据的基准数据集，分析最先进LLM在ESGBench上的性能表现。

Result: 识别了在事实一致性、可追溯性和领域对齐方面的关键挑战，为ESG导向AI系统的评估提供了基准。

Conclusion: ESGBench旨在加速透明和负责任ESG导向AI系统的研究，为评估可解释ESG问答系统提供了标准化框架。

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [13] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 提出自改写框架，让模型改写自身推理文本，通过选择性改写简单样本来改进内部推理质量，在保持RL算法可扩展性的同时显著提升准确率并缩短推理长度。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习仅关注最终正确性的奖励机制无法对内部推理过程提供详细监督，导致推理质量不佳，出现过度思考、思考不足、冗余思考和无序思考等问题。

Method: 采用自改写框架，模型改写自身推理文本；提出选择性改写方法，只改写模型持续正确的"简单"样本；在单批次中同时进行改写和原始生成，保持RL算法可扩展性。

Result: 在准确率-长度权衡方面，自改写方法在准确率提升0.6%的同时显著缩短推理长度46%；在内部推理质量方面，LLM-as-a-judge指标得分显著提高7.2分，成功缓解内部推理缺陷。

Conclusion: 自改写框架有效提升了推理模型的内部推理质量，在保持算法可扩展性的同时实现了更好的准确率-长度权衡，为解决推理过程中的质量问题提供了有效方案。

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [14] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: TurkColBERT是首个针对土耳其语检索的全面基准测试，比较了密集编码器和延迟交互模型。研究表明延迟交互模型在参数效率上显著优于密集编码器，小3-5倍的模型性能更好，并提出了生产就绪的索引算法MUVERA+Rerank。


<details>
  <summary>Details</summary>
Motivation: 神经信息检索系统在高资源语言中表现出色，但在形态丰富、资源较少的语言如土耳其语中研究不足。密集双编码器目前在土耳其IR中占主导地位，但延迟交互模型尚未得到系统评估。

Method: 采用两阶段适应流程：首先在土耳其语NLI/STS任务上微调英语和多语言编码器，然后使用在MS MARCO-TR上训练的PyLate将其转换为ColBERT风格的检索器。评估了10个模型在五个土耳其BEIR数据集上的表现。

Result: 延迟交互模型表现出强大的参数效率：1.0M参数的colbert-hash-nano-tr比600M的turkish-e5-large密集编码器小600倍，同时保留了其平均mAP的71%以上。小3-5倍的延迟交互模型显著优于密集编码器；ColmmBERT-base-TR在特定领域任务上mAP提升高达+13.8%。MUVERA+Rerank比PLAID快3.33倍，并提供+1.7%的相对mAP增益。

Conclusion: TurkColBERT为土耳其语检索建立了首个全面基准，证明了延迟交互模型在参数效率和性能上的优势，并提供了生产就绪的解决方案。局限性包括依赖中等规模数据集和翻译基准，可能无法完全反映真实世界的土耳其检索条件。

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [15] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 本文创建了大规模习语和比喻语言数据集，用于评估预训练语言模型处理比喻意义的能力，并通过槽位标注和序列标注任务进行训练和评估。


<details>
  <summary>Details</summary>
Motivation: 习语和比喻语言在口语和书面语中占很大比例，但大型语言模型在处理这类语言时仍存在困难，需要更好的数据集来缩小这一差距。

Method: 使用现有习语数据集获取习语列表，从大型语料库中检索上下文序列，创建一个大尺度潜在习语数据集和两个人工标注的确切习语数据集，并进行后处理以适应模型无关训练。

Result: 创建了用于习语识别（检测）任务的数据集，并在槽位标注和序列标注任务上进行了训练和评估。

Conclusion: 微调方法是最优的，但更大更好的数据集可以进一步缩小大型语言模型在习语和比喻语言理解方面的差距。

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [16] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 该论文分析了自然语言解释（rationales）的充分性指标，发现其不能有效衡量模型性能提升，并探讨了rationales在token分类和注意力正则化中的不同作用。


<details>
  <summary>Details</summary>
Motivation: 现有的充分性指标在评估rationales信息对模型性能的影响方面存在局限，需要更深入地理解rationales如何影响模型决策。

Method: 将充分性指标与两种建模范式联系起来：通过token分类识别rationales标记的能力，以及通过注意力正则化在输入中融入rationales来提升模型性能的能力。

Result: 发现高度信息化的rationales不一定有助于正确分类；充分性反而反映了非rationalized上下文对分类的干扰；rationales信息可以提升跨领域分类但效果不一致；充分性与token分类无关。

Conclusion: rationales的复杂性表明需要开发能够系统捕捉这类信息的指标，现有充分性指标存在局限性。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [17] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: 提出了MinerU-HTML，一种基于语言模型的HTML到文本提取方法，显著优于传统启发式方法，并构建了7.3万亿token的多语言语料库AICC，证明提取质量对模型性能有重要影响。


<details>
  <summary>Details</summary>
Motivation: 现有网页语料库主要依赖启发式提取器（如Trafilatura），这些方法难以保留文档结构和结构化元素（公式、代码、表格），作者假设提高提取质量对下游性能的影响可能与积极过滤策略一样重要。

Method: 将内容提取重新定义为序列标注问题，使用0.6B参数的语言模型解决。采用两阶段格式化流程，先明确分类语义元素，再转换为Markdown格式。

Result: 在MainWebBench基准测试中，MinerU-HTML达到81.8% ROUGE-N F1，远高于Trafilatura的63.6%，结构化元素保留率极高（代码块90.9%，公式94.0%）。使用AICC语料库训练的模型在13个基准测试中平均准确率达到50.8%，比使用TfCC语料库高1.08个百分点。

Conclusion: HTML提取是网页语料库构建中一个关键但常被低估的组成部分，基于模型的提取方法比启发式方法具有更好的扩展性和改进空间。

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [18] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 本研究评估了机器学习和深度学习模型在区分感知低质量与高质量新闻文章方面的效果，发现深度学习模型（特别是ModernBERT-large）表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探索机器学习和深度学习模型是否能够有效区分感知低质量与高质量新闻文章，以帮助自动识别新闻质量。

Method: 使用新创建的数据集（1,412,272篇英文新闻文章），评估了3个机器学习分类器和3个深度学习模型。专家共识评分将579个新闻源网站分为低质量和高质量两类，每类约706,000篇文章，每篇文章提取194个语言特征。

Result: 随机森林等传统机器学习分类器表现良好（准确率0.7355，ROC AUC 0.8131）。深度学习模型中，ModernBERT-large（256上下文长度）表现最佳（准确率0.8744，ROC-AUC 0.9593，F1 0.8739），DistilBERT-base（512上下文长度）次之（准确率0.8685，ROC-AUC 0.9554）。

Conclusion: 研究结果表明，传统基于CPU的机器学习分类器和深度学习分类器都能有效区分全球新闻文章的感知质量，其中深度学习模型表现更优。

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [19] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 本文研究了基于Transformer的语言模型如何处理习语表达，通过电路发现和分析技术识别了习语处理的计算模式，包括"习语头"和"增强接收"现象。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解Transformer模型如何处理非组合性语言（如习语），探索模型在计算效率和鲁棒性之间的平衡机制。

Method: 使用改进的路径修补算法进行电路发现，识别和分析"习语头"（在不同习语中频繁激活的注意力头）以及习语标记间的"增强接收"现象。

Result: 发现习语处理具有独特的计算模式，识别出特定的习语头，观察到由于早期处理导致的习语标记间注意力增强，揭示了Transformer处理非组合性语言的机制。

Conclusion: 这些发现为理解Transformer如何处理非组合性语言提供了见解，并为理解更复杂语法结构的处理提供了途径。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [20] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是一个轻量级但性能优越的文档结构数据提取模型，可在资源受限的硬件上部署，支持长文档处理。


<details>
  <summary>Details</summary>
Motivation: 开发一个既能达到最先进性能，又能在资源受限硬件上部署的文档结构数据提取模型，解决长文档处理的需求。

Method: 采用了特定的训练协议来优化模型性能，同时保持模型轻量化（仅6.6 GiB）。

Result: 模型在A10 GPU（24GB内存）上可处理多达125页A4文档，在文档理解任务中表现出色。

Conclusion: Arctic-Extract成功实现了在保持高性能的同时，能够在资源受限环境中部署的文档结构数据提取能力。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [21] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM激活预测文本体裁的框架，使用Mistral-7B和两个数据集，通过scikit-learn分类器实现了最高98%和71%的F1分数，证明可以从LLM中推断文本体裁。


<details>
  <summary>Details</summary>
Motivation: 理解LLM对于确保其安全有益部署至关重要，但由于LLM结构的难以解释性和无法人工评估所有输出，这一任务变得复杂。

Method: 使用Mistral-7B模型和两个数据集，基于LLM的激活状态，通过scikit-learn分类器预测文本的体裁。

Result: 在两个数据集上，体裁预测的F1分数分别达到98%和71%，结果始终优于控制任务。

Conclusion: 这提供了一个概念验证，表明可以使用浅层学习模型从LLM中推断文本体裁，为理解LLM行为迈出了重要一步。

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [22] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 本文挑战了ASR评估中过度依赖词错误率(WER)的标准，发现WER等现有指标与临床影响相关性差，提出了基于LLM的自动化评估框架来替代人工专家评估。


<details>
  <summary>Details</summary>
Motivation: 当前ASR在临床对话中广泛应用，但评估仍主要依赖WER，这种简单文本保真度评估无法反映转录错误对临床安全的影响。

Method: 建立专家标注的黄金标准基准，让临床专家比较真实话语与ASR转录，标注临床影响；引入LLM-as-a-Judge方法，使用GEPA进行程序化优化来复制专家临床评估。

Result: WER和现有指标与临床风险标签相关性差；优化的Gemini-2.5-Pro评估器达到90%准确率和0.816的Cohen's κ，性能与人类相当。

Conclusion: 该工作提供了一个经过验证的自动化框架，使ASR评估从简单的文本保真度转向必要的、可扩展的临床对话安全性评估。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [23] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 提出了一种无需人工标注训练数据的词义消歧方法，利用统计语言模型作为消歧器，将符号NLU系统生成的候选含义转换为可区分的自然语言替代项，通过LLM查询选择合适解释。


<details>
  <summary>Details</summary>
Motivation: 当前词义消歧方法主要针对粗粒度表示，需要人工标注训练数据，难以自动消歧更丰富的表示（如基于OpenCyc），这些表示对于复杂推理是必需的。

Method: 将符号NLU系统生成的多个候选含义转换为可区分的自然语言替代项，使用LLM查询根据语言上下文选择适当解释，然后将选定的含义传播回符号NLU系统。

Result: 通过与人工标注的黄金答案对比评估，证明了该方法的有效性。

Conclusion: 该方法提供了一种无需人工标注训练数据的词义消歧解决方案，能够处理更丰富的语义表示，为复杂推理任务提供支持。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [24] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 本文比较了多模态RAG系统中的两种检索方法：基于文本分块检索（图像先被LLM总结成文本）和直接多模态嵌入检索（图像以原生形式存储在向量空间中）。实验证明直接多模态嵌入检索显著优于基于LLM总结的方法，在金融财报问答任务上取得了13%的mAP@5绝对提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态RAG系统依赖LLM将图像总结成文本进行预处理，只将文本表示存储在向量数据库中，这导致上下文信息和视觉细节的丢失，对下游检索和问答任务至关重要。

Method: 对两种多模态RAG检索方法进行综合比较分析：1）文本分块检索（图像先被LLM总结成文本）；2）直接多模态嵌入检索（图像以原生形式存储在向量空间中）。在包含40个问答对的金融财报基准数据集上评估了6个LLM模型和2个多模态嵌入模型。

Result: 直接多模态嵌入检索显著优于基于LLM总结的方法，在mAP@5上取得13%的绝对提升（相对提升32%），在nDCG@5上取得11%的绝对提升（相对提升20%）。此外，直接多模态检索产生更准确和事实一致的答案。

Conclusion: LLM总结在预处理过程中引入信息损失，而直接多模态嵌入保留了用于检索和推理的视觉上下文。直接多模态嵌入检索在多模态RAG系统中具有实际应用价值。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


### [25] [Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs](https://arxiv.org/abs/2511.16664)
*Ali Taghibakhshi,Sharath Turuvekere Sreenivas,Saurav Muralidharan,Ruisi Cai,Marcin Chochowski,Ameya Sunil Mahabaleshwarkar,Yoshi Suhara,Oluwatobi Olabiyi,Daniel Korzekwa,Mostofa Patwary,Mohammad Shoeybi,Jan Kautz,Bryan Catanzaro,Ashwath Aithal,Nima Tajbakhsh,Pavlo Molchanov*

Main category: cs.CL

TL;DR: Nemotron Elastic是一个框架，用于构建推理导向的大型语言模型，通过单一父模型嵌入多个嵌套子模型，支持不同部署配置和预算，无需额外训练即可零样本提取。


<details>
  <summary>Details</summary>
Motivation: 训练针对不同规模和部署目标的大型语言模型家族成本过高，需要为每个不同大小的模型进行单独训练。现有的模型压缩方法虽然降低了成本，但每个压缩模型仍需数百亿token的训练成本。

Method: 采用混合Mamba-Attention架构，通过端到端训练的路由器与两阶段训练课程相结合，引入组感知SSM弹性化、异构MLP弹性化、基于归一化MSE的层重要性评估以及知识蒸馏，实现同时多预算优化。

Result: 应用于Nemotron Nano V2 12B模型，仅使用110B训练token同时生成9B和6B模型，相比从头训练模型家族成本降低360倍以上，相比最先进的压缩技术降低约7倍。每个嵌套模型在准确性上达到或超过最先进水平。

Conclusion: Nemotron Elastic框架提供了一种高效构建多尺度推理模型的方法，显著降低了训练成本，同时保持了模型性能，并且支持多合一推理模型，部署内存与模型家族数量无关。

Abstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [26] [QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation](https://arxiv.org/abs/2511.15996)
*Amin Bigdeli,Radin Hamidi Rad,Mert Incesu,Negar Arabzadeh,Charles L. A. Clarke,Ebrahim Bagheri*

Main category: cs.IR

TL;DR: QueryGym是一个轻量级、可扩展的Python工具包，为基于大语言模型的查询重写提供统一框架，解决现有方法实现分散、难以公平比较的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的查询重写方法虽然能显著提升检索效果，但各研究者的实现分散且不统一，阻碍了公平比较、快速实验、一致性基准测试和可靠部署。

Method: 提供统一的Python框架，包括：Python API支持多种LLM方法、检索无关的接口、集中式提示管理系统、内置基准测试支持以及完全开源的实现。

Result: 开发了QueryGym工具包，支持与Pyserini和PyTerrier等检索后端集成，提供版本控制和元数据跟踪的提示管理，并开源供所有研究人员使用。

Conclusion: QueryGym填补了LLM查询重写领域缺乏统一工具包的空白，为研究人员提供了公平比较和快速实验的基础设施，促进该领域的发展。

Abstract: We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.

</details>


### [27] [Incorporating Token Importance in Multi-Vector Retrieval](https://arxiv.org/abs/2511.16106)
*Archish S,Ankit Garg,Kirankumar Shiragur,Neeraj Kayal*

Main category: cs.IR

TL;DR: 本文提出了对ColBERT中Chamfer距离函数的改进，通过计算查询token贡献的加权和来增强表达力，在BEIR基准测试中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: ColBERT的Chamfer距离函数在计算相似度时平等对待所有查询token，但不同token的重要性可能不同，因此需要引入权重机制来更好地反映token的重要性。

Method: 在保持多向量表示固定的情况下，仅训练token权重，计算查询token贡献的加权和，其中权重反映token的重要性。

Result: 在BEIR基准测试中，零样本设置下使用IDF权重平均Recall@10提升1.28%，通过少样本微调提升3.66%。

Conclusion: 通过简单的token权重训练，可以显著增强ColBERT中后期交互多向量机制的表达能力，而无需改变原有的多向量表示。

Abstract: ColBERT introduced a late interaction mechanism that independently encodes queries and documents using BERT, and computes similarity via fine-grained interactions over token-level vector representations. This design enables expressive matching while allowing efficient computation of scores, as the multi-vector document representations could be pre-computed offline. ColBERT models distance using a Chamfer-style function: for each query token, it selects the closest document token and sums these distances across all query tokens.
  In our work, we explore enhancements to the Chamfer distance function by computing a weighted sum over query token contributions, where weights reflect the token importance. Empirically, we show that this simple extension, requiring only token-weight training while keeping the multi-vector representations fixed, further enhances the expressiveness of late interaction multi-vector mechanism. In particular, on the BEIR benchmark, our method achieves an average improvement of 1.28\% in Recall@10 in the zero-shot setting using IDF-based weights, and 3.66\% through few-shot fine-tuning.

</details>


### [28] [ARK: Answer-Centric Retriever Tuning via KG-augmented Curriculum Learning](https://arxiv.org/abs/2511.16326)
*Jiawei Zhou,Hang Ding,Haiyun Jiang*

Main category: cs.IR

TL;DR: 提出了一种针对检索增强生成（RAG）的答案对齐微调框架，通过课程式对比学习优化检索器，在长上下文场景中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 标准检索器在长上下文RAG中效果受限，因为它们基于查询-文档相似性优化，而不是与生成精确答案的下游目标对齐。

Method: 首先识别能够生成正确答案的高质量正样本块，然后使用基于知识图谱构建的增强查询进行课程式对比学习，挖掘渐进式困难负样本。

Result: 在10个Ultradomain和LongBench数据集上的实验表明，微调后的检索器达到最先进性能，比基础模型提升14.5%，同时保持长上下文RAG的高效性。

Conclusion: 该工作提供了一种构建真正以答案为中心的检索器的稳健有效方法，显著提升了RAG在知识密集型任务中的表现。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for knowledge-intensive tasks, yet its effectiveness in long-context scenarios is often bottlenecked by the retriever's inability to distinguish sparse yet crucial evidence. Standard retrievers, optimized for query-document similarity, frequently fail to align with the downstream goal of generating a precise answer. To bridge this gap, we propose a novel fine-tuning framework that optimizes the retriever for Answer Alignment. Specifically, we first identify high-quality positive chunks by evaluating their sufficiency to generate the correct answer. We then employ a curriculum-based contrastive learning scheme to fine-tune the retriever. This curriculum leverages LLM-constructed Knowledge Graphs (KGs) to generate augmented queries, which in turn mine progressively challenging hard negatives. This process trains the retriever to distinguish the answer-sufficient positive chunks from these nuanced distractors, enhancing its generalization. Extensive experiments on 10 datasets from the Ultradomain and LongBench benchmarks demonstrate that our fine-tuned retriever achieves state-of-the-art performance, improving 14.5% over the base model without substantial architectural modifications and maintaining strong efficiency for long-context RAG. Our work presents a robust and effective methodology for building truly answer-centric retrievers.

</details>


### [29] [An Efficient LLM-based Evolutional Recommendation with Locate-Forget-Update Paradigm](https://arxiv.org/abs/2511.16414)
*Hao Liu,Le Wu,Min Hou,Han Wu,Kun Zhang,Xin Li,Si Wei*

Main category: cs.IR

TL;DR: EvoRec是一个高效的定位-遗忘-更新框架，专门为基于LLM的推荐系统设计，通过识别和更新少量与偏好变化相关的参数来适应用户偏好的演化，同时节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的推荐系统难以适应不断变化的用户偏好，因为传统方法（重新训练或微调）在计算成本或偏好遗忘方面存在不足。

Method: 提出EvoRec框架，定位与偏好变化相关的少量参数，仅更新这些参数（仅占LoRA适配器参数的30%），不引入额外参数。

Result: 在两个真实数据集上的实验表明，EvoRec能有效适应用户偏好的演化，同时保护非活跃用户的兴趣不受干扰。

Conclusion: EvoRec为LLM推荐系统提供了一种高效的用户偏好演化建模方法，在保持性能的同时显著降低了计算成本。

Abstract: Nowadays, Large Language Models (LLMs) have shown exceptional performance in sequential recommendations, and the adoption of LLM-based recommender systems (LLMRec) is becoming increasingly widespread in existing e-commerce platforms. Despite the impressive performance, the constant high volume of new user-item interactions makes it difficult to adapt to the evolution of user preference over time, especially for LLM-based recommender systems. The challenge arises from the large number of parameters in LLMs, which makes traditional evolution methods (i.e., Re-training or Fine-tuning) impractical. Specifically, Re-training with all interactions results in prohibitively high computational costs. On the other hand, fine-tuning with only new interactions leads to preference forgetting among inactive users, ultimately compromising overall performance. To tackle this problem, we propose EvoRec, an efficient Locate-Forget-Update framework designed for LLM-based recommender systems to model the evolution of user preferences. EvoRec identifies a small set of parameters associated with preference changes and updates them precisely, thereby saving computational resources while maintaining strong recommendation performance. Notably, the modified parameters account for only 30\% of LoRA adapter parameters, with no additional parameters introduced. Extensive experiments on two real-world datasets demonstrate that, compared to existing methods, EvoRec not only efficiently evolves LLMRec to adapt to the preferences of active users, but also preserves the interests of inactive users from being disturbed during evolution.

</details>


### [30] [Music Recommendation with Large Language Models: Challenges, Opportunities, and Evaluation](https://arxiv.org/abs/2511.16478)
*Elena V. Epure,Yashar Deldjoo,Bruno Sguerra,Markus Schedl,Manuel Moussallam*

Main category: cs.IR

TL;DR: 本文探讨了大型语言模型（LLMs）如何改变音乐推荐系统的评估范式，主张需要重新思考评估方法，并提出了一个结构化的成功与风险维度框架。


<details>
  <summary>Details</summary>
Motivation: 传统音乐推荐系统主要基于信息检索框架，以准确性为衡量标准，但这种方法难以回答"什么是好的推荐"这一更深层次问题。LLMs的出现颠覆了这一框架，因为它们是基于生成而非排序的，使得标准准确性指标变得可疑。

Method: 首先回顾LLMs如何重塑用户建模、项目建模和自然语言推荐；然后检查NLP领域的评估实践，重点关注与MRS相关的方法论和开放挑战；最后综合见解，重点关注LLM提示在MRS中的应用，以构建结构化的成功与风险维度。

Result: 提出了一个更新的、教学性的、跨学科的评估视角，为MRS社区提供了应对LLM驱动推荐系统挑战的框架。

Conclusion: 向LLM驱动的音乐推荐系统的转变需要重新思考评估方法，本文为这一转变提供了理论基础和实践指导。

Abstract: Music Recommender Systems (MRS) have long relied on an information-retrieval framing, where progress is measured mainly through accuracy on retrieval-oriented subtasks. While effective, this reductionist paradigm struggles to address the deeper question of what makes a good recommendation, and attempts to broaden evaluation, through user studies or fairness analyses, have had limited impact. The emergence of Large Language Models (LLMs) disrupts this framework: LLMs are generative rather than ranking-based, making standard accuracy metrics questionable. They also introduce challenges such as hallucinations, knowledge cutoffs, non-determinism, and opaque training data, rendering traditional train/test protocols difficult to interpret. At the same time, LLMs create new opportunities, enabling natural-language interaction and even allowing models to act as evaluators.
  This work argues that the shift toward LLM-driven MRS requires rethinking evaluation. We first review how LLMs reshape user modeling, item modeling, and natural-language recommendation in music. We then examine evaluation practices from NLP, highlighting methodologies and open challenges relevant to MRS. Finally, we synthesize insights-focusing on how LLM prompting applies to MRS, to outline a structured set of success and risk dimensions. Our goal is to provide the MRS community with an updated, pedagogical, and cross-disciplinary perspective on evaluation.

</details>


### [31] [The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation](https://arxiv.org/abs/2511.16543)
*Jiaheng Zhang,Daqiang Zhang*

Main category: cs.IR

TL;DR: Prism框架通过解耦推荐和解释生成，使用知识蒸馏方法让小型学生模型从大型教师LLM学习生成高质量个性化解释，在保持性能的同时大幅提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决端到端可解释推荐系统中性能与效率的权衡问题，避免联合优化排序和解释时的次优妥协。

Method: 提出Prism解耦框架，将推荐过程分为专用排序阶段和解释生成阶段。使用大型教师LLM（如FLAN-T5-XXL）作为Oracle生成高保真解释知识，然后由经过微调的紧凑学生模型（如BART-Base）专门合成个性化解释。

Result: 在基准数据集上的实验表明，140M参数的Prism模型在忠实性和个性化的人类评估中显著优于11B参数的教师模型，推理速度提升24倍，内存消耗减少10倍。

Conclusion: 解耦结合有针对性的知识蒸馏为高质量可解释推荐提供了高效有效的途径。

Abstract: The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.
  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.
  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.

</details>


### [32] [PolyMinHash: Efficient Area-Based MinHashing of Polygons for Approximate Nearest Neighbor Search](https://arxiv.org/abs/2511.16576)
*Alima Subedi,Sankalpa Pokharel,Satish Puri*

Main category: cs.IR

TL;DR: PolyMinHash是一个用于多边形近似相似性搜索的系统，通过将MinHashing适配为2D多边形哈希方案来生成短且保持相似性的多边形签名。


<details>
  <summary>Details</summary>
Motivation: 随着数据集增大，精确最近邻搜索变得不可行，但现有ANN系统主要针对文本、图像和轨迹数据，多边形数据的ANN系统研究较少。

Method: 通过计算随机采样点落入多边形内部区域所需的点数来生成Minhash值，这些哈希值保持了基于面积的Jaccard相似性。

Result: 与暴力算法相比，哈希机制在查询细化阶段处理的候选数量减少了高达98%。

Conclusion: PolyMinHash系统在多边形相似性搜索中实现了搜索精度与运行时间之间的权衡，显著减少了候选处理数量。

Abstract: Similarity searches are a critical task in data mining. As data sets grow larger, exact nearest neighbor searches quickly become unfeasible, leading to the adoption of approximate nearest neighbor (ANN) searches. ANN has been studied for text data, images, and trajectories. However, there has been little effort to develop ANN systems for polygons in spatial database systems and geographic information systems. We present PolyMinHash, a system for approximate polygon similarity search that adapts MinHashing into a novel 2D polygon-hashing scheme to generate short, similarity-preserving signatures of input polygons. Minhash is generated by counting the number of randomly sampled points needed before the sampled point lands within the polygon's interior area, yielding hash values that preserve area-based Jaccard similarity. We present the tradeoff between search accuracy and runtime of our PolyMinHash system. Our hashing mechanism reduces the number of candidates to be processed in the query refinement phase by up to 98% compared to the number of candidates processed by the brute-force algorithm.

</details>
