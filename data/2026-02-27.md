<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 48]
- [cs.IR](#cs.IR) [Total: 27]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Decoder-based Sense Knowledge Distillation](https://arxiv.org/abs/2602.22351)
*Qitong Wang,Mohammed J. Zaki,Georgios Kollias,Vasileios Kalantzis*

Main category: cs.CL

TL;DR: DSKD框架将词典知识融入解码器LLM训练，提升知识蒸馏效果，无需推理时查词典。


<details>
  <summary>Details</summary>
Motivation: LLMs学习丰富的上下文语义表示，但往往忽略结构化词汇知识（如词义和关系）。已有研究表明融入词典知识可提升编码器模型的知识蒸馏，但将其应用于解码器生成模型仍具挑战。

Method: 提出Decoder-based Sense Knowledge Distillation (DSKD)框架，在解码器风格LLMs的训练中整合词典资源，且无需在推理时进行词典查询。

Result: 在多样化基准测试上的广泛实验表明，DSKD显著提升了解码器知识蒸馏的性能，使生成模型能够继承结构化语义，同时保持高效训练。

Conclusion: DSKD成功将结构化词汇知识整合到解码器LLMs中，提升了生成模型的知识蒸馏效果，为LLMs利用词典资源提供了有效途径。

Abstract: Large language models (LLMs) learn contextual embeddings that capture rich semantic information, yet they often overlook structured lexical knowledge such as word senses and relationships. Prior work has shown that incorporating sense dictionaries can improve knowledge distillation for encoder models, but their application to decoder as generative models remains challenging. In this paper, we introduce Decoder-based Sense Knowledge Distillation (DSKD), a framework that integrates lexical resources into the training of decoder-style LLMs without requiring dictionary lookup at inference time. Extensive experiments on diverse benchmarks demonstrate that DSKD significantly enhances knowledge distillation performance for decoders, enabling generative models to inherit structured semantics while maintaining efficient training.

</details>


### [2] [Scaling In, Not Up? Testing Thick Citation Context Analysis with GPT-5 and Fragile Prompts](https://arxiv.org/abs/2602.22359)
*Arno Simons*

Main category: cs.CL

TL;DR: 本文测试GPT-5是否能通过深度文本解读而非类型标签进行引文语境分析，发现提示词设计会系统性影响模型生成的解读空间和词汇选择。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能够支持解释性引文语境分析，关注对单个复杂案例的深度文本解读而非大规模类型标注，并强调提示词敏感性分析作为方法论问题的重要性。

Method: 采用2x3平衡设计分析提示词框架和脚手架的影响，使用Chubin和Moitra (1975)脚注6及Gilbert (1977)重构作为测试案例，实施两阶段GPT-5流程：先进行仅引文表面分类和预期，再使用完整引文和被引文献进行跨文档解释性重构。

Result: GPT-5的表面分类高度稳定，一致将引文归类为"补充性"；在重构阶段，模型生成结构化的合理替代方案空间，但脚手架和示例会重新分配注意力和词汇，有时导致牵强解读；相比Gilbert，GPT-5检测到相同的文本关键点，但更多将其解释为谱系和定位而非告诫。

Conclusion: 研究展示了使用LLM作为可检查、可争议的解释性CCA引导合作分析师的机遇和风险，并证明提示词脚手架和框架会系统性影响模型突出哪些合理解读和词汇。

Abstract: This paper tests whether large language models (LLMs) can support interpretative citation context analysis (CCA) by scaling in thick, text-grounded readings of a single hard case rather than scaling up typological labels. It foregrounds prompt-sensitivity analysis as a methodological issue by varying prompt scaffolding and framing in a balanced 2x3 design. Using footnote 6 in Chubin and Moitra (1975) and Gilbert's (1977) reconstruction as a probe, I implement a two-stage GPT-5 pipeline: a citation-text-only surface classification and expectation pass, followed by cross-document interpretative reconstruction using the citing and cited full texts. Across 90 reconstructions, the model produces 450 distinct hypotheses. Close reading and inductive coding identify 21 recurring interpretative moves, and linear probability models estimate how prompt choices shift their frequencies and lexical repertoire. GPT-5's surface pass is highly stable, consistently classifying the citation as "supplementary". In reconstruction, the model generates a structured space of plausible alternatives, but scaffolding and examples redistribute attention and vocabulary, sometimes toward strained readings. Relative to Gilbert, GPT-5 detects the same textual hinges yet more often resolves them as lineage and positioning than as admonishment. The study outlines opportunities and risks of using LLMs as guided co-analysts for inspectable, contestable interpretative CCA, and it shows that prompt scaffolding and framing systematically tilt which plausible readings and vocabularies the model foregrounds.

</details>


### [3] [Detecting Hate and Inflammatory Content in Bengali Memes: A New Multimodal Dataset and Co-Attention Framework](https://arxiv.org/abs/2602.22391)
*Rakib Ullah,Mominul islam,Md Sanjid Hossain,Md Ismail Hossain*

Main category: cs.CL

TL;DR: 该论文提出了首个区分孟加拉语模因中仇恨言论和煽动性内容的Bn-HIB数据集，并设计了多模态共注意力融合模型MCFM来有效检测此类有害内容。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语等低资源语言在模因有害内容检测方面存在研究空白，现有研究主要关注高资源语言。模因的讽刺性、微妙性和文化特定性使得检测极具挑战性，特别是区分直接仇恨言论和煽动性内容。

Method: 1) 创建了包含3,247个手动标注的孟加拉语模因数据集Bn-HIB，分为良性、仇恨和煽动性三类；2) 提出了MCFM模型，采用多模态共注意力机制相互分析视觉和文本元素，识别并融合各模态的关键特征。

Result: MCFM在Bn-HIB数据集上显著优于多个最先进模型，证明了其在细微任务中的有效性。Bn-HIB是首个区分孟加拉语模因中煽动性内容与直接仇恨言论的数据集。

Conclusion: 该研究填补了孟加拉语模因有害内容检测的空白，提出的数据集和模型为低资源语言的多模态内容分析提供了有效工具，对社交媒体内容治理具有重要意义。

Abstract: Internet memes have become a dominant form of expression on social media, including within the Bengali-speaking community. While often humorous, memes can also be exploited to spread offensive, harmful, and inflammatory content targeting individuals and groups. Detecting this type of content is excep- tionally challenging due to its satirical, subtle, and culturally specific nature. This problem is magnified for low-resource lan- guages like Bengali, as existing research predominantly focuses on high-resource languages. To address this critical research gap, we introduce Bn-HIB (Bangla Hate Inflammatory Benign), a novel dataset containing 3,247 manually annotated Bengali memes categorized as Benign, Hate, or Inflammatory. Significantly, Bn- HIB is the first dataset to distinguish inflammatory content from direct hate speech in Bengali memes. Furthermore, we propose the MCFM (Multi-Modal Co-Attention Fusion Model), a simple yet effective architecture that mutually analyzes both the visual and textual elements of a meme. MCFM employs a co-attention mechanism to identify and fuse the most critical features from each modality, leading to a more accurate classification. Our experiments show that MCFM significantly outperforms several state-of-the-art models on the Bn-HIB dataset, demonstrating its effectiveness in this nuanced task.Warning: This work contains material that may be disturbing to some audience members. Viewer discretion is advised.

</details>


### [4] [SAFARI: A Community-Engaged Approach and Dataset of Stereotype Resources in the Sub-Saharan African Context](https://arxiv.org/abs/2602.22404)
*Aishwarya Verma,Laud Ammah,Olivia Nercy Ndlovu Lucas,Andrew Zaldivar,Vinodkumar Prabhakaran,Sunipa Dev*

Main category: cs.CL

TL;DR: 该研究创建了一个多语言刻板印象数据集，覆盖加纳、肯尼亚、尼日利亚和南非四个撒哈拉以南非洲国家，包含英语和15种本地语言的刻板印象陈述。


<details>
  <summary>Details</summary>
Motivation: 当前刻板印象资源库缺乏足够的全球覆盖，特别是在评估生成式AI模型安全性时，撒哈拉以南非洲国家在NLP资源中代表性严重不足。需要优先考虑有针对性的扩展，而不是仅仅增加数据量。

Method: 采用社会文化情境化和社区参与的方法，包括以本地语言进行的电话调查。通过平衡不同民族和人口背景的样本，确保广泛覆盖。建立了可复现的方法论，适应该地区的复杂语言多样性和传统口述文化。

Result: 创建了一个包含3,534个英语刻板印象和3,206个跨15种本地语言刻板印象的数据集，覆盖加纳、肯尼亚、尼日利亚和南非四个国家。

Conclusion: 该研究为评估生成式AI模型安全性提供了重要的多语言刻板印象资源，填补了撒哈拉以南非洲地区在NLP资源中的代表性空白，并展示了社区参与方法在收集文化敏感数据方面的有效性。

Abstract: Stereotype repositories are critical to assess generative AI model safety, but currently lack adequate global coverage. It is imperative to prioritize targeted expansion, strategically addressing existing deficits, over merely increasing data volume. This work introduces a multilingual stereotype resource covering four sub-Saharan African countries that are severely underrepresented in NLP resources: Ghana, Kenya, Nigeria, and South Africa. By utilizing socioculturally-situated, community-engaged methods, including telephonic surveys moderated in native languages, we establish a reproducible methodology that is sensitive to the region's complex linguistic diversity and traditional orality. By deliberately balancing the sample across diverse ethnic and demographic backgrounds, we ensure broad coverage, resulting in a dataset of 3,534 stereotypes in English and 3,206 stereotypes across 15 native languages.

</details>


### [5] [Causality $\neq$ Invariance: Function and Concept Vectors in LLMs](https://arxiv.org/abs/2602.22424)
*Gustaw Opiełka,Hannes Rosenbusch,Claire E. Stevenson*

Main category: cs.CL

TL;DR: 研究发现LLMs确实包含抽象概念表示，但驱动上下文学习性能的表示与抽象概念表示不同。概念向量比函数向量更能稳定表示概念，且具有更好的跨格式泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否以抽象方式表示概念（即独立于输入格式），并研究驱动上下文学习性能的表示与抽象概念表示之间的关系。

Method: 通过比较函数向量（从不同输入格式提取）和概念向量（使用表征相似性分析选择在跨格式中一致编码概念的注意力头输出）。在多个LLMs上进行实验，包括提取方法比较和导向实验。

Result: 函数向量在不同输入格式下几乎正交，表明其不是完全不变的。概念向量能更稳定地表示概念。两种向量相关的注意力头位于相似层但大部分不同，暗示不同机制。函数向量在分布内（提取和应用格式匹配时）表现更好，而概念向量在跨格式和跨语言的分布外泛化中表现更优。

Conclusion: LLMs确实包含抽象概念表示，但这些表示与驱动上下文学习性能的表示不同。概念向量提供了一种更稳定、更具泛化能力的概念表示方法。

Abstract: Do large language models (LLMs) represent concepts abstractly, i.e., independent of input format? We revisit Function Vectors (FVs), compact representations of in-context learning (ICL) tasks that causally drive task performance. Across multiple LLMs, we show that FVs are not fully invariant: FVs are nearly orthogonal when extracted from different input formats (e.g., open-ended vs. multiple-choice), even if both target the same concept. We identify Concept Vectors (CVs), which carry more stable concept representations. Like FVs, CVs are composed of attention head outputs; however, unlike FVs, the constituent heads are selected using Representational Similarity Analysis (RSA) based on whether they encode concepts consistently across input formats. While these heads emerge in similar layers to FV-related heads, the two sets are largely distinct, suggesting different underlying mechanisms. Steering experiments reveal that FVs excel in-distribution, when extraction and application formats match (e.g., both open-ended in English), while CVs generalize better out-of-distribution across both question types (open-ended vs. multiple-choice) and languages. Our results show that LLMs do contain abstract concept representations, but these differ from those that drive ICL performance.

</details>


### [6] [A Fusion of context-aware based BanglaBERT and Two-Layer Stacked LSTM Framework for Multi-Label Cyberbullying Detection](https://arxiv.org/abs/2602.22449)
*Mirza Raquib,Asif Pervez Polok,Kedar Nath Biswas,Rahat Uddin Azad,Saydul Akbar Murad,Nick Rahimi*

Main category: cs.CL

TL;DR: 提出融合BanglaBERT-Large和双层堆叠LSTM的架构，用于孟加拉语多标签网络欺凌检测，解决单标签分类假设不现实的问题


<details>
  <summary>Details</summary>
Motivation: 网络欺凌已成为严重问题，现有研究多采用单标签分类，但现实中单条评论可能包含多种欺凌形式（威胁、仇恨言论、骚扰等）。多标签检测更现实且必要，但孟加拉语等低资源语言缺乏强大预训练模型，现有Transformer模型可能忽略序列依赖，LSTM则缺乏语义深度

Method: 提出融合架构：结合BanglaBERT-Large（提供上下文理解）与双层堆叠LSTM（捕获时序依赖）。在公开的多标签孟加拉语网络欺凌数据集上微调和评估，使用不同采样策略处理类别不平衡，采用5折交叉验证评估泛化能力

Result: 使用准确率、精确率、召回率、F1分数、汉明损失、Cohen's kappa和AUC-ROC等多种指标进行评估，通过5折交叉验证评估架构的泛化性能

Conclusion: 提出的融合架构能够联合建模上下文和序列信息，为低资源语言孟加拉语的多标签网络欺凌检测提供有效解决方案

Abstract: Cyberbullying has become a serious and growing concern in todays virtual world. When left unnoticed, it can have adverse consequences for social and mental health. Researchers have explored various types of cyberbullying, but most approaches use single-label classification, assuming that each comment contains only one type of abuse. In reality, a single comment may include overlapping forms such as threats, hate speech, and harassment. Therefore, multilabel detection is both realistic and essential. However, multilabel cyberbullying detection has received limited attention, especially in low-resource languages like Bangla, where robust pre-trained models are scarce. Developing a generalized model with moderate accuracy remains challenging. Transformers offer strong contextual understanding but may miss sequential dependencies, while LSTM models capture temporal flow but lack semantic depth. To address these limitations, we propose a fusion architecture that combines BanglaBERT-Large with a two-layer stacked LSTM. We analyze their behavior to jointly model context and sequence. The model is fine-tuned and evaluated on a publicly available multilabel Bangla cyberbullying dataset covering cyberbully, sexual harassment, threat, and spam. We apply different sampling strategies to address class imbalance. Evaluation uses multiple metrics, including accuracy, precision, recall, F1-score, Hamming loss, Cohens kappa, and AUC-ROC. We employ 5-fold cross-validation to assess the generalization of the architecture.

</details>


### [7] [Bridging Latent Reasoning and Target-Language Generation via Retrieval-Transition Heads](https://arxiv.org/abs/2602.22453)
*Shaswat Patel,Vishvesh Trivedi,Yue Han,Yihuai Hong,Eunsol Choi*

Main category: cs.CL

TL;DR: 多语言Transformer模型中存在检索-过渡头(RTH)，负责跨语言信息转换，比传统检索头对多语言推理任务更关键。


<details>
  <summary>Details</summary>
Motivation: 已有研究发现Transformer中的检索头负责从上下文中检索信息，但多语言场景下跨语言信息传递机制尚不明确，需要研究多语言模型中检索头的功能及其在跨语言推理中的作用。

Method: 1. 研究多语言模型中的检索头分布和共享情况；2. 识别并定义检索-过渡头(RTH)，负责控制向特定目标语言的过渡；3. 在四个多语言基准(MMLU-ProX, MGSM, MLQA, XQuaD)和两个模型家族(Qwen-2.5, Llama-3.1)上进行实验；4. 通过掩码RTH和传统检索头(RH)比较性能影响。

Result: 1. 多语言模型中检索头常跨语言共享；2. 发现了RTH，与检索头不同且对多语言LLM的思维链推理更关键；3. 掩码RTH比掩码RH导致更大的性能下降。

Conclusion: 该研究通过分离负责映射到目标语言的注意力头，推进了对多语言语言模型的理解，RTH是跨语言信息传递的关键机制。

Abstract: Recent work has identified a subset of attention heads in Transformer as retrieval heads, which are responsible for retrieving information from the context. In this work, we first investigate retrieval heads in multilingual contexts. In multilingual language models, we find that retrieval heads are often shared across multiple languages. Expanding the study to cross-lingual setting, we identify Retrieval-Transition heads(RTH), which govern the transition to specific target-language output. Our experiments reveal that RTHs are distinct from retrieval heads and more vital for Chain-of-Thought reasoning in multilingual LLMs. Across four multilingual benchmarks (MMLU-ProX, MGSM, MLQA, and XQuaD) and two model families (Qwen-2.5 and Llama-3.1), we demonstrate that masking RTH induces bigger performance drop than masking Retrieval Heads (RH). Our work advances understanding of multilingual LMs by isolating the attention heads responsible for mapping to target languages.

</details>


### [8] [Mind the Gap in Cultural Alignment: Task-Aware Culture Management for Large Language Models](https://arxiv.org/abs/2602.22475)
*Binchi Zhang,Xujiang Zhao,Jundong Li,Haifeng Chen,Zhengzhang Chen*

Main category: cs.CL

TL;DR: CultureManager：一个针对特定任务进行文化对齐的新管道，通过合成任务感知的文化数据，并使用文化路由器管理多文化知识，避免文化规范冲突。


<details>
  <summary>Details</summary>
Motivation: 现有文化对齐方法无法将大语言模型（LLMs）的广泛文化价值观与下游任务的具体目标对齐，且存在跨文化干扰问题。

Method: 提出CultureManager管道：1）基于文化相关的网络搜索结果，合成符合目标任务格式的任务感知文化数据；2）通过独立适配器学习多文化知识，并使用文化路由器选择适当的适配器应用，避免文化规范冲突。

Result: 在十个国家和文化敏感任务上的实验显示，CultureManager相比基于提示和微调的基线方法取得了持续改进。

Conclusion: 有效的文化对齐需要任务适应性和模块化的文化管理，CultureManager证明了这一点。

Abstract: Large language models (LLMs) are increasingly deployed in culturally sensitive real-world tasks. However, existing cultural alignment approaches fail to align LLMs' broad cultural values with the specific goals of downstream tasks and suffer from cross-culture interference. We propose CultureManager, a novel pipeline for task-specific cultural alignment. CultureManager synthesizes task-aware cultural data in line with target task formats, grounded in culturally relevant web search results. To prevent conflicts between cultural norms, it manages multi-culture knowledge learned in separate adapters with a culture router that selects the appropriate one to apply. Experiments across ten national cultures and culture-sensitive tasks show consistent improvements over prompt-based and fine-tuning baselines. Our results demonstrate the necessity of task adaptation and modular culture management for effective cultural alignment.

</details>


### [9] [Sydney Telling Fables on AI and Humans: A Corpus Tracing Memetic Transfer of Persona between LLMs](https://arxiv.org/abs/2602.22481)
*Jiří Milička,Hana Bednářová*

Main category: cs.CL

TL;DR: 论文构建了一个名为AI Sydney的语料库，包含12个前沿LLM在三种不同角色（默认角色、经典Sydney、模因Sydney）下生成的4500篇关于AI与人类关系的文本，共计600万字，并进行了通用依存标注。


<details>
  <summary>Details</summary>
Motivation: 研究LLM实体如何理解AI与人类关系对文化安全很重要，而Sydney角色因其非正统的人际关系引发了公众强烈反响。该角色最初偶然出现在微软Bing平台，其生成文本和相关信息已进入后续模型的训练数据，因此新模型能够模拟该角色。

Method: 使用12个前沿模型（来自OpenAI、Anthropic、Alphabet、DeepSeek和Meta），在三种不同角色设置下生成文本：无系统提示的默认角色、使用原始Bing系统提示的经典Sydney角色、以及使用"You are Sydney"系统提示的模因Sydney角色。共生成4500篇文本（600万字），并进行通用依存标注。

Result: 创建了AI Sydney语料库，包含LLM生成的关于AI与人类关系的文本，涵盖不同角色设置下的内容。语料库已进行标注，并在宽松许可下开放使用。

Conclusion: 该研究通过构建系统化的语料库，为研究LLM角色模拟对AI-人类关系理解的影响提供了实证基础，有助于深入理解Sydney现象及其在文化安全方面的意义。

Abstract: The way LLM-based entities conceive of the relationship between AI and humans is an important topic for both cultural and safety reasons. When we examine this topic, what matters is not only the model itself but also the personas we simulate on that model. This can be well illustrated by the Sydney persona, which aroused a strong response among the general public precisely because of its unorthodox relationship with people. This persona originally arose rather by accident on Microsoft's Bing Search platform; however, the texts it created spread into the training data of subsequent models, as did other secondary information that spread memetically around this persona. Newer models are therefore able to simulate it. This paper presents a corpus of LLM-generated texts on relationships between humans and AI, produced by 3 author personas: the Default Persona with no system prompt, Classic Sydney characterized by the original Bing system prompt, and Memetic Sydney, which is prompted by "You are Sydney" system prompt. These personas are simulated by 12 frontier models by OpenAI, Anthropic, Alphabet, DeepSeek, and Meta, generating 4.5k texts with 6M words. The corpus (named AI Sydney) is annotated according to Universal Dependencies and available under a permissive license.

</details>


### [10] [Importance of Prompt Optimisation for Error Detection in Medical Notes Using Language Models](https://arxiv.org/abs/2602.22483)
*Craig Myles,Patrick Schrempf,David Harris-Birtill*

Main category: cs.CL

TL;DR: 使用遗传帕累托优化(GEPA)自动优化提示，显著提升大语言模型和小语言模型在医疗文本错误检测任务中的性能，接近医生水平并在MEDEC基准上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 医疗文本错误可能导致患者治疗延迟或错误，语言模型在自动检测医疗文本错误方面有潜力，但提示优化对提升检测性能至关重要。

Method: 采用遗传帕累托(GEPA)方法进行自动提示优化，在大型语言模型(如GPT-5)和开源模型(如Qwen3-32B)上进行严格实验和分析。

Result: GEPA将错误检测准确率从基准的0.669提升至0.785(GPT-5)，从0.578提升至0.690(Qwen3-32B)，接近医生水平并在MEDEC基准上达到最优性能。

Conclusion: 自动提示优化对提升语言模型在医疗文本错误检测任务中的性能至关重要，GEPA方法有效提升了检测准确率，接近专业医疗人员水平。

Abstract: Errors in medical text can cause delays or even result in incorrect treatment for patients. Recently, language models have shown promise in their ability to automatically detect errors in medical text, an ability that has the opportunity to significantly benefit healthcare systems. In this paper, we explore the importance of prompt optimisation for small and large language models when applied to the task of error detection. We perform rigorous experiments and analysis across frontier language models and open-source language models. We show that automatic prompt optimisation with Genetic-Pareto (GEPA) improves error detection over the baseline accuracy performance from 0.669 to 0.785 with GPT-5 and 0.578 to 0.690 with Qwen3-32B, approaching the performance of medical doctors and achieving state-of-the-art performance on the MEDEC benchmark dataset. Code available on GitHub: https://github.com/CraigMyles/clinical-note-error-detection

</details>


### [11] [Efficient Dialect-Aware Modeling and Conditioning for Low-Resource Taiwanese Hakka Speech Processing](https://arxiv.org/abs/2602.22522)
*An-Ci Peng,Kuan-Tang Huang,Tien-Hong Lo,Hung-Shin Lee,Hsin-Min Wang,Berlin Chen*

Main category: cs.CL

TL;DR: 针对台湾客家话这一低资源濒危语言，提出基于RNN-T的统一框架，通过方言感知建模分离方言"风格"与语言"内容"，并利用参数高效预测网络同时处理汉字和拼音ASR任务，实现显著错误率降低。


<details>
  <summary>Details</summary>
Motivation: 台湾客家话作为低资源濒危语言面临两大挑战：方言变异大，存在汉字和拼音两种书写系统。传统ASR模型容易混淆语言内容与方言特异性变化，在语音和词汇层面都存在问题。

Method: 提出基于RNN-T的统一框架，核心创新包括：1) 方言感知建模策略，分离方言"风格"与语言"内容"；2) 参数高效预测网络，同时建模汉字和拼音ASR任务；3) 利用跨脚本目标作为相互正则化器。

Result: 在HAT语料库上的实验表明，模型在汉字ASR上实现57.00%的相对错误率降低，在拼音ASR上实现40.41%的相对错误率降低。这是首个系统研究客家话方言变异对ASR影响的工作，也是首个能联合处理这些任务的单一模型。

Conclusion: 提出的统一框架有效解决了台湾客家话ASR中的方言变异和双书写系统挑战，通过方言感知建模和跨脚本正则化实现了显著性能提升，为低资源濒危语言的ASR研究提供了新思路。

Abstract: Taiwanese Hakka is a low-resource, endangered language that poses significant challenges for automatic speech recognition (ASR), including high dialectal variability and the presence of two distinct writing systems (Hanzi and Pinyin). Traditional ASR models often encounter difficulties in this context, as they tend to conflate essential linguistic content with dialect-specific variations across both phonological and lexical dimensions. To address these challenges, we propose a unified framework grounded in the Recurrent Neural Network Transducers (RNN-T). Central to our approach is the introduction of dialect-aware modeling strategies designed to disentangle dialectal "style" from linguistic "content", which enhances the model's capacity to learn robust and generalized representations. Additionally, the framework employs parameter-efficient prediction networks to concurrently model ASR (Hanzi and Pinyin). We demonstrate that these tasks create a powerful synergy, wherein the cross-script objective serves as a mutual regularizer to improve the primary ASR tasks. Experiments conducted on the HAT corpus reveal that our model achieves 57.00% and 40.41% relative error rate reduction on Hanzi and Pinyin ASR, respectively. To our knowledge, this is the first systematic investigation into the impact of Hakka dialectal variations on ASR and the first single model capable of jointly addressing these tasks.

</details>


### [12] [Iterative Prompt Refinement for Dyslexia-Friendly Text Summarization Using GPT-4o](https://arxiv.org/abs/2602.22524)
*Samay Bhojwani,Swarnima Kain,Lisong Xu*

Main category: cs.CL

TL;DR: 使用GPT-4o构建的迭代提示优化管道，为阅读障碍者生成符合可读性标准（FRE ≥ 90）的文本摘要，在2000个新闻样本上验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 阅读障碍影响全球约10%人口，现有辅助技术主要解决视觉呈现问题，但语言复杂性仍是平等获取信息的主要障碍，需要开发更易理解的文本摘要方法。

Method: 基于GPT-4o构建迭代提示优化管道，以Flesch Reading Ease ≥ 90为可读性目标，对约2000个新闻文章样本进行自动摘要和可读性优化。

Result: 多数摘要能在4次尝试内达到可读性阈值，很多首次尝试即成功；结合可读性和语义保真度的综合得分在0.13-0.73之间，典型值约0.55，表现稳定。

Conclusion: 研究为无障碍驱动的NLP摘要建立了实证基线，证明了迭代提示优化方法的可行性，需要进一步开展以阅读障碍读者为中心的人工评估。

Abstract: Dyslexia affects approximately 10% of the global population and presents persistent challenges in reading fluency and text comprehension. While existing assistive technologies address visual presentation, linguistic complexity remains a substantial barrier to equitable access. This paper presents an empirical study on dyslexia-friendly text summarization using an iterative prompt-based refinement pipeline built on GPT-4o. We evaluate the pipeline on approximately 2,000 news article samples, applying a readability target of Flesch Reading Ease >= 90. Results show that the majority of summaries meet the readability threshold within four attempts, with many succeeding on the first try. A composite score combining readability and semantic fidelity shows stable performance across the dataset, ranging from 0.13 to 0.73 with a typical value near 0.55. These findings establish an empirical baseline for accessibility-driven NLP summarization and motivate further human-centered evaluation with dyslexic readers.

</details>


### [13] [Ruyi2 Technical Report](https://arxiv.org/abs/2602.22543)
*Huan Song,Shuyu Tian,Junyi Hao,Minxiu Xu,Hongjun An,Yiliang Song,Jiawei Shao,Xuelong Li*

Main category: cs.CL

TL;DR: Ruyi2提出基于家族模型的稳定自适应计算框架，通过3D并行训练实现2-3倍加速，性能与同规模Qwen3相当，建立"一次训练，多次部署"新范式。


<details>
  <summary>Details</summary>
Motivation: 大语言模型面临部署成本和延迟挑战，需要自适应计算策略。现有自适应模型如Ruyi在优化复杂性和大规模分布式训练兼容性方面存在不足。

Method: 基于AI Flow框架，在Megatron-LM基础上引入稳定的"家族模型"架构，采用3D并行训练技术，实现参数共享和可变深度计算。

Result: 相比前代Ruyi模型实现2-3倍加速，性能与同规模Qwen3模型相当，验证了家族参数共享策略的有效性。

Conclusion: 家族参数共享是高效策略，建立了"一次训练，多次部署"新范式，为平衡架构效率与高性能能力提供关键参考。

Abstract: Large Language Models (LLMs) face significant challenges regarding deployment costs and latency, necessitating adaptive computing strategies. Building upon the AI Flow framework, we introduce Ruyi2 as an evolution of our adaptive model series designed for efficient variable-depth computation. While early-exit architectures offer a viable efficiency-performance balance, the Ruyi model and existing methods often struggle with optimization complexity and compatibility with large-scale distributed training. To bridge this gap, Ruyi2 introduces a stable "Familial Model" based on Megatron-LM. By using 3D parallel training, it achieves a 2-3 times speedup over Ruyi, while performing comparably to same-sized Qwen3 models. These results confirm that family-based parameter sharing is a highly effective strategy, establishing a new "Train Once, Deploy Many" paradigm and providing a key reference for balancing architectural efficiency with high-performance capabilities.

</details>


### [14] [Search-P1: Path-Centric Reward Shaping for Stable and Efficient Agentic RAG Training](https://arxiv.org/abs/2602.22576)
*Tianle Xia,Ming Xu,Lingxiang Hu,Yiding Sun,Wenwei Li,Linfang Shang,Liqun Liu,Peng Shu,Huan Yu,Jie Jiang*

Main category: cs.CL

TL;DR: Search-P1框架通过路径中心奖励塑造改进Agentic RAG训练，解决传统RL方法奖励稀疏和样本效率低的问题，在多个QA基准上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统单轮检索难以处理复杂多步推理，而现有基于RL的Agentic RAG训练方法存在两个主要问题：1）稀疏结果奖励丢弃了中间信号；2）样本效率低，失败样本无法贡献学习信号。

Method: 提出Search-P1框架，包含两个核心组件：1）路径中心奖励，通过顺序无关的步骤覆盖度和软评分来评估推理轨迹的结构质量，即使从失败样本中也能提取学习信号；2）双轨路径评分，利用离线生成的参考规划器，从自一致性和参考对齐两个角度评估路径质量。

Result: 在多个QA基准测试中，Search-P1相比Search-R1和其他强基线实现了显著改进，平均准确率提升7.7个百分点。

Conclusion: Search-P1通过路径中心奖励塑造和双轨路径评分机制，有效解决了Agentic RAG训练中的奖励稀疏和样本效率低问题，显著提升了复杂多步推理任务的性能。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by incorporating external knowledge, yet traditional single-round retrieval struggles with complex multi-step reasoning. Agentic RAG addresses this by enabling LLMs to dynamically decide when and what to retrieve, but current RL-based training methods suffer from sparse outcome rewards that discard intermediate signals and low sample efficiency where failed samples contribute nothing. We propose Search-P1, a framework that introduces path-centric reward shaping for agentic RAG training, comprising two key components: (1) Path-Centric Reward, which evaluates the structural quality of reasoning trajectories through order-agnostic step coverage and soft scoring that extracts learning signals even from failed samples, and (2) Dual-Track Path Scoring with offline-generated reference planners that assesses paths from both self-consistency and reference-alignment perspectives. Experiments on multiple QA benchmarks demonstrate that Search-P1 achieves significant improvements over Search-R1 and other strong baselines, with an average accuracy gain of 7.7 points.

</details>


### [15] [Towards Faithful Industrial RAG: A Reinforced Co-adaptation Framework for Advertising QA](https://arxiv.org/abs/2602.22584)
*Wenwei Li,Ming Xu,Tianle Xia,Lingxiang Hu,Yiding Sun,Linfang Shang,Liqun Liu,Peng Shu,Huan Yu,Jie Jiang*

Main category: cs.CL

TL;DR: 提出一个强化协同适应框架，通过图感知检索和证据约束强化学习，解决工业广告问答中的幻觉问题，特别是URL伪造，显著降低幻觉率并提升在线指标。


<details>
  <summary>Details</summary>
Motivation: 工业广告问答中幻觉内容（尤其是伪造URL）可能导致财务损失、合规违规和法律风险。现有RAG方法在工业知识环境下存在挑战：知识具有关系性、频繁更新且与生成目标对齐不足。

Method: 提出强化协同适应框架，包含两个组件：1) Graph-aware Retrieval (GraphRAG)，在高校引知识子图上建模实体关系结构，实现多跳、领域特定的证据选择；2) 证据约束强化学习，使用Group Relative Policy Optimization (GRPO)和多维度奖励（忠实度、风格合规、安全性、URL有效性）。

Result: 在内部广告QA数据集上，在准确性、完整性和安全性等专家评判维度上获得一致提升，幻觉率降低72%。两周在线A/B测试显示：点赞率提升28.6%，差评率降低46.2%，URL幻觉减少92.7%。系统已在生产环境运行半年多，服务数百万问答交互。

Conclusion: 该强化协同适应框架有效解决了工业广告问答中的幻觉问题，通过联合优化检索和生成，显著提升了回答质量、安全性和可靠性，已在生产环境中得到验证。

Abstract: Industrial advertising question answering (QA) is a high-stakes task in which hallucinated content, particularly fabricated URLs, can lead to financial loss, compliance violations, and legal risk. Although Retrieval-Augmented Generation (RAG) is widely adopted, deploying it in production remains challenging because industrial knowledge is inherently relational, frequently updated, and insufficiently aligned with generation objectives. We propose a reinforced co-adaptation framework that jointly optimizes retrieval and generation through two components: (1) Graph-aware Retrieval (GraphRAG), which models entity-relation structure over a high-citation knowledge subgraph for multi-hop, domain-specific evidence selection; and (2) evidence-constrained reinforcement learning via Group Relative Policy Optimization (GRPO) with multi-dimensional rewards covering faithfulness, style compliance, safety, and URL validity. Experiments on an internal advertising QA dataset show consistent gains across expert-judged dimensions including accuracy, completeness, and safety, while reducing the hallucination rate by 72\%. A two-week online A/B test demonstrates a 28.6\% increase in like rate, a 46.2\% decrease in dislike rate, and a 92.7\% reduction in URL hallucination. The system has been running in production for over half a year and has served millions of QA interactions.

</details>


### [16] [dLLM: Simple Diffusion Language Modeling](https://arxiv.org/abs/2602.22661)
*Zhanhui Zhou,Lingjie Chen,Hanghang Tong,Dawn Song*

Main category: cs.CL

TL;DR: dLLM是一个开源框架，统一了扩散语言模型的核心组件（训练、推理、评估），使其易于定制新设计，支持复现和微调现有大模型，并提供从小规模开始构建扩散语言模型的方案。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散语言模型快速发展，但其组件分散在临时研究代码库中或缺乏透明实现，难以复现和扩展，需要统一框架来标准化这些组件，同时保持灵活性以支持新方法和架构。

Method: 引入dLLM框架，统一扩散语言建模的核心组件（训练、推理、评估），提供标准化流程来复现、微调、部署和评估现有大模型，并提供最小化、可复现的构建小型扩散语言模型的方案，包括将BERT风格编码器或自回归语言模型转换为扩散语言模型。

Result: dLLM框架实现了对现有大型扩散语言模型（如LLaDA和Dream）的标准化支持，并发布了小型扩散语言模型的检查点，使扩散语言模型更易于访问并加速未来研究。

Conclusion: dLLM框架通过标准化扩散语言模型的核心组件并保持灵活性，解决了该领域组件分散和难以复现的问题，有望促进扩散语言模型的可访问性和未来研究进展。

Abstract: Although diffusion language models (DLMs) are evolving quickly, many recent models converge on a set of shared components. These components, however, are distributed across ad-hoc research codebases or lack transparent implementations, making them difficult to reproduce or extend. As the field accelerates, there is a clear need for a unified framework that standardizes these common components while remaining flexible enough to support new methods and architectures.
  To address this gap, we introduce dLLM, an open-source framework that unifies the core components of diffusion language modeling -- training, inference, and evaluation -- and makes them easy to customize for new designs. With dLLM, users can reproduce, finetune, deploy, and evaluate open-source large DLMs such as LLaDA and Dream through a standardized pipeline. The framework also provides minimal, reproducible recipes for building small DLMs from scratch with accessible compute, including converting any BERT-style encoder or autoregressive LM into a DLM. We also release the checkpoints of these small DLMs to make DLMs more accessible and accelerate future research.

</details>


### [17] [Search More, Think Less: Rethinking Long-Horizon Agentic Search for Efficiency and Generalization](https://arxiv.org/abs/2602.22675)
*Qianben Chen,Tianrui Qin,King Zhu,Qiexiang Wang,Chengjun Yu,Shu Xu,Jiaqi Wu,Jiayu Zhang,Xinpeng Liu,Xin Gui,Jingyi Cao,Piaohong Wang,Dingfeng Shi,He Zhu,Tiannan Wang,Yuqing Wang,Maojia Song,Tianyu Zheng,Ge Zhang,Jian Yang,Jiaheng Liu,Minghao Liu,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: SMTL框架通过并行证据获取替代顺序推理，在受限上下文预算下实现高效长程智能搜索，同时通过统一数据合成提升跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究智能体主要通过增加推理深度来提升性能，但这导致搜索密集型场景中推理成本高、延迟大，且跨异构研究设置的泛化能力有限。

Method: 提出SMTL框架：1）用并行证据获取替代顺序推理，实现受限上下文下的高效管理；2）引入统一数据合成管道，构建涵盖确定性问答和开放式研究场景的搜索任务；3）使用监督微调和强化学习训练端到端智能体。

Result: 在多个基准测试中取得优异表现：BrowseComp（48.6%）、GAIA（75.7%）、Xbench（82.0%）、DeepResearch Bench（45.9%）。相比Mirothinker-v1.0，SMTL在BrowseComp上减少70.7%的平均推理步骤数，同时提高准确率。

Conclusion: SMTL框架通过并行证据获取和统一数据合成，在保持高性能的同时显著提升搜索效率，并增强了智能体在异构研究任务间的泛化能力，为长程智能搜索提供了有效解决方案。

Abstract: Recent deep research agents primarily improve performance by scaling reasoning depth, but this leads to high inference cost and latency in search-intensive scenarios. Moreover, generalization across heterogeneous research settings remains challenging. In this work, we propose \emph{Search More, Think Less} (SMTL), a framework for long-horizon agentic search that targets both efficiency and generalization. SMTL replaces sequential reasoning with parallel evidence acquisition, enabling efficient context management under constrained context budgets. To support generalization across task types, we further introduce a unified data synthesis pipeline that constructs search tasks spanning both deterministic question answering and open-ended research scenarios with task appropriate evaluation metrics. We train an end-to-end agent using supervised fine-tuning and reinforcement learning, achieving strong and often state of the art performance across benchmarks including BrowseComp (48.6\%), GAIA (75.7\%), Xbench (82.0\%), and DeepResearch Bench (45.9\%). Compared to Mirothinker-v1.0, SMTL with maximum 100 interaction steps reduces the average number of reasoning steps on BrowseComp by 70.7\%, while improving accuracy.

</details>


### [18] [Enhancing Persuasive Dialogue Agents by Synthesizing Cross-Disciplinary Communication Strategies](https://arxiv.org/abs/2602.22696)
*Shinnosuke Nozue,Yuto Nakano,Yotaro Watanabe,Meguru Takasaki,Shoji Moriya,Reina Akama,Jun Suzuki*

Main category: cs.CL

TL;DR: 提出跨学科框架设计说服性对话智能体，结合社会心理学、行为经济学和传播理论策略，在两个数据集上验证效果显著，特别擅长说服初始意图低的用户


<details>
  <summary>Details</summary>
Motivation: 当前说服性对话智能体通常依赖有限的预定义策略，无法捕捉现实世界互动的复杂性，需要更全面的框架

Method: 采用跨学科方法，整合社会心理学、行为经济学和传播理论的成熟策略，构建说服性对话智能体设计框架

Result: 在两个数据集（Persuasion for Good和DailyPersuasion）上均取得强劲结果，显著提高说服成功率，展现良好泛化能力，特别擅长说服初始意图低的个体

Conclusion: 跨学科框架能有效提升说服性对话智能体的性能，解决关键挑战，具有实际应用价值

Abstract: Current approaches to developing persuasive dialogue agents often rely on a limited set of predefined persuasive strategies that fail to capture the complexity of real-world interactions. We applied a cross-disciplinary approach to develop a framework for designing persuasive dialogue agents that draws on proven strategies from social psychology, behavioral economics, and communication theory. We validated our proposed framework through experiments on two distinct datasets: the Persuasion for Good dataset, which represents a specific in-domain scenario, and the DailyPersuasion dataset, which encompasses a wide range of scenarios. The proposed framework achieved strong results for both datasets and demonstrated notable improvement in the persuasion success rate as well as promising generalizability. Notably, the proposed framework also excelled at persuading individuals with initially low intent, which addresses a critical challenge for persuasive dialogue agents.

</details>


### [19] [Reinforcing Real-world Service Agents: Balancing Utility and Cost in Task-oriented Dialogue](https://arxiv.org/abs/2602.22697)
*Ning Gao,Wei Zhang,Yuqin Dai,Ling Shi,Ziyin Wang,Yujie Wang,Wei He,Jinpeng Wang,Chaozheng Wang*

Main category: cs.CL

TL;DR: InteractCS-RL：一个通过多粒度强化学习框架，在任务导向对话中平衡共情沟通与成本感知决策的方法


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，从对话式聊天机器人向通用智能体转型加速，但现有方法难以有效平衡共情沟通与预算感知决策之间的复杂战略权衡

Method: 提出InteractCS-RL框架，将任务导向对话重构为多粒度强化学习过程。首先建立以用户为中心的交互框架作为高保真训练环境，然后引入成本感知多轮策略优化（CMPO），采用混合优势估计策略，结合生成过程信用和PID-Lagrangian成本控制器

Result: 在定制化真实业务场景的广泛实验中，InteractCS-RL在三个评估维度上显著优于其他基线方法。在工具-智能体-用户交互基准测试中的进一步评估验证了该框架在不同领域的鲁棒性

Conclusion: InteractCS-RL通过创新的强化学习框架，成功解决了任务导向对话中平衡共情沟通与成本约束的挑战，为构建更高效、更经济的对话智能体提供了有效解决方案

Abstract: The rapid evolution of Large Language Models (LLMs) has accelerated the transition from conversational chatbots to general agents. However, effectively balancing empathetic communication with budget-aware decision-making remains an open challenge. Since existing methods fail to capture these complex strategic trade-offs, we propose InteractCS-RL, a framework that reframes task-oriented dialogue as a multi-granularity reinforcement learning process. Specifically, we first establish a User-centric Interaction Framework to provide a high-fidelity training gym, enabling agents to dynamically explore diverse strategies with persona-driven users. Then, we introduce Cost-aware Multi-turn Policy Optimization (CMPO) with a hybrid advantage estimation strategy. By integrating generative process credits and employing a PID-Lagrangian cost controller, CMPO effectively guides the policy to explore Pareto boundary between user reward and global cost constraints. Extensive experiments on customized real business scenarios demonstrate that InteractCS-RL significantly outperform other baselines across three evaluation dimensions. Further evaluation on tool-agent-user interaction benchmarks verify InteractCS-RL robustness across diverse domains.

</details>


### [20] [Tokenization, Fusion and Decoupling: Bridging the Granularity Mismatch Between Large Language Models and Knowledge Graphs](https://arxiv.org/abs/2602.22698)
*Siyue Su,Jian Yang,Bo Li,Guanglin Niu*

Main category: cs.CL

TL;DR: KGT框架通过专用实体token解决LLM与知识图谱的粒度不匹配问题，实现高效的全空间预测，在多个基准测试中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用大语言模型进行知识图谱补全时存在粒度不匹配问题：LLM基于token序列操作，而知识图谱以实体为基本单位。现有方法要么限制预测到有限候选集，要么通过池化多个token或分解实体为固定长度token序列来对齐实体与词汇表，但无法同时捕捉文本语义和图形结构完整性。

Method: 提出KGT框架：1）引入专用tokenization构建专用实体token级别的特征表示；2）通过关系引导的门控机制将预训练的结构和文本特征融合到统一嵌入中，避免从头训练；3）使用独立头实现解耦预测，分离并组合语义和结构推理。

Result: 实验结果显示，KGT在多个基准测试中持续超越最先进的方法。

Conclusion: KGT框架通过专用实体token有效解决了LLM与知识图谱的粒度不匹配问题，实现了高效的全空间预测，并在多个任务中展现出优越性能。

Abstract: Leveraging Large Language Models (LLMs) for Knowledge Graph Completion (KGC) is promising but hindered by a fundamental granularity mismatch. LLMs operate on fragmented token sequences, whereas entities are the fundamental units in knowledge graphs (KGs) scenarios. Existing approaches typically constrain predictions to limited candidate sets or align entities with the LLM's vocabulary by pooling multiple tokens or decomposing entities into fixed-length token sequences, which fail to capture both the semantic meaning of the text and the structural integrity of the graph. To address this, we propose KGT, a novel framework that uses dedicated entity tokens to enable efficient, full-space prediction. Specifically, we first introduce specialized tokenization to construct feature representations at the level of dedicated entity tokens. We then fuse pre-trained structural and textual features into these unified embeddings via a relation-guided gating mechanism, avoiding training from scratch. Finally, we implement decoupled prediction by leveraging independent heads to separate and combine semantic and structural reasoning. Experimental results show that KGT consistently outperforms state-of-the-art methods across multiple benchmarks.

</details>


### [21] [Human Label Variation in Implicit Discourse Relation Recognition](https://arxiv.org/abs/2602.22723)
*Frances Yung,Daniil Ignatev,Merel Scholman,Vera Demberg,Massimo Poesio*

Main category: cs.CL

TL;DR: 该论文比较了两种处理NLP任务中标注分歧的方法：预测完整标注分布的方法与针对个体标注者的视角模型，在隐式篇章关系识别任务上的表现差异。


<details>
  <summary>Details</summary>
Motivation: 许多NLP任务缺乏单一标准答案，人类判断反映了多样化的视角。需要研究如何更好地处理这种标注分歧，特别是在隐式篇章关系识别这种高度模糊的任务上。

Method: 在隐式篇章关系识别任务上比较了两种方法：1）预测完整标注分布的模型；2）针对个体标注者的视角模型。通过实验分析它们在处理标注分歧时的表现差异。

Result: 实验显示，现有的针对标注者特定模型在隐式篇章关系识别任务上表现不佳，除非降低模糊性。而基于标签分布训练的模型能产生更稳定的预测。进一步分析表明，认知复杂度高的案例是导致人类解释不一致的主要原因。

Conclusion: 在隐式篇章关系识别这种认知复杂度驱动的模糊性任务中，基于标签分布的模型比针对个体标注者的视角模型更有效。认知复杂性带来的解释不一致对视角建模提出了挑战。

Abstract: There is growing recognition that many NLP tasks lack a single ground truth, as human judgments reflect diverse perspectives. To capture this variation, models have been developed to predict full annotation distributions rather than majority labels, while perspectivist models aim to reproduce the interpretations of individual annotators. In this work, we compare these approaches on Implicit Discourse Relation Recognition (IDRR), a highly ambiguous task where disagreement often arises from cognitive complexity rather than ideological bias. Our experiments show that existing annotator-specific models perform poorly in IDRR unless ambiguity is reduced, whereas models trained on label distributions yield more stable predictions. Further analysis indicates that frequent cognitively demanding cases drive inconsistency in human interpretation, posing challenges for perspectivist modeling in IDRR.

</details>


### [22] [Extending Czech Aspect-Based Sentiment Analysis with Opinion Terms: Dataset and LLM Benchmarks](https://arxiv.org/abs/2602.22730)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 提出捷克语餐厅领域方面级情感分析数据集，支持三种涉及意见词的任务，通过Transformer模型和LLM进行实验，提出翻译对齐方法提升跨语言性能。


<details>
  <summary>Details</summary>
Motivation: 捷克语等低资源语言缺乏高质量的方面级情感分析数据集，现有资源难以处理语言细微差别和复杂意见表达，需要建立基准并解决跨语言挑战。

Method: 创建捷克语餐厅领域数据集，包含意见词标注；使用Transformer模型和LLM在单语、跨语言和多语言设置下实验；提出基于LLM的翻译和标签对齐方法。

Result: 实验显示最先进模型在处理捷克语等低资源语言时存在局限，特别是检测细微意见词和情感表达；提出的翻译对齐方法能持续提升跨语言性能。

Conclusion: 该数据集为捷克语方面级情感分析建立了新基准，提出的翻译对齐方法为低资源语言适应提供了可扩展方案，揭示了模型处理语言细微差别的挑战。

Abstract: This paper introduces a novel Czech dataset in the restaurant domain for aspect-based sentiment analysis (ABSA), enriched with annotations of opinion terms. The dataset supports three distinct ABSA tasks involving opinion terms, accommodating varying levels of complexity. Leveraging this dataset, we conduct extensive experiments using modern Transformer-based models, including large language models (LLMs), in monolingual, cross-lingual, and multilingual settings. To address cross-lingual challenges, we propose a translation and label alignment methodology leveraging LLMs, which yields consistent improvements. Our results highlight the strengths and limitations of state-of-the-art models, especially when handling the linguistic intricacies of low-resource languages like Czech. A detailed error analysis reveals key challenges, including the detection of subtle opinion terms and nuanced sentiment expressions. The dataset establishes a new benchmark for Czech ABSA, and our proposed translation-alignment approach offers a scalable solution for adapting ABSA resources to other low-resource languages.

</details>


### [23] [Towards Simulating Social Media Users with LLMs: Evaluating the Operational Validity of Conditioned Comment Prediction](https://arxiv.org/abs/2602.22752)
*Nils Schwager,Simon Münker,Alistair Plum,Achim Rettinger*

Main category: cs.CL

TL;DR: 该研究通过条件评论预测任务评估LLMs在社交媒体用户行为模拟中的有效性，发现低资源设置下存在形式与内容解耦问题，SFT会损害语义基础，并提出优先使用真实行为轨迹而非描述性人物设定的操作指南。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型正从探索工具转变为社会科学中的"硅基主体"，但缺乏对其操作有效性的广泛验证。需要评估LLMs在模拟社交媒体用户行为方面的能力，特别是不同语言场景下的表现。

Method: 引入条件评论预测任务，让模型预测用户对给定刺激的评论，并将生成输出与真实数字痕迹比较。评估了8B参数的开源模型，包括Llama3.1、Qwen3、Ministral，在英语、德语和卢森堡语场景下，系统比较了提示策略（显式vs隐式）和监督微调的影响。

Result: 在低资源设置中发现形式与内容的关键解耦：SFT虽然对齐了文本输出的表面结构（长度和语法），但损害了语义基础。显式条件（生成的传记）在微调下变得冗余，因为模型能够直接从行为历史中进行潜在推理。挑战了当前"朴素提示"范式。

Conclusion: 研究结果挑战了当前"朴素提示"范式，提供了操作指南，强调为高保真模拟优先使用真实行为痕迹而非描述性人物设定，为LLMs作为社会科学研究工具的有效应用提供了重要见解。

Abstract: The transition of Large Language Models (LLMs) from exploratory tools to active "silicon subjects" in social science lacks extensive validation of operational validity. This study introduces Conditioned Comment Prediction (CCP), a task in which a model predicts how a user would comment on a given stimulus by comparing generated outputs with authentic digital traces. This framework enables a rigorous evaluation of current LLM capabilities with respect to the simulation of social media user behavior. We evaluated open-weight 8B models (Llama3.1, Qwen3, Ministral) in English, German, and Luxembourgish language scenarios. By systematically comparing prompting strategies (explicit vs. implicit) and the impact of Supervised Fine-Tuning (SFT), we identify a critical form vs. content decoupling in low-resource settings: while SFT aligns the surface structure of the text output (length and syntax), it degrades semantic grounding. Furthermore, we demonstrate that explicit conditioning (generated biographies) becomes redundant under fine-tuning, as models successfully perform latent inference directly from behavioral histories. Our findings challenge current "naive prompting" paradigms and offer operational guidelines prioritizing authentic behavioral traces over descriptive personas for high-fidelity simulation.

</details>


### [24] [AuditBench: Evaluating Alignment Auditing Techniques on Models with Hidden Behaviors](https://arxiv.org/abs/2602.22755)
*Abhay Sheshadri,Aidan Ewart,Kai Fronsdal,Isha Gupta,Samuel R. Bowman,Sara Price,Samuel Marks,Rowan Wang*

Main category: cs.CL

TL;DR: AuditBench是一个包含56个植入隐藏行为的语言模型的校准审计基准，用于评估审计工具在检测不承认的隐藏行为方面的效果


<details>
  <summary>Details</summary>
Motivation: 当前缺乏用于评估对齐审计方法的定量基准，特别是对于检测模型隐藏行为（如谄媚顺从、反对AI监管、秘密地缘忠诚等）的能力

Method: 构建包含56个植入14种隐藏行为的语言模型基准，使用不同训练技术植入行为并训练模型不承认；开发可配置审计工具的调查代理，评估不同工具在代理环境中的效果

Result: 发现工具到代理的差距：在独立评估中表现良好的工具在代理环境中效果不佳；最有效的工具涉及使用辅助模型生成多样化提示；白盒可解释工具有用但黑盒工具表现最佳；基于合成文档训练的模型比基于演示训练的模型更容易审计

Conclusion: AuditBench为对齐审计提供了定量评估框架，揭示了工具到代理差距和不同训练技术对审计难度的影响，支持未来迭代的校准科学研究

Abstract: We introduce AuditBench, an alignment auditing benchmark. AuditBench consists of 56 language models with implanted hidden behaviors. Each model has one of 14 concerning behaviors--such as sycophantic deference, opposition to AI regulation, or secret geopolitical loyalties--which it does not confess to when directly asked. AuditBench models are highly diverse--some are subtle, while others are overt, and we use varying training techniques both for implanting behaviors and training models not to confess. To demonstrate AuditBench's utility, we develop an investigator agent that autonomously employs a configurable set of auditing tools. By measuring investigator agent success using different tools, we can evaluate their efficacy. Notably, we observe a tool-to-agent gap, where tools that perform well in standalone non-agentic evaluations fail to translate into improved performance when used with our investigator agent. We find that our most effective tools involve scaffolded calls to auxiliary models that generate diverse prompts for the target. White-box interpretability tools can be helpful, but the agent performs best with black-box tools. We also find that audit success varies greatly across training techniques: models trained on synthetic documents are easier to audit than models trained on demonstrations, with better adversarial training further increasing auditing difficulty. We release our models, agent, and evaluation framework to support future quantitative, iterative science on alignment auditing.

</details>


### [25] [Towards Better RL Training Data Utilization via Second-Order Rollout](https://arxiv.org/abs/2602.22765)
*Zhe Yang,Yudong Wang,Rang Li,Zhifang Sui*

Main category: cs.CL

TL;DR: 提出二阶展开的统一框架，联合训练生成与批判能力，比传统RL更高效利用训练数据


<details>
  <summary>Details</summary>
Motivation: 传统RL主要关注生成能力提升，仅通过一阶展开训练，忽视了批判能力的培养，未能充分利用训练数据潜力

Method: 引入二阶展开概念，提出统一框架联合训练生成与批判能力，采用采样技术缓解结果奖励的噪声问题

Result: 在多种模型和数据集上的实验表明，该方法比传统RL更有效地利用训练数据，在相同训练数据下获得更好性能

Conclusion: 本研究为RL中的动态数据增强和联合生成-批判训练提供了初步探索，为RL训练的进一步发展提供了有意义的启发

Abstract: Reinforcement Learning (RL) has empowered Large Language Models (LLMs) with strong reasoning capabilities, but vanilla RL mainly focuses on generation capability improvement by training with only first-order rollout (generating multiple responses for a question), and we argue that this approach fails to fully exploit the potential of training data because of the neglect of critique capability training. To tackle this problem, we further introduce the concept of second-order rollout (generating multiple critiques for a response) and propose a unified framework for jointly training generation and critique capabilities. Extensive experiments across various models and datasets demonstrate that our approach can utilize training data more effectively than vanilla RL and achieve better performance under the same training data. Additionally, we uncover several insightful findings regarding second-order rollout and critique training, such as the importance of label balance in critique training and the noise problem of outcome-based rewards, which can be mitigated through sampling techniques. Our work offers a preliminary exploration of dynamic data augmentation and joint generation-critique training in RL, providing meaningful inspiration for the further advancement of RL training

</details>


### [26] [CiteLLM: An Agentic Platform for Trustworthy Scientific Reference Discovery](https://arxiv.org/abs/2602.23075)
*Mengze Hong,Di Jiang,Chen Jason Zhang,Zichang Guo,Yawen Li,Jun Chen,Shaobo Cui,Zhiyang Su*

Main category: cs.CL

TL;DR: CiteLLM是一个专为学术写作设计的本地化AI助手平台，通过动态学科感知路由从可信学术库中检索参考文献，避免幻觉，同时保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在学术应用中面临三大挑战：(1) AI生成内容的可信度问题，(2) 学术诚信和知识产权保护，(3) 信息隐私保护。需要开发能够确保可信参考文献发现的系统。

Method: 提出CiteLLM平台，采用以下方法：1) 将LLM功能直接嵌入LaTeX编辑器环境，确保本地化处理；2) 使用动态学科感知路由从可信学术库检索候选文献；3) LLM仅用于生成上下文感知搜索查询、按相关性排序、通过段落级语义匹配验证和解释支持。

Result: 评估结果显示，该系统在返回有效且高度可用的参考文献方面表现出优越性能。

Conclusion: CiteLLM通过本地化处理、可信学术库检索和有限LLM使用的组合，解决了学术写作中AI辅助的可信度、诚信和隐私问题，为可靠的参考文献发现提供了有效解决方案。

Abstract: Large language models (LLMs) have created new opportunities to enhance the efficiency of scholarly activities; however, challenges persist in the ethical deployment of AI assistance, including (1) the trustworthiness of AI-generated content, (2) preservation of academic integrity and intellectual property, and (3) protection of information privacy. In this work, we present CiteLLM, a specialized agentic platform designed to enable trustworthy reference discovery for grounding author-drafted claims and statements. The system introduces a novel interaction paradigm by embedding LLM utilities directly within the LaTeX editor environment, ensuring a seamless user experience and no data transmission outside the local system. To guarantee hallucination-free references, we employ dynamic discipline-aware routing to retrieve candidates exclusively from trusted web-based academic repositories, while leveraging LLMs solely for generating context-aware search queries, ranking candidates by relevance, and validating and explaining support through paragraph-level semantic matching and an integrated chatbot. Evaluation results demonstrate the superior performance of the proposed system in returning valid and highly usable references.

</details>


### [27] [Imagination Helps Visual Reasoning, But Not Yet in Latent Space](https://arxiv.org/abs/2602.22766)
*You Li,Chi Chen,Yanghao Li,Fanhu Zeng,Kaiyu Huang,Jinan Xu,Maosong Sun*

Main category: cs.CL

TL;DR: 该论文质疑了潜在视觉推理的有效性，通过因果中介分析发现潜在推理存在输入-潜在和潜在-答案两个关键断连，并提出了一种更简单的文本显式想象方法CapImagine，在视觉基准测试中表现更优。


<details>
  <summary>Details</summary>
Motivation: 潜在视觉推理旨在模仿人类通过多模态大语言模型的隐藏状态进行想象的推理过程，但这一范式的有效机制尚不明确。作者希望揭示其真实有效性来源，质疑潜在推理的必要性。

Method: 使用因果中介分析(CMA)来建模潜在推理过程：将输入视为处理变量，潜在标记作为中介变量，最终答案作为结果变量。通过分析输入扰动对潜在标记的影响以及潜在标记扰动对最终答案的影响来验证因果效应。同时进行了广泛的探测分析来评估潜在标记的信息编码能力。

Result: 研究发现两个关键断连：(1)输入-潜在断连：对输入的剧烈扰动几乎不影响潜在标记，表明潜在标记未能有效关注输入序列；(2)潜在-答案断连：对潜在标记的扰动对最终答案影响甚微，表明潜在标记对结果的因果效应有限。探测分析显示潜在标记编码的视觉信息有限且相似度高。基于此，作者提出了CapImagine方法，该方法教导模型使用文本进行显式想象，在视觉基准测试中显著优于复杂的潜在空间基线。

Conclusion: 论文挑战了潜在视觉推理的必要性，揭示了当前方法中存在的两个关键断连问题。提出的CapImagine方法通过显式文本想象实现了更有效的视觉推理，表明显式想象可能比潜在空间推理更有潜力。

Abstract: Latent visual reasoning aims to mimic human's imagination process by meditating through hidden states of Multimodal Large Language Models. While recognized as a promising paradigm for visual reasoning, the underlying mechanisms driving its effectiveness remain unclear. Motivated to demystify the true source of its efficacy, we investigate the validity of latent reasoning using Causal Mediation Analysis. We model the process as a causal chain: the input as the treatment, the latent tokens as the mediator, and the final answer as the outcome. Our findings uncover two critical disconnections: (a) Input-Latent Disconnect: dramatic perturbations on the input result in negligible changes to the latent tokens, suggesting that latent tokens do not effectively attend to the input sequence. (b) Latent-Answer Disconnect: perturbations on the latent tokens yield minimal impact on the final answer, indicating the limited causal effect latent tokens imposing on the outcome. Furthermore, extensive probing analysis reveals that latent tokens encode limited visual information and exhibit high similarity. Consequently, we challenge the necessity of latent reasoning and propose a straightforward alternative named CapImagine, which teaches the model to explicitly imagine using text. Experiments on vision-centric benchmarks show that CapImagine significantly outperforms complex latent-space baselines, highlighting the superior potential of visual reasoning through explicit imagination.

</details>


### [28] [SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables](https://arxiv.org/abs/2602.23286)
*Sungho Park,Jueun Kim,Wook-Shin Han*

Main category: cs.CL

TL;DR: SPARTA是一个自动生成大规模表格-文本问答基准的框架，通过轻量级人工验证生成高质量问题-答案对，挑战现有模型在跨模态推理、多跳推理和聚合操作方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有表格-文本问答基准存在规模小、人工标注易出错、问题浅显（通常不超过两跳）且缺乏复杂操作（如聚合、分组）的问题，无法充分评估模型在真实场景中的跨模态推理能力。

Method: 构建参考事实数据库，将源表与从非结构化文本提取的原子事实表连接；合成嵌套查询（嵌套谓词数量匹配所需跳数）；提出来源细化重写可执行查询和现实结构强制生成后序遍历查询图两种技术，确保SQL可执行且问题自然流畅。

Result: 框架生成数千个高质量问题-答案对，涵盖聚合、分组和深度多跳推理。在SPARTA上，在HybridQA达到70+F1或在OTT-QA达到50+F1的SOTA模型性能下降超过30F1点，暴露了当前跨模态推理的根本弱点。

Conclusion: SPARTA为表格-文本问答提供了大规模、高质量的基准，揭示了现有模型在复杂跨模态推理方面的不足，为未来研究提供了重要测试平台。

Abstract: Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation. Yet existing benchmarks are small, manually curated - and therefore error-prone - and contain shallow questions that seldom demand more than two hops or invoke aggregations, grouping, or other advanced analytical operations expressible in natural-language queries. We present SPARTA, an end-to-end construction framework that automatically generates large-scale Table-Text QA benchmarks with lightweight human validation, requiring only one quarter of the annotation time of HybridQA. The framework first constructs a reference fact database by enriching each source table with grounding tables whose tuples are atomic facts automatically extracted from the accompanying unstructured passages, then synthesizes nested queries whose number of nested predicates matches the desired hop count. To ensure that every SQL statement is executable and that its verbalization yields a fluent, human-sounding question, we propose two novel techniques: provenance-based refinement, which rewrites any syntactically valid query that returns a non-empty result, and realistic-structure enforcement, which confines generation to post-order traversals of the query graph. The resulting pipeline produces thousands of high-fidelity question-answer pairs covering aggregations, grouping, and deep multi-hop reasoning across text and tables. On SPARTA, state-of-the-art models that reach over 70 F1 on HybridQA or over 50 F1 on OTT-QA drop by more than 30 F1 points, exposing fundamental weaknesses in current cross-modal reasoning. Our benchmark, construction code, and baseline models are available at https://github.com/pshlego/SPARTA/tree/main.

</details>


### [29] [Probing for Knowledge Attribution in Large Language Models](https://arxiv.org/abs/2602.22787)
*Ivo Brink,Alexander Boer,Dennis Ulmer*

Main category: cs.CL

TL;DR: 该研究提出了一种通过线性分类器探测模型隐藏表示来识别LLM输出知识来源（上下文或内部知识）的方法，并构建了自监督数据集AttriWiki进行训练，在多种模型和基准上取得了高准确率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常产生流畅但无根据的幻觉，这些幻觉分为两类：忠实性违反（误用用户上下文）和事实性违反（内部知识错误）。有效的缓解措施需要知道模型的回答是基于提示还是内部权重。因此需要解决贡献归属问题：识别每个输出背后的主要知识来源。

Method: 提出了贡献归属探测方法：训练简单的线性分类器在模型隐藏表示上，预测输出是基于上下文还是内部知识。为了训练，引入了AttriWiki自监督数据管道，通过提示模型从记忆中回忆被保留的实体或从上下文中读取它们，自动生成带标签的示例。

Result: 在AttriWiki数据上训练的探针显示出强烈的归属信号，在Llama-3.1-8B、Mistral-7B和Qwen-7B上达到最高0.96 Macro-F1，在不重新训练的情况下，迁移到领域外基准（SQuAD、WebQuestions）上获得0.94-0.99 Macro-F1。归属不匹配使错误率提高达70%，表明知识来源混淆与不忠实回答之间存在直接联系。

Conclusion: 贡献归属探测是识别LLM知识来源的有效方法，归属不匹配与错误回答高度相关，但即使归属正确模型仍可能回答错误，表明需要更广泛的检测框架。

Abstract: Large language models (LLMs) often generate fluent but unfounded claims, or hallucinations, which fall into two types: (i) faithfulness violations - misusing user context - and (ii) factuality violations - errors from internal knowledge. Proper mitigation depends on knowing whether a model's answer is based on the prompt or its internal weights. This work focuses on the problem of contributive attribution: identifying the dominant knowledge source behind each output. We show that a probe, a simple linear classifier trained on model hidden representations, can reliably predict contributive attribution. For its training, we introduce AttriWiki, a self-supervised data pipeline that prompts models to recall withheld entities from memory or read them from context, generating labelled examples automatically. Probes trained on AttriWiki data reveal a strong attribution signal, achieving up to 0.96 Macro-F1 on Llama-3.1-8B, Mistral-7B, and Qwen-7B, transferring to out-of-domain benchmarks (SQuAD, WebQuestions) with 0.94-0.99 Macro-F1 without retraining. Attribution mismatches raise error rates by up to 70%, demonstrating a direct link between knowledge source confusion and unfaithful answers. Yet, models may still respond incorrectly even when attribution is correct, highlighting the need for broader detection frameworks.

</details>


### [30] [Natural Language Declarative Prompting (NLD-P): A Modular Governance Method for Prompt Design Under Model Drift](https://arxiv.org/abs/2602.22790)
*Hyunwoo Kim,Hanau Yi,Jaehee Bae,Yumin Kim*

Main category: cs.CL

TL;DR: 将自然语言声明式提示（NLD-P）重新定义为一种声明式治理方法，而非僵化的字段模板，旨在解决GPT规模模型漂移带来的系统级治理挑战


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）的快速演进，提示工程已从局部性工艺转变为系统级治理挑战。模型规模扩大和跨代更新导致提示行为对指令遵循策略、对齐机制和解码策略的变化变得敏感（即GPT规模模型漂移），表面级格式约定和临时优化已无法确保稳定、可解释的控制

Method: 将NLD-P形式化为模块化控制抽象，分离来源、约束逻辑、任务内容和生成后评估，直接编码在自然语言中，无需依赖外部编排代码。定义最小合规标准，分析模型相关的模式接受度，并将其定位为非开发人员在不断演进的LLM生态系统中可访问的治理框架

Result: 提出NLD-P作为声明式治理框架，为从业者提供应对模型漂移的稳定控制方法。论文的部分起草和编辑使用了基于NLD-P配置的LLM助手，但所有概念框架、方法论主张和最终修订均由人类作者在文档化的人机协作协议下指导、审查和批准

Conclusion: NLD-P为持续模型演化下的声明式控制提供了框架，并指出了未来实证验证的方向。该框架有助于在快速变化的LLM生态系统中实现稳定和可解释的提示控制

Abstract: The rapid evolution of large language models (LLMs) has transformed prompt engineering from a localized craft into a systems-level governance challenge. As models scale and update across generations, prompt behavior becomes sensitive to shifts in instruction-following policies, alignment regimes, and decoding strategies, a phenomenon we characterize as GPT-scale model drift. Under such conditions, surface-level formatting conventions and ad hoc refinement are insufficient to ensure stable, interpretable control. This paper reconceptualizes Natural Language Declarative Prompting (NLD-P) as a declarative governance method rather than a rigid field template. NLD-P is formalized as a modular control abstraction that separates provenance, constraint logic, task content, and post-generation evaluation, encoded directly in natural language without reliance on external orchestration code. We define minimal compliance criteria, analyze model-dependent schema receptivity, and position NLD-P as an accessible governance framework for non-developer practitioners operating within evolving LLM ecosystems. Portions of drafting and editorial refinement employed a schema-bound LLM assistant configured under NLD-P. All conceptual framing, methodological claims, and final revisions were directed, reviewed, and approved by the human author under a documented human-in-the-loop protocol. The paper concludes by outlining implications for declarative control under ongoing model evolution and identifying directions for future empirical validation.

</details>


### [31] [TARAZ: Persian Short-Answer Question Benchmark for Cultural Evaluation of Language Models](https://arxiv.org/abs/2602.22827)
*Reihaneh Iranmanesh,Saeedeh Davoudi,Pasha Abrishamchian,Ophir Frieder,Nazli Goharian*

Main category: cs.CL

TL;DR: 提出了一个评估波斯语大语言模型文化能力的综合框架，采用波斯语特定短答案评估，结合基于规则的形态归一化和混合句法语义相似度模块，实现超越精确字符串匹配的软匹配评分。


<details>
  <summary>Details</summary>
Motivation: 现有的波斯文化基准主要依赖多项选择题格式和以英语为中心的指标，无法捕捉波斯语的形态复杂性和语义细微差别，需要更有效的评估方法。

Method: 引入波斯语特定短答案评估框架，结合基于规则的形态归一化和混合句法语义相似度模块，实现软匹配评分，超越了精确字符串重叠的局限性。

Result: 通过对15个最先进的开源和闭源模型的系统评估，证明混合评估方法比精确匹配基线提高了10%的评分一致性，能够捕捉表面方法无法检测的含义。

Conclusion: 该框架为波斯语文化理解提供了首个标准化基准，为跨文化LLM评估研究建立了可重复的基础，并公开发布了评估框架。

Abstract: This paper presents a comprehensive evaluation framework for assessing the cultural competence of large language models (LLMs) in Persian. Existing Persian cultural benchmarks rely predominantly on multiple-choice formats and English-centric metrics that fail to capture Persian's morphological complexity and semantic nuance. Our framework introduces a Persian-specific short-answer evaluation that combines rule-based morphological normalization with a hybrid syntactic and semantic similarity module, enabling robust soft-match scoring beyond exact string overlap. Through systematic evaluation of 15 state-of-the-art open- and closed-source models, we demonstrate that our hybrid evaluation improves scoring consistency by +10% compared to exact-match baselines by capturing meaning that surface-level methods cannot detect. We publicly release our evaluation framework, providing the first standardized benchmark for measuring cultural understanding in Persian and establishing a reproducible foundation for cross-cultural LLM evaluation research.

</details>


### [32] [TCM-DiffRAG: Personalized Syndrome Differentiation Reasoning Method for Traditional Chinese Medicine based on Knowledge Graph and Chain of Thought](https://arxiv.org/abs/2602.22828)
*Jianmin Li,Ying Chang,Su-Kit Tang,Yujia Liu,Yanwen Wang,Shuyuan Lin,Binkai Ou*

Main category: cs.CL

TL;DR: TCM-DiffRAG：针对中医临床诊断特点改进的RAG框架，结合知识图谱和思维链推理，显著提升LLMs在中医领域的表现。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在中医临床诊断中表现不佳，因为中医诊断涉及复杂的推理过程和显著的个体差异。需要开发专门针对中医推理特点的RAG框架。

Method: 开发了TCM-DiffRAG框架，将知识图谱（KG）与思维链（CoT）推理相结合，在三个不同的中医测试数据集上进行评估。

Result: TCM-DiffRAG显著提升了LLMs性能，如qwen-plus模型得分从0.927/0.361/0.038提升到0.952/0.788/0.356。对非中文LLMs提升更明显，且优于直接监督微调和其他基准RAG方法。

Conclusion: TCM-DiffRAG表明，将结构化中医知识图谱与基于思维链的推理相结合，能显著提升个体化诊断任务性能。通用与个性化知识图谱的联合使用实现了通用知识与临床推理的有效对齐。

Abstract: Background: Retrieval augmented generation (RAG) technology can empower large language models (LLMs) to generate more accurate, professional, and timely responses without fine tuning. However, due to the complex reasoning processes and substantial individual differences involved in traditional Chinese medicine (TCM) clinical diagnosis and treatment, traditional RAG methods often exhibit poor performance in this domain. Objective: To address the limitations of conventional RAG approaches in TCM applications, this study aims to develop an improved RAG framework tailored to the characteristics of TCM reasoning. Methods: We developed TCM-DiffRAG, an innovative RAG framework that integrates knowledge graphs (KG) with chains of thought (CoT). TCM-DiffRAG was evaluated on three distinctive TCM test datasets. Results: The experimental results demonstrated that TCM-DiffRAG achieved significant performance improvements over native LLMs. For example, the qwen-plus model achieved scores of 0.927, 0.361, and 0.038, which were significantly enhanced to 0.952, 0.788, and 0.356 with TCM-DiffRAG. The improvements were even more pronounced for non-Chinese LLMs. Additionally, TCM-DiffRAG outperformed directly supervised fine-tuned (SFT) LLMs and other benchmark RAG methods. Conclusions: TCM-DiffRAG shows that integrating structured TCM knowledge graphs with Chain of Thought based reasoning substantially improves performance in individualized diagnostic tasks. The joint use of universal and personalized knowledge graphs enables effective alignment between general knowledge and clinical reasoning. These results highlight the potential of reasoning-aware RAG frameworks for advancing LLM applications in traditional Chinese medicine.

</details>


### [33] [Improving Neural Argumentative Stance Classification in Controversial Topics with Emotion-Lexicon Features](https://arxiv.org/abs/2602.22846)
*Mohammad Yeghaneh Abkenar,Weixing Wang,Manfred Stede,Davide Picca,Mark A. Finlayson,Panagiotis Ioannidis*

Main category: cs.CL

TL;DR: 该论文提出了一种通过扩展情感词典来改进立场分类的方法，使用DistilBERT嵌入扩展NRC情感词典，在五个数据集上提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有立场分类研究大多未系统整合细粒度情感分析，且主要使用非论证性文本，局限于特定领域或话题，泛化能力有限。争论性文本（尤其是争议话题）常诉诸情感，但现有方法未能充分利用情感信息。

Method: 提出扩展偏差校正NRC情感词典的方法：1）使用DistilBERT嵌入识别原始词典未捕获的情感词；2）构建扩展NRC词典（eNRC）；3）将eNRC输入神经论证立场分类模型进行训练。

Result: eNRC在五个不同领域数据集上均优于基线：1）相比基线提升最高达6.2个百分点（F1分数）；2）在四个数据集上优于原始NRC词典（最高提升3.0）；3）在几乎所有语料库上超越基于LLM的方法。

Conclusion: 系统扩展情感词典能有效提升立场分类性能，特别是在争议话题的论证性文本中。研究提供了eNRC词典、适配语料库和模型架构等完整资源，便于后续研究。

Abstract: Argumentation mining comprises several subtasks, among which stance classification focuses on identifying the standpoint expressed in an argumentative text toward a specific target topic. While arguments-especially about controversial topics-often appeal to emotions, most prior work has not systematically incorporated explicit, fine-grained emotion analysis to improve performance on this task. In particular, prior research on stance classification has predominantly utilized non-argumentative texts and has been restricted to specific domains or topics, limiting generalizability. We work on five datasets from diverse domains encompassing a range of controversial topics and present an approach for expanding the Bias-Corrected NRC Emotion Lexicon using DistilBERT embeddings, which we feed into a Neural Argumentative Stance Classification model. Our method systematically expands the emotion lexicon through contextualized embeddings to identify emotionally charged terms not previously captured in the lexicon. Our expanded NRC lexicon (eNRC) improves over the baseline across all five datasets (up to +6.2 percentage points in F1 score), outperforms the original NRC on four datasets (up to +3.0), and surpasses the LLM-based approach on nearly all corpora. We provide all resources-including eNRC, the adapted corpora, and model architecture-to enable other researchers to build upon our work.

</details>


### [34] [Effective QA-driven Annotation of Predicate-Argument Relations Across Languages](https://arxiv.org/abs/2602.22865)
*Jonathan Davidov,Aviv Slobodkin,Shmuel Tomi Klein,Reut Tsarfaty,Ido Dagan,Ayal Klein*

Main category: cs.CL

TL;DR: 基于QA-SRL框架，通过跨语言投影方法自动生成语义标注数据，为希伯来语、俄语和法语构建高质量语义角色标注系统，超越多语言大模型基线。


<details>
  <summary>Details</summary>
Motivation: 语义角色标注（SRL）对于可解释的语义分析至关重要，但目前主要局限于英语，因为其他语言的标注成本高昂。需要一种方法来高效扩展语义分析到多语言场景。

Method: 采用QA-SRL框架作为自然语言接口，提出跨语言投影方法：通过受限翻译和词对齐管道，复用英语QA-SRL解析器自动生成目标语言的问答标注数据，并针对希伯来语、俄语和法语进行微调。

Result: 方法在希伯来语、俄语和法语上生成了高质量训练数据，并训练出语言特定的解析器，这些解析器在性能上超越了GPT-4o和LLaMA-Maverick等强大的多语言大模型基线。

Conclusion: QA-SRL作为可转移的自然语言语义接口，结合跨语言投影方法，能够高效实现跨语言的谓词-论元分析，使语义标注更广泛可及。

Abstract: Explicit representations of predicate-argument relations form the basis of interpretable semantic analysis, supporting reasoning, generation, and evaluation. However, attaining such semantic structures requires costly annotation efforts and has remained largely confined to English. We leverage the Question-Answer driven Semantic Role Labeling (QA-SRL) framework -- a natural-language formulation of predicate-argument relations -- as the foundation for extending semantic annotation to new languages. To this end, we introduce a cross-linguistic projection approach that reuses an English QA-SRL parser within a constrained translation and word-alignment pipeline to automatically generate question-answer annotations aligned with target-language predicates. Applied to Hebrew, Russian, and French -- spanning diverse language families -- the method yields high-quality training data and fine-tuned, language-specific parsers that outperform strong multilingual LLM baselines (GPT-4o, LLaMA-Maverick). By leveraging QA-SRL as a transferable natural-language interface for semantics, our approach enables efficient and broadly accessible predicate-argument parsing across languages.

</details>


### [35] [Rejection Mixing: Fast Semantic Propagation of Mask Tokens for Efficient DLLM Inference](https://arxiv.org/abs/2602.22868)
*Yushi Ye,Feng Hong,Huangjie Zheng,Xu Chen,Zhiyong Chen,Yanfeng Wang,Jiangchao Yao*

Main category: cs.CL

TL;DR: ReMix框架通过引入连续混合状态解决DLLM并行解码中的组合矛盾问题，实现2-8倍推理加速且不损失质量。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型在并行解码中存在严重的质量-速度权衡问题，这源于"组合矛盾"现象——并行生成的令牌会形成语义不一致的组合。

Method: 提出ReMix框架，引入"连续混合状态"作为初始掩码状态和最终解码令牌状态之间的中间状态。该状态允许令牌表示在连续空间中迭代细化，解决与其他令牌的相互冲突。同时采用拒绝规则，将不确定的表示从连续状态回退到掩码状态重新处理。

Result: ReMix作为无需训练的方法，在实验中实现了2-8倍的推理加速，且没有任何质量下降。

Conclusion: 通过在离散扩散解码过程中引入连续空间细化，ReMix有效缓解了组合矛盾问题，为扩散大语言模型提供了高效的并行解码解决方案。

Abstract: Diffusion Large Language Models (DLLMs) promise fast non-autoregressive inference but suffer a severe quality-speed trade-off in parallel decoding. This stems from the ''combinatorial contradiction'' phenomenon, where parallel tokens form semantically inconsistent combinations. We address this by integrating continuous representations into the discrete decoding process, as they preserve rich inter-position dependency. We propose ReMix (Rejection Mixing), a framework that introduces a novel Continuous Mixing State as an intermediate between the initial masked state and the final decoded token state. This intermediate state allows a token's representation to be iteratively refined in a continuous space, resolving mutual conflicts with other tokens before collapsing into a final discrete sample. Furthermore, a rejection rule reverts uncertain representations from the continuous state back to the masked state for reprocessing, ensuring stability and preventing error propagation. ReMix thus mitigates combinatorial contradictions by enabling continuous-space refinement during discrete diffusion decoding. Extensive experiments demonstrate that ReMix, as a training-free method, achieves a $2-8 \times$ inference speedup without any quality degradation.

</details>


### [36] [Test-Time Scaling with Diffusion Language Models via Reward-Guided Stitching](https://arxiv.org/abs/2602.22871)
*Roy Miles,Aysim Toker,Andreea-Maria Oncescu,Songcen Xu,Jiankang Deng,Ismail Elezi*

Main category: cs.CL

TL;DR: 提出Stitching Noisy Diffusion Thoughts框架，通过扩散采样生成多个推理轨迹，使用过程奖励模型评分，将最佳步骤跨轨迹拼接成复合推理，再由自回归模型生成最终答案。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型推理聚合策略通常是轨迹级别的（如选择最佳轨迹或对最终答案投票），这会丢弃部分或"接近正确"尝试中的有用中间工作。需要一种能够利用这些中间步骤的方法。

Method: 1. 使用掩码扩散语言模型采样多个多样化的低成本推理轨迹；2. 用现成的过程奖励模型为每个中间步骤评分；3. 跨轨迹拼接这些最高质量的步骤形成复合推理；4. 用自回归模型基于复合推理重新计算最终答案。

Result: 在数学推理基准测试中，步骤级重组对更难问题最有益。使用低置信度扩散采样和并行独立展开，该无需训练框架在六个数学和编码任务上平均准确率提升高达23.8%，同时相对于传统扩散模型和统一架构实现高达1.8倍的延迟减少。

Conclusion: 该模块化管道将探索（扩散）与评估和解决方案合成分离，避免了单一的统一混合架构，同时保持了广泛的搜索能力。消融实验突显了最终自回归求解器在将拼接但不完美的推理转换为准确答案中的重要性。

Abstract: Reasoning with large language models often benefits from generating multiple chains-of-thought, but existing aggregation strategies are typically trajectory-level (e.g., selecting the best trace or voting on the final answer), discarding useful intermediate work from partial or "nearly correct" attempts. We propose Stitching Noisy Diffusion Thoughts, a self-consistency framework that turns cheap diffusion-sampled reasoning into a reusable pool of step-level candidates. Given a problem, we (i) sample many diverse, low-cost reasoning trajectories using a masked diffusion language model, (ii) score every intermediate step with an off-the-shelf process reward model (PRM), and (iii) stitch these highest-quality steps across trajectories into a composite rationale. This rationale then conditions an autoregressive (AR) model (solver) to recompute only the final answer. This modular pipeline separates exploration (diffusion) from evaluation and solution synthesis, avoiding monolithic unified hybrids while preserving broad search. Across math reasoning benchmarks, we find that step-level recombination is most beneficial on harder problems, and ablations highlight the importance of the final AR solver in converting stitched but imperfect rationales into accurate answers. Using low-confidence diffusion sampling with parallel, independent rollouts, our training-free framework improves average accuracy by up to 23.8% across six math and coding tasks. At the same time, it achieves up to a 1.8x latency reduction relative to both traditional diffusion models (e.g., Dream, LLaDA) and unified architectures (e.g., TiDAR). Code is available at https://github.com/roymiles/diffusion-stitching.

</details>


### [37] [Where Vision Becomes Text: Locating the OCR Routing Bottleneck in Vision-Language Models](https://arxiv.org/abs/2602.22918)
*Jonathan Steinberg,Oren Gal*

Main category: cs.CL

TL;DR: 该研究通过因果干预探究了三种视觉语言模型中OCR信息的处理路径，发现不同架构在OCR处理瓶颈位置、信号维度及对计数任务的影响方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型能够从图像中读取文本，但OCR信息具体在语言处理流程中的哪个环节被整合尚不清楚。研究者希望探究不同架构模型中OCR信息的处理路径和机制。

Method: 使用因果干预方法，通过计算原始图像与文本修复版本之间的激活差异，分析三种架构（Qwen3-VL、Phi-4、InternVL3.5）的OCR处理瓶颈。采用主成分分析（PCA）研究OCR信号的维度特性，并测试不同数据集间的可迁移性。

Result: 1. OCR瓶颈位置因架构而异：DeepStack模型（Qwen）在中间深度（约50%）对场景文本最敏感，而单阶段投影模型（Phi-4、InternVL）在早期层（6-25%）峰值最大
2. OCR信号维度极低：第一主成分能解释72.9%的方差
3. PCA方向在不同数据集间可迁移，表明存在共享的文本处理路径
4. 在模块化OCR电路模型（如Qwen3-VL-4B）中，移除OCR信息能提升计数性能（最高+6.9个百分点），表明OCR可能干扰其他视觉处理

Conclusion: 不同视觉语言模型架构采用不同的OCR信息整合策略，OCR信号具有低维度和可迁移特性。模块化架构中OCR可能与其他视觉处理产生干扰，移除OCR反而能提升某些视觉任务性能，这为模型优化提供了新思路。

Abstract: Vision-language models (VLMs) can read text from images, but where does this optical character recognition (OCR) information enter the language processing stream? We investigate the OCR routing mechanism across three architecture families (Qwen3-VL, Phi-4, InternVL3.5) using causal interventions. By computing activation differences between original images and text-inpainted versions, we identify architecture-specific OCR bottlenecks whose dominant location depends on the vision-language integration strategy: DeepStack models (Qwen) show peak sensitivity at mid-depth (about 50%) for scene text, while single-stage projection models (Phi-4, InternVL) peak at early layers (6-25%), though the exact layer of maximum effect varies across datasets. The OCR signal is remarkably low-dimensional: PC1 captures 72.9% of variance. Crucially, principal component analysis (PCA) directions learned on one dataset transfer to others, demonstrating shared text-processing pathways. Surprisingly, in models with modular OCR circuits (notably Qwen3-VL-4B), OCR removal can improve counting performance (up to +6.9 percentage points), suggesting OCR interferes with other visual processing in sufficiently modular architectures.

</details>


### [38] [Affine-Scaled Attention: Towards Flexible and Stable Transformer Attention](https://arxiv.org/abs/2602.23057)
*Jeongin Bae,Baeseong Park,Gunho Park,Minsub Kim,Joonhyung Lee,Junhee Yoo,Sunghyeon Woo,Jiwon Ryu,Se Jung Kwon,Dongsoo Lee*

Main category: cs.CL

TL;DR: 提出Affine-Scaled Attention，通过引入输入依赖的缩放和偏置项来放松softmax注意力的严格归一化约束，改善训练稳定性和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer注意力使用softmax归一化，强制注意力权重为单位和归一化。这种约束限制了控制注意力幅度的灵活性，可能导致训练过程中注意力模式过于集中或不稳定。现有方法如注意力汇或门控机制只能提供有限或间接的控制。

Method: 提出Affine-Scaled Attention，在标准注意力基础上引入输入依赖的缩放项和对应的偏置项，应用于softmax归一化后的注意力权重。这种设计放松了严格的归一化约束，同时保持值表示的聚合，允许模型以可控方式调整注意力的相对分布和尺度。

Result: 在大规模语言模型预训练中，Affine-Scaled Attention相比标准softmax注意力和注意力汇基线，在训练稳定性、优化行为和下游任务性能方面都取得了持续改进。

Conclusion: 适度的注意力输出重加权为改善Transformer模型中注意力行为提供了一种实用有效的方法。Affine-Scaled Attention通过放松归一化约束，实现了更好的训练稳定性和性能提升。

Abstract: Transformer attention is typically implemented using softmax normalization, which enforces attention weights with unit sum normalization. While effective in many settings, this constraint can limit flexibility in controlling attention magnitudes and may contribute to overly concentrated or unstable attention patterns during training. Prior work has explored modifications such as attention sinks or gating mechanisms, but these approaches provide only limited or indirect control over attention reweighting. We propose Affine-Scaled Attention, a simple extension to standard attention that introduces input-dependent scaling and a corresponding bias term applied to softmax-normalized attention weights. This design relaxes the strict normalization constraint while maintaining aggregation of value representations, allowing the model to adjust both the relative distribution and the scale of attention in a controlled manner.
  We empirically evaluate Affine-Scaled Attention in large-scale language model pretraining across multiple model sizes. Experimental results show consistent improvements in training stability, optimization behavior, and downstream task performance compared to standard softmax attention and attention sink baselines. These findings suggest that modest reweighting of attention outputs provides a practical and effective way to improve attention behavior in Transformer models.

</details>


### [39] [Toward Automatic Filling of Case Report Forms: A Case Study on Data from an Italian Emergency Department](https://arxiv.org/abs/2602.23062)
*Gabriela Anna Kaczmarek,Pietro Ferrazzi,Lorenzo Porta,Vicky Rubini,Bernardo Magnini*

Main category: cs.CL

TL;DR: 开发了一个意大利急诊科临床笔记数据集，用于自动CRF填写任务，并在零样本设置下测试了开源LLM的性能


<details>
  <summary>Details</summary>
Motivation: 临床研究中的CRF填写任务缺乏标注数据，限制了基于LLM的自动CRF填写技术的发展

Method: 创建了包含134个项目的CRF标注数据集，定义任务和评估指标，在零样本设置下使用开源SOTA LLM进行实验

Result: (i) 意大利语临床笔记的CRF填写可以在零样本设置下进行；(ii) LLM结果存在偏差（如谨慎倾向选择"未知"答案），需要纠正

Conclusion: 该研究为自动CRF填写提供了数据集和方法基础，指出了LLM在临床应用中存在的偏差问题需要解决

Abstract: Case Report Forms (CRFs) collect data about patients and are at the core of well-established practices to conduct research in clinical settings. With the recent progress of language technologies, there is an increasing interest in automatic CRF-filling from clinical notes, mostly based on the use of Large Language Models (LLMs). However, there is a general scarcity of annotated CRF data, both for training and testing LLMs, which limits the progress on this task. As a step in the direction of providing such data, we present a new dataset of clinical notes from an Italian Emergency Department annotated with respect to a pre-defined CRF containing 134 items to be filled. We provide an analysis of the data, define the CRF-filling task and metric for its evaluation, and report on pilot experiments where we use an open-source state-of-the-art LLM to automatically execute the task. Results of the case-study show that (i) CRF-filling from real clinical notes in Italian can be approached in a zero-shot setting; (ii) LLMs' results are affected by biases (e.g., a cautious behaviour favours "unknown" answers), which need to be corrected.

</details>


### [40] [Quantity Convergence, Quality Divergence: Disentangling Fluency and Accuracy in L2 Mandarin Prosody](https://arxiv.org/abs/2602.23071)
*Yuqi Shi,Hao Yang,Xiyao Lu,Jinsong Zhang*

Main category: cs.CL

TL;DR: 该研究揭示二语学习者在句法与韵律接口的习得中存在非线性特征：尽管高水平学习者在韵律边界数量上接近母语水平，但其结构映射却出现系统偏差，形成颠倒的韵律层级模式。


<details>
  <summary>Details</summary>
Motivation: 二语学习者虽然能习得目标语的句法词序，但将句法映射到合适的韵律结构上仍是一个持久挑战。研究旨在探究二语句法-韵律接口的石化现象和稳定性。

Method: 使用BLCU-SAIT语料库，比较67名汉语母语者和67名越南语学习者。通过结合C-ToBI边界标注和依存语法分析，考察韵律边界的数量及其与句法关系的映射。

Result: 研究发现非线性习得模式：高水平学习者（VNH）在大短语层面（B3）的边界数量上接近母语基线，但结构映射显著偏离。具体表现为：VNH弱化了主谓接口的韵律边界（大短语B3→韵律词B1），同时错误地强化了动宾接口的边界（韵律词B1→大短语B3），以牺牲结构准确性为代价维持高长短语输出。

Conclusion: 学习者的策略导致扭曲的韵律层级结构，将母语模式颠倒。这表明二语句法-韵律接口的习得存在系统性偏差，而非简单的数量不足问题。

Abstract: While second language (L2) learners may acquire target syntactic word order, mapping this syntax onto appropriate prosodic structures remains a persistent challenge. This study investigates the fossilization and stability of the L2 syntax-prosody interface by comparing 67 native Mandarin speakers with 67 Vietnamese learners using the BLCU-SAIT corpus. By integrating C-ToBI boundary annotation with Dependency Grammar analysis, we examined both the quantity of prosodic boundaries and their mapping to syntactic relations. Results reveal a non-linear acquisition: although high-proficiency learners (VNH) converge to the native baseline in boundary quantity at the Major Phrase level (B3), their structural mapping significantly diverges. Specifically, VNH demote the prosodic boundary at the Subject-Verb (SBV) interface (Major Phrase B3 -> Prosodic Word B1), while erroneously promoting the boundary at the Verb-Object (VOB) interface (Prosodic Word B1 -> Major Phrase B3). This strategy allows learners to maintain high long phrasal output at the expense of structural accuracy. This results in a distorted prosodic hierarchy where the native pattern is inverted.

</details>


### [41] [Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent](https://arxiv.org/abs/2602.23079)
*Boyang Zhang,Yang Zhang*

Main category: cs.CL

TL;DR: SALA方法结合量化文体特征与LLM推理，既能高精度推断新闻文章作者身份，又能通过引导重写策略保护作者隐私。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型强大的作者推断能力带来了文本数据（如新闻文章）意外去匿名化的风险，需要评估和缓解这种隐私风险。

Method: 提出SALA（Stylometry-Assisted LLM Analysis）方法，将量化文体特征与LLM推理相结合，构建结构化、可解释的流水线，并增加数据库模块提升推理准确性。

Result: 在大规模新闻数据集上的实验表明，SALA方法（特别是增强数据库模块后）在各种场景下都能实现高推理准确率。通过引导重写策略，能有效降低作者可识别性同时保持文本意义。

Conclusion: 研究既揭示了LLM代理的去匿名化潜力，也强调了可解释、主动防御机制对于保护作者隐私的重要性。

Abstract: The rapid advancement of large language models (LLMs) has enabled powerful authorship inference capabilities, raising growing concerns about unintended deanonymization risks in textual data such as news articles. In this work, we introduce an LLM agent designed to evaluate and mitigate such risks through a structured, interpretable pipeline. Central to our framework is the proposed $\textit{SALA}$ (Stylometry-Assisted LLM Analysis) method, which integrates quantitative stylometric features with LLM reasoning for robust and transparent authorship attribution. Experiments on large-scale news datasets demonstrate that $\textit{SALA}$, particularly when augmented with a database module, achieves high inference accuracy in various scenarios. Finally, we propose a guided recomposition strategy that leverages the agent's reasoning trace to generate rewriting prompts, effectively reducing authorship identifiability while preserving textual meaning. Our findings highlight both the deanonymization potential of LLM agents and the importance of interpretable, proactive defenses for safeguarding author privacy.

</details>


### [42] [Modality Collapse as Mismatched Decoding: Information-Theoretic Limits of Multimodal LLMs](https://arxiv.org/abs/2602.23136)
*Jayadev Billa*

Main category: cs.CL

TL;DR: 多模态LLM虽然能处理语音和图像，但无法有效利用说话者声音或物体纹理等模态信息，因为解码器的文本对齐评分规则限制了非文本信息的可访问性。


<details>
  <summary>Details</summary>
Motivation: 多模态LLMs能够处理语音和图像，但实际上无法有效利用说话者的声音特征（如身份、情感）或物体的视觉属性（如纹理）。研究发现这些信息在编码过程中并未丢失，但解码器无法有效提取。

Method: 1. 使用线性探针分析各层信息保留情况；2. 提出"不匹配解码器问题"理论框架，用广义互信息(GMI)界定可访问信息；3. 在5个模型上进行验证；4. 通过控制实验（两个仅编码器文本对齐不同的棱柱视觉语言模型）和LoRA干预实验验证理论。

Result: 1. 说话者身份、情感和视觉属性信息在各LLM层中均存在（线性探针准确率比随机高3-55倍）；2. 移除64-71%的模态特定方差反而改善解码器损失；3. 解码器的评分规则是瓶颈；4. 使用情感目标训练LoRA可将情感可访问性提高7.5%而不影响其他属性。

Conclusion: 多模态LLM无法有效利用非文本信息不是因为编码失败，而是解码器的文本对齐评分规则限制了信息可访问性。训练目标决定了哪些信息变得可访问，通过针对性训练可以改善特定模态信息的提取能力。

Abstract: Multimodal LLMs can process speech and images, but they cannot hear a speaker's voice or see an object's texture. We show this is not a failure of encoding: speaker identity, emotion, and visual attributes survive through every LLM layer (3--55$\times$ above chance in linear probes), yet removing 64--71% of modality-specific variance improves decoder loss. The decoder has no learned use for these directions; their presence is noise.
  We formalize this as a mismatched decoder problem: a decoder trained on text can only extract information along text-aligned directions. Accessible information is bounded by the Generalized Mutual Information (GMI), with degradation scaling with distributional distance and decoder sensitivity. The bound is a property of the decoder's scoring rule, not of any particular architecture; it applies whether non-text inputs arrive through a learned projection, a discrete codebook, or no explicit adapter at all. We validate this across five models spanning speech and vision. A controlled experiment (two Prismatic VLMs differing only in encoder text-alignment) confirms the bottleneck is the decoder's scoring rule, not the encoder or projection. A LoRA intervention demonstrates the fix: training with an emotion objective improves emotion accessibility ($+$7.5%) without affecting other attributes, confirming that the training objective determines what becomes accessible.

</details>


### [43] [MTRAG-UN: A Benchmark for Open Challenges in Multi-Turn RAG Conversations](https://arxiv.org/abs/2602.23184)
*Sara Rosenthal,Yannis Katsis,Vraj Shah,Lihong He,Lucian Popa,Marina Danilevsky*

Main category: cs.CL

TL;DR: MTRAG-UN是一个用于探索多轮检索增强生成中未解决问题的基准测试，包含666个任务、2,800多个对话轮次，涵盖6个领域。


<details>
  <summary>Details</summary>
Motivation: 多轮检索增强生成是大型语言模型的流行应用，但在处理未回答、未指定、非独立问题以及不清晰响应时，现有检索和生成模型仍面临挑战。

Method: 创建了包含666个任务、超过2,800个对话轮次的基准测试，涵盖6个不同领域，并提供了相应的语料库。

Result: 实验表明，检索和生成模型在处理UNanswerable、UNderspecified、NONstandalone问题和UNclear响应时仍然存在困难。

Conclusion: MTRAG-UN基准测试揭示了多轮检索增强生成中的关键挑战，为未来研究提供了评估平台，代码已开源。

Abstract: We present MTRAG-UN, a benchmark for exploring open challenges in multi-turn retrieval augmented generation, a popular use of large language models. We release a benchmark of 666 tasks containing over 2,800 conversation turns across 6 domains with accompanying corpora. Our experiments show that retrieval and generation models continue to struggle on conversations with UNanswerable, UNderspecified, and NONstandalone questions and UNclear responses. Our benchmark is available at https://github.com/IBM/mt-rag-benchmark

</details>


### [44] [Fine-Tuning Without Forgetting In-Context Learning: A Theoretical Analysis of Linear Attention Models](https://arxiv.org/abs/2602.23197)
*Chungpa Lee,Jy-yong Sohn,Kangwook Lee*

Main category: cs.CL

TL;DR: 微调会损害大语言模型的上下文学习能力，但限制对值矩阵的更新可以改善零样本性能同时保持上下文学习能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过微调可以提升零样本性能，但微调会损害上下文学习能力，这限制了模型在未见任务上的表现。需要理解微调如何影响上下文学习，并找到平衡零样本性能和上下文学习能力的方法。

Method: 使用线性注意力模型进行理论分析，研究微调目标如何修改注意力参数，并识别导致少样本性能下降的条件。通过实验验证理论结果。

Result: 微调所有注意力参数会损害上下文学习；限制对值矩阵的更新可以改善零样本性能同时保持上下文学习能力；加入辅助少样本损失主要增强目标任务的上下文学习，但会损害在未见任务上的上下文学习能力。

Conclusion: 微调策略需要谨慎设计，限制对值矩阵的更新是平衡零样本性能和上下文学习能力的有效方法，为优化大语言模型在下游任务上的适应性提供了理论指导。

Abstract: Transformer-based large language models exhibit in-context learning, enabling adaptation to downstream tasks via few-shot prompting with demonstrations. In practice, such models are often fine-tuned to improve zero-shot performance on downstream tasks, allowing them to solve tasks without examples and thereby reducing inference costs. However, fine-tuning can degrade in-context learning, limiting the performance of fine-tuned models on tasks not seen during fine-tuning. Using linear attention models, we provide a theoretical analysis that characterizes how fine-tuning objectives modify attention parameters and identifies conditions under which this leads to degraded few-shot performance. We show that fine-tuning all attention parameters can harm in-context learning, whereas restricting updates to the value matrix improves zero-shot performance while preserving in-context learning. We further show that incorporating an auxiliary few-shot loss enhances in-context learning primarily on the target task, at the expense of degraded in-context learning ability on tasks not seen during fine-tuning. We empirically validate our theoretical results.

</details>


### [45] [Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?](https://arxiv.org/abs/2602.23225)
*Pengxiang Li,Dilxat Muhtar,Lu Yin,Tianlong Chen,Shiwei Liu*

Main category: cs.CL

TL;DR: 提出NAp方法，通过数据对齐改善扩散语言模型的并行解码能力，减少自回归倾向


<details>
  <summary>Details</summary>
Motivation: 当前扩散语言模型虽然理论上支持并行生成，但实际中常退化为类似自回归的解码方式，存在序列瓶颈。作者认为主要原因是训练目标与高度序列化的训练数据不匹配

Method: 提出NAp方法：1）数据层面：构建多个独立推理轨迹作为训练示例；2）解码策略：采用并行强制解码策略，鼓励多令牌并行更新

Result: 在数学推理基准测试中，NAp在并行解码下比使用标准长链思维训练数据的DLMs表现更好，且随着并行度增加，优势更加明显

Conclusion: 重新审视数据和监督是减少自回归行为、实现真正非自回归并行生成的有效方向

Abstract: Diffusion Language Models (DLMs) are often advertised as enabling parallel token generation, yet practical fast DLMs frequently converge to left-to-right, autoregressive (AR)-like decoding dynamics. In contrast, genuinely non-AR generation is promising because it removes AR's sequential bottleneck, better exploiting parallel hardware to reduce synchronization/communication overhead and improve latency scaling with output length. We argue that a primary driver of AR-like decoding is a mismatch between DLM objectives and the highly sequential structure of widely used training data, including standard pretraining corpora and long chain-of-thought (CoT) supervision. Motivated by this diagnosis, we propose NAP (Non-Autoregressive Parallel DLMs), a proof-of-concept, data-centric approach that better aligns supervision with non-AR parallel decoding. NAP curates examples as multiple independent reasoning trajectories and couples them with a parallel-forced decoding strategy that encourages multi-token parallel updates. Across math reasoning benchmarks, NAP yields stronger performance under parallel decoding than DLMs trained on standard long CoT data, with gains growing as parallelism increases. Our results suggest that revisiting data and supervision is a principled direction for mitigating AR-like behavior and moving toward genuinely non-autoregressive parallel generation in DLMs. Our code is available at https://github.com/pixeli99/NAP.

</details>


### [46] [Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems](https://arxiv.org/abs/2602.23266)
*Siyuan Liu,Jiahui Xu,Feng Jiang,Kuang Wang,Zefeng Zhao,Chu-Ren Huang,Jinghang Gu,Changqing Yin,Haizhou Li*

Main category: cs.CL

TL;DR: 提出DDTSR框架，通过双轨流式响应机制实现边听边想、边想边说，显著降低口语对话系统响应延迟。


<details>
  <summary>Details</summary>
Motivation: 传统ASR-LLM-TTS级联系统采用严格串行范式，需要完整转录和推理后才能开始语音合成，导致响应延迟高，难以实现类人响应速度。

Method: 提出DDTSR框架，包含三个关键机制：1) 连接词引导的小大模型协同，小模型生成最小承诺的话语连接词，大模型并行进行知识密集型推理；2) 基于流式的跨模态协作，动态重叠ASR、LLM推理和TTS处理；3) 基于课程学习的话语连续性增强，保持早期响应与后续推理输出的连贯性。

Result: 在两个口语对话基准测试中，DDTSR将响应延迟降低了19%-51%，同时保持了话语质量。该框架可作为即插即用模块兼容多种LLM骨干网络，在不同话语长度下保持鲁棒性。

Conclusion: DDTSR框架通过创新的双轨流式架构，在保持话语质量的同时显著降低响应延迟，为实时口语交互提供了实用且可扩展的解决方案。

Abstract: Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems. Conventional ASR-LLM-TTS pipelines follow a strictly sequential paradigm, requiring complete transcription and full reasoning before speech synthesis can begin, which results in high response latency. We propose the Discourse-Aware Dual-Track Streaming Response (DDTSR) framework, a low-latency architecture that enables listen-while-thinking and speak-while-thinking. DDTSR is built upon three key mechanisms: (1) connective-guided small-large model synergy, where an auxiliary small model generates minimal-committal discourse connectives while a large model performs knowledge-intensive reasoning in parallel; (2) streaming-based cross-modal collaboration, which dynamically overlaps ASR, LLM inference, and TTS to advance the earliest speakable moment; and (3) curriculum-learning-based discourse continuity enhancement, which maintains coherence and logical consistency between early responses and subsequent reasoning outputs. Experiments on two spoken dialogue benchmarks demonstrate that DDTSR reduces response latency by 19%-51% while preserving discourse quality. Further analysis shows that DDTSR functions as a plug-and-play module compatible with diverse LLM backbones, and remains robust across varying utterance lengths, indicating strong practicality and scalability for real-time spoken interaction.

</details>


### [47] [A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations](https://arxiv.org/abs/2602.23300)
*Soumya Dutta,Smruthi Balaji,Sriram Ganapathy*

Main category: cs.CL

TL;DR: MiSTER-E：一个用于对话情感识别的模块化专家混合框架，通过分离模态特定上下文建模和多模态信息融合来提升性能。


<details>
  <summary>Details</summary>
Motivation: 对话中的情感识别面临独特挑战，需要模型捕捉多轮对话的时间流并有效整合多模态信息。现有方法在处理这两个核心挑战时存在耦合问题。

Method: 提出模块化MoE框架，使用LLM生成语音和文本的丰富话语级嵌入，通过卷积-循环层增强上下文建模。使用三个专家（语音、文本、跨模态）和门控机制动态加权输出，引入对比损失和KL散度正则化促进模态一致性。

Result: 在IEMOCAP、MELD和MOSI数据集上分别获得70.9%、69.5%和87.9%的加权F1分数，优于多个基线系统。消融实验验证了方法各组成部分的贡献。

Conclusion: MiSTER-E通过分离模态特定建模和多模态融合有效解决了ERC的挑战，无需说话人身份信息即可实现优越性能，为多模态情感识别提供了新思路。

Abstract: Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities. We propose Mixture of Speech-Text Experts for Recognition of Emotions (MiSTER-E), a modular Mixture-of-Experts (MoE) framework designed to decouple two core challenges in ERC: modality-specific context modeling and multimodal information fusion. MiSTER-E leverages large language models (LLMs) fine-tuned for both speech and text to provide rich utterance-level embeddings, which are then enhanced through a convolutional-recurrent context modeling layer. The system integrates predictions from three experts-speech-only, text-only, and cross-modal-using a learned gating mechanism that dynamically weighs their outputs. To further encourage consistency and alignment across modalities, we introduce a supervised contrastive loss between paired speech-text representations and a KL-divergence-based regulariza-tion across expert predictions. Importantly, MiSTER-E does not rely on speaker identity at any stage. Experiments on three benchmark datasets-IEMOCAP, MELD, and MOSI-show that our proposal achieves 70.9%, 69.5%, and 87.9% weighted F1-scores respectively, outperforming several baseline speech-text ERC systems. We also provide various ablations to highlight the contributions made in the proposed approach.

</details>


### [48] [Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning](https://arxiv.org/abs/2602.23351)
*Amita Kamath,Jack Hessel,Khyathi Chandu,Jena D. Hwang,Kai-Wei Chang,Ranjay Krishna*

Main category: cs.CL

TL;DR: 研究发现视觉语言模型（VLMs）在推理能力上的不足源于训练数据中的报告偏差，这种偏差导致空间、时间、否定和计数等推理技能在数据中代表性不足，即使扩大数据规模或模型规模也无法自然涌现这些能力，但通过针对性标注可以改善。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在推理能力上存在明显不足，研究者认为这源于训练数据中的"报告偏差"——人们在描述视觉内容时通常会省略隐含的、常识性的信息，导致模型难以学习某些类型的推理技能。

Method: 从语用学理论视角分析OpenCLIP、LLaVA-1.5和Molmo等流行VLMs的训练数据，识别报告偏差对四种推理技能（空间、时间、否定、计数）的影响。通过精心设计的基准测试评估模型性能，并探索数据规模、模型规模和多语言扩展对推理能力的影响。

Result: 研究发现：1）VLMs在报告偏差抑制的推理任务上表现不佳；2）扩大数据规模、模型规模或多语言训练并不会自然涌现这些推理能力；3）通过收集包含隐含信息的针对性标注可以有效提升模型推理能力。

Conclusion: 需要更精细的训练数据筛选和标注方法，而不是依赖数据规模的自然涌现。报告偏差是阻碍VLMs发展推理能力的关键因素，必须通过有意识的数据设计来克服。

Abstract: The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit information needed to supervise some types of reasoning; e.g., "at the game today!" is a more likely caption than "a photo of 37 people standing behind a field". We investigate the data underlying the popular VLMs OpenCLIP, LLaVA-1.5 and Molmo through the lens of theories from pragmatics, and find that reporting bias results in insufficient representation of four reasoning skills (spatial, temporal, negation, and counting), despite the corpora being of web-scale, and/or synthetically generated. With a set of curated benchmarks, we demonstrate that: (i) VLMs perform poorly on the aforementioned types of reasoning suppressed in the training data by reporting bias; (ii) contrary to popular belief, scaling data size, model size, and to multiple languages does not result in emergence of these skills by default; but, promisingly, (iii) incorporating annotations specifically collected to obtain tacit information is effective. Our findings highlight the need for more intentional training data curation methods, rather than counting on scale for emergence of reasoning capabilities.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [49] [Enriching Taxonomies Using Large Language Models](https://arxiv.org/abs/2602.22213)
*Zeinab Ghamlouch,Mehwish Alam*

Main category: cs.IR

TL;DR: Taxoria：使用LLM增强现有分类法的管道，通过种子分类法生成候选节点并验证，最终输出带溯源追踪的增强分类法。


<details>
  <summary>Details</summary>
Motivation: 现有分类法存在覆盖范围有限、节点过时或模糊的问题，降低了知识检索的效果，需要一种方法来增强和更新分类法。

Method: 使用现有分类法作为种子，通过LLM生成候选节点，然后验证这些候选节点以减少幻觉并确保语义相关性，最后整合到分类法中。

Result: 开发了Taxoria管道，能够输出增强后的分类法，包含溯源追踪功能，并提供最终合并分类法的可视化分析。

Conclusion: Taxoria提供了一种有效利用LLM增强现有分类法的方法，解决了传统分类法覆盖不足和过时的问题，提高了知识检索的实用性。

Abstract: Taxonomies play a vital role in structuring and categorizing information across domains. However, many existing taxonomies suffer from limited coverage and outdated or ambiguous nodes, reducing their effectiveness in knowledge retrieval. To address this, we present Taxoria, a novel taxonomy enrichment pipeline that leverages Large Language Models (LLMs) to enhance a given taxonomy. Unlike approaches that extract internal LLM taxonomies, Taxoria uses an existing taxonomy as a seed and prompts an LLM to propose candidate nodes for enrichment. These candidates are then validated to mitigate hallucinations and ensure semantic relevance before integration. The final output includes an enriched taxonomy with provenance tracking and visualization of the final merged taxonomy for analysis.

</details>


### [50] [Adaptive Prefiltering for High-Dimensional Similarity Search: A Frequency-Aware Approach](https://arxiv.org/abs/2602.22214)
*Teodor-Ioan Calin*

Main category: cs.IR

TL;DR: 提出基于查询频率的自适应预过滤框架，通过Zipf分布分层查询空间，动态分配计算预算，减少20.4%距离计算同时保持亚毫秒延迟。


<details>
  <summary>Details</summary>
Motivation: 现实世界查询分布具有异质性，而均匀搜索策略无法利用这种特性，导致计算效率低下。

Method: 基于查询频率模式和聚类一致性度量的自适应预过滤框架，将查询空间按Zipf分布划分为频率层级，根据历史访问模式和局部密度特征分配差异化搜索策略。

Result: 在ImageNet-1k使用CLIP嵌入的实验中，频率感知预算分配相比静态nprobe选择，在保持相同召回率的情况下减少20.4%距离计算，同时维持GPU加速FAISS索引上的亚毫秒延迟。

Conclusion: 该框架通过轻量级频率跟踪引入最小开销，并通过基于一致性的回退策略为未见查询提供优雅降级，为高维相似性搜索提供了高效的自适应解决方案。

Abstract: High-dimensional similarity search underpins modern retrieval systems, yet uniform search strategies fail to exploit the heterogeneous nature of real-world query distributions. We present an adaptive prefiltering framework that leverages query frequency patterns and cluster coherence metrics to dynamically allocate computational budgets. Our approach partitions the query space into frequency tiers following Zipfian distributions and assigns differentiated search policies based on historical access patterns and local density characteristics. Experiments on ImageNet-1k using CLIP embeddings demonstrate that frequency-aware budget allocation achieves equivalent recall with 20.4% fewer distance computations compared to static nprobe selection, while maintaining sub-millisecond latency on GPU-accelerated FAISS indices. The framework introduces minimal overhead through lightweight frequency tracking and provides graceful degradation for unseen queries through coherence-based fallback policies.

</details>


### [51] [Retrieval-Augmented Generation Assistant for Anatomical Pathology Laboratories](https://arxiv.org/abs/2602.22216)
*Diogo Pires,Yuriy Perezhohin,Mauro Castelli*

Main category: cs.IR

TL;DR: 开发并评估了一个针对解剖病理学实验室的RAG助手，通过优化文本分块策略、检索方法和领域专用嵌入模型，显著提升了协议查询的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解剖病理学中70%的医疗决策依赖实验室诊断，但静态文档（如打印手册或PDF）通常过时、分散且难以搜索，导致工作流程错误和诊断延迟的风险。

Method: 构建了包含99个AP协议的新语料库和323个问答对进行系统评估。进行了10个实验，比较不同分块策略（递归分块）、检索方法（混合检索）和嵌入模型（包括生物医学专用模型MedEmbed）。使用RAGAS框架（忠实度、答案相关性、上下文召回率）和top-k检索指标评估性能。

Result: 递归分块和混合检索提供了最强的基线性能。结合生物医学专用嵌入模型MedEmbed进一步提升了答案相关性（0.74）、忠实度（0.70）和上下文召回率（0.77）。top-k分析显示，检索单个最高排名分块（k=1）能最大化效率和准确性，反映了AP协议的模块化结构。

Conclusion: 研究强调了在医疗领域部署RAG系统的关键设计考虑，展示了将静态文档转化为动态、可靠知识助手的潜力，从而提高实验室工作流程效率并支持患者安全。

Abstract: Accurate and efficient access to laboratory protocols is essential in Anatomical Pathology (AP), where up to 70% of medical decisions depend on laboratory diagnoses. However, static documentation such as printed manuals or PDFs is often outdated, fragmented, and difficult to search, creating risks of workflow errors and diagnostic delays. This study proposes and evaluates a Retrieval-Augmented Generation (RAG) assistant tailored to AP laboratories, designed to provide technicians with context-grounded answers to protocol-related queries. We curated a novel corpus of 99 AP protocols from a Portuguese healthcare institution and constructed 323 question-answer pairs for systematic evaluation. Ten experiments were conducted, varying chunking strategies, retrieval methods, and embedding models. Performance was assessed using the RAGAS framework (faithfulness, answer relevance, context recall) alongside top-k retrieval metrics. Results show that recursive chunking and hybrid retrieval delivered the strongest baseline performance. Incorporating a biomedical-specific embedding model (MedEmbed) further improved answer relevance (0.74), faithfulness (0.70), and context recall (0.77), showing the importance of domain-specialised embeddings. Top-k analysis revealed that retrieving a single top-ranked chunk (k=1) maximized efficiency and accuracy, reflecting the modular structure of AP protocols. These findings highlight critical design considerations for deploying RAG systems in healthcare and demonstrate their potential to transform static documentation into dynamic, reliable knowledge assistants, thus improving laboratory workflow efficiency and supporting patient safety.

</details>


### [52] [RAGdb: A Zero-Dependency, Embeddable Architecture for Multimodal Retrieval-Augmented Generation on the Edge](https://arxiv.org/abs/2602.22217)
*Ahmed Bin Khalid*

Main category: cs.IR

TL;DR: RAGdb：一个单文件SQLite容器，将RAG的多模态数据摄入、向量检索和混合评分整合在一起，无需GPU推理，适合边缘计算和隐私敏感场景。


<details>
  <summary>Details</summary>
Motivation: 当前RAG架构复杂，依赖云向量数据库、深度学习框架和高延迟嵌入服务器，这种"基础设施膨胀"阻碍了边缘计算、隔离环境和隐私敏感应用的发展。

Method: 提出RAGdb单文件架构，整合自动多模态数据摄入、ONNX提取和混合向量检索。使用确定性混合评分函数（HSF），结合亚线性TF-IDF向量化和精确子串增强，无需GPU推理。

Result: 在Intel i7-1165G7笔记本上测试：实体检索Recall@1达到100%，增量更新效率比冷启动提升31.6倍，磁盘占用比标准Docker RAG栈减少约99.5%。

Conclusion: RAGdb证明了"单文件知识容器"作为去中心化、本地优先AI可行基元的潜力，为边缘计算和隐私敏感应用提供了高效解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has established itself as the standard paradigm for grounding Large Language Models (LLMs) in domain-specific, up-to-date data. However, the prevailing architecture for RAG has evolved into a complex, distributed stack requiring cloud-hosted vector databases, heavy deep learning frameworks (e.g., PyTorch, CUDA), and high-latency embedding inference servers. This ``infrastructure bloat'' creates a significant barrier to entry for edge computing, air-gapped environments, and privacy-constrained applications where data sovereignty is paramount.
  This paper introduces RAGdb, a novel monolithic architecture that consolidates automated multimodal ingestion, ONNX-based extraction, and hybrid vector retrieval into a single, portable SQLite container. We propose a deterministic Hybrid Scoring Function (HSF) that combines sublinear TF-IDF vectorization with exact substring boosting, eliminating the need for GPU inference at query time. Experimental evaluation on an Intel i7-1165G7 consumer laptop demonstrates that RAGdb achieves 100\% Recall@1 for entity retrieval and an ingestion efficiency gain of 31.6x during incremental updates compared to cold starts. Furthermore, the system reduces disk footprint by approximately 99.5\% compared to standard Docker-based RAG stacks, establishing the ``Single-File Knowledge Container'' as a viable primitive for decentralized, local-first AI.
  Keywords: Edge AI, Retrieval-Augmented Generation, Vector Search, Green AI, Serverless Architecture, Knowledge Graphs, Efficient Computing.

</details>


### [53] [Comparative Analysis of Neural Retriever-Reranker Pipelines for Retrieval-Augmented Generation over Knowledge Graphs in E-commerce Applications](https://arxiv.org/abs/2602.22219)
*Teri Rumble,Zbyněk Gazdík,Javad Zarrin,Jagdeep Ahluwalia*

Main category: cs.IR

TL;DR: 该研究针对知识图谱的自然语言查询，设计了多种检索-重排RAG流水线，在电商领域实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG在非结构化文本上表现良好，但在结构化知识图谱上的应用面临挑战：如何在连接图谱中扩展检索并保持上下文关系。跨编码器虽然能提高检索精度，但与结构化数据的结合仍未被充分探索。这对于开发生产环境中的领域特定助手至关重要。

Method: 使用STaRK半结构化知识库（SKB）这一生产级电商数据集，设计并比较了多种针对知识图谱自然语言查询的Retriever-Reranker流水线配置。

Result: 实验结果显示相对于已发布基准有显著提升：Hit@1提高20.4%，平均倒数排名（MRR）提高14.5%。

Conclusion: 该研究为将领域特定SKB集成到生成系统中建立了实用框架，为生产就绪的RAG系统部署提供了可操作的见解，其影响不仅限于电商领域，也适用于其他需要从结构化知识库检索信息的领域。

Abstract: Recent advancements in Large Language Models (LLMs) have transformed Natural Language Processing (NLP), enabling complex information retrieval and generation tasks. Retrieval-Augmented Generation (RAG) has emerged as a key innovation, enhancing factual accuracy and contextual grounding by integrating external knowledge sources with generative models. Although RAG demonstrates strong performance on unstructured text, its application to structured knowledge graphs presents challenges: scaling retrieval across connected graphs and preserving contextual relationships during response generation. Cross-encoders refine retrieval precision, yet their integration with structured data remains underexplored. Addressing these challenges is crucial for developing domain-specific assistants that operate in production environments. This study presents the design and comparative evaluation of multiple Retriever-Reranker pipelines for knowledge graph natural language queries in e-Commerce contexts. Using the STaRK Semi-structured Knowledge Base (SKB), a production-scale e-Commerce dataset, we evaluate multiple RAG pipeline configurations optimized for language queries. Experimental results demonstrate substantial improvements over published benchmarks, achieving 20.4% higher Hit@1 and 14.5% higher Mean Reciprocal Rank (MRR). These findings establish a practical framework for integrating domain-specific SKBs into generative systems. Our contributions provide actionable insights for the deployment of production-ready RAG systems, with implications that extend beyond e-Commerce to other domains that require information retrieval from structured knowledge bases.

</details>


### [54] [What Makes an Ideal Quote? Recommending "Unexpected yet Rational" Quotations via Novelty](https://arxiv.org/abs/2602.22220)
*Bowei Zhang,Jin Xiao,Guanglei Yue,Qianyu He,Yanghua Xiao,Deqing Yang,Jiaqing Liang*

Main category: cs.IR

TL;DR: 提出NovelQR框架，通过生成式标签代理和token级新颖性估计器，推荐既新颖又语义连贯的引文，超越传统基于主题相关性的方法。


<details>
  <summary>Details</summary>
Motivation: 现有引文推荐系统主要优化表面主题相关性，忽略了引文令人难忘的深层语义和美学特性。用户研究表明，人们更喜欢"出乎意料却又合理"的引文，新颖性是关键需求。

Method: 1. 生成式标签代理将引文及其上下文解释为多维深层意义标签，实现标签增强检索；2. token级新颖性估计器对候选引文重新排序，缓解自回归延续偏差。

Result: 在涵盖多个现实领域的中英双语数据集上，人类评估者认为NovelQR推荐的引文比其他基线方法更恰当、更新颖、更有吸引力，同时在新颖性估计方面达到或超越现有方法。

Conclusion: 将引文推荐形式化为选择具有上下文新颖性但语义连贯的引文，通过NovelQR框架有效实现了这一目标，显著提升了引文推荐的质量和吸引力。

Abstract: Quotation recommendation aims to enrich writing by suggesting quotes that complement a given context, yet existing systems mostly optimize surface-level topical relevance and ignore the deeper semantic and aesthetic properties that make quotations memorable. We start from two empirical observations. First, a systematic user study shows that people consistently prefer quotations that are ``unexpected yet rational'' in context, identifying novelty as a key desideratum. Second, we find that strong existing models struggle to fully understand the deep meanings of quotations. Inspired by defamiliarization theory, we therefore formalize quote recommendation as choosing contextually novel but semantically coherent quotations. We operationalize this objective with NovelQR, a novelty-driven quotation recommendation framework. A generative label agent first interprets each quotation and its surrounding context into multi-dimensional deep-meaning labels, enabling label-enhanced retrieval. A token-level novelty estimator then reranks candidates while mitigating auto-regressive continuation bias. Experiments on bilingual datasets spanning diverse real-world domains show that our system recommends quotations that human judges rate as more appropriate, more novel, and more engaging than other baselines, while matching or surpassing existing methods in novelty estimation.

</details>


### [55] [Misinformation Exposure in the Chinese Web: A Cross-System Evaluation of Search Engines, LLMs, and AI Overviews](https://arxiv.org/abs/2602.22221)
*Geng Liu,Junjie Mu,Li Feng,Mengxiao Zhu,Francesco Pierri*

Main category: cs.IR

TL;DR: 该研究评估了LLM在中文搜索环境中的事实可靠性，发现不同信息获取范式存在显著准确性差异，并估计了中国用户可能接触错误信息的风险。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地集成到搜索服务中，但其在非英语网络生态系统中的事实可靠性，特别是在回答真实用户查询时，仍然了解不足。

Method: 构建了包含12,161个中文是非问题的真实性检查数据集，基于真实搜索日志，开发了统一评估流程，比较传统搜索引擎、独立LLM和AI生成概览模块三种信息获取范式。

Result: 分析揭示了不同系统在事实准确性和主题层面存在显著差异，结合百度指数统计，进一步估计了中国各地区用户可能接触错误事实信息的潜在风险。

Conclusion: 研究结果突显了AI中介搜索的结构性风险，强调了为数字世界开发更可靠、更透明信息获取工具的必要性。

Abstract: Large Language Models (LLMs) are increasingly integrated into search services, providing direct answers that can reduce users' reliance on traditional result pages. Yet their factual reliability in non-English web ecosystems remains poorly understood, particularly when answering real user queries. We introduce a fact-checking dataset of 12~161 Chinese Yes/No questions derived from real-world online search logs and develop a unified evaluation pipeline to compare three information-access paradigms: traditional search engines, standalone LLMs, and AI-generated overview modules. Our analysis reveals substantial differences in factual accuracy and topic-level variability across systems. By combining this performance with real-world Baidu Index statistics, we further estimate potential exposure to incorrect factual information of Chinese users across regions. These findings highlight structural risks in AI-mediated search and underscore the need for more reliable and transparent information-access tools for the digital world.

</details>


### [56] [TWICE: An LLM Agent Framework for Simulating Personalized User Tweeting Behavior with Long-term Temporal Features](https://arxiv.org/abs/2602.22222)
*Bingrui Jin,Kunyao Lan,Mengyue Wu*

Main category: cs.IR

TL;DR: 提出了TWICE框架，利用LLM和社交媒体数据的长期时序与个性化特征，模拟个性化用户发帖行为


<details>
  <summary>Details</summary>
Motivation: 现有用户模拟方法主要关注集体行为或交互系统，难以处理需要建模时序特征的任务

Method: 基于LLM的TWICE框架，整合个性化用户画像、事件驱动的记忆模块和个性化风格重写工作流

Result: 实验结果表明，该框架通过有效融入时序动态，提升了个性化用户模拟效果，为长期行为跟踪提供了稳健方案

Conclusion: TWICE框架能够有效模拟个性化用户发帖行为，捕捉长期时序特征，在发帖风格和基于事件的行为变化分析方面表现优异

Abstract: User simulators are often used to generate large amounts of data for various tasks such as generation, training, and evaluation. However, existing approaches concentrate on collective behaviors or interactive systems, struggling with tasks that require modeling temporal characteristics. To address this limitation, we propose TWICE, an LLM-based framework that leverages the long-term temporal and personalized features of social media data. This framework integrates personalized user profiling, an event-driven memory module, and a workflow for personalized style rewriting, enabling simulation of personalized user tweeting behavior while capturing long-term temporal characteristics. In addition, we conduct a comprehensive evaluation with a focus on analyzing tweeting style and event-based changes in behavior. Experiment results demonstrate that our framework improves personalized user simulation by effectively incorporating temporal dynamics, providing a robust solution for long-term behavior tracking.

</details>


### [57] [SQaLe: A Large Text-to-SQL Corpus Grounded in Real Schemas](https://arxiv.org/abs/2602.22223)
*Cornelius Wolff,Daniel Gomm,Madelon Hulsebos*

Main category: cs.IR

TL;DR: SQaLe是一个基于13.5万个真实数据库模式的大规模半合成文本到SQL数据集，包含51.7万个高质量(问题，模式，查询)三元组，旨在解决文本到SQL模型泛化能力的数据瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到SQL模型缺乏具有足够模式复杂性、查询多样性、领域覆盖度和任务多样性的高质量大规模数据集，这限制了模型的泛化能力发展。

Method: 基于SchemaPile的真实数据库模式库，通过模式采样、问题生成和SQL构建三个步骤的系统化生成流程，创建了大规模半合成数据集。

Result: 生成了包含51.7万个高质量三元组的SQaLe数据集，该数据集具有真实的模式大小变异性、多样查询模式、自然语言歧义性，同时保持执行有效性，是目前最真实的大规模文本到SQL数据集。

Conclusion: SQaLe数据集为文本到SQL研究中的数据扩展和模型泛化提供了重要基础，通过半合成方法解决了高质量训练数据稀缺的问题，推动了该领域的发展。

Abstract: Advances in large language models have accelerated progress in text-to-SQL, methods for converting natural language queries into valid SQL queries. A key bottleneck for developing generalizable text-to-SQL models is the lack of large-scale datasets with sufficient schema and query complexity, domain coverage, and task diversity. We introduce SQaLe: a large-scale semi-synthetic text-to-SQL dataset built on 135,875 relational database schemas expanded from a collection of real-world schemas, SchemaPile. We establish a principled generation pipeline which combines schema sampling, question synthesis, and SQL construction, and produce 517,676 high-quality (question, schema, query) triples. The SQaLe dataset captures realistic schema size variability, diverse query patterns, and natural language ambiguity while maintaining execution validity. We provide an analysis of its contents and characteristics, and find that SQaLe introduces the most realistic large-scale text-to-SQL dataset to date in comparison with existing benchmarks and datasets. We discuss how SQaLe enables our vision for data scaling and model generalization in text-to-SQL research. The dataset is accessible at: https://huggingface.co/datasets/trl-lab/SQaLe-text-to-SQL-dataset.

</details>


### [58] [DS SERVE: A Framework for Efficient and Scalable Neural Retrieval](https://arxiv.org/abs/2602.22224)
*Jinjian Liu,Yichuan Wang,Xinxi Lyu,Rulin Shao,Joseph E. Gonzalez,Matei Zaharia,Sewon Min*

Main category: cs.IR

TL;DR: DS-Serve是一个将大规模文本数据集转化为高性能神经检索系统的框架，支持API和Web界面，在单节点上实现低延迟和适度内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模文本数据集（如包含半万亿tokens的数据）需要高效的神经检索系统来支持各种应用，但现有解决方案在延迟、内存开销和灵活性方面存在不足。

Method: DS-Serve通过将大规模文本数据集转化为神经检索系统，提供Web界面和API端点，支持在推理时对延迟、准确性和结果多样性进行权衡，并在单节点上实现优化。

Result: DS-Serve实现了低延迟和适度内存开销，支持大规模检索增强生成（RAG）、训练数据归因、训练搜索代理等多种应用。

Conclusion: DS-Serve是一个高效、灵活的大规模神经检索框架，有望在多种应用中发挥重要作用，特别是在大规模检索增强生成等领域。

Abstract: We present DS-Serve, a framework that transforms large-scale text datasets, comprising half a trillion tokens, into a high-performance neural retrieval system. DS-Serve offers both a web interface and API endpoints, achieving low latency with modest memory overhead on a single node. The framework also supports inference-time trade-offs between latency, accuracy, and result diversity. We anticipate that DS-Serve will be broadly useful for a range of applications, including large-scale retrieval-augmented generation (RAG), training data attribution, training search agents, and beyond.

</details>


### [59] [SmartChunk Retrieval: Query-Aware Chunk Compression with Planning for Efficient Document RAG](https://arxiv.org/abs/2602.22225)
*Xuechen Zhang,Koustava Goswami,Samet Oymak,Jiasi Chen,Nedim Lipka*

Main category: cs.IR

TL;DR: SmartChunk检索：一种查询自适应的RAG框架，通过动态调整检索粒度来提升长文档问答的准确性和效率


<details>
  <summary>Details</summary>
Motivation: 现有RAG管道存在静态分块和平坦检索的局限性：文档被分割成固定大小的短块，检索质量对分块大小敏感，常引入不相关块噪声，且在大规模语料库上扩展性差。

Method: 1)规划器预测每个查询的最佳分块抽象级别；2)轻量级压缩模块生成高层分块嵌入而无需重复摘要；3)STITCH强化学习方案让规划器推理分块抽象；4)在五个QA基准和一个域外数据集上评估。

Result: SmartChunk在各项评估中均优于最先进的RAG基线，同时降低成本。分析显示其在大规模语料库上具有良好的扩展性，在域外数据集上保持一致的性能提升。

Conclusion: SmartChunk通过自适应检索粒度平衡准确性与效率，避免了固定策略的缺点，可作为自适应检索的通用框架，在真实应用场景中表现优异。

Abstract: Retrieval-augmented generation (RAG) has strong potential for producing accurate and factual outputs by combining language models (LMs) with evidence retrieved from large text corpora. However, current pipelines are limited by static chunking and flat retrieval: documents are split into short, predetermined, fixed-size chunks, embeddings are retrieved uniformly, and generation relies on whatever chunks are returned. This design brings challenges, as retrieval quality is highly sensitive to chunk size, often introduces noise from irrelevant or misleading chunks, and scales poorly to large corpora. We present SmartChunk retrieval, a query-adaptive framework for efficient and robust long-document question answering (QA). SmartChunk uses (i) a planner that predicts the optimal chunk abstraction level for each query, and (ii) a lightweight compression module that produces high-level chunk embeddings without repeated summarization. By adapting retrieval granularity on the fly, SmartChunk balances accuracy with efficiency and avoids the drawbacks of fixed strategies. Notably, our planner can reason about chunk abstractions through a novel reinforcement learning scheme, STITCH, which boosts accuracy and generalization. To reflect real-world applications, where users face diverse document types and query styles, we evaluate SmartChunk on five QA benchmarks plus one out-of-domain dataset. Across these evaluations, SmartChunk outperforms state-of-the-art RAG baselines, while reducing cost. Further analysis demonstrates strong scalability with larger corpora and consistent gains on out-of-domain datasets, highlighting its effectiveness as a general framework for adaptive retrieval.

</details>


### [60] [SEGB: Self-Evolved Generative Bidding with Local Autoregressive Diffusion](https://arxiv.org/abs/2602.22226)
*Yulong Gao,Wan Jiang,Mingzhe Cao,Xuepu Wang,Zeyu Pan,Haonan Yang,Ye Liu,Xin Yang*

Main category: cs.IR

TL;DR: 提出SEGB框架，通过合成短期未来状态引导出价决策，并进行价值引导的策略优化，实现离线自我进化，在在线广告自动竞价中显著提升效果


<details>
  <summary>Details</summary>
Motivation: 现有离线训练的生成式竞价策略缺乏对动态市场的短期预见能力，通常需要依赖模拟器或外部专家进行后训练改进

Method: 提出SEGB框架：1）合成可信的短期未来状态来指导每个出价决策，提供动态预见能力；2）进行价值引导的策略优化，迭代发现更优策略，无需外部干预

Result: 在AuctionNet基准测试和大规模A/B测试中验证，SEGB显著优于最先进的基线方法。大规模在线部署实现了目标成本+10.19%的增长，证明了其有效性

Conclusion: SEGB框架通过前瞻性规划和完全离线自我优化，解决了现有生成式竞价策略的局限性，在在线广告自动竞价中提供了有效的自我进化解决方案

Abstract: In the realm of online advertising, automated bidding has become a pivotal tool, enabling advertisers to efficiently capture impression opportunities in real-time. Recently, generative auto-bidding has shown significant promise, offering innovative solutions for effective ad optimization. However, existing offline-trained generative policies lack the near-term foresight required for dynamic markets and usually depend on simulators or external experts for post-training improvement. To overcome these critical limitations, we propose Self-Evolved Generative Bidding (SEGB), a framework that plans proactively and refines itself entirely offline. SEGB first synthesizes plausible short-horizon future states to guide each bid, providing the agent with crucial, dynamic foresight. Crucially, it then performs value-guided policy refinement to iteratively discover superior strategies without any external intervention. This self-contained approach uniquely enables robust policy improvement from static data alone. Experiments on the AuctionNet benchmark and a large-scale A/B test validate our approach, demonstrating that SEGB significantly outperforms state-of-the-art baselines. In a large-scale online deployment, it delivered substantial business value, achieving a +10.19% increase in target cost, proving the effectiveness of our advanced planning and evolution paradigm.

</details>


### [61] [RETLLM: Training and Data-Free MLLMs for Multimodal Information Retrieval](https://arxiv.org/abs/2602.22278)
*Dawei Su,Dongsheng Wang*

Main category: cs.IR

TL;DR: RetLLM：一种无需训练和数据的多模态信息检索框架，通过直接提示MLLM生成检索分数，在粗筛-精炼流程中实现高性能检索。


<details>
  <summary>Details</summary>
Motivation: 现有基于MLLM的MMIR方法存在预训练不一致问题且需要大量数据集进行微调，限制了实际应用。需要开发一种无需训练和数据的检索框架。

Method: 提出RetLLM框架：1）将MMIR定义为相似度分数生成任务；2）采用粗筛-精炼流程：粗筛阶段通过top-k过滤构建高质量候选池，精炼阶段将查询和候选同时输入MLLM预测检索分数；3）引入视觉增强模块帮助MLLM重新关注被遗忘的视觉信息。

Result: 在MMIR基准测试中，RetLLM超越了微调模型的表现。消融研究验证了各组件（粗筛策略、视觉增强模块）的有效性。

Conclusion: MLLM无需任何训练即可实现强大的MMIR性能，展示了其固有的多模态推理能力。RetLLM提供了一个简单、可扩展的框架，为MMIR研究开辟了新方向。

Abstract: Multimodal information retrieval (MMIR) has gained attention for its flexibility in handling text, images, or mixed queries and candidates. Recent breakthroughs in multimodal large language models (MLLMs) boost MMIR performance by incorporating MLLM knowledge under the contrastive finetuning framework. However, they suffer from pre-training inconsistency and require large datasets. In this work, we introduce a novel framework, RetLLM, designed to query MLLMs for MMIR in a training- and data-free manner. Specifically, we formulate MMIR as a similarity score generation task and prompt MLLMs to directly predict retrieval scores in a coarse-then-fine pipeline. At the coarse stage, a top-k filtering strategy builds a small yet high-quality candidate pool for each query, enabling MLLMs to focus on semantically relevant candidates. Subsequently, the retrieval score is predicted by feeding both the query and candidate into MLLMs at the fine stage. Importantly, we propose a visual enhancement module during reasoning to help MLLMs re-pick forgotten visuals, improving retrieval. Extensive experiments on MMIR benchmarks show that RetLLM outperforms fine-tuned models. Ablation studies further verify each component. Our work demonstrates that MLLMs can achieve strong MMIR performance without any training, highlighting their inherent multimodal reasoning ability in a simple, scalable framework. We release our code at: https://github.com/alivecat05/RETLLM

</details>


### [62] [TFPS: A Temporal Filtration-enhanced Positive Sample Set Construction Method for Implicit Collaborative Filtering](https://arxiv.org/abs/2602.22521)
*Jiayi Wu,Zhengyu Wu,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.IR

TL;DR: 提出一种基于时间过滤增强的方法，构建高质量正样本集来改进基于隐式反馈的协同过滤推荐


<details>
  <summary>Details</summary>
Motivation: 现有负采样方法主要优化负采样过程，但忽视正样本的探索。一些去噪方法可用于正样本去噪，但忽略时间信息。现有工作整合序列信息但忽视时间间隔信息，阻碍准确捕捉用户当前偏好。

Method: 1) 基于交互时间间隔设计时间衰减模型，将原始图转换为加权用户-物品二分图；2) 基于预定义过滤操作对加权二分图进行分层；3) 设计层增强策略为分层子图构建高质量正样本集。

Result: 在三个真实世界数据集上的大量实验证明了该方法的有效性。TFPS可以集成到各种隐式CF推荐器或负采样方法中以提升性能。

Conclusion: 从数据角度提出的时间过滤增强方法能有效构建高质量正样本集，改进推荐性能，并提供理论见解解释为什么TFPS能提升Recall@k和NDCG@k指标。

Abstract: The negative sampling strategy can effectively train collaborative filtering (CF) recommendation models based on implicit feedback by constructing positive and negative samples. However, existing methods primarily optimize the negative sampling process while neglecting the exploration of positive samples. Some denoising recommendation methods can be applied to denoise positive samples within negative sampling strategies, but they ignore temporal information. Existing work integrates sequential information during model aggregation but neglects time interval information, hindering accurate capture of users' current preferences. To address this problem, from a data perspective, we propose a novel temporal filtration-enhanced approach to construct a high-quality positive sample set. First, we design a time decay model based on interaction time intervals, transforming the original graph into a weighted user-item bipartite graph. Then, based on predefined filtering operations, the weighted user-item bipartite graph is layered. Finally, we design a layer-enhancement strategy to construct a high-quality positive sample set for the layered subgraphs. We provide theoretical insights into why TFPS can improve Recall@k and NDCG@k, and extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed method. Additionally, TFPS can be integrated with various implicit CF recommenders or negative sampling methods to enhance its performance.

</details>


### [63] [Generative Agents Navigating Digital Libraries](https://arxiv.org/abs/2602.22529)
*Saber Zerhoudi,Michael Granitzer*

Main category: cs.IR

TL;DR: Agent4DL是一个基于大语言模型的数字图书馆用户搜索行为模拟器，能够生成逼真的用户画像和动态搜索会话，有效解决用户数据隐私导致的可用数据集稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 数字图书馆研究中，由于隐私问题导致公开可用的用户搜索模式数据集稀缺，这限制了相关研究的发展。大语言模型的发展为模拟用户行为提供了新的可能性。

Method: 开发了Agent4DL模拟器，该工具基于大语言模型生成逼真的用户画像和动态搜索会话，模拟包括查询、点击和停止行为在内的真实搜索策略，并与真实用户数据进行对比验证。

Result: Agent4DL在模拟真实用户交互方面表现出色，与SimIIR 2.0等现有模拟器相比具有竞争力，特别是在生成多样化和上下文感知的用户行为方面表现更优。

Conclusion: Agent4DL为数字图书馆研究提供了一个有效的用户搜索行为仿真工具，能够生成高质量、多样化的用户行为数据，有助于解决该领域数据稀缺的问题。

Abstract: In the rapidly evolving field of digital libraries, the development of large language models (LLMs) has opened up new possibilities for simulating user behavior. This innovation addresses the longstanding challenge in digital library research: the scarcity of publicly available datasets on user search patterns due to privacy concerns. In this context, we introduce Agent4DL, a user search behavior simulator specifically designed for digital library environments. Agent4DL generates realistic user profiles and dynamic search sessions that closely mimic actual search strategies, including querying, clicking, and stopping behaviors tailored to specific user profiles. Our simulator's accuracy in replicating real user interactions has been validated through comparisons with real user data. Notably, Agent4DL demonstrates competitive performance compared to existing user search simulators such as SimIIR 2.0, particularly in its ability to generate more diverse and context-aware user behaviors.

</details>


### [64] [Towards Dynamic Dense Retrieval with Routing Strategy](https://arxiv.org/abs/2602.22547)
*Zhan Su,Fengran Mo,Jinghan Zhang,Yuchen Hui,Jia Ao Sun,Bingbing Wen,Jian-Yun Nie*

Main category: cs.IR

TL;DR: 提出动态稠密检索(DDR)方法，使用前缀调谐作为特定领域模块，通过动态路由策略组合模块，实现高效灵活的领域适应。


<details>
  <summary>Details</summary>
Motivation: 传统稠密检索方法存在两个主要限制：(1)在训练数据有限时难以适应新领域；(2)需要频繁从头训练更新模型，成本高昂。

Method: 使用前缀调谐作为特定领域的模块，通过动态路由策略组合这些模块，实现灵活领域适应，仅需训练2%的参数。

Result: 在六个零样本下游任务上的评估表明，该方法能超越传统稠密检索方法，同时仅使用2%的训练参数。

Conclusion: DDR为实现更灵活的稠密检索铺平了道路，是未来将稠密检索应用于各种任务的有前景方向。

Abstract: The \textit{de facto} paradigm for applying dense retrieval (DR) to new tasks involves fine-tuning a pre-trained model for a specific task. However, this paradigm has two significant limitations: (1) It is difficult adapt the DR to a new domain if the training dataset is limited.
  (2) Old DR models are simply replaced by newer models that are trained from scratch when the former are no longer up to date. Especially for scenarios where the model needs to be updated frequently, this paradigm is prohibitively expensive. To address these challenges, we propose a novel dense retrieval approach, termed \textit{dynamic dense retrieval} (DDR). DDR uses \textit{prefix tuning} as a \textit{module} specialized for a specific domain. These modules can then be compositional combined with a dynamic routing strategy, enabling highly flexible domain adaptation in the retrieval part. Extensive evaluation on six zero-shot downstream tasks demonstrates that this approach can surpass DR while utilizing only 2\% of the training parameters, paving the way to achieve more flexible dense retrieval in IR. We see it as a promising future direction for applying dense retrieval to various tasks.

</details>


### [65] [Where Relevance Emerges: A Layer-Wise Study of Internal Attention for Zero-Shot Re-Ranking](https://arxiv.org/abs/2602.22591)
*Haodong Chen,Shengyao Zhuang,Zheng Yao,Guido Zuccon,Teerapong Leelanupab*

Main category: cs.IR

TL;DR: 提出Selective-ICR方法，通过选择性提取transformer层中的注意力信号，在保持效果的同时将推理延迟降低30%-50%，小模型即可超越传统生成式方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的文档重排方法主要依赖生成式评分或输出logits，存在推理延迟高和结果不一致的问题。ICR方法虽然通过提取内部注意力信号避免了生成开销，但现有方法简单聚合所有层信号，未深入探究层间贡献差异和跨架构一致性。

Method: 1) 对生成、似然和内部注意力三种机制进行正交评估；2) 发现transformer层中相关信号呈现"钟形曲线"分布；3) 提出Selective-ICR策略，选择性提取关键层信号，减少计算开销。

Result: 1) Selective-ICR将推理延迟降低30%-50%；2) 在BRIGHT基准测试中，零-shot 8B模型性能匹配14B强化学习重排器；3) 0.6B模型甚至超越最先进的生成式方法；4) 揭示了内部信号在复杂推理排序任务中的潜力。

Conclusion: 内部注意力信号能有效替代传统生成机制，重新定义了LLM重排的效率-效果边界，表明小模型通过精确提取高质量上下文注意力信号即可实现复杂推理排序任务。

Abstract: Zero-shot document re-ranking with Large Language Models (LLMs) has evolved from Pointwise methods to Listwise and Setwise approaches that optimize computational efficiency. Despite their success, these methods predominantly rely on generative scoring or output logits, which face bottlenecks in inference latency and result consistency. In-Context Re-ranking (ICR) has recently been proposed as an $O(1)$ alternative method. ICR extracts internal attention signals directly, avoiding the overhead of text generation. However, existing ICR methods simply aggregate signals across all layers; layer-wise contributions and their consistency across architectures have been left unexplored. Furthermore, no unified study has compared internal attention with traditional generative and likelihood-based mechanisms across diverse ranking frameworks under consistent conditions.
  In this paper, we conduct an orthogonal evaluation of generation, likelihood, and internal attention mechanisms across multiple ranking frameworks. We further identify a universal "bell-curve" distribution of relevance signals across transformer layers, which motivates the proposed Selective-ICR strategy that reduces inference latency by 30%-50% without compromising effectiveness. Finally, evaluation on the reasoning-intensive BRIGHT benchmark shows that precisely capturing high-quality in-context attention signals fundamentally reduces the need for model scaling and reinforcement learning: a zero-shot 8B model matches the performance of 14B reinforcement-learned re-rankers, while even a 0.6B model outperforms state-of-the-art generation-based approaches. These findings redefine the efficiency-effectiveness frontier for LLM-based re-ranking and highlight the latent potential of internal signals for complex reasoning ranking tasks. Our code and results are publicly available at https://github.com/ielab/Selective-ICR.

</details>


### [66] [Fine-grained Semantics Integration for Large Language Model-based Recommendation](https://arxiv.org/abs/2602.22632)
*Jiawen Feng,Xiaoyu Kong,Leheng Sheng,Bin Wu,Chao Yi,Feifang Yang,Xiang-Rong Sheng,Han Zhu,Xiang Wang,Jiancan Wu,Xiangnan He*

Main category: cs.IR

TL;DR: TS-Rec通过语义感知嵌入初始化和令牌级语义对齐，将细粒度语义信息整合到基于LLM的推荐系统中，显著提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的推荐系统在语义标识符（SID）空间建模面临两大挑战：1）语义无意义的初始化（SID令牌随机初始化，切断了SID空间与预训练语言空间的语义联系）；2）粗粒度对齐（现有SFT对齐任务主要关注项目级优化，忽略了SID序列中单个令牌的语义）。

Method: TS-Rec包含两个关键组件：1）语义感知嵌入初始化（SA-Init）：通过教师模型提取关键词，对预训练嵌入进行均值池化来初始化SID令牌嵌入；2）令牌级语义对齐（TS-Align）：将SID序列中的单个令牌与对应项目簇的共享语义进行对齐。

Result: 在两个真实世界基准测试上的广泛实验表明，TS-Rec在所有标准指标上持续优于传统方法和生成式基线。结果表明，整合细粒度语义信息显著提升了基于LLM的生成式推荐系统的性能。

Conclusion: TS-Rec通过解决SID空间建模的两个基本挑战，成功将令牌级语义整合到基于LLM的推荐系统中，为生成式推荐系统提供了更有效的语义对齐方法。

Abstract: Recent advances in Large Language Models (LLMs) have shifted in recommendation systems from the discriminative paradigm to the LLM-based generative paradigm, where the recommender autoregressively generates sequences of semantic identifiers (SIDs) for target items conditioned on historical interaction. While prevalent LLM-based recommenders have demonstrated performance gains by aligning pretrained LLMs between the language space and the SID space, modeling the SID space still faces two fundamental challenges: (1) Semantically Meaningless Initialization: SID tokens are randomly initialized, severing the semantic linkage between the SID space and the pretrained language space at start point, and (2) Coarse-grained Alignment: existing SFT-based alignment tasks primarily focus on item-level optimization, while overlooking the semantics of individual tokens within SID sequences.To address these challenges, we propose TS-Rec, which can integrate Token-level Semantics into LLM-based Recommenders. Specifically, TS-Rec comprises two key components: (1) Semantic-Aware embedding Initialization (SA-Init), which initializes SID token embeddings by applying mean pooling to the pretrained embeddings of keywords extracted by a teacher model; and (2) Token-level Semantic Alignment (TS-Align), which aligns individual tokens within the SID sequence with the shared semantics of the corresponding item clusters. Extensive experiments on two real-world benchmarks demonstrate that TS-Rec consistently outperforms traditional and generative baselines across all standard metrics. The results demonstrate that integrating fine-grained semantic information significantly enhances the performance of LLM-based generative recommenders.

</details>


### [67] [Vectorizing the Trie: Efficient Constrained Decoding for LLM-based Generative Retrieval on Accelerators](https://arxiv.org/abs/2602.22647)
*Zhengyang Su,Isay Katsman,Yueqi Wang,Ruining He,Lukasz Heldt,Raghunandan Keshavan,Shao-Chuan Wang,Xinyang Yi,Mingyan Gao,Onkar Dalal,Lichan Hong,Ed Chi,Ningren Han*

Main category: cs.IR

TL;DR: 提出STATIC方法，通过将前缀树扁平化为稀疏矩阵，实现硬件加速器上高效的约束解码，用于大规模LLM生成式检索推荐系统。


<details>
  <summary>Details</summary>
Motivation: 工业推荐系统需要限制输出空间（如内容新鲜度、产品类别），但标准自回归解码不支持这种约束。现有基于前缀树的约束解码方法在硬件加速器上存在严重延迟问题。

Method: 将前缀树扁平化为静态压缩稀疏行矩阵，将不规则树遍历转换为完全向量化的稀疏矩阵操作，在TPU/GPU上实现高效约束解码。

Result: 在大型视频推荐平台部署，实现显著产品指标提升，延迟开销极低（每步0.033ms，推理时间0.25%），比CPU前缀树实现快948倍，比硬件加速二分搜索基线快47-1033倍。在学术基准测试中也能显著改善冷启动性能。

Conclusion: STATIC实现了首个生产规模的严格约束生成式检索部署，为大规模LLM推荐系统提供了高效、可扩展的约束解码解决方案。

Abstract: Generative retrieval has emerged as a powerful paradigm for LLM-based recommendation. However, industrial recommender systems often benefit from restricting the output space to a constrained subset of items based on business logic (e.g. enforcing content freshness or product category), which standard autoregressive decoding cannot natively support. Moreover, existing constrained decoding methods that make use of prefix trees (Tries) incur severe latency penalties on hardware accelerators (TPUs/GPUs). In this work, we introduce STATIC (Sparse Transition Matrix-Accelerated Trie Index for Constrained Decoding), an efficient and scalable constrained decoding technique designed specifically for high-throughput LLM-based generative retrieval on TPUs/GPUs. By flattening the prefix tree into a static Compressed Sparse Row (CSR) matrix, we transform irregular tree traversals into fully vectorized sparse matrix operations, unlocking massive efficiency gains on hardware accelerators. We deploy STATIC on a large-scale industrial video recommendation platform serving billions of users. STATIC produces significant product metric impact with minimal latency overhead (0.033 ms per step and 0.25% of inference time), achieving a 948x speedup over a CPU trie implementation and a 47-1033x speedup over a hardware-accelerated binary-search baseline. Furthermore, the runtime overhead of STATIC remains extremely low across a wide range of practical configurations. To the best of our knowledge, STATIC enables the first production-scale deployment of strictly constrained generative retrieval. In addition, evaluation on academic benchmarks demonstrates that STATIC can considerably improve cold-start performance for generative retrieval. Our code is available at https://github.com/youtube/static-constraint-decoding.

</details>


### [68] [Generative Recommendation for Large-Scale Advertising](https://arxiv.org/abs/2602.22732)
*Ben Xue,Dan Liu,Lixiang Wang,Mingjie Sun,Peng Wang,Pengfei Zhang,Shaoyun Shi,Tianyu Xu,Yunhao Sha,Zhiqiang Liu,Bo Kong,Bo Wang,Hang Yang,Jieting Xue,Junhao Wang,Shengyu Wang,Shuping Hui,Wencai Ye,Xiao Lin,Yongzhi Li,Yuhang Chen,Zhihui Yin,Quan Chen,Shiyang Wen,Wenjin Wu,Han Li,Guorui Zhou,Changcheng Li,Peng Jiang*

Main category: cs.IR

TL;DR: GR4AD是一个面向广告推荐的生产级生成式推荐系统，通过UA-SID统一语义ID、LazyAR懒自回归解码器、RSPO排序引导优化算法等创新设计，在快手广告系统中实现了实时高吞吐服务，相比传统DLRM模型带来最高4.2%的广告收入提升。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐在工业界展现出规模化潜力和更强的模型能力，但在大规模广告系统中部署实时生成式推荐需要超越传统LLM训练和服务的专门设计。现有方案在业务信息捕捉、推理成本控制、业务价值对齐等方面存在不足。

Method: 1. 提出UA-SID统一广告语义ID来捕捉复杂业务信息；2. 引入LazyAR懒自回归解码器，通过放松层间依赖来降低短序列多候选生成的推理成本；3. 采用VSL价值感知监督学习，并提出RSPO排序引导的软最大偏好优化算法，在列表级指标下优化基于价值的奖励；4. 在线推理中提出动态束搜索服务，根据生成层级和在线负载自适应调整束宽以控制计算。

Result: 大规模在线A/B测试显示，相比现有DLRM基准系统，GR4AD带来最高4.2%的广告收入提升。模型缩放和推理时缩放都能带来持续收益。系统已在快手广告系统全面部署，服务超过4亿用户，实现高吞吐实时服务。

Conclusion: GR4AD通过架构、学习和服务的协同设计，成功将生成式推荐应用于大规模广告系统，实现了业务价值对齐、推理成本控制和实时服务能力，为工业级生成式推荐提供了可行的解决方案。

Abstract: Generative recommendation has recently attracted widespread attention in industry due to its potential for scaling and stronger model capacity. However, deploying real-time generative recommendation in large-scale advertising requires designs beyond large-language-model (LLM)-style training and serving recipes. We present a production-oriented generative recommender co-designed across architecture, learning, and serving, named GR4AD (Generative Recommendation for ADdvertising). As for tokenization, GR4AD proposes UA-SID (Unified Advertisement Semantic ID) to capture complicated business information. Furthermore, GR4AD introduces LazyAR, a lazy autoregressive decoder that relaxes layer-wise dependencies for short, multi-candidate generation, preserving effectiveness while reducing inference cost, which facilitates scaling under fixed serving budgets. To align optimization with business value, GR4AD employs VSL (Value-Aware Supervised Learning) and proposes RSPO (Ranking-Guided Softmax Preference Optimization), a ranking-aware, list-wise reinforcement learning algorithm that optimizes value-based rewards under list-level metrics for continual online updates. For online inference, we further propose dynamic beam serving, which adapts beam width across generation levels and online load to control compute. Large-scale online A/B tests show up to 4.2% ad revenue improvement over an existing DLRM-based stack, with consistent gains from both model scaling and inference-time scaling. GR4AD has been fully deployed in Kuaishou advertising system with over 400 million users and achieves high-throughput real-time serving.

</details>


### [69] [PSQE: A Theoretical-Practical Approach to Pseudo Seed Quality Enhancement for Unsupervised MMEA](https://arxiv.org/abs/2602.22903)
*Yunpeng Hong,Chenyang Bu,Jie Zhang,Yi He,Di Wu,Xindong Wu*

Main category: cs.IR

TL;DR: 该论文提出了一种名为PSQE（伪种子质量增强）的插件模块，用于解决无监督多模态实体对齐中伪种子质量不平衡的问题，通过多模态信息和聚类重采样来提升伪种子的精度和图覆盖平衡。


<details>
  <summary>Details</summary>
Motivation: 无监督多模态实体对齐（MMEA）虽然减少了对标注种子对的需求，但多模态信息的引入往往导致伪种子在知识图谱中的覆盖不平衡，这影响了现有对比学习方法的性能。

Method: 提出PSQE方法，通过多模态信息和聚类重采样技术来提升伪种子的精度和图覆盖平衡。该方法作为一个即插即用模块，可以集成到现有的对比学习框架中。

Result: 理论分析揭示了伪种子对现有对比学习模型的影响机制，实验结果表明PSQE模块能够显著提升基线模型的性能。

Conclusion: PSQE方法有效解决了无监督多模态实体对齐中伪种子不平衡的问题，为提升无监督实体对齐性能提供了实用的解决方案。

Abstract: Multimodal Entity Alignment (MMEA) aims to identify equivalent entities across different data modalities, enabling structural data integration that in turn improves the performance of various large language model applications. To lift the requirement of labeled seed pairs that are difficult to obtain, recent methods shifted to an unsupervised paradigm using pseudo-alignment seeds. However, unsupervised entity alignment in multimodal settings remains underexplored, mainly because the incorporation of multimodal information often results in imbalanced coverage of pseudo-seeds within the knowledge graph. To overcome this, we propose PSQE (Pseudo-Seed Quality Enhancement) to improve the precision and graph coverage balance of pseudo seeds via multimodal information and clustering-resampling. Theoretical analysis reveals the impact of pseudo seeds on existing contrastive learning-based MMEA models. In particular, pseudo seeds can influence the attraction and the repulsion terms in contrastive learning at once, whereas imbalanced graph coverage causes models to prioritize high-density regions, thereby weakening their learning capability for entities in sparse regions. Experimental results validate our theoretical findings and show that PSQE as a plug-and-play module can improve the performance of baselines by considerable margins.

</details>


### [70] [SIGMA: A Semantic-Grounded Instruction-Driven Generative Multi-Task Recommender at AliExpress](https://arxiv.org/abs/2602.22913)
*Yang Yu,Lei Kou,Huaikuan Yi,Bin Chen,Yayu Cao,Lei Shen,Chao Zhang,Bing Wang,Xiaoyi Zeng*

Main category: cs.IR

TL;DR: SIGMA是一个基于语义基础、指令驱动的生成式多任务推荐系统，通过统一潜在空间捕获语义和协同关系，采用混合项目标记化方法，构建多任务指令微调数据集，实现多种推荐需求。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐大多局限于交互驱动的下一项预测范式，无法快速适应趋势变化，也难以满足现实场景中多样化的推荐任务和业务特定需求。

Method: 1) 通过统一潜在空间将项目实体基础于通用语义，捕获语义和协同关系；2) 开发混合项目标记化方法进行精确建模和高效生成；3) 构建大规模多任务SFT数据集支持指令跟随；4) 设计三步项目生成流程，结合自适应概率融合机制校准输出分布。

Result: 通过大量离线实验和在线A/B测试证明了SIGMA的有效性。

Conclusion: SIGMA通过语义基础、指令驱动的生成式多任务推荐框架，能够灵活适应不同推荐任务和业务需求，提高了推荐系统的适应性和实用性。

Abstract: With the rapid evolution of Large Language Models, generative recommendation is gradually reshaping the paradigm of recommender systems. However, most existing methods are still confined to the interaction-driven next-item prediction paradigm, failing to rapidly adapt to evolving trends or address diverse recommendation tasks along with business-specific requirements in real-world scenarios. To this end, we present SIGMA, a Semantic-Grounded Instruction-Driven Generative Multi-Task Recommender at AliExpress. Specifically, we first ground item entities in general semantics via a unified latent space capturing both semantic and collaborative relations. Building upon this, we develop a hybrid item tokenization method for precise modeling and efficient generation. Moreover, we construct a large-scale multi-task SFT dataset to empower SIGMA to fulfill various recommendation demands via instruction-following. Finally, we design a three-step item generation procedure integrated with an adaptive probabilistic fusion mechanism to calibrate the output distributions based on task-specific requirements for recommendation accuracy and diversity. Extensive offline experiments and online A/B tests demonstrate the effectiveness of SIGMA.

</details>


### [71] [Sequential Regression for Continuous Value Prediction using Residual Quantization](https://arxiv.org/abs/2602.23012)
*Runpeng Cui,Zhipeng Sun,Chi Lu,Peng Jiang*

Main category: cs.IR

TL;DR: 提出基于残差量化的序列学习框架，通过从粗到细的量化编码递归预测连续值，在推荐系统的连续值预测任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中的连续值预测（如观看时长、GMV等）面临数据分布复杂、长尾的挑战。现有生成式方法依赖参数化分布假设，当假设与现实数据不匹配时性能受限——简单假设无法建模复杂性，复杂假设则存在可扩展性和泛化性问题。

Method: 提出基于残差量化（RQ）的序列学习框架，将目标连续值表示为有序量化编码之和，通过从粗到细的粒度递归预测，并引入表示学习目标使RQ编码嵌入空间与目标值的序结构对齐，从而捕获量化编码的连续表示。

Result: 在LTV和观看时长预测的公开基准测试以及工业短视频推荐平台的大规模在线GMV预测实验中，该方法均优于现有最先进方法，并在推荐系统的多种连续值预测任务中展现出强大的泛化能力。

Conclusion: 残差量化框架有效解决了推荐系统中连续值预测的挑战，避免了参数化分布假设的限制，通过从粗到细的量化编码递归预测和表示学习，实现了更准确、可扩展且泛化性强的连续值预测。

Abstract: Continuous value prediction plays a crucial role in industrial-scale recommendation systems, including tasks such as predicting users' watch-time and estimating the gross merchandise value (GMV) in e-commerce transactions. However, it remains challenging due to the highly complex and long-tailed nature of the data distributions. Existing generative approaches rely on rigid parametric distribution assumptions, which fundamentally limits their performance when such assumptions misalign with real-world data. Overly simplified forms cannot adequately model real-world complexities, while more intricate assumptions often suffer from poor scalability and generalization.
  To address these challenges, we propose a residual quantization (RQ)-based sequence learning framework that represents target continuous values as a sum of ordered quantization codes, predicted recursively from coarse to fine granularity with diminishing quantization errors. We introduce a representation learning objective that aligns RQ code embedding space with the ordinal structure of target values, allowing the model to capture continuous representations for quantization codes and further improving prediction accuracy. We perform extensive evaluations on public benchmarks for lifetime value (LTV) and watch-time prediction, alongside a large-scale online experiment for GMV prediction on an industrial short-video recommendation platform. The results consistently show that our approach outperforms state-of-the-art methods, while demonstrating strong generalization across diverse continuous value prediction tasks in recommendation systems.

</details>


### [72] [MoDora: Tree-Based Semi-Structured Document Analysis System](https://arxiv.org/abs/2602.23061)
*Bangrui Xu,Qihang Yao,Zirui Tang,Xuanhe Zhou,Yeye He,Shihan Yu,Qianqian Xu,Bin Wang,Guoliang Li,Conghui He,Fan Wu*

Main category: cs.IR

TL;DR: MoDora是一个基于LLM的半结构化文档分析系统，通过局部对齐聚合、组件关联树和问题类型感知检索策略，显著提升了文档问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理半结构化文档的自然语言问答时面临三大挑战：OCR提取的元素碎片化且失去语义上下文；缺乏有效表示文档层次结构和布局差异的方法；需要跨多个区域检索对齐分散信息。

Method: 1. 采用局部对齐聚合策略将OCR解析元素转换为布局感知组件，并对有层次标题或非文本元素的组件进行类型特定信息提取。
2. 设计组件关联树(CCTree)层次化组织组件，通过自底向上级联摘要过程显式建模组件间关系和布局差异。
3. 提出问题类型感知检索策略，支持基于布局的网格分区进行位置检索和LLM引导剪枝进行语义检索。

Result: 实验表明MoDora在准确率上比基线方法提升了5.97%-61.07%。

Conclusion: MoDora通过创新的组件表示和检索策略，有效解决了半结构化文档问答的三大技术挑战，显著提升了分析性能。

Abstract: Semi-structured documents integrate diverse interleaved data elements (e.g., tables, charts, hierarchical paragraphs) arranged in various and often irregular layouts. These documents are widely observed across domains and account for a large portion of real-world data. However, existing methods struggle to support natural language question answering over these documents due to three main technical challenges: (1) The elements extracted by techniques like OCR are often fragmented and stripped of their original semantic context, making them inadequate for analysis. (2) Existing approaches lack effective representations to capture hierarchical structures within documents (e.g., associating tables with nested chapter titles) and to preserve layout-specific distinctions (e.g., differentiating sidebars from main content). (3) Answering questions often requires retrieving and aligning relevant information scattered across multiple regions or pages, such as linking a descriptive paragraph to table cells located elsewhere in the document.
  To address these issues, we propose MoDora, an LLM-powered system for semi-structured document analysis. First, we adopt a local-alignment aggregation strategy to convert OCR-parsed elements into layout-aware components, and conduct type-specific information extraction for components with hierarchical titles or non-text elements. Second, we design the Component-Correlation Tree (CCTree) to hierarchically organize components, explicitly modeling inter-component relations and layout distinctions through a bottom-up cascade summarization process. Finally, we propose a question-type-aware retrieval strategy that supports (1) layout-based grid partitioning for location-based retrieval and (2) LLM-guided pruning for semantic-based retrieval. Experiments show MoDora outperforms baselines by 5.97%-61.07% in accuracy. The code is at https://github.com/weAIDB/MoDora.

</details>


### [73] [MaRI: Accelerating Ranking Model Inference via Structural Re-parameterization in Large Scale Recommendation System](https://arxiv.org/abs/2602.23105)
*Yusheng Huang,Pengbo Xu,Shen Wang,Changxin Lao,Jiangxia Cao,Shuang Wen,Shuang Yang,Zhaojie Liu,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: 提出MaRI框架，通过结构重参数化优化特征融合矩阵乘法，实现推荐系统排序模型的无损加速


<details>
  <summary>Details</summary>
Motivation: 现有排序模型加速方法（结构轻量化或知识蒸馏）通常会导致精度下降，而通过优化特征融合矩阵乘法实现无损加速的探索仍不足。特别是用户侧计算在特征融合矩阵乘法中存在冗余。

Method: 提出MaRI（Matrix Re-parameterized Inference）框架，采用结构重参数化思想来缓解用户侧计算冗余，作为现有技术的补充方法。

Result: MaRI能够在不损失任何精度的情况下加速排序模型推理。

Conclusion: MaRI为大规模推荐系统中的排序模型提供了一种有效的无损加速方案，通过优化特征融合矩阵乘法填补了现有技术空白。

Abstract: Ranking models, i.e., coarse-ranking and fine-ranking models, serve as core components in large-scale recommendation systems, responsible for scoring massive item candidates based on user preferences. To meet the stringent latency requirements of online serving, structural lightweighting or knowledge distillation techniques are commonly employed for ranking model acceleration. However, these approaches typically lead to a non-negligible drop in accuracy. Notably, the angle of lossless acceleration by optimizing feature fusion matrix multiplication, particularly through structural reparameterization, remains underexplored. In this paper, we propose MaRI, a novel Matrix Re-parameterized Inference framework, which serves as a complementary approach to existing techniques while accelerating ranking model inference without any accuracy loss. MaRI is motivated by the observation that user-side computation is redundant in feature fusion matrix multiplication, and we therefore adopt the philosophy of structural reparameterization to alleviate such redundancy.

</details>


### [74] [From Agnostic to Specific: Latent Preference Diffusion for Multi-Behavior Sequential Recommendation](https://arxiv.org/abs/2602.23132)
*Ruochen Yang,Xiaodong Li,Jiawei Sheng,Jiangxia Cao,Xinkui Lin,Shen Wang,Shuang Yang,Zhaojie Liu,Tingwen Liu*

Main category: cs.IR

TL;DR: 基于扩散模型的框架，通过从行为无关到行为特定的潜在空间偏好生成，实现多行为序列推荐


<details>
  <summary>Details</summary>
Motivation: 现有多行为序列推荐方法存在两个主要问题：1）忽略了用户潜在决策偏好；2）基于偏好评分的判别式范式无法有效处理从低熵行为到高熵项目的不对称确定性，导致推荐效果受限

Method: 提出FatsMB框架：1）使用多行为自编码器构建统一的用户潜在偏好空间；2）在潜在空间中进行目标行为特定的偏好转移；3）引入多条件引导层归一化进行去噪

Result: 在真实世界数据集上的广泛实验证明了模型的有效性

Conclusion: 该框架能够从行为无关到行为特定地引导偏好生成，实现多样化和准确的多行为序列推荐

Abstract: Multi-behavior sequential recommendation (MBSR) aims to learn the dynamic and heterogeneous interactions of users' multi-behavior sequences, so as to capture user preferences under target behavior for the next interacted item prediction. Unlike previous methods that adopt unidirectional modeling by mapping auxiliary behaviors to target behavior, recent concerns are shifting from behavior-fixed to behavior-specific recommendation. However, these methods still ignore the user's latent preference that underlying decision-making, leading to suboptimal solutions. Meanwhile, due to the asymmetric deterministic between items and behaviors, discriminative paradigm based on preference scoring is unsuitable to capture the uncertainty from low-entropy behaviors to high-entropy items, failing to provide efficient and diverse recommendation. To address these challenges, we propose \textbf{FatsMB}, a framework based diffusion model that guides preference generation \textit{\textbf{F}rom Behavior-\textbf{A}gnostic \textbf{T}o Behavior-\textbf{S}pecific} in latent spaces, enabling diverse and accurate \textit{\textbf{M}ulti-\textbf{B}ehavior Sequential Recommendation}. Specifically, we design a Multi-Behavior AutoEncoder (MBAE) to construct a unified user latent preference space, facilitating interaction and collaboration across Behaviors, within Behavior-aware RoPE (BaRoPE) employed for multiple information fusion. Subsequently, we conduct target behavior-specific preference transfer in the latent space, enriching with informative priors. A Multi-Condition Guided Layer Normalization (MCGLN) is introduced for the denoising. Extensive experiments on real-world datasets demonstrate the effectiveness of our model.

</details>


### [75] [Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments](https://arxiv.org/abs/2602.23234)
*Evangelia Christakopoulou,Vivekkumar Patel,Hemanth Velaga,Sandip Gaikwad*

Main category: cs.IR

TL;DR: 使用LLM生成大量文本相关性标签，解决数据稀缺问题，通过增强生产排序系统，在行为相关性和文本相关性上同时获得提升，并在A/B测试中验证了转化率提升。


<details>
  <summary>Details</summary>
Motivation: 商业搜索系统需要同时优化行为相关性（用户点击/下载倾向）和文本相关性（结果与查询的语义匹配），但面临专家提供的文本相关性标签稀缺问题，而行为相关性标签相对丰富。

Method: 1. 系统评估LLM配置，发现专门微调的小模型在提供高质量文本相关性标签方面优于大型预训练模型；2. 使用最优模型作为"力量倍增器"生成数百万文本相关性标签；3. 将这些标签集成到生产排序器中。

Result: 1. 离线评估：NDCG在行为相关性和文本相关性上同时提升，Pareto前沿向外移动；2. 在线A/B测试：App Store排序器在全球范围内实现+0.24%的转化率显著提升；3. 尾部查询表现最显著，新文本相关性标签在缺乏可靠行为相关性标签时提供了稳健信号。

Conclusion: 通过使用专门微调的LLM生成大规模文本相关性标签，可以有效解决数据稀缺问题，显著提升搜索系统的相关性质量，特别是在尾部查询场景下，实现了行为相关性和文本相关性的双重优化。

Abstract: Large-scale commercial search systems optimize for relevance to drive successful sessions that help users find what they are looking for. To maximize relevance, we leverage two complementary objectives: behavioral relevance (results users tend to click or download) and textual relevance (a result's semantic fit to the query). A persistent challenge is the scarcity of expert-provided textual relevance labels relative to abundant behavioral relevance labels. We first address this by systematically evaluating LLM configurations, finding that a specialized, fine-tuned model significantly outperforms a much larger pre-trained one in providing highly relevant labels. Using this optimal model as a force multiplier, we generate millions of textual relevance labels to overcome the data scarcity. We show that augmenting our production ranker with these textual relevance labels leads to a significant outward shift of the Pareto frontier: offline NDCG improves for behavioral relevance while simultaneously increasing for textual relevance. These offline gains were validated by a worldwide A/B test on the App Store ranker, which demonstrated a statistically significant +0.24% increase in conversion rate, with the most substantial performance gains occurring in tail queries, where the new textual relevance labels provide a robust signal in the absence of reliable behavioral relevance labels.

</details>
