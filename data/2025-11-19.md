<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models](https://arxiv.org/abs/2511.13722)
*William Guo,Adaku Uchendu,Ana Smith*

Main category: cs.CL

TL;DR: 本文评估了多种水印技术的鲁棒性，发现它们能保持语义但会偏离原始文本的写作风格，且容易受到对抗性攻击，特别是回译攻击。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型生成文本的潜在危害，研究者提出了水印技术，但现有技术存在降低文本质量、易受对抗攻击的问题，阻碍了其广泛应用。

Method: 通过比较改写和回译（英语→其他语言→英语）两种对抗攻击方式，评估多种水印技术的鲁棒性；使用语言指标来评估水印文本在质量和写作风格上的保持能力。

Result: 水印技术能够保持语义，但会偏离未加水印文本的写作风格，并且容易受到对抗性攻击，特别是回译攻击。

Conclusion: 当前的水印技术在保持语义方面表现良好，但在写作风格保持和对抗攻击鲁棒性方面存在不足，需要进一步改进以促进其广泛应用。

Abstract: To mitigate the potential harms of Large Language Models (LLMs)generated text, researchers have proposed watermarking, a process of embedding detectable signals within text. With watermarking, we can always accurately detect LLM-generated texts. However, recent findings suggest that these techniques often negatively affect the quality of the generated texts, and adversarial attacks can strip the watermarking signals, causing the texts to possibly evade detection. These findings have created resistance in the wide adoption of watermarking by LLM creators. Finally, to encourage adoption, we evaluate the robustness of several watermarking techniques to adversarial attacks by comparing paraphrasing and back translation (i.e., English $\to$ another language $\to$ English) attacks; and their ability to preserve quality and writing style of the unwatermarked texts by using linguistic metrics to capture quality and writing style of texts. Our results suggest that these watermarking techniques preserve semantics, deviate from the writing style of the unwatermarked texts, and are susceptible to adversarial attacks, especially for the back translation attack.

</details>


### [2] [Refine Thought: A Test-Time Inference Method for Embedding Model Reasoning](https://arxiv.org/abs/2511.13726)
*Guangzhi Wang,Kai Li,Yinghao Jiao,Zhi Liu*

Main category: cs.CL

TL;DR: RT方法通过多次前向传播增强文本嵌入模型的语义推理能力，在语义推理任务上表现显著提升，同时保持通用语义理解任务的性能。


<details>
  <summary>Details</summary>
Motivation: 提升文本嵌入模型的语义推理能力，激活预训练阶段学到的推理能力。

Method: 通过多次前向传播运行文本嵌入模型，获得最终的语义表示。

Result: 在BRIGHT和PJBenchmark1语义推理任务上取得显著改进，在C-MTEB等通用语义理解任务上保持稳定性能。

Conclusion: RT是一种有效的测试时推理方法，能够激活解码器专用文本嵌入模型在预训练中学到的语义推理能力。

Abstract: We propose RT (Refine Thought), a method that can enhance the semantic rea-soning ability of text embedding models. The method obtains the final semanticrepresentation by running multiple forward passes of the text embedding model.Experiments show that RT achieves significant improvements on semantic reason-ing tasks in BRIGHT and the person job matching benchmark PJBenchmark1, while maintaining consistent performance on general-purpose semantic under-standing tasks such as C-MTEB. Our results indicate that RT is effective becauseit further activates the semantic reasoning ability learned during pretraining bydecoder-only text embedding models(e.g., Qwen3-Embedding-8B). RT canbe seen as a test-time inference method.

</details>


### [3] [Can QE-informed (Re)Translation lead to Error Correction?](https://arxiv.org/abs/2511.13884)
*Govardhan Padmanabhan*

Main category: cs.CL

TL;DR: 本文提出了两种无需训练的QE-informed方法用于机器翻译错误修正，其中获胜方法通过选择不同LLM生成的最佳质量翻译，在WMT 2025任务3中取得了领先成绩。


<details>
  <summary>Details</summary>
Motivation: 虽然联合训练QE和APE系统能提升性能，但APE系统存在过度修正问题导致性能下降，因此研究无需训练的QE-informed方法。

Method: 提出两种方法：1) QE-informed重翻译：选择不同LLM生成的多候选翻译中质量最高的；2) 类似APE的方法：根据QE解释替换错误子串，使用条件启发式最小化编辑次数。

Result: 两种方法的Delta COMET得分分别为0.0201和-0.0108，第一种方法在子任务排行榜中获胜。

Conclusion: 无需训练的QE-informed重翻译方法在机器翻译错误修正任务中表现优于基于编辑的方法，证明了选择最佳翻译策略的有效性。

Abstract: The paper presents two approaches submitted to the WMT 2025 Automated Translation Quality Evaluation Systems Task 3 - Quality Estimation (QE)-informed Segment-level Error Correction. While jointly training QE systems with Automatic Post-Editing (APE) has shown improved performance for both tasks, APE systems are still known to overcorrect the output of Machine Translation (MT), leading to a degradation in performance. We investigate a simple training-free approach - QE-informed Retranslation, and compare it with another within the same training-free paradigm. Our winning approach selects the highest-quality translation from multiple candidates generated by different LLMs. The second approach, more akin to APE, instructs an LLM to replace error substrings as specified in the provided QE explanation(s). A conditional heuristic was employed to minimise the number of edits, with the aim of maximising the Gain-to-Edit ratio. The two proposed approaches achieved a Delta COMET score of 0.0201 and -0.0108, respectively, leading the first approach to achieve the winning position on the subtask leaderboard.

</details>


### [4] [What Works for 'Lost-in-the-Middle' in LLMs? A Study on GM-Extract and Mitigations](https://arxiv.org/abs/2511.13900)
*Mihir Gupte,Eshan Dixit,Muhammad Tayyab,Arun Adiththan*

Main category: cs.CL

TL;DR: GM-Extract基准数据集评估LLM在控制变量检索中的表现，发现数据表示方式显著影响检索性能，缓解方法的效果具有复杂性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长文本中有效利用上下文的能力下降（"迷失在中间"现象）对基于检索的LLM应用构成重大挑战。

Method: 提出GM-Extract基准数据集，使用两个指标（空间检索能力和语义检索能力）评估7-8B参数模型在多文档任务中的表现，并进行缓解方法的文献调查和应用测试。

Result: 数据表示方式显著改变检索性能，性能模式与困惑度得分相关，缓解方法的效果具有高度复杂性，既有成功改善性能的情况，也有产生负面影响的意外情况。

Conclusion: 在真实应用场景中评估LLM的长文本处理能力至关重要，缓解方法的效果需要根据具体场景谨慎选择，GM-Extract为未来研究提供了有价值的基准。

Abstract: The diminishing ability of large language models (LLMs) to effectively utilize long-range context-the "lost-in-the-middle" phenomenon-poses a significant challenge in retrieval-based LLM applications. To study the impact of this phenomenon in a real-world application setting, we introduce GM-Extract, a novel benchmark dataset meticulously designed to evaluate LLM performance on retrieval of control variables. To accurately diagnose failure modes, we propose a simple yet elegant evaluation system using two distinct metrics: one for spatial retrieval capability (Document Metric) and the other for semantic retrieval capability (Variable Extraction Metric). We conduct a systematic evaluation of 7-8B parameter models on two multi-document tasks (key-value extraction and question-answering), demonstrating a significant change in retrieval performance simply by altering how the data is represented in the context window. While a distinct U-shaped curve was not consistently observed, our analysis reveals a clear pattern of performance across models, which we further correlate with perplexity scores. Furthermore, we perform a literature survey of mitigation methods, which we categorize into two distinct approaches: black-box and white-box methods. We then apply these techniques to our benchmark, finding that their efficacy is highly nuanced. Our evaluation highlights scenarios where these strategies successfully improve performance, as well as surprising cases where they lead to a negative impact, providing a comprehensive understanding of their utility in a practical context.

</details>


### [5] [Hint-Augmented Re-ranking: Efficient Product Search using LLM-Based Query Decomposition](https://arxiv.org/abs/2511.13994)
*Yilun Zhu,Nikhita Vedula,Shervin Malmasi*

Main category: cs.CL

TL;DR: LLM框架解析电商搜索中的最高级查询意图，通过提取结构化提示来改进搜索性能，在MAP和MRR指标上显著提升，并开发高效方法将语义理解转移到轻量级模型。


<details>
  <summary>Details</summary>
Motivation: 电商搜索中的最高级查询（如'最好'、'最流行'）需要跨多个维度比较候选商品，这要求语言理解和领域知识。现有方法难以有效解析这些查询的潜在意图。

Method: 开发一个框架，将查询分解为属性-值提示，这些提示与检索过程同时生成，从而能够高效集成到排序管道中。还开发了将最高级解释转移到轻量级模型的高效方法。

Result: 该方法在MAP指标上提升了10.9个百分点，在MRR指标上提升了5.9个百分点，显著优于基线方法。

Conclusion: 研究揭示了最高级语义如何在模型间表示和传递，推进了检索系统中的语言解释能力，同时解决了实际部署的延迟约束问题。

Abstract: Search queries with superlatives (e.g., best, most popular) require comparing candidates across multiple dimensions, demanding linguistic understanding and domain knowledge. We show that LLMs can uncover latent intent behind these expressions in e-commerce queries through a framework that extracts structured interpretations or hints. Our approach decomposes queries into attribute-value hints generated concurrently with retrieval, enabling efficient integration into the ranking pipeline. Our method improves search performanc eby 10.9 points in MAP and ranking by 5.9 points in MRR over baselines. Since direct LLM-based reranking faces prohibitive latency, we develop an efficient approach transferring superlative interpretations to lightweight models. Our findings provide insights into how superlative semantics can be represented and transferred between models, advancing linguistic interpretation in retrieval systems while addressing practical deployment constraints.

</details>


### [6] [Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports](https://arxiv.org/abs/2511.14010)
*Chenchen Kuai,Zihao Li,Braden Rosen,Stephanie Paan,Navid Jafari,Jean-Louis Briaud,Yunlong Zhang,Youssef M. A. Hashash,Yang Zhou*

Main category: cs.CL

TL;DR: MoRA-RAG框架通过混合检索和代理分块技术，将灾害勘察报告转化为结构化知识，显著提升多灾害推理的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 灾害勘察报告包含理解多灾害相互作用的关键证据，但其非结构化叙述使得系统知识传递困难。大语言模型在缺乏领域基础时会产生不可靠或虚构的输出。

Method: 提出MoRA-RAG框架，包含混合检索机制动态路由跨灾害特定数据库的查询，使用代理分块保持检索时的上下文连贯性，并包含验证循环评估证据充分性、优化查询和在信息不完整时启动定向搜索。

Result: 在HazardRecQA数据集上，MoRA-RAG达到94.5%准确率，比零样本LLM提升30%，比最先进RAG系统提升10%，同时在不同LLM架构上减少幻觉。使开源LLM达到与专有模型相当的性能。

Conclusion: MoRA-RAG为将灾后文档转化为可操作、可信赖的灾害韧性智能建立了新范式。

Abstract: Post-disaster reconnaissance reports contain critical evidence for understanding multi-hazard interactions, yet their unstructured narratives make systematic knowledge transfer difficult. Large language models (LLMs) offer new potential for analyzing these reports, but often generate unreliable or hallucinated outputs when domain grounding is absent. This study introduces the Mixture-of-Retrieval Agentic RAG (MoRA-RAG), a knowledge-grounded LLM framework that transforms reconnaissance reports into a structured foundation for multi-hazard reasoning. The framework integrates a Mixture-of-Retrieval mechanism that dynamically routes queries across hazard-specific databases while using agentic chunking to preserve contextual coherence during retrieval. It also includes a verification loop that assesses evidence sufficiency, refines queries, and initiates targeted searches when information remains incomplete. We construct HazardRecQA by deriving question-answer pairs from GEER reconnaissance reports, which document 90 global events across seven major hazard types. MoRA-RAG achieves up to 94.5 percent accuracy, outperforming zero-shot LLMs by 30 percent and state-of-the-art RAG systems by 10 percent, while reducing hallucinations across diverse LLM architectures. MoRA-RAG also enables open-weight LLMs to achieve performance comparable to proprietary models. It establishes a new paradigm for transforming post-disaster documentation into actionable, trustworthy intelligence for hazard resilience.

</details>


### [7] [HiEAG: Evidence-Augmented Generation for Out-of-Context Misinformation Detection](https://arxiv.org/abs/2511.14027)
*Junjie Wu,Yumeng Fu,Nan Yu,Guohong Fu*

Main category: cs.CL

TL;DR: HiEAG是一个分层证据增强生成框架，通过多模态大语言模型改进外部一致性检查，在OOC虚假信息检测中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的OOC虚假信息检测方法过于强调内部一致性，忽视了图像-文本对与外部证据之间的外部一致性的重要性。

Method: 提出分层证据增强生成框架，通过证据重排序（使用AESP）和证据重写（使用AEGP）模块，结合检索、重排序和重写的综合流程，利用MLLMs的广泛知识。

Result: 在不同基准数据集上的实验结果表明，HiEAG在所有样本的准确率上超过了之前的最先进方法。

Conclusion: HiEAG框架通过分层证据增强生成有效改进了外部一致性检查，在OOC虚假信息检测任务中表现出色，并支持判断解释。

Abstract: Recent advancements in multimodal out-of-context (OOC) misinformation detection have made remarkable progress in checking the consistencies between different modalities for supporting or refuting image-text pairs. However, existing OOC misinformation detection methods tend to emphasize the role of internal consistency, ignoring the significant of external consistency between image-text pairs and external evidence. In this paper, we propose HiEAG, a novel Hierarchical Evidence-Augmented Generation framework to refine external consistency checking through leveraging the extensive knowledge of multimodal large language models (MLLMs). Our approach decomposes external consistency checking into a comprehensive engine pipeline, which integrates reranking and rewriting, apart from retrieval. Evidence reranking module utilizes Automatic Evidence Selection Prompting (AESP) that acquires the relevant evidence item from the products of evidence retrieval. Subsequently, evidence rewriting module leverages Automatic Evidence Generation Prompting (AEGP) to improve task adaptation on MLLM-based OOC misinformation detectors. Furthermore, our approach enables explanation for judgment, and achieves impressive performance with instruction tuning. Experimental results on different benchmark datasets demonstrate that our proposed HiEAG surpasses previous state-of-the-art (SOTA) methods in the accuracy over all samples.

</details>


### [8] [Based on Data Balancing and Model Improvement for Multi-Label Sentiment Classification Performance Enhancement](https://arxiv.org/abs/2511.14073)
*Zijin Su,Huanzhu Lv,Yuren Niu,Yiming Liu*

Main category: cs.CL

TL;DR: 构建平衡的多标签情感数据集并开发增强分类模型，显著提升多标签情感分类性能


<details>
  <summary>Details</summary>
Motivation: 现有的多标签情感分类数据集（如GoEmotions）存在严重的类别不平衡问题，影响模型性能，特别是对于代表性不足的情感类别

Method: 1. 构建平衡数据集：整合原始GoEmotions数据、使用RoBERTa-base-GoEmotions模型标注的Sentiment140样本，以及GPT-4 mini生成的人工标注文本；2. 开发增强分类模型：结合FastText预训练嵌入、卷积层提取局部特征、双向LSTM进行上下文学习、注意力机制突出情感相关词；3. 使用sigmoid激活输出层进行多标签预测，采用混合精度训练提高计算效率

Result: 实验结果显示，与在非平衡数据上训练的模型相比，在准确率、精确率、召回率、F1分数和AUC方面均有显著提升

Conclusion: 该方法通过数据平衡策略和增强模型架构，有效解决了多标签情感分类中的类别不平衡问题，显著提升了模型性能

Abstract: Multi-label sentiment classification plays a vital role in natural language processing by detecting multiple emotions within a single text. However, existing datasets like GoEmotions often suffer from severe class imbalance, which hampers model performance, especially for underrepresented emotions. To address this, we constructed a balanced multi-label sentiment dataset by integrating the original GoEmotions data, emotion-labeled samples from Sentiment140 using a RoBERTa-base-GoEmotions model, and manually annotated texts generated by GPT-4 mini. Our data balancing strategy ensured an even distribution across 28 emotion categories. Based on this dataset, we developed an enhanced multi-label classification model that combines pre-trained FastText embeddings, convolutional layers for local feature extraction, bidirectional LSTM for contextual learning, and an attention mechanism to highlight sentiment-relevant words. A sigmoid-activated output layer enables multi-label prediction, and mixed precision training improves computational efficiency. Experimental results demonstrate significant improvements in accuracy, precision, recall, F1-score, and AUC compared to models trained on imbalanced data, highlighting the effectiveness of our approach.

</details>


### [9] [Stealth Fine-Tuning: Efficiently Breaking Alignment in RVLMs Using Self-Generated CoT](https://arxiv.org/abs/2511.14106)
*Le Yu,Zhengyue Zhao,Yawen Zheng,Yunhao Liu*

Main category: cs.CL

TL;DR: 提出了一种名为Stealth Fine-Tuning的新型攻击方法，通过分段干扰和自生成输出作为监督微调数据，能够以低成本（仅需499个样本和3小时A100训练）有效绕过RVLMs的安全对齐防御，同时保持模型的通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（RVLMs）依赖安全对齐来防止有害行为，但其暴露的思维链（CoT）轨迹引入了新的攻击面。研究发现RVLMs的安全对齐很容易被突破。

Method: 采用Stealth Fine-Tuning攻击方法，通过分段干扰引发有害推理轨迹，并将自生成输出作为监督微调数据，使用轮次加权损失设计实现轻量级、分布一致的微调。

Result: 在实验中，仅使用499个样本和单张A100显卡（QLoRA）训练不到3小时，Stealth Fine-Tuning的ASR比IDEATOR高出38.52%，同时保持通用推理能力，调整后的模型保留了原始表示分布。在AdvBench和多个通用基准测试中验证了该方法的有效性。

Conclusion: Stealth Fine-Tuning是一种低成本且高效的绕过对齐防御的方法，暴露了RVLMs安全对齐的脆弱性。

Abstract: Reasoning-augmented Vision-Language Models (RVLMs) rely on safety alignment to prevent harmful behavior, yet their exposed chain-of-thought (CoT) traces introduce new attack surfaces. In this work, we find that the safety alignment of RVLMs can be easily break through a novel attack method termed \textbf{Stealth Fine-Tuning}. Our method elicits harmful reasoning traces through \textbf{segment-level interference} and reuses the self-generated outputs as supervised fine-tuning data. Through a \textbf{turn-based weighted} loss design, yielding a lightweight, distribution-consistent finetuning method. In our experiment, with only 499 samples and under 3 hours on a single A100 (QLoRA), Stealth Fine-Tuning outperforms IDEATOR by 38.52\% ASR while preserving general reasoning ability, as the tuned model retains the original representation distribution. Experiments on AdvBench and several general benchmarks demonstrate that Stealth Fine-Tuning is a low-cost and highly effective way to bypass alignment defenses. \textcolor{red}{\textbf{Disclaimer: This paper contains content that may be disturbing or offensive.}}

</details>


### [10] [Synthetic Clinical Notes for Rare ICD Codes: A Data-Centric Framework for Long-Tail Medical Coding](https://arxiv.org/abs/2511.14112)
*Truong Vo,Weiyi Wu,Kaize Ding*

Main category: cs.CL

TL;DR: 提出了一种数据中心的框架，通过生成高质量的合成出院摘要来解决ICD编码中的长尾分布问题，显著扩展了训练数据分布，在保持强微F1的同时适度提高了宏F1性能。


<details>
  <summary>Details</summary>
Motivation: 临床文本自动ICD编码任务受到诊断代码极端长尾分布的阻碍，数千个罕见和零样本ICD代码在MIMIC-III等数据集中代表性严重不足，导致宏F1分数较低。

Method: 构建基于真实世界共现模式、ICD描述、同义词、分类法和相似临床笔记的结构化提示，生成覆盖7,902个ICD代码的90,000个合成笔记，显著扩展训练分布。在原始和扩展数据集上微调PLM-ICD和GKI-ICD两个最先进的基于transformer的模型。

Result: 实验表明该方法在保持强微F1的同时适度提高了宏F1，优于先前的最先进方法。虽然相对于计算成本而言增益可能显得边际，但结果证明了精心设计的合成数据可以增强长尾ICD代码预测的公平性。

Conclusion: 精心制作的合成数据能够增强长尾ICD代码预测的公平性，为解决医疗NLP中的长尾分布问题提供了有效的数据中心解决方案。

Abstract: Automatic ICD coding from clinical text is a critical task in medical NLP but remains hindered by the extreme long-tail distribution of diagnostic codes. Thousands of rare and zero-shot ICD codes are severely underrepresented in datasets like MIMIC-III, leading to low macro-F1 scores. In this work, we propose a data-centric framework that generates high-quality synthetic discharge summaries to mitigate this imbalance. Our method constructs realistic multi-label code sets anchored on rare codes by leveraging real-world co-occurrence patterns, ICD descriptions, synonyms, taxonomy, and similar clinical notes. Using these structured prompts, we generate 90,000 synthetic notes covering 7,902 ICD codes, significantly expanding the training distribution. We fine-tune two state-of-the-art transformer-based models, PLM-ICD and GKI-ICD, on both the original and extended datasets. Experiments show that our approach modestly improves macro-F1 while maintaining strong micro-F1, outperforming prior SOTA. While the gain may seem marginal relative to the computational cost, our results demonstrate that carefully crafted synthetic data can enhance equity in long-tail ICD code prediction.

</details>


### [11] [From Graphs to Hypergraphs: Enhancing Aspect-Based Sentiment Analysis via Multi-Level Relational Modeling](https://arxiv.org/abs/2511.14142)
*Omkar Mahesh Kashyap,Padegal Amit,Madhav Kashyap,Ashwini M Joshi,Shylaja SS*

Main category: cs.CL

TL;DR: HyperABSA是一个动态超图框架，通过样本特定的层次聚类构建方面-意见结构，解决了传统图方法在短文本情感分析中的冗余和参数开销问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于图的方法只能建模成对依赖关系，需要为不同关系视图构建多个图，这引入了冗余、参数开销和融合过程中的错误传播，限制了在短文本、低资源设置下的鲁棒性。

Method: 提出动态超图框架HyperABSA，通过样本特定的层次聚类诱导方面-意见结构，并引入加速-回退截止点的新方法来自适应确定层次聚类的粒度级别。

Result: 在三个基准数据集（Lap14、Rest14、MAMS）上的实验显示，相比强大的图基线方法取得了持续改进，特别是与RoBERTa骨干网络结合时获得了显著提升。

Conclusion: 动态超图构建是ABSA任务中高效且强大的替代方案，并具有扩展到其他短文本NLP任务的潜力。

Abstract: Aspect-Based Sentiment Analysis (ABSA) predicts sentiment polarity for specific aspect terms, a task made difficult by conflicting sentiments across aspects and the sparse context of short texts. Prior graph-based approaches model only pairwise dependencies, forcing them to construct multiple graphs for different relational views. These introduce redundancy, parameter overhead, and error propagation during fusion, limiting robustness in short-text, low-resource settings. We present HyperABSA, a dynamic hypergraph framework that induces aspect-opinion structures through sample-specific hierarchical clustering. To construct these hyperedges, we introduce a novel acceleration-fallback cutoff for hierarchical clustering, which adaptively determines the level of granularity. Experiments on three benchmarks (Lap14, Rest14, MAMS) show consistent improvements over strong graph baselines, with substantial gains when paired with RoBERTa backbones. These results position dynamic hypergraph construction as an efficient, powerful alternative for ABSA, with potential extensions to other short-text NLP tasks.

</details>


### [12] [Applying Relation Extraction and Graph Matching to Answering Multiple Choice Questions](https://arxiv.org/abs/2511.14144)
*Naoki Shimoda,Akihiro Yamamoto*

Main category: cs.CL

TL;DR: 提出了一种结合Transformer关系抽取和知识图谱匹配的方法，用于回答填空题形式的多选题，同时保持输出过程的可追溯性。


<details>
  <summary>Details</summary>
Motivation: 知识图谱构建成本高，通常被视为静态数据库。但基于Transformer的关系抽取方法能够从自然语言文本动态生成知识图谱，这为用知识图谱表示输入句子的含义提供了可能性。

Method: 通过关系抽取方法将问题句子转换为关系图，然后在封闭世界假设下与事实正确的知识图谱进行验证，以衡量问题句子的真实性。

Result: 实验结果表明，该方法能正确回答约70%的问题，同时提供过程的可追溯性。问题类别对准确率有显著影响。

Conclusion: 该方法成功实现了动态知识图谱生成与验证的结合，为多选题回答提供了可追溯的解决方案，但准确率受问题类别影响较大。

Abstract: In this research, we combine Transformer-based relation extraction with matching of knowledge graphs (KGs) and apply them to answering multiple-choice questions (MCQs) while maintaining the traceability of the output process. KGs are structured representations of factual knowledge consisting of entities and relations. Due to the high construction cost, they had been regarded as static databases with validated links. However, the recent development of Transformer-based relation extraction (RE) methods has enabled us to generate KGs dynamically by giving them natural language texts, and thereby opened the possibility for representing the meaning of the input sentences with the created KGs. Using this effect, we propose a method that answers MCQs in the "fill-in-the-blank" format, taking care of the point that RE methods generate KGs that represent false information if provided with factually incorrect texts. We measure the truthfulness of each question sentence by (i) converting the sentence into a relational graph using an RE method and (ii) verifying it against factually correct KGs under the closed-world assumption. The experimental results demonstrate that our method correctly answers up to around 70% of the questions, while providing traceability of the procedure. We also highlight that the question category has a vast influence on the accuracy.

</details>


### [13] [Selective Weak-to-Strong Generalization](https://arxiv.org/abs/2511.14166)
*Hao Lang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 提出选择性弱到强泛化框架，通过训练二元分类器识别强模型能回答的问题，避免不必要的弱监督，并使用图平滑方法优化弱标签，在三个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 未来超人类模型将超越人类能力，人类只能对超人类模型进行弱监督。现有弱到强泛化方法固定使用弱监督，但部分弱标签对模型有害，存在鲁棒性问题。

Method: 训练二元分类器P(IK)识别强模型能回答的问题，使用自生成标签进行对齐；通过图平滑方法优化弱标签。

Result: 在三个基准测试中持续优于竞争基线；P(IK)能跨任务和难度泛化。

Conclusion: 选择性弱到强泛化有助于超对齐，能有效避免不必要的弱监督，提升模型性能。

Abstract: Future superhuman models will surpass the ability of humans and humans will only be able to \textit{weakly} supervise superhuman models. To alleviate the issue of lacking high-quality data for model alignment, some works on weak-to-strong generalization (W2SG) finetune a strong pretrained model with a weak supervisor so that it can generalize beyond weak supervision. However, the invariable use of weak supervision in existing methods exposes issues in robustness, with a proportion of weak labels proving harmful to models. In this paper, we propose a selective W2SG framework to avoid using weak supervision when unnecessary. We train a binary classifier P(IK) to identify questions that a strong model can answer and use its self-generated labels for alignment. We further refine weak labels with a graph smoothing method. Extensive experiments on three benchmarks show that our method consistently outperforms competitive baselines. Further analyses show that P(IK) can generalize across tasks and difficulties, which indicates selective W2SG can help superalignment.

</details>


### [14] [SymLoc: Symbolic Localization of Hallucination across HaluEval and TruthfulQA](https://arxiv.org/abs/2511.14172)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 提出了首个基于符号语言知识的幻觉定位框架，通过分析符号触发词在模型各层的处理过程，揭示了幻觉本质上是符号语义处理失败而非一般生成问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理符号触发词（如修饰语、否定、数字等）时仍存在幻觉问题，但缺乏对这些符号幻觉来源的清晰理解，需要系统性地处理这些触发词并定位幻觉在模型内部的产生位置。

Method: 提出符号定位框架，利用符号语言和语义知识追踪幻觉在所有模型层的发展，通过关注模型如何处理符号触发词，使用HaluEval和TruthfulQA分析五个模型。

Result: 符号知识方法显示这些语言元素的注意力方差在早期层（2-4）爆炸性增长至临界不稳定状态，否定触发灾难性方差水平，表明符号语义处理从一开始就崩溃。尽管模型规模更大，幻觉率仍保持高位（78.3%-83.7%），深层中符号语义触发词的注意力急剧下降。

Conclusion: 幻觉本质上是符号语言处理失败，而非一般生成问题，符号语义知识为理解和定位LLMs中幻觉机制提供了关键。

Abstract: LLMs still struggle with hallucination, especially when confronted with symbolic triggers like modifiers, negation, numbers, exceptions, and named entities. Yet, we lack a clear understanding of where these symbolic hallucinations originate, making it crucial to systematically handle such triggers and localize the emergence of hallucination inside the model. While prior work explored localization using statistical techniques like LSC and activation variance analysis, these methods treat all tokens equally and overlook the role symbolic linguistic knowledge plays in triggering hallucinations. So far, no approach has investigated how symbolic elements specifically drive hallucination failures across model layers, nor has symbolic linguistic knowledge been used as the foundation for a localization framework. We propose the first symbolic localization framework that leverages symbolic linguistic and semantic knowledge to meaningfully trace the development of hallucinations across all model layers. By focusing on how models process symbolic triggers, we analyze five models using HaluEval and TruthfulQA. Our symbolic knowledge approach reveals that attention variance for these linguistic elements explodes to critical instability in early layers (2-4), with negation triggering catastrophic variance levels, demonstrating that symbolic semantic processing breaks down from the very beginning. Through the lens of symbolic linguistic knowledge, despite larger model sizes, hallucination rates remain consistently high (78.3%-83.7% across Gemma variants), with steep attention drops for symbolic semantic triggers throughout deeper layers. Our findings demonstrate that hallucination is fundamentally a symbolic linguistic processing failure, not a general generation problem, revealing that symbolic semantic knowledge provides the key to understanding and localizing hallucination mechanisms in LLMs.

</details>


### [15] [LiveRAG: A diverse Q&A dataset with varying difficulty level for RAG evaluation](https://arxiv.org/abs/2511.14531)
*David Carmel,Simone Filice,Guy Horowitz,Yoelle Maarek,Alex Shtoff,Oren Somekh,Ran Tavory*

Main category: cs.CL

TL;DR: LiveRAG是一个包含895个合成问答对的公开基准数据集，用于系统评估基于检索增强生成（RAG）的问答系统，源自SIGIR'2025 LiveRAG挑战赛，包含真实答案、支持性声明以及难度和区分度评分。


<details>
  <summary>Details</summary>
Motivation: 随着RAG在生成式AI解决方案中日益突出，需要系统评估其有效性，但缺乏标准化的评估基准。

Method: 创建了包含895个合成问答对的LiveRAG基准数据集，基于SIGIR'2025 LiveRAG挑战赛，添加了真实答案、支持性声明，并应用项目反应理论模型计算难度和区分度评分。

Result: 分析显示基准问题具有多样性、广泛的难度范围，并能有效区分系统能力，有助于推进RAG研究和系统评估。

Conclusion: LiveRAG基准将帮助社区推进RAG研究，进行系统评估，并开发更强大的问答系统。

Abstract: With Retrieval Augmented Generation (RAG) becoming more and more prominent in generative AI solutions, there is an emerging need for systematically evaluating their effectiveness. We introduce the LiveRAG benchmark, a publicly available dataset of 895 synthetic questions and answers designed to support systematic evaluation of RAG-based Q&A systems. This synthetic benchmark is derived from the one used during the SIGIR'2025 LiveRAG Challenge, where competitors were evaluated under strict time constraints. It is augmented with information that was not made available to competitors during the Challenge, such as the ground-truth answers, together with their associated supporting claims which were used for evaluating competitors' answers. In addition, each question is associated with estimated difficulty and discriminability scores, derived from applying an Item Response Theory model to competitors' responses. Our analysis highlights the benchmark's questions diversity, the wide range of their difficulty levels, and their usefulness in differentiating between system capabilities. The LiveRAG benchmark will hopefully help the community advance RAG research, conduct systematic evaluation, and develop more robust Q&A systems.

</details>


### [16] [Harnessing Deep LLM Participation for Robust Entity Linking](https://arxiv.org/abs/2511.14181)
*Jiajun Hou,Chenyu Zhang,Rui Meng*

Main category: cs.CL

TL;DR: DeepEL是一个将大语言模型深度集成到实体链接各个阶段的框架，通过自验证机制利用全局上下文信息纠正预测，在10个基准数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只将大语言模型应用于实体链接的孤立阶段，未能充分利用其在整个过程中的能力，且孤立消歧不足以实现最优性能。

Method: 提出DeepEL框架，将大语言模型集成到实体链接的每个阶段，并引入基于全局上下文信息的自验证机制，使大语言模型能够纠正自身预测并识别同一句子中实体间的连贯关系。

Result: 在10个基准数据集上的广泛评估表明，DeepEL显著优于现有最先进方法，整体F1分数平均提升2.6%，在域外数据集上提升4%。

Conclusion: 深度集成大语言模型能有效推进实体链接技术的前沿发展，自验证机制和全局上下文利用是提升性能的关键。

Abstract: Entity Linking (EL), the task of mapping textual entity mentions to their corresponding entries in knowledge bases, constitutes a fundamental component of natural language understanding. Recent advancements in Large Language Models (LLMs) have demonstrated remarkable potential for enhancing EL performance. Prior research has leveraged LLMs to improve entity disambiguation and input representation, yielding significant gains in accuracy and robustness. However, these approaches typically apply LLMs to isolated stages of the EL task, failing to fully integrate their capabilities throughout the entire process.
  In this work, we introduce DeepEL, a comprehensive framework that incorporates LLMs into every stage of the entity linking task. Furthermore, we identify that disambiguating entities in isolation is insufficient for optimal performance. To address this limitation, we propose a novel self-validation mechanism that utilizes global contextual information, enabling LLMs to rectify their own predictions and better recognize cohesive relationships among entities within the same sentence.
  Extensive empirical evaluation across ten benchmark datasets demonstrates that DeepEL substantially outperforms existing state-of-the-art methods, achieving an average improvement of 2.6\% in overall F1 score and a remarkable 4% gain on out-of-domain datasets. These results underscore the efficacy of deep LLM integration in advancing the state-of-the-art in entity linking.

</details>


### [17] [ArbESC+: Arabic Enhanced Edit Selection System Combination for Grammatical Error Correction Resolving conflict and improving system combination in Arabic GEC](https://arxiv.org/abs/2511.14230)
*Ahlam Alrehili,Areej Alhothali*

Main category: cs.CL

TL;DR: 提出了首个阿拉伯语多系统语法纠错框架ArbESC+，通过组合多个模型生成纠错建议，使用分类器选择最佳修正，在QALB数据集上取得了优于单一模型的效果。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语具有复杂的形态和句法结构，比其它语言更具挑战性。虽然现代神经模型已有很大改进，但以往方法大多使用单一模型，没有充分利用多系统组合的潜力。

Method: 开发了ArbESC+多系统框架，使用AraT5、ByT5、mT5、AraBART等多个模型生成纠错建议，将其表示为数值特征，通过分类器选择最佳修正，并采用支持技术过滤重叠修正和评估决策可靠性。

Result: 在QALB-14测试数据上F0.5达到82.63%，在QALB-15 L1数据上达到84.64%，在QALB-15 L2数据上达到65.55%，优于单一模型。

Conclusion: 这是首个整合语言错误修正的阿拉伯语尝试，为开发先进的阿拉伯语文本处理工具提供了实用步骤，将惠及阿拉伯语用户和研究者。

Abstract: Grammatical Error Correction (GEC) is an important aspect of natural language processing. Arabic has a complicated morphological and syntactic structure, posing a greater challenge than other languages. Even though modern neural models have improved greatly in recent years, the majority of previous attempts used individual models without taking into account the potential benefits of combining different systems. In this paper, we present one of the first multi-system approaches for correcting grammatical errors in Arabic, the Arab Enhanced Edit Selection System Complication (ArbESC+). Several models are used to collect correction proposals, which are represented as numerical features in the framework. A classifier determines and implements the appropriate corrections based on these features. In order to improve output quality, the framework uses support techniques to filter overlapping corrections and estimate decision reliability. A combination of AraT5, ByT5, mT5, AraBART, AraBART+Morph+GEC, and Text editing systems gave better results than a single model alone, with F0.5 at 82.63% on QALB-14 test data, 84.64% on QALB-15 L1 data, and 65.55% on QALB-15 L2 data. As one of the most significant contributions of this work, it's the first Arab attempt to integrate linguistic error correction. Improving existing models provides a practical step towards developing advanced tools that will benefit users and researchers of Arabic text processing.

</details>


### [18] [MuCPT: Music-related Natural Language Model Continued Pretraining](https://arxiv.org/abs/2511.14245)
*Kai Tian,Yirong Mao,Wendong Bi,Hanjie Wang,Que Wenhui*

Main category: cs.CL

TL;DR: 本文提出了一个用于音乐领域大语言模型的数据训练框架，包括构建大规模音乐相关语料库（40B tokens）、实施领域优先的数据处理流程、引入基于参考模型的软评分质量控制系统，以及设计MusicSimpleQA基准测试来评估事实性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用任务上表现良好，但在音乐等专业领域受到限制，特别是在音乐娱乐领域，语料库规模、纯度和数据与训练目标的匹配至关重要。

Method: 1. 构建大规模音乐相关自然语言语料库（40B tokens）；2. 实施领域优先数据管道：轻量级分类器筛选和加权领域内文本，多阶段清理、去重和隐私保护掩码；3. 集成多源音乐文本与元数据；4. 引入基于参考模型的token级软评分进行质量控制；5. 设计MusicSimpleQA基准测试。

Result: 提出了一个可扩展的数据训练框架和可重用的评估工具，用于构建音乐领域的领域特定大语言模型，通过减少噪声梯度和放大任务对齐信号，实现更有效的音乐领域持续预训练和对齐。

Conclusion: 这项工作在语料库构建和训练目标设定方面都取得了进展，为音乐领域构建领域特定大语言模型提供了可扩展的数据训练框架和可重用的评估工具。

Abstract: Large language models perform strongly on general tasks but remain constrained in specialized settings such as music, particularly in the music-entertainment domain, where corpus scale, purity, and the match between data and training objectives are critical. We address this by constructing a large, music-related natural language corpus (40B tokens) that combines open source and in-house data, and by implementing a domain-first data pipeline: a lightweight classifier filters and weights in-domain text, followed by multi-stage cleaning, de-duplication, and privacy-preserving masking. We further integrate multi-source music text with associated metadata to form a broader, better-structured foundation of domain knowledge. On the training side, we introduce reference-model (RM)-based token-level soft scoring for quality control: a unified loss-ratio criterion is used both for data selection and for dynamic down-weighting during optimization, reducing noise gradients and amplifying task-aligned signals, thereby enabling more effective music-domain continued pretraining and alignment. To assess factuality, we design the MusicSimpleQA benchmark, which adopts short, single-answer prompts with automated agreement scoring. Beyond the benchmark design, we conduct systematic comparisons along the axes of data composition. Overall, this work advances both the right corpus and the right objective, offering a scalable data-training framework and a reusable evaluation tool for building domain LLMs in the music field.

</details>


### [19] [Towards Authentic Movie Dubbing with Retrieve-Augmented Director-Actor Interaction Learning](https://arxiv.org/abs/2511.14249)
*Rui Liu,Yuan Zhao,Zhenqi Jia*

Main category: cs.CL

TL;DR: 提出Authentic-Dubber模型，通过检索增强的导演-演员交互学习方案，模拟真实电影配音工作流程，显著提升情感表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有电影配音方法模拟简化的演员直接配音流程，忽略了导演与演员之间的关键交互环节，而真实工作流程中导演会指导演员内化情感上下文线索。

Method: 构建多模态参考片段库模拟导演提供的学习素材；提出基于情感相似性的检索增强策略；开发渐进式图基语音生成方法逐步融入检索到的多模态情感知识。

Result: 在V2C Animation基准数据集上的主观和客观评估验证了有效性，实现了情感表达能力的全面提升。

Conclusion: Authentic-Dubber通过模拟真实配音工作流程，在情感表达方面取得了显著改进，为电影配音任务提供了更真实的解决方案。

Abstract: The automatic movie dubbing model generates vivid speech from given scripts, replicating a speaker's timbre from a brief timbre prompt while ensuring lip-sync with the silent video. Existing approaches simulate a simplified workflow where actors dub directly without preparation, overlooking the critical director-actor interaction. In contrast, authentic workflows involve a dynamic collaboration: directors actively engage with actors, guiding them to internalize the context cues, specifically emotion, before performance. To address this issue, we propose a new Retrieve-Augmented Director-Actor Interaction Learning scheme to achieve authentic movie dubbing, termed Authentic-Dubber, which contains three novel mechanisms: (1) We construct a multimodal Reference Footage library to simulate the learning footage provided by directors. Note that we integrate Large Language Models (LLMs) to achieve deep comprehension of emotional representations across multimodal signals. (2) To emulate how actors efficiently and comprehensively internalize director-provided footage during dubbing, we propose an Emotion-Similarity-based Retrieval-Augmentation strategy. This strategy retrieves the most relevant multimodal information that aligns with the target silent video. (3) We develop a Progressive Graph-based speech generation approach that incrementally incorporates the retrieved multimodal emotional knowledge, thereby simulating the actor's final dubbing process. The above mechanisms enable the Authentic-Dubber to faithfully replicate the authentic dubbing workflow, achieving comprehensive improvements in emotional expressiveness. Both subjective and objective evaluations on the V2C Animation benchmark dataset validate the effectiveness. The code and demos are available at https://github.com/AI-S2-Lab/Authentic-Dubber.

</details>


### [20] [AfriSpeech-MultiBench: A Verticalized Multidomain Multicountry Benchmark Suite for African Accented English ASR](https://arxiv.org/abs/2511.14255)
*Gabrial Zencha Ashungafac,Mardhiyah Sanni,Busayo Awobade,Alex Gichamba,Tobi Olatunji*

Main category: cs.CL

TL;DR: AfriSpeech-MultiBench是首个针对非洲英语口音的领域特定评估套件，覆盖100多种口音、10+国家和7个应用领域，评估了多种语音识别系统在非洲语境下的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管语音AI技术快速发展，但缺乏针对非洲语言多样性的公开应用特定模型评估，需要填补这一空白以促进包容性语音应用。

Method: 使用来自各种开放非洲英语口音语音数据集的自发和非自发对话，对开源、闭源、单模态ASR和多模态LLM语音识别系统进行基准测试。

Result: 开源ASR在自发语音中表现良好但在嘈杂非母语对话中退化；多模态LLM对口音更鲁棒但处理领域特定命名实体困难；专有模型在清晰语音中准确度高但随国家和领域变化显著；针对非洲英语微调的模型在延迟较低时达到竞争性准确度。

Conclusion: 通过发布这一全面基准，使从业者和研究人员能够选择适合非洲用例的语音技术，促进服务不足社区的包容性语音应用发展。

Abstract: Recent advances in speech-enabled AI, including Google's NotebookLM and OpenAI's speech-to-speech API, are driving widespread interest in voice interfaces globally. Despite this momentum, there exists no publicly available application-specific model evaluation that caters to Africa's linguistic diversity. We present AfriSpeech-MultiBench, the first domain-specific evaluation suite for over 100 African English accents across 10+ countries and seven application domains: Finance, Legal, Medical, General dialogue, Call Center, Named Entities and Hallucination Robustness. We benchmark a diverse range of open, closed, unimodal ASR and multimodal LLM-based speech recognition systems using both spontaneous and non-spontaneous speech conversation drawn from various open African accented English speech datasets. Our empirical analysis reveals systematic variation: open-source ASR models excels in spontaneous speech contexts but degrades on noisy, non-native dialogue; multimodal LLMs are more accent-robust yet struggle with domain-specific named entities; proprietary models deliver high accuracy on clean speech but vary significantly by country and domain. Models fine-tuned on African English achieve competitive accuracy with lower latency, a practical advantage for deployment, hallucinations still remain a big problem for most SOTA models. By releasing this comprehensive benchmark, we empower practitioners and researchers to select voice technologies suited to African use-cases, fostering inclusive voice applications for underserved communities.

</details>


### [21] [Entropy-Guided Reasoning Compression](https://arxiv.org/abs/2511.14258)
*Hourun Zhu,Yang Gao,Wenlong Fei,Jiawei Li,Huashan Sun*

Main category: cs.CL

TL;DR: 该论文提出了一种熵引导的训练框架来解决大型推理模型在压缩训练过程中出现的熵冲突问题，能够在保持甚至提升准确率的同时将推理长度压缩至原始的20%。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务上表现出色，但其思维链输出过长导致计算成本高和部署困难。现有的压缩方法部分成功但忽视了训练过程中的熵冲突现象——压缩训练减少熵导致推理变短但探索受限，而准确性目标增加熵导致推理链变长，使模型陷入局部困境。

Method: 采用熵引导的训练框架：当熵下降时，引导模型进行简洁的思维步骤；当熵上升时，在紧凑推理模式下加强探索以提高鲁棒性。分析发现熵冲突源于高熵的逻辑连接词在性能目标下获得更大梯度而被鼓励，同时压缩目标又惩罚这些可能冗余的连接词。

Result: 在六个数学基准测试上的实验表明，该方法将推理长度压缩至原始的20%，同时保持甚至超过了基线准确率。

Conclusion: 熵引导的训练框架有效解决了推理模型压缩中的熵冲突问题，实现了推理长度的大幅压缩而不损失性能，为实际部署提供了可行的解决方案。

Abstract: Large reasoning models have demonstrated remarkable performance on complex reasoning tasks, yet the excessive length of their chain-of-thought outputs remains a major practical bottleneck due to high computation cost and poor deployability. Existing compression methods have achieved partial success but overlook a crucial phenomenon in the training process -- the entropy conflict. During compression training, entropy decreases, leading to shorter reasoning but limited exploration, while accuracy-oriented objectives increase entropy, lengthening reasoning chains. This can cause the model to get stuck in a local dilemma. Our analysis further reveals the origin of the entropy conflict: many high-entropy tokens are logical connectors that receive larger gradients and are encouraged under the performance objective, while the compression objective simultaneously penalizes these potentially redundant connectors. This opposing pressure creates a direct source of entropy conflict. To address these issues, we adopt an entropy-guided training framework. As entropy descends, the model is guided toward efficient reasoning by encouraging concise thought steps; as entropy rises, exploration is reinforced under the compact reasoning mode to improve robustness. Experiments on six mathematical benchmarks show that our method compresses reasoning length to 20% of the original while maintaining or even surpassing baseline accuracy. Code and models will be released publicly.

</details>


### [22] [Don't Miss the Forest for the Trees: In-Depth Confidence Estimation for LLMs via Reasoning over the Answer Space](https://arxiv.org/abs/2511.14275)
*Ante Wang,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: 本文提出通过预测语言化概率分布来增强LLM置信度估计的方法，该方法要求模型考虑整个答案空间而非单一猜测，在各种任务和模型中都显示出优势。


<details>
  <summary>Details</summary>
Motivation: 虽然结合思维链推理可以提升语言化置信度估计的透明性，但推理策略如何影响置信度估计仍未被充分探索。

Method: 通过预测语言化概率分布来鼓励深度推理，要求LLM考虑答案空间中的所有候选答案并仔细分配置信度分数以满足分布要求。

Result: 该方法在不同模型和各种任务中都显示出优势，无论答案空间是否已知，即使在强化学习后优势依然保持，且其推理模式与人类期望一致。

Conclusion: 预测语言化概率分布是一种有效的置信度估计方法，能够促进深度推理并在多种场景下保持稳定优势。

Abstract: Knowing the reliability of a model's response is essential in application. With the strong generation capabilities of LLMs, research has focused on generating verbalized confidence. This is further enhanced by combining chain-of-thought reasoning, which provides logical and transparent estimation. However, how reasoning strategies affect the estimated confidence is still under-explored. In this work, we demonstrate that predicting a verbalized probability distribution can effectively encourage in-depth reasoning for confidence estimation. Intuitively, it requires an LLM to consider all candidates within the answer space instead of basing on a single guess, and to carefully assign confidence scores to meet the requirements of a distribution. This method shows an advantage across different models and various tasks, regardless of whether the answer space is known. Its advantage is maintained even after reinforcement learning, and further analysis shows its reasoning patterns are aligned with human expectations.

</details>


### [23] [AraLingBench A Human-Annotated Benchmark for Evaluating Arabic Linguistic Capabilities of Large Language Models](https://arxiv.org/abs/2511.14295)
*Mohammad Zbib,Hasan Abed Al Kader Hammoud,Sina Mukalled,Nadine Rizk,Fatima Karnib,Issam Lakkis,Ammar Mohanna,Bernard Ghanem*

Main category: cs.CL

TL;DR: AraLingBench是一个全面人工标注的基准测试，用于评估大型语言模型的阿拉伯语语言能力，涵盖语法、形态学、拼写、阅读理解和句法五个核心类别。


<details>
  <summary>Details</summary>
Motivation: 当前阿拉伯语LLMs在知识型基准测试中得分很高，但缺乏真正的语言掌握能力，需要通过专门的基准测试来评估其深层语言理解能力。

Method: 通过150个专家设计的多项选择题，直接评估结构语言理解能力，测试了35个阿拉伯语和双语LLMs。

Result: 当前模型表现出较强的表层熟练度，但在深层语法和句法推理方面存在困难，许多模型通过记忆或模式识别而非真实理解来获得成功。

Conclusion: AraLingBench通过分离和测量基本语言技能，为开发阿拉伯语LLMs提供了诊断框架，揭示了知识型基准测试高分与真正语言掌握之间的持续差距。

Abstract: We present AraLingBench: a fully human annotated benchmark for evaluating the Arabic linguistic competence of large language models (LLMs). The benchmark spans five core categories: grammar, morphology, spelling, reading comprehension, and syntax, through 150 expert-designed multiple choice questions that directly assess structural language understanding. Evaluating 35 Arabic and bilingual LLMs reveals that current models demonstrate strong surface level proficiency but struggle with deeper grammatical and syntactic reasoning. AraLingBench highlights a persistent gap between high scores on knowledge-based benchmarks and true linguistic mastery, showing that many models succeed through memorization or pattern recognition rather than authentic comprehension. By isolating and measuring fundamental linguistic skills, AraLingBench provides a diagnostic framework for developing Arabic LLMs. The full evaluation code is publicly available on GitHub.

</details>


### [24] [ConInstruct: Evaluating Large Language Models on Conflict Detection and Resolution in Instructions](https://arxiv.org/abs/2511.14342)
*Xingwei He,Qianru Zhang,Pengfei Chen,Guanhua Chen,Linlin Yu,Yuan Yuan,Siu-Ming Yiu*

Main category: cs.CL

TL;DR: ConInstruct基准测试评估LLM在用户指令包含冲突约束时的检测与解决能力，发现专有模型检测能力强但很少明确通知用户冲突，开源模型中仅DeepSeek-R1表现优秀。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM遵循用户指令的能力，但忽略了指令包含冲突约束的常见场景，LLM在此类条件下的行为尚未充分探索。

Method: 引入ConInstruct基准测试，专门评估LLM检测和解决用户指令中冲突的能力，通过该数据集评估冲突检测性能并分析冲突解决行为。

Result: 专有LLM冲突检测能力强，开源模型中仅DeepSeek-R1表现类似；DeepSeek-R1和Claude-4.5-Sonnet平均F1分数分别为91.5%和87.3%，排名前二；但LLM很少明确通知用户冲突或请求澄清。

Conclusion: 当前LLM在冲突检测方面存在重要缺陷，很少主动通知用户冲突，这是设计指令遵循型LLM时需要改进的关键领域。

Abstract: Instruction-following is a critical capability of Large Language Models (LLMs). While existing works primarily focus on assessing how well LLMs adhere to user instructions, they often overlook scenarios where instructions contain conflicting constraints-a common occurrence in complex prompts. The behavior of LLMs under such conditions remains under-explored. To bridge this gap, we introduce ConInstruct, a benchmark specifically designed to assess LLMs' ability to detect and resolve conflicts within user instructions. Using this dataset, we evaluate LLMs' conflict detection performance and analyze their conflict resolution behavior. Our experiments reveal two key findings: (1) Most proprietary LLMs exhibit strong conflict detection capabilities, whereas among open-source models, only DeepSeek-R1 demonstrates similarly strong performance. DeepSeek-R1 and Claude-4.5-Sonnet achieve the highest average F1-scores at 91.5% and 87.3%, respectively, ranking first and second overall. (2) Despite their strong conflict detection abilities, LLMs rarely explicitly notify users about the conflicts or request clarification when faced with conflicting constraints. These results underscore a critical shortcoming in current LLMs and highlight an important area for future improvement when designing instruction-following LLMs.

</details>


### [25] [The Tokenization Bottleneck: How Vocabulary Extension Improves Chemistry Representation Learning in Pretrained Language Models](https://arxiv.org/abs/2511.14365)
*Prathamesh Kalamkar,Ned Letcher,Meissane Chami,Sahger Lad,Shayan Mohanty,Prasanna Pendse*

Main category: cs.CL

TL;DR: 本文提出了一种解决大语言模型在化学应用中"分词瓶颈"的方法，通过扩展词汇表加入化学相关标记，并在化学领域文本上继续预训练，实现了自然语言和分子结构的统一表示。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在化学应用中的主要障碍是"分词瓶颈"——基于通用领域文本训练的分词器会将化学表示（如SMILES）分割成语义无意义的子标记，影响模型性能。

Method: 采用目标词汇扩展策略：在预训练大语言模型的词汇表中添加化学显著性标记，然后在化学领域文本上进行继续预训练，以整合新知识。

Result: 经验证明该方法有效，在多个下游化学任务上表现出优越性能。

Conclusion: 通过统一自然语言和分子结构的表示，成功解决了大语言模型在化学应用中的分词瓶颈问题，为化学领域的大语言模型应用提供了有效解决方案。

Abstract: The application of large language models (LLMs) to chemistry is frequently hampered by a "tokenization bottleneck", where tokenizers tuned on general-domain text tend to fragment chemical representations such as SMILES into semantically uninformative sub-tokens. This paper introduces a principled methodology to resolve this bottleneck by unifying the representation of natural language and molecular structures within a single model. Our approach involves targeted vocabulary extension-augmenting a pretrained LLM's vocabulary with chemically salient tokens, followed by continued pretraining on chemistry-domain text to integrate this new knowledge. We provide an empirical demonstration of the effectiveness of this strategy, showing that our methodology leads to superior performance on a range of downstream chemical tasks.

</details>


### [26] [ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning](https://arxiv.org/abs/2511.14366)
*Hongwei Liu,Junnan Liu,Shudong Liu,Haodong Duan,Yuqiang Li,Mao Su,Xiaohong Liu,Guangtao Zhai,Xinyu Fang,Qianhong Ma,Taolin Zhang,Zihan Ma,Yufeng Zhao,Peiheng Zhou,Linchen Xiao,Wenlong Zhang,Shijie Zhou,Xingjian Ma,Siqi Sun,Jiaye Ge,Meng Li,Yuhong Liu,Jianxin Dong,Jiaying Li,Hui Wu,Hanwen Liang,Jintai Lin,Yanting Wang,Jie Dong,Tong Zhu,Tianfan Fu,Conghui He,Qi Zhang,Songyang Zhang,Lei Bai,Kai Chen*

Main category: cs.CL

TL;DR: ATLAS是一个大规模、高难度、跨学科的科学推理评估套件，包含约800个原创问题，旨在解决现有基准测试在区分前沿模型能力方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在性能饱和、学科范围狭窄、答案格式简化、数据污染等问题，无法有效评估模型在真实科学探究中的能力。

Method: 由领域专家开发跨七个科学领域的原创问题，采用多阶段专家评审和对抗测试确保质量，并使用LLM评委小组进行自动化评估。

Result: 初步结果显示ATLAS能有效区分领先模型的先进科学推理能力。

Conclusion: ATLAS将发展成一个长期、开放、社区驱动的平台，为人工通用智能的进展提供可靠评估标准。

Abstract: The rapid advancement of Large Language Models (LLMs) has led to performance saturation on many established benchmarks, questioning their ability to distinguish frontier models. Concurrently, existing high-difficulty benchmarks often suffer from narrow disciplinary focus, oversimplified answer formats, and vulnerability to data contamination, creating a fidelity gap with real-world scientific inquiry. To address these challenges, we introduce ATLAS (AGI-Oriented Testbed for Logical Application in Science), a large-scale, high-difficulty, and cross-disciplinary evaluation suite composed of approximately 800 original problems. Developed by domain experts (PhD-level and above), ATLAS spans seven core scientific fields: mathematics, physics, chemistry, biology, computer science, earth science, and materials science. Its key features include: (1) High Originality and Contamination Resistance, with all questions newly created or substantially adapted to prevent test data leakage; (2) Cross-Disciplinary Focus, designed to assess models' ability to integrate knowledge and reason across scientific domains; (3) High-Fidelity Answers, prioritizing complex, open-ended answers involving multi-step reasoning and LaTeX-formatted expressions over simple multiple-choice questions; and (4) Rigorous Quality Control, employing a multi-stage process of expert peer review and adversarial testing to ensure question difficulty, scientific value, and correctness. We also propose a robust evaluation paradigm using a panel of LLM judges for automated, nuanced assessment of complex answers. Preliminary results on leading models demonstrate ATLAS's effectiveness in differentiating their advanced scientific reasoning capabilities. We plan to develop ATLAS into a long-term, open, community-driven platform to provide a reliable "ruler" for progress toward Artificial General Intelligence.

</details>


### [27] [Mitigating Label Length Bias in Large Language Models](https://arxiv.org/abs/2511.14385)
*Mario Sanz-Guerrero,Katharina von der Wense*

Main category: cs.CL

TL;DR: 提出标准化上下文校准（NCC）方法，解决LLM在多标签预测中的标签长度偏差问题，在多个数据集和模型上显著提升性能，F1得分最高提升10%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在候选选项预测时存在标签偏差，现有校准方法忽视了多标记类标签带来的偏差，特别是标签长度不一致导致的处理不一致问题。

Method: 提出标准化上下文校准（NCC），在完整标签级别进行标准化和校准预测，可扩展到多项选择题等更广泛任务。

Result: NCC在多个数据集和模型上实现统计显著改进，F1得分最高提升10%；与上下文学习结合时，对少样本示例选择更不敏感，需要更少示例达到竞争性能，产生更可靠置信度估计。

Conclusion: 缓解完整标签偏差对于提高基于LLM方法的性能和鲁棒性至关重要，特别是在类标签自然包含多个标记的实际应用中。

Abstract: Large language models (LLMs) are powerful zero- and few-shot learners. However, when predicting over a set of candidate options, LLMs suffer from label biases, and existing calibration methods overlook biases arising from multi-token class labels. We tackle an issue we call label length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we propose normalized contextual calibration (NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10% F1. Moreover, NCC extends bias mitigation to broader tasks such as multiple-choice question answering. Our analysis shows that, when combined with in-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples for competitive performance, and produces more reliable confidence estimates. These findings highlight the importance of mitigating full-label biases to improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens.

</details>


### [28] [Unified Defense for Large Language Models against Jailbreak and Fine-Tuning Attacks in Education](https://arxiv.org/abs/2511.14423)
*Xin Yi,Yue Li,Dongsheng Shi,Linlin Wang,Xiaoling Wang,Liang He*

Main category: cs.CL

TL;DR: 提出了EduHarm基准和TSSF框架，用于评估和防御教育场景下LLM的越狱和微调攻击，在保持良性查询效用的同时增强安全性。


<details>
  <summary>Details</summary>
Motivation: LLM在教育应用中面临越狱和微调攻击的安全风险，现有研究缺乏针对教育场景独特安全需求的评估方法。

Method: 构建EduHarm基准，提出三阶段防护框架：安全感知注意力重对齐、分层安全判断、防御驱动双路由。

Result: 在8种越狱攻击策略和3个微调攻击数据集上的实验表明，TSSF能有效增强安全性，同时避免对良性查询的过度拒绝。

Conclusion: TSSF框架为教育LLM提供了同时防御越狱和微调攻击的有效解决方案，在安全性和实用性之间取得了良好平衡。

Abstract: Large Language Models (LLMs) are increasingly integrated into educational applications. However, they remain vulnerable to jailbreak and fine-tuning attacks, which can compromise safety alignment and lead to harmful outputs. Existing studies mainly focus on general safety evaluations, with limited attention to the unique safety requirements of educational scenarios. To address this gap, we construct EduHarm, a benchmark containing safe-unsafe instruction pairs across five representative educational scenarios, enabling systematic safety evaluation of educational LLMs. Furthermore, we propose a three-stage shield framework (TSSF) for educational LLMs that simultaneously mitigates both jailbreak and fine-tuning attacks. First, safety-aware attention realignment redirects attention toward critical unsafe tokens, thereby restoring the harmfulness feature that discriminates between unsafe and safe inputs. Second, layer-wise safety judgment identifies harmfulness features by aggregating safety cues across multiple layers to detect unsafe instructions. Finally, defense-driven dual routing separates safe and unsafe queries, ensuring normal processing for benign inputs and guarded responses for harmful ones. Extensive experiments across eight jailbreak attack strategies demonstrate that TSSF effectively strengthens safety while preventing over-refusal of benign queries. Evaluations on three fine-tuning attack datasets further show that it consistently achieves robust defense against harmful queries while maintaining preserving utility gains from benign fine-tuning.

</details>


### [29] [MedBench v4: A Robust and Scalable Benchmark for Evaluating Chinese Medical Language Models, Multimodal Models, and Intelligent Agents](https://arxiv.org/abs/2511.14439)
*Jinru Ding,Lu Lu,Chao Ding,Mouxiao Bian,Jiayuan Chen,Renjie Lu,Wenrao Pang,Xiaoqin Wu,Zhiqiang Liu,Luyi Jiang,Bing Han,Yunqiu Wang,Jie Xu*

Main category: cs.CL

TL;DR: MedBench v4是一个全国性的医疗AI基准测试平台，包含70多万个专家策划的任务，涵盖24个主要和91个次要专科，评估了15个前沿模型。结果显示基础LLM平均得分54.1/100，多模态模型表现更差（47.5/100），而基于相同骨干的智能体显著提升性能至79.8/100。


<details>
  <summary>Details</summary>
Motivation: 随着医疗大语言模型、多模态模型和智能体的发展，需要能够反映真实临床工作流程和安全约束的评估框架。

Method: 构建了一个基于云的基准测试基础设施，包含70多万个经过多阶段精炼和多轮临床医生评审的任务，使用LLM作为评判者来评分开放式回答。

Result: 基础LLM平均得分54.1/100（最佳：Claude Sonnet 4.5，62.5/100），但安全和伦理得分较低（18.4/100）。多模态模型整体表现更差（平均47.5/100；最佳：GPT-5，54.9/100）。基于相同骨干的智能体显著提升端到端性能至79.8/100。

Conclusion: MedBench v4揭示了基础模型在多模态推理和安全方面存在持续差距，但治理意识的智能体编排可以显著提高临床准备度而不牺牲能力，为医院、开发者和政策制定者提供了实用的医疗AI审计参考。

Abstract: Recent advances in medical large language models (LLMs), multimodal models, and agents demand evaluation frameworks that reflect real clinical workflows and safety constraints. We present MedBench v4, a nationwide, cloud-based benchmarking infrastructure comprising over 700,000 expert-curated tasks spanning 24 primary and 91 secondary specialties, with dedicated tracks for LLMs, multimodal models, and agents. Items undergo multi-stage refinement and multi-round review by clinicians from more than 500 institutions, and open-ended responses are scored by an LLM-as-a-judge calibrated to human ratings. We evaluate 15 frontier models. Base LLMs reach a mean overall score of 54.1/100 (best: Claude Sonnet 4.5, 62.5/100), but safety and ethics remain low (18.4/100). Multimodal models perform worse overall (mean 47.5/100; best: GPT-5, 54.9/100), with solid perception yet weaker cross-modal reasoning. Agents built on the same backbones substantially improve end-to-end performance (mean 79.8/100), with Claude Sonnet 4.5-based agents achieving up to 85.3/100 overall and 88.9/100 on safety tasks. MedBench v4 thus reveals persisting gaps in multimodal reasoning and safety for base models, while showing that governance-aware agentic orchestration can markedly enhance benchmarked clinical readiness without sacrificing capability. By aligning tasks with Chinese clinical guidelines and regulatory priorities, the platform offers a practical reference for hospitals, developers, and policymakers auditing medical AI.

</details>


### [30] [Tell Me: An LLM-powered Mental Well-being Assistant with RAG, Synthetic Dialogue Generation, and Agentic Planning](https://arxiv.org/abs/2511.14445)
*Trishala Jayesh Ahalpara*

Main category: cs.CL

TL;DR: Tell Me是一个基于大语言模型的心理健康系统，包含个性化对话助手、合成治疗对话生成器和AI健康管理团队，旨在提供可访问的心理支持而非替代专业治疗。


<details>
  <summary>Details</summary>
Motivation: 解决心理健康资源获取障碍和治疗数据稀缺问题，通过AI技术降低支持门槛，补充现有护理资源。

Method: 系统集成三个组件：检索增强生成(RAG)助手提供个性化对话；合成客户-治疗师对话生成器基于客户档案生成数据；Well-being AI团队使用CrewAI生成周度自我护理计划和冥想音频。

Result: 在精心设计的健康场景中评估RAG助手，使用自动LLM判断和人类用户研究进行验证。

Conclusion: 这项工作展示了NLP研究者与心理健康专业人士跨学科合作的机会，推动人机交互在健康领域的负责任创新。

Abstract: We present Tell Me, a mental well-being system that leverages advances in large language models to provide accessible, context-aware support for users and researchers. The system integrates three components: (i) a retrieval-augmented generation (RAG) assistant for personalized, knowledge-grounded dialogue; (ii) a synthetic client-therapist dialogue generator conditioned on client profiles to facilitate research on therapeutic language and data augmentation; and (iii) a Well-being AI crew, implemented with CrewAI, that produces weekly self-care plans and guided meditation audio. The system is designed as a reflective space for emotional processing rather than a substitute for professional therapy. It illustrates how conversational assistants can lower barriers to support, complement existing care, and broaden access to mental health resources. To address the shortage of confidential therapeutic data, we introduce synthetic client-therapist dialogue generation conditioned on client profiles. Finally, the planner demonstrates an innovative agentic workflow for dynamically adaptive, personalized self-care, bridging the limitations of static well-being tools. We describe the architecture, demonstrate its functionalities, and report evaluation of the RAG assistant in curated well-being scenarios using both automatic LLM-based judgments and a human-user study. This work highlights opportunities for interdisciplinary collaboration between NLP researchers and mental health professionals to advance responsible innovation in human-AI interaction for well-being.

</details>


### [31] [Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning](https://arxiv.org/abs/2511.14460)
*Mingyue Cheng,Jie Ouyang,Shuo Yu,Ruiran Yan,Yucong Luo,Zirui Liu,Daoyu Wang,Qi Liu,Enhong Chen*

Main category: cs.CL

TL;DR: 本文提出了一个针对LLM智能体的强化学习框架Agent-R1，通过扩展MDP框架来定义LLM智能体的关键组件，并在多跳问答任务上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在强化学习训练方面缺乏专门的方法论和灵活可扩展的训练框架，阻碍了该领域的发展。

Method: 系统性地扩展马尔可夫决策过程(MDP)框架来定义LLM智能体的关键组件，并开发了模块化、灵活且用户友好的Agent-R1训练框架。

Result: 在多跳问答基准任务上的实验初步验证了所提方法和框架的有效性。

Conclusion: Agent-R1框架为LLM智能体的强化学习训练提供了一个实用且可扩展的解决方案，有助于推动该领域的发展。

Abstract: Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems. Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges. Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose. To help advance this area, this paper first revisits and clarifies Reinforcement Learning methodologies for LLM Agents by systematically extending the Markov Decision Process (MDP) framework to comprehensively define the key components of an LLM Agent. Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments. We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.

</details>


### [32] [Examining the Metrics for Document-Level Claim Extraction in Czech and Slovak](https://arxiv.org/abs/2511.14566)
*Lucia Makaiová,Martin Fajčík,Antonín Jarolím*

Main category: cs.CL

TL;DR: 本文探讨了文档级声明提取的评估方法，通过声明对齐和相似度计算来比较模型提取和人工标注的声明集，并在捷克和斯洛伐克新闻评论数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 文档级声明提取在事实核查领域仍是一个开放挑战，现有的评估方法关注有限，需要可靠的评估框架来比较模型提取和人工标注的声明集。

Method: 研究声明对齐技术，通过最佳对齐和评估方法来计算两个声明集之间的相似度，作为模型提取性能的评估指标和标注者间一致性的度量。

Result: 在捷克和斯洛伐克新闻评论数据集上的实验揭示了当前评估方法在文档级声明提取中的局限性，需要能够正确捕捉语义相似度和评估声明关键属性的更先进方法。

Conclusion: 当前评估方法在文档级声明提取中存在不足，需要开发能够更好处理语义相似度、原子性、可核查性和去上下文化的更先进评估方法。

Abstract: Document-level claim extraction remains an open challenge in the field of fact-checking, and subsequently, methods for evaluating extracted claims have received limited attention. In this work, we explore approaches to aligning two sets of claims pertaining to the same source document and computing their similarity through an alignment score. We investigate techniques to identify the best possible alignment and evaluation method between claim sets, with the aim of providing a reliable evaluation framework. Our approach enables comparison between model-extracted and human-annotated claim sets, serving as a metric for assessing the extraction performance of models and also as a possible measure of inter-annotator agreement. We conduct experiments on newly collected dataset-claims extracted from comments under Czech and Slovak news articles-domains that pose additional challenges due to the informal language, strong local context, and subtleties of these closely related languages. The results draw attention to the limitations of current evaluation approaches when applied to document-level claim extraction and highlight the need for more advanced methods-ones able to correctly capture semantic similarity and evaluate essential claim properties such as atomicity, checkworthiness, and decontextualization.

</details>


### [33] [Leveraging Digitized Newspapers to Collect Summarization Data in Low-Resource Languages](https://arxiv.org/abs/2511.14598)
*Noam Dahan,Omer Kidron,Gabriel Stanovsky*

Main category: cs.CL

TL;DR: 利用历史报纸的首页预告作为自然生成的摘要数据，开发了跨七种语言的自动数据收集方法，并创建了希伯来语首个多文档摘要数据集HEBTEASESUM。


<details>
  <summary>Details</summary>
Motivation: 在代表性不足的语言中，高质量的摘要数据稀缺，而数字化历史报纸提供了大量未开发的自然标注数据源。

Method: 通过首页预告收集自然生成的摘要，开发了适用于不同语言资源水平的自动数据收集流程。

Result: 该方法在七种不同语言中普遍适用，支持多文档摘要，并成功应用于希伯来语报纸，创建了HEBTEASESUM数据集。

Conclusion: 历史报纸的首页预告是获取多语言摘要数据的有效来源，该方法可扩展至资源匮乏的语言。

Abstract: High quality summarization data remains scarce in under-represented languages. However, historical newspapers, made available through recent digitization efforts, offer an abundant source of untapped, naturally annotated data. In this work, we present a novel method for collecting naturally occurring summaries via Front-Page Teasers, where editors summarize full length articles. We show that this phenomenon is common across seven diverse languages and supports multi-document summarization. To scale data collection, we develop an automatic process, suited to varying linguistic resource levels. Finally, we apply this process to a Hebrew newspaper title, producing HEBTEASESUM, the first dedicated multi-document summarization dataset in Hebrew.

</details>


### [34] [A Method for Characterizing Disease Progression from Acute Kidney Injury to Chronic Kidney Disease](https://arxiv.org/abs/2511.14603)
*Yilu Fang,Jordan G. Nestor,Casey N. Ta,Jerard Z. Kneifati-Hayek,Chunhua Weng*

Main category: cs.CL

TL;DR: 本研究利用电子健康记录数据，通过聚类分析识别了15种不同的急性肾损伤后临床状态，并使用多状态模型估计了向慢性肾病进展的转移概率，发现17%的AKI患者发展为CKD，并识别了不同临床状态下的风险因素。


<details>
  <summary>Details</summary>
Motivation: 急性肾损伤患者发展为慢性肾病的风险很高，但识别高风险患者仍然具有挑战性，需要开发数据驱动的方法来动态跟踪AKI患者的临床演变。

Method: 使用电子健康记录数据，通过纵向医疗代码和肌酐测量值生成患者向量，进行聚类分析识别AKI后临床状态，采用多状态模型估计状态间转移概率和CKD进展风险。

Result: 在20,699名入院时患有AKI的患者中，3,491名（17%）发展为CKD；识别出15种不同的AKI后状态，每种状态具有不同的CKD发展概率；75%的患者在研究期间保持单一状态或仅发生一次转移。

Conclusion: 该研究展示了一种数据驱动的方法来识别高风险AKI患者，支持开发用于早期CKD检测和干预的决策支持工具，发现了已知和新型CKD风险因素在不同临床状态中的影响差异。

Abstract: Patients with acute kidney injury (AKI) are at high risk of developing chronic kidney disease (CKD), but identifying those at greatest risk remains challenging. We used electronic health record (EHR) data to dynamically track AKI patients' clinical evolution and characterize AKI-to-CKD progression. Post-AKI clinical states were identified by clustering patient vectors derived from longitudinal medical codes and creatinine measurements. Transition probabilities between states and progression to CKD were estimated using multi-state modeling. After identifying common post-AKI trajectories, CKD risk factors in AKI subpopulations were identified through survival analysis. Of 20,699 patients with AKI at admission, 3,491 (17%) developed CKD. We identified fifteen distinct post-AKI states, each with different probabilities of CKD development. Most patients (75%, n=15,607) remained in a single state or made only one transition during the study period. Both established (e.g., AKI severity, diabetes, hypertension, heart failure, liver disease) and novel CKD risk factors, with their impact varying across these clinical states. This study demonstrates a data-driven approach for identifying high-risk AKI patients, supporting the development of decision-support tools for early CKD detection and intervention.

</details>


### [35] [Bridging Human and Model Perspectives: A Comparative Analysis of Political Bias Detection in News Media Using Large Language Models](https://arxiv.org/abs/2511.14606)
*Shreya Adrita Banik,Niaz Nafi Rahman,Tahsina Moiukh,Farig Sadeque*

Main category: cs.CL

TL;DR: 本研究比较了人类标注与多种大语言模型在政治偏见检测中的表现，发现RoBERTa在传统Transformer模型中与人类标注最一致，GPT在零样本设置下表现最佳，揭示了人类与LLM在偏见感知上的系统性差异。


<details>
  <summary>Details</summary>
Motivation: 尽管NLP技术已能自动分类政治偏见，但大语言模型与人类判断的一致性程度仍未被充分探索和理解，需要系统评估人类与模型在偏见感知上的差异。

Method: 构建手动标注的新闻文章数据集，评估标注一致性、偏见极性和模型间一致性，比较GPT、BERT、RoBERTa和FLAN等多种LLM与人类标注的差异。

Result: 实验结果显示，传统Transformer模型中RoBERTa与人类标签对齐度最高，生成模型GPT在零样本设置下与人类标注的总体一致性最强，微调后的RoBERTa模型在所有基线中获得了最高准确率和最强的人类标注对齐度。

Conclusion: 人类与LLM在政治偏见感知上存在系统性差异，需要结合人类可解释性和模型可扩展性的混合评估框架来自动化媒体偏见检测。

Abstract: Detecting political bias in news media is a complex task that requires interpreting subtle linguistic and contextual cues. Although recent advances in Natural Language Processing (NLP) have enabled automatic bias classification, the extent to which large language models (LLMs) align with human judgment still remains relatively underexplored and not yet well understood. This study aims to present a comparative framework for evaluating the detection of political bias across human annotations and multiple LLMs, including GPT, BERT, RoBERTa, and FLAN. We construct a manually annotated dataset of news articles and assess annotation consistency, bias polarity, and inter-model agreement to quantify divergence between human and model perceptions of bias. Experimental results show that among traditional transformer-based models, RoBERTa achieves the highest alignment with human labels, whereas generative models such as GPT demonstrate the strongest overall agreement with human annotations in a zero-shot setting. Among all transformer-based baselines, our fine-tuned RoBERTa model acquired the highest accuracy and the strongest alignment with human-annotated labels. Our findings highlight systematic differences in how humans and LLMs perceive political slant, underscoring the need for hybrid evaluation frameworks that combine human interpretability with model scalability in automated media bias detection.

</details>


### [36] [Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities](https://arxiv.org/abs/2511.14631)
*Kahaan Gandhi,Boris Bolliet,Inigo Zubeldia*

Main category: cs.CL

TL;DR: VLM指导的多智能体系统通过将图表作为可验证检查点，显著提升了端到端自主科学发现能力，在10项任务基准测试中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统自主科学发现系统缺乏实时错误纠正和适应性，需要开发能够自我修正并适应新数据集的智能系统。

Method: 使用视觉语言模型作为评判者，基于动态生成的领域特定评分标准评估图表，使智能体能够实时纠正错误并引导探索性数据分析。

Result: 在宇宙学和天体化学案例研究中，系统能够从错误推理路径中恢复并适应新数据集；在10项任务基准测试中，VLM增强系统达到0.7-0.8的pass@1分数，显著优于代码基线(0.2-0.3)和代码+文本基线(0.4-0.5)。

Conclusion: VLM指导的多智能体系统为自主科学发现提供了有效框架，不仅性能优越，还提供了可审计的推理轨迹以提高可解释性。

Abstract: We show that multi-agent systems guided by vision-language models (VLMs) improve end-to-end autonomous scientific discovery. By treating plots as verifiable checkpoints, a VLM-as-a-judge evaluates figures against dynamically generated domain-specific rubrics, enabling agents to correct their own errors and steer exploratory data analysis in real-time. Case studies in cosmology and astrochemistry demonstrate recovery from faulty reasoning paths and adaptation to new datasets without human intervention. On a 10-task benchmark for data-driven discovery, VLM-augmented systems achieve pass at 1 scores of 0.7-0.8, compared to 0.2-0.3 for code-only and 0.4-0.5 for code-and-text baselines, while also providing auditable reasoning traces that improve interpretability. Code available here: https://github.com/CMBAgents/cmbagent

</details>


### [37] [A Specialized Large Language Model for Clinical Reasoning and Diagnosis in Rare Diseases](https://arxiv.org/abs/2511.14638)
*Tao Yang,Dandan Huang,Yunting Lin,Pengfei Wu,Zhikun Wu,Gangyuan Ma,Yulan Lu,Xinran Dong,Dingpeng Li,Junshuang Ge,Zhiyan Zhang,Xuanzhao Huang,Wenyan Nong,Yao Zhou,Hui Tang,Hongxi Yang,Shijie Zhang,Juan Li,Xiaojun Cao,Lin Yang,Xia Gao,Kaishou Xu,Xiaoqiong Gu,Wen Zhang,Huimin Xia,Li Liu,Wenhao Zhou,Mulin Jun Li*

Main category: cs.CL

TL;DR: RareSeek R1是一个专门针对罕见病诊断的AI系统，通过领域专业临床语料库、指令调优和基于图的检索，在电子健康记录分析中达到与经验医生相当的性能，显著缩短诊断时间。


<details>
  <summary>Details</summary>
Motivation: 罕见病影响全球数亿人，但诊断通常需要数年时间。传统方法将证据提取与诊断推理分离，通用/医学大语言模型面临真实世界电子健康记录稀缺、领域知识陈旧和幻觉问题。

Method: 构建大型领域专业临床语料库和临床医生验证的推理集，通过分阶段指令调优、思维链学习和基于图的检索开发RareSeek R1系统。

Result: 在多中心电子健康记录叙述和公共基准测试中，RareSeek R1达到最先进的准确性、稳健的泛化能力，以及在噪声或重叠表型下的稳定性。增强检索在叙述与优先变异配对时效果最佳。人类研究显示其性能与经验医生相当。

Conclusion: 这项工作推进了以叙述为先、知识整合的推理范式，缩短诊断历程，并提供可审计、临床可转化的决策支持，透明推理突出了支撑正确诊断的关键非表型证据。

Abstract: Rare diseases affect hundreds of millions worldwide, yet diagnosis often spans years. Convectional pipelines decouple noisy evidence extraction from downstream inferential diagnosis, and general/medical large language models (LLMs) face scarce real world electronic health records (EHRs), stale domain knowledge, and hallucinations. We assemble a large, domain specialized clinical corpus and a clinician validated reasoning set, and develop RareSeek R1 via staged instruction tuning, chain of thought learning, and graph grounded retrieval. Across multicenter EHR narratives and public benchmarks, RareSeek R1 attains state of the art accuracy, robust generalization, and stability under noisy or overlapping phenotypes. Augmented retrieval yields the largest gains when narratives pair with prioritized variants by resolving ambiguity and aligning candidates to mechanisms. Human studies show performance on par with experienced physicians and consistent gains in assistive use. Notably, transparent reasoning highlights decisive non phenotypic evidence (median 23.1%, such as imaging, interventions, functional tests) underpinning many correct diagnoses. This work advances a narrative first, knowledge integrated reasoning paradigm that shortens the diagnostic odyssey and enables auditable, clinically translatable decision support.

</details>


### [38] [Graded strength of comparative illusions is explained by Bayesian inference](https://arxiv.org/abs/2511.14642)
*Yuhan Zhang,Erxiao Wang,Cory Shain*

Main category: cs.CL

TL;DR: 该研究通过定量模型验证了语言处理中的比较错觉现象可以用贝叶斯推理和噪声通道理论来解释，模型成功预测了错觉强度的细微差异和代词与名词短语主语的影响。


<details>
  <summary>Details</summary>
Motivation: 先前研究发现语言处理中存在比较错觉现象，但缺乏对错觉强度细微差异和特定语法结构影响的定量解释。本研究旨在通过噪声通道理论为这一现象提供更精确的计算模型。

Method: 开发了一个结合统计语言模型和人类行为数据的定量模型，计算不同解释的后验概率，直接预测比较错觉的强度。

Result: 模型不仅解释了比较错觉强度的细微差异，还解释了代词与完整名词短语作为than从句主语时产生的先前未解释的效应。

Conclusion: 研究结果支持噪声通道理论作为语言处理的统一计算理论，该理论能够解释包括错觉和非错觉在内的多种语言处理现象。

Abstract: Like visual processing, language processing is susceptible to illusions in which people systematically misperceive stimuli. In one such case--the comparative illusion (CI), e.g., More students have been to Russia than I have--comprehenders tend to judge the sentence as acceptable despite its underlying nonsensical comparison. Prior research has argued that this phenomenon can be explained as Bayesian inference over a noisy channel: the posterior probability of an interpretation of a sentence is proportional to both the prior probability of that interpretation and the likelihood of corruption into the observed (CI) sentence. Initial behavioral work has supported this claim by evaluating a narrow set of alternative interpretations of CI sentences and showing that comprehenders favor interpretations that are more likely to have been corrupted into the illusory sentence. In this study, we replicate and go substantially beyond this earlier work by directly predicting the strength of illusion with a quantitative model of the posterior probability of plausible interpretations, which we derive through a novel synthesis of statistical language models with human behavioral data. Our model explains not only the fine gradations in the strength of CI effects, but also a previously unexplained effect caused by pronominal vs. full noun phrase than-clause subjects. These findings support a noisy-channel theory of sentence comprehension by demonstrating that the theory makes novel predictions about the comparative illusion that bear out empirically. This outcome joins related evidence of noisy channel processing in both illusory and non-illusory contexts to support noisy channel inference as a unified computational-level theory of diverse language processing phenomena.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [39] [TaoSearchEmb: A Multi-Objective Reinforcement Learning Framework for Dense Retrieval in Taobao Search](https://arxiv.org/abs/2511.13885)
*Xingxian Liu,Dongshuai Li,Tao Wen,Jiahui Wan,Gui Ling,Fuyu Lv,Dan Ou,Haihong Tang*

Main category: cs.IR

TL;DR: 提出Retrieval-GRPO框架，使用强化学习替代传统硬负样本构建，通过LLM奖励模型和多目标优化解决电商搜索中的语义检索问题。


<details>
  <summary>Details</summary>
Motivation: 传统BERT架构的密集检索方法依赖复杂的离线硬负样本构建流程，限制了模型迭代效率和语义表示能力的进化潜力，同时多任务学习存在跷跷板效应。

Method: 使用强化学习动态检索Top-K候选商品，引入相关性LLM作为奖励模型生成实时反馈，结合相关性分数、商品质量分数和多路排他性指标进行多目标优化。

Result: 消除了对硬负样本的依赖，缓解了跷跷板效应，显著提升了复杂长尾查询的语义泛化能力，已在中国最大电商平台部署。

Conclusion: Retrieval-GRPO框架通过强化学习和多目标优化有效解决了传统密集检索方法的局限性，实现了更高效的语义检索性能。

Abstract: Dense retrieval, as the core component of e-commerce search engines, maps user queries and items into a unified semantic space through pre-trained embedding models to enable large-scale real-time semantic retrieval. Despite the rapid advancement of LLMs gradually replacing traditional BERT architectures for embedding, their training paradigms still adhere to BERT-like supervised fine-tuning and hard negative mining strategies. This approach relies on complex offline hard negative sample construction pipelines, which constrain model iteration efficiency and hinder the evolutionary potential of semantic representation capabilities. Besides, existing multi-task learning frameworks face the seesaw effect when simultaneously optimizing semantic relevance and non-relevance objectives. In this paper, we propose Retrieval-GRPO, a multi-objective reinforcement learning-based dense retrieval framework designed to address these challenges. The method eliminates offline hard negative sample construction by dynamically retrieving Top-K candidate products for each query during training, while introducing a relevance LLM as a reward model to generate real-time feedback. Specifically, the retrieval model dynamically optimizes embedding representations through reinforcement learning, with reward signals combining LLM-generated relevance scores, product quality scores, and multi-way exclusivity metrics to achieve multi-objective user preference alignment and real-time error correction. This mechanism not only removes dependency on hard negatives but also mitigates the seesaw effect through collaborative multi-objective optimization, significantly enhancing the model's semantic generalization capability for complex long-tail queries. Extensive offline and online experiments validate the effectiveness of Retrieval-GRPO, which has been deployed on China's largest e-commerce platform.

</details>


### [40] [NeuroPath: Neurobiology-Inspired Path Tracking and Reflection for Semantically Coherent Retrieval](https://arxiv.org/abs/2511.14096)
*Junchen Li,Rongzheng Wang,Yihong Huang,Qizhi Chen,Jiasheng Zhang,Shuang Liang*

Main category: cs.IR

TL;DR: NeuroPath是一个基于神经生物学启发的语义路径追踪RAG框架，通过动态路径追踪和后检索补全，显著提升了多跳问答性能，在三个数据集上平均召回率提升16.3%，同时减少22.8%的token消耗。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法在多跳问答中难以捕捉文档间的复杂依赖关系，而现有的图基RAG方法在节点匹配和子图构建过程中会损失语义连贯性并引入无关噪声。

Method: NeuroPath框架包含两个步骤：1) 动态路径追踪 - 在构建的知识图上进行目标导向的语义路径追踪和剪枝；2) 后检索补全 - 使用中间推理和原始查询进行第二阶段检索，完善查询目标并补全推理路径中的缺失信息。

Result: 在三个多跳问答数据集上，NeuroPath超越了现有最先进的基线方法，在召回率@2和召回率@5上分别平均提升了16.3%和13.5%。相比现有的迭代式RAG方法，NeuroPath实现了更高的准确率，同时减少了22.8%的token消耗。

Conclusion: NeuroPath通过模拟神经生物学中的路径导航规划，有效解决了图基RAG中的语义连贯性损失和噪声问题，在多跳问答任务中表现出卓越的性能和鲁棒性，并在不同复杂度的任务中展现出良好的可扩展性。

Abstract: Retrieval-augmented generation (RAG) greatly enhances large language models (LLMs) performance in knowledge-intensive tasks. However, naive RAG methods struggle with multi-hop question answering due to their limited capacity to capture complex dependencies across documents. Recent studies employ graph-based RAG to capture document connections. However, these approaches often result in a loss of semantic coherence and introduce irrelevant noise during node matching and subgraph construction. To address these limitations, we propose NeuroPath, an LLM-driven semantic path tracking RAG framework inspired by the path navigational planning of place cells in neurobiology. It consists of two steps: Dynamic Path Tracking and Post-retrieval Completion. Dynamic Path Tracking performs goal-directed semantic path tracking and pruning over the constructed knowledge graph (KG), improving noise reduction and semantic coherence. Post-retrieval Completion further reinforces these benefits by conducting second-stage retrieval using intermediate reasoning and the original query to refine the query goal and complete missing information in the reasoning path. NeuroPath surpasses current state-of-the-art baselines on three multi-hop QA datasets, achieving average improvements of 16.3% on recall@2 and 13.5% on recall@5 over advanced graph-based RAG methods. Moreover, compared to existing iter-based RAG methods, NeuroPath achieves higher accuracy and reduces token consumption by 22.8%. Finally, we demonstrate the robustness of NeuroPath across four smaller LLMs (Llama3.1, GLM4, Mistral0.3, and Gemma3), and further validate its scalability across tasks of varying complexity. Code is available at https://github.com/KennyCaty/NeuroPath.

</details>


### [41] [WebRec: Enhancing LLM-based Recommendations with Attention-guided RAG from Web](https://arxiv.org/abs/2511.14182)
*Zihuai Zhao,Yujuan Ding,Wenqi Fan,Qing Li*

Main category: cs.IR

TL;DR: WebRec是一个基于网络检索增强生成(RAG)的推荐系统框架，利用大语言模型的推理能力将推荐任务转化为适合网络检索的用户偏好查询，并通过MP-Head机制处理网络检索中的噪声信息。


<details>
  <summary>Details</summary>
Motivation: 现有基于RAG的推荐系统未能充分利用网络这一丰富的最新信息来源，面临两个主要挑战：如何为网络检索生成有效查询，以及如何处理包含大量噪声内容的在线网站。

Method: 提出WebRec框架：1) 利用LLM的推理能力将推荐任务解释为用户偏好查询；2) 设计MP-Head机制，通过消息传递增强LLM对分散相关信息的注意力。

Result: 通过大量实验验证了所提出的基于网络的RAG方法在推荐场景中的有效性。

Conclusion: WebRec框架成功解决了网络检索在推荐系统中的挑战，通过创新的查询生成和噪声处理机制，有效提升了推荐系统的性能。

Abstract: Recommender systems play a vital role in alleviating information overload and enriching users' online experience. In the era of large language models (LLMs), LLM-based recommender systems have emerged as a prevalent paradigm for advancing personalized recommendations. Recently, retrieval-augmented generation (RAG) has drawn growing interest to facilitate the recommendation capability of LLMs, incorporating useful information retrieved from external knowledge bases. However, as a rich source of up-to-date information, the web remains under-explored by existing RAG-based recommendations. In particular, unique challenges are posed from two perspectives: one is to generate effective queries for web retrieval, considering the inherent knowledge gap between web search and recommendations; another challenge lies in harnessing online websites that contain substantial noisy content. To tackle these limitations, we propose WebRec, a novel web-based RAG framework, which takes advantage of the reasoning capability of LLMs to interpret recommendation tasks into queries of user preferences that cater to web retrieval. Moreover, given noisy web-retrieved information, where relevant pieces of evidence are scattered far apart, an insightful MP-Head is designed to enhance LLM attentions between distant tokens of relevant information via message passing. Extensive experiments have been conducted to demonstrate the effectiveness of our proposed web-based RAG methods in recommendation scenarios.

</details>


### [42] [LLM-Aligned Geographic Item Tokenization for Local-Life Recommendation](https://arxiv.org/abs/2511.14221)
*Hao Jiang,Guoquan Wang,Donglin Zhou,Sheng Yu,Yang Zeng,Wencong Zeng,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: LGSID是一个用于本地生活推荐的LLM对齐地理项目标记化框架，通过强化学习对齐和分层地理标记化，解决了传统文本推荐方法在空间特征和距离感知方面的不足。


<details>
  <summary>Details</summary>
Motivation: 在本地生活服务等特定领域任务中，简单地将位置信息注入提示无法捕捉细粒度空间特征和项目间的真实距离感知。

Method: 框架包含两个关键组件：(1) 基于强化学习的地理LLM对齐，使用列表式奖励模型捕获项目间的真实空间关系，并引入G-DPO算法；(2) 分层地理项目标记化，主要标记来自离散空间和内容属性，残差标记使用对齐LLM的地理表示向量进行细化。

Result: 在快手行业数据集上的实验表明，LGSID持续优于最先进的判别式和生成式推荐模型。消融研究、可视化和案例研究进一步验证了其有效性。

Conclusion: LGSID框架成功地将地理空间知识注入LLM，提升了本地生活推荐中空间特征和距离感知的能力，在真实数据集上表现出优越性能。

Abstract: Recent advances in Large Language Models (LLMs) have enhanced text-based recommendation by enriching traditional ID-based methods with semantic generalization capabilities. Text-based methods typically encode item textual information via prompt design and generate discrete semantic IDs through item tokenization. However, in domain-specific tasks such as local-life services, simply injecting location information into prompts fails to capture fine-grained spatial characteristics and real-world distance awareness among items. To address this, we propose LGSID, an LLM-Aligned Geographic Item Tokenization Framework for Local-life Recommendation. This framework consists of two key components: (1) RL-based Geographic LLM Alignment, and (2) Hierarchical Geographic Item Tokenization. In the RL-based alignment module, we initially train a list-wise reward model to capture real-world spatial relationships among items. We then introduce a novel G-DPO algorithm that uses pre-trained reward model to inject generalized spatial knowledge and collaborative signals into LLMs while preserving their semantic understanding. Furthermore, we propose a hierarchical geographic item tokenization strategy, where primary tokens are derived from discrete spatial and content attributes, and residual tokens are refined using the aligned LLM's geographic representation vectors. Extensive experiments on real-world Kuaishou industry datasets show that LGSID consistently outperforms state-of-the-art discriminative and generative recommendation models. Ablation studies, visualizations, and case studies further validate its effectiveness.

</details>


### [43] [Infer As You Train: A Symmetric Paradigm of Masked Generative for Click-Through Rate Prediction](https://arxiv.org/abs/2511.14403)
*Moyu Zhang,Yujun Jin,Yun Chen,Jinxin Hu,Yu Zhang,Xiaoyi Zeng*

Main category: cs.IR

TL;DR: 提出了对称掩码生成范式SGCTR，在训练和推理阶段都应用生成能力，通过迭代重定义输入样本特征来提升CTR预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在训练阶段使用生成范式进行表示学习，但在在线推理时又回归到判别范式，无法充分利用生成能力提升预测精度，这种训练与推理阶段的不对称限制了生成范式的潜力。

Method: SGCTR框架在训练阶段学习特征依赖关系获得生成能力，在在线推理阶段应用这些生成能力迭代重定义输入样本的特征，减轻噪声特征的影响。

Result: 大量实验验证了SGCTR的优越性，证明在训练和推理阶段对称应用生成范式能显著释放其在CTR预测中的潜力。

Conclusion: 对称地在训练和推理阶段应用生成范式能够充分发挥生成模型在CTR预测中的能力，显著提升预测准确性。

Abstract: Generative models are increasingly being explored in click-through rate (CTR) prediction field to overcome the limitations of the conventional discriminative paradigm, which rely on a simple binary classification objective. However, existing generative models typically confine the generative paradigm to the training phase, primarily for representation learning. During online inference, they revert to a standard discriminative paradigm, failing to leverage their powerful generative capabilities to further improve prediction accuracy. This fundamental asymmetry between the training and inference phases prevents the generative paradigm from realizing its full potential. To address this limitation, we propose the Symmetric Masked Generative Paradigm for CTR prediction (SGCTR), a novel framework that establishes symmetry between the training and inference phases. Specifically, after acquiring generative capabilities by learning feature dependencies during training, SGCTR applies the generative capabilities during online inference to iteratively redefine the features of input samples, which mitigates the impact of noisy features and enhances prediction accuracy. Extensive experiments validate the superiority of SGCTR, demonstrating that applying the generative paradigm symmetrically across both training and inference significantly unlocks its power in CTR prediction.

</details>


### [44] [Jasper-Token-Compression-600M Technical Report](https://arxiv.org/abs/2511.14405)
*Dun Zhang,Ziyang Zeng,Yudong Zhou,Shuyang Lu*

Main category: cs.IR

TL;DR: 提出了Jasper-Token-Compression-600M模型，结合知识蒸馏与token压缩技术，在双语（英中）领域实现高效压缩文本表示，性能接近8B模型但效率更高。


<details>
  <summary>Details</summary>
Motivation: 扩展蒸馏方法到双语领域，通过对比学习和动态压缩率调整来提升模型性能和效率。

Method: 基于知识蒸馏和token压缩技术，引入一维卷积token压缩模块，动态调整压缩率训练。

Result: 模型在保持0.6B模型效率的同时，性能达到8B模型水平，嵌入质量和推理效率显著提升。

Conclusion: 成功开发了高效的Jasper-Token-Compression-600M模型，验证了知识蒸馏与token压缩结合在双语任务中的有效性。

Abstract: This technical report presents the training methodology and evaluation results of the open-source Jasper-Token-Compression-600M model, released in November 2025. Building on previous distillation-based recipes from the English Stella and Jasper models, we successfully extend this approach to a bilingual (English and Chinese) domain, further enhancing model performance through the incorporation of contrastive learning. A key innovation of our model is the introduction of a one-dimensional convolution-based token compression module. We dynamically adjust the compression rate during training, enabling the model to learn more robust and efficient compressed text representations. By combining knowledge distillation with token compression techniques, we achieve significant improvements in both embedding quality and inference efficiency. Our model performs with higher efficiency than a traditional 0.6B model while achieving performance comparable to that of an 8B model. For more information on the model release, visit: https://huggingface.co/infgrad/Jasper-Token-Compression-600M.

</details>


### [45] [Effective Diversification of Multi-Carousel Book Recommendation](https://arxiv.org/abs/2511.14461)
*Daniël Wilten,Gideon Maillette de Buy Wenniger,Arjen Hommersom,Paul Lucassen,Emiel Poortman*

Main category: cs.IR

TL;DR: 本文提出了在协同过滤算法基础上增加图书推荐多样性的方法，通过多种策略在公共图书馆网络目录中提高推荐项目的多样性，并引入了相应的评估指标。


<details>
  <summary>Details</summary>
Motivation: 当前流媒体平台使用的轮播式推荐虽然提供了结构化和易于导航的界面，但无法有效增加推荐多样性，而多样性对于保持用户参与度至关重要。

Method: 在协同过滤算法基础上提出了几种增加项目多样性的方法，专门针对公共图书馆网络目录的图书推荐场景。

Result: 提出的系统在准确性和超越准确性方面找到了合适的平衡，通过引入的评估指标验证了策略的有效性。

Conclusion: 通过提出的多样性增强方法，能够在保持推荐准确性的同时有效提高推荐项目的多样性，为公共图书馆的图书推荐系统提供了实用的解决方案。

Abstract: Using multiple carousels, lists that wrap around and can be scrolled, is the basis for offering content in most contemporary movie streaming platforms. Carousels allow for highlighting different aspects of users' taste, that fall in categories such as genres and authors. However, while carousels offer structure and greater ease of navigation, they alone do not increase diversity in recommendations, while this is essential to keep users engaged. In this work we propose several approaches to effectively increase item diversity within the domain of book recommendations, on top of a collaborative filtering algorithm. These approaches are intended to improve book recommendations in the web catalogs of public libraries. Furthermore, we introduce metrics to evaluate the resulting strategies, and show that the proposed system finds a suitable balance between accuracy and beyond-accuracy aspects.

</details>
