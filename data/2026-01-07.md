<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 83]
- [cs.IR](#cs.IR) [Total: 20]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [WearVox: An Egocentric Multichannel Voice Assistant Benchmark for Wearables](https://arxiv.org/abs/2601.02391)
*Zhaojiang Lin,Yong Xu,Kai Sun,Jing Zheng,Yin Huang,Surya Teja Appini,Krish Narang,Renjie Tao,Ishan Kapil Jain,Siddhant Arora,Ruizhi Li,Yiteng Huang,Kaushik Patnaik,Wenfang Xu,Suwon Shon,Yue Liu,Ahmed A Aly,Anuj Kumar,Florian Metze,Xin Luna Dong*

Main category: cs.CL

TL;DR: WearVox：首个针对可穿戴设备语音助手的基准测试，包含3842个多通道、以自我为中心的音频记录，覆盖5个任务，用于评估真实场景下的语音助手性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语音助手基准测试大多忽略可穿戴设备（如AI眼镜）带来的独特挑战：以自我为中心的音频受运动和噪声影响、快速微交互、需要区分设备导向语音和背景对话等，因此需要专门针对可穿戴场景的评估基准。

Method: 创建WearVox基准测试，包含3842个通过AI眼镜收集的多通道、以自我为中心的音频记录，涵盖搜索基础问答、闭卷问答、侧谈拒绝、工具调用和语音翻译五个任务，覆盖多种室内外环境和声学条件，并附带丰富的元数据。

Result: 主流实时语音大模型在WearVox上的准确率仅为29%-59%，在嘈杂户外音频上性能显著下降；多通道音频输入相比单通道能显著提升模型对环境噪声的鲁棒性，并改善设备导向语音和背景语音的区分能力。

Conclusion: 空间音频线索对上下文感知语音助手至关重要，WearVox为推进可穿戴语音AI研究提供了一个全面的测试平台，揭示了当前模型在真实可穿戴场景中的局限性。

Abstract: Wearable devices such as AI glasses are transforming voice assistants into always-available, hands-free collaborators that integrate seamlessly with daily life, but they also introduce challenges like egocentric audio affected by motion and noise, rapid micro-interactions, and the need to distinguish device-directed speech from background conversations. Existing benchmarks largely overlook these complexities, focusing instead on clean or generic conversational audio. To bridge this gap, we present WearVox, the first benchmark designed to rigorously evaluate voice assistants in realistic wearable scenarios. WearVox comprises 3,842 multi-channel, egocentric audio recordings collected via AI glasses across five diverse tasks including Search-Grounded QA, Closed-Book QA, Side-Talk Rejection, Tool Calling, and Speech Translation, spanning a wide range of indoor and outdoor environments and acoustic conditions. Each recording is accompanied by rich metadata, enabling nuanced analysis of model performance under real-world constraints. We benchmark leading proprietary and open-source speech Large Language Models (SLLMs) and find that most real-time SLLMs achieve accuracies on WearVox ranging from 29% to 59%, with substantial performance degradation on noisy outdoor audio, underscoring the difficulty and realism of the benchmark. Additionally, we conduct a case study with two new SLLMs that perform inference with single-channel and multi-channel audio, demonstrating that multi-channel audio inputs significantly enhance model robustness to environmental noise and improve discrimination between device-directed and background speech. Our results highlight the critical importance of spatial audio cues for context-aware voice assistants and establish WearVox as a comprehensive testbed for advancing wearable voice AI research.

</details>


### [2] [PCEval: A Benchmark for Evaluating Physical Computing Capabilities of Large Language Models](https://arxiv.org/abs/2601.02404)
*Inpyo Song,Eunji Jeon,Jangwon Lee*

Main category: cs.CL

TL;DR: PCEval 是首个用于评估大语言模型在物理计算领域能力的自动化基准测试，重点关注硬件约束下的逻辑与物理实现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在软件开发等领域表现出色，但在涉及硬件约束的物理计算领域（软件需要与物理硬件交互和控制）的有效性尚未充分探索。缺乏自动化评估基准来全面评估LLM在物理计算项目中的逻辑和物理能力。

Method: 提出了PCEval评估框架，通过仿真环境自动评估LLM生成电路和兼容代码的能力，涵盖不同项目复杂度。测试了13个领先模型，提供可重复、自动验证的实证评估。

Result: 评估发现：LLM在代码生成和逻辑电路设计方面表现良好，但在物理面包板布局创建方面存在显著困难，特别是在管理正确的引脚连接和避免电路错误方面。

Conclusion: PCEval推进了我们对AI在硬件依赖计算环境中辅助作用的理解，为开发更有效的物理计算教育工具奠定了基础。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, including software development, education, and technical assistance. Among these, software development is one of the key areas where LLMs are increasingly adopted. However, when hardware constraints are considered-for instance, in physical computing, where software must interact with and control physical hardware -their effectiveness has not been fully explored. To address this gap, we introduce \textsc{PCEval} (Physical Computing Evaluation), the first benchmark in physical computing that enables a fully automatic evaluation of the capabilities of LLM in both the logical and physical aspects of the projects, without requiring human assessment. Our evaluation framework assesses LLMs in generating circuits and producing compatible code across varying levels of project complexity. Through comprehensive testing of 13 leading models, \textsc{PCEval} provides the first reproducible and automatically validated empirical assessment of LLMs' ability to reason about fundamental hardware implementation constraints within a simulation environment. Our findings reveal that while LLMs perform well in code generation and logical circuit design, they struggle significantly with physical breadboard layout creation, particularly in managing proper pin connections and avoiding circuit errors. \textsc{PCEval} advances our understanding of AI assistance in hardware-dependent computing environments and establishes a foundation for developing more effective tools to support physical computing education.

</details>


### [3] [Losses that Cook: Topological Optimal Transport for Structured Recipe Generation](https://arxiv.org/abs/2601.02531)
*Mattia Ottoborgo,Daniele Rege Cambrin,Paolo Garza*

Main category: cs.CL

TL;DR: 提出基于RECIPE-NLG的烹饪食谱生成模型，引入拓扑损失处理食材列表，显著提升食材和动作层面的生成质量


<details>
  <summary>Details</summary>
Motivation: 烹饪食谱生成需要同时考虑文本流畅性、时间温度准确性、步骤连贯性和食材正确性，而传统基于交叉熵的训练方法仅关注流畅性，无法满足食谱生成的特殊需求

Method: 基于RECIPE-NLG框架，引入多种复合目标函数：1) 拓扑损失，将食材列表表示为嵌入空间中的点云，最小化预测食材与真实食材的差异；2) Dice损失；3) 混合损失。使用标准NLG指标和食谱专用指标进行评估

Result: 拓扑损失显著提升食材和动作层面的指标；Dice损失在时间/温度精度上表现优异；混合损失在数量和时间的权衡中取得协同增益。人工偏好分析显示模型在62%的情况下被优先选择

Conclusion: 复合目标函数特别是拓扑损失能有效提升食谱生成质量，不同损失函数在不同维度各有优势，混合损失能实现更好的综合性能，为食谱生成任务提供了更全面的优化方案

Abstract: Cooking recipes are complex procedures that require not only a fluent and factual text, but also accurate timing, temperature, and procedural coherence, as well as the correct composition of ingredients. Standard training procedures are primarily based on cross-entropy and focus solely on fluency. Building on RECIPE-NLG, we investigate the use of several composite objectives and present a new topological loss that represents ingredient lists as point clouds in embedding space, minimizing the divergence between predicted and gold ingredients. Using both standard NLG metrics and recipe-specific metrics, we find that our loss significantly improves ingredient- and action-level metrics. Meanwhile, the Dice loss excels in time/temperature precision, and the mixed loss yields competitive trade-offs with synergistic gains in quantity and time. A human preference analysis supports our finding, showing our model is preferred in 62% of the cases.

</details>


### [4] [ModeX: Evaluator-Free Best-of-N Selection for Open-Ended Generation](https://arxiv.org/abs/2601.02535)
*Hyeong Kyu Choi,Sharon Li*

Main category: cs.CL

TL;DR: ModeX：一种无需评估器的Best-of-N选择框架，通过识别生成文本中的主导语义共识来提升开放任务性能


<details>
  <summary>Details</summary>
Motivation: 现有Best-of-N和self-consistency方法依赖外部评估器、奖励模型或精确字符串匹配投票，限制了在开放任务中的适用性和效率。需要一种无需外部评估的通用选择框架。

Method: 提出ModeX框架，构建候选生成文本的相似度图，递归应用谱聚类选择代表中心点。还提出ModeX-Lite版本，通过早期剪枝提高效率。

Result: 在文本摘要、代码生成和数学推理等开放任务中，ModeX方法持续优于标准的单路径和多路径基线，提供计算高效的鲁棒解决方案。

Conclusion: ModeX提供了一种无需外部评估器的通用Best-of-N选择框架，能有效识别生成文本中的语义共识，在多种开放任务中展现优越性能。

Abstract: Selecting a single high-quality output from multiple stochastic generations remains a fundamental challenge for large language models (LLMs), particularly in open-ended tasks where no canonical answer exists. While Best-of-N and self-consistency methods show that aggregating multiple generations can improve performance, existing approaches typically rely on external evaluators, reward models, or exact string-match voting, limiting their applicability and efficiency. We propose Mode Extraction (ModeX), an evaluator-free Best-of-N selection framework that generalizes majority voting to open-ended text generation by identifying the modal output representing the dominant semantic consensus among generated texts. ModeX constructs a similarity graph over candidate generations and recursively applies spectral clustering to select a representative centroid, without requiring additional inference or auxiliary models. We further instantiate this selection principle as ModeX--Lite, an improved version of ModeX with early pruning for efficiency. Across open-ended tasks--including text summarization, code generation, and mathematical reasoning--our approaches consistently outperform standard single- and multi-path baselines, providing a computationally efficient solution for robust open-ended text generation. Code is released in https://github.com/deeplearning-wisc/ModeX.

</details>


### [5] [LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference](https://arxiv.org/abs/2601.02569)
*Hossein Rajabzadeh,Maryam Dialameh,Chul B. Park,Il-Min Kim,Hyock Ju Kwon*

Main category: cs.CL

TL;DR: LoRA-Drop：一种通过时间计算调度加速LLM推理的即插即用框架，在多数解码步中重用前一个token的隐藏状态并应用低秩LoRA校正，定期刷新步骤执行完整模型以防止漂移。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型受限于顺序解码，每个新token通常需要执行所有Transformer层。现有的动态深度和层跳过方法虽然降低了成本，但往往依赖辅助路由机制或在跳过层未补偿时导致精度下降。

Method: 提出LoRA-Drop框架，对固定的中间层子集应用时间计算调度：在大多数解码步骤中，选定的层重用前一个token的隐藏状态并应用低秩LoRA校正；定期的刷新步骤执行完整模型以防止漂移。无需路由网络，兼容标准KV缓存，可通过在LoRA步骤中跳过可丢弃层的KV更新并定期刷新来减少KV缓存占用。

Result: 在LLaMA2-7B、LLaMA3-8B、Qwen2.5-7B和Qwen2.5-14B上，LoRA-Drop实现了高达2.6倍的解码加速和45-55%的KV缓存减少，同时保持与基线精度相差在0.5个百分点以内。在推理、代码生成和长上下文/多语言基准测试中，识别出能保持质量同时提供显著效率增益的一致安全调度配置区域。

Conclusion: LoRA-Drop为LLM中的自适应容量推理提供了一个简单路径，无需复杂的路由机制即可实现显著的效率提升，同时保持模型质量。

Abstract: Autoregressive large language models (LLMs) are bottlenecked by sequential decoding, where each new token typically requires executing all transformer layers. Existing dynamic-depth and layer-skipping methods reduce this cost, but often rely on auxiliary routing mechanisms or incur accuracy degradation when bypassed layers are left uncompensated. We present \textbf{LoRA-Drop}, a plug-and-play inference framework that accelerates decoding by applying a \emph{temporal compute schedule} to a fixed subset of intermediate layers: on most decoding steps, selected layers reuse the previous-token hidden state and apply a low-rank LoRA correction, while periodic \emph{refresh} steps execute the full model to prevent drift. LoRA-Drop requires no routing network, is compatible with standard KV caching, and can reduce KV-cache footprint by skipping KV updates in droppable layers during LoRA steps and refreshing periodically. Across \textbf{LLaMA2-7B}, \textbf{LLaMA3-8B}, \textbf{Qwen2.5-7B}, and \textbf{Qwen2.5-14B}, LoRA-Drop achieves up to \textbf{2.6$\times$ faster decoding} and \textbf{45--55\% KV-cache reduction} while staying within \textbf{0.5 percentage points (pp)} of baseline accuracy. Evaluations on reasoning (GSM8K, MATH, BBH), code generation (HumanEval, MBPP), and long-context/multilingual benchmarks (LongBench, XNLI, XCOPA) identify a consistent \emph{safe zone} of scheduling configurations that preserves quality while delivering substantial efficiency gains, providing a simple path toward adaptive-capacity inference in LLMs. Codes are available at https://github.com/hosseinbv/LoRA-Drop.git.

</details>


### [6] [Fact-Checking with Large Language Models via Probabilistic Certainty and Consistency](https://arxiv.org/abs/2601.02574)
*Haoran Wang,Maryam Khalid,Qiong Wu,Jian Gao,Cheng Cao*

Main category: cs.CL

TL;DR: PCC框架通过建模LLM的概率确定性和推理一致性来估计事实置信度，实现自适应验证策略，仅在必要时触发检索，提升事实核查的效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM事实核查方法通常不加区分地检索外部证据，忽视了模型的内部知识，可能引入无关噪声，且缺乏针对性机制来解决模型推理中的特定不确定性。

Method: 提出概率确定性和一致性(PCC)框架，通过联合建模LLM的概率确定性和推理一致性来估计事实置信度，基于置信度信号实现自适应验证策略：高置信时直接回答，不确定或不一致时触发定向检索，高模糊性时进行深度搜索。

Result: 在三个具有挑战性的基准测试中，PCC在不确定性量化方面优于口头置信度方法，并持续超越基于LLM的事实核查基线。此外，PCC在不同LLM上表现出良好的泛化能力。

Conclusion: PCC框架通过自适应地结合内部知识和外部检索，有效解决了LLM事实核查中的幻觉问题，提高了效率和可靠性，为LLM的事实准确性提供了实用解决方案。

Abstract: Large language models (LLMs) are increasingly used in applications requiring factual accuracy, yet their outputs often contain hallucinated responses. While fact-checking can mitigate these errors, existing methods typically retrieve external evidence indiscriminately, overlooking the model's internal knowledge and potentially introducing irrelevant noise. Moreover, current systems lack targeted mechanisms to resolve specific uncertainties in the model's reasoning. Inspired by how humans fact-check, we argue that LLMs should adaptively decide whether to rely on internal knowledge or initiate retrieval based on their confidence in a given claim. We introduce Probabilistic Certainty and Consistency (PCC), a framework that estimates factual confidence by jointly modeling an LLM's probabilistic certainty and reasoning consistency. These confidence signals enable an adaptive verification strategy: the model answers directly when confident, triggers targeted retrieval when uncertain or inconsistent, and escalates to deep search when ambiguity is high. Our confidence-guided routing mechanism ensures that retrieval is invoked only when necessary, improving both efficiency and reliability. Extensive experiments across three challenging benchmarks show that PCC achieves better uncertainty quantification than verbalized confidence and consistently outperforms strong LLM-based fact-checking baselines. Furthermore, we demonstrate that PCC generalizes well across various LLMs.

</details>


### [7] [DataParasite Enables Scalable and Repurposable Online Data Curation](https://arxiv.org/abs/2601.02578)
*Mengyi Sun*

Main category: cs.CL

TL;DR: DataParasite是一个开源模块化管道，用于可扩展的在线数据收集，通过自然语言指令定义任务，大幅降低计算社会科学数据收集成本


<details>
  <summary>Details</summary>
Motivation: 计算社会科学依赖从异构在线来源组装的数据库，这个过程通常劳动密集、成本高昂且难以复制。现有系统通常不透明、不灵活或不适合科学数据管理。

Method: 将表格数据管理任务分解为独立的实体级搜索，通过轻量级配置文件定义，使用共享的任务无关Python脚本执行。支持通过自然语言指令重新用于新任务。

Result: 在多个计算社会科学典型任务（教师招聘历史、精英死亡事件、政治职业轨迹）中，DataParasite实现高准确性，同时将数据收集成本相对于手动管理降低一个数量级。

Conclusion: 通过降低在线数据组装的技术和劳动障碍，DataParasite为计算社会科学及其他领域提供了可扩展、透明和可重复使用的数据管理实践基础。

Abstract: Many questions in computational social science rely on datasets assembled from heterogeneous online sources, a process that is often labor-intensive, costly, and difficult to reproduce. Recent advances in large language models enable agentic search and structured extraction from the web, but existing systems are frequently opaque, inflexible, or poorly suited to scientific data curation. Here we introduce DataParasite, an open-source, modular pipeline for scalable online data collection. DataParasite decomposes tabular curation tasks into independent, entity-level searches defined through lightweight configuration files and executed through a shared, task-agnostic python script. Crucially, the same pipeline can be repurposed to new tasks, including those without predefined entity lists, using only natural-language instructions. We evaluate the pipeline on multiple canonical tasks in computational social science, including faculty hiring histories, elite death events, and political career trajectories. Across tasks, DataParasite achieves high accuracy while reducing data-collection costs by an order of magnitude relative to manual curation. By lowering the technical and labor barriers to online data assembly, DataParasite provides a practical foundation for scalable, transparent, and reusable data curation in computational social science and beyond.

</details>


### [8] [Reconstructing Item Characteristic Curves using Fine-Tuned Large Language Models](https://arxiv.org/abs/2601.02580)
*Christopher Ormerod*

Main category: cs.CL

TL;DR: 利用大语言模型模拟学生反应来隐式建模试题参数，无需昂贵的实地测试即可估计IRT参数。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖昂贵的实地测试收集学生表现数据来校准IRT参数，需要大量时间和资源。

Method: 使用Qwen-3密集模型系列和LoRA技术微调LLM，让模型在不同潜在能力描述下生成多项选择题回答，重构正确回答概率作为学生能力的函数，生成合成ICC来估计IRT参数。

Result: 在六年级英语语言艺术项目和BEA 2024共享任务数据集上的评估表明，该方法与基线方法相当或更优，在建模试题区分度方面特别有效。

Conclusion: 基于模拟的方法能够有效估计IRT参数，为心理测量学提供了一种经济高效的替代方案，特别是在建模试题区分度方面表现出色。

Abstract: Traditional methods for determining assessment item parameters, such as difficulty and discrimination, rely heavily on expensive field testing to collect student performance data for Item Response Theory (IRT) calibration. This study introduces a novel approach that implicitly models these psychometric properties by fine-tuning Large Language Models (LLMs) to simulate student responses across a spectrum of latent abilities. Leveraging the Qwen-3 dense model series and Low-Rank Adaptation (LoRA), we train models to generate responses to multiple choice questions conditioned on discrete ability descriptors. We reconstruct the probability of a correct response as a function of student ability, effectively generating synthetic Item Characteristic Curves (ICCs) to estimate IRT parameters. Evaluation on a dataset of Grade 6 English Language Arts (ELA) items and the BEA 2024 Shared Task dataset demonstrates that this method competes with or outperforms baseline approaches. This simulation-based technique seems particularly effective at modeling item discrimination.

</details>


### [9] [FlowPlan-G2P: A Structured Generation Framework for Transforming Scientific Papers into Patent Descriptions](https://arxiv.org/abs/2601.02589)
*Kris W Pan,Yongmin Yoo*

Main category: cs.CL

TL;DR: FlowPlan-G2P是一个将科学论文转化为专利描述的框架，通过模仿专家起草者的认知流程，分三步实现：概念图提取、段落章节规划、图条件生成，显著提升逻辑连贯性和法律合规性。


<details>
  <summary>Details</summary>
Motivation: 每年有超过350万项专利申请，起草专利描述需要深厚的技术和法律专业知识。将科学论文转化为专利描述特别困难，因为两者修辞风格不同且法律要求严格。现有的黑盒文本到文本方法难以建模结构推理和法律约束。

Method: 提出FlowPlan-G2P框架，将任务重新制定为三个阶段：1) 概念图归纳：通过类似专家的推理提取技术实体和关系形成有向图；2) 段落和章节规划：将图重组为与规范专利章节对齐的连贯聚类；3) 图条件生成：使用章节特定子图和定制提示生成法律合规的段落。

Result: 实验表明，FlowPlan-G2P在逻辑连贯性和法律合规性方面显著优于端到端的LLM基线方法。

Conclusion: 该框架为论文到专利生成建立了新范式，并推进了专业领域的结构化文本生成。

Abstract: Over 3.5 million patents are filed annually, with drafting patent descriptions requiring deep technical and legal expertise. Transforming scientific papers into patent descriptions is particularly challenging due to their differing rhetorical styles and stringent legal requirements. Unlike black-box text-to-text approaches that struggle to model structural reasoning and legal constraints, we propose FlowPlan-G2P, a novel framework that mirrors the cognitive workflow of expert drafters by reformulating this task into three stages: (1) Concept Graph Induction, extracting technical entities and relationships into a directed graph via expert-like reasoning; (2) Paragraph and Section Planning, reorganizing the graph into coherent clusters aligned with canonical patent sections; and (3) Graph-Conditioned Generation, producing legally compliant paragraphs using section-specific subgraphs and tailored prompts. Experiments demonstrate that FlowPlan-G2P significantly improves logical coherence and legal compliance over end-to-end LLM baselines. Our framework establishes a new paradigm for paper-to-patent generation and advances structured text generation for specialized domains.

</details>


### [10] [Scalable Construction of a Lung Cancer Knowledge Base: Profiling Semantic Reasoning in LLMs](https://arxiv.org/abs/2601.02604)
*Cesar Felipe Martínez Cisneros,Jesús Ulises Quiroz Bautista,Claudia Anahí Guzmán Solano,Bogdan Kaleb García Rivera,Iván García Pacheco,Yalbi Itzel Balderas Martínez,Kolawole John Adebayoc,Ignacio Arroyo Fernández*

Main category: cs.CL

TL;DR: 该研究提出一个基于OpenIE构建肺癌知识库的管道，用于增强大语言模型在生物医学领域的性能，通过微调T5模型显著提升了语义一致性和任务表现。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型应用于生物医学研究需要高质量的领域特定知识，但在肿瘤学领域缺乏可扩展、低成本的方法来构建结构化知识库以进行有效微调。

Method: 开发了一个四步管道：1) 使用MeSH词表识别医学概念；2) 筛选具有开放许可(CC0)的PubMed文献；3) 使用OpenIE方法提取(主体，关系，客体)三元组；4) 通过命名实体识别(NER)丰富三元组以确保生物医学相关性。

Result: 构建了一个大规模、领域特定且噪声感知的肺癌知识库，通过监督语义微调T5模型后，使用ROUGE和BERTScore评估显示模型性能显著提升，语义连贯性明显改善。

Conclusion: OpenIE衍生的知识资源可作为可扩展、低成本的解决方案，有效增强生物医学自然语言处理能力，为大语言模型在精准医学领域的应用提供了实用路径。

Abstract: The integration of Large Language Models (LLMs) into biomedical research offers new opportunities for domainspecific reasoning and knowledge representation. However, their performance depends heavily on the semantic quality of training data. In oncology, where precision and interpretability are vital, scalable methods for constructing structured knowledge bases are essential for effective fine-tuning. This study presents a pipeline for developing a lung cancer knowledge base using Open Information Extraction (OpenIE). The process includes: (1) identifying medical concepts with the MeSH thesaurus; (2) filtering open-access PubMed literature with permissive licenses (CC0); (3) extracting (subject, relation, object) triplets using OpenIE method; and (4) enriching triplet sets with Named Entity Recognition (NER) to ensure biomedical relevance. The resulting triplet sets provide a domain-specific, large-scale, and noise-aware resource for fine-tuning LLMs. We evaluated T5 models finetuned on this dataset through Supervised Semantic Fine-Tuning. Comparative assessments with ROUGE and BERTScore show significantly improved performance and semantic coherence, demonstrating the potential of OpenIE-derived resources as scalable, low-cost solutions for enhancing biomedical NLP.

</details>


### [11] [Improved Evidence Extraction for Document Inconsistency Detection with LLMs](https://arxiv.org/abs/2601.02627)
*Nelvin Tan,Yaowen Zhang,James Asikin Cheung,Fusheng Liu,Yu-Ching Shih,Dong Yang*

Main category: cs.CL

TL;DR: 提出基于大语言模型的文档不一致性检测新方法，重点关注证据提取而非分类，引入新评估指标和redact-and-retry框架，显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在多个领域表现出色，但在文档不一致性检测方面的研究相对有限。现有方法主要关注是否存在不一致的分类问题，而缺乏对不一致证据的具体提取能力。

Method: 提出redact-and-retry框架，采用受限过滤机制，配合新设计的全面证据提取评估指标，用于改进大语言模型在文档不一致性检测中的表现。

Result: 实验结果表明该方法显著优于直接提示方法，在大语言模型为基础的文档不一致性检测方面取得了有希望的结果。

Conclusion: 通过引入新的证据提取指标和redact-and-retry框架，该研究有效提升了基于大语言模型的文档不一致性检测能力，特别是在证据提取方面取得了实质性改进。

Abstract: Large language models (LLMs) are becoming useful in many domains due to their impressive abilities that arise from large training datasets and large model sizes. However, research on LLM-based approaches to document inconsistency detection is relatively limited. There are two key aspects of document inconsistency detection: (i) classification of whether there exists any inconsistency, and (ii) providing evidence of the inconsistent sentences. We focus on the latter, and introduce new comprehensive evidence-extraction metrics and a redact-and-retry framework with constrained filtering that substantially improves LLM-based document inconsistency detection over direct prompting. We back our claims with promising experimental results.

</details>


### [12] [Empirical Comparison of Encoder-Based Language Models and Feature-Based Supervised Machine Learning Approaches to Automated Scoring of Long Essays](https://arxiv.org/abs/2601.02659)
*Kuo Wang,Haowei Hua,Pengfei Yan,Hong Jiao,Dan Song*

Main category: cs.CL

TL;DR: 研究比较了多种编码器语言模型在长文本自动评分中的表现，发现基于多预训练模型嵌入的集成模型显著优于单个模型。


<details>
  <summary>Details</summary>
Motivation: 长文本处理对仅编码器语言模型构成挑战，特别是在长文章自动评分任务中。本研究旨在探索如何有效利用编码器模型处理长文本评分问题。

Method: 训练了多种BERT系列模型（BERT、RoBERTa、DistilBERT、DeBERTa），构建了基于多编码器模型嵌入的集成模型，以及基于特征的监督机器学习集成模型（GBDT、XGBoost、LightGBM）。使用17,307篇文章数据集，按80%/10%/10%划分训练/验证/测试集，以二次加权Kappa评估性能。

Result: 集成嵌入模型（结合多个预训练语言模型表示，以梯度提升分类器作为集成模型）在长文章评分任务中显著优于单个语言模型。

Conclusion: 对于长文本自动评分任务，集成多个预训练语言模型的嵌入表示并结合梯度提升分类器是最有效的解决方案，能够克服单个编码器模型在处理长上下文时的局限性。

Abstract: Long context may impose challenges for encoder-only language models in text processing, specifically for automated scoring of essays. This study trained several commonly used encoder-based language models for automated scoring of long essays. The performance of these trained models was evaluated and compared with the ensemble models built upon the base language models with a token limit of 512?. The experimented models include BERT-based models (BERT, RoBERTa, DistilBERT, and DeBERTa), ensemble models integrating embeddings from multiple encoder models, and ensemble models of feature-based supervised machine learning models, including Gradient-Boosted Decision Trees, eXtreme Gradient Boosting, and Light Gradient Boosting Machine. We trained, validated, and tested each model on a dataset of 17,307 essays, with an 80%/10%/10% split, and evaluated model performance using Quadratic Weighted Kappa. This study revealed that an ensemble-of-embeddings model that combines multiple pre-trained language model representations with gradient-boosting classifier as the ensemble model significantly outperforms individual language models at scoring long essays.

</details>


### [13] [When Do Tools and Planning Help LLMs Think? A Cost- and Latency-Aware Benchmark](https://arxiv.org/abs/2601.02663)
*Subha Ghoshal,Ali Al-Bustami*

Main category: cs.CL

TL;DR: 研究对比了不同LLM推理策略在真实任务中的表现，发现工具增强能提升某些任务准确率但大幅增加延迟，而简单提示在另一些任务中表现最佳，强调了需要任务特定的模型和工具复杂度选择。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型越来越多地依赖推理时规划和外部工具来提升推理能力，但缺乏在实际任务中对这些策略的系统性基准测试，特别是关于准确率、延迟和成本之间的权衡。

Method: 使用LangChain和LangGraph构建对比实验：1）一次性提示基线；2）配备任务特定工具的规划-执行-重规划智能体（包括DBpedia SPARQL查询、模式探索、维基百科检索和主题网络搜索）。在两个真实场景测试：基于图结构知识的事件问答（Event-QA）和Reddit ChangeMyView的说服性回复生成（CMV）。每个任务评估60个示例（3组×20），使用GPT-4o和GPT-4o-mini，测量准确率和端到端延迟。

Result: 在Event-QA上，最佳工具增强配置显著提升准确率（GPT-4o从47.5%到67.5%），但延迟增加两个数量级（从~8秒到~317秒）。在CMV上，一次性提示表现最佳（GPT-4o-mini达到75%，~6秒），而规划+搜索大幅增加延迟却没有一致的准确率提升。复杂多工具编排暴露了小模型的失败模式。结果显示了模型大小和工具复杂度选择的权衡。

Conclusion: 研究强调了需要根据具体任务、成本意识来选择模型大小和智能体/工具复杂度。工具增强策略在某些任务中有效但代价高昂，而简单方法在其他任务中可能更优，实际部署需要仔细权衡准确率、延迟和成本。

Abstract: Modern large language models (LLMs) increasingly rely on inference-time planning and external tools to improve reasoning. We benchmark this behavior on two real-world settings: event-centric question answering over graph-structured knowledge (Event-QA) and persuasive response generation in Reddit ChangeMyView (CMV). Using LangChain and LangGraph, we compare a one-shot baseline against a plan--execute--replan agent equipped with task-specific tools (DBpedia SPARQL/lookup/schema exploration, Wikipedia-focused retrieval, and topical web search). We evaluate on 60 examples each from Event-QA and CMV (3 splits of 20), and report both mean end-to-end latency and per-example token cost estimates. We evaluate GPT-4o and GPT-4o-mini under identical workflows and report accuracy and end-to-end latency. On Event-QA, the best tool-augmented configuration improves accuracy (e.g., 47.5\% $\rightarrow$ 67.5\% for GPT-4o) while increasing latency by orders of magnitude ($\sim$8s $\rightarrow$ $\sim$317s per example). On CMV, one-shot prompting is strongest (e.g., GPT-4o-mini achieves 75\% at $\sim$6s), and planning+search increases latency substantially without consistent gains. However, complex multi-tool orchestration exposes failure modes where the smaller model degrades. Overall, the findings highlight the need for task-specific, cost-aware choices of both model size and agent/tooling complexity.

</details>


### [14] [Towards Comprehensive Stage-wise Benchmarking of Large Language Models in Fact-Checking](https://arxiv.org/abs/2601.02669)
*Hongzhan Lin,Zixin Chen,Zhiqi Shen,Ziyang Luo,Zhen Ye,Jing Ma,Tat-Seng Chua,Guandong Xu*

Main category: cs.CL

TL;DR: FactArena是一个完全自动化的竞技场式评估框架，用于全面、分阶段地对大型语言模型在完整事实核查流程中的表现进行基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注声明验证，忽视了更广泛的事实核查工作流程（包括声明提取和证据检索）。这种狭隘的焦点使得当前基准测试无法揭示现代LLMs的系统性推理失败、事实盲点和鲁棒性限制。

Method: FactArena包含三个关键组件：1）LLM驱动的事实核查流程，标准化声明分解、通过工具增强交互进行证据检索、以及基于理由的裁决预测；2）竞技场式判断机制，遵循统一的参考指南，确保在异构判断代理之间进行无偏且一致的成对比较；3）竞技场驱动的声明演化模块，自适应生成更具挑战性和语义可控的声明，以探测LLMs在固定种子数据之外的事实鲁棒性。

Result: 在涵盖七个模型家族的16个最先进LLMs上，FactArena产生了稳定且可解释的排名。分析进一步揭示了静态声明验证准确性与端到端事实核查能力之间的显著差异。

Conclusion: 该框架为诊断LLMs的事实推理提供了一个可扩展且可信赖的范式，指导未来模型开发，并推动LLMs在安全关键事实核查应用中的可靠部署。

Abstract: Large Language Models (LLMs) are increasingly deployed in real-world fact-checking systems, yet existing evaluations focus predominantly on claim verification and overlook the broader fact-checking workflow, including claim extraction and evidence retrieval. This narrow focus prevents current benchmarks from revealing systematic reasoning failures, factual blind spots, and robustness limitations of modern LLMs. To bridge this gap, we present FactArena, a fully automated arena-style evaluation framework that conducts comprehensive, stage-wise benchmarking of LLMs across the complete fact-checking pipeline. FactArena integrates three key components: (i) an LLM-driven fact-checking process that standardizes claim decomposition, evidence retrieval via tool-augmented interactions, and justification-based verdict prediction; (ii) an arena-styled judgment mechanism guided by consolidated reference guidelines to ensure unbiased and consistent pairwise comparisons across heterogeneous judge agents; and (iii) an arena-driven claim-evolution module that adaptively generates more challenging and semantically controlled claims to probe LLMs' factual robustness beyond fixed seed data. Across 16 state-of-the-art LLMs spanning seven model families, FactArena produces stable and interpretable rankings. Our analyses further reveal significant discrepancies between static claim-verification accuracy and end-to-end fact-checking competence, highlighting the necessity of holistic evaluation. The proposed framework offers a scalable and trustworthy paradigm for diagnosing LLMs' factual reasoning, guiding future model development, and advancing the reliable deployment of LLMs in safety-critical fact-checking applications.

</details>


### [15] [Multi-Turn Jailbreaking of Aligned LLMs via Lexical Anchor Tree Search](https://arxiv.org/abs/2601.02670)
*Devang Kulshreshtha,Hang Su,Chinmay Hegde,Haohan Wang*

Main category: cs.CL

TL;DR: LATS提出了一种无需攻击者LLM的越狱方法，通过词汇锚注入将越狱重构为多轮对话的广度优先树搜索，在仅需约6.4次查询的情况下，在最新GPT、Claude和Llama模型上实现了97-100%的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有越狱方法需要攻击者LLM来生成对抗性查询，且查询预算要求高，导致成本昂贵。此外，攻击者LLM生成的查询通常包含不可解释的随机前缀，这些资源限制使得越狱变得昂贵且不实用。

Method: LATS采用无需攻击者LLM的方法，纯粹通过词汇锚注入进行操作。该方法将越狱重构为多轮对话的广度优先树搜索，每个节点逐步将攻击目标中缺失的内容词注入到良性提示中。

Result: 在AdvBench和HarmBench上的评估显示，LATS在最新的GPT、Claude和Llama模型上实现了97-100%的攻击成功率，平均仅需约6.4次查询，而其他方法需要20+次查询。

Conclusion: 研究结果表明对话结构是一个强大且保护不足的攻击面，同时展示了在高攻击成功率易达的时代，LATS具有卓越的查询效率。代码将开源以支持可复现性。

Abstract: Most jailbreak methods achieve high attack success rates (ASR) but require attacker LLMs to craft adversarial queries and/or demand high query budgets. These resource limitations make jailbreaking expensive, and the queries generated by attacker LLMs often consist of non-interpretable random prefixes. This paper introduces Lexical Anchor Tree Search (), addressing these limitations through an attacker-LLM-free method that operates purely via lexical anchor injection. LATS reformulates jailbreaking as a breadth-first tree search over multi-turn dialogues, where each node incrementally injects missing content words from the attack goal into benign prompts. Evaluations on AdvBench and HarmBench demonstrate that LATS achieves 97-100% ASR on latest GPT, Claude, and Llama models with an average of only ~6.4 queries, compared to 20+ queries required by other methods. These results highlight conversational structure as a potent and under-protected attack surface, while demonstrating superior query efficiency in an era where high ASR is readily achievable. Our code will be released to support reproducibility.

</details>


### [16] [Extracting books from production language models](https://arxiv.org/abs/2601.02671)
*Ahmed Ahmed,A. Feder Cooper,Sanmi Koyejo,Percy Liang*

Main category: cs.CL

TL;DR: 研究发现即使有安全措施，商业大语言模型仍存在训练数据提取风险，特别是受版权保护文本，不同模型易受攻击程度不同。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs和版权争议中的核心问题：训练数据是否被模型记忆并可能被提取，特别是商业LLMs在安全措施下是否仍存在数据提取风险。

Method: 采用两阶段方法：(1)初始探测测试提取可行性，有时使用Best-of-N越狱技术；(2)迭代续写提示尝试提取书籍内容。评估四个商业LLMs，使用基于块的最长公共子串近似计算提取成功率。

Result: 不同模型提取效果差异显著：Gemini 2.5 Pro和Grok 3无需越狱即可提取大量文本（如《哈利·波特》nv-recall达76.8%和70.3%），Claude 3.7 Sonnet和GPT-4.1需要越狱，Claude在越狱后可输出接近原文的整本书（nv-recall=95.8%），GPT-4.1需要更多越狱尝试且最终会拒绝继续。

Conclusion: 即使有模型和系统级安全防护，商业LLMs仍存在提取受版权保护训练数据的风险，需要更强的安全措施来防止数据泄露。

Abstract: Many unresolved legal questions over LLMs and copyright center on memorization: whether specific training data have been encoded in the model's weights during training, and whether those memorized data can be extracted in the model's outputs. While many believe that LLMs do not memorize much of their training data, recent work shows that substantial amounts of copyrighted text can be extracted from open-weight models. However, it remains an open question if similar extraction is feasible for production LLMs, given the safety measures these systems implement. We investigate this question using a two-phase procedure: (1) an initial probe to test for extraction feasibility, which sometimes uses a Best-of-N (BoN) jailbreak, followed by (2) iterative continuation prompts to attempt to extract the book. We evaluate our procedure on four production LLMs -- Claude 3.7 Sonnet, GPT-4.1, Gemini 2.5 Pro, and Grok 3 -- and we measure extraction success with a score computed from a block-based approximation of longest common substring (nv-recall). With different per-LLM experimental configurations, we were able to extract varying amounts of text. For the Phase 1 probe, it was unnecessary to jailbreak Gemini 2.5 Pro and Grok 3 to extract text (e.g, nv-recall of 76.8% and 70.3%, respectively, for Harry Potter and the Sorcerer's Stone), while it was necessary for Claude 3.7 Sonnet and GPT-4.1. In some cases, jailbroken Claude 3.7 Sonnet outputs entire books near-verbatim (e.g., nv-recall=95.8%). GPT-4.1 requires significantly more BoN attempts (e.g., 20X), and eventually refuses to continue (e.g., nv-recall=4.0%). Taken together, our work highlights that, even with model- and system-level safeguards, extraction of (in-copyright) training data remains a risk for production LLMs.

</details>


### [17] [Iterative Structured Pruning for Large Language Models with Multi-Domain Calibration](https://arxiv.org/abs/2601.02674)
*Guangxin Wu,Hao Zhang,Zhang Zhibin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: 提出一种新型结构化剪枝框架，通过混合多领域校准集和迭代校准策略有效识别并移除冗余通道，在保持硬件兼容性的同时实现显著模型压缩。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型规模不断增长带来了计算开销、内存占用和推理延迟等部署挑战，现有非结构化剪枝技术产生的稀疏模式需要专用硬件或软件支持，限制了实际应用。

Method: 采用结构化剪枝方法，提出基于混合多领域校准集和迭代校准策略的框架，通过消除整个架构组件来识别和移除冗余通道，保持与标准硬件加速器的兼容性。

Result: 在各种模型和多样化下游任务上的广泛实验表明，该方法实现了显著的模型压缩，同时性能下降最小。

Conclusion: 提出的结构化剪枝框架为大型语言模型的实际部署提供了有效解决方案，在保持硬件兼容性的同时实现了高效压缩，有助于降低部署成本并提高推理效率。

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide spectrum of natural language processing tasks. However, their ever-growing scale introduces significant barriers to real-world deployment, including substantial computational overhead, memory footprint, and inference latency. While model pruning presents a viable solution to these challenges, existing unstructured pruning techniques often yield irregular sparsity patterns that necessitate specialized hardware or software support. In this work, we explore structured pruning, which eliminates entire architectural components and maintains compatibility with standard hardware accelerators. We introduce a novel structured pruning framework that leverages a hybrid multi-domain calibration set and an iterative calibration strategy to effectively identify and remove redundant channels. Extensive experiments on various models across diverse downstream tasks show that our approach achieves significant compression with minimal performance degradation.

</details>


### [18] [EvoRoute: Experience-Driven Self-Routing LLM Agent Systems](https://arxiv.org/abs/2601.02695)
*Guibin Zhang,Haiyang Yu,Kaiming Yang,Bingli Wu,Fei Huang,Yongbin Li,Shuicheng Yan*

Main category: cs.CL

TL;DR: EvoRoute是一个自进化的模型路由范式，通过动态选择Pareto最优的LLM主干来平衡智能体系统的性能、成本和延迟，实现显著的成本和延迟降低。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型协调的复杂智能体AI系统在复杂多轮任务上表现出色，但面临高昂的经济成本和严重延迟问题，形成了性能、成本和延迟之间的三元悖论。

Method: 提出了EvoRoute自进化模型路由范式，利用不断扩展的先前经验知识库，在每个步骤动态选择Pareto最优的LLM主干，平衡准确性、效率和资源使用，并通过环境反馈持续优化选择策略。

Result: 在GAIA和BrowseComp+等挑战性智能体基准测试中，EvoRoute集成到现成的智能体系统中，不仅保持或提升了系统性能，还将执行成本降低了高达80%，延迟减少了超过70%。

Conclusion: EvoRoute通过自进化的动态路由机制有效解决了智能体系统的三元悖论，在保证性能的同时大幅降低了成本和延迟，为构建经济高效的智能体系统提供了新思路。

Abstract: Complex agentic AI systems, powered by a coordinated ensemble of Large Language Models (LLMs), tool and memory modules, have demonstrated remarkable capabilities on intricate, multi-turn tasks. However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off. We formalize this challenge as the \textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion. To dismantle this trilemma, we introduce EvoRoute, a self-evolving model routing paradigm that transcends static, pre-defined model assignments. Leveraging an ever-expanding knowledge base of prior experience, EvoRoute dynamically selects Pareto-optimal LLM backbones at each step, balancing accuracy, efficiency, and resource use, while continually refining its own selection policy through environment feedback. Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$.

</details>


### [19] [Boosting Accuracy and Interpretability in Multilingual Hate Speech Detection Through Layer Freezing and Explainable AI](https://arxiv.org/abs/2601.02697)
*Meysam Shirdel Bilehsavar,Negin Mahmoudi,Mohammad Jalili Torkamani,Kiana Kiashemshaki*

Main category: cs.CL

TL;DR: 本研究评估了三种基于Transformer的模型（BERT-base-multilingual-cased、RoBERTa-base和XLM-RoBERTa-base）在五种语言上的情感分析和仇恨言论检测性能，并集成LIME框架提高模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 情感分析和仇恨言论检测对于在线内容审核至关重要，能够检测和缓解有害或冒犯性内容，从而为创建更安全的数字环境做出贡献。当前需要提高多语言环境下这些任务的性能和透明度。

Method: 研究比较了三种Transformer模型：BERT-base-multilingual-cased、RoBERTa-base和XLM-RoBERTa-base（前八层冻结），在英语、韩语、日语、中文和法语五种语言上进行评估。使用准确率、精确率、召回率和F1分数等标准指标，并集成LIME框架进行可解释性分析。

Result: 论文未提供具体的性能结果数据，但描述了通过结合先进的Transformer架构和可解释性技术，旨在提高多语言情感分析和仇恨言论检测系统的有效性和透明度。

Conclusion: 通过将最先进的Transformer架构与可解释性技术相结合，本研究旨在提高多语言情感分析和仇恨言论检测系统的有效性和透明度，为更安全的数字环境做出贡献。

Abstract: Sentiment analysis focuses on identifying the emotional polarity expressed in textual data, typically categorized as positive, negative, or neutral. Hate speech detection, on the other hand, aims to recognize content that incites violence, discrimination, or hostility toward individuals or groups based on attributes such as race, gender, sexual orientation, or religion. Both tasks play a critical role in online content moderation by enabling the detection and mitigation of harmful or offensive material, thereby contributing to safer digital environments. In this study, we examine the performance of three transformer-based models: BERT-base-multilingual-cased, RoBERTa-base, and XLM-RoBERTa-base with the first eight layers frozen, for multilingual sentiment analysis and hate speech detection. The evaluation is conducted across five languages: English, Korean, Japanese, Chinese, and French. The models are compared using standard performance metrics, including accuracy, precision, recall, and F1-score. To enhance model interpretability and provide deeper insight into prediction behavior, we integrate the Local Interpretable Model-agnostic Explanations (LIME) framework, which highlights the contribution of individual words to the models decisions. By combining state-of-the-art transformer architectures with explainability techniques, this work aims to improve both the effectiveness and transparency of multilingual sentiment analysis and hate speech detection systems.

</details>


### [20] [Adversarial Question Answering Robustness: A Multi-Level Error Analysis and Mitigation Study](https://arxiv.org/abs/2601.02700)
*Agniv Roy Choudhury,Vignesh Ponselvan Rajasingh*

Main category: cs.CL

TL;DR: 本文通过系统实验研究了Transformer模型在AddSent对抗数据集上的鲁棒性，通过多层次错误分析识别主要失败模式，并发现模型规模扩大可消除鲁棒性-准确性权衡，最后提出实体感知对比学习策略显著缩小对抗性能差距。


<details>
  <summary>Details</summary>
Motivation: 尽管问答系统在标准基准测试（如SQuAD）上表现出色，但它们仍然容易受到对抗样本的攻击。本研究旨在探索Transformer模型在AddSent对抗数据集上的对抗鲁棒性，并开发有效的缓解策略。

Method: 1. 在AddSent对抗数据集上进行系统实验，涵盖不同模型规模；2. 使用五种互补的分类方案进行多层次错误分析；3. 系统评估对抗性微调比例；4. 进行数据增强实验；5. 实施三种针对性缓解策略，包括实体感知对比学习。

Result: 1. 识别否定混淆和实体替换为主要失败模式；2. 确定80%干净数据+20%对抗数据为最优微调比例；3. 发现小模型存在容量瓶颈；4. 将模型从ELECTRA-small扩展到ELECTRA-base消除了鲁棒性-准确性权衡，在干净和对抗数据上都取得显著改进；5. 实体感知对比学习表现最佳：在AddSent上达到89.89% EM，在SQuAD上达到90.73% EM，将对抗差距缩小了94.9%。

Conclusion: 这是首个将全面语言学错误分析与NER引导的对比学习相结合用于对抗性QA的研究，表明针对性缓解策略可以使干净和对抗性能达到近乎相等的水平。模型规模扩大和实体感知对比学习是提高对抗鲁棒性的关键因素。

Abstract: Question answering (QA) systems achieve impressive performance on standard benchmarks like SQuAD, but remain vulnerable to adversarial examples. This project investigates the adversarial robustness of transformer models on the AddSent adversarial dataset through systematic experimentation across model scales and targeted mitigation strategies. We perform comprehensive multi-level error analysis using five complementary categorization schemes, identifying negation confusion and entity substitution as the primary failure modes. Through systematic evaluation of adversarial fine-tuning ratios, we identify 80% clean + 20% adversarial data as optimal. Data augmentation experiments reveal a capacity bottleneck in small models. Scaling from ELECTRA-small (14M parameters) to ELECTRA-base (110M parameters) eliminates the robustness-accuracy trade-off, achieving substantial improvements on both clean and adversarial data. We implement three targeted mitigation strategies, with Entity-Aware contrastive learning achieving best performance: 89.89% AddSent Exact Match (EM) and 90.73% SQuAD EM, representing 94.9% closure of the adversarial gap. To our knowledge, this is the first work integrating comprehensive linguistic error analysis with Named Entity Recognition (NER)-guided contrastive learning for adversarial QA, demonstrating that targeted mitigation can achieve near-parity between clean and adversarial performance.

</details>


### [21] [Mitigating Prompt-Induced Hallucinations in Large Language Models via Structured Reasoning](https://arxiv.org/abs/2601.02739)
*Jinbo Hao,Kai Yang,Qingzhen Su,Yang Chen,Yifan Li,Chao Jiang*

Main category: cs.CL

TL;DR: 本文提出一种基于代码模块的知识蒸馏链式模型，通过引入代码指导知识图谱探索并将其作为思维链提示的一部分，有效减少大语言模型的提示诱导幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在幻觉问题，特别是在提示诱导下容易产生不准确的信息。现有方法在知识表示和推理约束方面仍有改进空间，需要更结构化的外部知识输入来提升推理准确性。

Method: 基于知识蒸馏链式模型，引入代码模块指导知识图谱探索，将代码作为思维链提示的一部分，形成结构化外部知识输入。开发改进的知识蒸馏链式模型来分析和约束LLMs的推理过程。

Result: 在GPT-4和LLaMA-3.3上的实验显示，代码模块显著提升了模型捕获上下文信息的能力，有效缓解提示诱导幻觉。HIT@1、HIT@3、HIT@5分别提升15.64%、13.38%、13.28%，多个评估设置下HIT@1、HIT@3、HIT@5分数超过95%。

Conclusion: 提出的方法显著减少了大语言模型的幻觉行为，同时提升了模型的准确性和可验证性，代码模块的引入为缓解LLM幻觉问题提供了有效途径。

Abstract: To address hallucination issues in large language models (LLMs), this paper proposes a method for mitigating prompt-induced hallucinations. Building on a knowledge distillation chain-style model, we introduce a code module to guide knowledge-graph exploration and incorporate code as part of the chain-of-thought prompt, forming an external knowledge input that provides more accurate and structured information to the model. Based on this design, we develop an improved knowledge distillation chain-style model and leverage it to analyze and constrain the reasoning process of LLMs, thereby improving inference accuracy. We empirically evaluate the proposed approach using GPT-4 and LLaMA-3.3 on multiple public datasets. Experimental results demonstrate that incorporating code modules significantly enhances the model's ability to capture contextual information and effectively mitigates prompt-induced hallucinations. Specifically, HIT@1, HIT@3, and HIT@5 improve by 15.64%, 13.38%, and 13.28%, respectively. Moreover, the proposed method achieves HIT@1, HIT@3, and HIT@5 scores exceeding 95% across several evaluation settings. These results indicate that the proposed approach substantially reduces hallucination behavior while improving the accuracy and verifiability of large language models.

</details>


### [22] [Language Hierarchization Provides the Optimal Solution to Human Working Memory Limits](https://arxiv.org/abs/2601.02740)
*Luyao Chen,Weibo Gao,Junjie Wu,Jinshan Wu,Angela D. Friederici*

Main category: cs.CL

TL;DR: 该研究通过计算模拟和自然语言验证，发现层级处理比线性处理更能有效约束语言处理中的单元数量，使其符合人类工作记忆容量限制，从而解释了人类语言普遍具有层级结构的原因。


<details>
  <summary>Details</summary>
Motivation: 人类语言具有独特的层级结构，但为什么语言是层级的？本研究旨在探究层级结构是否与人类有限的工作记忆容量有关，以及层级处理是否能优化语言处理效率。

Method: 建立了量化语言处理机制中平均单元数与人类工作记忆容量匹配程度的似然函数，通过计算模拟符号序列和验证自然语言句子，比较层级处理与线性处理在约束单元数量方面的表现。

Result: 层级处理在约束θ_MLE值（最大似然估计的单元平均数）方面远优于线性处理，能更好地符合人类工作记忆容量限制，且随着序列/句子长度增加，这种优势更加明显。结果还显示出与儿童工作记忆发展相关的收敛模式。

Conclusion: 构建层级结构能优化序列语言输入的处理效率，同时保持在记忆约束范围内，这真正解释了人类语言普遍具有层级性质的原因。

Abstract: Language is a uniquely human trait, conveying information efficiently by organizing word sequences in sentences into hierarchical structures. A central question persists: Why is human language hierarchical? In this study, we show that hierarchization optimally solves the challenge of our limited working memory capacity. We established a likelihood function that quantifies how well the average number of units according to the language processing mechanisms aligns with human working memory capacity (WMC) in a direct fashion. The maximum likelihood estimate (MLE) of this function, tehta_MLE, turns out to be the mean of units. Through computational simulations of symbol sequences and validation analyses of natural language sentences, we uncover that compared to linear processing, hierarchical processing far surpasses it in constraining the tehta_MLE values under the human WMC limit, along with the increase of sequence/sentence length successfully. It also shows a converging pattern related to children's WMC development. These results suggest that constructing hierarchical structures optimizes the processing efficiency of sequential language input while staying within memory constraints, genuinely explaining the universal hierarchical nature of human language.

</details>


### [23] [SYNAPSE: Empowering LLM Agents with Episodic-Semantic Memory via Spreading Activation](https://arxiv.org/abs/2601.02744)
*Hanqi Jiang,Junhao Chen,Yi Pan,Ling Chen,Weihang You,Yifan Zhou,Ruidong Zhang,Yohannes Abate,Tianming Liu*

Main category: cs.CL

TL;DR: Synapse是一个基于认知科学的动态记忆架构，通过激活扩散而非静态向量相似性来提升LLM的长期记忆能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标准检索增强方法无法解决长期智能体记忆的割裂性问题，需要超越静态向量相似性的统一记忆架构。

Method: 提出Synapse架构，将记忆建模为动态图，通过激活扩散、侧向抑制和时间衰减来动态突出相关子图；实现三元混合检索策略，融合几何嵌入和基于激活的图遍历。

Result: 在LoCoMo基准测试中，Synapse在复杂时序和多跳推理任务上显著优于现有最先进方法，有效解决了"上下文隧道"问题。

Conclusion: Synapse为LLM的长期记忆问题提供了稳健解决方案，代码和数据将在接受后公开。

Abstract: While Large Language Models (LLMs) excel at generalized reasoning, standard retrieval-augmented approaches fail to address the disconnected nature of long-term agentic memory. To bridge this gap, we introduce Synapse (Synergistic Associative Processing Semantic Encoding), a unified memory architecture that transcends static vector similarity. Drawing from cognitive science, Synapse models memory as a dynamic graph where relevance emerges from spreading activation rather than pre-computed links. By integrating lateral inhibition and temporal decay, the system dynamically highlights relevant sub-graphs while filtering interference. We implement a Triple Hybrid Retrieval strategy that fuses geometric embeddings with activation-based graph traversal. Comprehensive evaluations on the LoCoMo benchmark show that Synapse significantly outperforms state-of-the-art methods in complex temporal and multi-hop reasoning tasks, offering a robust solution to the "Contextual Tunneling" problem. Our code and data will be made publicly available upon acceptance.

</details>


### [24] [Window-based Membership Inference Attacks Against Fine-tuned Large Language Models](https://arxiv.org/abs/2601.02751)
*Yuetian Chen,Yuntao Du,Kaiyuan Zhang,Ashish Kundu,Charles Fleming,Bruno Ribeiro,Ninghui Li*

Main category: cs.CL

TL;DR: WBC是一种针对大语言模型的新型成员推理攻击方法，通过滑动窗口局部比较损失信号，显著提升了攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型成员推理攻击主要依赖全局信号（如平均损失），这会稀释记忆化的局部细微信号，降低攻击效果。作者挑战这种全局平均范式，认为成员信号在局部上下文中更加明显。

Method: 提出WBC（基于窗口的比较）方法，采用滑动窗口和基于符号的聚合策略。该方法在不同大小的滑动窗口上比较目标模型和参考模型的损失，每个窗口基于损失比较对成员关系进行二元投票。通过几何间隔的窗口大小进行投票集成，捕捉从词元级到短语级的记忆化模式。

Result: 在11个数据集上的实验表明，WBC显著优于现有基线方法，获得更高的AUC分数，在低误报率阈值下检测率提高了2-3倍。

Conclusion: 聚合局部证据比全局平均更有效，暴露了微调大语言模型中的关键隐私漏洞。局部化方法为成员推理攻击提供了更有效的范式。

Abstract: Most membership inference attacks (MIAs) against Large Language Models (LLMs) rely on global signals, like average loss, to identify training data. This approach, however, dilutes the subtle, localized signals of memorization, reducing attack effectiveness. We challenge this global-averaging paradigm, positing that membership signals are more pronounced within localized contexts. We introduce WBC (Window-Based Comparison), which exploits this insight through a sliding window approach with sign-based aggregation. Our method slides windows of varying sizes across text sequences, with each window casting a binary vote on membership based on loss comparisons between target and reference models. By ensembling votes across geometrically spaced window sizes, we capture memorization patterns from token-level artifacts to phrase-level structures. Extensive experiments across eleven datasets demonstrate that WBC substantially outperforms established baselines, achieving higher AUC scores and 2-3 times improvements in detection rates at low false positive thresholds. Our findings reveal that aggregating localized evidence is fundamentally more effective than global averaging, exposing critical privacy vulnerabilities in fine-tuned LLMs.

</details>


### [25] [EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce](https://arxiv.org/abs/2601.02752)
*Kaiyan Zhao,Zijie Meng,Zheyong Xie,Jin Duan,Yao Hu,Zuozhu Liu,Shaosheng Cao*

Main category: cs.CL

TL;DR: EComStage：一个用于评估LLM智能体在电子商务中分阶段推理过程的统一基准，涵盖感知、规划和行动三个阶段，包含7个代表性任务，评估了30多个模型，揭示了阶段和场景特定的优劣势。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估智能体是否成功完成最终任务，忽视了中间推理阶段对有效决策的重要性。需要一个新的基准来全面评估LLM智能体在电子商务场景中的分阶段推理能力。

Method: 提出EComStage基准，包含感知（理解用户意图）、规划（制定行动计划）和行动（执行决策）三个阶段。包含7个代表性电子商务任务，涵盖客户导向和商家导向场景，所有样本经过人工标注和质量检查。

Result: 评估了30多个LLM（1B到200B+参数，包括开源和闭源模型），揭示了不同阶段和场景导向下的特定优势和弱点，为实际应用提供了细粒度见解。

Conclusion: EComStage提供了对LLM智能体在电子商务中推理能力的全面评估框架，为设计和优化实际应用中的LLM智能体提供了可操作的见解。

Abstract: Large Language Model (LLM)-based agents are increasingly deployed in e-commerce applications to assist customer services in tasks such as product inquiries, recommendations, and order management. Existing benchmarks primarily evaluate whether these agents successfully complete the final task, overlooking the intermediate reasoning stages that are crucial for effective decision-making. To address this gap, we propose EComStage, a unified benchmark for evaluating agent-capable LLMs across the comprehensive stage-wise reasoning process: Perception (understanding user intent), Planning (formulating an action plan), and Action (executing the decision). EComStage evaluates LLMs through seven separate representative tasks spanning diverse e-commerce scenarios, with all samples human-annotated and quality-checked. Unlike prior benchmarks that focus only on customer-oriented interactions, EComStage also evaluates merchant-oriented scenarios, including promotion management, content review, and operational support relevant to real-world applications. We evaluate a wide range of over 30 LLMs, spanning from 1B to over 200B parameters, including open-source models and closed-source APIs, revealing stage/orientation- specific strengths and weaknesses. Our results provide fine-grained, actionable insights for designing and optimizing LLM-based agents in real-world e-commerce settings.

</details>


### [26] [MiMo-V2-Flash Technical Report](https://arxiv.org/abs/2601.02780)
*Bangjun Xiao,Bingquan Xia,Bo Yang,Bofei Gao,Bowen Shen,Chen Zhang,Chenhong He,Chiheng Lou,Fuli Luo,Gang Wang,Gang Xie,Hailin Zhang,Hanglong Lv,Hanyu Li,Heyu Chen,Hongshen Xu,Houbin Zhang,Huaqiu Liu,Jiangshan Duo,Jianyu Wei,Jiebao Xiao,Jinhao Dong,Jun Shi,Junhao Hu,Kainan Bao,Kang Zhou,Lei Li,Liang Zhao,Linghao Zhang,Peidian Li,Qianli Chen,Shaohui Liu,Shihua Yu,Shijie Cao,Shimao Chen,Shouqiu Yu,Shuo Liu,Tianling Zhou,Weijiang Su,Weikun Wang,Wenhan Ma,Xiangwei Deng,Bohan Mao,Bowen Ye,Can Cai,Chenghua Wang,Chengxuan Zhu,Chong Ma,Chun Chen,Chunan Li,Dawei Zhu,Deshan Xiao,Dong Zhang,Duo Zhang,Fangyue Liu,Feiyu Yang,Fengyuan Shi,Guoan Wang,Hao Tian,Hao Wu,Heng Qu,Hongfei Yi,Hongxu An,Hongyi Guan,Xing Zhang,Yifan Song,Yihan Yan,Yihao Zhao,Yingchun Lai,Yizhao Gao,Yu Cheng,Yuanyuan Tian,Yudong Wang,Zhen Tang,Zhengju Tang,Zhengtao Wen,Zhichao Song,Zhixian Zheng,Zihan Jiang,Jian Wen,Jiarui Sun,Jiawei Li,Jinlong Xue,Jun Xia,Kai Fang,Menghang Zhu,Nuo Chen,Qian Tu,Qihao Zhang,Qiying Wang,Rang Li,Rui Ma,Shaolei Zhang,Shengfan Wang,Shicheng Li,Shuhao Gu,Shuhuai Ren,Sirui Deng,Tao Guo,Tianyang Lu,Weiji Zhuang,Weikang Zhang,Weimin Xiong,Wenshan Huang,Wenyu Yang,Xin Zhang,Xing Yong,Xu Wang,Xueyang Xie,Yilin Jiang,Yixin Yang,Yongzhe He,Yu Tu,Yuanliang Dong,Yuchen Liu,Yue Ma,Yue Yu,Yuxing Xiang,Zhaojun Huang,Zhenru Lin,Zhipeng Xu,Zhiyang Chen,Zhonghua Deng,Zihan Zhang,Zihao Yue*

Main category: cs.CL

TL;DR: MiMo-V2-Flash是一个309B总参数、15B激活参数的MoE模型，采用混合注意力架构和多令牌预测预训练，通过新颖的多教师策略蒸馏方法实现高效后训练，性能媲美顶级开源模型但参数更少，推理时利用MTP作为草案模型实现加速。


<details>
  <summary>Details</summary>
Motivation: 开发一个既能提供强大推理和代理能力，又能保持高效推理速度的大语言模型。现有顶级模型参数规模庞大，希望在保持性能的同时减少参数使用，并通过创新的训练和推理优化技术实现效率提升。

Method: 1. 采用混合专家架构（309B总参数，15B激活参数）
2. 混合注意力架构：滑动窗口注意力（128令牌窗口）与全局注意力按5:1比例交错
3. 多令牌预测预训练：在27万亿令牌上使用原生32k上下文长度，后扩展到256k
4. 多教师策略蒸馏：使用领域专家教师提供密集令牌级奖励，使学生模型完全掌握教师专业知识

Result: 1. 性能媲美DeepSeek-V3.2和Kimi-K2等顶级开源模型，但总参数分别仅为它们的1/2和1/3
2. 推理优化：通过将MTP作为草案模型进行推测解码，实现最高3.6的接受长度和2.6倍解码加速（使用三层MTP）
3. 开源模型权重和三层MTP权重以促进社区研究合作

Conclusion: MiMo-V2-Flash通过创新的混合架构、高效训练方法和推理优化技术，实现了参数效率与性能的平衡，为快速强大的推理和代理能力提供了有效解决方案，并通过开源促进社区发展。

Abstract: We present MiMo-V2-Flash, a Mixture-of-Experts (MoE) model with 309B total parameters and 15B active parameters, designed for fast, strong reasoning and agentic capabilities. MiMo-V2-Flash adopts a hybrid attention architecture that interleaves Sliding Window Attention (SWA) with global attention, with a 128-token sliding window under a 5:1 hybrid ratio. The model is pre-trained on 27 trillion tokens with Multi-Token Prediction (MTP), employing a native 32k context length and subsequently extended to 256k. To efficiently scale post-training compute, MiMo-V2-Flash introduces a novel Multi-Teacher On-Policy Distillation (MOPD) paradigm. In this framework, domain-specialized teachers (e.g., trained via large-scale reinforcement learning) provide dense and token-level reward, enabling the student model to perfectly master teacher expertise. MiMo-V2-Flash rivals top-tier open-weight models such as DeepSeek-V3.2 and Kimi-K2, despite using only 1/2 and 1/3 of their total parameters, respectively. During inference, by repurposing MTP as a draft model for speculative decoding, MiMo-V2-Flash achieves up to 3.6 acceptance length and 2.6x decoding speedup with three MTP layers. We open-source both the model weights and the three-layer MTP weights to foster open research and community collaboration.

</details>


### [27] [Punctuation-aware Hybrid Trainable Sparse Attention for Large Language Models](https://arxiv.org/abs/2601.02819)
*Junxiang Qiu,Shuo Wang,Zhengsu Chen,Hengheng Zhang,Jinda Lu,Changcheng Li,Qi Tian*

Main category: cs.CL

TL;DR: PHSA是一种基于标点符号的混合稀疏注意力机制，通过标点作为语义边界锚点，在保持计算效率的同时减少信息损失，显著优于密集注意力和现有稀疏注意力方法。


<details>
  <summary>Details</summary>
Motivation: 密集注意力因二次复杂度难以处理长序列，现有稀疏注意力方法使用粗粒度语义表示进行块选择，会模糊块内语义边界并丢失关键信息。

Method: 提出标点感知混合稀疏注意力(PHSA)：1)设计双分支聚合机制，融合全局语义表示和标点增强的边界特征；2)引入极端稀疏自适应训练和推理策略，稳定低令牌激活率下的模型行为。

Result: 在通用基准和长上下文评估中，PHSA持续优于密集注意力和最先进的稀疏注意力基线。对于0.6B参数模型和32k令牌输入序列，在97.3%稀疏比下能将信息损失减少10.8%。

Conclusion: PHSA通过利用标点作为语义边界锚点，有效解决了现有稀疏注意力方法的局限性，在保持计算效率的同时显著减少了信息损失，为长上下文建模提供了更优的解决方案。

Abstract: Attention serves as the fundamental mechanism for long-context modeling in large language models (LLMs), yet dense attention becomes structurally prohibitive for long sequences due to its quadratic complexity. Consequently, sparse attention has received increasing attention as a scalable alternative. However, existing sparse attention methods rely on coarse-grained semantic representations during block selection, which blur intra-block semantic boundaries and lead to the loss of critical information. To address this issue, we propose \textbf{P}unctuation-aware \textbf{H}ybrid \textbf{S}parse \textbf{A}ttention \textbf{(PHSA)}, a natively trainable sparse attention framework that leverages punctuation tokens as semantic boundary anchors. Specifically, (1) we design a dual-branch aggregation mechanism that fuses global semantic representations with punctuation-enhanced boundary features, preserving the core semantic structure while introducing almost no additional computational overhead; (2) we introduce an extreme-sparsity-adaptive training and inference strategy that stabilizes model behavior under very low token activation ratios; Extensive experiments on general benchmarks and long-context evaluations demonstrate that PHSA consistently outperforms dense attention and state-of-the-art sparse attention baselines, including InfLLM v2. Specifically, for the 0.6B-parameter model with 32k-token input sequences, PHSA can reduce the information loss by 10.8\% at a sparsity ratio of 97.3\%.

</details>


### [28] [The performances of the Chinese and U.S. Large Language Models on the Topic of Chinese Culture](https://arxiv.org/abs/2601.02830)
*Feiyan Liu,Chenxun Zhuo,Siyan Zhao,Bao Ge,Tianming Liu*

Main category: cs.CL

TL;DR: 中美开发的大语言模型在中文文化理解任务上存在差异，中国模型表现更优


<details>
  <summary>Details</summary>
Motivation: 研究中美两国开发的大语言模型在中文环境下是否表现出文化差异，特别是对中国文化的理解能力

Method: 采用直接提问范式，评估GPT-5.1、DeepSeek-V3.2、Qwen3-Max、Gemini2.5Pro等模型对中国传统文化（历史、文学、诗歌等）的理解能力

Result: 中国开发的模型在中文文化任务上普遍优于美国开发的模型；美国模型中Gemini 2.5Pro和GPT-5.1表现相对较好

Conclusion: 性能差异可能源于训练数据分布、本地化策略以及开发过程中对中国文化内容的重视程度不同

Abstract: Cultural backgrounds shape individuals' perspectives and approaches to problem-solving. Since the emergence of GPT-1 in 2018, large language models (LLMs) have undergone rapid development. To date, the world's ten leading LLM developers are primarily based in China and the United States. To examine whether LLMs released by Chinese and U.S. developers exhibit cultural differences in Chinese-language settings, we evaluate their performance on questions about Chinese culture. This study adopts a direct-questioning paradigm to evaluate models such as GPT-5.1, DeepSeek-V3.2, Qwen3-Max, and Gemini2.5Pro. We assess their understanding of traditional Chinese culture, including history, literature, poetry, and related domains. Comparative analyses between LLMs developed in China and the U.S. indicate that Chinese models generally outperform their U.S. counterparts on these tasks. Among U.S.-developed models, Gemini 2.5Pro and GPT-5.1 achieve relatively higher accuracy. The observed performance differences may potentially arise from variations in training data distribution, localization strategies, and the degree of emphasis on Chinese cultural content during model development.

</details>


### [29] [TiMem: Temporal-Hierarchical Memory Consolidation for Long-Horizon Conversational Agents](https://arxiv.org/abs/2601.02845)
*Kai Li,Xuanqing Yu,Ziyi Ni,Yi Zeng,Yao Xu,Zheqing Zhang,Xin Li,Jitao Sang,Xiaogang Duan,Xuelei Wang,Chengbao Liu,Jie Tan*

Main category: cs.CL

TL;DR: TiMem是一个用于长对话智能体的时序-层次化记忆框架，通过时序记忆树组织对话，实现从原始观察到抽象人格表征的系统记忆整合，在保持准确性的同时显著减少回忆长度。


<details>
  <summary>Details</summary>
Motivation: 现有记忆框架在处理长对话时面临有限上下文窗口的问题，对时序结构化信息的支持有限，导致记忆碎片化和长时程个性化不稳定。需要一种能有效组织长时程对话记忆的方法。

Method: 提出TiMem框架，核心是时序记忆树(TMT)，具备三个关键特性：1) 通过TMT实现时序-层次化组织；2) 语义引导的记忆整合，无需微调即可跨层次整合记忆；3) 复杂度感知的记忆回忆，平衡不同复杂度查询的精度和效率。

Result: 在一致的评估设置下，TiMem在两个基准测试中达到最先进准确率：LoCoMo上75.30%，LongMemEval-S上76.88%。相比基线方法显著提升，同时在LoCoMo上减少52.20%的回忆长度。流形分析显示在LoCoMo上人格分离清晰，在LongMemEval-S上分散度降低。

Conclusion: TiMem将时序连续性作为长对话智能体记忆的首要组织原则，通过时序-层次化框架有效解决了长时程记忆管理的挑战，在保持高性能的同时显著提升了记忆效率。

Abstract: Long-horizon conversational agents have to manage ever-growing interaction histories that quickly exceed the finite context windows of large language models (LLMs). Existing memory frameworks provide limited support for temporally structured information across hierarchical levels, often leading to fragmented memories and unstable long-horizon personalization. We present TiMem, a temporal--hierarchical memory framework that organizes conversations through a Temporal Memory Tree (TMT), enabling systematic memory consolidation from raw conversational observations to progressively abstracted persona representations. TiMem is characterized by three core properties: (1) temporal--hierarchical organization through TMT; (2) semantic-guided consolidation that enables memory integration across hierarchical levels without fine-tuning; and (3) complexity-aware memory recall that balances precision and efficiency across queries of varying complexity. Under a consistent evaluation setup, TiMem achieves state-of-the-art accuracy on both benchmarks, reaching 75.30% on LoCoMo and 76.88% on LongMemEval-S. It outperforms all evaluated baselines while reducing the recalled memory length by 52.20% on LoCoMo. Manifold analysis indicates clear persona separation on LoCoMo and reduced dispersion on LongMemEval-S. Overall, TiMem treats temporal continuity as a first-class organizing principle for long-horizon memory in conversational agents.

</details>


### [30] [To Generate or Discriminate? Methodological Considerations for Measuring Cultural Alignment in LLMs](https://arxiv.org/abs/2601.02858)
*Saurabh Kumar Pandey,Sougata Saha,Monojit Choudhury*

Main category: cs.CL

TL;DR: 该研究通过逆向社会人口统计学提示（ISDP）评估LLMs的文化能力，发现与SDP方法相比，LLMs在实际用户行为上的表现优于模拟行为，但在个体层面的表现趋于一致，揭示了个人化的局限性。


<details>
  <summary>Details</summary>
Motivation: 社会人口统计学提示（SDP）虽然能评估LLMs的文化能力，但容易受到提示敏感性、解码参数和生成任务复杂度等混杂因素影响，导致难以区分性能不佳是由于模型偏见还是任务设计问题。

Method: 使用逆向社会人口统计学提示（ISDP），让LLMs根据实际和模拟的用户行为来判别和预测人口统计学特征。使用Goodreads-CSI数据集（包含印度、墨西哥和美国用户对英文书评的理解难度数据），测试了Aya-23、Gemma-2、GPT-4o和LLaMA-3.1四个LLMs。

Result: 1. 模型在实际用户行为上的表现优于模拟行为，这与SDP方法的结果相反。2. 在个体层面，两种行为类型的表现都下降且趋于接近，表明个人化存在局限性。

Conclusion: ISDP提供了一种更可靠的评估LLMs文化能力的方法，揭示了SDP方法可能高估了模型偏见，同时表明当前LLMs在个体层面的文化适应能力有限。

Abstract: Socio-demographic prompting (SDP) - prompting Large Language Models (LLMs) using demographic proxies to generate culturally aligned outputs - often shows LLM responses as stereotypical and biased. While effective in assessing LLMs' cultural competency, SDP is prone to confounding factors such as prompt sensitivity, decoding parameters, and the inherent difficulty of generation over discrimination tasks due to larger output spaces. These factors complicate interpretation, making it difficult to determine if the poor performance is due to bias or the task design. To address this, we use inverse socio-demographic prompting (ISDP), where we prompt LLMs to discriminate and predict the demographic proxy from actual and simulated user behavior from different users. We use the Goodreads-CSI dataset (Saha et al., 2025), which captures difficulty in understanding English book reviews for users from India, Mexico, and the USA, and test four LLMs: Aya-23, Gemma-2, GPT-4o, and LLaMA-3.1 with ISDP. Results show that models perform better with actual behaviors than simulated ones, contrary to what SDP suggests. However, performance with both behavior types diminishes and becomes nearly equal at the individual level, indicating limits to personalization.

</details>


### [31] [Training Language Models with homotokens Leads to Delayed Overfitting](https://arxiv.org/abs/2601.02867)
*Adrian Cosma,Stefan Ruseti,Emilian Radoi,Mihai Dascalu*

Main category: cs.CL

TL;DR: 本文提出一种名为"同形标记"的数据增强方法，通过利用同一词汇的多种有效子词切分来训练语言模型，提高模型对标记化变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 子词标记化在语言模型中引入了一个计算层，其中许多不同的标记序列可以解码为相同的表面形式并保留含义，但会引发不同的内部计算。尽管存在这种非唯一性，语言模型通常只使用单一的最长前缀标记化进行训练，这限制了模型对标记化变化的适应能力。

Method: 1. 形式化定义"同形标记"——同一词汇项的有效子词切分的替代方案；2. 提出轻量级训练架构，通过辅助因果编码器和块因果交叉注意力，在规范的下一个标记预测基础上对采样的同形标记变体进行条件化；3. 不修改训练目标或标记接口。

Result: 1. 在数据受限的预训练中，同形标记增强持续延迟了重复数据暴露下的过拟合，并提高了跨多种评估数据集的泛化能力；2. 在多语言微调中，同形标记的有效性取决于标记器质量：当规范标记高度压缩时增益最强，而当标记器已经过度分割输入时增益减弱。

Conclusion: 同形标记为在语言模型中诱导标记化不变性提供了一种简单且模块化的机制，能够提高模型对标记化变化的鲁棒性，特别是在数据受限和标记器质量参差不齐的情况下。

Abstract: Subword tokenization introduces a computational layer in language models where many distinct token sequences decode to the same surface form and preserve meaning, yet induce different internal computations. Despite this non-uniqueness, language models are typically trained using a single canonical longest-prefix tokenization. We formalize homotokens-alternative valid subword segmentations of the same lexical item-as a strictly meaning-preserving form of data augmentation. We introduce a lightweight training architecture that conditions canonical next-token prediction on sampled homotoken variants via an auxiliary causal encoder and block-causal cross-attention, without modifying the training objective or token interface. In data-constrained pretraining, homotoken augmentation consistently delays overfitting under repeated data exposure and improves generalization across diverse evaluation datasets. In multilingual fine-tuning, we find that the effectiveness of homotokens depends on tokenizer quality: gains are strongest when canonical tokens are highly compressed and diminish when the tokenizer already over-fragments the input. Overall, homotokens provide a simple and modular mechanism for inducing tokenization invariance in language models.

</details>


### [32] [LongBench Pro: A More Realistic and Comprehensive Bilingual Long-Context Evaluation Benchmark](https://arxiv.org/abs/2601.02872)
*Ziyang Chen,Xing Wu,Junlong Jia,Chaochen Gao,Qi Fu,Debing Zhang,Songlin Hu*

Main category: cs.CL

TL;DR: LongBench Pro是一个双语长上下文基准测试，包含1500个自然长上下文样本，支持8k-256k token长度，通过人机协作构建，评估发现长上下文优化比参数扩展更重要。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文基准测试存在可扩展性和真实性的权衡：合成任务无法反映真实世界复杂性，而完全人工标注又成本过高，难以扩展到极端长度和多样场景。

Method: 提出人机协作构建流程：前沿LLM生成具有挑战性的问题和参考答案，包括设计原理和解题过程，专家随后验证正确性并修正问题案例。构建了包含1500个自然长上下文样本的双语基准，涵盖11个主要任务和25个次要任务。

Result: 评估46个广泛使用的长上下文LLM发现：(1)长上下文优化对理解能力的贡献大于参数扩展；(2)有效上下文长度通常短于宣称长度，存在明显的跨语言不对齐；(3)"思考"范式主要帮助原生推理训练的模型，而混合思考设计提供了有前景的帕累托权衡。

Conclusion: LongBench Pro为推进长上下文理解提供了稳健的测试平台，其人机协作构建方法平衡了质量与可扩展性，揭示了当前长上下文模型的关键特征和局限性。

Abstract: The rapid expansion of context length in large language models (LLMs) has outpaced existing evaluation benchmarks. Current long-context benchmarks often trade off scalability and realism: synthetic tasks underrepresent real-world complexity, while fully manual annotation is costly to scale to extreme lengths and diverse scenarios. We present LongBench Pro, a more realistic and comprehensive bilingual benchmark of 1,500 naturally occurring long-context samples in English and Chinese spanning 11 primary tasks and 25 secondary tasks, with input lengths from 8k to 256k tokens. LongBench Pro supports fine-grained analysis with task-specific metrics and a multi-dimensional taxonomy of context requirement (full vs. partial dependency), length (six levels), and difficulty (four levels calibrated by model performance). To balance quality with scalability, we propose a Human-Model Collaborative Construction pipeline: frontier LLMs draft challenging questions and reference answers, along with design rationales and solution processes, to reduce the cost of expert verification. Experts then rigorously validate correctness and refine problematic cases. Evaluating 46 widely used long-context LLMs on LongBench Pro yields three findings: (1) long-context optimization contributes more to long-context comprehension than parameter scaling; (2) effective context length is typically shorter than the claimed context length, with pronounced cross-lingual misalignment; and (3) the "thinking" paradigm helps primarily models trained with native reasoning, while mixed-thinking designs offer a promising Pareto trade-off. In summary, LongBench Pro provides a robust testbed for advancing long-context understanding.

</details>


### [33] [Revisiting Data Compression with Language Modeling](https://arxiv.org/abs/2601.02875)
*Chen-Han Tsai*

Main category: cs.CL

TL;DR: 大型语言模型在数据压缩任务中的应用研究，在enwik9数据集上实现了18%的调整压缩率，并探索了在多语言、代码和字节流序列压缩中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管先前研究表明LLM在文本和多模态数据压缩中表现出色，但仍存在实际挑战阻碍其替代现有压缩算法。本研究旨在探索降低调整压缩率的方法，并验证LLM在非英语数据、代码数据和字节流序列压缩中的能力。

Method: 探索了多种使用LLM作为数据压缩器的方法，无需额外模型训练，重点优化调整压缩率。对非英语数据、代码数据和字节流序列进行了专门配置和测试。

Result: 在enwik9数据集上实现了约18%的调整压缩率，创下新的SOTA记录。LLM在文本主导领域表现出色，但在非自然文本序列压缩中，通过适当配置仍能保持竞争力。

Conclusion: LLM作为数据压缩器具有巨大潜力，特别是在文本领域。虽然在实际应用中仍面临挑战，但通过合适的配置和优化，LLM能够在多种数据类型上实现有竞争力的压缩性能。

Abstract: In this report, we investigate the potential use of large language models (LLM's) in the task of data compression. Previous works have demonstrated promising results in applying LLM's towards compressing not only text, but also a wide range of multi-modal data. Despite the favorable performance achieved, there still remains several practical questions that pose a challenge towards replacing existing data compression algorithms with LLM's. In this work, we explore different methods to achieve a lower adjusted compression rate using LLM's as data compressors. In comparison to previous works, we were able to achieve a new state-of-the-art (SOTA) adjusted compression rate of around $18\%$ on the enwik9 dataset without additional model training. Furthermore, we explore the use of LLM's in compressing non-English data, code data, byte stream sequences. We show that while LLM's excel in compressing data in text-dominant domains, their ability in compressing non-natural text sequences still remain competitive if configured in the right way.

</details>


### [34] [Transparent Semantic Change Detection with Dependency-Based Profiles](https://arxiv.org/abs/2601.02891)
*Bach Phan-Tat,Kris Heylen,Dirk Geeraerts,Stefano De Pascale,Dirk Speelman*

Main category: cs.CL

TL;DR: 提出一种基于依存共现模式的语义变化检测方法，在性能上优于多种分布语义模型，且结果更可解释。


<details>
  <summary>Details</summary>
Motivation: 当前基于嵌入的分布语义模型在语义变化检测中表现良好但缺乏可解释性，需要更透明的方法。

Method: 采用纯依赖依存共现模式的方法，通过分析词汇在句法结构中的共现关系来检测语义变化。

Result: 该方法在语义变化检测任务中表现有效，甚至优于多种分布语义模型，预测结果合理且可解释。

Conclusion: 依存共现模式为语义变化检测提供了有效的替代方案，在保持性能的同时增强了可解释性。

Abstract: Most modern computational approaches to lexical semantic change detection (LSC) rely on embedding-based distributional word representations with neural networks. Despite the strong performance on LSC benchmarks, they are often opaque. We investigate an alternative method which relies purely on dependency co-occurrence patterns of words. We demonstrate that it is effective for semantic change detection and even outperforms a number of distributional semantic models. We provide an in-depth quantitative and qualitative analysis of the predictions, showing that they are plausible and interpretable.

</details>


### [35] [Linear Script Representations in Speech Foundation Models Enable Zero-Shot Transliteration](https://arxiv.org/abs/2601.02906)
*Ryan Soh-Eun Shim,Kwanghee Choi,Kalvin Chang,Ming-Hao Hsu,Florian Eichin,Zhizheng Wu,Alane Suhr,Michael A. Hedderich,David Harwath,David R. Mortensen,Barbara Plank*

Main category: cs.CL

TL;DR: 研究发现多语言语音模型中脚本信息线性编码于激活空间，通过修改推理时的激活向量可直接控制输出脚本，实现了语音识别输出的后处理脚本控制。


<details>
  <summary>Details</summary>
Motivation: 多语言语音基础模型（如Whisper）在网页规模数据上训练，每种语言包含多种区域变体。不同区域变体常使用不同文字书写同一语言，导致语音识别输出存在脚本不确定性。需要解决这种输出脚本的非确定性。

Method: 研究发现脚本信息在多语言语音模型的激活空间中呈线性编码，通过在推理时修改激活向量可直接控制输出脚本。该方法通过添加脚本向量到激活空间，即使在不常规的语言-脚本配对情况下也能诱导脚本变化。

Result: 该方法在语音识别输出的后处理脚本控制中表现优异，在Whisper所有模型大小上都展现出竞争力。

Conclusion: 多语言语音模型中脚本信息在激活空间中线性编码，通过修改推理时激活向量可实现输出脚本的直接控制，为语音识别输出提供了有效的脚本控制方法。

Abstract: Multilingual speech foundation models such as Whisper are trained on web-scale data, where data for each language consists of a myriad of regional varieties. However, different regional varieties often employ different scripts to write the same language, rendering speech recognition output also subject to non-determinism in the output script. To mitigate this problem, we show that script is linearly encoded in the activation space of multilingual speech models, and that modifying activations at inference time enables direct control over output script. We find the addition of such script vectors to activations at test time can induce script change even in unconventional language-script pairings (e.g. Italian in Cyrillic and Japanese in Latin script). We apply this approach to inducing post-hoc control over the script of speech recognition output, where we observe competitive performance across all model sizes of Whisper.

</details>


### [36] [Beyond the Black Box: Theory and Mechanism of Large Language Models](https://arxiv.org/abs/2601.02907)
*Zeyu Gan,Ruifeng Ren,Wei Yao,Xiaolin Hu,Gengze Xu,Chen Qian,Huayi Tang,Zixuan Gong,Xinhao Yao,Pengwei Tang,Zhenxing Dou,Yong Liu*

Main category: cs.CL

TL;DR: 这篇综述提出了一个基于生命周期的统一分类法，将大语言模型研究分为六个阶段，系统回顾了支撑LLM性能的基础理论和内部机制，并为LLM开发从工程启发式转向原则性科学学科提供了路线图。


<details>
  <summary>Details</summary>
Motivation: 当前LLM领域存在一个关键悖论：尽管实证效果显著，但我们对LLM的理论理解仍然相对薄弱，导致这些系统在很大程度上被视为"黑箱"。为了解决这种理论碎片化问题，需要建立一个系统性的理论框架。

Method: 提出了一个基于生命周期的统一分类法，将LLM研究组织成六个阶段：数据准备、模型准备、训练、对齐、推理和评估。在该框架下，系统回顾了驱动LLM性能的基础理论和内部机制。

Result: 分析了核心理论问题，如数据混合的数学原理、各种架构的表征极限、对齐算法的优化动态等。识别了前沿挑战，包括合成数据自我改进的理论极限、安全保证的数学边界、涌现智能的机制起源。

Conclusion: 通过将实证观察与严谨科学探究相结合，这项工作为将LLM开发从工程启发式转向原则性科学学科提供了结构化路线图，旨在推动LLM领域从经验主义向理论化发展。

Abstract: The rapid emergence of Large Language Models (LLMs) has precipitated a profound paradigm shift in Artificial Intelligence, delivering monumental engineering successes that increasingly impact modern society. However, a critical paradox persists within the current field: despite the empirical efficacy, our theoretical understanding of LLMs remains disproportionately nascent, forcing these systems to be treated largely as ``black boxes''. To address this theoretical fragmentation, this survey proposes a unified lifecycle-based taxonomy that organizes the research landscape into six distinct stages: Data Preparation, Model Preparation, Training, Alignment, Inference, and Evaluation. Within this framework, we provide a systematic review of the foundational theories and internal mechanisms driving LLM performance. Specifically, we analyze core theoretical issues such as the mathematical justification for data mixtures, the representational limits of various architectures, and the optimization dynamics of alignment algorithms. Moving beyond current best practices, we identify critical frontier challenges, including the theoretical limits of synthetic data self-improvement, the mathematical bounds of safety guarantees, and the mechanistic origins of emergent intelligence. By connecting empirical observations with rigorous scientific inquiry, this work provides a structured roadmap for transitioning LLM development from engineering heuristics toward a principled scientific discipline.

</details>


### [37] [Image, Word and Thought: A More Challenging Language Task for the Iterated Learning Model](https://arxiv.org/abs/2601.02911)
*Hyoyeon Lee,Seth Bullock,Conor Houghton*

Main category: cs.CL

TL;DR: 迭代学习模型成功应用于七段显示图像的复杂意义通信任务，代理能够学习并传递具有表达性、组合性和稳定性的语言。


<details>
  <summary>Details</summary>
Motivation: 探索语言传递约束如何促进语言结构的涌现，特别是针对更复杂意义（七段显示图像）的语言学习任务。

Method: 采用半监督迭代学习模型，结合监督学习和无监督学习，使用自编码器架构，应用于七段显示图像的通信任务。

Result: 代理能够学习并传递表达性语言（128种字形使用不同编码）、组合性语言（信号成分一致映射到意义成分）和稳定性语言（代际间语言不发生变化）。

Conclusion: 迭代学习模型成功扩展到复杂意义通信任务，验证了语言传递约束能够促进表达性、组合性和稳定性语言结构的涌现。

Abstract: The iterated learning model simulates the transmission of language from generation to generation in order to explore how the constraints imposed by language transmission facilitate the emergence of language structure. Despite each modelled language learner starting from a blank slate, the presence of a bottleneck limiting the number of utterances to which the learner is exposed can lead to the emergence of language that lacks ambiguity, is governed by grammatical rules, and is consistent over successive generations, that is, one that is expressive, compositional and stable. The recent introduction of a more computationally tractable and ecologically valid semi supervised iterated learning model, combining supervised and unsupervised learning within an autoencoder architecture, has enabled exploration of language transmission dynamics for much larger meaning-signal spaces. Here, for the first time, the model has been successfully applied to a language learning task involving the communication of much more complex meanings: seven-segment display images. Agents in this model are able to learn and transmit a language that is expressive: distinct codes are employed for all 128 glyphs; compositional: signal components consistently map to meaning components, and stable: the language does not change from generation to generation.

</details>


### [38] [RAL2M: Retrieval Augmented Learning-To-Match Against Hallucination in Compliance-Guaranteed Service Systems](https://arxiv.org/abs/2601.02917)
*Mengze Hong,Di Jiang,Jiangtao Wen,Zhiyang Su,Yawen Li,Yanjie Sun,Guan Wang,Chen Jason Zhang*

Main category: cs.CL

TL;DR: RAL2M框架将LLM重新定位为检索系统中的查询-响应匹配判断器，通过查询自适应潜在集成策略缓解判断幻觉，提供了一种替代纯生成方法的稳健方案。


<details>
  <summary>Details</summary>
Motivation: 解决LLM驱动服务系统中的幻觉问题，需要显式知识基础来保证合规性响应。传统生成方法容易产生幻觉，需要更稳健的替代方案。

Method: 提出检索增强学习匹配(RAL2M)框架：1)将LLM重新定位为检索系统中的查询-响应匹配判断器而非生成器；2)提出查询自适应潜在集成策略，显式建模异构模型能力和LLM间的相互依赖关系，获得校准的共识决策。

Result: 在大规模基准测试上的广泛实验表明，该方法有效利用了"群体智慧"，显著优于强基线方法。

Conclusion: RAL2M通过将LLM重新定位为匹配判断器，从根本上消除了生成幻觉，同时通过潜在集成策略缓解判断幻觉，为未来利用潜在表示的研究提供了最佳实践和方向。

Abstract: Hallucination is a major concern in LLM-driven service systems, necessitating explicit knowledge grounding for compliance-guaranteed responses. In this paper, we introduce Retrieval-Augmented Learning-to-Match (RAL2M), a novel framework that eliminates generation hallucination by repositioning LLMs as query-response matching judges within a retrieval-based system, providing a robust alternative to purely generative approaches. To further mitigate judgment hallucination, we propose a query-adaptive latent ensemble strategy that explicitly models heterogeneous model competence and interdependencies among LLMs, deriving a calibrated consensus decision. Extensive experiments on large-scale benchmarks demonstrate that the proposed method effectively leverages the "wisdom of the crowd" and significantly outperforms strong baselines. Finally, we discuss best practices and promising directions for further exploiting latent representations in future work.

</details>


### [39] [Memorization, Emergence, and Explaining Reversal Failures: A Controlled Study of Relational Semantics in LLMs](https://arxiv.org/abs/2601.02931)
*Yihua Zhu,Qianying Liu,Jiaxin Wang,Fei Cheng,Chaoran Liu,Akiko Aizawa,Sadao Kurohashi,Hidetoshi Shimodaira*

Main category: cs.CL

TL;DR: 该论文研究了自回归LLM如何学习关系语义逻辑（对称性和逆逻辑），发现当有足够逻辑监督时，即使在浅层模型中也会出现关系语义的涌现，而反向推理失败主要源于自回归顺序偏差而非语义理解不足。


<details>
  <summary>Details</summary>
Motivation: 自回归LLM在需要连接实体的关系任务上表现良好，但尚不清楚它们是否学习到了关系的逻辑语义（如对称性和逆逻辑），以及反向推理失败是由于缺乏关系语义还是自左向右的顺序偏差导致的。

Method: 提出了一个基于知识图谱的受控合成框架，从对称/逆三元组生成文本，从头训练GPT风格的自回归模型，并评估记忆、逻辑推理和对未见实体的上下文泛化能力。

Result: 研究发现：1）在足够逻辑监督下，即使在浅层（2-3层）模型中也会出现关系语义的涌现；2）成功的泛化与稳定的中间层信号对齐；3）顺序匹配的前向/反向测试和扩散基线表明，反向推理失败主要源于自回归顺序偏差而非逆语义理解不足。

Conclusion: 自回归LLM能够学习关系逻辑语义，但其反向推理失败主要源于模型架构的自回归顺序偏差，而非对关系语义的理解缺陷。这为理解LLM的关系推理能力提供了重要见解。

Abstract: Autoregressive LLMs perform well on relational tasks that require linking entities via relational words (e.g., father/son, friend), but it is unclear whether they learn the logical semantics of such relations (e.g., symmetry and inversion logic) and, if so, whether reversal-type failures arise from missing relational semantics or left-to-right order bias. We propose a controlled Knowledge Graph-based synthetic framework that generates text from symmetric/inverse triples, train GPT-style autoregressive models from scratch, and evaluate memorization, logical inference, and in-context generalization to unseen entities to address these questions. We find a sharp phase transition in which relational semantics emerge with sufficient logic-bearing supervision, even in shallow (2-3 layer) models, and that successful generalization aligns with stable intermediate-layer signals. Finally, order-matched forward/reverse tests and a diffusion baseline indicate that reversal failures are primarily driven by autoregressive order bias rather than deficient inversion semantics.

</details>


### [40] [Pearmut: Human Evaluation of Translation Made Trivial](https://arxiv.org/abs/2601.02933)
*Vilém Zouhar,Tom Kocmi*

Main category: cs.CL

TL;DR: Pearmut是一个轻量级但功能丰富的人类评估平台，旨在使多语言NLP任务的人类评估像自动评估一样简单易行。


<details>
  <summary>Details</summary>
Motivation: 当前多语言NLP领域，人类评估虽然是黄金标准，但由于现有工具设置复杂、工程和操作开销大，实践中常被自动评估替代。需要一种能降低门槛、简化流程的人类评估解决方案。

Method: 开发了Pearmut平台，支持多语言任务评估（特别是机器翻译），实现了标准评估协议（DA、ESA、MQM），同时允许扩展新协议。平台提供文档级上下文、绝对和对比评估、注意力检查、ESAAI预标注以及静态和主动学习分配策略。

Result: Pearmut成功降低了人类评估的进入门槛，使可靠的人类评估成为模型开发和诊断中实用、常规的组成部分，而不再是偶尔为之的工作。

Conclusion: Pearmut平台通过简化设置和操作流程，使人类评估变得切实可行，有望促进更广泛地采用人类评估作为多语言NLP模型开发和诊断的常规实践。

Abstract: Human evaluation is the gold standard for multilingual NLP, but is often skipped in practice and substituted with automatic metrics, because it is notoriously complex and slow to set up with existing tools with substantial engineering and operational overhead. We introduce Pearmut, a lightweight yet feature-rich platform that makes end-to-end human evaluation as easy to run as automatic evaluation. Pearmut removes common entry barriers and provides support for evaluating multilingual tasks, with a particular focus on machine translation. The platform implements standard evaluation protocols, including DA, ESA, or MQM, but is also extensible to allow prototyping new protocols. It features document-level context, absolute and contrastive evaluation, attention checks, ESAAI pre-annotations and both static and active learning-based assignment strategies. Pearmut enables reliable human evaluation to become a practical, routine component of model development and diagnosis rather than an occasional effort.

</details>


### [41] [Enhancing Multilingual RAG Systems with Debiased Language Preference-Guided Query Fusion](https://arxiv.org/abs/2601.02956)
*Jeonghyun Park,Byeongjeong Kim,Seojin Hwang,Hwanhee Lee*

Main category: cs.CL

TL;DR: 该论文提出了一种去偏语言偏好度量DeLP，揭示了mRAG系统中先前报告的英语偏好主要是证据分布偏差而非模型固有偏好，并基于此开发了DELTA框架，利用单语对齐优化跨语言检索和生成。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言检索增强生成(mRAG)系统普遍表现出对英语的偏好，通常采用英语枢纽策略。先前研究将此归因于大语言模型(LLM)的英语中心能力，但作者认为这种测量被评估基准中的结构性先验所扭曲。

Method: 1. 识别了三种评估偏差：曝光偏差、黄金可用性先验（均源于英语资源集中）和文化先验（源于主题局部性）；2. 提出DeLP度量，显式排除这些结构性混杂因素；3. 开发DELTA框架，利用单语对齐优化跨语言检索和生成。

Result: 使用DeLP分析显示，先前报告的英语偏好主要是证据分布的结果而非模型固有偏差；研究发现检索器本质上偏好查询和文档语言之间的单语对齐；DELTA框架在多种语言上持续优于英语枢纽和mRAG基线方法。

Conclusion: mRAG系统中观察到的英语偏好主要是评估基准的结构性偏差所致，而非模型固有倾向。通过去偏评估和利用单语对齐的DELTA框架，可以更有效地实现跨语言检索增强生成。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems often exhibit a perceived preference for high-resource languages, particularly English, resulting in the widespread adoption of English pivoting. While prior studies attribute this advantage to the superior English-centric capabilities of Large Language Models (LLMs), we find that such measurements are significantly distorted by structural priors inherent in evaluation benchmarks. Specifically, we identify exposure bias and a gold availability prior-both driven by the disproportionate concentration of resources in English-as well as cultural priors rooted in topic locality, as factors that hinder accurate assessment of genuine language preference. To address these biases, we propose DeLP (Debiased Language Preference), a calibrated metric designed to explicitly factor out these structural confounds. Our analysis using DeLP reveals that the previously reported English preference is largely a byproduct of evidence distribution rather than an inherent model bias. Instead, we find that retrievers fundamentally favor monolingual alignment between the query and the document language. Building on this insight, we introduce DELTA (DEbiased Language preference-guided Text Augmentation), a lightweight and efficient mRAG framework that strategically leverages monolingual alignment to optimize cross-lingual retrieval and generation. Experimental results demonstrate that DELTA consistently outperforms English pivoting and mRAG baselines across diverse languages.

</details>


### [42] [LLM-Augmented Changepoint Detection: A Framework for Ensemble Detection and Automated Explanation](https://arxiv.org/abs/2601.02957)
*Fabian Lukassen,Christoph Weisser,Michael Schlee,Manish Kumar,Anton Thielmann,Benjamin Saefken,Thomas Kneib*

Main category: cs.CL

TL;DR: 提出结合集成统计方法与大型语言模型的变点检测框架，提升检测准确性和对时序数据中体制变化的可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决当前变点检测领域的两个关键限制：1) 个体检测方法在不同数据特征下表现出互补的优缺点，方法选择困难且容易产生次优结果；2) 缺乏自动化的、情境化的检测变化解释。

Method: 采用集成方法聚合十种不同的变点检测算法结果，结合LLM驱动的解释管道自动生成情境化叙述，并通过检索增强生成(RAG)解决方案支持私有或领域特定数据的解释。

Result: 集成方法相比个体方法展现出优越的性能和鲁棒性，能够将检测到的变点与潜在的现实世界历史事件联系起来，开源Python框架在金融、政治科学和环境科学等多个领域展示了实用价值。

Conclusion: 该框架通过结合集成统计方法和LLM解释能力，将原始统计输出转化为分析师和决策者可操作的情报，提升了变点检测的准确性和可解释性。

Abstract: This paper introduces a novel changepoint detection framework that combines ensemble statistical methods with Large Language Models (LLMs) to enhance both detection accuracy and the interpretability of regime changes in time series data. Two critical limitations in the field are addressed. First, individual detection methods exhibit complementary strengths and weaknesses depending on data characteristics, making method selection non-trivial and prone to suboptimal results. Second, automated, contextual explanations for detected changes are largely absent. The proposed ensemble method aggregates results from ten distinct changepoint detection algorithms, achieving superior performance and robustness compared to individual methods. Additionally, an LLM-powered explanation pipeline automatically generates contextual narratives, linking detected changepoints to potential real-world historical events. For private or domain-specific data, a Retrieval-Augmented Generation (RAG) solution enables explanations grounded in user-provided documents. The open source Python framework demonstrates practical utility in diverse domains, including finance, political science, and environmental science, transforming raw statistical output into actionable insights for analysts and decision-makers.

</details>


### [43] [Low-Resource Heuristics for Bahnaric Optical Character Recognition Improvement](https://arxiv.org/abs/2601.02965)
*Phat Tran,Phuoc Pham,Hung Trinh,Tho Quan*

Main category: cs.CL

TL;DR: 该研究提出结合表格检测与概率后处理的OCR方法，将巴拿语文档识别准确率从72.86%提升至79.26%，为少数民族语言数字化提供框架。


<details>
  <summary>Details</summary>
Motivation: 巴拿语作为越南、柬埔寨、老挝的少数民族语言，面临保存挑战，现有研究不足且数据稀缺。扫描文档的图像质量退化（破损、模糊区域）导致OCR错误严重，影响信息检索系统。

Method: 采用综合方法：1）应用先进的表格和非表格检测技术提升输入数据质量；2）对OCR输出进行基于概率的后处理启发式纠错。

Result: 实验结果显示识别准确率显著提升，从72.86%提高到79.26%，验证了方法的有效性。

Conclusion: 本研究为巴拿语保存提供了宝贵资源，其框架可推广到其他少数民族语言的数字化工作中，解决了文档退化导致的OCR精度问题。

Abstract: Bahnar, a minority language spoken across Vietnam, Cambodia, and Laos, faces significant preservation challenges due to limited research and data availability. This study addresses the critical need for accurate digitization of Bahnar language documents through optical character recognition (OCR) technology. Digitizing scanned paper documents poses significant challenges, as degraded image quality from broken or blurred areas introduces considerable OCR errors that compromise information retrieval systems. We propose a comprehensive approach combining advanced table and non-table detection techniques with probability-based post-processing heuristics to enhance recognition accuracy. Our method first applies detection algorithms to improve input data quality, then employs probabilistic error correction on OCR output. Experimental results indicate a substantial improvement, with recognition accuracy increasing from 72.86% to 79.26%. This work contributes valuable resources for Bahnar language preservation and provides a framework applicable to other minority language digitization efforts.

</details>


### [44] [Reliability-Aware Adaptive Self-Consistency for Efficient Sampling in LLM Reasoning](https://arxiv.org/abs/2601.02970)
*Junseok Kim,Nakyeong Yang,Kyungmin Min,Kyomin Jung*

Main category: cs.CL

TL;DR: ReASC通过基于证据充分性的自适应采样策略，结合响应频率和置信度，显著降低推理成本的同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的自适应自洽性方法虽然通过调整采样预算来降低推理成本，但它们依赖基于计数的停止规则，将所有响应同等对待，这往往导致不必要的采样。

Method: 提出可靠性感知自适应自洽性（ReASC），包含两个阶段：单样本决策阶段解决单个响应就能自信回答的实例；可靠性感知累积阶段通过联合利用响应频率和置信度来聚合响应。

Result: 在五个模型和四个数据集上，ReASC相比现有基线始终实现最佳准确率-成本权衡，在3B到27B参数规模上提高推理效率。例如在GSM8K上使用Gemma-3-4B-it时，ReASC将推理成本降低高达70%同时保持准确性。

Conclusion: ReASC通过将自适应采样从响应计数重新定义为证据充分性，利用响应级置信度进行原则性信息聚合，有效解决了传统自适应自洽性方法的局限性。

Abstract: Self-Consistency improves reasoning reliability through multi-sample aggregation, but incurs substantial inference cost. Adaptive self-consistency methods mitigate this issue by adjusting the sampling budget; however, they rely on count-based stopping rules that treat all responses equally, often leading to unnecessary sampling. We propose Reliability-Aware Adaptive Self-Consistency (ReASC), which addresses this limitation by reframing adaptive sampling from response counting to evidence sufficiency, leveraging response-level confidence for principled information aggregation. ReASC operates in two stages: a single-sample decision stage that resolves instances confidently answerable from a single response, and a reliability-aware accumulation stage that aggregates responses by jointly leveraging their frequency and confidence. Across five models and four datasets, ReASC consistently achieves the best accuracy-cost trade-off compared to existing baselines, yielding improved inference efficiency across model scales from 3B to 27B parameters. As a concrete example, ReASC reduces inference cost by up to 70\% relative to self-consistency while preserving accuracy on GSM8K using Gemma-3-4B-it.

</details>


### [45] [Correct, Concise and Complete: Multi-stage Training For Adaptive Reasoning](https://arxiv.org/abs/2601.02972)
*Nathanaël Carraz Rakotonirina,Ren Pang,Neha Anna John,Michael Bohlke-Schneider,Momchil Hardalov*

Main category: cs.CL

TL;DR: 提出多阶段高效推理方法，结合监督微调和强化学习，通过自适应长度惩罚减少LLMs推理过程中的过度思考现象，在保持准确性的同时显著缩短响应长度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过增加推理时间计算（如思维链）提升了推理能力，但往往产生不必要的冗长推理过程，导致计算成本增加甚至性能下降，这种现象被称为"过度思考"。

Method: 提出多阶段高效推理方法：1）通过拒绝采样或推理轨迹重格式化进行监督微调；2）使用自适应长度惩罚的强化学习；3）设计轻量级奖励函数，惩罚第一个正确答案后的冗余标记，只在有益时鼓励自我验证。

Result: 在七个多样化推理任务上的评估显示：8B模型响应长度平均减少28%，32B模型减少40%，性能仅轻微下降1.6和2.5个百分点。在过度思考调整准确率曲线下面积（AUC_OAA）指标上得分为76.6，比基准模型高5分，比次优方法高2.5分。

Conclusion: 该方法概念简单但效果显著，相比现有复杂的高效推理方法实现了更优的权衡，能够有效减少LLMs推理过程中的过度思考现象，在保持准确性的同时显著降低计算成本。

Abstract: The reasoning capabilities of large language models (LLMs) have improved substantially through increased test-time computation, typically in the form of intermediate tokens known as chain-of-thought (CoT). However, CoT often becomes unnecessarily long, increasing computation cost without actual accuracy gains or sometimes even degrading performance, a phenomenon known as ``overthinking''. We propose a multi-stage efficient reasoning method that combines supervised fine-tuning -- via rejection sampling or reasoning trace reformatting -- with reinforcement learning using an adaptive length penalty. We introduce a lightweight reward function that penalizes tokens generated after the first correct answer but encouraging self-verification only when beneficial. We conduct a holistic evaluation across seven diverse reasoning tasks, analyzing the accuracy--response length trade-off. Our approach reduces response length by an average of 28\% for 8B models and 40\% for 32B models, while incurring only minor performance drops of 1.6 and 2.5 points, respectively. Despite its conceptual simplicity, it achieves a superior trade-off compared to more complex state-of-the-art efficient reasoning methods, scoring 76.6, in terms of the area under the Overthinking-Adjusted Accuracy curve ($\text{AUC}_{\text{OAA}}$) -- 5 points above the base model and 2.5 points above the second-best approach.

</details>


### [46] [Mechanistic Knobs in LLMs: Retrieving and Steering High-Order Semantic Features via Sparse Autoencoders](https://arxiv.org/abs/2601.02978)
*Ruikang Zhang,Shuo Wang,Qi Su*

Main category: cs.CL

TL;DR: 提出基于稀疏自编码器的框架，用于检索和操控与高级语言行为相关的可解释内部特征，通过对比特征检索实现复杂语义属性的精确双向调控。


<details>
  <summary>Details</summary>
Motivation: 尽管机理可解释性研究已能识别和干预大语言模型的内部特征，但如何将这些内部特征与复杂行为级语义属性的可靠控制联系起来仍是一个挑战。

Method: 采用基于稀疏自编码器的框架，结合对比特征检索流程（基于受控语义对立）、统计激活分析和生成验证，从稀疏激活空间中提取单语义功能特征。

Result: 以"大五人格"特质为案例，该方法相比现有激活操控方法（如对比激活加法）能实现更精确的双向行为调控，同时保持更好的稳定性和性能。发现"功能忠实性"效应：干预特定内部特征会引发与目标语义属性一致的多语言维度连贯可预测变化。

Conclusion: 大语言模型内化了高阶概念的深度集成表征，该方法为复杂AI行为调控提供了一条新颖、稳健的机理路径。

Abstract: Recent work in Mechanistic Interpretability (MI) has enabled the identification and intervention of internal features in Large Language Models (LLMs). However, a persistent challenge lies in linking such internal features to the reliable control of complex, behavior-level semantic attributes in language generation. In this paper, we propose a Sparse Autoencoder-based framework for retrieving and steering semantically interpretable internal features associated with high-level linguistic behaviors. Our method employs a contrastive feature retrieval pipeline based on controlled semantic oppositions, combing statistical activation analysis and generation-based validation to distill monosemantic functional features from sparse activation spaces. Using the Big Five personality traits as a case study, we demonstrate that our method enables precise, bidirectional steering of model behavior while maintaining superior stability and performance compared to existing activation steering methods like Contrastive Activation Addition (CAA). We further identify an empirical effect, which we term Functional Faithfulness, whereby intervening on a specific internal feature induces coherent and predictable shifts across multiple linguistic dimensions aligned with the target semantic attribute. Our findings suggest that LLMs internalize deeply integrated representations of high-order concepts, and provide a novel, robust mechanistic path for the regulation of complex AI behaviors.

</details>


### [47] [P-Check: Advancing Personalized Reward Model via Learning to Generate Dynamic Checklist](https://arxiv.org/abs/2601.02986)
*Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 提出P-Check框架，通过动态生成个性化检查清单来改进奖励建模，引入偏好对比准则加权策略，在奖励准确性和下游生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有个性化奖励建模方法主要依赖用户交互历史，但将用户上下文视为静态或隐式条件信号，未能捕捉人类判断的动态性和多面性。

Method: 提出P-Check框架，训练即插即用的检查清单生成器，合成动态评估准则来指导奖励预测；引入偏好对比准则加权策略，根据准则在个性化判断中的区分能力分配显著性分数。

Result: P-Check不仅提高了奖励准确性，还增强了下游个性化生成性能，并在分布外场景中保持鲁棒性。

Conclusion: P-Check通过动态生成个性化检查清单，有效解决了现有方法在捕捉人类判断动态性方面的局限性，为个性化奖励建模提供了新思路。

Abstract: Recent approaches in personalized reward modeling have primarily focused on leveraging user interaction history to align model judgments with individual preferences. However, existing approaches largely treat user context as a static or implicit conditioning signal, failing to capture the dynamic and multi-faceted nature of human judgment. In this paper, we propose P-Check, a novel personalized reward modeling framework, designed to train a plug-and-play checklist generator that synthesizes dynamic evaluation criteria for guiding the reward prediction. To better align these checklists with personalized nuances, we introduce Preference-Contrastive Criterion Weighting, a training strategy that assigns saliency scores to criteria based on their discriminative power for personalized judgment. We conduct extensive experiments and demonstrate that P-Check not only improves reward accuracy but also enhances downstream personalized generation, and remains robust in OOD scenarios.

</details>


### [48] [Mechanistic Interpretability of Large-Scale Counting in LLMs through a System-2 Strategy](https://arxiv.org/abs/2601.02989)
*Hosein Hasani,Mohammadali Banayeeanzade,Ali Nafisi,Sadegh Mohammadian,Fatemeh Askari,Mobin Bagherian,Amirmohammad Izadi,Mahdieh Soleymani Baghshah*

Main category: cs.CL

TL;DR: 提出基于系统2认知过程的测试时策略，将大计数任务分解为模型可可靠解决的小子问题，使LLM突破架构限制实现高精度大规模计数。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂数学问题上表现优异，但在计数任务中存在系统性限制。这是由于transformer架构的局限性，计数需要在多层中进行，深度约束导致较大计数问题的精度下降。

Method: 提出受系统2认知过程启发的测试时策略：将大计数任务分解为模型可可靠解决的独立子问题。通过观察性和因果中介分析理解该策略的底层机制，识别关键组件包括：潜在计数计算并存储在每个部分的最终项表示中，通过专用注意力头传递到中间步骤，并在最后阶段聚合产生总计数。

Result: 实验结果表明该策略使LLM能够超越架构限制，在大规模计数任务上实现高精度。该策略显著提升了模型在大型计数问题上的性能。

Conclusion: 这项工作为LLM中的系统2计数提供了机制性洞察，并提出了一种可推广的方法来改进和理解其推理行为，为解决transformer架构在计数任务中的固有局限性提供了有效途径。

Abstract: Large language models (LLMs), despite strong performance on complex mathematical problems, exhibit systematic limitations in counting tasks. This issue arises from architectural limits of transformers, where counting is performed across layers, leading to degraded precision for larger counting problems due to depth constraints. To address this limitation, we propose a simple test-time strategy inspired by System-2 cognitive processes that decomposes large counting tasks into smaller, independent sub-problems that the model can reliably solve. We evaluate this approach using observational and causal mediation analyses to understand the underlying mechanism of this System-2-like strategy. Our mechanistic analysis identifies key components: latent counts are computed and stored in the final item representations of each part, transferred to intermediate steps via dedicated attention heads, and aggregated in the final stage to produce the total count. Experimental results demonstrate that this strategy enables LLMs to surpass architectural limitations and achieve high accuracy on large-scale counting tasks. This work provides mechanistic insight into System-2 counting in LLMs and presents a generalizable approach for improving and understanding their reasoning behavior.

</details>


### [49] [Stable-RAG: Mitigating Retrieval-Permutation-Induced Hallucinations in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.02993)
*Qianchi Zhang,Hainan Zhang,Liang Pang,Hongwei Zheng,Zhiming Zheng*

Main category: cs.CL

TL;DR: Stable-RAG：通过多文档顺序推理聚类来缓解RAG中检索顺序敏感性导致的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 研究发现检索增强生成（RAG）中，即使包含黄金文档，大语言模型对检索文档的顺序排列表现出显著敏感性，导致答案变化。现有鲁棒RAG方法主要关注低质量检索和位置偏差，但没有直接解决这种排列敏感性问题。

Method: 提出Stable-RAG方法：1）在多个检索顺序下运行生成器；2）对隐藏状态进行聚类；3）从捕获主导推理模式的聚类中心表示进行解码；4）利用这些推理结果将幻觉输出对齐到正确答案，鼓励模型在不同文档排列下产生一致且准确的预测。

Result: 在三个QA数据集上的实验表明，与基线方法相比，Stable-RAG显著提高了答案准确性、推理一致性，并在不同数据集、检索器和输入长度上展现出更强的鲁棒泛化能力。

Conclusion: Stable-RAG通过估计和缓解排列敏感性，有效减少了RAG中的幻觉问题，提高了模型对检索文档顺序变化的鲁棒性。

Abstract: Retrieval-Augmented Generation (RAG) has become a key paradigm for reducing factual hallucinations in large language models (LLMs), yet little is known about how the order of retrieved documents affects model behavior. We empirically show that under Top-5 retrieval with the gold document included, LLM answers vary substantially across permutations of the retrieved set, even when the gold document is fixed in the first position. This reveals a previously underexplored sensitivity to retrieval permutations. Although robust RAG methods primarily focus on enhancing LLM robustness to low-quality retrieval and mitigating positional bias to distribute attention fairly over long contexts, neither approach directly addresses permutation sensitivity. In this paper, we propose Stable-RAG, which exploits permutation sensitivity estimation to mitigate permutation-induced hallucinations. Stable-RAG runs the generator under multiple retrieval orders, clusters hidden states, and decodes from a cluster-center representation that captures the dominant reasoning pattern. It then uses these reasoning results to align hallucinated outputs toward the correct answer, encouraging the model to produce consistent and accurate predictions across document permutations. Experiments on three QA datasets show that Stable-RAG significantly improves answer accuracy, reasoning consistency and robust generalization across datasets, retrievers, and input lengths compared with baselines.

</details>


### [50] [Large Reasoning Models Are (Not Yet) Multilingual Latent Reasoners](https://arxiv.org/abs/2601.02996)
*Yihong Liu,Raoyuan Zhao,Hinrich Schütze,Michael A. Hedderich*

Main category: cs.CL

TL;DR: 大型推理模型在多语言环境中存在潜在推理能力，但在不同语言间表现不均衡，呈现出以英语为中心的推理路径。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在数学推理任务上表现出色，但研究表明它们经常在完成文本推理步骤之前就得出正确答案，这表明存在潜在推理（内部非语言计算）。然而，这种现象主要在英语中被探索，其多语言行为仍未知。

Method: 采用基于截断的策略，在11种语言中系统研究多语言潜在推理。通过只给模型部分推理痕迹，观察正确答案如何逐步形成，从而测量逐步潜在预测形成。同时进行表征分析以理解内部机制。

Result: 发现了多语言潜在推理的明确证据，但表现不均衡：在资源丰富的语言中表现强，在低资源语言中表现弱，在更难的基准测试中普遍较少观察到。尽管表面存在差异，但预测的内部演化在不同语言间高度一致，并且与英语广泛对齐。

Conclusion: 多语言潜在推理确实存在，但呈现出以英语为中心的推理路径，这揭示了大型推理模型在处理不同语言时的内部计算机制差异。

Abstract: Large reasoning models (LRMs) achieve strong performance on mathematical reasoning tasks, often attributed to their capability to generate explicit chain-of-thought (CoT) explanations. However, recent work shows that LRMs often arrive at the correct answer before completing these textual reasoning steps, indicating the presence of latent reasoning -- internal, non-verbal computation encoded in hidden states. While this phenomenon has been explored in English, its multilingual behavior remains largely unknown. In this paper, we conduct a systematic investigation of multilingual latent reasoning in LRMs across 11 languages. Using a truncation-based strategy, we examine how the correct answer emerges as the model is given only partial reasoning traces, allowing us to measure stepwise latent prediction formation. Our results reveal clear evidence of multilingual latent reasoning, though unevenly: strong in resource-rich languages, weaker in low-resource ones, and broadly less observable on harder benchmarks. To understand whether these differences reflect distinct internal mechanisms, we further perform representational analyses. Despite surface-level disparities, we find that the internal evolution of predictions is highly consistent across languages and broadly aligns with English -- a pattern suggesting an English-centered latent reasoning pathway.

</details>


### [51] [SentGraph: Hierarchical Sentence Graph for Multi-hop Retrieval-Augmented Question Answering](https://arxiv.org/abs/2601.03014)
*Junli Liang,Pengfei Zhou,Wangqiu Zhou,Wenjie Qing,Qi Zhao,Ziwen Wang,Qi Song,Xiangyang Li*

Main category: cs.CL

TL;DR: SentGraph是一个基于句子级图结构的RAG框架，通过显式建模句子间的逻辑关系来提升多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在处理多跳问答任务时存在显著局限，基于文档分块的检索常提供不相关和逻辑不连贯的上下文，导致证据链不完整和推理错误。

Method: 提出SentGraph框架：离线构建分层句子图，基于修辞结构理论区分核心句和卫星句，组织成主题级子图并建立跨文档实体桥梁；在线检索时进行图引导的证据选择和路径扩展。

Result: 在四个多跳问答基准测试上的广泛实验证明了SentGraph的有效性，验证了显式建模句子级逻辑依赖关系对多跳推理的重要性。

Conclusion: SentGraph通过句子级图结构显式建模逻辑关系，显著提升了多跳问答的性能，为解决传统RAG在多跳推理中的局限性提供了有效方案。

Abstract: Traditional Retrieval-Augmented Generation (RAG) effectively supports single-hop question answering with large language models but faces significant limitations in multi-hop question answering tasks, which require combining evidence from multiple documents. Existing chunk-based retrieval often provides irrelevant and logically incoherent context, leading to incomplete evidence chains and incorrect reasoning during answer generation. To address these challenges, we propose SentGraph, a sentence-level graph-based RAG framework that explicitly models fine-grained logical relationships between sentences for multi-hop question answering. Specifically, we construct a hierarchical sentence graph offline by first adapting Rhetorical Structure Theory to distinguish nucleus and satellite sentences, and then organizing them into topic-level subgraphs with cross-document entity bridges. During online retrieval, SentGraph performs graph-guided evidence selection and path expansion to retrieve fine-grained sentence-level evidence. Extensive experiments on four multi-hop question answering benchmarks demonstrate the effectiveness of SentGraph, validating the importance of explicitly modeling sentence-level logical dependencies for multi-hop reasoning.

</details>


### [52] [MMFormalizer: Multimodal Autoformalization in the Wild](https://arxiv.org/abs/2601.03017)
*Jing Xiong,Qi Han,Yunta Hsieh,Hui Shen,Huajian Xin,Chaofan Tao,Chenyang Zhao,Hengyuan Zhang,Taiqiang Wu,Zhen Zhang,Haochen Wang,Zhongwei Wan,Lingpeng Kong,Ngai Wong*

Main category: cs.CL

TL;DR: MMFormalizer是一种多模态自动形式化方法，通过整合自适应实体接地，将自然语言数学转化为形式化陈述，支持物理世界中的视觉推理。


<details>
  <summary>Details</summary>
Motivation: 传统自动形式化方法主要基于文本，无法处理物理世界中需要从视觉元素推断隐藏约束（如质量或能量）的多模态挑战。

Method: 通过递归接地和公理组合，从感知接地的基元递归构建形式命题，自适应递归终止确保每个抽象都有视觉证据支持并锚定在维度或公理基础上。

Result: 在PhyX-AF基准测试中，前沿模型如GPT-5和Gemini-3-Pro在编译和语义准确性方面表现最佳，GPT-5在物理推理方面表现突出，几何领域仍然最具挑战性。

Conclusion: MMFormalizer为统一的多模态自动形式化提供了可扩展框架，首次能够处理经典力学、相对论、量子力学和热力学等复杂物理领域。

Abstract: Autoformalization, which translates natural language mathematics into formal statements to enable machine reasoning, faces fundamental challenges in the wild due to the multimodal nature of the physical world, where physics requires inferring hidden constraints (e.g., mass or energy) from visual elements. To address this, we propose MMFormalizer, which extends autoformalization beyond text by integrating adaptive grounding with entities from real-world mathematical and physical domains. MMFormalizer recursively constructs formal propositions from perceptually grounded primitives through recursive grounding and axiom composition, with adaptive recursive termination ensuring that every abstraction is supported by visual evidence and anchored in dimensional or axiomatic grounding. We evaluate MMFormalizer on a new benchmark, PhyX-AF, comprising 115 curated samples from MathVerse, PhyX, Synthetic Geometry, and Analytic Geometry, covering diverse multimodal autoformalization tasks. Results show that frontier models such as GPT-5 and Gemini-3-Pro achieve the highest compile and semantic accuracy, with GPT-5 excelling in physical reasoning, while geometry remains the most challenging domain. Overall, MMFormalizer provides a scalable framework for unified multimodal autoformalization, bridging perception and formal reasoning. To the best of our knowledge, this is the first multimodal autoformalization method capable of handling classical mechanics (derived from the Hamiltonian), as well as relativity, quantum mechanics, and thermodynamics. More details are available on our project page: MMFormalizer.github.io

</details>


### [53] [Dementia-R1: Reinforced Pretraining and Reasoning from Unstructured Clinical Notes for Real-World Dementia Prognosis](https://arxiv.org/abs/2601.03018)
*Choonghan Kim,Hyunmin Hwang,Hangeol Chang,Jaemin Kim,Jinse Park,Jae-Sung Lim,Jong Chul Ye*

Main category: cs.CL

TL;DR: Dementia-R1：一个用于纵向痴呆预测的强化学习框架，通过冷启动RL策略预测临床指标，在真实临床数据上达到77.03%的F1分数，7B模型在ADNI基准上媲美GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床文本理解上表现良好，但在痴呆预后等纵向预测任务上存在困难，这些任务需要对多个就诊中的复杂、非单调症状轨迹进行推理。标准监督训练缺乏症状演变的显式标注，而直接强化学习受到稀疏二元奖励的阻碍。

Method: 提出Dementia-R1框架，采用冷启动RL策略：首先预训练模型从患者历史中预测可验证的临床指标，增强对疾病进展的推理能力，然后再确定最终的临床状态。

Result: 在真实世界非结构化临床数据集上达到77.03%的F1分数；在ADNI基准上，7B模型的表现与GPT-4o相当，能有效捕捉波动的认知轨迹。

Conclusion: Dementia-R1通过冷启动RL策略解决了纵向痴呆预测中的挑战，在缺乏显式标注的情况下实现了对复杂症状轨迹的有效推理，为临床纵向预测任务提供了新思路。

Abstract: While Large Language Models (LLMs) have shown strong performance on clinical text understanding, they struggle with longitudinal prediction tasks such as dementia prognosis, which require reasoning over complex, non-monotonic symptom trajectories across multiple visits. Standard supervised training lacks explicit annotations for symptom evolution, while direct Reinforcement Learning (RL) is hindered by sparse binary rewards. To address this challenge, we introduce Dementia-R1, an RL-based framework for longitudinal dementia prognosis from unstructured clinical notes. Our approach adopts a Cold-Start RL strategy that pre-trains the model to predict verifiable clinical indices extracted from patient histories, enhancing the capability to reason about disease progression before determining the final clinical status. Extensive experiments demonstrate that Dementia-R1 achieves an F1 score of 77.03% on real-world unstructured clinical datasets. Notably, on the ADNI benchmark, our 7B model rivals GPT-4o, effectively capturing fluctuating cognitive trajectories. Code is available at https://anonymous.4open.science/r/dementiar1-CDB5

</details>


### [54] [MedDialogRubrics: A Comprehensive Benchmark and Evaluation Framework for Multi-turn Medical Consultations in Large Language Models](https://arxiv.org/abs/2601.03023)
*Lecheng Gong,Weimin Fang,Ting Yang,Dongjie Tao,Chunxiao Guo,Peng Wei,Bo Xie,Jinqun Guan,Zixiao Chen,Fang Shi,Jinjie Gu,Junwei Liu*

Main category: cs.CL

TL;DR: 提出MedDialogRubrics基准，包含5200个合成病例和60000+细粒度评估标准，用于评估医疗大语言模型的多轮诊断能力。


<details>
  <summary>Details</summary>
Motivation: 现有医疗对话AI的评估基准和框架在信息收集和诊断推理能力方面缺乏严格评估，需要更系统的评估方法。

Method: 使用多智能体系统合成真实患者记录；设计患者智能体并加入动态引导机制防止幻觉；提出结构化LLM和专家标注的标准生成流程，基于循证医学指南和拒绝采样获取"必问"项目。

Result: 对最先进模型进行全面评估发现，当前模型在多维评估中面临重大挑战，表明改进医疗对话需要对话管理架构的进步，而不仅仅是基础模型的微调。

Conclusion: MedDialogRubrics为医疗对话AI提供了严格的评估基准，揭示了当前模型的局限性，并指出了未来研究需要关注对话管理架构的改进。

Abstract: Medical conversational AI (AI) plays a pivotal role in the development of safer and more effective medical dialogue systems. However, existing benchmarks and evaluation frameworks for assessing the information-gathering and diagnostic reasoning abilities of medical large language models (LLMs) have not been rigorously evaluated. To address these gaps, we present MedDialogRubrics, a novel benchmark comprising 5,200 synthetically constructed patient cases and over 60,000 fine-grained evaluation rubrics generated by LLMs and subsequently refined by clinical experts, specifically designed to assess the multi-turn diagnostic capabilities of LLM. Our framework employs a multi-agent system to synthesize realistic patient records and chief complaints from underlying disease knowledge without accessing real-world electronic health records, thereby mitigating privacy and data-governance concerns. We design a robust Patient Agent that is limited to a set of atomic medical facts and augmented with a dynamic guidance mechanism that continuously detects and corrects hallucinations throughout the dialogue, ensuring internal coherence and clinical plausibility of the simulated cases. Furthermore, we propose a structured LLM-based and expert-annotated rubric-generation pipeline that retrieves Evidence-Based Medicine (EBM) guidelines and utilizes the reject sampling to derive a prioritized set of rubric items ("must-ask" items) for each case. We perform a comprehensive evaluation of state-of-the-art models and demonstrate that, across multiple assessment dimensions, current models face substantial challenges. Our results indicate that improving medical dialogue will require advances in dialogue management architectures, not just incremental tuning of the base-model.

</details>


### [55] [LittiChoQA: Literary Texts in Indic Languages Chosen for Question Answering](https://arxiv.org/abs/2601.03025)
*Aarya Khandelwal,Ritwik Mishra,Rajiv Ratn Shah*

Main category: cs.CL

TL;DR: LittiChoQA是最大的印度语言文学QA数据集，包含27万对问答，评估显示完整上下文微调效果最好但效率低，上下文缩短可提高吞吐量，Krutrim-2模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决印度语言在长上下文QA任务上资源稀缺的问题，特别是文学文本的低资源语言QA挑战。

Method: 构建LittiChoQA数据集（自动生成27万+问答对），评估多语言LLM在完整上下文和缩短上下文设置下的表现，包括基于答案段落选择和向量检索的缩短方法。

Result: 完整上下文微调获得最高得分（语义分76.1），上下文缩短提高吞吐量但性能下降；Krutrim-2模型表现最佳；答案段落选择（74.9）优于向量检索（71.4）。

Conclusion: 在印度语言文学QA中存在性能与效率的权衡，完整上下文效果最好但效率低，上下文缩短是可行的折中方案，Krutrim-2展示了在低资源语言任务上的优势。

Abstract: Long-context question answering (QA) over literary texts poses significant challenges for modern large language models, particularly in low-resource languages. We address the scarcity of long-context QA resources for Indic languages by introducing LittiChoQA, the largest literary QA dataset to date covering many languages spoken in the Gangetic plains of India. The dataset comprises over 270K automatically generated question-answer pairs with a balanced distribution of factoid and non-factoid questions, generated from naturally authored literary texts collected from the open web. We evaluate multiple multilingual LLMs on non-factoid, abstractive QA, under both full-context and context-shortened settings. Results demonstrate a clear trade-off between performance and efficiency: full-context fine-tuning yields the highest token-level and semantic-level scores, while context shortening substantially improves throughput. Among the evaluated models, Krutrim-2 achieves the strongest performance, obtaining a semantic score of 76.1 with full context. While, in shortened context settings it scores 74.9 with answer paragraph selection and 71.4 with vector-based retrieval. Qualitative evaluations further corroborate these findings.

</details>


### [56] [Reducing Hallucinations in LLMs via Factuality-Aware Preference Learning](https://arxiv.org/abs/2601.03027)
*Sindhuja Chaduvula,Ahmed Y. Radwan,Azib Farooq,Yani Ioannou,Shaina Raza*

Main category: cs.CL

TL;DR: F-DPO是一种基于DPO的改进方法，通过引入事实性标签和边界调整来减少大语言模型中的幻觉，提高事实准确性，无需额外奖励模型或多阶段训练。


<details>
  <summary>Details</summary>
Motivation: 现有偏好对齐方法（如RLHF和DPO）虽然能改善指令遵循能力，但可能强化幻觉问题，因为偏好判断可能更倾向于奖励流畅性和自信度而非事实准确性。

Method: F-DPO扩展了标准DPO，采用两种关键改进：(1) 标签翻转转换，确保选择的回答不比拒绝的回答更不真实；(2) 添加事实感知边界，强调正确性差异明显的回答对，当两个回答事实性相同时退化为标准DPO。通过为DPO数据对添加二元事实性标签和合成幻觉变体来构建事实感知偏好数据。

Result: 在七个开源大语言模型（1B-14B）上，F-DPO相比基础模型和标准DPO持续提高事实性并降低幻觉率。在Qwen3-8B上，幻觉率降低五倍（从0.424到0.084），事实性分数提高50%（从5.26到7.90）。在TruthfulQA上，Qwen2.5-14B的MC1准确率提高17%（0.500到0.585），MC2准确率提高49%（0.357到0.531）。

Conclusion: F-DPO是一种简单有效的改进方法，能显著提高大语言模型的事实准确性并减少幻觉，无需额外奖励模型、token级标注或多阶段训练，具有良好的泛化能力。

Abstract: Preference alignment methods such as RLHF and Direct Preference Optimization (DPO) improve instruction following, but they can also reinforce hallucinations when preference judgments reward fluency and confidence over factual correctness. We introduce F-DPO (Factuality-aware Direct Preference Optimization), a simple extension of DPO that uses only binary factuality labels. F-DPO (i) applies a label-flipping transformation that corrects misordered preference pairs so the chosen response is never less factual than the rejected one, and (ii) adds a factuality-aware margin that emphasizes pairs with clear correctness differences, while reducing to standard DPO when both responses share the same factuality. We construct factuality-aware preference data by augmenting DPO pairs with binary factuality indicators and synthetic hallucinated variants. Across seven open-weight LLMs (1B-14B), F-DPO consistently improves factuality and reduces hallucination rates relative to both base models and standard DPO. On Qwen3-8B, F-DPO reduces hallucination rates by five times (from 0.424 to 0.084) while improving factuality scores by 50 percent (from 5.26 to 7.90). F-DPO also generalizes to out-of-distribution benchmarks: on TruthfulQA, Qwen2.5-14B achieves plus 17 percent MC1 accuracy (0.500 to 0.585) and plus 49 percent MC2 accuracy (0.357 to 0.531). F-DPO requires no auxiliary reward model, token-level annotations, or multi-stage training.

</details>


### [57] [NorwAI's Large Language Models: Technical Report](https://arxiv.org/abs/2601.03034)
*Jon Atle Gulla,Peng Liu,Lemei Zhang*

Main category: cs.CL

TL;DR: 挪威NorLLM团队开发了针对挪威语和斯堪的纳维亚语言的大语言模型家族，基于多种Transformer架构，通过从头预训练或持续预训练，支持25B-88.45B令牌，具备指令调优版本，为北欧组织提供开放使用。


<details>
  <summary>Details</summary>
Motivation: 挪威语作为约500万人使用的语言，在自然语言处理的重要突破中代表性不足。为了解决这一差距，需要开发专门针对挪威语和斯堪的纳维亚语言的模型。

Method: 基于GPT、Mistral、Llama2、Mixtral和Magistral等多样化Transformer架构，使用挪威语扩展的分词器，通过从头预训练或持续预训练处理25B-88.45B令牌，采用先进的训练后策略优化性能。

Result: 开发了专门针对挪威语和斯堪的纳维亚语言的模型家族，包括指令调优变体（如Mistral-7B-Instruct和Mixtral-8x7B-Instruct），展示了强大的助手式能力，适合实际部署到交互式和特定领域应用中。

Conclusion: NorwAI大语言模型已向北欧组织、公司和学生开放，供研究和实验使用，报告详细记录了模型架构、训练数据、分词器设计、微调策略、部署和评估。

Abstract: Norwegian, spoken by approximately five million people, remains underrepresented in many of the most significant breakthroughs in Natural Language Processing (NLP). To address this gap, the NorLLM team at NorwAI has developed a family of models specifically tailored to Norwegian and other Scandinavian languages, building on diverse Transformer-based architectures such as GPT, Mistral, Llama2, Mixtral and Magistral. These models are either pretrained from scratch or continually pretrained on 25B - 88.45B tokens, using a Norwegian-extended tokenizer and advanced post-training strategies to optimize performance, enhance robustness, and improve adaptability across various real-world tasks. Notably, instruction-tuned variants (e.g., Mistral-7B-Instruct and Mixtral-8x7B-Instruct) showcase strong assistant-style capabilities, underscoring their potential for practical deployment in interactive and domain-specific applications. The NorwAI large language models are openly available to Nordic organizations, companies and students for both research and experimental use. This report provides detailed documentation of the model architectures, training data, tokenizer design, fine-tuning strategies, deployment, and evaluations.

</details>


### [58] [BaseCal: Unsupervised Confidence Calibration via Base Model Signals](https://arxiv.org/abs/2601.03042)
*Hexiang Tan,Wanli Yang,Junwei Zhang,Xin Chen,Rui Tang,Du Su,Jingang Wang,Yuanzhuo Wang,Fei Sun,Xueqi Cheng*

Main category: cs.CL

TL;DR: 提出BaseCal方法，利用基础LLM校准后训练LLM的置信度，解决后训练LLM过度自信问题，无需人工标注或模型修改。


<details>
  <summary>Details</summary>
Motivation: 后训练LLM普遍存在严重过度自信问题，而相应的基础LLM通常保持良好校准，这为利用基础LLM校准后训练LLM置信度提供了自然动机。

Method: 提出两种方法：BaseCal-ReEval（将后训练LLM回答输入基础LLM获取平均概率作为置信度）和BaseCal-Proj（训练轻量投影将后训练LLM隐藏状态映射回基础LLM状态，再通过基础LLM输出层获取校准置信度）。

Result: 在五个数据集和三个LLM家族上的实验表明，BaseCal相比最佳无监督基线平均减少42.90%的预期校准误差。

Conclusion: BaseCal作为无需人工标注或模型修改的即插即用无监督解决方案，能有效校准后训练LLM的置信度，提高输出可靠性。

Abstract: Reliable confidence is essential for trusting the outputs of LLMs, yet widely deployed post-trained LLMs (PoLLMs) typically compromise this trust with severe overconfidence. In contrast, we observe that their corresponding base LLMs often remain well-calibrated. This naturally motivates us to calibrate PoLLM confidence using the base LLM as a reference. This work proposes two ways to achieve this. A straightforward solution, BaseCal-ReEval, evaluates PoLLM's responses by feeding them into the base LLM to get average probabilities as confidence. While effective, this approach introduces additional inference overhead. To address this, we propose BaseCal-Proj, which trains a lightweight projection to map the final-layer hidden states of PoLLMs back to those of their base LLMs. These projected states are then processed by the base LLM's output layer to derive base-calibrated confidence for PoLLM's responses. Notably, BaseCal is an unsupervised, plug-and-play solution that operates without human labels or LLM modifications. Experiments across five datasets and three LLM families demonstrate the effectiveness of BaseCal, reducing Expected Calibration Error (ECE) by an average of 42.90\% compared to the best unsupervised baselines.

</details>


### [59] [Lil: Less is Less When Applying Post-Training Sparse-Attention Algorithms in Long-Decode Stage](https://arxiv.org/abs/2601.03043)
*Junhao Hu,Fangze Li,Mingtao Xu,Feifan Meng,Shiju Zhao,Tiancheng Hu,Ting Peng,Anmin Liu,Wenrui Huang,Chenxu Liu,Ziyue Hua,Tao Xie*

Main category: cs.CL

TL;DR: 本文发现稀疏注意力机制在解码阶段可能适得其反，导致序列长度显著增加，提出了"少即是少"现象，并设计了早期停止算法来缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理阶段的时间复杂度主要来自解码阶段，现有稀疏注意力算法旨在降低该阶段复杂度，但可能因信息损失导致序列长度增加，反而增加端到端复杂度。

Method: 通过理论和实证分析揭示"少即是少"现象，提出早期停止算法，在稀疏解码过程中检测信息损失超过信息增益的阈值，自动停止生成。

Result: 早期停止算法在推理密集型基准测试中能减少高达90%的token消耗，准确率下降小于2%，有效缓解了稀疏注意力带来的序列长度增加问题。

Conclusion: 稀疏注意力机制存在"少即是少"的悖论，提出的早期停止算法能显著减少计算成本，为高效推理提供了实用解决方案。

Abstract: Large language models (LLMs) demonstrate strong capabilities across a wide range of complex tasks and are increasingly deployed at scale, placing significant demands on inference efficiency. Prior work typically decomposes inference into prefill and decode stages, with the decode stage dominating total latency. To reduce time and memory complexity in the decode stage, a line of work introduces sparse-attention algorithms. In this paper, we show, both empirically and theoretically, that sparse attention can paradoxically increase end-to-end complexity: information loss often induces significantly longer sequences, a phenomenon we term ``Less is Less'' (Lil). To mitigate the Lil problem, we propose an early-stopping algorithm that detects the threshold where information loss exceeds information gain during sparse decoding. Our early-stopping algorithm reduces token consumption by up to 90% with a marginal accuracy degradation of less than 2% across reasoning-intensive benchmarks.

</details>


### [60] [Temporal Graph Network: Hallucination Detection in Multi-Turn Conversation](https://arxiv.org/abs/2601.03051)
*Vidhi Rathore,Sambu Aneesh,Himanshu Singh*

Main category: cs.CL

TL;DR: 本文提出了一种基于图神经网络的对话级幻觉检测方法，通过构建对话时序图并利用消息传递机制，在幻觉检测任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 对话AI系统在多轮对话中容易产生幻觉，特别是在上下文变化和出现矛盾的情况下。现有方法主要关注单轮对话的幻觉检测，缺乏对多轮对话中上下文关系的建模能力。

Method: 将整个对话表示为时序图，每个对话轮次作为节点，使用句子编码器进行编码。构建两种边连接：共享实体边（连接提及相同实体的轮次）和时间边（连接连续轮次）。通过消息传递更新节点嵌入，使用注意力池化生成对话表示，最后通过分类器检测幻觉类型。

Result: 该方法在对话级幻觉检测任务上表现优于现有方法，注意力机制能够为决策过程提供可解释性。代码和模型权重已开源。

Conclusion: 图神经网络方法能有效建模多轮对话中的复杂关系，为对话级幻觉检测提供了有效的解决方案，且具有较好的可解释性。

Abstract: Hallucinations can be produced by conversational AI systems, particularly in multi-turn conversations where context changes and contradictions may eventually surface. By representing the entire conversation as a temporal graph, we present a novel graph-based method for detecting dialogue-level hallucinations. Our framework models each dialogue as a node, encoding it using a sentence transformer. We explore two different ways of connectivity: i) shared-entity edges, which connect turns that refer to the same entities; ii) temporal edges, which connect contiguous turns in the conversation. Message-passing is used to update the node embeddings, allowing flow of information between related nodes. The context-aware node embeddings are then combined using attention pooling into a single vector, which is then passed on to a classifier to determine the presence and type of hallucinations. We demonstrate that our method offers slightly improved performance over existing methods. Further, we show the attention mechanism can be used to justify the decision making process. The code and model weights are made available at: https://github.com/sambuaneesh/anlp-project.

</details>


### [61] [Detecting Hallucinations in Retrieval-Augmented Generation via Semantic-level Internal Reasoning Graph](https://arxiv.org/abs/2601.03052)
*Jianpeng Hu,Yanzeng Li,Jialun Zhong,Wenfa Qi,Lei Zou*

Main category: cs.CL

TL;DR: 本文提出了一种基于语义级内部推理图的忠实性幻觉检测方法，通过扩展层相关传播算法构建内部推理图，并设计基于小预训练语言模型的通用框架，在RAGTruth和Dolly-15k数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的检索增强生成系统虽能减少事实性幻觉，但忠实性幻觉仍然存在。现有方法要么忽略捕捉模型内部推理过程，要么对这些特征处理粗糙，导致判别器难以学习。

Method: 1. 将层相关传播算法从token级扩展到语义级，基于归因向量构建内部推理图，提供更忠实的语义级依赖表示。2. 设计基于小预训练语言模型的通用框架，利用LLM推理中的依赖关系进行训练和幻觉检测，通过阈值动态调整正确样本的通过率。

Result: 实验结果表明，该方法在RAGTruth和Dolly-15k数据集上相比最先进的基线方法取得了更好的整体性能。

Conclusion: 提出的语义级内部推理图方法能有效检测忠实性幻觉，通过捕捉模型内部推理过程并提供更精细的语义依赖表示，优于现有方法。

Abstract: The Retrieval-augmented generation (RAG) system based on Large language model (LLM) has made significant progress. It can effectively reduce factuality hallucinations, but faithfulness hallucinations still exist. Previous methods for detecting faithfulness hallucinations either neglect to capture the models' internal reasoning processes or handle those features coarsely, making it difficult for discriminators to learn. This paper proposes a semantic-level internal reasoning graph-based method for detecting faithfulness hallucination. Specifically, we first extend the layer-wise relevance propagation algorithm from the token level to the semantic level, constructing an internal reasoning graph based on attribution vectors. This provides a more faithful semantic-level representation of dependency. Furthermore, we design a general framework based on a small pre-trained language model to utilize the dependencies in LLM's reasoning for training and hallucination detection, which can dynamically adjust the pass rate of correct samples through a threshold. Experimental results demonstrate that our method achieves better overall performance compared to state-of-the-art baselines on RAGTruth and Dolly-15k.

</details>


### [62] [Do LLMs Encode Functional Importance of Reasoning Tokens?](https://arxiv.org/abs/2601.03066)
*Janvijay Singh,Dilek Hakkani-Tür*

Main category: cs.CL

TL;DR: 本文提出贪婪剪枝方法，通过迭代删除对模型似然影响最小的推理标记来压缩推理链，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过生成长推理链解决复杂任务，但存在计算成本高、难以分离功能相关推理的问题。现有压缩方法有限，缺乏对模型内部标记级功能重要性的洞察。

Method: 提出贪婪剪枝方法：一种保持似然性的删除过程，迭代删除那些删除后对模型似然影响最小的推理标记，生成长度可控的推理链。

Result: 在蒸馏框架中评估显示，使用剪枝链训练的学生模型在相同推理长度下优于前沿模型监督的压缩基线。分析还显示系统性的剪枝模式，注意力分数可以预测贪婪剪枝排名。

Conclusion: 模型在推理标记上编码了非平凡的功能重要性结构，贪婪剪枝方法能有效压缩推理链同时保持性能，为理解模型内部推理机制提供了诊断工具。

Abstract: Large language models solve complex tasks by generating long reasoning chains, achieving higher accuracy at the cost of increased computational cost and reduced ability to isolate functionally relevant reasoning. Prior work on compact reasoning shortens such chains through probabilistic sampling, heuristics, or supervision from frontier models, but offers limited insight into whether models internally encode token-level functional importance for answer generation. We address this gap diagnostically and propose greedy pruning, a likelihood-preserving deletion procedure that iteratively removes reasoning tokens whose removal minimally degrades model likelihood under a specified objective, yielding length-controlled reasoning chains. We evaluate pruned reasoning in a distillation framework and show that students trained on pruned chains outperform a frontier-model-supervised compression baseline at matched reasoning lengths. Finally, our analysis reveals systematic pruning patterns and shows that attention scores can predict greedy pruning ranks, further suggesting that models encode a nontrivial functional importance structure over reasoning tokens.

</details>


### [63] [Learning to Diagnose and Correct Moral Errors: Towards Enhancing Moral Sensitivity in Large Language Models](https://arxiv.org/abs/2601.03079)
*Bocheng Chen,Han Zi,Xi Chen,Xitong Zhang,Kristen Johnson,Guangliang Liu*

Main category: cs.CL

TL;DR: 论文提出两种语用推理方法增强大语言模型的道德敏感性，使其能诊断道德良性与危险输入并纠正道德错误


<details>
  <summary>Details</summary>
Motivation: 道德敏感性是人类道德能力的基础，但目前使大语言模型具备道德敏感性极具挑战性。论文旨在回答如何增强LLMs的道德敏感性这一问题。

Method: 提出两种语用推理方法：1）诊断道德良性与危险输入；2）纠正道德错误。这些方法基于统一的语用推理视角，从推理负载角度设计推理过程，而不是在语义多样的表层形式上建模道德话语。

Result: 实证证据表明，提出的语用推理方法能有效增强LLMs的道德敏感性，在代表性的道德相关基准测试中取得了强劲性能。

Conclusion: 通过统一的语用推理视角设计推理方法，可以有效增强大语言模型的道德敏感性，使其在道德相关任务中表现更好。

Abstract: Moral sensitivity is fundamental to human moral competence, as it guides individuals in regulating everyday behavior. Although many approaches seek to align large language models (LLMs) with human moral values, how to enable them morally sensitive has been extremely challenging. In this paper, we take a step toward answering the question: how can we enhance moral sensitivity in LLMs? Specifically, we propose two pragmatic inference methods that faciliate LLMs to diagnose morally benign and hazardous input and correct moral errors, whereby enhancing LLMs' moral sensitivity. A central strength of our pragmatic inference methods is their unified perspective: instead of modeling moral discourses across semantically diverse and complex surface forms, they offer a principled perspective for designing pragmatic inference procedures grounded in their inferential loads. Empirical evidence demonstrates that our pragmatic methods can enhance moral sensitivity in LLMs and achieves strong performance on representative morality-relevant benchmarks.

</details>


### [64] [Grad-ELLM: Gradient-based Explanations for Decoder-only LLMs](https://arxiv.org/abs/2601.03089)
*Xin Huang,Antoni B. Chan*

Main category: cs.CL

TL;DR: 提出了Grad-ELLM，一种基于梯度的归因方法，专门针对仅解码器Transformer的LLM，通过结合注意力层梯度和注意力图生成热力图，无需修改架构，并在多个任务上显示出更高的忠实性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）虽然能力强大，但其黑盒性质引发了对透明度和忠实性的担忧。现有的输入归因方法通常是模型无关的，未针对Transformer架构进行优化，导致忠实性有限。

Method: 提出Grad-ELLM，一种梯度归因方法：1）从注意力层梯度聚合通道重要性；2）从注意力图聚合空间重要性；3）在每个生成步骤生成热力图，无需架构修改。还提出了两个忠实性度量π-Soft-NC和π-Soft-NS，改进了Soft-NC/NS，通过控制扰动时保留的信息量实现更公平的比较。

Result: 在情感分类、问答和开放生成任务上使用不同模型进行评估，实验结果显示Grad-ELLM在忠实性方面始终优于其他归因方法。

Conclusion: Grad-ELLM通过专门针对仅解码器Transformer架构的梯度归因方法，显著提高了LLM输入归因的忠实性，同时提出的π-Soft-NC/NS度量提供了更公平的评估标准。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse tasks, yet their black-box nature raises concerns about transparency and faithfulness. Input attribution methods aim to highlight each input token's contributions to the model's output, but existing approaches are typically model-agnostic, and do not focus on transformer-specific architectures, leading to limited faithfulness. To address this, we propose Grad-ELLM, a gradient-based attribution method for decoder-only transformer-based LLMs. By aggregating channel importance from gradients of the output logit with respect to attention layers and spatial importance from attention maps, Grad-ELLM generates heatmaps at each generation step without requiring architectural modifications. Additionally, we introduce two faithfulneses metrics $π$-Soft-NC and $π$-Soft-NS, which are modifications of Soft-NC/NS that provide fairer comparisons by controlling the amount of information kept when perturbing the text. We evaluate Grad-ELLM on sentiment classification, question answering, and open-generation tasks using different models. Experiment results show that Grad-ELLM consistently achieves superior faithfulness than other attribution methods.

</details>


### [65] [Who Laughs with Whom? Disentangling Influential Factors in Humor Preferences across User Clusters and LLMs](https://arxiv.org/abs/2601.03103)
*Soichiro Murakami,Hidetaka Kamigaito,Hiroya Takamura,Manabu Okumura*

Main category: cs.CL

TL;DR: 该研究通过聚类分析日本创意游戏Oogiri用户的幽默偏好，使用Bradley-Terry-Luce模型估计可解释的偏好因子权重，发现大语言模型(LLMs)的幽默判断可以与特定用户群相似，并通过角色提示引导LLMs的偏好。


<details>
  <summary>Details</summary>
Motivation: 幽默偏好存在显著的个体和文化差异，这使得使用大语言模型评估幽默变得复杂。研究旨在解决LLMs在幽默评估中如何捕捉和反映这种异质性的问题。

Method: 1. 使用日本创意响应游戏Oogiri的投票日志数据
2. 对用户进行聚类分析以识别不同的幽默偏好群体
3. 使用Bradley-Terry-Luce模型估计各聚类在可解释偏好因子上的权重
4. 通过提示LLMs选择更有趣的回复来获取其偏好判断
5. 使用角色提示(persona prompting)引导LLMs的偏好方向

Result: 1. 用户聚类显示出不同的幽默偏好模式
2. LLMs的幽默判断结果可以与特定用户群的偏好相似
3. 通过角色提示可以成功引导LLMs的偏好朝向特定用户群

Conclusion: 研究表明LLMs能够捕捉和模拟人类幽默偏好的异质性，通过适当的提示策略可以引导LLMs的偏好方向。研究提供了数据收集和分析脚本以支持可重复性。

Abstract: Humor preferences vary widely across individuals and cultures, complicating the evaluation of humor using large language models (LLMs). In this study, we model heterogeneity in humor preferences in Oogiri, a Japanese creative response game, by clustering users with voting logs and estimating cluster-specific weights over interpretable preference factors using Bradley-Terry-Luce models. We elicit preference judgments from LLMs by prompting them to select the funnier response and found that user clusters exhibit distinct preference patterns and that the LLM results can resemble those of particular clusters. Finally, we demonstrate that, by persona prompting, LLM preferences can be directed toward a specific cluster. The scripts for data collection and analysis will be released to support reproducibility.

</details>


### [66] [Discovering and Causally Validating Emotion-Sensitive Neurons in Large Audio-Language Models](https://arxiv.org/abs/2601.03115)
*Xiutian Zhao,Björn Schuller,Berrak Sisman*

Main category: cs.CL

TL;DR: 该研究首次对大型音频语言模型中的情感敏感神经元进行了神经元级可解释性分析，通过推理时干预揭示了情感编码的因果机制。


<details>
  <summary>Details</summary>
Motivation: 情感是语音交流的核心维度，但现代大型音频语言模型如何内部编码情感仍缺乏机制性解释，需要从神经元层面理解情感处理机制。

Method: 在Qwen2.5-Omni、Kimi-Audio和Audio Flamingo 3三个开源模型中，比较了基于频率、熵、幅度和对比度的神经元选择器；使用推理时干预（消融和增益放大）分析情感敏感神经元。

Result: 发现了情感特异性特征：消融特定情感相关的神经元会显著降低该情感的识别能力，而增益放大则会引导预测向目标情感；这些效应随干预强度系统性变化；情感敏感神经元呈现非均匀的层间聚类，并具有部分跨数据集迁移能力。

Conclusion: 研究为大型音频语言模型中的情感决策提供了因果性、神经元级的解释，并证明有针对性的神经元干预是实现可控情感行为的有效方法。

Abstract: Emotion is a central dimension of spoken communication, yet, we still lack a mechanistic account of how modern large audio-language models (LALMs) encode it internally. We present the first neuron-level interpretability study of emotion-sensitive neurons (ESNs) in LALMs and provide causal evidence that such units exist in Qwen2.5-Omni, Kimi-Audio, and Audio Flamingo 3. Across these three widely used open-source models, we compare frequency-, entropy-, magnitude-, and contrast-based neuron selectors on multiple emotion recognition benchmarks. Using inference-time interventions, we reveal a consistent emotion-specific signature: ablating neurons selected for a given emotion disproportionately degrades recognition of that emotion while largely preserving other classes, whereas gain-based amplification steers predictions toward the target emotion. These effects arise with modest identification data and scale systematically with intervention strength. We further observe that ESNs exhibit non-uniform layer-wise clustering with partial cross-dataset transfer. Taken together, our results offer a causal, neuron-level account of emotion decisions in LALMs and highlight targeted neuron interventions as an actionable handle for controllable affective behaviors.

</details>


### [67] [ToxiGAN: Toxic Data Augmentation via LLM-Guided Directional Adversarial Generation](https://arxiv.org/abs/2601.03121)
*Peiran Li,Jan Fillies,Adrian Paschke*

Main category: cs.CL

TL;DR: ToxiGAN提出了一种结合对抗生成和LLM语义指导的类别感知文本增强框架，通过两步定向训练策略和语义压舱物机制解决GAN增强中的模式崩溃和语义漂移问题，在仇恨言论检测任务上显著优于传统和LLM增强方法。


<details>
  <summary>Details</summary>
Motivation: 当前毒性语言数据增强面临监督有限和分布偏斜的挑战，现有GAN增强方法存在模式崩溃和语义漂移问题，而LLM增强方法通常将LLM视为静态生成器，缺乏动态语义指导。

Method: ToxiGAN采用类别感知对抗生成框架，结合两步定向训练策略：首先使用LLM生成中性文本作为语义压舱物，然后动态选择中性范例提供平衡指导，使毒性样本明确优化以偏离这些范例，增强类别特定的对比信号。

Result: 在四个仇恨言论基准测试中，ToxiGAN在macro-F1和hate-F1指标上均取得最佳平均性能，一致优于传统和基于LLM的增强方法。消融和敏感性分析证实了语义压舱物和定向训练对增强分类器鲁棒性的益处。

Conclusion: ToxiGAN通过结合对抗生成和动态LLM语义指导，成功解决了毒性语言数据增强中的关键挑战，为可控制、类别特定的文本增强提供了有效框架，显著提升了毒性分类的鲁棒性。

Abstract: Augmenting toxic language data in a controllable and class-specific manner is crucial for improving robustness in toxicity classification, yet remains challenging due to limited supervision and distributional skew. We propose ToxiGAN, a class-aware text augmentation framework that combines adversarial generation with semantic guidance from large language models (LLMs). To address common issues in GAN-based augmentation such as mode collapse and semantic drift, ToxiGAN introduces a two-step directional training strategy and leverages LLM-generated neutral texts as semantic ballast. Unlike prior work that treats LLMs as static generators, our approach dynamically selects neutral exemplars to provide balanced guidance. Toxic samples are explicitly optimized to diverge from these exemplars, reinforcing class-specific contrastive signals. Experiments on four hate speech benchmarks show that ToxiGAN achieves the strongest average performance in both macro-F1 and hate-F1, consistently outperforming traditional and LLM-based augmentation methods. Ablation and sensitivity analyses further confirm the benefits of semantic ballast and directional training in enhancing classifier robustness.

</details>


### [68] [The Anatomy of Conversational Scams: A Topic-Based Red Teaming Analysis of Multi-Turn Interactions in LLMs](https://arxiv.org/abs/2601.03134)
*Xiangzhe Yuan,Zhenhao Zhang,Haoming Tang,Siying Hu*

Main category: cs.CL

TL;DR: 该研究通过LLM-to-LLM模拟框架系统评估多轮对话诈骗风险，发现现有单轮安全评估无法捕捉多轮对话中的安全漏洞，揭示了LLM在多轮互动中的安全风险模式。


<details>
  <summary>Details</summary>
Motivation: 随着LLM通过扩展对话获得说服性和代理能力，它们在多轮对话诈骗中引入了新的风险，而现有的单轮安全评估无法有效捕捉这些风险。

Method: 使用受控的LLM-to-LLM模拟框架，在英语和中文的多轮诈骗场景中评估8个最先进的模型，分析对话结果并定性标注攻击者策略、防御响应和失败模式。

Result: 诈骗互动遵循反复升级的模式，防御机制采用验证和延迟策略。交互失败主要源于安全护栏激活和角色不稳定性。不同模型在英语和中文场景中表现存在差异。

Conclusion: 多轮交互安全是LLM行为中一个关键且独特的维度，需要专门的安全评估方法来应对多轮对话中的风险。

Abstract: As LLMs gain persuasive agentic capabilities through extended dialogues, they introduce novel risks in multi-turn conversational scams that single-turn safety evaluations fail to capture. We systematically study these risks using a controlled LLM-to-LLM simulation framework across multi-turn scam scenarios. Evaluating eight state-of-the-art models in English and Chinese, we analyze dialogue outcomes and qualitatively annotate attacker strategies, defensive responses, and failure modes. Results reveal that scam interactions follow recurrent escalation patterns, while defenses employ verification and delay mechanisms. Furthermore, interactional failures frequently stem from safety guardrail activation and role instability. Our findings highlight multi-turn interactional safety as a critical, distinct dimension of LLM behavior.

</details>


### [69] [Improving Indigenous Language Machine Translation with Synthetic Data and Language-Specific Preprocessing](https://arxiv.org/abs/2601.03135)
*Aashish Dhawan,Christopher Driggers-Ellis,Christan Grant,Daisy Zhe Wang*

Main category: cs.CL

TL;DR: 该论文研究了在缺乏平行语料库的土著语言中，通过合成数据增强提升神经机器翻译性能的方法，重点针对美洲的土著语言。


<details>
  <summary>Details</summary>
Motivation: 低资源的土著语言通常缺乏足够的平行语料库来支持有效的神经机器翻译，这限制了这些语言的机器翻译发展。合成数据生成为缓解数据稀缺问题提供了一种实用策略。

Method: 使用高容量多语言翻译模型生成合成句子对，增强美洲土著语言的平行数据集。对多语言mBART模型进行微调，比较仅使用精选数据和合成数据增强的效果。采用语言特定的预处理，包括正字法归一化和噪声感知过滤，以减少语料库伪影。

Result: 在瓜拉尼语-西班牙语和克丘亚语-西班牙语的翻译实验中，合成数据增强带来了chrF++指标的持续改进。而在艾马拉语的诊断实验中，则凸显了通用预处理对于高度黏着性语言的局限性。

Conclusion: 合成数据增强能有效提升低资源土著语言的机器翻译质量，但需要针对特定语言特性（特别是高度黏着性语言）设计专门的预处理方法。该方法为缺乏平行语料库的土著语言机器翻译提供了可行的解决方案。

Abstract: Low-resource indigenous languages often lack the parallel corpora required for effective neural machine translation (NMT). Synthetic data generation offers a practical strategy for mitigating this limitation in data-scarce settings. In this work, we augment curated parallel datasets for indigenous languages of the Americas with synthetic sentence pairs generated using a high-capacity multilingual translation model. We fine-tune a multilingual mBART model on curated-only and synthetically augmented data and evaluate translation quality using chrF++, the primary metric used in recent AmericasNLP shared tasks for agglutinative languages.
  We further apply language-specific preprocessing, including orthographic normalization and noise-aware filtering, to reduce corpus artifacts. Experiments on Guarani--Spanish and Quechua--Spanish translation show consistent chrF++ improvements from synthetic data augmentation, while diagnostic experiments on Aymara highlight the limitations of generic preprocessing for highly agglutinative languages.

</details>


### [70] [Limited Linguistic Diversity in Embodied AI Datasets](https://arxiv.org/abs/2601.03136)
*Selma Wanna,Agnes Luhtaru,Jonathan Salfity,Ryan Barron,Juston Moore,Cynthia Matuszek,Mitch Pryor*

Main category: cs.CL

TL;DR: 对多个广泛使用的视觉-语言-动作（VLA）数据集进行系统性语言特征审计，发现这些数据集中的指令语言高度重复、模板化，缺乏结构多样性。


<details>
  <summary>Details</summary>
Motivation: 语言在VLA模型中起着关键作用，但目前用于训练和评估这些系统的数据集的语言特性缺乏充分记录。研究人员希望了解这些数据集实际包含什么类型的指令以及提供多少语言多样性。

Method: 对多个广泛使用的VLA语料库进行系统性数据集审计，从互补维度量化指令语言特征：词汇多样性、重复和重叠度、语义相似性、句法复杂性。

Result: 分析显示许多数据集依赖高度重复、模板化的命令，结构变化有限，导致指令形式分布狭窄。这些数据集在语言信号方面存在显著局限性。

Conclusion: 这些发现旨在为当前VLA训练和评估数据中的语言信号提供描述性文档，支持更详细的数据集报告、更原则性的数据集选择，以及旨在扩大语言覆盖范围的针对性数据整理或增强策略。

Abstract: Language plays a critical role in Vision-Language-Action (VLA) models, yet the linguistic characteristics of the datasets used to train and evaluate these systems remain poorly documented. In this work, we present a systematic dataset audit of several widely used VLA corpora, aiming to characterize what kinds of instructions these datasets actually contain and how much linguistic variety they provide. We quantify instruction language along complementary dimensions-including lexical variety, duplication and overlap, semantic similarity, and syntactic complexity. Our analysis shows that many datasets rely on highly repetitive, template-like commands with limited structural variation, yielding a narrow distribution of instruction forms. We position these findings as descriptive documentation of the language signal available in current VLA training and evaluation data, intended to support more detailed dataset reporting, more principled dataset selection, and targeted curation or augmentation strategies that broaden language coverage.

</details>


### [71] [Self-Verification is All You Need To Pass The Japanese Bar Examination](https://arxiv.org/abs/2601.03144)
*Andrew Shin*

Main category: cs.CL

TL;DR: 本文提出了一种自验证模型，该模型在新构建的数据集上训练，能够在不改变原始试题结构和评分规则的情况下，首次使LLM通过日本司法考试。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型快速发展，但在高度专业化和结构化的考试中实现可靠性能仍面临挑战。日本司法考试是一个特别具有挑战性的基准，不仅需要高级法律推理能力，还要求严格遵守涉及多个命题联合评估的复杂答题格式。现有方法虽然通过将问题分解为简单真伪判断有所改进，但未在原始考试格式和评分方案下系统评估，无法确定是否真正具备考试水平的胜任能力。

Method: 构建了忠实复制考试真实格式和评分标准的新数据集，训练了一个自验证模型。该模型能够在不改变原始试题结构或评分规则的情况下工作。同时与多智能体推理和基于分解的监督等替代策略进行了广泛比较。

Result: 模型在真实考试评分标准下超过了官方及格分数线，这是首次证明LLM能够在保持日本司法考试原始试题结构和评分规则的情况下通过考试。比较实验表明，多智能体推理和分解监督等方法无法达到可比性能。

Conclusion: 结果强调了格式忠实监督和一致性验证的重要性，表明精心设计的单模型方法在高压专业推理任务中可以胜过更复杂的系统。格式忠实监督和一致性验证对于专业考试的成功至关重要。

Abstract: Despite rapid advances in large language models (LLMs), achieving reliable performance on highly professional and structured examinations remains a significant challenge. The Japanese bar examination is a particularly demanding benchmark, requiring not only advanced legal reasoning but also strict adherence to complex answer formats that involve joint evaluation of multiple propositions. While recent studies have reported improvements by decomposing such questions into simpler true--false judgments, these approaches have not been systematically evaluated under the original exam format and scoring scheme, leaving open the question of whether they truly capture exam-level competence. In this paper, we present a self-verification model trained on a newly constructed dataset that faithfully replicates the authentic format and evaluation scale of the exam. Our model is able to exceed the official passing score when evaluated on the actual exam scale, marking the first demonstration, to our knowledge, of an LLM passing the Japanese bar examination without altering its original question structure or scoring rules. We further conduct extensive comparisons with alternative strategies, including multi-agent inference and decomposition-based supervision, and find that these methods fail to achieve comparable performance. Our results highlight the importance of format-faithful supervision and consistency verification, and suggest that carefully designed single-model approaches can outperform more complex systems in high-stakes professional reasoning tasks. Our dataset and codes are publicly available.

</details>


### [72] [Decoupling the Effect of Chain-of-Thought Reasoning: A Human Label Variation Perspective](https://arxiv.org/abs/2601.03154)
*Beiduo Chen,Tiancheng Hu,Caiqi Zhang,Robert Litschko,Anna Korhonen,Barbara Plank*

Main category: cs.CL

TL;DR: 长链思维推理调优的大语言模型在单答案任务表现出色，但在需要捕捉概率模糊性而非解决模糊性的任务（如人类标签变异建模）中能力有限，表现出"解耦机制"：推理文本决定最终准确率，而模型先验主导分布排序。


<details>
  <summary>Details</summary>
Motivation: 虽然推理调优的大语言模型在单答案任务中表现出色，但它们能否有效建模人类标签变异（即捕捉概率模糊性而非解决模糊性）尚未得到充分探索。作者希望通过系统解耦实验来研究这个问题。

Method: 通过基于分布的任务进行系统解耦实验，采用Cross-CoT实验来分离推理文本和内在模型先验的影响。进行逐步分析来追踪推理过程中不同阶段的影响。

Result: 发现明显的"解耦机制"：虽然CoT改善了分布对齐，但最终准确率由CoT内容决定（贡献99%方差），而分布排序由模型先验主导（超过80%）。逐步分析显示，CoT对准确率的影响在推理过程中单调增长，但分布结构主要由LLM的内在先验决定。

Conclusion: 长链思维推理可以作为大语言模型决定最佳选项的决策者，但在模糊任务中无法作为细粒度的分布校准器。这意味着当前推理方法在捕捉概率模糊性方面存在局限。

Abstract: Reasoning-tuned LLMs utilizing long Chain-of-Thought (CoT) excel at single-answer tasks, yet their ability to model Human Label Variation--which requires capturing probabilistic ambiguity rather than resolving it--remains underexplored. We investigate this through systematic disentanglement experiments on distribution-based tasks, employing Cross-CoT experiments to isolate the effect of reasoning text from intrinsic model priors. We observe a distinct "decoupled mechanism": while CoT improves distributional alignment, final accuracy is dictated by CoT content (99% variance contribution), whereas distributional ranking is governed by model priors (over 80%). Step-wise analysis further shows that while CoT's influence on accuracy grows monotonically during the reasoning process, distributional structure is largely determined by LLM's intrinsic priors. These findings suggest that long CoT serves as a decisive LLM decision-maker for the top option but fails to function as a granular distribution calibrator for ambiguous tasks.

</details>


### [73] [WebAnchor: Anchoring Agent Planning to Stabilize Long-Horizon Web Reasoning](https://arxiv.org/abs/2601.03164)
*Yu Xinmiao,Zhang Liwen,Feng Xiaocheng,Jiang Yong,Qin Bing,Xie Pengjun,Zhou Jingren*

Main category: cs.CL

TL;DR: Anchor-GRPO：一种两阶段强化学习框架，通过解耦规划和执行来解决长时程网页推理中的"计划锚点"问题，显著提升任务成功率和工具使用效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体在网页信息搜索中面临规划瓶颈，特别是在长时程策略上表现不佳。研究发现存在"计划锚点"现象，即第一个推理步骤对下游行为产生不成比例的影响，而当前RL算法未能考虑这一点，将奖励均匀分布在轨迹上。

Method: 提出Anchor-GRPO两阶段RL框架：第一阶段通过从自我对弈经验和人工校准中获得的细粒度评估标准优化第一步规划；第二阶段通过稀疏奖励将执行与初始计划对齐，确保稳定高效的工具使用。

Result: 在BrowseComp、BrowseComp-Zh、GAIA和XBench-DeepSearch四个基准测试中，Anchor-GRPO在3B到30B的模型上都优于基线GRPO和First-step GRPO。WebAnchor-30B在BrowseComp上达到46.0% pass@1，在GAIA上达到76.4%。框架还表现出良好的可扩展性，随着模型规模和上下文长度增加获得更高准确率。

Conclusion: Anchor-GRPO通过解决"计划锚点"问题有效提升了长时程网页推理任务的性能，为基于LLM的智能体优化提供了新思路，并展示了良好的可扩展性。

Abstract: Large Language Model(LLM)-based agents have shown strong capabilities in web information seeking, with reinforcement learning (RL) becoming a key optimization paradigm. However, planning remains a bottleneck, as existing methods struggle with long-horizon strategies. Our analysis reveals a critical phenomenon, plan anchor, where the first reasoning step disproportionately impacts downstream behavior in long-horizon web reasoning tasks. Current RL algorithms, fail to account for this by uniformly distributing rewards across the trajectory. To address this, we propose Anchor-GRPO, a two-stage RL framework that decouples planning and execution. In Stage 1, the agent optimizes its first-step planning using fine-grained rubrics derived from self-play experiences and human calibration. In Stage 2, execution is aligned with the initial plan through sparse rewards, ensuring stable and efficient tool usage. We evaluate Anchor-GRPO on four benchmarks: BrowseComp, BrowseComp-Zh, GAIA, and XBench-DeepSearch. Across models from 3B to 30B, Anchor-GRPO outperforms baseline GRPO and First-step GRPO, improving task success and tool efficiency. Notably, WebAnchor-30B achieves 46.0% pass@1 on BrowseComp and 76.4% on GAIA. Anchor-GRPO also demonstrates strong scalability, getting higher accuracy as model size and context length increase.

</details>


### [74] [Can Embedding Similarity Predict Cross-Lingual Transfer? A Systematic Study on African Languages](https://arxiv.org/abs/2601.03168)
*Tewodros Kederalah Idris,Prasenjit Mitra,Roald Eiselen*

Main category: cs.CL

TL;DR: 该论文系统评估了五种嵌入相似度指标在预测跨语言迁移性能中的有效性，发现余弦差距和检索类指标表现良好，但需要注意模型特异性以避免辛普森悖论。


<details>
  <summary>Details</summary>
Motivation: 对于非洲低资源语言，缺乏可靠的源语言选择方法。实践者需要有效指标来预测跨语言迁移的成功率，以构建更好的NLP系统。

Method: 系统评估五种嵌入相似度指标：在816个迁移实验中，涵盖三个NLP任务、三个非洲中心多语言模型和来自四个语系的12种语言。

Result: 余弦差距和检索类指标（P@1、CSLS）能可靠预测迁移成功率（ρ=0.4-0.6），而CKA几乎没有预测能力（ρ≈0.1）。关键发现是：当跨模型聚合数据时，相关性符号会反转（辛普森悖论），因此必须按模型验证。嵌入指标的预测能力与URIEL语言类型学相当。

Conclusion: 研究为源语言选择提供了具体指导，强调了模型特异性分析的重要性，建议使用余弦差距或检索类指标进行预测，但必须针对具体模型进行验证。

Abstract: Cross-lingual transfer is essential for building NLP systems for low-resource African languages, but practitioners lack reliable methods for selecting source languages. We systematically evaluate five embedding similarity metrics across 816 transfer experiments spanning three NLP tasks, three African-centric multilingual models, and 12 languages from four language families. We find that cosine gap and retrieval-based metrics (P@1, CSLS) reliably predict transfer success ($ρ= 0.4-0.6$), while CKA shows negligible predictive power ($ρ\approx 0.1$). Critically, correlation signs reverse when pooling across models (Simpson's Paradox), so practitioners must validate per-model. Embedding metrics achieve comparable predictive power to URIEL linguistic typology. Our results provide concrete guidance for source language selection and highlight the importance of model-specific analysis.

</details>


### [75] [Maximizing Local Entropy Where It Matters: Prefix-Aware Localized LLM Unlearning](https://arxiv.org/abs/2601.03190)
*Naixin Zhai,Pengyang Shao,Binbin Zheng,Fei Shen,Long Bai,Xun Yang*

Main category: cs.CL

TL;DR: PALU提出了一种针对LLMs的机器遗忘框架，通过局部熵最大化在时间和词汇维度上进行精确遗忘，仅抑制敏感前缀和扁平化top-k logits，减少对模型通用性能的损害。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法通常对所有响应标记进行无差别处理，并在整个词汇表上强制不确定性，导致不必要的性能下降和扩展到内容无关区域的优化。

Method: 提出PALU框架，基于局部熵最大化目标，在时间和词汇维度上进行精确遗忘：1）仅抑制敏感前缀以切断因果生成链路；2）仅扁平化top-k logits以最大化关键子空间的不确定性。

Result: 大量实验验证PALU在遗忘效果和通用性能保持方面优于现有基线方法。

Conclusion: PALU通过局部化方法实现了高效、精确的机器遗忘，避免了冗余优化并最小化了对模型通用性能的损害。

Abstract: Machine unlearning aims to forget sensitive knowledge from Large Language Models (LLMs) while maintaining general utility. However, existing approaches typically treat all tokens in a response indiscriminately and enforce uncertainty over the entire vocabulary. This global treatment results in unnecessary utility degradation and extends optimization to content-agnostic regions. To address these limitations, we propose PALU (Prefix-Aware Localized Unlearning), a framework driven by a local entropy maximization objective across both temporal and vocabulary dimensions. PALU reveals that (i) suppressing the sensitive prefix alone is sufficient to sever the causal generation link, and (ii) flattening only the top-$k$ logits is adequate to maximize uncertainty in the critical subspace. These findings allow PALU to avoid redundant optimization across the full vocabulary and parameter space while minimizing collateral damage to general model performance. Extensive experiments validate that PALU achieves superior forgetting efficacy and utility preservation compared to state-of-the-art baselines.

</details>


### [76] [MemRL: Self-Evolving Agents via Runtime Reinforcement Learning on Episodic Memory](https://arxiv.org/abs/2601.03192)
*Shengtao Zhang,Jiaqian Wang,Ruiwen Zhou,Junwei Liao,Yuchen Feng,Weinan Zhang,Ying Wen,Zhiyu Li,Feiyu Xiong,Yutao Qi,Bo Tang,Muning Wen*

Main category: cs.CL

TL;DR: MemRL是一个通过非参数强化学习在情景记忆上实现智能体自我进化的框架，通过将稳定的LLM推理与可塑的记忆分离，使用两阶段检索机制，显著提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 人类智能能够通过情景模拟从过去经验中合成新任务的解决方案，而现有大型语言模型虽然具备强大推理能力，但难以模拟这种自我进化。微调计算成本高且容易导致灾难性遗忘，而现有的基于记忆的方法依赖被动的语义匹配，经常检索到噪声信息。

Method: MemRL框架通过非参数强化学习在情景记忆上实现智能体自我进化。它明确分离了冻结LLM的稳定推理与可塑、进化的记忆。采用两阶段检索机制：首先通过语义相关性过滤候选记忆，然后基于学习的Q值（效用）进行选择。这些效用通过环境反馈以试错方式持续优化，使智能体能够区分高价值策略和相似噪声。

Result: 在HLE、BigCodeBench、ALFWorld和Lifelong Agent Bench等基准测试上的大量实验表明，MemRL显著优于现有最先进的基线方法。分析实验证实MemRL有效解决了稳定性-可塑性困境，实现了无需权重更新的持续运行时改进。

Conclusion: MemRL框架成功实现了智能体通过情景记忆的自我进化，解决了传统方法在计算成本、灾难性遗忘和噪声检索方面的局限性，为持续学习系统提供了新的解决方案。

Abstract: The hallmark of human intelligence is the ability to master new skills through Constructive Episodic Simulation-retrieving past experiences to synthesize solutions for novel tasks. While Large Language Models possess strong reasoning capabilities, they struggle to emulate this self-evolution: fine-tuning is computationally expensive and prone to catastrophic forgetting, while existing memory-based methods rely on passive semantic matching that often retrieves noise. To address these challenges, we propose MemRL, a framework that enables agents to self-evolve via non-parametric reinforcement learning on episodic memory. MemRL explicitly separates the stable reasoning of a frozen LLM from the plastic, evolving memory. Unlike traditional methods, MemRL employs a Two-Phase Retrieval mechanism that filters candidates by semantic relevance and then selects them based on learned Q-values (utility). These utilities are continuously refined via environmental feedback in an trial-and-error manner, allowing the agent to distinguish high-value strategies from similar noise. Extensive experiments on HLE, BigCodeBench, ALFWorld, and Lifelong Agent Bench demonstrate that MemRL significantly outperforms state-of-the-art baselines. Our analysis experiments confirm that MemRL effectively reconciles the stability-plasticity dilemma, enabling continuous runtime improvement without weight updates.

</details>


### [77] [X-MuTeST: A Multilingual Benchmark for Explainable Hate Speech Detection and A Novel LLM-consulted Explanation Framework](https://arxiv.org/abs/2601.03194)
*Mohammad Zia Ur Rehman,Sai Kartheek Reddy Kasu,Shashivardhan Reddy Koppula,Sai Rithwik Reddy Chirra,Shwetank Shekhar Singh,Nagendra Kumar*

Main category: cs.CL

TL;DR: X-MuTeST是一个用于仇恨言论检测的可解释性训练框架，结合LLM语义推理与传统注意力增强技术，在印地语、泰卢固语和英语上提供基准人类标注理由，提升分类性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体仇恨言论检测在准确性和可解释性方面面临挑战，特别是在资源不足的印度语言中。现有方法缺乏有效的解释机制，需要结合人类理由和模型注意力来改善检测效果。

Method: 提出X-MuTeST框架：1) 使用LLM进行高级语义推理；2) 计算原始文本与unigram/bigram/trigram的预测概率差异；3) 将LLM解释与X-MuTeST解释结合；4) 利用人类标注理由训练模型；5) 结合人类理由优化模型注意力。

Result: 在6,004个印地语、4,492个泰卢固语和6,334个英语样本上评估，显示：1) 使用人类理由训练提升分类性能和可解释性；2) 结合人类理由与可解释性方法进一步改进；3) 在合理性（Token-F1、IOU-F1）和忠实性（Comprehensiveness、Sufficiency）指标上表现良好。

Conclusion: X-MuTeST框架通过结合LLM语义推理、传统注意力技术和人类标注理由，有效提升了仇恨言论检测的准确性和可解释性，特别是在资源不足的语言中，推动了跨语言仇恨言论检测的发展。

Abstract: Hate speech detection on social media faces challenges in both accuracy and explainability, especially for underexplored Indic languages. We propose a novel explainability-guided training framework, X-MuTeST (eXplainable Multilingual haTe Speech deTection), for hate speech detection that combines high-level semantic reasoning from large language models (LLMs) with traditional attention-enhancing techniques. We extend this research to Hindi and Telugu alongside English by providing benchmark human-annotated rationales for each word to justify the assigned class label. The X-MuTeST explainability method computes the difference between the prediction probabilities of the original text and those of unigrams, bigrams, and trigrams. Final explanations are computed as the union between LLM explanations and X-MuTeST explanations. We show that leveraging human rationales during training enhances both classification performance and explainability. Moreover, combining human rationales with our explainability method to refine the model attention yields further improvements. We evaluate explainability using Plausibility metrics such as Token-F1 and IOU-F1 and Faithfulness metrics such as Comprehensiveness and Sufficiency. By focusing on under-resourced languages, our work advances hate speech detection across diverse linguistic contexts. Our dataset includes token-level rationale annotations for 6,004 Hindi, 4,492 Telugu, and 6,334 English samples. Data and code are available on https://github.com/ziarehman30/X-MuTeST

</details>


### [78] [DIP: Dynamic In-Context Planner For Diffusion Language Models](https://arxiv.org/abs/2601.03199)
*Yang Li,Han Meng,Chenan Wang,Haipeng Chen*

Main category: cs.CL

TL;DR: 提出DIP方法，通过动态选择和插入上下文示例来加速扩散语言模型的推理，在保持生成质量的同时实现高达12.9倍的推理加速。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然展现出强大的自然语言处理能力，但由于其双向注意力机制，随着上下文长度增加会带来显著的计算开销。需要解决扩散模型在长上下文场景下的效率问题。

Method: 基于扩散生成范式允许在生成过程中动态调整上下文的特点，提出了动态上下文规划器(DIP)。该方法不是一次性提供所有上下文示例，而是在生成过程中动态选择和插入相关示例。

Result: DIP在保持生成质量的同时，实现了高达12.9倍的标准推理加速，以及1.17倍的KV缓存增强推理加速。

Conclusion: 扩散语言模型的生成范式允许高效的动态上下文调整，DIP方法通过动态选择上下文示例显著提升了推理效率，为解决扩散模型的计算开销问题提供了有效方案。

Abstract: Diffusion language models (DLMs) have shown strong potential for general natural language tasks with in-context examples. However, due to the bidirectional attention mechanism, DLMs incur substantial computational cost as context length increases. This work addresses this issue with a key discovery: unlike the sequential generation in autoregressive language models (ARLMs), the diffusion generation paradigm in DLMs allows \textit{efficient dynamic adjustment of the context} during generation. Building on this insight, we propose \textbf{D}ynamic \textbf{I}n-Context \textbf{P}lanner (DIP), a context-optimization method that dynamically selects and inserts in-context examples during generation, rather than providing all examples in the prompt upfront. Results show DIP maintains generation quality while achieving up to 12.9$\times$ inference speedup over standard inference and 1.17$\times$ over KV cache-enhanced inference.

</details>


### [79] [UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward](https://arxiv.org/abs/2601.03205)
*Yile Liu,Yixian Liu,Zongwei Li,Yufei Huang,Xinhua Feng,Zhichao Hu,Jinglu Hu,Jianfeng Yan,Fengzong Lian,Yuhong Liu*

Main category: cs.CL

TL;DR: 提出UltraLogic框架，通过代码化求解方法将问题逻辑核心与自然语言表达解耦，自动化生成高质量、难度分级的大规模推理数据，并使用双极浮点奖励机制提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自然语言处理方面表现出潜力，但需要多步逻辑、规划和验证的复杂通用推理仍然是关键瓶颈。现有的可验证奖励强化学习在特定领域成功，但缺乏大规模、高质量、难度校准的通用推理数据。

Method: 提出UltraLogic框架：1）采用代码化求解方法将问题逻辑核心与自然语言表达解耦；2）包含数百种独特任务类型和跨十个难度级别的自动校准流程；3）引入双极浮点奖励机制，使用分级惩罚区分完美响应与存在逻辑缺陷的响应。

Result: 实验表明：任务多样性是推理能力提升的主要驱动力；双极浮点奖励结合难度匹配策略显著提高了训练效率，引导模型达到全局逻辑最优。

Conclusion: UltraLogic框架通过自动化生成高质量、难度分级的推理数据，结合创新的奖励机制，有效解决了通用推理中的数据瓶颈问题，为提升大语言模型的复杂推理能力提供了系统化解决方案。

Abstract: While Large Language Models (LLMs) have demonstrated significant potential in natural language processing , complex general-purpose reasoning requiring multi-step logic, planning, and verification remains a critical bottleneck. Although Reinforcement Learning with Verifiable Rewards (RLVR) has succeeded in specific domains , the field lacks large-scale, high-quality, and difficulty-calibrated data for general reasoning. To address this, we propose UltraLogic, a framework that decouples the logical core of a problem from its natural language expression through a Code-based Solving methodology to automate high-quality data production. The framework comprises hundreds of unique task types and an automated calibration pipeline across ten difficulty levels. Furthermore, to mitigate binary reward sparsity and the Non-negative Reward Trap, we introduce the Bipolar Float Reward (BFR) mechanism, utilizing graded penalties to effectively distinguish perfect responses from those with logical flaws. Our experiments demonstrate that task diversity is the primary driver for reasoning enhancement , and that BFR, combined with a difficulty matching strategy, significantly improves training efficiency, guiding models toward global logical optima.

</details>


### [80] [MalruleLib: Large-Scale Executable Misconception Reasoning with Step Traces for Modeling Student Thinking in Mathematics](https://arxiv.org/abs/2601.03217)
*Xinghe Chen,Naiming Liu,Shashank Sonkar*

Main category: cs.CL

TL;DR: MalruleLib是一个基于学习科学的框架，将数学误解转化为可执行程序，用于生成学生错误推理的逐步轨迹，支持教育AI进行跨情境的学生建模和诊断。


<details>
  <summary>Details</summary>
Motivation: 学生在数学中经常出现系统性错误：他们会应用一致但错误的程序，并在不同情境中重复这些错误。需要一种能够捕捉这些误解并生成相应学生推理轨迹的方法，以支持教育AI进行更准确的学生建模和诊断。

Method: 基于67个学习科学和数学教育文献，将文档化的误解转化为可执行程序（malrules）。构建了101个malrules覆盖498个参数化问题模板，生成成对的正确推理路径和malrule一致的学生推理路径的逐步轨迹。

Result: 1. 语言模型在跨模板误解预测上的准确率从直接问题解决的66%下降到40%；2. MalruleLib可生成超过100万个实例；3. 跨模板预测性能下降10-21%；4. 提供学生步骤轨迹可将预测准确率提高3-15%。

Conclusion: MalruleLib为教育AI提供了基础设施，能够跨情境建模学生程序，支持针对底层误解的诊断和反馈，解决了学生建模中的核心问题。

Abstract: Student mistakes in mathematics are often systematic: a learner applies a coherent but wrong procedure and repeats it across contexts. We introduce MalruleLib, a learning-science-grounded framework that translates documented misconceptions into executable procedures, drawing on 67 learning-science and mathematics education sources, and generates step-by-step traces of malrule-consistent student work. We formalize a core student-modeling problem as Malrule Reasoning Accuracy (MRA): infer a misconception from one worked mistake and predict the student's next answer under cross-template rephrasing. Across nine language models (4B-120B), accuracy drops from 66% on direct problem solving to 40% on cross-template misconception prediction. MalruleLib encodes 101 malrules over 498 parameterized problem templates and produces paired dual-path traces for both correct reasoning and malrule-consistent student reasoning. Because malrules are executable and templates are parameterizable, MalruleLib can generate over one million instances, enabling scalable supervision and controlled evaluation. Using MalruleLib, we observe cross-template degradations of 10-21%, while providing student step traces improves prediction by 3-15%. We release MalruleLib as infrastructure for educational AI that models student procedures across contexts, enabling diagnosis and feedback that targets the underlying misconception.

</details>


### [81] [Multi-RADS Synthetic Radiology Report Dataset and Head-to-Head Benchmarking of 41 Open-Weight and Proprietary Language Models](https://arxiv.org/abs/2601.03232)
*Kartik Bose,Abhinandan Kumar,Raghuraman Soundararajan,Priya Mudgil,Samonee Ralmilay,Niharika Dutta,Manphool Singhal,Arun Kumar,Saugata Sen,Anurima Patra,Priya Ghosh,Abanti Das,Amit Gupta,Ashish Verma,Dipin Sudhakaran,Ekta Dhamija,Himangi Unde,Ishan Kumar,Krithika Rangarajan,Prerna Garg,Rachel Sequeira,Sudhin Shylendran,Taruna Yadav,Tej Pal,Pankaj Gupta*

Main category: cs.CL

TL;DR: 该研究创建了RXL-RADSet基准数据集，评估了开源小语言模型与专有模型在放射学报告风险分类任务上的性能，发现大型SLMs（20-32B参数）在引导提示下可接近专有模型表现。


<details>
  <summary>Details</summary>
Motivation: 放射学报告和数据分析系统（RADS）标准化了风险沟通，但自动化RADS分配面临挑战：指南复杂、输出格式限制、跨RADS框架和模型大小的基准测试有限。

Method: 创建RXL-RADSet包含1,600份合成放射学报告，涵盖10种RADS标准和多种成像模态。使用LLMs生成报告，经过两阶段放射科医生验证。评估41个量化SLMs（0.135-32B参数）和GPT-5.2，使用固定引导提示。主要终点是有效性和准确性。

Result: GPT-5.2在引导提示下达到99.8%有效性和81.1%准确性。SLMs总体达到96.8%有效性和61.1%准确性；最佳SLMs（20-32B）达到约99%有效性和70%+准确性。性能随模型规模增加而提升（拐点在<1B和>=10B之间）。引导提示相比零样本提示显著改善性能。

Conclusion: RXL-RADSet提供了放射科医生验证的多RADS基准；大型SLMs（20-32B）在引导提示下可接近专有模型性能，但对于更高复杂度的RADS方案仍存在差距。

Abstract: Background: Reporting and Data Systems (RADS) standardize radiology risk communication but automated RADS assignment from narrative reports is challenging because of guideline complexity, output-format constraints, and limited benchmarking across RADS frameworks and model sizes. Purpose: To create RXL-RADSet, a radiologist-verified synthetic multi-RADS benchmark, and compare validity and accuracy of open-weight small language models (SLMs) with a proprietary model for RADS assignment. Materials and Methods: RXL-RADSet contains 1,600 synthetic radiology reports across 10 RADS (BI-RADS, CAD-RADS, GB-RADS, LI-RADS, Lung-RADS, NI-RADS, O-RADS, PI-RADS, TI-RADS, VI-RADS) and multiple modalities. Reports were generated by LLMs using scenario plans and simulated radiologist styles and underwent two-stage radiologist verification. We evaluated 41 quantized SLMs (12 families, 0.135-32B parameters) and GPT-5.2 under a fixed guided prompt. Primary endpoints were validity and accuracy; a secondary analysis compared guided versus zero-shot prompting. Results: Under guided prompting GPT-5.2 achieved 99.8% validity and 81.1% accuracy (1,600 predictions). Pooled SLMs (65,600 predictions) achieved 96.8% validity and 61.1% accuracy; top SLMs in the 20-32B range reached ~99% validity and mid-to-high 70% accuracy. Performance scaled with model size (inflection between <1B and >=10B) and declined with RADS complexity primarily due to classification difficulty rather than invalid outputs. Guided prompting improved validity (99.2% vs 96.7%) and accuracy (78.5% vs 69.6%) compared with zero-shot. Conclusion: RXL-RADSet provides a radiologist-verified multi-RADS benchmark; large SLMs (20-32B) can approach proprietary-model performance under guided prompting, but gaps remain for higher-complexity schemes.

</details>


### [82] [STReasoner: Empowering LLMs for Spatio-Temporal Reasoning in Time Series via Spatial-Aware Reinforcement Learning](https://arxiv.org/abs/2601.03248)
*Juntong Ni,Shiyu Wang,Ming Jin,Qi He,Wei Jin*

Main category: cs.CL

TL;DR: 提出ST-Bench基准测试和STReasoner模型，用于时空时间序列的显式推理，相比专有模型成本仅0.004倍但性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 现有研究过于关注预测准确性而忽视推理能力，时空时间序列推理对交通网络、电网、疾病传播等高风险决策系统至关重要，但该领域发展不足。

Method: 1) 提出ST-Bench基准，包含四个核心任务；2) 基于网络SDE的多智能体数据合成管道；3) 提出STReasoner模型，使LLM能够整合时间序列、图结构和文本进行显式推理；4) 引入S-GRPO强化学习算法，专门奖励空间信息带来的性能提升。

Result: STReasoner在基准测试中平均准确率提升17%-135%，成本仅为专有模型的0.004倍，在真实世界数据上展现出强大的泛化能力。

Conclusion: 通过ST-Bench基准和STReasoner模型，解决了时空时间序列推理领域的不足，实现了低成本高性能的显式推理，为高风险决策系统提供了重要工具。

Abstract: Spatio-temporal reasoning in time series involves the explicit synthesis of temporal dynamics, spatial dependencies, and textual context. This capability is vital for high-stakes decision-making in systems such as traffic networks, power grids, and disease propagation. However, the field remains underdeveloped because most existing works prioritize predictive accuracy over reasoning. To address the gap, we introduce ST-Bench, a benchmark consisting of four core tasks, including etiological reasoning, entity identification, correlation reasoning, and in-context forecasting, developed via a network SDE-based multi-agent data synthesis pipeline. We then propose STReasoner, which empowers LLM to integrate time series, graph structure, and text for explicit reasoning. To promote spatially grounded logic, we introduce S-GRPO, a reinforcement learning algorithm that rewards performance gains specifically attributable to spatial information. Experiments show that STReasoner achieves average accuracy gains between 17% and 135% at only 0.004X the cost of proprietary models and generalizes robustly to real-world data.

</details>


### [83] [Automated Semantic Rules Detection (ASRD) for Emergent Communication Interpretation](https://arxiv.org/abs/2601.03254)
*Bastien Vanderplaetse,Xavier Siebert,Stéphane Dupont*

Main category: cs.CL

TL;DR: 提出ASRD算法自动检测多智能体涌现通信中的语义规则，提升通信可解释性


<details>
  <summary>Details</summary>
Motivation: 当前多智能体涌现通信研究缺乏对通信可解释性的关注，需要工具来解释自主发展的通信策略

Method: 提出自动化语义规则检测(ASRD)算法，在Lewis Game中训练智能体，从交换信息中提取模式，将模式与输入数据属性关联

Result: ASRD算法能有效提取相关模式，将模式与输入数据特定属性关联，显著简化后续分析

Conclusion: ASRD算法为涌现通信的可解释性提供了有效工具，能自动检测语义规则，促进对自主发展通信策略的理解

Abstract: The field of emergent communication within multi-agent systems examines how autonomous agents can independently develop communication strategies, without explicit programming, and adapt them to varied environments. However, few studies have focused on the interpretability of emergent languages. The research exposed in this paper proposes an Automated Semantic Rules Detection (ASRD) algorithm, which extracts relevant patterns in messages exchanged by agents trained with two different datasets on the Lewis Game, which is often studied in the context of emergent communication. ASRD helps at the interpretation of the emergent communication by relating the extracted patterns to specific attributes of the input data, thereby considerably simplifying subsequent analysis.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [84] [GCRank: A Generative Contextual Comprehension Paradigm for Takeout Ranking Model](https://arxiv.org/abs/2601.02361)
*Ziheng Ni,Congcong Liu,Cai Shang,Yiming Sun,Junjie Li,Zhiwei Fang,Guangpeng Chen,Jian Li,Zehua Zhang,Changping Peng,Zhangang Lin,Ching Law,Jingping Shao*

Main category: cs.IR

TL;DR: 提出生成式上下文理解框架，通过统一架构建模异构信号，在餐饮外卖广告平台实现显著业务提升


<details>
  <summary>Details</summary>
Motivation: 现有广告排序模型依赖碎片化模块和手工特征，难以理解复杂用户意图，尤其在基于位置的服务中，用户决策受动态空间、时间和个体上下文影响

Method: 提出生成式框架将排序重构为上下文理解任务，包含两个核心组件：生成式上下文编码器（GCE）和生成式上下文融合（GCF）。GCE包含个性化上下文增强器（PCE）、集体上下文增强器（CCE）和动态上下文增强器（DCE）三个专门模块

Result: 在关键业务指标上取得显著提升，包括点击率和平台收入，已成功部署在大规模餐饮外卖广告平台，展现了实际影响

Conclusion: 这项工作开创了生成式推荐的新视角，突出了其在工业广告系统中的实际潜力

Abstract: The ranking stage serves as the central optimization and allocation hub in advertising systems, governing economic value distribution through eCPM and orchestrating the user-centric blending of organic and advertising content. Prevailing ranking models often rely on fragmented modules and hand-crafted features, limiting their ability to interpret complex user intent. This challenge is further amplified in location-based services such as food delivery, where user decisions are shaped by dynamic spatial, temporal, and individual contexts. To address these limitations, we propose a novel generative framework that reframes ranking as a context comprehension task, modeling heterogeneous signals in a unified architecture. Our architecture consists of two core components: the Generative Contextual Encoder (GCE) and the Generative Contextual Fusion (GCF). The GCE comprises three specialized modules: a Personalized Context Enhancer (PCE) for user-specific modeling, a Collective Context Enhancer (CCE) for group-level patterns, and a Dynamic Context Enhancer (DCE) for real-time situational adaptation. The GCF module then seamlessly integrates these contextual representations through low-rank adaptation. Extensive experiments confirm that our method achieves significant gains in critical business metrics, including click-through rate and platform revenue. We have successfully deployed our method on a large-scale food delivery advertising platform, demonstrating its substantial practical impact. This work pioneers a new perspective on generative recommendation and highlights its practical potential in industrial advertising systems.

</details>


### [85] [The Impact of LLM-Generated Reviews on Recommender Systems: Textual Shifts, Performance Effects, and Strategic Platform Control](https://arxiv.org/abs/2601.02362)
*Itzhak Ziv,Moshe Unger,Hilah Geva*

Main category: cs.IR

TL;DR: 研究AI生成评论对推荐系统的影响，发现人类评论训练模型表现最佳，平台控制的AI生成策略更有效


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的发展，推荐系统越来越多地接触到AI生成内容与人类创作内容并存的情况，需要了解AI生成评论如何影响推荐系统性能和商业结果

Method: 使用TripAdvisor酒店评论数据集，通过LLMs生成合成评论，分析用户中心（个人使用AI工具优化评论）和平台中心（平台从结构化元数据直接生成评论）两种AI内容引入途径，评估AI评论对推荐系统训练和部署阶段的影响

Result: AI生成评论在多个文本维度上与人类评论存在系统性差异；虽然两种AI评论都能提升推荐系统性能，但人类评论训练模型始终表现最优；人类训练模型能稳健地泛化到AI内容，而AI训练模型对两种内容类型都表现不佳；基于语调的框架策略（鼓励性、建设性或批判性）能显著提升平台生成评论的效果

Conclusion: 平台控制在AI生成评论的生成和整合中具有战略重要性，确保合成内容能够补充推荐系统的稳健性和可持续商业价值

Abstract: The rise of generative AI technologies is reshaping content-based recommender systems (RSes), which increasingly encounter AI-generated content alongside human-authored content. This study examines how the introduction of AI-generated reviews influences RS performance and business outcomes. We analyze two distinct pathways through which AI content can enter RSes: user-centric, in which individuals use AI tools to refine their reviews, and platform-centric, in which platforms generate synthetic reviews directly from structured metadata. Using a large-scale dataset of hotel reviews from TripAdvisor, we generate synthetic reviews using LLMs and evaluate their impact across the training and deployment phases of RSes. We find that AI-generated reviews differ systematically from human-authored reviews across multiple textual dimensions. Although both user- and platform-centric AI reviews enhance RS performance relative to models without textual data, models trained on human reviews consistently achieve superior performance, underscoring the quality of authentic human data. Human-trained models generalize robustly to AI content, whereas AI-trained models underperform on both content types. Furthermore, tone-based framing strategies (encouraging, constructive, or critical) substantially enhance platform-generated review effectiveness. Our findings highlight the strategic importance of platform control in governing the generation and integration of AI-generated reviews, ensuring that synthetic content complements recommendation robustness and sustainable business value.

</details>


### [86] [Towards Trustworthy LLM-Based Recommendation via Rationale Integration](https://arxiv.org/abs/2601.02364)
*Chung Park,Taesan Kim,Hyeongjun Yun,Dongjoon Hong,Junui Hong,Kijung Park,MinCheol Cho,Mira Myong,Jihoon Oh,Min sung Choi*

Main category: cs.IR

TL;DR: 本文提出了一种基于LLM的推荐系统LLM-Rec，它不仅预测推荐物品，还生成逻辑推理依据，通过"推理优先"的指令调优提升推荐性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统主要优化准确性和短期参与度，忽视了透明度和可信度。虽然亚马逊和Instagram等平台开始提供推荐理由，但大多数系统仍将其视为事后产物。需要一种能生成逻辑推理依据的推荐系统来增强用户信任和参与度。

Method: 提出LLM-Rec推荐系统，采用基于LLM的方法，使用自标注的推理数据集和"推理优先"格式的指令调优，模型先生成解释再输出推荐物品，采用思维链风格的推理表示。

Result: 在Amazon Review数据集的时尚和科学领域实验中，LLM-Rec相比现有基线方法表现出显著改进，同时公开发布了包含用户历史、推理和推荐物品的数据集以促进可复现性。

Conclusion: LLM-Rec通过生成逻辑推理依据不仅增强了推荐系统的可解释性，还提升了推荐性能，为构建更透明可信的推荐系统提供了有效方法。

Abstract: Traditional recommender systems (RS) have been primarily optimized for accuracy and short-term engagement, often overlooking transparency and trustworthiness. Recently, platforms such as Amazon and Instagram have begun providing recommendation rationales to users, acknowledging their critical role in fostering trust and enhancing engagement; however, most existing systems still treat them as post-hoc artifacts. We propose an LLM-based recommender (LLM-Rec) that not only predicts items but also generates logically grounded rationales. Our approach leverages a self-annotated rationale dataset and instruction tuning in a rationale-first format, where the model generates an explanation before outputting the recommended item. By adopting this strategy and representing rationales in a chain-of-thought (CoT) style, LLM-Rec strengthens both interpretability and recommendation performance. Experiments on the Fashion and Scientific domains of the Amazon Review dataset demonstrate significant improvements over well-established baselines. To encourage reproducibility and future research, we publicly release a rationale-augmented recommendation dataset containing user histories, rationales, and recommended items.

</details>


### [87] [FUSE : Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation](https://arxiv.org/abs/2601.02365)
*Tushar Vatsa,Vibha Belavadi,Priya Shanmugasundaram,Suhas Suresha,Dewang Sultania*

Main category: cs.IR

TL;DR: FUSE是一个多模态搜索推荐系统，通过使用紧凑的Grounded Design Representation替代原始图像提示，结合七种上下文预算策略和管道归因层监控，显著提升检索质量和系统性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态创意助手在检索质量上面临多种挑战：用户意图理解、内容类型选择、候选查找和结果排序都可能失败。同时，发送和处理原始图像成本高昂，使得朴素的多模态方法不切实际。

Method: FUSE使用Grounded Design Representation（GDR）作为紧凑的JSON表示替代原始图像，包含画布元素、结构、样式、显著颜色和用户选择。系统实现七种上下文预算策略：全面基线提示、上下文压缩、思维链推理、小样本优化、检索增强上下文、两阶段处理和零样本最小化。最后通过管道归因层监控系统性能。

Result: 在788个评估查询上的系统评估显示，上下文压缩策略在所有管道阶段表现最佳：意图准确率93.3%，路由成功率86.8%（含后备方案），召回率99.4%，NDCG@5为88.5%。

Conclusion: 研究表明，战略性的上下文摘要优于全面和最小化的上下文策略。FUSE通过紧凑表示和智能上下文管理，有效解决了多模态检索中的关键挑战。

Abstract: Multimodal creative assistants decompose user goals and route tasks to subagents for layout, styling, retrieval, and generation. Retrieval quality is pivotal, yet failures can arise at several stages: understanding user intent, choosing content types, finding candidates (recall), or ranking results. Meanwhile, sending and processing images is costly, making naive multimodal approaches impractical. We present FUSE: Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation. FUSE replaces most raw-image prompting with a compact Grounded Design Representation (GDR): a selection aware JSON of canvas elements (image, text, shape, icon, video, logo), structure, styles, salient colors, and user selection provided by the Planner team. FUSE implements seven context budgeting strategies: comprehensive baseline prompting, context compression, chain-of-thought reasoning, mini-shot optimization, retrieval-augmented context, two-stage processing, and zero-shot minimalism. Finally, a pipeline attribution layer monitors system performance by converting subagent signals into simple checks: intent alignment, content-type/routing sanity, recall health (e.g., zero-hit and top-match strength), and ranking displacement analysis. We evaluate the seven context budgeting variants across 788 evaluation queries from diverse users and design templates (refer Figure 3). Our systematic evaluation reveals that Context Compression achieves optimal performance across all pipeline stages, with 93.3% intent accuracy, 86.8% routing success(with fallbacks), 99.4% recall, and 88.5% NDCG@5. This approach demonstrates that strategic context summarization outperforms both comprehensive and minimal contextualization strategies.

</details>


### [88] [TextBridgeGNN: Pre-training Graph Neural Network for Cross-Domain Recommendation via Text-Guided Transfer](https://arxiv.org/abs/2601.02366)
*Yiwen Chen,Yiqing Wu,Huishi Luo,Fuzhen Zhuang,Deqing Wang*

Main category: cs.IR

TL;DR: TextBridgeGNN：基于文本语义桥接的图推荐预训练框架，通过文本特征连接不同领域，实现知识有效迁移


<details>
  <summary>Details</summary>
Motivation: 传统基于ID嵌入的图推荐模型面临跨领域迁移困难的问题，主要由于ID空间隔离和异构图结构不兼容。需要构建能够跨领域预训练的推荐模型。

Method: 1) 使用文本作为语义桥连接不同领域，通过多层次图传播学习领域特定和全局知识；2) 预训练阶段利用文本信息打破数据孤岛，设计分层GNN保留协同信号并增强语义；3) 微调阶段提出相似性迁移机制，从语义相关节点初始化目标域ID嵌入。

Result: 实验表明TextBridgeGNN在跨领域、多领域和无训练设置下均优于现有方法，能够有效融合PLM驱动的语义和图协同过滤，无需昂贵的语言模型微调或实时推理开销。

Conclusion: TextBridgeGNN成功解决了图推荐模型的跨领域迁移问题，通过文本桥接机制实现了有效的知识转移，为构建预训练图推荐模型提供了可行方案。

Abstract: Graph-based recommendation has achieved great success in recent years. The classical graph recommendation model utilizes ID embedding to store essential collaborative information. However, this ID-based paradigm faces challenges in transferring to a new domain, making it hard to build a pre-trained graph recommendation model. This phenomenon primarily stems from two inherent challenges: (1) the non-transferability of ID embeddings due to isolated domain-specific ID spaces, and (2) structural incompatibility between heterogeneous interaction graphs across domains.
  To address these issues, we propose TextBridgeGNN, a pre-training and fine-tuning framework that can effectively transfer knowledge from a pre-trained GNN to downstream tasks. We believe the key lies in how to build the relationship between domains. Specifically, TextBridgeGNN uses text as a semantic bridge to connect domains through multi-level graph propagation. During the pre-training stage, textual information is utilized to break the data islands formed by multiple domains, and hierarchical GNNs are designed to learn both domain-specific and domain-global knowledge with text features, ensuring the retention of collaborative signals and the enhancement of semantics. During the fine-tuning stage, a similarity transfer mechanism is proposed. This mechanism initializes ID embeddings in the target domain by transferring from semantically related nodes, successfully transferring the ID embeddings and graph pattern.
  Experiments demonstrate that TextBridgeGNN outperforms existing methods in cross-domain, multi-domain, and training-free settings, highlighting its ability to integrate Pre-trained Language Model (PLM)-driven semantics with graph-based collaborative filtering without costly language model fine-tuning or real-time inference overhead.

</details>


### [89] [Distillation-based Scenario-Adaptive Mixture-of-Experts for the Matching Stage of Multi-scenario Recommendation](https://arxiv.org/abs/2601.02368)
*Ruibing Wang,Shuhan Guo,Haotong Du,Quanming Yao*

Main category: cs.IR

TL;DR: DSMOE通过场景自适应投影模块和跨架构知识蒸馏框架，解决了多场景推荐匹配阶段中MMOE的专家塌陷和头部场景参数主导问题，显著提升了长尾场景的检索质量。


<details>
  <summary>Details</summary>
Motivation: 多场景推荐中，虽然MMOE在排序阶段表现良好，但在匹配阶段迁移时面临两个主要问题：独立双塔架构的盲目优化，以及头部场景参数主导导致的长尾场景专家塌陷问题。

Method: 提出DSMOE框架，包含两个核心组件：1）场景自适应投影模块（SAP），生成轻量级的场景特定参数，防止长尾场景专家塌陷；2）跨架构知识蒸馏框架，使用交互感知的教师模型指导双塔学生模型学习复杂匹配模式。

Result: 在真实数据集上的大量实验表明，DSMOE在多场景推荐匹配任务上表现优异，特别是在数据稀疏、代表性不足的长尾场景中显著提升了检索质量。

Conclusion: DSMOE通过结构性和分布性瓶颈的解决方案，成功将MMOE的优势扩展到匹配阶段，为多场景推荐系统提供了有效的匹配框架，特别有利于长尾场景的性能提升。

Abstract: Multi-scenario recommendation is pivotal for optimizing user experience across diverse contexts. While Multi-gate Mixture-of-Experts (MMOE) thrives in ranking, its transfer to the matching stage is hindered by the blind optimization inherent to independent two-tower architectures and the parameter dominance of head scenarios. To address these structural and distributional bottlenecks, we propose Distillation-based Scenario-Adaptive Mixture-of-Experts (DSMOE). Specially, we devise a Scenario-Adaptive Projection (SAP) module to generate lightweight, context-specific parameters, effectively preventing expert collapse in long-tail scenarios. Concurrently, we introduce a cross-architecture knowledge distillation framework, where an interaction-aware teacher guides the two-tower student to capture complex matching patterns. Extensive experiments on real-world datasets demonstrate DSMOE's superiority, particularly in significantly improving retrieval quality for under-represented, data-sparse scenarios.

</details>


### [90] [Improving News Recommendations through Hybrid Sentiment Modelling and Reinforcement Learning](https://arxiv.org/abs/2601.02372)
*Eunice Kingenga,Mike Wa Nkongolo*

Main category: cs.IR

TL;DR: 结合混合情感分析与强化学习的自适应新闻推荐框架，能有效识别并推荐情感匹配的文章，实现个性化推荐


<details>
  <summary>Details</summary>
Motivation: 传统新闻推荐系统在情感分析方面存在歧义、词典不一致和上下文理解有限的问题，特别是在多源新闻环境中。现有模型通常将情感视为次要特征，难以适应用户的情感偏好。

Method: 提出自适应情感感知新闻推荐框架，结合混合情感分析与强化学习。使用BBC News数据集，混合情感模型整合VADER、AFINN、TextBlob和SentiWordNet分数生成稳健的文章级情感估计。文章分为积极、消极或中性，这些情感状态嵌入Q-learning架构中，指导智能体学习最优推荐策略。

Result: 该系统能有效识别并推荐情感匹配的文章，通过迭代Q-learning更新持续改进个性化推荐。结果表明，混合情感建模与强化学习相结合为以用户为中心的新闻推荐提供了可行、可解释和自适应的方法。

Conclusion: 结合混合情感分析与强化学习的情感感知新闻推荐框架能够解决传统方法的局限性，提供更精准、自适应和个性化的推荐体验。

Abstract: News recommendation systems rely on automated sentiment analysis to personalise content and enhance user engagement. Conventional approaches often struggle with ambiguity, lexicon inconsistencies, and limited contextual understanding, particularly in multi-source news environments. Existing models typically treat sentiment as a secondary feature, reducing their ability to adapt to users' affective preferences. To address these limitations, this study develops an adaptive, sentiment-aware news recommendation framework by integrating hybrid sentiment analysis with reinforcement learning. Using the BBC News dataset, a hybrid sentiment model combines VADER, AFINN, TextBlob, and SentiWordNet scores to generate robust article-level sentiment estimates. Articles are categorised as positive, negative, or neutral, and these sentiment states are embedded within a Q-learning architecture to guide the agent in learning optimal recommendation policies. The proposed system effectively identifies and recommends articles with aligned emotional profiles while continuously improving personalisation through iterative Q-learning updates. The results demonstrate that coupling hybrid sentiment modelling with reinforcement learning provides a feasible, interpretable, and adaptive approach for user-centred news recommendation.

</details>


### [91] [A Lay User Explainable Food Recommendation System Based on Hybrid Feature Importance Extraction and Large Language Models](https://arxiv.org/abs/2601.02374)
*Melissa Tessa,Diderot D. Cidjeu,Rachele Carli,Sarah Abchiche,Ahmad Aldarwishd,Igor Tchappi,Amro Najjar*

Main category: cs.IR

TL;DR: 使用LLM和SHAP结合的方法为食品推荐系统提供更全面、动态且易于理解的事后解释


<details>
  <summary>Details</summary>
Motivation: 当前食品推荐系统的解释对普通用户来说不够详细和易懂，需要更全面、动态且令人信服的解释来增强用户信任和系统透明度

Method: 结合大型语言模型(LLM)和SHAP关键变量提取的混合方法，开发事后处理流程，为推荐结果生成动态解释

Result: 相比文献中的现有方法，该方法能为普通用户提供更全面、动态且令人信服的解释，增强了用户信任和系统透明度

Conclusion: LLM与SHAP结合的混合方法能有效改善食品推荐系统的解释质量，使复杂推荐结果对普通用户更易理解

Abstract: Large Language Models (LLM) have experienced strong development in recent years, with varied applications. This paper uses LLMs to develop a post-hoc process that provides more elaborated explanations of the results of food recommendation systems. By combining LLM with a hybrid extraction of key variables using SHAP, we obtain dynamic, convincing and more comprehensive explanations to lay user, compared to those in the literature. This approach enhances user trust and transparency by making complex recommendation outcomes easier to understand for a lay user.

</details>


### [92] [TAG-HGT: A Scalable and Cost-Effective Framework for Inductive Cold-Start Academic Recommendation](https://arxiv.org/abs/2601.02381)
*Zhexiang Li*

Main category: cs.IR

TL;DR: TAG-HGT是一个神经符号框架，通过解耦的"语义优先、结构精炼"范式，将冻结大语言模型的语义知识与轻量级异构图转换器结合，实现了冷启动推荐的高精度与工业级可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决学术平台中每日大量新学者加入的归纳冷启动推荐问题。现有生成图模型虽然语义能力强，但推理延迟高（13分钟/1000请求）、计算成本大，无法满足实时百万级应用的工业部署需求。

Method: 采用解耦的"语义优先、结构精炼"范式：1）使用冻结的DeepSeek-V3大语言模型作为离线语义工厂；2）通过跨视图对比学习将语义知识蒸馏到轻量级异构图转换器中；3）结合LLM提供的全局语义召回和图结构提供的局部区分能力。

Result: 在OpenAlex数据集上，TAG-HGT实现了SOTA系统召回率91.97%，比纯结构基线提升20.7%。推理延迟降低了5个数量级（从780秒降至1.73毫秒），推理成本从每1000查询1.50美元降至0.001美元以下，成本降低99.9%。

Conclusion: TAG-HGT成功弥合了生成质量与工业可扩展性之间的鸿沟，通过神经符号框架实现了高精度冷启动推荐，同时满足实时、大规模应用的工业部署要求，使高精度学术推荐变得民主化。

Abstract: Inductive cold-start recommendation remains the "Achilles' Heel" of industrial academic platforms, where thousands of new scholars join daily without historical interaction records. While recent Generative Graph Models (e.g., HiGPT, OFA) demonstrate promising semantic capabilities, their prohibitive inference latency (often exceeding 13 minutes per 1,000 requests) and massive computational costs render them practically undeployable for real-time, million-scale applications. To bridge this gap between generative quality and industrial scalability, we propose TAG-HGT, a cost-effective neuro-symbolic framework. Adopting a decoupled "Semantics-First, Structure-Refined" paradigm, TAG-HGT utilizes a frozen Large Language Model (DeepSeek-V3) as an offline semantic factory and distills its knowledge into a lightweight Heterogeneous Graph Transformer (HGT) via Cross-View Contrastive Learning (CVCL). We present a key insight: while LLM semantics provide necessary global recall, structural signals offer the critical local discrimination needed to distinguish valid collaborators from semantically similar but socially unreachable strangers in dense embedding spaces. Validated under a strict Time-Machine Protocol on the massive OpenAlex dataset, TAG-HGT achieves a SOTA System Recall@10 of 91.97%, outperforming structure-only baselines by 20.7%. Most significantly, from an industrial perspective, TAG-HGT reduces inference latency by five orders of magnitude ($4.5 \times 10^{5}\times$) compared to generative baselines (from 780s down to 1.73 ms), and slashes inference costs from $\sim$$1.50 to $<$$0.001 per 1k queries. This 99.9% cost reduction democratizes high-precision academic recommendation.

</details>


### [93] [Tree of Preferences for Diversified Recommendation](https://arxiv.org/abs/2601.02386)
*Hanyang Yuan,Ning Tang,Tongya Zheng,Jiarong Xu,Xintong Hu,Renhong Huang,Shunyu Liu,Jiacong Hu,Jiawei Chen,Mingli Song*

Main category: cs.IR

TL;DR: 本文提出了一种利用大语言模型挖掘用户潜在偏好、解决推荐系统多样性不足问题的新方法，通过构建偏好树结构和生成合成交互数据来训练推荐模型。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统主要从观察到的用户反馈中推断用户偏好多样性，但由于数据偏差，这些数据可能无法完全反映用户兴趣，导致未探索的偏好被忽视或未显现，从而造成推荐多样性不足。

Method: 提出了一种基于大语言模型的新方法：1）引入偏好树结构从粗到细建模用户偏好；2）利用LLM系统性推理用户行为背后的逻辑，挖掘未探索的偏好；3）采用以数据为中心的方法，识别匹配用户偏好的候选物品并生成反映未探索偏好的合成交互；4）整合这些交互训练通用推荐器实现多样化；5）通过动态选择有影响力的用户优化整体效率。

Result: 在多样性和相关性方面的广泛评估表明，该方法在大多数情况下优于现有方法，在其他情况下接近最优性能，且推理延迟合理。

Conclusion: 该研究从数据偏差视角探索了多样化推荐，通过利用大语言模型的世界知识和零样本推理能力挖掘用户未探索的偏好，为推荐系统提供了更全面、多样化的解决方案。

Abstract: Diversified recommendation has attracted increasing attention from both researchers and practitioners, which can effectively address the homogeneity of recommended items. Existing approaches predominantly aim to infer the diversity of user preferences from observed user feedback. Nonetheless, due to inherent data biases, the observed data may not fully reflect user interests, where underexplored preferences can be overwhelmed or remain unmanifested. Failing to capture these preferences can lead to suboptimal diversity in recommendations. To fill this gap, this work aims to study diversified recommendation from a data-bias perspective. Inspired by the outstanding performance of large language models (LLMs) in zero-shot inference leveraging world knowledge, we propose a novel approach that utilizes LLMs' expertise to uncover underexplored user preferences from observed behavior, ultimately providing diverse and relevant recommendations. To achieve this, we first introduce Tree of Preferences (ToP), an innovative structure constructed to model user preferences from coarse to fine. ToP enables LLMs to systematically reason over the user's rationale behind their behavior, thereby uncovering their underexplored preferences. To guide diversified recommendations using uncovered preferences, we adopt a data-centric approach, identifying candidate items that match user preferences and generating synthetic interactions that reflect underexplored preferences. These interactions are integrated to train a general recommender for diversification. Moreover, we scale up overall efficiency by dynamically selecting influential users during optimization. Extensive evaluations of both diversity and relevance show that our approach outperforms existing methods in most cases and achieves near-optimal performance in others, with reasonable inference latency.

</details>


### [94] [Socially-Aware Recommender Systems Mitigate Opinion Clusterization](https://arxiv.org/abs/2601.02412)
*Lukas Schüepp,Carmen Amo Alonso,Florian Dörfler,Giulia De Pasquale*

Main category: cs.IR

TL;DR: 本文提出了一种考虑用户社交网络拓扑结构的推荐系统，通过利用用户社交关系来促进内容多样化，缓解过滤气泡和意见极化问题。


<details>
  <summary>Details</summary>
Motivation: 推荐系统通过匹配用户与创作者内容来最大化参与度，创作者则调整内容以适应用户偏好，同时用户偏好又受到推荐内容和社交圈内容的共同影响。这种反馈循环导致了过滤气泡和意见极化问题，需要设计能够考虑这种复杂互动的推荐系统。

Method: 开发了一种社交网络感知的推荐系统，明确考虑用户-创作者反馈互动，并战略性地利用用户自身社交网络的拓扑结构来促进内容多样化。

Result: 研究证明，意见集群化与推荐内容对用户意见的影响力呈正相关。所提出的方法展示了社交感知推荐系统在对抗意见极化和集群化现象方面的能力。

Conclusion: 在推荐系统设计中考虑并利用用户社交网络对于调节过滤气泡效应、平衡内容多样性与个性化至关重要。社交感知推荐系统能够有效缓解意见极化和集群化问题。

Abstract: Recommender systems shape online interactions by matching users with creators content to maximize engagement. Creators, in turn, adapt their content to align with users preferences and enhance their popularity. At the same time, users preferences evolve under the influence of both suggested content from the recommender system and content shared within their social circles. This feedback loop generates a complex interplay between users, creators, and recommender algorithms, which is the key cause of filter bubbles and opinion polarization. We develop a social network-aware recommender system that explicitly accounts for this user-creators feedback interaction and strategically exploits the topology of the user's own social network to promote diversification. Our approach highlights how accounting for and exploiting user's social network in the recommender system design is crucial to mediate filter bubble effects while balancing content diversity with personalization. Provably, opinion clusterization is positively correlated with the influence of recommended content on user opinions. Ultimately, the proposed approach shows the power of socially-aware recommender systems in combating opinion polarization and clusterization phenomena.

</details>


### [95] [A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance](https://arxiv.org/abs/2601.02428)
*Okan Bursa*

Main category: cs.IR

TL;DR: ARM是一个动态记忆检索增强生成框架，通过选择性记忆和遗忘机制替代静态向量索引，实现高效检索和自调节内存增长。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用静态向量索引存在效率问题，无法适应动态知识变化。受到人类认知中巩固和遗忘机制的启发，需要一种能自动管理记忆、平衡性能和效率的动态RAG框架。

Method: 提出自适应RAG记忆（ARM）框架，采用动态记忆基质代替静态向量索引。频繁检索的项目被巩固和保护，很少使用的项目逐渐衰减。框架包含轻量级嵌入层（约2200万参数），并实现动态选择性检索策略和运行时可配置的嵌入权重优化。

Result: 在轻量级检索基准测试中，ARM达到接近SOTA性能（NDCG@5≈0.940，Recall@5=1.000），在超高效模型（<2500万参数）中效率最佳。Llama 3.1+静态RAG获得最高关键词覆盖率（67.2%），GPT-4o+动态选择性检索策略响应最快（平均8.2秒）且覆盖率有竞争力（58.7%）。

Conclusion: ARM提供了质量、延迟和内存效率之间的实用权衡，具有竞争性准确性、自调节内存增长和可解释的保留动态，无需重新训练生成器，适用于生产和研究RAG系统。

Abstract: We introduce \emph{Adaptive RAG Memory} (ARM), a retrieval-augmented generation (RAG) framework that replaces a static vector index with a \emph{dynamic} memory substrate governed by selective remembrance and decay. Frequently retrieved items are consolidated and protected from forgetting, while rarely used items gradually decay, inspired by cognitive consolidation and forgetting principles. On a lightweight retrieval benchmark, ARM reaches near state-of-the-art performance (e.g., NDCG@5 $\approx$ 0.940, Recall@5 $=1.000$) with only $\sim$22M parameters in the embedding layer, achieving the best efficiency among ultra-efficient models ($<$25M parameters). In addition, we compare static vs. dynamic RAG combinations across Llama 3.1 and GPT-4o. Llama 3.1 with static RAG achieves the highest key-term coverage (67.2\%) at moderate latency, while GPT-4o with a dynamic selective retrieval policy attains the fastest responses (8.2s on average) with competitive coverage (58.7\%). We further present an engineering optimization of the DynamicRAG implementation, making embedding weights configurable, adjustable at runtime, and robust to invalid settings.
  ARM yields competitive accuracy, self-regularizing memory growth, and interpretable retention dynamics without retraining the generator\color{black} and provides practical trade-off between quality, latency and memory efficiency for production and research RAG system.

</details>


### [96] [CREAM: Continual Retrieval on Dynamic Streaming Corpora with Adaptive Soft Memory](https://arxiv.org/abs/2601.02708)
*HuiJeong Son,Hyeongu Kang,Sunho Kim,Subeen Ho,SeongKu Kang,Dongha Lee,Susik Yoon*

Main category: cs.IR

TL;DR: CREAM是一个自监督的基于记忆的持续检索框架，通过动态结构化软记忆捕捉流数据中的语义演变，在无标签设置下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 动态数据流中的信息检索面临挑战，数据分布漂移会降低AI检索系统性能。现有基于记忆的持续学习方法依赖固定查询和标注文档，限制了向未见查询和文档的泛化能力，不适用于实际应用。

Method: 提出CREAM自监督框架，通过细粒度相似度估计、正则化聚类原型和分层核心集采样三项关键技术，将流式查询和文档的演化语义捕获到动态结构化软记忆中。

Result: 在两个基准数据集上的实验表明，CREAM在无标签设置下比最强方法平均提升27.79%的Success@5和44.5%的Recall@10，性能达到甚至超过监督方法。

Conclusion: CREAM通过自监督方式有效解决了动态数据流中的持续检索问题，无需标注数据即可适应已见和未见主题，为实际应用提供了实用解决方案。

Abstract: Information retrieval (IR) in dynamic data streams is emerging as a challenging task, as shifts in data distribution degrade the performance of AI-powered IR systems. To mitigate this issue, memory-based continual learning has been widely adopted for IR. However, existing methods rely on a fixed set of queries with ground-truth relevant documents, which limits generalization to unseen queries and documents, making them impractical for real-world applications. To enable more effective learning with unseen topics of a new corpus without ground-truth labels, we propose CREAM, a self-supervised framework for memory-based continual retrieval. CREAM captures the evolving semantics of streaming queries and documents into dynamically structured soft memory and leverages it to adapt to both seen and unseen topics in an unsupervised setting. We realize this through three key techniques: fine-grained similarity estimation, regularized cluster prototyping, and stratified coreset sampling. Experiments on two benchmark datasets demonstrate that CREAM exhibits superior adaptability and retrieval accuracy, outperforming the strongest method in a label-free setting by 27.79\% in Success@5 and 44.5\% in Recall@10 on average, and achieving performance comparable to or even exceeding that of supervised methods.

</details>


### [97] [Ahead of the Spread: Agent-Driven Virtual Propagation for Early Fake News Detection](https://arxiv.org/abs/2601.02750)
*Bincheng Gu,Min Gao,Junliang Yu,Zongwei Wang,Zhiyi Liu,Kai Shu,Hongyu Zhang*

Main category: cs.IR

TL;DR: AVOID使用LLM驱动的智能体模拟虚拟传播轨迹，为早期假新闻检测提供补充证据，无需真实传播数据


<details>
  <summary>Details</summary>
Motivation: 早期假新闻检测面临传播信号缺失的挑战，传统依赖内容的方法效果有限，而基于传播动态的方法在早期阶段无法获得足够的传播数据

Method: 1. 将早期检测重新定义为证据生成范式，主动模拟而非被动观察传播信号
2. 利用具有差异化角色和数据驱动角色的LLM驱动智能体，在没有真实传播数据的情况下构建早期传播行为
3. 采用去噪引导的融合策略，将模拟传播与内容语义对齐

Result: 在基准数据集上的广泛实验表明，AVOID始终优于最先进的基线方法，证明了虚拟传播增强对早期假新闻检测的有效性和实用价值

Conclusion: AVOID通过主动模拟传播动态而非依赖被动观察，为早期假新闻检测提供了一种创新方法，解决了早期阶段传播信号缺失的核心挑战

Abstract: Early detection of fake news is critical for mitigating its rapid dissemination on social media, which can severely undermine public trust and social stability. Recent advancements show that incorporating propagation dynamics can significantly enhance detection performance compared to previous content-only approaches. However, this remains challenging at early stages due to the absence of observable propagation signals. To address this limitation, we propose AVOID, an \underline{a}gent-driven \underline{v}irtual pr\underline{o}pagat\underline{i}on for early fake news \underline{d}etection. AVOID reformulates early detection as a new paradigm of evidence generation, where propagation signals are actively simulated rather than passively observed. Leveraging LLM-powered agents with differentiated roles and data-driven personas, AVOID realistically constructs early-stage diffusion behaviors without requiring real propagation data. The resulting virtual trajectories provide complementary social evidence that enriches content-based detection, while a denoising-guided fusion strategy aligns simulated propagation with content semantics. Extensive experiments on benchmark datasets demonstrate that AVOID consistently outperforms state-of-the-art baselines, highlighting the effectiveness and practical value of virtual propagation augmentation for early fake news detection. The code and data are available at https://github.com/Ironychen/AVOID.

</details>


### [98] [Netflix Artwork Personalization via LLM Post-training](https://arxiv.org/abs/2601.02764)
*Hyunji Nam,Sejoon Oh,Emma Kong,Yesu Feng,Moumita Bhattacharya*

Main category: cs.IR

TL;DR: 本文研究利用LLM进行个性化艺术品推荐，针对不同用户偏好选择最合适的视觉呈现，在Netflix数据集上取得了3-5%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 用户对娱乐平台（如Netflix）上的艺术品（封面图）具有多样化偏好，同一作品的不同视觉呈现可能吸引不同类型的用户。当前的一刀切推荐方式无法满足这种个性化需求。

Method: 对预训练LLM（Llama 3.1 8B）进行后训练，使其能够根据用户偏好为每个用户选择最合适的作品视觉呈现。使用了11万数据点进行训练，5千用户-作品对进行评估。

Result: 后训练的LLM在个性化艺术品推荐任务上比Netflix生产模型提升了3-5%的性能，展示了LLM在细粒度个性化推荐方面的潜力。

Conclusion: 利用LLM进行个性化艺术品推荐是可行且有效的方向，能够根据用户多样化偏好提供更精准的视觉呈现选择，从而提高用户满意度和参与度。

Abstract: Large language models (LLMs) have demonstrated success in various applications of user recommendation and personalization across e-commerce and entertainment. On many entertainment platforms such as Netflix, users typically interact with a wide range of titles, each represented by an artwork. Since users have diverse preferences, an artwork that appeals to one type of user may not resonate with another with different preferences. Given this user heterogeneity, our work explores the novel problem of personalized artwork recommendations according to diverse user preferences. Similar to the multi-dimensional nature of users' tastes, titles contain different themes and tones that may appeal to different viewers. For example, the same title might feature both heartfelt family drama and intense action scenes. Users who prefer romantic content may like the artwork emphasizing emotional warmth between the characters, while those who prefer action thrillers may find high-intensity action scenes more intriguing. Rather than a one-size-fits-all approach, we conduct post-training of pre-trained LLMs to make personalized artwork recommendations, selecting the most preferred visual representation of a title for each user and thereby improving user satisfaction and engagement. Our experimental results with Llama 3.1 8B models (trained on a dataset of 110K data points and evaluated on 5K held-out user-title pairs) show that the post-trained LLMs achieve 3-5\% improvements over the Netflix production model, suggesting a promising direction for granular personalized recommendations using LLMs.

</details>


### [99] [COFFEE: COdesign Framework for Feature Enriched Embeddings in Ads-Ranking Systems](https://arxiv.org/abs/2601.02807)
*Sohini Roychowdhury,Doris Wang,Qian Ge,Joy Mu,Srihari Reddy*

Main category: cs.IR

TL;DR: 本文提出了一种三维框架来增强用户-广告表示，通过整合多样化事件源、延长用户历史、丰富事件属性和多模态嵌入，在不增加模型推理复杂度的前提下显著提升广告推荐效果。


<details>
  <summary>Details</summary>
Motivation: 商业广告推荐模型需要多样化和丰富的数据源来准确评估用户兴趣。虽然扩展的用户参与历史可以改进用户兴趣预测，但同样重要的是嵌入来自多个来源的活动序列以确保用户和广告表示的新鲜度，遵循扩展定律原则。

Method: 提出了一个新颖的三维框架：第一维度研究整合多样化事件源的影响；第二维度考虑更长用户历史的益处；第三维度专注于通过额外事件属性和多模态嵌入来丰富数据。通过比较有机用户参与源（如内容浏览）与广告曝光源来评估投资回报率。

Result: 该框架使广告曝光源的AUC和扩展曲线斜率比有机使用源提高1.56到2倍，即使在100到10K的短在线序列长度下。当使用丰富的广告曝光事件源时，点击率预测的AUC比基线生产广告推荐系统提高0.56%，为更长和离线的用户-广告表示改进了序列扩展分辨率。

Conclusion: 提出的三维源丰富框架能够有效增强用户-广告表示，显著提升广告推荐性能，同时不增加模型推理或服务复杂度，为商业广告推荐系统提供了实用的改进方案。

Abstract: Diverse and enriched data sources are essential for commercial ads-recommendation models to accurately assess user interest both before and after engagement with content. While extended user-engagement histories can improve the prediction of user interests, it is equally important to embed activity sequences from multiple sources to ensure freshness of user and ad-representations, following scaling law principles. In this paper, we present a novel three-dimensional framework for enhancing user-ad representations without increasing model inference or serving complexity. The first dimension examines the impact of incorporating diverse event sources, the second considers the benefits of longer user histories, and the third focuses on enriching data with additional event attributes and multi-modal embeddings. We assess the return on investment (ROI) of our source enrichment framework by comparing organic user engagement sources, such as content viewing, with ad-impression sources. The proposed method can boost the area under curve (AUC) and the slope of scaling curves for ad-impression sources by 1.56 to 2 times compared to organic usage sources even for short online-sequence lengths of 100 to 10K. Additionally, click-through rate (CTR) prediction improves by 0.56% AUC over the baseline production ad-recommendation system when using enriched ad-impression event sources, leading to improved sequence scaling resolutions for longer and offline user-ad representations.

</details>


### [100] [HarmonRank: Ranking-aligned Multi-objective Ensemble for Live-streaming E-commerce Recommendation](https://arxiv.org/abs/2601.02955)
*Boyang Xia,Zhou Yu,Zhiliang Zhu,Hanxiao Sun,Biyun Han,Jun Wang,Runnan Liu,Wenwu Ou*

Main category: cs.IR

TL;DR: 提出了HarmonRank框架，用于直播电商多目标推荐，通过排序对齐和跨目标对齐来优化推荐效果。


<details>
  <summary>Details</summary>
Motivation: 直播电商推荐需要平衡购买和用户-主播互动等多个目标。传统集成方法存在两个问题：1) 二元分类优化方向与排序任务（AUC评估）不一致；2) 忽视了目标之间的相关性（如评论和购买行为的依赖关系）。

Method: 提出了HarmonRank多目标集成框架：1) 排序对齐：将AUC排序指标公式化为秩和问题，利用可微排序技术进行排序导向优化；2) 跨目标对齐：将原始的一步集成范式改为两步关系感知集成方案。

Result: 在两个工业数据集上的离线实验和在线实验表明，该方法显著优于现有最先进方法。已在快手直播电商推荐平台（4亿DAU）全面部署，贡献超过2%的购买增益。

Conclusion: HarmonRank通过排序对齐和跨目标对齐，有效解决了直播电商多目标推荐中的优化不一致和忽视目标相关性的问题，实现了更好的多目标权衡。

Abstract: Recommendation for live-streaming e-commerce is gaining increasing attention due to the explosive growth of the live streaming economy. Different from traditional e-commerce, live-streaming e-commerce shifts the focus from products to streamers, which requires ranking mechanism to balance both purchases and user-streamer interactions for long-term ecology. To trade off multiple objectives, a popular solution is to build an ensemble model to integrate multi-objective scores into a unified score. The ensemble model is usually supervised by multiple independent binary classification losses of all objectives. However, this paradigm suffers from two inherent limitations. First, the optimization direction of the binary classification task is misaligned with the ranking task (evaluated by AUC). Second, this paradigm overlooks the alignment between objectives, e.g., comment and buy behaviors are partially dependent which can be revealed in labels correlations. The model can achieve better trade-offs if it learns the aligned parts of ranking abilities among different objectives.
  To mitigate these limitations, we propose a novel multi-objective ensemble framework HarmonRank to fulfill both alignment to the ranking task and alignment among objectives. For alignment to ranking, we formulate ranking metric AUC as a rank-sum problem and utilize differentiable ranking techniques for ranking-oriented optimization. For inter-objective alignment, we change the original one-step ensemble paradigm to a two-step relation-aware ensemble scheme.
  Extensive offline experiments results on two industrial datasets and online experiments demonstrate that our approach significantly outperforms existing state-of-the-art methods. The proposed method has been fully deployed in Kuaishou's live-streaming e-commerce recommendation platform with 400 million DAUs, contributing over 2% purchase gain.

</details>


### [101] [Auditing Search Query Suggestion Bias Through Recursive Algorithm Interrogation](https://arxiv.org/abs/2601.02962)
*Fabian Haak,Philipp Schaer*

Main category: cs.IR

TL;DR: 本文提出了一种识别搜索查询建议偏见的新方法，通过递归算法询问技术创建建议树，扩展数据基础，用于分析政治领域人物相关搜索的主题偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管搜索查询建议在在线信息搜索中扮演重要角色，但相关研究较少。主要原因包括上下文稀疏性和数据基础有限（每个查询最多10个建议），这使得识别搜索查询建议中的偏见变得困难。

Method: 采用递归算法询问技术，创建搜索查询建议树，从而获得更多潜在的搜索查询建议，深化偏见分析的数据基础。

Result: 基于扩展后的建议数据，研究了政治领域人物相关搜索中的主题群体偏见。

Conclusion: 该方法为识别搜索查询建议偏见提供了新的替代途径，通过深化数据基础提高了偏见识别的有效性。

Abstract: Despite their important role in online information search, search query suggestions have not been researched as much as most other aspects of search engines. Although reasons for this are multi-faceted, the sparseness of context and the limited data basis of up to ten suggestions per search query pose the most significant problem in identifying bias in search query suggestions. The most proven method to reduce sparseness and improve the validity of bias identification of search query suggestions so far is to consider suggestions from subsequent searches over time for the same query. This work presents a new, alternative approach to search query bias identification that includes less high-level suggestions to deepen the data basis of bias analyses. We employ recursive algorithm interrogation techniques and create suggestion trees that enable access to more subliminal search query suggestions. Based on these suggestions, we investigate topical group bias in person-related searches in the political domain.

</details>


### [102] [Parallel Latent Reasoning for Sequential Recommendation](https://arxiv.org/abs/2601.03153)
*Jiakai Tang,Xu Chen,Wen Chen,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: PLR框架通过并行多推理轨迹扩展宽度级计算，解决序列推荐中深度推理的收益递减问题，显著提升性能同时保持实时推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法仅依赖单轨迹的深度级扩展，随着推理深度增加面临收益递减问题，无法有效捕捉稀疏行为序列中的复杂用户偏好。

Method: 提出并行潜在推理(PLR)框架：1)通过连续潜在空间中的可学习触发令牌构建并行推理流；2)通过全局推理正则化保持流间多样性；3)通过混合推理流聚合自适应合成多流输出。

Result: 在三个真实世界数据集上的实验表明，PLR显著优于最先进的基线方法，同时保持实时推理效率。理论分析验证了并行推理在提高泛化能力方面的有效性。

Conclusion: PLR为序列推荐中超越现有深度扩展的推理能力增强开辟了新途径，证明了宽度级计算扩展在捕捉复杂用户偏好方面的优势。

Abstract: Capturing complex user preferences from sparse behavioral sequences remains a fundamental challenge in sequential recommendation. Recent latent reasoning methods have shown promise by extending test-time computation through multi-step reasoning, yet they exclusively rely on depth-level scaling along a single trajectory, suffering from diminishing returns as reasoning depth increases. To address this limitation, we propose \textbf{Parallel Latent Reasoning (PLR)}, a novel framework that pioneers width-level computational scaling by exploring multiple diverse reasoning trajectories simultaneously. PLR constructs parallel reasoning streams through learnable trigger tokens in continuous latent space, preserves diversity across streams via global reasoning regularization, and adaptively synthesizes multi-stream outputs through mixture-of-reasoning-streams aggregation. Extensive experiments on three real-world datasets demonstrate that PLR substantially outperforms state-of-the-art baselines while maintaining real-time inference efficiency. Theoretical analysis further validates the effectiveness of parallel reasoning in improving generalization capability. Our work opens new avenues for enhancing reasoning capacity in sequential recommendation beyond existing depth scaling.

</details>


### [103] [Fine-tuning Small Language Models as Efficient Enterprise Search Relevance Labelers](https://arxiv.org/abs/2601.03211)
*Yue Kang,Zhuoyi Huang,Benji Schussheim,Diana Licon,Dina Atia,Shixing Cao,Jacob Danovitch,Kunho Kim,Billy Norcilien,Jonah Karpman,Mahmound Sayed,Mike Taylor,Tao Sun,Pavel Metrikov,Vipul Agarwal,Chris Quirk,Ye-Yi Wang,Nick Craswell,Irene Shaffer,Tianwei Chen,Sulaiman Vesal,Soundar Srinivasan*

Main category: cs.IR

TL;DR: 提出使用合成数据蒸馏训练小型语言模型作为相关性标注器，在保证标注质量的同时大幅提升吞吐量和降低成本。


<details>
  <summary>Details</summary>
Motivation: 企业搜索领域缺乏高质量标注数据，而获取大规模标注数据成本高昂且困难，需要一种可扩展的解决方案。

Method: 利用LLM从种子文档生成企业查询，用BM25检索难负样本，再用教师LLM分配相关性分数，最后将合成数据集蒸馏到SLM中。

Result: 蒸馏后的SLM在923个企业查询-文档对的人工标注基准上，与人类判断的一致性达到或超过教师LLM，同时吞吐量提升17倍，成本效益提高19倍。

Conclusion: 该方法为企业级检索应用提供了可扩展、经济高效的相关性标注方案，支持实际场景中的快速离线评估和迭代。

Abstract: In enterprise search, building high-quality datasets at scale remains a central challenge due to the difficulty of acquiring labeled data. To resolve this challenge, we propose an efficient approach to fine-tune small language models (SLMs) for accurate relevance labeling, enabling high-throughput, domain-specific labeling comparable or even better in quality to that of state-of-the-art large language models (LLMs). To overcome the lack of high-quality and accessible datasets in the enterprise domain, our method leverages on synthetic data generation. Specifically, we employ an LLM to synthesize realistic enterprise queries from a seed document, apply BM25 to retrieve hard negatives, and use a teacher LLM to assign relevance scores. The resulting dataset is then distilled into an SLM, producing a compact relevance labeler. We evaluate our approach on a high-quality benchmark consisting of 923 enterprise query-document pairs annotated by trained human annotators, and show that the distilled SLM achieves agreement with human judgments on par with or better than the teacher LLM. Furthermore, our fine-tuned labeler substantially improves throughput, achieving 17 times increase while also being 19 times more cost-effective. This approach enables scalable and cost-effective relevance labeling for enterprise-scale retrieval applications, supporting rapid offline evaluation and iteration in real-world settings.

</details>
