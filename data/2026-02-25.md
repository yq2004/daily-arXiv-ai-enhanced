<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 33]
- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Talking to Yourself: Defying Forgetting in Large Language Models](https://arxiv.org/abs/2602.20162)
*Yutao Sun,Mingshuai Chen,Tiancheng Zhao,Phillip Miao,Zilun Zhang,Haozhan Shen,Ruizhe Zhu,Jianwei Yin*

Main category: cs.CL

TL;DR: 提出SA-SFT方法，通过自生成对话数据与任务数据混合训练，有效缓解大语言模型微调时的灾难性遗忘问题，无需外部数据或额外调优。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在特定任务数据上微调时容易出现灾难性遗忘，导致通用知识和推理能力下降，需要一种简单有效的缓解方法。

Method: SA-SFT方法：在微调前让大语言模型生成自对话数据，然后将这些自生成数据与任务数据混合，不改变优化或训练计划，实现轻量级自增强。

Result: 在50个评估场景中，SA-SFT保持了与原始模型相当的性能，在40个案例中取得最佳结果，优于层冻结和外部数据混合等基线方法。

Conclusion: 自生成数据提供的自对齐能有效对抗风格诱导的参数漂移，SA-SFT为鲁棒的LLM适应提供了简单有效的机制，避免灾难性遗忘。

Abstract: Catastrophic forgetting remains a major challenge when fine-tuning large language models (LLMs) on narrow, task-specific data, often degrading their general knowledge and reasoning abilities. We propose SA-SFT, a lightweight self-augmentation routine in which an LLM generates self-dialogues prior to fine-tuning, and the resulting self-authored data are mixed with task data without modifying optimization or training schedules.
  Despite requiring no external data or additional tuning, SA-SFT consistently mitigates catastrophic forgetting while improving in-domain performance. Across 50 evaluation scenarios, it maintains performance comparable to the original model and achieves the best results in 40 cases, outperforming common baselines such as layer freezing and external data mixing. Guided by these empirical findings, we further present a theoretical analysis suggesting that forgetting can partly stem from style-induced parameter drift, and that self-alignment through self-generated data provides an effective means to counteract this effect. Overall, our results indicate that self-augmentation offers a simple and effective mechanism for robust LLM adaptation without incurring catastrophic forgetting.

</details>


### [2] [Benchmarking Distilled Language Models: Performance and Efficiency in Resource-Constrained Settings](https://arxiv.org/abs/2602.20164)
*Sachin Gopal Wani,Eric Page,Ajay Dholakia,David Ellison*

Main category: cs.CL

TL;DR: 知识蒸馏能创建比传统训练更高效的小语言模型，8B蒸馏模型比普通训练计算效率高2000倍以上，性能媲美大10倍的模型


<details>
  <summary>Details</summary>
Motivation: 研究知识蒸馏在开发资源受限环境下高效小语言模型方面的潜力，通过量化分析比较蒸馏模型与普通模型、专有模型的性能和计算成本

Method: 对蒸馏模型、普通模型和专有模型进行基准测试，分析它们的性能和计算成本，提供定量效率分析

Result: 蒸馏创建了更优的性能-计算曲线，8B蒸馏模型比普通训练计算效率高2000倍以上，推理能力与标准大10倍的模型相当甚至更好

Conclusion: 蒸馏不仅是压缩技术，更是构建先进、可访问AI的主要策略，验证了其在资源受限环境下的实用价值

Abstract: Knowledge distillation offers a transformative pathway to developing powerful, yet efficient, small language models (SLMs) suitable for resource-constrained environments. In this paper, we benchmark the performance and computational cost of distilled models against their vanilla and proprietary counterparts, providing a quantitative analysis of their efficiency. Our results demonstrate that distillation creates a superior performance-tocompute curve. We find that creating a distilled 8B model is over 2,000 times more compute-efficient than training its vanilla counterpart, while achieving reasoning capabilities on par with, or even exceeding, standard models ten times its size. These findings validate distillation not just as a compression technique, but as a primary strategy for building state-of-the-art, accessible AI

</details>


### [3] [ConceptRM: The Quest to Mitigate Alert Fatigue through Consensus-Based Purity-Driven Data Cleaning for Reflection Modelling](https://arxiv.org/abs/2602.20166)
*Yongda Yu,Lei Zhang,Xinxin Guo,Minghui Yu,Zhengqi Zhuang,Guoping Rong,Haifeng Shen,Zhengfeng Li,Boge Wang,Guoan Zhang,Bangyu Xiang,Xiaobin Xu*

Main category: cs.CL

TL;DR: 提出ConceptRM方法，通过少量专家标注作为锚点，利用协同学习从噪声数据中构建高质量语料库，有效拦截虚假警报


<details>
  <summary>Details</summary>
Motivation: 智能代理产生的海量警报（多为虚假）导致用户产生"警报疲劳"，容易忽略关键问题。现有方法依赖用户反馈数据训练反射模型，但这些数据噪声大，人工清理成本高

Method: ConceptRM方法：1) 使用少量专家标注作为锚点；2) 创建具有不同噪声比例的扰动数据集；3) 采用协同教学训练多个不同模型进行协作学习；4) 通过分析模型共识决策从噪声数据中识别可靠负样本

Result: 实验表明ConceptRM显著提高了虚假警报拦截能力，在域内数据集上比最先进的LLM基线高出53.31%，在域外数据集上高出41.67%，同时保持了极低的标注成本

Conclusion: ConceptRM通过协同学习从噪声数据中构建高质量训练语料，有效解决了警报疲劳问题，在最小化标注成本的同时显著提升了虚假警报拦截性能

Abstract: In many applications involving intelligent agents, the overwhelming volume of alerts (mostly false) generated by the agents may desensitize users and cause them to overlook critical issues, leading to the so-called ''alert fatigue''. A common strategy is to train a reflection model as a filter to intercept false alerts with labelled data collected from user verification feedback. However, a key challenge is the noisy nature of such data as it is often collected in production environments. As cleaning noise via manual annotation incurs high costs, this paper proposes a novel method ConceptRM for constructing a high-quality corpus to train a reflection model capable of effectively intercepting false alerts. With only a small amount of expert annotations as anchors, ConceptRM creates perturbed datasets with varying noise ratios and utilizes co-teaching to train multiple distinct models for collaborative learning. By analyzing the consensus decisions of these models, it effectively identifies reliable negative samples from a noisy dataset. Experimental results demonstrate that ConceptRM significantly enhances the interception of false alerts with minimal annotation cost, outperforming several state-of-the-art LLM baselines by up to 53.31% on in-domain datasets and 41.67% on out-of-domain datasets.

</details>


### [4] [InterviewSim: A Scalable Framework for Interview-Grounded Personality Simulation](https://arxiv.org/abs/2602.20294)
*Yu Li,Pranav Narayanan Venkit,Yada Pruksachatkun,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 基于真实访谈数据的人格模拟评估框架，通过大规模访谈数据（23,000个访谈，67.1万问答对）提出四个评估指标，发现数据驱动方法优于传统方法，并揭示检索增强与时间顺序方法的不同优势。


<details>
  <summary>Details</summary>
Motivation: 现有的人格模拟评估方法依赖人口统计调查、人格问卷或简短的AI访谈作为代理，缺乏对个体实际言论的直接评估，需要建立基于真实访谈数据的评估框架。

Method: 从1,000个公众人物的23,000个验证访谈转录中提取67.1万问答对，提出包含内容相似性、事实一致性、人格对齐和事实知识保留四个维度的评估框架，系统比较不同数据利用方法。

Result: 基于真实访谈数据的方法显著优于仅依赖传记资料或模型参数知识的方法；检索增强方法在捕捉人格风格和回答质量方面表现更好，而时间顺序方法在保持事实一致性和知识保留方面更优。

Conclusion: 该评估框架支持基于应用需求的原则性方法选择，为推进人格模拟研究提供实证见解和可行指导。

Abstract: Simulating real personalities with large language models requires grounding generation in authentic personal data. Existing evaluation approaches rely on demographic surveys, personality questionnaires, or short AI-led interviews as proxies, but lack direct assessment against what individuals actually said. We address this gap with an interview-grounded evaluation framework for personality simulation at a large scale. We extract over 671,000 question-answer pairs from 23,000 verified interview transcripts across 1,000 public personalities, each with an average of 11.5 hours of interview content. We propose a multi-dimensional evaluation framework with four complementary metrics measuring content similarity, factual consistency, personality alignment, and factual knowledge retention. Through systematic comparison, we demonstrate that methods grounded in real interview data substantially outperform those relying solely on biographical profiles or the model's parametric knowledge. We further reveal a trade-off in how interview data is best utilized: retrieval-augmented methods excel at capturing personality style and response quality, while chronological-based methods better preserve factual consistency and knowledge retention. Our evaluation framework enables principled method selection based on application requirements, and our empirical findings provide actionable insights for advancing personality simulation research.

</details>


### [5] [What Makes a Good Query? Measuring the Impact of Human-Confusing Linguistic Features on LLM Performance](https://arxiv.org/abs/2602.20300)
*William Watson,Nicole Cho,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CL

TL;DR: 研究发现查询语句的特定语言特征（如从句嵌套、指代模糊）与LLM幻觉风险相关，而意图明确、可回答性强的查询则降低幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 传统上LLM幻觉被归因于模型或解码策略的缺陷，但研究认为查询语句的形式也会影响模型响应。基于语言学理论，探索是否存在某些类型的查询更容易导致幻觉。

Method: 构建22维查询特征向量，涵盖从句复杂性、词汇稀有性、指代、否定、可回答性、意图基础等语言学特征。使用369,837个真实世界查询进行大规模分析，识别与幻觉风险相关的查询特征模式。

Result: 分析揭示了"风险景观"：某些特征（如深层从句嵌套、指代模糊）与更高的幻觉倾向相关；而清晰的意图基础和可回答性则与较低的幻觉率相关。领域特异性等特征则表现出混合、数据集和模型依赖的效应。

Conclusion: 研究确立了与幻觉风险相关的可观察查询特征表示，为引导性查询重写和未来干预研究铺平了道路，表明查询形式是影响LLM幻觉的重要因素。

Abstract: Large Language Model (LLM) hallucinations are usually treated as defects of the model or its decoding strategy. Drawing on classical linguistics, we argue that a query's form can also shape a listener's (and model's) response. We operationalize this insight by constructing a 22-dimension query feature vector covering clause complexity, lexical rarity, and anaphora, negation, answerability, and intention grounding, all known to affect human comprehension. Using 369,837 real-world queries, we ask: Are there certain types of queries that make hallucination more likely? A large-scale analysis reveals a consistent "risk landscape": certain features such as deep clause nesting and underspecification align with higher hallucination propensity. In contrast, clear intention grounding and answerability align with lower hallucination rates. Others, including domain specificity, show mixed, dataset- and model-dependent effects. Thus, these findings establish an empirically observable query-feature representation correlated with hallucination risk, paving the way for guided query rewriting and future intervention studies.

</details>


### [6] [No One Size Fits All: QueryBandits for Hallucination Mitigation](https://arxiv.org/abs/2602.20332)
*Nicole Cho,William Watson,Alec Koppel,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CL

TL;DR: QueryBandits：一个模型无关的上下文老虎机框架，通过在线学习选择最优查询重写策略来缓解闭源大语言模型的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前大多数缓解大语言模型幻觉的研究都集中在开源模型上，采用事后检测和参数编辑方法。然而，机构部署中绝大多数是闭源模型，针对闭源模型幻觉缓解的研究严重不足，需要一种无需重新训练或梯度调整的纯前向机制。

Method: 提出QueryBandits框架，这是一个基于上下文老虎机的模型无关方法。它通过经验验证和校准的奖励函数，在线学习选择最优查询重写策略（如改写或扩展）。框架使用Thompson Sampling等算法，根据语义特征动态调整策略选择。

Result: 在16个QA场景中，最佳QueryBandit（Thompson Sampling）相比No-Rewrite基线获得87.5%的胜率，分别比零样本静态策略（如Paraphrase或Expand）高出42.6%和60.3%。所有上下文老虎机在所有数据集上都优于普通老虎机，特征方差越大，臂选择方差也越大，证实了没有单一重写策略对所有查询都最优。

Conclusion: 研究表明，不灵活的查询重写策略反而可能加剧幻觉。通过QueryBandits在线学习语义特征上的策略，可以纯通过前向机制改变模型行为，使其适用于闭源模型，无需重新训练或基于梯度的调整。

Abstract: Advanced reasoning capabilities in Large Language Models (LLMs) have led to more frequent hallucinations; yet most mitigation work focuses on open-source models for post-hoc detection and parameter editing. The dearth of studies focusing on hallucinations in closed-source models is especially concerning, as they constitute the vast majority of models in institutional deployments. We introduce QueryBandits, a model-agnostic contextual bandit framework that adaptively learns online to select the optimal query-rewrite strategy by leveraging an empirically validated and calibrated reward function. Across 16 QA scenarios, our top QueryBandit (Thompson Sampling) achieves an 87.5% win rate over a No-Rewrite baseline and outperforms zero-shot static policies (e.g., Paraphrase or Expand) by 42.6% and 60.3%, respectively. Moreover, all contextual bandits outperform vanilla bandits across all datasets, with higher feature variance coinciding with greater variance in arm selection. This substantiates our finding that there is no single rewrite policy optimal for all queries. We also discover that certain static policies incur higher cumulative regret than No-Rewrite, indicating that an inflexible query-rewriting policy can worsen hallucinations. Thus, learning an online policy over semantic features with QueryBandits can shift model behavior purely through forward-pass mechanisms, enabling its use with closed-source models and bypassing the need for retraining or gradient-based adaptation.

</details>


### [7] [Natural Language Processing Models for Robust Document Categorization](https://arxiv.org/abs/2602.20336)
*Radoslaw Roszczyk,Pawel Tecza,Maciej Stodolski,Krzysztof Siwek*

Main category: cs.CL

TL;DR: 评估了三种机器学习方法在自动文本分类中的表现，设计了一个不平衡文档分类演示系统，发现BiLSTM在准确率和计算效率之间提供了最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 研究如何在将AI集成到实际自动化流程中时，平衡分类准确率与计算效率，特别关注处理不平衡文档分类的实际应用需求。

Method: 评估了三种不同复杂度的模型：朴素贝叶斯分类器、双向LSTM网络和微调的基于Transformer的BERT模型。设计并实现了一个演示系统，用于验证实际应用性。

Result: BERT准确率最高（超过99%），但计算成本最高；朴素贝叶斯训练最快（毫秒级），但准确率最低（约94.5%）；BiLSTM提供最佳平衡（约98.56%准确率，中等计算成本）。类别不平衡对所有方法都有影响。

Conclusion: 对于所研究的场景，BiLSTM提供了最平衡的解决方案，同时为未来改进和进一步探索Transformer架构提供了机会。

Abstract: This article presents an evaluation of several machine learning methods applied to automated text classification, alongside the design of a demonstrative system for unbalanced document categorization and distribution. The study focuses on balancing classification accuracy with computational efficiency, a key consideration when integrating AI into real world automation pipelines. Three models of varying complexity were examined: a Naive Bayes classifier, a bidirectional LSTM network, and a fine tuned transformer based BERT model.
  The experiments reveal substantial differences in performance. BERT achieved the highest accuracy, consistently exceeding 99\%, but required significantly longer training times and greater computational resources. The BiLSTM model provided a strong compromise, reaching approximately 98.56\% accuracy while maintaining moderate training costs and offering robust contextual understanding. Naive Bayes proved to be the fastest to train, on the order of milliseconds, yet delivered the lowest accuracy, averaging around 94.5\%. Class imbalance influenced all methods, particularly in the recognition of minority categories.
  A fully functional demonstrative system was implemented to validate practical applicability, enabling automated routing of technical requests with throughput unattainable through manual processing. The study concludes that BiLSTM offers the most balanced solution for the examined scenario, while also outlining opportunities for future improvements and further exploration of transformer architectures.

</details>


### [8] [How communicatively optimal are exact numeral systems? Once more on lexicon size and morphosyntactic complexity](https://arxiv.org/abs/2602.20372)
*Chundra Cathcart,Arne Rubehn,Katja Bocklage,Luca Ciucci,Kellen Parker van Dam,Alžběta Kučerová,Jekaterina Mažara,Carlo Y. Meloni,David Snee,Johann-Mattis List*

Main category: cs.CL

TL;DR: 该研究发现许多语言的数字系统在沟通效率上低于预期，挑战了先前关于递归数字系统优化效率的观点。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为精确递归数字系统通过平衡数字词汇库大小和数字术语的平均形态句法复杂性来优化沟通效率，但作者认为这些研究未能充分解释语言所展现的复杂程度。

Method: 使用来自52种遗传多样语言的数据，采用区分可预测和不可预测词形变化（形式变异）的注释方案进行分析。

Result: 研究发现世界上许多语言的数字系统效率明显低于预期水平，表明这些系统并非如先前研究所认为的那样高效。

Conclusion: 研究结果对数字系统研究和更广泛的语言演化研究具有重要意义，挑战了关于语言系统优化效率的现有假设。

Abstract: Recent research argues that exact recursive numeral systems optimize communicative efficiency by balancing a tradeoff between the size of the numeral lexicon and the average morphosyntactic complexity (roughly length in morphemes) of numeral terms. We argue that previous studies have not characterized the data in a fashion that accounts for the degree of complexity languages display. Using data from 52 genetically diverse languages and an annotation scheme distinguishing between predictable and unpredictable allomorphy (formal variation), we show that many of the world's languages are decisively less efficient than one would expect. We discuss the implications of our findings for the study of numeral systems and linguistic evolution more generally.

</details>


### [9] [Case-Aware LLM-as-a-Judge Evaluation for Enterprise-Scale RAG Systems](https://arxiv.org/abs/2602.20379)
*Mukul Chhabra,Luigi Medrano,Arush Verma*

Main category: cs.CL

TL;DR: 提出面向企业多轮RAG系统的案例感知评估框架，通过八个操作指标和严重性感知评分协议，解决现有评估方法在企业场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 企业RAG助手在多轮案例工作流（如技术支持、IT运维）中运行，现有RAG评估框架主要为基准测试或单轮场景设计，无法捕捉企业特有的失败模式，如案例识别错误、工作流错位、跨轮次部分解决等问题。

Method: 提出案例感知的LLM-as-a-Judge评估框架，使用八个基于操作的指标分别评估检索质量、基础保真度、答案效用、精度完整性以及案例/工作流对齐。采用严重性感知评分协议减少分数膨胀，通过确定性提示和严格JSON输出实现可扩展的批量评估、回归测试和生产监控。

Result: 通过对比两个指令调优模型在短工作流和长工作流中的表现，研究发现通用代理指标提供模糊信号，而提出的框架能够揭示对企业关键的可操作权衡，有助于系统改进。

Conclusion: 该案例感知评估框架能够有效评估企业多轮RAG系统，解决企业特有的评估需求，为系统优化提供可操作的洞察，优于现有通用评估方法。

Abstract: Enterprise Retrieval-Augmented Generation (RAG) assistants operate in multi-turn, case-based workflows such as technical support and IT operations, where evaluation must reflect operational constraints, structured identifiers (e.g., error codes, versions), and resolution workflows. Existing RAG evaluation frameworks are primarily designed for benchmark-style or single-turn settings and often fail to capture enterprise-specific failure modes such as case misidentification, workflow misalignment, and partial resolution across turns.
  We present a case-aware LLM-as-a-Judge evaluation framework for enterprise multi-turn RAG systems. The framework evaluates each turn using eight operationally grounded metrics that separate retrieval quality, grounding fidelity, answer utility, precision integrity, and case/workflow alignment. A severity-aware scoring protocol reduces score inflation and improves diagnostic clarity across heterogeneous enterprise cases. The system uses deterministic prompting with strict JSON outputs, enabling scalable batch evaluation, regression testing, and production monitoring.
  Through a comparative study of two instruction-tuned models across short and long workflows, we show that generic proxy metrics provide ambiguous signals, while the proposed framework exposes enterprise-critical tradeoffs that are actionable for system improvement.

</details>


### [10] [Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning](https://arxiv.org/abs/2602.21103)
*Sanket Badhe,Deep Shah*

Main category: cs.CL

TL;DR: 通过Prompt-Level Distillation技术，从小型模型中提取显式推理模式并组织成结构化指令，使小型模型在保持低延迟的同时达到前沿模型性能，并提供完全可验证的透明推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在明显缺陷：Chain-of-Thought提示准确但延迟高、推理成本大；微调小模型则牺牲可解释性且引入资源开销。需要一种既能保持高性能又具有低延迟、可解释性的解决方案。

Method: 提出Prompt-Level Distillation（PLD）方法：从教师模型中提取显式推理模式，将其组织成结构化、表达性强的指令，并作为学生模型的系统提示。该方法保留了推理的透明度，同时避免了传统微调的资源开销。

Result: 在StereoSet和Contract-NLI数据集上使用Gemma-3 4B模型测试，PLD将Macro F1分数分别从57%提升到90.0%和从67%提升到83%。该紧凑模型在保持可忽略延迟开销的同时，达到了前沿模型的性能水平。

Conclusion: PLD方法成功解决了推理任务中的性能-延迟-可解释性权衡问题，使小型模型能够以透明、可验证的方式达到前沿性能，特别适用于法律、金融、内容审核等受监管行业，以及高吞吐量用例和边缘设备。

Abstract: Advanced reasoning typically requires Chain-of-Thought prompting, which is accurate but incurs prohibitive latency and substantial test-time inference costs. The standard alternative, fine-tuning smaller models, often sacrifices interpretability while introducing significant resource and operational overhead. To address these limitations, we introduce Prompt-Level Distillation (PLD). We extract explicit reasoning patterns from a Teacher model and organize them into a structured list of expressive instructions for the Student model's System Prompt. Evaluated on the StereoSet and Contract-NLI datasets using Gemma-3 4B, PLD improved Macro F1 scores from 57\% to 90.0\% and 67\% to 83\% respectively, enabling this compact model to match frontier performance with negligible latency overhead. These expressive instructions render the decision-making process transparent, allowing for full human verification of logic, making this approach ideal for regulated industries such as law, finance, and content moderation, as well as high-volume use cases and edge devices.

</details>


### [11] [Disentangling Geometry, Performance, and Training in Language Models](https://arxiv.org/abs/2602.20433)
*Atharva Kulkarni,Jacob Mitchell Springer,Arjun Subramonian,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 研究发现Transformer权重几何特性（特别是unembedding矩阵的有效秩）与模型性能的关系复杂，不能可靠预测下游任务表现，主要反映训练选择而非性能


<details>
  <summary>Details</summary>
Motivation: Transformer权重的几何特性（特别是unembedding矩阵）在语言模型可解释性研究中很有用，但其对下游性能预测的效用尚不清楚。本研究旨在系统探究模型性能与unembedding矩阵几何特性（特别是有效秩）之间的关系。

Method: 使用108个OLMo风格语言模型进行实验，这些模型在受控变化条件下训练。分析unembedding矩阵的有效秩，并扩展到其他几何指标和最终层表示，研究它们与模型性能的关系。

Result: 1. 最佳性能模型通常具有较高的有效秩，但这一趋势在不同任务和训练设置中并不普遍；2. 低有效秩不会导致小型模型后期性能下降，而是与其同时发生；3. 存在低秩模型不表现出饱和的对抗性案例；4. 有效秩受预训练超参数（如批量大小和权重衰减）强烈影响，进而影响模型性能；5. 其他几何指标与有效秩基本一致，但都不能可靠预测下游性能。

Conclusion: 模型几何特性（通过现有指标捕获）主要反映训练选择而非性能，不能可靠地用于预测下游任务表现。

Abstract: Geometric properties of Transformer weights, particularly the unembedding matrix, have been widely useful in language model interpretability research. Yet, their utility for estimating downstream performance remains unclear. In this work, we systematically investigate the relationship between model performance and the unembedding matrix geometry, particularly its effective rank. Our experiments, involving a suite of 108 OLMo-style language models trained under controlled variation, reveal several key findings. While the best-performing models often exhibit a high effective rank, this trend is not universal across tasks and training setups. Contrary to prior work, we find that low effective rank does not cause late-stage performance degradation in small models, but instead co-occurs with it; we find adversarial cases where low-rank models do not exhibit saturation. Moreover, we show that effective rank is strongly influenced by pre-training hyperparameters, such as batch size and weight decay, which in-turn affect the model's performance. Lastly, extending our analysis to other geometric metrics and final-layer representation, we find that these metrics are largely aligned, but none can reliably predict downstream performance. Overall, our findings suggest that the model's geometry, as captured by existing metrics, primarily reflects training choices rather than performance.

</details>


### [12] [From Performance to Purpose: A Sociotechnical Taxonomy for Evaluating Large Language Model Utility](https://arxiv.org/abs/2602.20513)
*Gavin Levinson,Keith Feldman*

Main category: cs.CL

TL;DR: 提出LUX框架，一个用于评估语言模型实用性的综合分类法，涵盖性能、交互、运营和治理四个领域，支持定量比较和模型选择。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在现实系统中的应用越来越广泛，但仅靠任务级成功不足以评估模型在实际应用中的适用性。高风险应用环境中，LLM的有效性受多种社会技术因素影响，现有评估指标分散且缺乏统一分类，无法支持跨用例的一致性评估和比较。

Method: 引入语言模型实用性分类法(LUX)，将实用性评估结构化到四个领域：性能、交互、运营和治理。每个领域按层次组织为主题对齐的维度和组件，每个组件都基于可量化比较的指标。还开发了外部动态网络工具，连接组件到相关指标库。

Result: LUX框架提供了评估LLM实用性的统一分类法，支持跨用例的定量比较和模型选择对齐。网络工具便于探索框架并访问相关评估指标。

Conclusion: LUX填补了LLM实用性评估缺乏统一分类法的空白，为实际应用中的模型评估和选择提供了结构化框架，有助于在复杂现实系统中做出更明智的决策。

Abstract: As large language models (LLMs) continue to improve at completing discrete tasks, they are being integrated into increasingly complex and diverse real-world systems. However, task-level success alone does not establish a model's fit for use in practice. In applied, high-stakes settings, LLM effectiveness is driven by a wider array of sociotechnical determinants that extend beyond conventional performance measures. Although a growing set of metrics capture many of these considerations, they are rarely organized in a way that supports consistent evaluation, leaving no unified taxonomy for assessing and comparing LLM utility across use cases. To address this gap, we introduce the Language Model Utility Taxonomy (LUX), a comprehensive framework that structures utility evaluation across four domains: performance, interaction, operations, and governance. Within each domain, LUX is organized hierarchically into thematically aligned dimensions and components, each grounded in metrics that enable quantitative comparison and alignment of model selection with intended use. In addition, an external dynamic web tool is provided to support exploration of the framework by connecting each component to a repository of relevant metrics (factors) for applied evaluation.

</details>


### [13] [Stop-Think-AutoRegress: Language Modeling with Latent Diffusion Planning](https://arxiv.org/abs/2602.20528)
*Justin Lovelace,Christian Belardi,Sofian Zalouk,Adhitya Polavaram,Srivatsa Kundurthy,Kilian Q. Weinberger*

Main category: cs.CL

TL;DR: STAR-LDM结合潜在扩散规划与自回归生成，通过"思考"阶段在连续空间进行全局规划，再生成离散token，在语言理解和推理任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统自回归语言模型受限于token-by-token决策，缺乏全局规划能力，无法在连续语义空间进行思考，导致生成内容可能缺乏连贯性和逻辑性。

Method: 引入"思考"阶段暂停生成，通过扩散过程在潜在空间精化语义计划，然后将该计划用于指导后续的自回归生成，实现全局规划与局部生成相结合。

Result: 在语言理解基准测试中显著优于相似规模模型，在LLM作为评判者的比较中，叙事连贯性和常识推理任务上获得>70%胜率，且可通过轻量分类器实现细粒度控制。

Conclusion: STAR-LDM成功整合了扩散规划和自回归生成的优势，实现了更好的全局规划能力，同时保持了生成质量和可控性，为语言模型架构提供了新方向。

Abstract: The Stop-Think-AutoRegress Language Diffusion Model (STAR-LDM) integrates latent diffusion planning with autoregressive generation. Unlike conventional autoregressive language models limited to token-by-token decisions, STAR-LDM incorporates a "thinking" phase that pauses generation to refine a semantic plan through diffusion before continuing. This enables global planning in continuous space prior to committing to discrete tokens. Evaluations show STAR-LDM significantly outperforms similar-sized models on language understanding benchmarks and achieves $>70\%$ win rates in LLM-as-judge comparisons for narrative coherence and commonsense reasoning. The architecture also allows straightforward control through lightweight classifiers, enabling fine-grained steering of attributes without model retraining while maintaining better fluency-control trade-offs than specialized approaches.

</details>


### [14] [Personal Information Parroting in Language Models](https://arxiv.org/abs/2602.20580)
*Nishant Subramani,Kshitish Ghate,Mona Diab*

Main category: cs.CL

TL;DR: 开发了R&R检测器套件来识别个人信息，发现语言模型会记忆并复现训练数据中的个人信息，且模型规模和预训练时间与记忆程度正相关。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型在大规模网络数据上训练，包含大量个人信息实例，这些信息可能被模型记忆，增加了隐私风险。需要量化这种记忆现象并研究其影响因素。

Method: 开发了R&R检测器套件来检测电子邮件地址、电话号码和IP地址，优于现有的基于正则表达式的PI检测器。在手动整理的483个PI实例上，测量了Pythia模型套件（160M-6.9B）在不同预训练步数（70k-143k迭代）下的记忆情况。

Result: Pythia-6.9b模型逐字复现了13.6%的PI实例。模型规模和预训练时间与记忆程度呈正相关：即使最小的Pythia-160m模型也复现了2.7%的实例。

Conclusion: 强烈建议对预训练数据集进行积极过滤和匿名化处理，以最小化个人信息被模型复现的风险。

Abstract: Modern language models (LM) are trained on large scrapes of the Web, containing millions of personal information (PI) instances, many of which LMs memorize, increasing privacy risks. In this work, we develop the regexes and rules (R&R) detector suite to detect email addresses, phone numbers, and IP addresses, which outperforms the best regex-based PI detectors. On a manually curated set of 483 instances of PI, we measure memorization: finding that 13.6% are parroted verbatim by the Pythia-6.9b model, i.e., when the model is prompted with the tokens that precede the PI in the original document, greedy decoding generates the entire PI span exactly. We expand this analysis to study models of varying sizes (160M-6.9B) and pretraining time steps (70k-143k iterations) in the Pythia model suite and find that both model size and amount of pretraining are positively correlated with memorization. Even the smallest model, Pythia-160m, parrots 2.7% of the instances exactly. Consequently, we strongly recommend that pretraining datasets be aggressively filtered and anonymized to minimize PI parroting.

</details>


### [15] [Enhancing Hate Speech Detection on Social Media: A Comparative Analysis of Machine Learning Models and Text Transformation Approaches](https://arxiv.org/abs/2602.20634)
*Saurabh Mishra,Shivani Thakur,Radhika Mamidi*

Main category: cs.CL

TL;DR: 评估机器学习模型在仇恨言论检测中的效果，并探索文本转换技术来中性化有害内容


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台上仇恨言论的泛滥需要开发有效的检测和调节工具

Method: 比较传统模型（CNN、LSTM）与先进神经网络模型（BERT及其变体），探索结合不同架构特征的混合模型，并引入创新的文本转换技术

Result: BERT等先进模型因深度上下文理解而表现出更高准确性，混合模型在某些场景中展现改进能力，文本转换技术能有效将负面表达转换为中性表达

Conclusion: 讨论了当前技术的优势和局限性，提出了未来构建更强大仇恨言论检测系统的方向

Abstract: The proliferation of hate speech on social media platforms has necessitated the development of effective detection and moderation tools. This study evaluates the efficacy of various machine learning models in identifying hate speech and offensive language and investigates the potential of text transformation techniques to neutralize such content. We compare traditional models like CNNs and LSTMs with advanced neural network models such as BERT and its derivatives, alongside exploring hybrid models that combine different architectural features. Our results indicate that while advanced models like BERT show superior accuracy due to their deep contextual understanding, hybrid models exhibit improved capabilities in certain scenarios. Furthermore, we introduce innovative text transformation approaches that convert negative expressions into neutral ones, thereby potentially mitigating the impact of harmful content. The implications of these findings are discussed, highlighting the strengths and limitations of current technologies and proposing future directions for more robust hate speech detection systems.

</details>


### [16] [Semantic Novelty at Scale: Narrative Shape Taxonomy and Readership Prediction in 28,606 Books](https://arxiv.org/abs/2602.20647)
*W. Frederick Zimmerman*

Main category: cs.CL

TL;DR: 该研究提出语义新颖性作为叙事结构的信息论度量，应用于28,606本前1920年英文书籍，发现八种叙事形态原型，其中新颖性轨迹的波动性是读者参与度的最强预测因子。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种在语料库尺度上量化叙事结构的信息论方法。传统研究多关注情感或主题，而信息密度动态变化这一基本维度尚未被充分探索。研究者希望了解叙事中的语义新颖性模式如何影响读者参与度，以及不同体裁和历史时期是否存在系统性差异。

Method: 方法包括：1）定义语义新颖性为每个段落的句子嵌入与前面所有段落运行质心的余弦距离；2）使用768维SBERT嵌入计算PG19数据集中28,606本书的段落级新颖性曲线；3）通过16段分段聚合近似（PAA）降维；4）使用Ward-linkage聚类识别叙事形态原型；5）分析体积（方差）、速度、终始比等指标与读者参与度的关系；6）控制长度混淆因素；7）进行体裁和历时分析。

Result: 主要结果：1）识别出八种叙事形态原型，从陡降（快速收敛）到陡升（不可预测性递增）；2）体积（新颖性轨迹方差）是读者参与度的最强长度无关预测因子（部分rho=0.32）；3）体裁强烈约束叙事形态（卡方=2121.6，p<10^{-242}），小说保持平台型，非小说前载信息；4）历史分析显示1840-1910年间书籍越来越可预测（终始比趋势r=-0.74，p=0.037）；5）SAX分析显示85%签名独特性，表明每本书在语义空间中几乎有唯一路径。

Conclusion: 结论是信息密度动态构成了叙事结构的基本维度，对读者参与度有可测量的影响。研究展示了语料库研究中朴素相关性可能被长度混淆因素主导，强调了控制混淆的重要性。语义新颖性为理解叙事结构和读者参与提供了新的量化框架。

Abstract: I introduce semantic novelty--cosine distance between each paragraph's sentence embedding and the running centroid of all preceding paragraphs--as an information-theoretic measure of narrative structure at corpus scale. Applying it to 28,606 books in PG19 (pre-1920 English literature), I compute paragraph-level novelty curves using 768-dimensional SBERT embeddings, then reduce each to a 16-segment Piecewise Aggregate Approximation (PAA). Ward-linkage clustering on PAA vectors reveals eight canonical narrative shape archetypes, from Steep Descent (rapid convergence) to Steep Ascent (escalating unpredictability). Volume--variance of the novelty trajectory--is the strongest length-independent predictor of readership (partial rho = 0.32), followed by speed (rho = 0.19) and Terminal/Initial ratio (rho = 0.19). Circuitousness shows strong raw correlation (rho = 0.41) but is 93 percent correlated with length; after control, partial rho drops to 0.11--demonstrating that naive correlations in corpus studies can be dominated by length confounds. Genre strongly constrains narrative shape (chi squared = 2121.6, p < 10 to the power negative 242), with fiction maintaining plateau profiles while nonfiction front-loads information. Historical analysis shows books became progressively more predictable between 1840 and 1910 (T/I ratio trend r = negative 0.74, p = 0.037). SAX analysis reveals 85 percent signature uniqueness, suggesting each book traces a nearly unique path through semantic space. These findings demonstrate that information-density dynamics, distinct from sentiment or topic, constitute a fundamental dimension of narrative structure with measurable consequences for reader engagement. Dataset: https://huggingface.co/datasets/wfzimmerman/pg19-semantic-novelty

</details>


### [17] [CARE: An Explainable Computational Framework for Assessing Client-Perceived Therapeutic Alliance Using Large Language Models](https://arxiv.org/abs/2602.20648)
*Anqi Li,Chenxiao Wang,Yu Lu,Renjun Xu,Lizhi Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: CARE是一个基于LLM的框架，能够从心理咨询对话中自动预测多维联盟评分并生成可解释的理由，显著提升与客户感知联盟的相关性。


<details>
  <summary>Details</summary>
Motivation: 传统心理咨询联盟评估方法存在局限性：后问卷负担重且延迟，现有计算方法评分粗糙、缺乏可解释理由，且无法建模整体会话上下文。

Method: 基于CounselingWAI数据集，使用9,516个专家标注理由增强，采用LLaMA-3.1-8B-Instruct骨干模型，通过理由增强监督进行微调。

Result: CARE优于主流LLM，将咨询师评估与客户感知联盟的差距大幅缩小，与客户评分的Pearson相关性提升70%以上；理由增强监督进一步提升预测准确性；生成高质量、情境化的理由。

Conclusion: CARE在真实中文在线心理咨询中识别联盟建设挑战，展示互动模式如何影响联盟发展，提供可行见解，证明其作为AI辅助工具支持心理健康的潜力。

Abstract: Client perceptions of the therapeutic alliance are critical for counseling effectiveness. Accurately capturing these perceptions remains challenging, as traditional post-session questionnaires are burdensome and often delayed, while existing computational approaches produce coarse scores, lack interpretable rationales, and fail to model holistic session context. We present CARE, an LLM-based framework to automatically predict multi-dimensional alliance scores and generate interpretable rationales from counseling transcripts. Built on the CounselingWAI dataset and enriched with 9,516 expert-curated rationales, CARE is fine-tuned using rationale-augmented supervision with the LLaMA-3.1-8B-Instruct backbone. Experiments show that CARE outperforms leading LLMs and substantially reduces the gap between counselor evaluations and client-perceived alliance, achieving over 70% higher Pearson correlation with client ratings. Rationale-augmented supervision further improves predictive accuracy. CARE also produces high-quality, contextually grounded rationales, validated by both automatic and human evaluations. Applied to real-world Chinese online counseling sessions, CARE uncovers common alliance-building challenges, illustrates how interaction patterns shape alliance development, and provides actionable insights, demonstrating its potential as an AI-assisted tool for supporting mental health care.

</details>


### [18] [CAMEL: Confidence-Gated Reflection for Reward Modeling](https://arxiv.org/abs/2602.20670)
*Zirui Zhu,Hailun Xu,Yang Luo,Yong Liu,Kanchan Sarkar,Kun Xu,Yang You*

Main category: cs.CL

TL;DR: CAMEL：基于置信度门控的反思框架，通过单令牌偏好决策和选择性反思，在保持高效的同时提升奖励模型性能


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型存在效率与可解释性的权衡：标量判别模型效率高但缺乏可解释性，生成式判断模型提供丰富推理但计算开销大。需要一种既能保持高效又能提供高质量判断的方法。

Method: 提出CAMEL框架：1）利用log-probability margin作为置信度代理，2）先进行轻量级单令牌偏好决策，3）仅对低置信度实例选择性调用反思机制，4）通过强化学习与反事实前缀增强训练模型，促进真正的自我修正。

Result: 在三个广泛使用的奖励模型基准测试中达到82.9%的平均准确率，比之前最佳模型提升3.2%，仅用14B参数就超越了70B参数模型，建立了更好的准确率-效率Pareto前沿。

Conclusion: CAMEL通过置信度门控机制实现了效率与性能的平衡，为奖励模型提供了一种既能保持高效计算又能进行深入反思的实用框架，在参数效率方面表现突出。

Abstract: Reward models play a fundamental role in aligning large language models with human preferences. Existing methods predominantly follow two paradigms: scalar discriminative preference models, which are efficient but lack interpretability, and generative judging models, which offer richer reasoning at the cost of higher computational overhead. We observe that the log-probability margin between verdict tokens strongly correlates with prediction correctness, providing a reliable proxy for instance difficulty without additional inference cost. Building on this insight, we propose CAMEL, a confidence-gated reflection framework that performs a lightweight single-token preference decision first and selectively invokes reflection only for low-confidence instances. To induce effective self-correction, we train the model via reinforcement learning with counterfactual prefix augmentation, which exposes the model to diverse initial verdicts and encourages genuine revision. Empirically, CAMEL achieves state-of-the-art performance on three widely used reward-model benchmarks with 82.9% average accuracy, surpassing the best prior model by 3.2% and outperforming 70B-parameter models using only 14B parameters, while establishing a strictly better accuracy-efficiency Pareto frontier.

</details>


### [19] [ID-LoRA: Efficient Low-Rank Adaptation Inspired by Matrix Interpolative Decomposition](https://arxiv.org/abs/2602.20727)
*Xindian Ma,Rundong Kong,Peng Zhang,Ruoxiang Huang,Yongyu Jiang*

Main category: cs.CL

TL;DR: ID-LoRA：一种新型参数高效微调框架，通过从预训练权重矩阵中提取和重用聚类参数组，在显著减少可训练参数的同时保持模型能力，打破传统LoRA的性能与参数效率权衡。


<details>
  <summary>Details</summary>
Motivation: 当大语言模型规模扩大时，即使最新的LoRA变体仍会引入大量可训练参数开销。而为了降低开销激进地减小秩会显著降低复杂多任务场景下的性能，存在性能与参数效率的权衡问题。

Method: ID-LoRA从预训练权重矩阵中提取和重用聚类参数组，用这些组形成多个低秩组件，所有组件共享单个初始化的可训练低秩矩阵，从而减少可训练参数数量同时保持模型容量。

Result: 在数学推理、代码生成、MMLU、常识问答和安全对齐五个基准测试中，ID-LoRA优于全量微调和现有PEFT基线，同时使用比标准LoRA少46%的可训练参数。在多任务场景中，在代码和MMLU任务上超越LoRA及其变体，仅需传统LoRA 54%的参数。

Conclusion: ID-LoRA打破了PEFT中性能与参数效率的权衡，通过创新地重用预训练权重矩阵中的聚类参数组，在显著减少可训练参数的同时保持甚至提升模型性能。

Abstract: LoRA has become a universal Parameter-Efficient Fine-Tuning (PEFT) technique that equips Large Language Models (LLMs) to adapt quickly to new tasks. However, when these models are scaled up, even the latest LoRA variants still introduce considerable overhead in trainable parameters. Conversely, aggressively lowering the rank to curb this overhead markedly degrades performance in complex multi-task settings. We propose ID-LoRA, a novel PEFT framework that breaks the trade-off. Its core innovation lies in extracting and reusing clustered parameter groups from the pretrained weight matrix. These groups are then used to form multiple low-rank components, all of which share only a single initialized trainable low-rank matrix. This approach cuts the number of trainable parameters while keeping the model's capacity intact. We evaluate ID-LoRA on five diverse benchmarks: Mathematical Reasoning, Code Generation, MMLU, CommonsenseQA, and Safety Alignment. ID-LoRA outperforms both full fine-tuning and existing PEFT baselines (e.g., LoRA, DoRA, HydraLoRA) while using up to 46% fewer trainable parameters than the standard LoRA. In multi-task scenarios, it surpasses LoRA and its recent variants (e.g., DoRA and HydraLoRA) on both Code and MMLU tasks, yet requires only 54% of the trainable parameters demanded by the conventional LoRA.

</details>


### [20] [Adaptive Text Anonymization: Learning Privacy-Utility Trade-offs via Prompt Optimization](https://arxiv.org/abs/2602.20743)
*Gabriel Loiseau,Damien Sileo,Damien Riquet,Maxime Meyer,Marc Tommasi*

Main category: cs.CL

TL;DR: 提出自适应文本匿名化框架，通过任务特定提示优化自动构建匿名化指令，适应不同隐私-效用需求


<details>
  <summary>Details</summary>
Motivation: 现有匿名化方法依赖静态手工设计策略，缺乏灵活性，难以适应不同数据域、隐私目标和下游应用的需求

Method: 提出自适应文本匿名化任务，开发任务特定提示优化框架，自动为语言模型构建匿名化指令，适应不同隐私目标、领域和使用模式

Result: 在五个数据集上评估，框架在所有设置中均优于现有基线，在隐私-效用权衡上表现更好，计算效率高，开源模型性能与大型闭源模型相当，还能发现新的匿名化策略

Conclusion: 自适应文本匿名化框架能有效适应多样化的隐私-效用需求，在多个领域和设置中优于现有方法，具有实际应用价值

Abstract: Anonymizing textual documents is a highly context-sensitive problem: the appropriate balance between privacy protection and utility preservation varies with the data domain, privacy objectives, and downstream application. However, existing anonymization methods rely on static, manually designed strategies that lack the flexibility to adjust to diverse requirements and often fail to generalize across domains. We introduce adaptive text anonymization, a new task formulation in which anonymization strategies are automatically adapted to specific privacy-utility requirements. We propose a framework for task-specific prompt optimization that automatically constructs anonymization instructions for language models, enabling adaptation to different privacy goals, domains, and downstream usage patterns. To evaluate our approach, we present a benchmark spanning five datasets with diverse domains, privacy constraints, and utility objectives. Across all evaluated settings, our framework consistently achieves a better privacy-utility trade-off than existing baselines, while remaining computationally efficient and effective on open-source language models, with performance comparable to larger closed-source models. Additionally, we show that our method can discover novel anonymization strategies that explore different points along the privacy-utility trade-off frontier.

</details>


### [21] [Explicit Grammar Semantic Feature Fusion for Robust Text Classification](https://arxiv.org/abs/2602.20749)
*Azrin Sultana,Firoz Ahmed*

Main category: cs.CL

TL;DR: 提出了一种轻量级文本分类模型，通过将句法结构与语义信息融合，避免使用计算密集的完整Transformer模型，在资源受限环境中实现高效分类


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型虽然能捕捉文本的深层语法和语义特征，但计算量大，不适合资源受限环境。需要一种既轻量又能有效结合语法和语义信息的分类方法

Method: 将句子级语法结构（句法组成、短语模式、复杂度指标）编码为紧凑的语法向量，与冻结的上下文嵌入融合，形成统一表示。使用DBNs、LSTMs、BiLSTMs、BERT和XLNET等模型进行训练评估

Result: 统一特征表示模型能同时捕捉文本的语义和结构特性，性能优于基线模型2%-15%，在异构领域学习更有效。模型非常轻量，在边缘设备上表现更好

Conclusion: 将语法作为显式归纳偏置而非可学习模块，构建了轻量级模型，在保持性能的同时显著降低计算需求，适合资源受限环境

Abstract: Natural Language Processing enables computers to understand human language by analysing and classifying text efficiently with deep-level grammatical and semantic features. Existing models capture features by learning from large corpora with transformer models, which are computationally intensive and unsuitable for resource-constrained environments. Therefore, our proposed study incorporates comprehensive grammatical rules alongside semantic information to build a robust, lightweight classification model without resorting to full parameterised transformer models or heavy deep learning architectures. The novelty of our approach lies in its explicit encoding of sentence-level grammatical structure, including syntactic composition, phrase patterns, and complexity indicators, into a compact grammar vector, which is then fused with frozen contextual embeddings. These heterogeneous elements unified a single representation that captures both the structural and semantic characteristics of the text. Deep learning models such as Deep Belief Networks (DBNs), Long Short-Term Memory (LSTMs), BiLSTMs, and transformer-based BERT and XLNET were used to train and evaluate the model, with the number of epochs varied. Based on experimental results, the unified feature representation model captures both the semantic and structural properties of text, outperforming baseline models by 2%-15%, enabling more effective learning across heterogeneous domains. Unlike prior syntax-aware transformer models that inject grammatical structure through additional attention layers, tree encoders, or full fine-tuning, the proposed framework treats grammar as an explicit inductive bias rather than a learnable module, resulting in a very lightweight model that delivers better performance on edge devices

</details>


### [22] [SibylSense: Adaptive Rubric Learning via Memory Tuning and Adversarial Probing](https://arxiv.org/abs/2602.20751)
*Yifei Xu,Guilherme Potje,Shivam Shandilya,Tiancheng Yuan,Leonardo de Oliveira Nunes,Rakshanda Agarwal,Saeid Asgari,Adam Atkinson,Emre Kıcıman,Songwu Lu,Ranveer Chandra,Tusher Chakraborty*

Main category: cs.CL

TL;DR: SibylSense：一种通过可调记忆库自适应生成评估标准的推理时学习方法，提升开放生成任务中RL后训练的效果


<details>
  <summary>Details</summary>
Motivation: 为开放生成任务设计对齐且鲁棒的奖励函数是RL后训练的关键障碍。现有评估标准构建方法存在局限：专家评估标准成本高，提示生成的评估标准肤浅或不一致，固定池判别性评估标准易饱和和漂移导致奖励攻击。

Method: 提出SibylSense方法，通过可调记忆库自适应生成评估标准。使用验证器基于少量示例的参考-候选答案判别性差距计算项目奖励来更新记忆。交替进行记忆调优和评估标准对抗策略更新，生成满足评估标准的候选答案，缩小判别性差距，驱动评估标准生成器捕捉新质量维度。

Result: 在两个开放生成任务上的实验表明，SibylSense能产生更具判别性的评估标准，相比静态和非自适应基线，显著提升下游强化学习性能。

Conclusion: SibylSense通过推理时自适应学习，有效解决了评估标准构建的扩展性问题，为开放生成任务的RL后训练提供了更有效的奖励机制。

Abstract: Designing aligned and robust rewards for open-ended generation remains a key barrier to RL post-training. Rubrics provide structured, interpretable supervision, but scaling rubric construction is difficult: expert rubrics are costly, prompted rubrics are often superficial or inconsistent, and fixed-pool discriminative rubrics can saturate and drift, enabling reward hacking. We present SibylSense, an inference-time learning approach that adapts a frozen rubric generator through a tunable memory bank of validated rubric items. Memory is updated via verifier-based item rewards measured by reference-candidate answer discriminative gaps from a handful of examples. SibylSense alternates memory tuning with a rubric-adversarial policy update that produces rubric-satisfying candidate answers, shrinking discriminative gaps and driving the rubric generator to capture new quality dimensions. Experiments on two open-ended tasks show that SibylSense yields more discriminative rubrics and improves downstream RL performance over static and non-adaptive baselines.

</details>


### [23] [Overton Pluralistic Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2602.20759)
*Yu Fu,Seongho Son,Ilija Bogunovic*

Main category: cs.CL

TL;DR: 提出OP-GRPO框架，让单一LLM无需显式提示就能生成多元视角的回复，实现"小模型，大视角覆盖"效果。


<details>
  <summary>Details</summary>
Motivation: 现有对齐范式难以捕捉人类价值观的多元性，需要一种能让单一模型生成多样化视角的方法。

Method: 1. 训练相似度估计器（Sentence Transformer）用于评估回复的覆盖范围；2. 使用OP-GRPO强化学习框架，结合双奖励系统确保视角的广泛覆盖和独特性。

Result: Qwen2.5-3B-Instruct模型相比20B GPT-OSS基线在NLI基准上获得37.4%相对准确率提升，相比模块化架构基线有19.1%相对改进，GPT-4.1评估也证实了方法的鲁棒性。

Conclusion: OP-GRPO框架成功实现了隐式多元主义，让小模型也能获得广泛的视角覆盖，为价值对齐提供了新思路。

Abstract: Existing alignment paradigms remain limited in capturing the pluralistic nature of human values. Overton Pluralism addresses this gap by generating responses with diverse perspectives from a single query. This paper introduces OP-GRPO (Overton Pluralistic Group Relative Policy Optimization), a reinforcement learning framework for implicit Overton Pluralism that enables a single large language model to produce pluralistic responses without explicit prompting or modular orchestration. Our workflow consists of two main steps. First, similarity estimator training fine-tunes a Sentence Transformer for Overton Pluralism tasks to provide more accurate coverage evaluation of generated responses. Second, OP-GRPO training incorporates this similarity estimator into a dual-reward system designed to ensure both broad coverage of genuine human perspectives and the uniqueness of each perspective, thereby promoting diversity. Empirical results demonstrate a "small models, big perspective coverage" effect. The trained Qwen2.5-3B-Instruct model surpasses a 20B GPT-OSS baseline with a 37.4 percent relative accuracy gain on a Natural Language Inference benchmark, and also outperforms a modular architecture baseline with a 19.1 percent relative improvement. Additional evaluations using GPT-4.1 as a large language model judge further confirm the robustness of the approach.

</details>


### [24] [Don't Ignore the Tail: Decoupling top-K Probabilities for Efficient Language Model Distillation](https://arxiv.org/abs/2602.20816)
*Sayantan Dasgupta,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 提出一种新的尾感知散度方法，用于语言模型蒸馏，通过解耦教师模型预测概率中前K个最高概率与较低概率的贡献，提升分布尾部的影响


<details>
  <summary>Details</summary>
Motivation: 传统KL散度在语言模型蒸馏中主要受教师模型最高概率的token主导，这削弱了较低概率但可能包含有用信息的分布尾部对学习信号的贡献

Method: 提出一种新的尾感知散度，将教师模型预测概率中前K个最高概率与较低概率的贡献解耦，同时保持与KL散度相同的计算复杂度

Result: 实验表明，该改进的蒸馏方法在各种数据集上，在预训练和监督蒸馏解码器模型中都取得了有竞争力的性能，且蒸馏过程高效，可在学术预算下处理大型数据集

Conclusion: 提出的尾感知散度方法通过减少教师模型主导模式的影响并增加分布尾部的贡献，在语言模型蒸馏中取得了良好效果，同时保持了计算效率

Abstract: The core learning signal used in language model distillation is the standard Kullback-Leibler (KL) divergence between the student and teacher distributions. Traditional KL divergence tends to be dominated by the next tokens with the highest probabilities, i.e., the teacher's modes, thereby diminishing the influence of less probable yet potentially informative components of the output distribution. We propose a new tail-aware divergence that decouples the contribution of the teacher model's top-K predicted probabilities from that of lower-probability predictions, while maintaining the same computational profile as the KL Divergence. Our decoupled approach reduces the impact of the teacher modes and, consequently, increases the contribution of the tail of the distribution. Experimental results demonstrate that our modified distillation method yields competitive performance in both pre-training and supervised distillation of decoder models across various datasets. Furthermore, the distillation process is efficient and can be performed with a modest academic budget for large datasets, eliminating the need for industry-scale computing.

</details>


### [25] [FinAnchor: Aligned Multi-Model Representations for Financial Prediction](https://arxiv.org/abs/2602.20859)
*Zirui He,Huopu Zhang,Yanguang Liu,Sirui Wu,Mengnan Du*

Main category: cs.CL

TL;DR: FinAnchor是一个轻量级框架，通过锚定嵌入空间和线性映射对齐多LLM表示，提升金融长文档预测性能


<details>
  <summary>Details</summary>
Motivation: 金融长文档预测面临信号稀疏、噪声干扰的挑战，且不同任务和时间段的最优LLM嵌入模型存在差异

Method: 选择锚定嵌入空间，学习线性映射将其他模型的表示对齐到该空间，然后聚合对齐后的特征形成统一表示

Result: 在多个金融NLP任务中，FinAnchor持续优于强单模型基线和标准集成方法

Conclusion: 锚定异构表示对于稳健的金融预测是有效的，FinAnchor框架无需微调底层模型即可集成多LLM嵌入

Abstract: Financial prediction from long documents involves significant challenges, as actionable signals are often sparse and obscured by noise, and the optimal LLM for generating embeddings varies across tasks and time periods. In this paper, we propose FinAnchor(Financial Anchored Representations), a lightweight framework that integrates embeddings from multiple LLMs without fine-tuning the underlying models. FinAnchor addresses the incompatibility of feature spaces by selecting an anchor embedding space and learning linear mappings to align representations from other models into this anchor. These aligned features are then aggregated to form a unified representation for downstream prediction. Across multiple financial NLP tasks, FinAnchor consistently outperforms strong single-model baselines and standard ensemble methods, demonstrating the effectiveness of anchoring heterogeneous representations for robust financial prediction.

</details>


### [26] [Exa-PSD: a new Persian sentiment analysis dataset on Twitter](https://arxiv.org/abs/2602.20892)
*Seyed Himan Ghaderi,Saeed Sarbazi Azad,Mohammad Mehdi Jaziriyan,Ahmad Akbari*

Main category: cs.CL

TL;DR: 本文提出了一个波斯语推特情感分析数据集Exa，包含12,000条标注数据，并评估了预训练模型Pars Bert和Roberta在该数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 波斯语自然语言处理面临挑战，现有数据集多为特定领域（如产品、食品、酒店等），而社交媒体中用户常使用讽刺、口语化表达，需要专门针对推特平台的波斯语情感分析数据集。

Method: 收集波斯语推特数据，由5名波斯语母语标注者标注为积极、中性、消极三类，共12,000条推文。使用预训练模型Pars Bert和Roberta作为基础模型进行评估。

Result: 评估达到了79.87的宏观F1分数，表明模型和数据集对于情感分析系统具有足够价值。

Conclusion: Exa数据集填补了波斯语推特情感分析数据集的空白，为波斯语NLP研究提供了有价值的资源，预训练模型在该数据集上表现良好。

Abstract: Today, Social networks such as Twitter are the most widely used platforms for communication of people. Analyzing this data has useful information to recognize the opinion of people in tweets. Sentiment analysis plays a vital role in NLP, which identifies the opinion of the individuals about a specific topic. Natural language processing in Persian has many challenges despite the adventure of strong language models. The datasets available in Persian are generally in special topics such as products, foods, hotels, etc while users may use ironies, colloquial phrases in social media To overcome these challenges, there is a necessity for having a dataset of Persian sentiment analysis on Twitter. In this paper, we introduce the Exa sentiment analysis Persian dataset, which is collected from Persian tweets. This dataset contains 12,000 tweets, annotated by 5 native Persian taggers. The aforementioned data is labeled in 3 classes: positive, neutral and negative. We present the characteristics and statistics of this dataset and use the pre-trained Pars Bert and Roberta as the base model to evaluate this dataset. Our evaluation reached a 79.87 Macro F-score, which shows the model and data can be adequately valuable for a sentiment analysis system.

</details>


### [27] [The Art of Efficient Reasoning: Data, Reward, and Optimization](https://arxiv.org/abs/2602.20945)
*Taiqiang Wu,Zenan Zu,Bo Zhou,Ngai Wong*

Main category: cs.CL

TL;DR: 系统研究LLM高效推理机制，提出两阶段训练范式，发现训练相对简单提示可避免长度崩溃，学习到的长度偏置可跨域泛化


<details>
  <summary>Details</summary>
Motivation: 大语言模型从扩展的思维链推理中获益，但计算开销巨大。高效推理旨在通过强化学习激励短而准确的思维轨迹，但相关机制尚不明确。

Method: 采用更细粒度的评估指标（包括基于正确性的长度分布和不同token预算下的性能），通过统一协议进行大量实验（约20万GPU小时），分解训练提示、rollout、奖励塑造和优化策略。

Result: 发现训练过程遵循两阶段范式：长度适应和推理精炼。关键发现是训练相对简单的提示可确保正奖励信号的密度，避免长度崩溃。学习到的长度偏置可跨域泛化。在Qwen3系列（0.6B-30B）上验证了鲁棒性和泛化性。

Conclusion: 系统研究揭示了高效推理的机制，提出了实用的训练指南，证明学习到的长度偏置具有跨域泛化能力，为高效推理提供了理论基础和实践指导。

Abstract: Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward shaping with Reinforcement Learning (RL). In this paper, we systematically investigate the mechanics of efficient reasoning for LLMs. For comprehensive evaluation, we advocate for more fine-grained metrics, including length distribution conditioned on correctness and performance across a wide spectrum of token budgets ranging from 2k to 32k. First, we reveal that the training process follows a two-stage paradigm: length adaptation and reasoning refinement. After that, we conduct extensive experiments (about 0.2 million GPU hours) in a unified protocol, deconstructing training prompts and rollouts, reward shaping, and optimization strategies. In particular, a key finding is to train on relatively easier prompts, ensuring the density of positive reward signals and thus avoiding the length collapse. Meanwhile, the learned length bias can be generalized across domains. We distill all findings into valuable insights and practical guidelines, and further validate them across the Qwen3 series, ranging from 0.6B to 30B, demonstrating the robustness and generalization.

</details>


### [28] [Blackbird Language Matrices: A Framework to Investigate the Linguistic Competence of Language Models](https://arxiv.org/abs/2602.20966)
*Paola Merlo,Chunyang Jiang,Giuseppe Samo,Vivi Nastase*

Main category: cs.CL

TL;DR: BLM任务是一个受智力测试启发的多选语言矩阵任务，通过结构化数据集评估LLM的语言对象检测、系统模式识别和推理能力


<details>
  <summary>Details</summary>
Motivation: 为了探究当前大语言模型的核心能力：是否能检测语言对象及其属性？能否发现和使用跨句子的系统模式？更容易犯语言错误还是推理错误？这些错误如何相互作用？

Method: 创建Blackbird Language Matrices(BLM)任务，构建结构化多级数据集（句子内、输入序列间、候选答案内），通过基准测试和针对性实验（分块和系统性）评估不同模型

Result: BLM任务虽然具有挑战性，但可以通过简单基线模型在多语言中获得良好性能，定制模型性能更优；模型表示包含解决语言任务所需的语法对象和属性；解决方案通过检测跨句子的系统模式实现

Conclusion: 精心策划的结构化数据集支持多方面的语言和大语言模型属性研究，BLM数据集因其结构化特性、包含学习上下文和预期答案、部分手工构建，可用于可解释性研究，帮助理解LLM的行为原因

Abstract: This article describes a novel language task, the Blackbird Language Matrices (BLM) task, inspired by intelligence tests, and illustrates the BLM datasets, their construction and benchmarking, and targeted experiments on chunking and systematicity. BLMs are multiple-choice problems, structured at multiple levels: within each sentence, across the input sequence, within each candidate answer. Because of their rich structure, these curated, but naturalistic datasets are key to answer some core questions about current large language models abilities: do LLMs detect linguistic objects and their properties? Do they detect and use systematic patterns across sentences? Are they more prone to linguistic or reasoning errors, and how do these interact?
  We show that BLMs, while challenging, can be solved at good levels of performance, in more than one language, with simple baseline models or, at better performance levels, with more tailored models. We show that their representations contain the grammatical objects and attributes relevant to solve a linguistic task. We also show that these solutions are reached by detecting systematic patterns across sentences.
  The paper supports the point of view that curated, structured datasets support multi-faceted investigations of properties of language and large language models. Because they present a curated, articulated structure, because they comprise both learning contexts and expected answers, and because they are partly built by hand, BLMs fall in the category of datasets that can support explainability investigations, and be useful to ask why large language models behave the way they do.

</details>


### [29] [Linear Reasoning vs. Proof by Cases: Obstacles for Large Language Models in FOL Problem Solving](https://arxiv.org/abs/2602.20973)
*Yuliang Ji,Fuchen Shen,Jian Wu,Qiujie Xie,Yue Zhang*

Main category: cs.CL

TL;DR: 该论文提出了PC-FOL数据集，专门针对基于案例的数学推理，以评估大语言模型在非线性的案例推理能力，并揭示了其与线性推理之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据集主要关注线性推理，而忽略了反证法、分情况证明等重要的推理形式，这限制了对大语言模型推理能力的全面评估。

Method: 首先引入由专业数学家标注的PC-FOL数据集，专注于基于案例的推理问题，并包含手动编写的自然语言证明。然后通过实验评估领先的大语言模型在该数据集上的表现，并基于图模型进行理论分析。

Result: 实验结果表明，大语言模型在基于案例的推理问题上存在显著的性能差距。理论分析从图模型角度解释了这种差异。

Conclusion: 这项工作揭示了自动自然语言数学证明生成领域的核心挑战，为未来研究铺平了道路。

Abstract: To comprehensively evaluate the mathematical reasoning capabilities of Large Language Models (LLMs), researchers have introduced abundant mathematical reasoning datasets. However, most existing datasets primarily focus on linear reasoning, neglecting other parts such as proof by contradiction and proof by cases, which are crucial for investigating LLMs' reasoning abilities. To address this limitation, we first introduce a novel first-order logic (FOL) dataset named PC-FOL, annotated by professional mathematicians, focusing on case-based reasoning problems. All instances in this dataset are equipped with a manually written natural language proof, clearly distinguishing it from conventional linear reasoning datasets. Our experimental results over leading LLMs demonstrate a substantial performance gap between linear reasoning and case-based reasoning problems. To further investigate this phenomenon, we provide a theoretical analysis grounded in graphical model, which provides an explanation for the observed disparity between the two types of reasoning problems. We hope this work can reveal the core challenges in the field of automated natural language mathematical proof generation, paving the way for future research.

</details>


### [30] [Evaluating Proactive Risk Awareness of Large Language Models](https://arxiv.org/abs/2602.20976)
*Xuan Luo,Yubin Chen,Zhiyu Hou,Linpu Yu,Geng Tu,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: 论文提出了一种主动风险意识评估框架，用于衡量LLMs能否在损害发生前预测潜在危害并提供警告，并构建了Butterfly数据集来实例化该框架在环境生态领域的应用。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地嵌入日常决策，其安全责任已从应对显性有害意图扩展到预测非预期但具有后果的风险。当前的安全对齐与真实世界生态责任要求之间存在差距。

Method: 提出了一个主动风险意识评估框架，并构建了Butterfly数据集（包含1,094个查询），模拟普通解决方案寻求活动，这些活动的响应可能引发潜在生态影响。在五个广泛使用的LLMs上进行实验，分析了响应长度、语言和多模态的影响。

Result: 实验结果显示，在长度限制的响应下主动意识显著下降，跨语言表现相似，且在多模态物种保护方面存在持续的盲点。

Conclusion: 研究发现当前LLMs的安全对齐与真实世界生态责任要求之间存在关键差距，强调了在LLM部署中需要主动安全防护措施。

Abstract: As large language models (LLMs) are increasingly embedded in everyday decision-making, their safety responsibilities extend beyond reacting to explicit harmful intent toward anticipating unintended but consequential risks. In this work, we introduce a proactive risk awareness evaluation framework that measures whether LLMs can anticipate potential harms and provide warnings before damage occurs. We construct the Butterfly dataset to instantiate this framework in the environmental and ecological domain. It contains 1,094 queries that simulate ordinary solution-seeking activities whose responses may induce latent ecological impact. Through experiments across five widely used LLMs, we analyze the effects of response length, languages, and modality. Experimental results reveal consistent, significant declines in proactive awareness under length-restricted responses, cross-lingual similarities, and persistent blind spots in (multimodal) species protection. These findings highlight a critical gap between current safety alignment and the requirements of real-world ecological responsibility, underscoring the need for proactive safeguards in LLM deployment.

</details>


### [31] [Beyond the Star Rating: A Scalable Framework for Aspect-Based Sentiment Analysis Using LLMs and Text Classification](https://arxiv.org/abs/2602.21082)
*Vishal Patil,Shree Vaishnavi Bacha,Revanth Yamani,Yidan Sun,Mayank Kejriwal*

Main category: cs.CL

TL;DR: 该研究提出混合方法：用LLM识别评论中的方面，用传统机器学习进行情感分类，成功分析了470万条餐厅评论，证明该方法能有效进行大规模基于方面的情感分析。


<details>
  <summary>Details</summary>
Motivation: 客户评论是重要信息来源，但分析数百万条非结构化评论具有挑战性。LLMs虽在自然语言理解方面有潜力，但大规模应用受限于计算成本和可扩展性问题。

Method: 采用混合方法：使用ChatGPT分析餐厅评论样本识别关键方面，基于人工标注评论开发情感分类器，然后将该方法应用于从主要在线平台收集的470万条17年间的评论。

Result: 回归分析显示，机器标注的方面能显著解释餐厅总体评分在不同用餐体验方面、菜系和地理区域中的方差。该方法成功识别了关键方面并进行了大规模情感分析。

Conclusion: LLMs与传统机器学习方法结合可以有效自动化大规模客户反馈的基于方面的情感分析，为酒店业和其他服务行业的研究者和从业者提供了实用框架。

Abstract: Customer-provided reviews have become an important source of information for business owners and other customers alike. However, effectively analyzing millions of unstructured reviews remains challenging. While large language models (LLMs) show promise for natural language understanding, their application to large-scale review analysis has been limited by computational costs and scalability concerns. This study proposes a hybrid approach that uses LLMs for aspect identification while employing classic machine-learning methods for sentiment classification at scale. Using ChatGPT to analyze sampled restaurant reviews, we identified key aspects of dining experiences and developed sentiment classifiers using human-labeled reviews, which we subsequently applied to 4.7 million reviews collected over 17 years from a major online platform. Regression analysis reveals that our machine-labeled aspects significantly explain variance in overall restaurant ratings across different aspects of dining experiences, cuisines, and geographical regions. Our findings demonstrate that combining LLMs with traditional machine learning approaches can effectively automate aspect-based sentiment analysis of large-scale customer feedback, suggesting a practical framework for both researchers and practitioners in the hospitality industry and potentially, other service sectors.

</details>


### [32] [PVminer: A Domain-Specific Tool to Detect the Patient Voice in Patient Generated Data](https://arxiv.org/abs/2602.21165)
*Samah Fodeh,Linhai Ma,Yan Wang,Srivani Talakokkul,Ganesh Puthiaraju,Afshan Khan,Ashley Hagaman,Sarah Lowe,Aimee Roundtree*

Main category: cs.CL

TL;DR: PVminer：一个用于结构化患者语音的领域自适应NLP框架，通过多标签多分类预测任务整合BERT编码器和主题建模，在患者-提供者通信中实现高性能的患者语音检测。


<details>
  <summary>Details</summary>
Motivation: 患者生成的文本（如安全消息、调查、访谈）包含丰富的患者语音表达，反映了沟通行为和社会健康决定因素。传统的定性编码方法劳动密集且无法扩展到大规模患者消息，现有机器学习方法通常将患者中心沟通和社会健康决定因素视为独立任务，或依赖不适合患者语言的模型。

Method: 提出PVminer框架，将患者语音检测制定为多标签多分类预测任务，整合患者特定BERT编码器（PV-BERT-base和PV-BERT-large）、用于主题增强的无监督主题建模（PV-Topic-BERT），以及用于代码、子代码和组合级别标签的微调分类器。在微调和推理过程中融入主题表示以丰富语义输入。

Result: PVminer在分层任务中表现优异，优于生物医学和临床预训练基线，F1分数达到82.25%（代码）、80.14%（子代码）和最高77.87%（组合）。消融研究表明作者身份和主题增强都带来显著性能提升。

Conclusion: PVminer是一个有效的领域自适应NLP框架，能够从患者生成文本中结构化提取患者语音，解决了传统方法的可扩展性问题，并为患者中心沟通和社会健康决定因素分析提供了统一解决方案。预训练模型、源代码和文档将公开发布。

Abstract: Patient-generated text such as secure messages, surveys, and interviews contains rich expressions of the patient voice (PV), reflecting communicative behaviors and social determinants of health (SDoH). Traditional qualitative coding frameworks are labor intensive and do not scale to large volumes of patient-authored messages across health systems. Existing machine learning (ML) and natural language processing (NLP) approaches provide partial solutions but often treat patient-centered communication (PCC) and SDoH as separate tasks or rely on models not well suited to patient-facing language. We introduce PVminer, a domain-adapted NLP framework for structuring patient voice in secure patient-provider communication. PVminer formulates PV detection as a multi-label, multi-class prediction task integrating patient-specific BERT encoders (PV-BERT-base and PV-BERT-large), unsupervised topic modeling for thematic augmentation (PV-Topic-BERT), and fine-tuned classifiers for Code, Subcode, and Combo-level labels. Topic representations are incorporated during fine-tuning and inference to enrich semantic inputs. PVminer achieves strong performance across hierarchical tasks and outperforms biomedical and clinical pre-trained baselines, achieving F1 scores of 82.25% (Code), 80.14% (Subcode), and up to 77.87% (Combo). An ablation study further shows that author identity and topic-based augmentation each contribute meaningful gains. Pre-trained models, source code, and documentation will be publicly released, with annotated datasets available upon request for research use.

</details>


### [33] [On Data Engineering for Scaling LLM Terminal Capabilities](https://arxiv.org/abs/2602.21193)
*Renjie Pi,Grace Lam,Mohammad Shoeybi,Pooya Jannaty,Bryan Catanzaro,Wei Ping*

Main category: cs.CL

TL;DR: 该论文提出了一种用于终端代理的数据工程方法，包括Terminal-Task-Gen任务生成管道和Terminal-Corpus数据集，并训练了Nemotron-Terminal模型系列，在Terminal-Bench 2.0上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在终端能力方面取得了快速进展，但最先进终端代理的训练数据策略仍然很大程度上未公开。本文旨在填补这一空白，系统研究终端代理的数据工程实践。

Method: 提出了Terminal-Task-Gen轻量级合成任务生成管道，支持基于种子和基于技能的任务构建；分析了数据过滤、课程学习、长上下文训练和缩放行为等数据与训练策略；创建了Terminal-Corpus大规模开源终端任务数据集。

Result: 使用该数据集训练了基于Qwen3(8B, 14B, 32B)初始化的Nemotron-Terminal模型系列，在Terminal-Bench 2.0上取得了显著提升：8B模型从2.5%提升至13.0%，14B模型从4.0%提升至20.2%，32B模型从3.4%提升至27.4%，性能匹配了更大的模型。

Conclusion: 该研究为终端代理领域提供了系统化的数据工程方法，开源了模型检查点和大部分合成数据集，将加速该领域的研究进展。

Abstract: Despite rapid recent progress in the terminal capabilities of large language models, the training data strategies behind state-of-the-art terminal agents remain largely undisclosed. We address this gap through a systematic study of data engineering practices for terminal agents, making two key contributions: (1) Terminal-Task-Gen, a lightweight synthetic task generation pipeline that supports seed-based and skill-based task construction, and (2) a comprehensive analysis of data and training strategies, including filtering, curriculum learning, long context training, and scaling behavior. Our pipeline yields Terminal-Corpus, a large-scale open-source dataset for terminal tasks. Using this dataset, we train Nemotron-Terminal, a family of models initialized from Qwen3(8B, 14B, 32B) that achieve substantial gains on Terminal-Bench 2.0: Nemotron-Terminal-8B improves from 2.5% to 13.0% Nemotron-Terminal-14B improves from 4.0% to 20.2%, and Nemotron-Terminal-32B improves from 3.4% to 27.4%, matching the performance of significantly larger models. To accelerate research in this domain, we open-source our model checkpoints and most of our synthetic datasets at https://huggingface.co/collections/nvidia/nemotron-terminal.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [34] [Indaleko: The Unified Personal Index](https://arxiv.org/abs/2602.20507)
*William Anthony Mason*

Main category: cs.IR

TL;DR: 本文提出了一种与人类记忆机制对齐的个人信息检索系统架构——统一个人索引（UPI），通过整合时间、空间和活动元数据，实现了自然语言的多维度查询。


<details>
  <summary>Details</summary>
Motivation: 现有个人信息检索系统存在根本缺陷，它们忽略了人类记忆的工作方式。当前平台强制用户使用关键词搜索孤立的数据孤岛，而人类自然回忆是通过情境线索（何时、何地、在什么情境下遇到信息）进行的。

Method: 提出了统一个人索引（UPI）架构，通过将时间、空间和活动元数据整合到统一的图数据库中，构建了Indaleko原型系统。该系统使用内存锚点索引实现亚秒级查询响应，通过UUID语义解耦保护隐私，并支持快速集成新数据源。

Result: Indaleko原型在31百万文件、160TB跨8个存储平台的数据集上验证了可行性。相比Google Drive、OneDrive、Dropbox和Windows Search等商业系统，Indaleko能成功处理结合时间、位置和活动模式的多维度查询，而现有系统在记忆式查询上完全失败。系统实现了亚秒级查询响应，对明确记忆模式保持完美精确度。

Conclusion: UPI架构弥合了认知理论与分布式系统设计之间的鸿沟，将个人信息检索从关键词匹配转变为记忆对齐的查找。这不仅为现有数据提供了即时效益，还为未来情境感知系统奠定了基础。

Abstract: Personal information retrieval fails when systems ignore how human memory works. While existing platforms force keyword searches across isolated silos, humans naturally recall through episodic cues like when, where, and in what context information was encountered. This dissertation presents the Unified Personal Index (UPI), a memory-aligned architecture that bridges this fundamental gap. The Indaleko prototype demonstrates the UPI's feasibility on a 31-million file dataset spanning 160TB across eight storage platforms. By integrating temporal, spatial, and activity metadata into a unified graph database, Indaleko enables natural language queries like "photos near the conference venue last spring" that existing systems cannot process. The implementation achieves sub-second query responses through memory anchor indexing, eliminates cross-platform search fragmentation, and maintains perfect precision for well-specified memory patterns. Evaluation against commercial systems (Google Drive, OneDrive, Dropbox, Windows Search) reveals that all fail on memory-based queries, returning overwhelming result sets without contextual filtering. In contrast, Indaleko successfully processes multi-dimensional queries combining time, location, and activity patterns. The extensible architecture supports rapid integration of new data sources (10 minutes to 10 hours per provider) while preserving privacy through UUID-based semantic decoupling. The UPI's architectural synthesis bridges cognitive theory with distributed systems design, as demonstrated through the Indaleko prototype and rigorous evaluation. This work transforms personal information retrieval from keyword matching to memory-aligned finding, providing immediate benefits for existing data while establishing foundations for future context-aware systems.

</details>


### [35] [PRECTR-V2:Unified Relevance-CTR Framework with Cross-User Preference Mining, Exposure Bias Correction, and LLM-Distilled Encoder Optimization](https://arxiv.org/abs/2602.20676)
*Shuzhi Cao,Rong Chen,Ailong He,Shuguang Han,Jufeng Chen*

Main category: cs.IR

TL;DR: PRECTR-V2：一个改进的搜索系统统一框架，通过挖掘全局相关性偏好、构建困难负样本和轻量级Transformer编码器，解决冷启动用户建模、曝光偏差和模型架构限制问题。


<details>
  <summary>Details</summary>
Motivation: 解决PRECTR框架面临的三个主要挑战：1）低活跃用户和新用户搜索行为数据有限，难以实现个性化相关性偏好建模；2）训练数据主要来自高相关性曝光，与粗排阶段候选空间存在分布不匹配，导致泛化偏差；3）延迟限制下使用冻结BERT编码器的Emb+MLP架构，阻碍联合优化，造成表征学习与CTR微调不对齐。

Method: 1）通过挖掘特定查询下的全局相关性偏好，缓解低活跃用户稀疏行为问题；2）通过嵌入噪声注入和相关性标签重构构建困难负样本，使用成对损失优化其与正样本的相对排序；3）通过LLM知识蒸馏和在文本相关性分类任务上的SFT预训练轻量级Transformer编码器，替代冻结BERT模块。

Result: 提出的PRECTR-V2方法能够：1）有效处理冷启动场景下的个性化相关性建模；2）纠正曝光偏差；3）实现表征学习与CTR微调的更好对齐，超越传统Emb+MLP范式。

Conclusion: PRECTR-V2通过三方面改进解决了前代框架的主要限制，为搜索系统中的相关性匹配和CTR预测协调提供了更有效的统一框架，特别是在冷启动用户处理、分布匹配和模型架构优化方面取得显著进展。

Abstract: In search systems, effectively coordinating the two core objectives of search relevance matching and click-through rate (CTR) prediction is crucial for discovering users' interests and enhancing platform revenue. In our prior work PRECTR, we proposed a unified framework to integrate these two subtasks,thereby eliminating their inconsistency and leading to mutual benefit.However, our previous work still faces three main challenges. First, low-active users and new users have limited search behavioral data, making it difficult to achieve effective personalized relevance preference modeling. Second, training data for ranking models predominantly come from high-relevance exposures, creating a distribution mismatch with the broader candidate space in coarse-ranking, leading to generalization bias. Third, due to the latency constraint, the original model employs an Emb+MLP architecture with a frozen BERT encoder, which prevents joint optimization and creates misalignment between representation learning and CTR fine-tuning. To solve these issues, we further reinforce our method and propose PRECTR-V2. Specifically, we mitigate the low-activity users' sparse behavior problem by mining global relevance preferences under the specific query, which facilitates effective personalized relevance modeling for cold-start scenarios. Subsequently, we construct hard negative samples through embedding noise injection and relevance label reconstruction, and optimize their relative ranking against positive samples via pairwise loss, thereby correcting exposure bias. Finally, we pretrain a lightweight transformer-based encoder via knowledge distillation from LLM and SFT on the text relevance classification task. This encoder replaces the frozen BERT module, enabling better adaptation to CTR fine-tuning and advancing beyond the traditional Emb+MLP paradigm.

</details>


### [36] [IntRR: A Framework for Integrating SID Redistribution and Length Reduction](https://arxiv.org/abs/2602.20704)
*Zesheng Wang,Longfei Xu,Weidong Deng,Huimin Yan,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: IntRR框架通过目标对齐的语义ID重分配和结构长度缩减，解决了生成式推荐中语义ID与推荐目标不对齐、序列长度膨胀的问题，显著提升了推荐准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐中的语义ID存在两个主要问题：1）索引目标（第一阶段）与实际推荐目标（第二阶段）不对齐，且语义ID在第二阶段保持静态，无法适应用户交互的复杂性；2）将分层语义ID展平为令牌序列导致序列长度膨胀，带来高昂的计算开销和推理延迟。

Method: 提出IntRR框架，包含两个核心组件：1）利用物品特定唯一ID作为协作锚点，在分层码本层间动态重新分配语义权重，实现目标对齐的语义ID重分配；2）递归处理语义ID层次结构，避免序列展平，确保每个物品仅需一个令牌的固定成本。

Result: 在基准数据集上的广泛实验表明，IntRR相比代表性生成式基线方法有显著改进，在推荐准确性和效率方面均实现了优越性能。

Conclusion: IntRR通过动态语义ID重分配和递归层次处理，有效解决了生成式推荐中语义ID不对齐和序列长度膨胀的问题，为生成式推荐系统提供了更准确、高效的解决方案。

Abstract: Generative Recommendation (GR) has emerged as a transformative paradigm that reformulates the traditional cascade ranking system into a sequence-to-item generation task, facilitated by the use of discrete Semantic IDs (SIDs). However, current SIDs are suboptimal as the indexing objectives (Stage 1) are misaligned with the actual recommendation goals (Stage 2). Since these identifiers remain static (Stage 2), the backbone model lacks the flexibility to adapt them to the evolving complexities of user interactions. Furthermore, the prevailing strategy of flattening hierarchical SIDs into token sequences leads to sequence length inflation, resulting in prohibitive computational overhead and inference latency. To address these challenges, we propose IntRR, a novel framework that integrates objective-aligned SID Redistribution and structural Length Reduction. By leveraging item-specific Unique IDs (UIDs) as collaborative anchors, this approach dynamically redistributes semantic weights across hierarchical codebook layers. Concurrently, IntRR handles the SID hierarchy recursively, eliminating the need to flatten sequences. This ensures a fixed cost of one token per item. Extensive experiments on benchmark datasets demonstrate that IntRR yields substantial improvements over representative generative baselines, achieving superior performance in both recommendation accuracy and efficiency.

</details>


### [37] [RMIT-ADM+S at the MMU-RAG NeurIPS 2025 Competition](https://arxiv.org/abs/2602.20735)
*Kun Ran,Marwah Alaofi,Danula Hettiachchi,Chenglong Ma,Khoi Nguyen Dinh Anh,Khoi Vo Nguyen,Sachin Pathiyan Cherumanal,Lida Rashidi,Falk Scholer,Damiano Spina,Shuoqi Sun,Oleg Zendel*

Main category: cs.IR

TL;DR: 提出R2RAG系统，通过轻量级组件动态调整检索策略，基于查询复杂性和证据充分性进行自适应，在单个消费级GPU上高效运行并赢得竞赛奖项。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG系统在复杂研究任务中检索策略固定的局限性，需要在资源受限环境下实现高效且自适应的检索增强生成。

Method: 基于G-RAG系统扩展，引入轻量级组件构建R2RAG架构，通过推断查询复杂性和证据充分性动态调整检索策略，并集成基于输出质量分析的模块。

Result: R2RAG在NeurIPS 2025 MMU-RAG竞赛的Text-to-Text赛道中获奖，获得开源类别最佳动态评估奖，证明其在资源受限环境下高效处理复杂研究任务的能力。

Conclusion: R2RAG通过精心设计和高效资源利用，展示了轻量级自适应RAG架构在复杂研究任务中的高有效性，为资源受限环境下的检索增强生成提供了可行方案。

Abstract: This paper presents the award-winning RMIT-ADM+S system for the Text-to-Text
  track of the NeurIPS~2025 MMU-RAG Competition. We introduce Routing-to-RAG
  (R2RAG), a research-focused retrieval-augmented generation (RAG)
  architecture composed of lightweight components that dynamically adapt the
  retrieval strategy based on inferred query complexity and evidence
  sufficiency. The system uses smaller LLMs, enabling operation on a single
  consumer-grade GPU while supporting complex research tasks. It builds on the
  G-RAG system, winner of the ACM~SIGIR~2025 LiveRAG Challenge, and extends it
  with modules informed by qualitative review of outputs. R2RAG won the Best
  Dynamic Evaluation award in the Open Source category, demonstrating high
  effectiveness with careful design and efficient use of resources.

</details>


### [38] [Mitigating Preference Leakage via Strict Estimator Separation for Normative Generative Ranking](https://arxiv.org/abs/2602.20800)
*Dalia Nahhas,Xiaohao Cai,Imran Razzak,Shoaib Jameel*

Main category: cs.IR

TL;DR: 该论文提出了一种无泄漏的双评估框架来解决生成式信息检索中的文化相关性评估问题，通过严格分离监督和评估模型来避免偏好泄漏，并在新基准上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式信息检索中，候选选择成为瓶颈，特别是在文化相关性等规范性标准方面。当前的LLM-as-a-Judge评估方法存在循环性和偏好泄漏问题，即监督和评估模型重叠导致性能虚高。

Method: 1. 将文化相关性形式化为查询内排序任务；2. 引入无泄漏的双评估框架，严格分离监督模型（Judge B）和评估模型（Judge A）；3. 在新基准NGR-33k（33,052个文化相关故事）上测试；4. 使用Judge B监督的交叉编码器蒸馏出密集双编码器模型；5. 在人类标注的Moral Stories数据集上验证框架。

Result: 1. 经典基线方法仅获得适度提升；2. 从Judge B监督的交叉编码器蒸馏出的密集双编码器（BGE-M3）非常有效；3. 虽然交叉编码器为蒸馏提供了强监督信号，但在无泄漏的Judge A评估下，蒸馏出的BGE-M3模型显著优于交叉编码器；4. 在Moral Stories数据集上，该框架与人类规范高度一致。

Conclusion: 严格的评估者分离是可信的生成式信息检索评估的前提条件，微妙的文化偏好可以在无泄漏的情况下蒸馏到高效的排序器中。

Abstract: In Generative Information Retrieval (GenIR), the bottleneck has shifted from generation to the selection of candidates, particularly for normative criteria such as cultural relevance. Current LLM-as-a-Judge evaluations often suffer from circularity and preference leakage, where overlapping supervision and evaluation models inflate performance. We address this by formalising cultural relevance as a within-query ranking task and introducing a leakage-free two-judge framework that strictly separates supervision (Judge B) from evaluation (Judge A). On a new benchmark of 33,052 (NGR-33k) culturally grounded stories, we find that while classical baselines yield only modest gains, a dense bi-encoder distilled from a Judge-B-supervised Cross-Encoder is highly effective. Although the Cross-Encoder provides a strong supervision signal for distillation, the distilled BGE-M3 model substantially outperforms it under leakage-free Judge~A evaluation. We validate our framework on the human-curated Moral Stories dataset, showing strong alignment with human norms. Our results demonstrate that rigorous evaluator separation is a prerequisite for credible GenIR evaluation, proving that subtle cultural preferences can be distilled into efficient rankers without leakage.

</details>


### [39] [E-MMKGR: A Unified Multimodal Knowledge Graph Framework for E-commerce Applications](https://arxiv.org/abs/2602.20877)
*Jiwoo Kang,Yeon-Chang Lee*

Main category: cs.IR

TL;DR: E-MMKGR框架通过构建电子商务多模态知识图谱，学习统一物品表示，提升推荐和搜索任务性能


<details>
  <summary>Details</summary>
Motivation: 现有多模态推荐系统依赖固定模态集和任务特定目标，限制了模态扩展性和任务泛化能力

Method: 构建电子商务多模态知识图谱E-MMKG，通过GNN传播和知识图谱优化学习统一物品表示

Result: 在Amazon数据集上，推荐任务Recall@10提升10.18%，产品搜索比向量检索提升21.72%

Conclusion: 该框架通过统一语义表示有效解决了模态扩展和任务泛化问题，具有实际应用价值

Abstract: Multimodal recommender systems (MMRSs) enhance collaborative filtering by leveraging item-side modalities, but their reliance on a fixed set of modalities and task-specific objectives limits both modality extensibility and task generalization. We propose E-MMKGR, a framework that constructs an e-commerce-specific Multimodal Knowledge Graph E-MMKG and learns unified item representations through GNN-based propagation and KG-oriented optimization. These representations provide a shared semantic foundation applicable to diverse tasks. Experiments on real-world Amazon datasets show improvements of up to 10.18% in Recall@10 for recommendation and up to 21.72% over vector-based retrieval for product search, demonstrating the effectiveness and extensibility of our approach.

</details>


### [40] [Naver Labs Europe @ WSDM CUP | Multilingual Retrieval](https://arxiv.org/abs/2602.20986)
*Thibault Formal,Maxime Louis,Hervé Déjean,Stéphane Clinchant*

Main category: cs.IR

TL;DR: 本研究在WSDM Cup 2026多语言文档检索任务中评估了SPLARE稀疏检索模型，通过渐进式改进（包括重排序和分数融合）取得了优于密集基线的结果。


<details>
  <summary>Details</summary>
Motivation: WSDM Cup 2026的多语言文档检索任务为跨语言泛化提供了具有挑战性的基准，同时也是评估SPLARE稀疏检索模型在非英语场景下性能的理想测试平台。

Method: 从SPLARE-7B模型开始，逐步添加轻量级改进：使用Qwen3-Reranker-4B进行重排序，并采用简单的分数融合策略，共评估了五个渐进增强的运行版本。

Result: 实验结果表明，SPLARE模型相比最先进的密集基线（如Qwen3-8B-Embed）表现出更强的性能，证明了稀疏检索模型在多语言检索场景中的竞争力。

Conclusion: 本研究展示了学习型稀疏检索模型（特别是SPLARE）在超越英语中心场景的多语言检索任务中仍然具有相关性和竞争力，为跨语言检索提供了有效解决方案。

Abstract: This report presents our participation to the WSDM Cup 2026 shared task on multilingual document retrieval from English queries. The task provides a challenging benchmark for cross-lingual generalization. It also provides a natural testbed for evaluating SPLARE, our recently proposed learned sparse retrieval model, which produces generalizable sparse latent representations and is particularly well suited to multilingual retrieval settings.
  We evaluate five progressively enhanced runs, starting from a SPLARE-7B model and incorporating lightweight improvements, including reranking with Qwen3-Reranker-4B and simple score fusion strategies. Our results demonstrate the strength of SPLARE compared to state-of-the-art dense baselines such as Qwen3-8B-Embed. More broadly, our submission highlights the continued relevance and competitiveness of learned sparse retrieval models beyond English-centric scenarios.

</details>


### [41] [Generative Pseudo-Labeling for Pre-Ranking with LLMs](https://arxiv.org/abs/2602.20995)
*Junyu Bi,Xinting Niu,Daixuan Cheng,Kun Yuan,Tao Wang,Binbin Cao,Jian Wu,Yuning Jiang*

Main category: cs.IR

TL;DR: 提出GPL框架，利用大语言模型为未曝光物品生成无偏伪标签，解决推荐系统预排序阶段的训练-服务偏差问题


<details>
  <summary>Details</summary>
Motivation: 工业推荐系统中预排序阶段存在训练-服务偏差问题：模型只在曝光交互上训练，但线上服务时需要为所有召回物品评分，包括未曝光物品。这导致样本选择偏差和泛化能力下降，特别是对长尾内容影响更大。现有方法存在误标负样本或传播曝光偏差的问题。

Method: 提出生成式伪标签（GPL）框架，利用大语言模型为未曝光物品生成无偏、内容感知的伪标签。通过离线生成用户特定兴趣锚点，并在冻结的语义空间中与候选物品匹配，从而对齐训练分布与线上服务空间。

Result: 在大规模生产系统中部署，点击率提升3.07%，同时显著提升了推荐多样性和长尾物品发现能力。

Conclusion: GPL框架通过利用LLMs生成无偏伪标签，有效解决了预排序阶段的训练-服务偏差问题，在保持线上服务效率的同时，显著提升了推荐效果和多样性。

Abstract: Pre-ranking is a critical stage in industrial recommendation systems, tasked with efficiently scoring thousands of recalled items for downstream ranking. A key challenge is the train-serving discrepancy: pre-ranking models are trained only on exposed interactions, yet must score all recalled candidates -- including unexposed items -- during online serving. This mismatch not only induces severe sample selection bias but also degrades generalization, especially for long-tail content. Existing debiasing approaches typically rely on heuristics (e.g., negative sampling) or distillation from biased rankers, which either mislabel plausible unexposed items as negatives or propagate exposure bias into pseudo-labels. In this work, we propose Generative Pseudo-Labeling (GPL), a framework that leverages large language models (LLMs) to generate unbiased, content-aware pseudo-labels for unexposed items, explicitly aligning the training distribution with the online serving space. By offline generating user-specific interest anchors and matching them with candidates in a frozen semantic space, GPL provides high-quality supervision without adding online latency. Deployed in a large-scale production system, GPL improves click-through rate by 3.07%, while significantly enhancing recommendation diversity and long-tail item discovery.

</details>


### [42] [HiSAC: Hierarchical Sparse Activation Compression for Ultra-long Sequence Modeling in Recommenders](https://arxiv.org/abs/2602.21009)
*Kun Yuan,Junyu Bi,Daixuan Cheng,Changfa Wu,Shuwen Xiao,Binbin Cao,Jian Wu,Yuning Jiang*

Main category: cs.IR

TL;DR: HiSAC提出了一种分层稀疏激活压缩框架，通过多级语义ID和全局分层码本，稀疏激活个性化兴趣代理作为细粒度偏好中心，在语义空间中聚合历史信号以减少量化误差并保留长尾行为。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统利用超长用户行为序列捕捉动态偏好，但端到端建模在生产环境中存在延迟和内存限制。现有方法在识别用户特定中心粒度、准确分配行为方面存在困难，导致量化误差和长尾偏好丢失。

Method: HiSAC将交互编码为多级语义ID，构建全局分层码本，通过分层投票机制稀疏激活个性化兴趣代理作为细粒度偏好中心，使用Soft-Routing Attention在语义空间中聚合历史信号，根据相似度加权以最小化量化误差。

Result: 在淘宝"猜你喜欢"首页部署中，HiSAC实现了显著的压缩和成本降低，在线A/B测试显示CTR持续提升1.65%，证明了其可扩展性和实际有效性。

Conclusion: HiSAC通过分层稀疏激活压缩框架有效解决了超长用户行为序列建模的效率和精度问题，在保持推荐质量的同时实现了生产环境中的实际部署和性能提升。

Abstract: Modern recommender systems leverage ultra-long user behavior sequences to capture dynamic preferences, but end-to-end modeling is infeasible in production due to latency and memory constraints. While summarizing history via interest centers offers a practical alternative, existing methods struggle to (1) identify user-specific centers at appropriate granularity and (2) accurately assign behaviors, leading to quantization errors and loss of long-tail preferences. To alleviate these issues, we propose Hierarchical Sparse Activation Compression (HiSAC), an efficient framework for personalized sequence modeling. HiSAC encodes interactions into multi-level semantic IDs and constructs a global hierarchical codebook. A hierarchical voting mechanism sparsely activates personalized interest-agents as fine-grained preference centers. Guided by these agents, Soft-Routing Attention aggregates historical signals in semantic space, weighting by similarity to minimize quantization error and retain long-tail behaviors. Deployed on Taobao's "Guess What You Like" homepage, HiSAC achieves significant compression and cost reduction, with online A/B tests showing a consistent 1.65% CTR uplift -- demonstrating its scalability and real-world effectiveness.

</details>


### [43] [Position-Aware Sequential Attention for Accurate Next Item Recommendations](https://arxiv.org/abs/2602.21052)
*Timur Nabiev,Evgeny Frolov*

Main category: cs.IR

TL;DR: 提出了一种基于位置核的自注意力机制，通过解耦位置信息和语义信息，直接在位置空间上调节注意力权重，改善了序列建模能力。


<details>
  <summary>Details</summary>
Motivation: 传统的加性位置嵌入方法存在局限性：位置信息与项目语义信息纠缠在一起，在深层架构中传播较弱，限制了捕获丰富序列模式的能力。

Method: 引入了一种核化自注意力机制，使用可学习的位置核在纯位置空间操作，与语义相似性解耦，直接调节注意力权重。在每个注意力块中应用该核，实现自适应多尺度序列建模。

Result: 在标准的下一个项目预测基准测试中，位置核注意力机制持续优于强大的竞争基线方法。

Conclusion: 位置核注意力机制通过解耦位置和语义信息，直接调节注意力权重，能够更有效地捕获序列模式，在序列建模任务中表现出优越性能。

Abstract: Sequential self-attention models usually rely on additive positional embeddings, which inject positional information into item representations at the input. In the absence of positional signals, the attention block is permutation-equivariant over sequence positions and thus has no intrinsic notion of temporal order beyond causal masking. We argue that additive positional embeddings make the attention mechanism only superficially sensitive to sequence order: positional information is entangled with item embedding semantics, propagates weakly in deep architectures, and limits the ability to capture rich sequential patterns. To address these limitations, we introduce a kernelized self-attention mechanism, where a learnable positional kernel operates purely in the position space, disentangled from semantic similarity, and directly modulates attention weights. When applied per attention block, this kernel enables adaptive multi-scale sequential modeling. Experiments on standard next-item prediction benchmarks show that our positional kernel attention consistently improves over strong competing baselines.

</details>


### [44] [Turning Semantics into Topology: LLM-Driven Attribute Augmentation for Collaborative Filtering](https://arxiv.org/abs/2602.21099)
*Junjie Meng,Ranxu zhang,Wei Wu,Rui Zhang,Chuan Qin,Qi Zhang,Qi Liu,Hui Xiong,Chao Wang*

Main category: cs.IR

TL;DR: TAGCF框架将LLM的语义知识转化为图拓扑连接，通过用户-属性-物品图增强协同过滤，在多个基准数据集上取得显著改进


<details>
  <summary>Details</summary>
Motivation: 现有方法要么计算成本过高（直接推理），要么只关注单边特征增强而非整体协同信号增强。需要一种有效将LLM语义信号转化为传统协同嵌入的方法。

Method: 提出TAGCF框架：1) 使用LLM从用户-物品对推断交互意图和因果关系，表示为用户-属性-物品图中的中间属性节点；2) 提出自适应关系权重图卷积（ARGC），使用关系特定预测网络动态估计每种关系类型的重要性。

Result: 在多个基准数据集和CF骨干网络上进行广泛实验，显示出一致的改进，包括冷启动场景的全面评估验证了框架的有效性和鲁棒性。

Conclusion: TAGCF通过将语义知识转化为拓扑连接，有效增强了协同过滤，解决了现有方法在语义信号转化方面的挑战。

Abstract: Large Language Models (LLMs) have shown great potential for enhancing recommender systems through their extensive world knowledge and reasoning capabilities. However, effectively translating these semantic signals into traditional collaborative embeddings remains an open challenge. Existing approaches typically fall into two extremes: direct inference methods are computationally prohibitive for large-scale retrieval, while embedding-based methods primarily focus on unilateral feature augmentation rather than holistic collaborative signal enhancement. To bridge this gap, we propose Topology-Augmented Graph Collaborative Filtering (TAGCF), a novel framework that transforms semantic knowledge into topological connectivity. Unlike existing approaches that depend on textual features or direct interaction synthesis, TAGCF employs LLMs to infer interaction intents and underlying causal relationships from user-item pairs, representing these insights as intermediate attribute nodes within an enriched User-Attribute-Item (U-A-I) graph. Furthermore, to effectively model the heterogeneous relations in this augmented structure, we propose Adaptive Relation-weighted Graph Convolution (ARGC), which employs relation-specific prediction networks to dynamically estimate the importance of each relation type. Extensive experiments across multiple benchmark datasets and CF backbones demonstrate consistent improvements, with comprehensive evaluations including cold-start scenarios validating the effectiveness and robustness of our framework. All code will be made publicly available. For anonymous review, our code is available at the following anonymous link: https://anonymous.4open.science/r/AGCF-2441353190/.

</details>


### [45] [Multi-Vector Index Compression in Any Modality](https://arxiv.org/abs/2602.21202)
*Hanxiang Qin,Alexander Martin,Rohan Jha,Chunsheng Zuo,Reno Kriz,Benjamin Van Durme*

Main category: cs.IR

TL;DR: 提出四种用于多向量检索的索引压缩方法，其中注意力引导聚类(AGC)在文本、视觉文档和视频检索任务中表现最佳


<details>
  <summary>Details</summary>
Motivation: 晚期交互范式在文本、图像、视觉文档和视频检索中占主导地位，但其计算和存储成本随文档长度线性增长，对于图像、视频、音频丰富的语料库成本过高

Method: 提出了四种查询无关的多向量文档表示压缩方法：序列调整、记忆标记、层次池化，以及新颖的注意力引导聚类(AGC)。AGC使用注意力引导机制识别文档中最具语义显著性的区域作为聚类中心，并加权标记聚合

Result: 在文本(BEIR)、视觉文档(ViDoRe)和视频(MSR-VTT, MultiVENT 2.0)检索任务中，注意力引导聚类一致优于其他参数化压缩方法，比非参数层次聚类提供更大的索引大小灵活性，且与完整未压缩索引相比达到竞争性或改进的性能

Conclusion: 注意力引导聚类(AGC)是一种有效的多向量检索压缩方法，在各种模态的检索任务中表现优异，为处理多模态丰富语料库提供了高效解决方案

Abstract: We study efficient multi-vector retrieval for late interaction in any modality. Late interaction has emerged as a dominant paradigm for information retrieval in text, images, visual documents, and videos, but its computation and storage costs grow linearly with document length, making it costly for image-, video-, and audio-rich corpora. To address this limitation, we explore query-agnostic methods for compressing multi-vector document representations under a constant vector budget. We introduce four approaches for index compression: sequence resizing, memory tokens, hierarchical pooling, and a novel attention-guided clustering (AGC). AGC uses an attention-guided mechanism to identify the most semantically salient regions of a document as cluster centroids and to weight token aggregation. Evaluating these methods on retrieval tasks spanning text (BEIR), visual-document (ViDoRe), and video (MSR-VTT, MultiVENT 2.0), we show that attention-guided clustering consistently outperforms other parameterized compression methods (sequence resizing and memory tokens), provides greater flexibility in index size than non-parametric hierarchical clustering, and achieves competitive or improved performance compared to a full, uncompressed index. The source code is available at: github.com/hanxiangqin/omni-col-press.

</details>
