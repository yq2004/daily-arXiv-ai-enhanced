<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 30]
- [cs.IR](#cs.IR) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Teaching People LLM's Errors and Getting it Right](https://arxiv.org/abs/2512.21422)
*Nathan Stringham,Fateme Hashemi Chaleshtori,Xinyuan Yan,Zhichao Xu,Bei Wang,Ana Marasović*

Main category: cs.CL

TL;DR: 该分析论文探讨了为什么教用户识别LLM失败模式的方法未能有效减轻过度依赖。研究发现失败模式确实存在，但现有自动发现方法效果不一，且评估指标需要改进。


<details>
  <summary>Details</summary>
Motivation: 用户经常在不该使用大语言模型(LLM)时过度依赖它们，部分原因是看到LLM能作诗和回答复杂问题，就错误地认为它们不会在基础任务上出错。虽然已有研究尝试通过聚类实例嵌入来识别LLM可能失败的区域并教用户这些失败模式，但这种方法并未完全成功。本文旨在探究失败原因。

Method: 1. 通过元标签分组分析验证失败模式是否存在；2. 评估提示和嵌入方法是否能有效发现已知失败模式；3. 重新设计评估指标，提出衡量用户能否有效利用失败模式预测LLM错误倾向的能力；4. 进行用户研究验证新指标的有效性。

Result: 1. 确认存在足够规模且LLM易出错的元标签组，即失败模式确实存在；2. 现有自动发现方法效果参差不齐，这可能解释了先前研究的负面结果；3. 使用新的评估指标（用户利用失败模式预测错误的能力）显示教学有积极效果，而传统的人机团队准确率指标则未显示效果。

Conclusion: 教用户识别失败模式可能是减轻过度依赖的可行方法，但成功取决于更好的自动失败发现方法和使用更合适的评估指标（如本文提出的指标）。

Abstract: People use large language models (LLMs) when they should not. This is partly because they see LLMs compose poems and answer intricate questions, so they understandably, but incorrectly, assume LLMs won't stumble on basic tasks like simple arithmetic. Prior work has tried to address this by clustering instance embeddings into regions where an LLM is likely to fail and automatically describing patterns in these regions. The found failure patterns are taught to users to mitigate their overreliance. Yet, this approach has not fully succeeded. In this analysis paper, we aim to understand why.
  We first examine whether the negative result stems from the absence of failure patterns. We group instances in two datasets by their meta-labels and evaluate an LLM's predictions on these groups. We then define criteria to flag groups that are sizable and where the LLM is error-prone, and find meta-label groups that meet these criteria. Their meta-labels are the LLM's failure patterns that could be taught to users, so they do exist. We next test whether prompting and embedding-based approaches can surface these known failures. Without this, users cannot be taught about them to reduce their overreliance. We find mixed results across methods, which could explain the negative result. Finally, we revisit the final metric that measures teaching effectiveness. We propose to assess a user's ability to effectively use the given failure patterns to anticipate when an LLM is error-prone. A user study shows a positive effect from teaching with this metric, unlike the human-AI team accuracy. Our findings show that teaching failure patterns could be a viable approach to mitigating overreliance, but success depends on better automated failure-discovery methods and using metrics like ours.

</details>


### [2] [Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models](https://arxiv.org/abs/2512.21439)
*Geoffroy Morlat,Marceau Nahon,Augustin Chartouny,Raja Chatila,Ismael T. Freire,Mehdi Khamassi*

Main category: cs.CL

TL;DR: COMETH是一个结合概率上下文学习、LLM语义抽象和人类道德评估的框架，用于建模上下文如何影响模糊行为的可接受性，相比端到端LLM提示将人类判断对齐度提高约一倍。


<details>
  <summary>Details</summary>
Motivation: 道德判断不仅取决于行为结果，还受上下文情境影响。现有端到端LLM在上下文敏感的道德预测中表现有限，缺乏可解释性，需要建立结合人类评估和模型学习的框架来理解上下文如何塑造道德判断。

Method: 1. 创建包含300个场景的实证数据集，涵盖6个核心行动；2. 收集101名参与者的三元判断；3. 使用LLM过滤器和MiniLM嵌入配合K-means进行预处理，生成核心行动聚类；4. COMETH通过基于分歧准则的在线聚类从人类判断分布中学习行动特定道德上下文；5. 泛化模块提取简洁的非评估性二元上下文特征，在基于似然的透明模型中学习特征权重。

Result: COMETH与多数人类判断的对齐度约为60%，相比端到端LLM提示的约30%提高了一倍。框架能揭示驱动预测的上下文特征，提供可解释的道德预测。

Conclusion: COMETH提供了一个结合人类判断、模型学习和LLM语义的可重复管道，作为端到端LLM的可解释替代方案，用于上下文敏感的道德预测和解释。该框架展示了如何系统性地建模道德上下文，提高预测准确性同时保持透明度。

Abstract: Moral actions are judged not only by their outcomes but by the context in which they occur. We present COMETH (Contextual Organization of Moral Evaluation from Textual Human inputs), a framework that integrates a probabilistic context learner with LLM-based semantic abstraction and human moral evaluations to model how context shapes the acceptability of ambiguous actions. We curate an empirically grounded dataset of 300 scenarios across six core actions (violating Do not kill, Do not deceive, and Do not break the law) and collect ternary judgments (Blame/Neutral/Support) from N=101 participants. A preprocessing pipeline standardizes actions via an LLM filter and MiniLM embeddings with K-means, producing robust, reproducible core-action clusters. COMETH then learns action-specific moral contexts by clustering scenarios online from human judgment distributions using principled divergence criteria. To generalize and explain predictions, a Generalization module extracts concise, non-evaluative binary contextual features and learns feature weights in a transparent likelihood-based model. Empirically, COMETH roughly doubles alignment with majority human judgments relative to end-to-end LLM prompting (approx. 60% vs. approx. 30% on average), while revealing which contextual features drive its predictions. The contributions are: (i) an empirically grounded moral-context dataset, (ii) a reproducible pipeline combining human judgments with model-based context learning and LLM semantics, and (iii) an interpretable alternative to end-to-end LLMs for context-sensitive moral prediction and explanation.

</details>


### [3] [Oogiri-Master: Benchmarking Humor Understanding via Oogiri](https://arxiv.org/abs/2512.21494)
*Soichiro Murakami,Hidetaka Kamigaito,Hiroya Takamura,Manabu Okumura*

Main category: cs.CL

TL;DR: 该论文通过日本创意回应游戏Oogiri研究LLM的幽默理解能力，创建了Oogiri-Master基准测试和Oogiri-Corpus数据集，分析了影响幽默感的语言因素，并展示了先进LLM在幽默理解方面接近人类水平的表现。


<details>
  <summary>Details</summary>
Motivation: 幽默是评估大语言模型（LLM）类人创造性思维的重要测试场。现有研究在幽默评估方面存在局限：数据集包含的候选回应数量少、评分时暴露流行度信号、缺乏客观可比较的幽默度指标。因此需要更严谨的方法来研究"什么因素让回应在人类看来有趣"这一核心问题。

Method: 1. 创建Oogiri-Corpus数据集：每个提示配约100个多样化候选回应，由约100名人类评委独立评分，减少流行度偏见，实现稳健聚合。
2. 定量分析幽默相关的语言因素：如文本长度、歧义性、不协调解决等，并推导预测人类判断的客观指标。
3. 开发Oogiri-Master基准测试：评估各种LLM和人类基线表现，测试基于洞察的提示增强方法。

Result: 1. 最先进的LLM在幽默理解任务上接近人类表现水平。
2. 基于洞察的提示增强（insight-augmented prompting）能提升模型性能。
3. 确定了与幽默感相关的客观语言特征和预测指标。
4. 建立了评估LLM幽默理解的系统化、可重复框架。

Conclusion: 该研究为评估和推进LLM的幽默理解能力提供了原则性基础，通过精心设计的数据集和基准测试，实现了对幽默这一复杂认知能力的量化分析，展示了LLM在创造性思维任务上的进步潜力。

Abstract: Humor is a salient testbed for human-like creative thinking in large language models (LLMs). We study humor using the Japanese creative response game Oogiri, in which participants produce witty responses to a given prompt, and ask the following research question: What makes such responses funny to humans? Previous work has offered only limited reliable means to answer this question. Existing datasets contain few candidate responses per prompt, expose popularity signals during ratings, and lack objective and comparable metrics for funniness. Thus, we introduce Oogiri-Master and Oogiri-Corpus, which are a benchmark and dataset designed to enable rigorous evaluation of humor understanding in LLMs. Each prompt is paired with approximately 100 diverse candidate responses, and funniness is rated independently by approximately 100 human judges without access to others' ratings, reducing popularity bias and enabling robust aggregation. Using Oogiri-Corpus, we conduct a quantitative analysis of the linguistic factors associated with funniness, such as text length, ambiguity, and incongruity resolution, and derive objective metrics for predicting human judgments. Subsequently, we benchmark a range of LLMs and human baselines in Oogiri-Master, demonstrating that state-of-the-art models approach human performance and that insight-augmented prompting improves the model performance. Our results provide a principled basis for evaluating and advancing humor understanding in LLMs.

</details>


### [4] [Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management](https://arxiv.org/abs/2512.21567)
*Changzhi Sun,Xiangyu Chen,Jixiang Luo,Dell Zhang,Xuelong Li*

Main category: cs.CL

TL;DR: 本文提出DAM（决策理论智能体记忆）框架，将记忆管理重构为不确定性下的序列决策问题，而非依赖手工启发式方法。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型系统的外部记忆管理主要依赖手工设计的启发式方法，这些方法难以预测记忆决策的长期和不确定后果。记忆的读写选择会以难以预见的方式影响未来的检索和下游行为。

Method: 提出DAM框架，将记忆管理分解为即时信息访问和分层存储维护。通过价值函数和不确定性估计器评估候选操作，聚合策略基于估计的长期效用和风险进行决策仲裁。

Result: DAM提供了一个原则性的重构框架，阐明了启发式方法的局限性，并为未来不确定性感知记忆系统研究奠定了基础。该框架本身不是新算法，而是概念性贡献。

Conclusion: 记忆管理应被视为不确定性下的序列决策问题，DAM框架为此提供了理论基础，有助于开发更智能、可预测的记忆系统。

Abstract: External memory is a key component of modern large language model (LLM) systems, enabling long-term interaction and personalization. Despite its importance, memory management is still largely driven by hand-designed heuristics, offering little insight into the long-term and uncertain consequences of memory decisions. In practice, choices about what to read or write shape future retrieval and downstream behavior in ways that are difficult to anticipate. We argue that memory management should be viewed as a sequential decision-making problem under uncertainty, where the utility of memory is delayed and dependent on future interactions. To this end, we propose DAM (Decision-theoretic Agent Memory), a decision-theoretic framework that decomposes memory management into immediate information access and hierarchical storage maintenance. Within this architecture, candidate operations are evaluated via value functions and uncertainty estimators, enabling an aggregate policy to arbitrate decisions based on estimated long-term utility and risk. Our contribution is not a new algorithm, but a principled reframing that clarifies the limitations of heuristic approaches and provides a foundation for future research on uncertainty-aware memory systems.

</details>


### [5] [A Unified Definition of Hallucination, Or: It's the World Model, Stupid](https://arxiv.org/abs/2512.21577)
*Emmy Liu,Varun Gangal,Chelsea Zou,Xiaoqi Huang,Michael Yu,Alex Chang,Zhuofu Tao,Sachin Kumar,Steven Y. Feng*

Main category: cs.CL

TL;DR: 该论文提出了幻觉的统一定义，认为幻觉本质上是语言模型内部世界建模的不准确性，这种不准确性对用户可见（如与知识库矛盾的事实）。论文通过统一视角澄清了幻觉概念，并提出了基于合成世界模型的基准测试框架。


<details>
  <summary>Details</summary>
Motivation: 尽管神经语言模型出现以来已有多次尝试解决幻觉问题，但即使是最先进的大语言模型仍存在幻觉。现有文献对幻觉的定义各不相同且混乱，缺乏统一的理论框架来清晰界定什么是幻觉、什么不是，这阻碍了有效的评估和缓解技术的发展。

Method: 论文从历史角度梳理了文献中各种幻觉定义，将其整合为一个统一定义：幻觉是语言模型内部世界建模的不准确性，这种不准确性对用户可见。通过变化参考世界模型（如知识库、上下文）和知识冲突策略，可以解释现有各种定义。基于这一定义，论文规划了一套基准测试框架，使用合成但完全指定的世界模型来定义和评估幻觉。

Result: 提出了统一的幻觉定义框架，将不同文献中的定义视为该框架的特例。该框架要求评估明确其假设的"世界"或真相来源，澄清了幻觉与规划错误或奖励相关错误的区别，为比较基准和缓解技术提供了共同语言。

Conclusion: 统一的幻觉定义有助于澄清概念混淆，促进更有效的评估和缓解技术发展。基于合成世界模型的基准测试框架可以压力测试和改进语言模型的世界建模能力，为解决幻觉问题提供系统化方法。

Abstract: Despite numerous attempts to solve the issue of hallucination since the inception of neural language models, it remains a problem in even frontier large language models today. Why is this the case? We walk through definitions of hallucination used in the literature from a historical perspective up to the current day, and fold them into a single definition of hallucination, wherein different prior definitions focus on different aspects of our definition. At its core, we argue that hallucination is simply inaccurate (internal) world modeling, in a form where it is observable to the user (e.g., stating a fact which contradicts a knowledge base, or producing a summary which contradicts a known source). By varying the reference world model as well as the knowledge conflict policy (e.g., knowledge base vs. in-context), we arrive at the different existing definitions of hallucination present in the literature.
  We argue that this unified view is useful because it forces evaluations to make clear their assumed "world" or source of truth, clarifies what should and should not be called hallucination (as opposed to planning or reward/incentive-related errors), and provides a common language to compare benchmarks and mitigation techniques. Building on this definition, we outline plans for a family of benchmarks in which hallucinations are defined as mismatches with synthetic but fully specified world models in different environments, and sketch out how these benchmarks can use such settings to stress-test and improve the world modeling components of language models.

</details>


### [6] [Gamayun's Path to Multilingual Mastery: Cost-Efficient Training of a 1.5B-Parameter LLM](https://arxiv.org/abs/2512.21580)
*Alexander Podolskiy,Semen Molokov,Timofey Gerasin,Maksim Titov,Alexey Rukhovich,Artem Khrapov,Kirill Morozov,Evgeny Tetin,Constantine Korikov,Pavel Efimov,Polina Lazukova,Yuliya Skripkar,Nikita Okhotnikov,Irina Piontkovskaya,Meng Xiaojun,Zou Xueyi,Zhang Zhenhe*

Main category: cs.CL

TL;DR: Gamayun是一个15亿参数的多语言语言模型，通过两阶段预训练策略在资源受限环境中实现高效部署，在较小训练预算下超越了LLaMA3.2-1B和Qwen2.5-1.5B等模型，在俄语任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 针对资源受限环境中缺乏小型非英语中心化LLM研究的问题，需要开发一个高效部署的多语言模型，特别关注俄语支持。

Method: 采用两阶段预训练策略：1) 平衡多语言训练实现跨语言对齐；2) 高质量英语数据增强以将性能增益传递到其他语言。模型支持12种语言，训练数据量为2.5T token。

Result: 在显著较小的训练预算下，Gamayun在英语和多语言任务上超越了LLaMA3.2-1B（9T token）和Qwen2.5-1.5B（18T token），在俄语任务上达到同类尺寸模型（1-2B参数）的SOTA水平，包括MERA基准测试。

Conclusion: Gamayun证明了通过精心设计的训练策略，即使使用相对较小的训练预算，也能构建出在资源受限环境中高效部署的竞争性多语言LLM，特别在俄语支持方面表现突出。

Abstract: We present Gamayun, a 1.5B-parameter multilingual language model trained entirely from scratch on 2.5T tokens. Designed for efficiency and deployment in resource-constrained environments, Gamayun addresses the lack of research on small non-English-centric LLMs by adopting a novel two-stage pre-training strategy: balanced multilingual training for cross-lingual alignment, followed by high-quality English enrichment to transfer performance gains across languages. Our model supports 12 languages, with special focus on Russian. Despite a significantly smaller training budget than comparable models, Gamayun outperforms LLaMA3.2-1B (9T tokens) on all considered benchmarks, and surpasses Qwen2.5-1.5B (18T tokens) on a wide range of English and multilingual tasks. It matches or exceeds Qwen3 (36T tokens) on most tasks outside advanced STEM, achieving state-of-the-art results in Russian, including the MERA benchmark, among the models of comparable size (1-2B parameters).

</details>


### [7] [Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2512.21625)
*Xinyu Tang,Yuliang Zhan,Zhixun Li,Wayne Xin Zhao,Zhenduo Zhang,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 该论文提出A3PO方法，通过自适应非对称的token级优势信号分配，优化大型推理模型的强化学习训练。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通常使用带可验证奖励的强化学习进行训练，但现有方法未系统研究正负样本极性对训练动态和行为的影响，需要更精细的优势信号分配机制。

Method: 提出A3PO方法：通过自适应非对称的token级优势塑造进行策略优化，更精确地为不同极性的关键token分配优势信号。

Result: 在五个推理基准测试上的实验证明了该方法的有效性。

Conclusion: A3PO方法通过精细化的优势信号分配，能够更有效地利用正负样本的不同作用，提升大型推理模型的训练效果。

Abstract: Large reasoning models (LRMs) are typically trained using reinforcement learning with verifiable reward (RLVR) to enhance their reasoning abilities. In this paradigm, policies are updated using both positive and negative self-generated rollouts, which correspond to distinct sample polarities. In this paper, we provide a systematic investigation into how these sample polarities affect RLVR training dynamics and behaviors. We find that positive samples sharpen existing correct reasoning patterns, while negative samples encourage exploration of new reasoning paths. We further explore how adjusting the advantage values of positive and negative samples at both the sample level and the token level affects RLVR training. Based on these insights, we propose an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, namely A3PO, that more precisely allocates advantage signals to key tokens across different polarities. Experiments across five reasoning benchmarks demonstrate the effectiveness of our approach.

</details>


### [8] [Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations](https://arxiv.org/abs/2512.21635)
*Chengxu Yang,Jingling Yuan,Siqi Cai,Jiawei Jiang,Chuang Hu*

Main category: cs.CL

TL;DR: HIC-Bench是一个评估LLM幻觉的创新框架，将幻觉分为智能幻觉(IH)和缺陷幻觉(DH)，系统研究它们与创造力的关系，涵盖10个科学领域，使用多维度指标和动态提示优化。


<details>
  <summary>Details</summary>
Motivation: 当前LLM幻觉通常被视为需要最小化的错误，但部分幻觉可能包含创造性或有认知价值的内容，这一维度在现有文献中缺乏量化。现有幻觉检测方法主要关注事实一致性，难以处理异质科学任务并平衡创造性与准确性。

Method: 提出HIC-Bench框架，将幻觉分为智能幻觉(IH)和缺陷幻觉(DH)，采用多维度指标矩阵整合托兰斯创造性思维测试(TTCT)指标（原创性、可行性、价值）和幻觉特定维度（科学合理性、事实偏差），涵盖10个科学领域的开放式创新任务，使用动态幻觉提示(DHP)优化模型输出，通过多LLM评委平均分减少偏见，人工标注验证IH/DH分类。

Result: 实验结果显示IH和DH之间存在非线性关系，表明创造性和正确性可以共同优化。IH可以作为创造力的催化剂，LLM幻觉能够推动科学创新。

Conclusion: HIC-Bench为LLM幻觉的创造性智能研究提供了有价值的平台，揭示了幻觉在促进科学创新方面的潜力，挑战了将幻觉单纯视为错误的传统观点。

Abstract: Hallucinations in large language models (LLMs) are commonly regarded as errors to be minimized. However, recent perspectives suggest that some hallucinations may encode creative or epistemically valuable content, a dimension that remains underquantified in current literature. Existing hallucination detection methods primarily focus on factual consistency, struggling to handle heterogeneous scientific tasks and balance creativity with accuracy. To address these challenges, we propose HIC-Bench, a novel evaluation framework that categorizes hallucinations into Intelligent Hallucinations (IH) and Defective Hallucinations (DH), enabling systematic investigation of their interplay in LLM creativity. HIC-Bench features three core characteristics: (1) Structured IH/DH Assessment. using a multi-dimensional metric matrix integrating Torrance Tests of Creative Thinking (TTCT) metrics (Originality, Feasibility, Value) with hallucination-specific dimensions (scientific plausibility, factual deviation); (2) Cross-Domain Applicability. spanning ten scientific domains with open-ended innovation tasks; and (3) Dynamic Prompt Optimization. leveraging the Dynamic Hallucination Prompt (DHP) to guide models toward creative and reliable outputs. The evaluation process employs multiple LLM judges, averaging scores to mitigate bias, with human annotators verifying IH/DH classifications. Experimental results reveal a nonlinear relationship between IH and DH, demonstrating that creativity and correctness can be jointly optimized. These insights position IH as a catalyst for creativity and reveal the ability of LLM hallucinations to drive scientific innovation.Additionally, the HIC-Bench offers a valuable platform for advancing research into the creative intelligence of LLM hallucinations.

</details>


### [9] [Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech](https://arxiv.org/abs/2512.21706)
*Shuchang Pan,Siddharth Banerjee,Dhruv Hebbar,Siddhant Patel,Akshaj Gupta,Kan Jen Cheng,Hanjo Kim,Zeyi Austin Li,Martin Q. Ma,Tingle Li,Gopala Anumanchipalli,Jiachen Lian*

Main category: cs.CL

TL;DR: 本文提出了一个基于思维图（GoT）的因果推理框架，用于建模对话中的意图到行为路径，预测高层次沟通意图和低层次言语行为，并生成可解释的推理链。


<details>
  <summary>Details</summary>
Motivation: 人类对话由隐含的思维链组织，表现为定时的言语行为。捕捉这种因果路径对于构建自然的全双工交互系统至关重要。现有系统缺乏对这种因果关系的建模能力。

Method: 1. 将对话过程建模为思维图（GoT）中的因果推理
2. 采用分层标注方案形式化意图到行为路径
3. 预测高层次沟通意图和低层次言语行为
4. 学习这些行为的因果和时间依赖关系
5. 使用混合语料库训练：可控的事件丰富模拟 + 人工标注原理 + 真实对话语音
6. 将流式预测结构化为演化图
7. 使用多模态Transformer预测下一个言语行为、生成决策理由并动态优化推理

Result: 1. 在合成和真实全双工对话上的实验显示
2. 框架实现了稳健的行为检测
3. 产生了可解释的推理链
4. 为全双工口语对话系统中的对话推理基准测试奠定了基础

Conclusion: GoT框架通过建模对话中的因果推理路径，不仅能够准确预测言语行为，还能生成可解释的决策理由，为构建更自然、智能的全双工对话系统提供了重要基础。

Abstract: Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this causal pathway is key to building natural full-duplex interactive systems. We introduce a framework that enables reasoning over conversational behaviors by modeling this process as causal inference within a Graph-of-Thoughts (GoT). Our approach formalizes the intent-to-action pathway with a hierarchical labeling scheme, predicting high-level communicative intents and low-level speech acts to learn their causal and temporal dependencies. To train this system, we develop a hybrid corpus that pairs controllable, event-rich simulations with human-annotated rationales and real conversational speech. The GoT framework structures streaming predictions as an evolving graph, enabling a multimodal transformer to forecast the next speech act, generate concise justifications for its decisions, and dynamically refine its reasoning. Experiments on both synthetic and real duplex dialogues show that the framework delivers robust behavior detection, produces interpretable reasoning chains, and establishes a foundation for benchmarking conversational reasoning in full duplex spoken dialogue systems.

</details>


### [10] [MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles](https://arxiv.org/abs/2512.21708)
*Jing Han,Binwei Yan,Tianyu Guo,Zheyuan Bai,Mengyu Zheng,Hanting Chen,Ying Nie*

Main category: cs.CL

TL;DR: 该论文提出了Mixture-of-Roles (MoR)框架，通过角色分解和参数高效微调方法来优化LLM代理任务性能。


<details>
  <summary>Details</summary>
Motivation: 尽管在微调大语言模型以促进代理任务方面取得了进展，但针对代理任务的参数高效微调方法仍未被充分探索。

Method: 1) 将代理任务能力分解为推理者、执行者和总结者三个角色；2) 提出MoR框架，包含三个专门的LoRA组，每个组负责一个角色；3) 开发基于公开数据集的多角色数据生成管道，包含角色特定内容完成和可靠性验证。

Result: 在各种LLM和代理基准测试上进行了广泛实验和消融研究，证明了所提方法的有效性。

Conclusion: MoR框架通过角色分解和参数高效微调，有效提升了LLM在代理任务中的性能，为代理任务的PEFT方法提供了新思路。

Abstract: Despite recent advancements of fine-tuning large language models (LLMs) to facilitate agent tasks, parameter-efficient fine-tuning (PEFT) methodologies for agent remain largely unexplored. In this paper, we introduce three key strategies for PEFT in agent tasks: 1) Inspired by the increasingly dominant Reason+Action paradigm, we first decompose the capabilities necessary for the agent tasks into three distinct roles: reasoner, executor, and summarizer. The reasoner is responsible for comprehending the user's query and determining the next role based on the execution trajectory. The executor is tasked with identifying the appropriate functions and parameters to invoke. The summarizer conveys the distilled information from conversations back to the user. 2) We then propose the Mixture-of-Roles (MoR) framework, which comprises three specialized Low-Rank Adaptation (LoRA) groups, each designated to fulfill a distinct role. By focusing on their respective specialized capabilities and engaging in collaborative interactions, these LoRAs collectively accomplish the agent task. 3) To effectively fine-tune the framework, we develop a multi-role data generation pipeline based on publicly available datasets, incorporating role-specific content completion and reliability verification. We conduct extensive experiments and thorough ablation studies on various LLMs and agent benchmarks, demonstrating the effectiveness of the proposed method. This project is publicly available at https://mor-agent.github.io.

</details>


### [11] [Detecting AI-Generated Paraphrases in Bengali: A Comparative Study of Zero-Shot and Fine-Tuned Transformers](https://arxiv.org/abs/2512.21709)
*Md. Rakibul Islam,Most. Sharmin Sultana Samu,Md. Zahid Hossain,Farhad Uz Zaman,Md. Kamrozzaman Bhuiyan*

Main category: cs.CL

TL;DR: 该研究针对孟加拉语中AI生成文本检测的空白，评估了五种Transformer模型，发现零样本性能不佳（约50%准确率），但经过微调后，XLM-RoBERTa、mDeBERTa和MultilingualBERT能达到约91%的准确率和F1分数，为孟加拉语AI文本检测奠定了基础。


<details>
  <summary>Details</summary>
Motivation: LLMs能生成接近人类水平的文本，引发了关于虚假信息和内容滥用的担忧。检测AI生成文本对于维护内容真实性和防止恶意应用至关重要。虽然已有研究涉及多语言检测，但孟加拉语领域尚未充分探索，且其丰富的词汇和复杂结构使得区分人类写作和AI生成文本尤为困难。

Method: 研究调查了五种基于Transformer的模型：XLMRoBERTa-Large、mDeBERTaV3-Base、BanglaBERT-Base、IndicBERT-Base和MultilingualBERT-Base。首先进行零样本评估，然后对模型进行任务特定的微调，以提升检测性能。

Result: 零样本评估显示所有模型性能接近随机水平（约50%准确率），表明需要任务特定的微调。微调后性能显著提升，XLM-RoBERTa、mDeBERTa和MultilingualBERT在准确率和F1分数上均达到约91%。IndicBERT表现相对较弱，表明其在该任务微调中的有效性有限。

Conclusion: 该研究推进了孟加拉语中AI生成文本检测的发展，为构建强大的系统来对抗AI生成内容奠定了基础。研究强调了针对特定语言特性进行模型微调的重要性，特别是在孟加拉语这种具有丰富词汇和复杂结构的语言中。

Abstract: Large language models (LLMs) can produce text that closely resembles human writing. This capability raises concerns about misuse, including disinformation and content manipulation. Detecting AI-generated text is essential to maintain authenticity and prevent malicious applications. Existing research has addressed detection in multiple languages, but the Bengali language remains largely unexplored. Bengali's rich vocabulary and complex structure make distinguishing human-written and AI-generated text particularly challenging. This study investigates five transformer-based models: XLMRoBERTa-Large, mDeBERTaV3-Base, BanglaBERT-Base, IndicBERT-Base and MultilingualBERT-Base. Zero-shot evaluation shows that all models perform near chance levels (around 50% accuracy) and highlight the need for task-specific fine-tuning. Fine-tuning significantly improves performance, with XLM-RoBERTa, mDeBERTa and MultilingualBERT achieving around 91% on both accuracy and F1-score. IndicBERT demonstrates comparatively weaker performance, indicating limited effectiveness in fine-tuning for this task. This work advances AI-generated text detection in Bengali and establishes a foundation for building robust systems to counter AI-generated content.

</details>


### [12] [Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought](https://arxiv.org/abs/2512.21711)
*Yuyi Zhang,Boyu Tang,Tianjie Ju,Sufeng Duan,Gongshen Liu*

Main category: cs.CL

TL;DR: 该论文通过可靠性视角分析LLM中的潜在token机制，揭示COCONUT方法实际上是一种伪推理机制，它通过利用数据集伪影而非真实推理来提升基准性能。


<details>
  <summary>Details</summary>
Motivation: 潜在token在增强大型语言模型推理方面受到关注，但其内部机制尚不明确。作者希望从可靠性角度分析潜在token机制，揭示其作为不可解释占位符而非忠实编码推理的根本弱点。

Method: 采用两种互补方法：1) 转向实验，扰动特定token子集（COCONUT和显式CoT），比较敏感性；2) 捷径实验，在偏见和分布外设置下评估模型，分析数据集伪影利用情况。

Result: 在MMLU和HotpotQA上的实验表明：1) COCONUT token对转向扰动不敏感，缺乏推理关键信息；2) COCONUT持续利用数据集伪影，在基准测试中夸大性能而不进行真实推理。

Conclusion: COCONUT是一种伪推理机制，它生成看似合理的推理轨迹，但实际上掩盖了对捷径的依赖，而非忠实表示推理过程。这暴露了潜在token方法在可靠性方面的根本缺陷。

Abstract: Latent tokens are gaining attention for enhancing reasoning in large language models (LLMs), yet their internal mechanisms remain unclear. This paper examines the problem from a reliability perspective, uncovering fundamental weaknesses: latent tokens function as uninterpretable placeholders rather than encoding faithful reasoning. While resistant to perturbation, they promote shortcut usage over genuine reasoning. We focus on Chain-of-Continuous-Thought (COCONUT), which claims better efficiency and stability than explicit Chain-of-Thought (CoT) while maintaining performance. We investigate this through two complementary approaches. First, steering experiments perturb specific token subsets, namely COCONUT and explicit CoT. Unlike CoT tokens, COCONUT tokens show minimal sensitivity to steering and lack reasoning-critical information. Second, shortcut experiments evaluate models under biased and out-of-distribution settings. Results on MMLU and HotpotQA demonstrate that COCONUT consistently exploits dataset artifacts, inflating benchmark performance without true reasoning. These findings reposition COCONUT as a pseudo-reasoning mechanism: it generates plausible traces that conceal shortcut dependence rather than faithfully representing reasoning processes.

</details>


### [13] [CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation](https://arxiv.org/abs/2512.21715)
*Rui Ke,Jiahui Xu,Shenghao Yang,Kuang Wang,Feng Jiang,Haizhou Li*

Main category: cs.CL

TL;DR: CATCH是一个用于用户中心对话系统主题检测的统一框架，通过上下文感知主题表示、偏好引导主题聚类和分层主题生成，解决了稀疏短文本表示和用户偏好建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有主题检测方法难以处理稀疏、简短的话语以获得准确的主题表示，并且无法捕捉跨对话的用户层面主题偏好。主题检测需要在跨对话中保持一致性并与个性化用户偏好对齐，这带来了重大挑战。

Method: CATCH框架包含三个核心组件：(1)上下文感知主题表示，利用周围主题片段丰富话语级语义；(2)偏好引导主题聚类，联合建模语义邻近性和个性化反馈以跨对话对齐主题；(3)分层主题生成机制，旨在抑制噪声并生成鲁棒、连贯的主题标签。

Result: 在多领域客户对话基准（DSTC-12）上的实验表明，CATCH在主题聚类和主题生成质量方面都具有有效性，使用了8B参数的LLM。

Conclusion: CATCH通过整合上下文感知表示、个性化聚类和分层生成，为无预定义模式的主题检测提供了一个有效的统一框架，能够更好地处理用户中心对话系统中的主题检测挑战。

Abstract: Theme detection is a fundamental task in user-centric dialogue systems, aiming to identify the latent topic of each utterance without relying on predefined schemas. Unlike intent induction, which operates within fixed label spaces, theme detection requires cross-dialogue consistency and alignment with personalized user preferences, posing significant challenges. Existing methods often struggle with sparse, short utterances for accurate topic representation and fail to capture user-level thematic preferences across dialogues. To address these challenges, we propose CATCH (Controllable Theme Detection with Contextualized Clustering and Hierarchical Generation), a unified framework that integrates three core components: (1) context-aware topic representation, which enriches utterance-level semantics using surrounding topic segments; (2) preference-guided topic clustering, which jointly models semantic proximity and personalized feedback to align themes across dialogue; and (3) a hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels. Experiments on a multi-domain customer dialogue benchmark (DSTC-12) demonstrate the effectiveness of CATCH with 8B LLM in both theme clustering and topic generation quality.

</details>


### [14] [Ara-HOPE: Human-Centric Post-Editing Evaluation for Dialectal Arabic to Modern Standard Arabic Translation](https://arxiv.org/abs/2512.21787)
*Abdullah Alabdullah,Lifeng Han,Chenghua Lin*

Main category: cs.CL

TL;DR: 本文介绍了Ara-HOPE框架，一个针对阿拉伯方言到现代标准阿拉伯语翻译评估的人类中心化后编辑评估系统，包含错误分类和标注协议，能有效评估不同翻译系统的性能差异。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言到现代标准阿拉伯语翻译面临词汇、句法和语义差异的挑战，现有自动评估指标和通用人工评估框架难以捕捉方言特有的翻译错误，阻碍了翻译评估的进展。

Method: 提出了Ara-HOPE框架，包括一个五类错误分类法和决策树标注协议，通过比较评估三个机器翻译系统（阿拉伯语中心的Jais、通用GPT-3.5和基线NLLB-200）来验证框架有效性。

Result: 评估结果显示，方言特定术语和语义保留是DA-MSA翻译中最持久的挑战，Ara-HOPE能有效突出不同系统间的系统性性能差异。

Conclusion: Ara-HOPE为评估阿拉伯方言机器翻译质量建立了新框架，并为改进方言感知的机器翻译系统提供了可操作的指导。

Abstract: Dialectal Arabic to Modern Standard Arabic (DA-MSA) translation is a challenging task in Machine Translation (MT) due to significant lexical, syntactic, and semantic divergences between Arabic dialects and MSA. Existing automatic evaluation metrics and general-purpose human evaluation frameworks struggle to capture dialect-specific MT errors, hindering progress in translation assessment. This paper introduces Ara-HOPE, a human-centric post-editing evaluation framework designed to systematically address these challenges. The framework includes a five-category error taxonomy and a decision-tree annotation protocol. Through comparative evaluation of three MT systems (Arabic-centric Jais, general-purpose GPT-3.5, and baseline NLLB-200), Ara-HOPE effectively highlights systematic performance differences between these systems. The results show that dialect-specific terminology and semantic preservation remain the most persistent challenges in DA-MSA translation. Ara-HOPE establishes a new framework for evaluating Dialectal Arabic MT quality and provides actionable guidance for improving dialect-aware MT systems.

</details>


### [15] [Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning](https://arxiv.org/abs/2512.21789)
*Ting-Hao K. Huang,Ryan A. Rossi,Sungchul Kim,Tong Yu,Ting-Yao E. Hsu,Ho Yin,Ng,C. Lee Giles*

Main category: cs.CL

TL;DR: SciCap项目在2021-2025年间从宾州大学的种子项目发展成为科学图表标注领域的核心项目，通过多机构合作构建了大规模图表-标题数据集，开展了自动和人工评估，应对了大语言模型的兴起，并开发了辅助科学家撰写更好标题的交互系统。


<details>
  <summary>Details</summary>
Motivation: 最初动机是测试在文本模型（如SciBERT）中成功的领域特定训练方法是否也适用于图表标题生成，探索科学图表标注这一特定领域的问题。

Method: 1. 从arXiv论文中收集、整理和持续更新大规模图表-标题配对数据集
2. 对生成标题和作者撰写标题进行广泛的自动和人工评估
3. 应对大语言模型的快速发展
4. 发起年度挑战赛
5. 开发辅助科学家撰写更好标题的交互系统

Result: 成功将SciCap项目从种子想法发展为科学图表标注领域的核心项目，建立了多机构合作框架，创建了持续更新的数据集，开展了系统评估，并开发了实用的交互工具。

Conclusion: 总结了前五年的技术和方法学经验教训，提出了科学图表标注领域尚未解决的五个主要挑战，并为下一阶段研究指明了方向。

Abstract: Between 2021 and 2025, the SciCap project grew from a small seed-funded idea at The Pennsylvania State University (Penn State) into one of the central efforts shaping the scientific figure-captioning landscape. Supported by a Penn State seed grant, Adobe, and the Alfred P. Sloan Foundation, what began as our attempt to test whether domain-specific training, which was successful in text models like SciBERT, could also work for figure captions expanded into a multi-institution collaboration. Over these five years, we curated, released, and continually updated a large collection of figure-caption pairs from arXiv papers, conducted extensive automatic and human evaluations on both generated and author-written captions, navigated the rapid rise of large language models (LLMs), launched annual challenges, and built interactive systems that help scientists write better captions. In this piece, we look back at the first five years of SciCap and summarize the key technical and methodological lessons we learned. We then outline five major unsolved challenges and propose directions for the next phase of research in scientific figure captioning.

</details>


### [16] [On The Conceptualization and Societal Impact of Cross-Cultural Bias](https://arxiv.org/abs/2512.21809)
*Vitthal Bhandari*

Main category: cs.CL

TL;DR: 对2025年发表的20篇关于NLP文化偏见的论文进行系统性分析，提出观察框架以帮助研究者更具体地概念化偏见并有效评估其危害，倡导对跨文化偏见语言技术进行更稳健的社会影响评估。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，尽管大语言模型（LLMs）能够基于文化背景生成响应，但它们并不完美且倾向于跨文化泛化。当前研究在评估语言技术文化偏见时，往往不接触实际使用该技术的利益相关者，这回避了研究者本应解决的根本问题。

Method: 受arXiv:2005.14050v2工作的启发，系统分析了2025年发表的20篇关于NLP文化偏见识别与评估的文献，提取出一系列观察结果和框架。

Result: 提出了一个观察框架，使未来NLP研究者能够更具体地概念化偏见，并有效评估其危害。该框架旨在推动对表现出跨文化偏见的语言技术进行更稳健的社会影响评估。

Conclusion: 需要建立更全面的评估方法，将实际利益相关者的参与纳入文化偏见评估过程，以更准确地衡量语言技术的社会影响，解决现有评估方法的局限性。

Abstract: Research has shown that while large language models (LLMs) can generate their responses based on cultural context, they are not perfect and tend to generalize across cultures. However, when evaluating the cultural bias of a language technology on any dataset, researchers may choose not to engage with stakeholders actually using that technology in real life, which evades the very fundamental problem they set out to address.
  Inspired by the work done by arXiv:2005.14050v2, I set out to analyse recent literature about identifying and evaluating cultural bias in Natural Language Processing (NLP). I picked out 20 papers published in 2025 about cultural bias and came up with a set of observations to allow NLP researchers in the future to conceptualize bias concretely and evaluate its harms effectively. My aim is to advocate for a robust assessment of the societal impact of language technologies exhibiting cross-cultural bias.

</details>


### [17] [Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments](https://arxiv.org/abs/2512.21817)
*Hong Su*

Main category: cs.CL

TL;DR: 提出Method Decoration (DeMe)框架，通过目标、经验、环境反馈等装饰信息修改LLM方法生成路径，提升IoT系统在未知环境中的适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的IoT系统在生成任务执行方法时存在两个主要问题：1) 无法系统性地为新情况生成新方法；2) 依赖固定的设备特定逻辑，无法适应动态环境变化。

Method: 提出Method Decoration (DeMe)通用框架，从隐藏目标、累积学习方法、环境反馈中提取装饰信息，通过预装饰、后装饰、中间步骤修改、步骤插入等方式重组LLM的方法生成路径。

Result: 实验结果表明，方法装饰使IoT设备在面对未知或故障操作条件时能够推导出更合适的方法。

Conclusion: DeMe框架通过动态装饰LLM方法生成路径，实现了上下文感知、安全对齐和环境自适应的智能IoT方法生成。

Abstract: Intelligent IoT systems increasingly rely on large language models (LLMs) to generate task-execution methods for dynamic environments. However, existing approaches lack the ability to systematically produce new methods when facing previously unseen situations, and they often depend on fixed, device-specific logic that cannot adapt to changing environmental conditions.In this paper, we propose Method Decoration (DeMe), a general framework that modifies the method-generation path of an LLM using explicit decorations derived from hidden goals, accumulated learned methods, and environmental feedback. Unlike traditional rule augmentation, decorations in DeMe are not hardcoded; instead, they are extracted from universal behavioral principles, experience, and observed environmental differences. DeMe enables the agent to reshuffle the structure of its method path-through pre-decoration, post-decoration, intermediate-step modification, and step insertion-thereby producing context-aware, safety-aligned, and environment-adaptive methods. Experimental results show that method decoration allows IoT devices to derive ore appropriate methods when confronting unknown or faulty operating conditions.

</details>


### [18] [Knowledge Reasoning of Large Language Models Integrating Graph-Structured Information for Pest and Disease Control in Tobacco](https://arxiv.org/abs/2512.21837)
*Siyu Li,Chenwei Song,Wan Zhou,Xinyi Liu*

Main category: cs.CL

TL;DR: 本文提出了一种集成图结构信息的LLM方法，用于烟草病虫害防治的知识推理，通过构建领域知识图谱并融合图神经网络，显著提升了推理准确性和深度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在烟草病虫害防治领域的知识推理存在局限性，缺乏对结构化领域知识的有效利用，导致在复杂推理场景中准确性不足。

Method: 基于GraphRAG框架，首先利用LLM辅助构建烟草病虫害知识图谱，然后采用Transformer架构作为核心推理模型，结合GNN学习节点表示，使用ChatGLM作为骨干LLM并通过LoRA进行参数高效微调。

Result: 实验结果表明，该方法在多项评估指标上持续优于基线方法，显著提高了推理准确性和深度，特别是在复杂的多跳推理和比较推理场景中表现突出。

Conclusion: 通过将图结构信息集成到LLM推理过程中，能够有效提升烟草病虫害防治领域的知识推理能力，为领域专家提供更准确、深入的支持。

Abstract: This paper proposes a large language model (LLM) approach that integrates graph-structured information for knowledge reasoning in tobacco pest and disease control. Built upon the GraphRAG framework, the proposed method enhances knowledge retrieval and reasoning by explicitly incorporating structured information from a domain-specific knowledge graph. Specifically, LLMs are first leveraged to assist in the construction of a tobacco pest and disease knowledge graph, which organizes key entities such as diseases, symptoms, control methods, and their relationships. Based on this graph, relevant knowledge is retrieved and integrated into the reasoning process to support accurate answer generation. The Transformer architecture is adopted as the core inference model, while a graph neural network (GNN) is employed to learn expressive node representations that capture both local and global relational information within the knowledge graph. A ChatGLM-based model serves as the backbone LLM and is fine-tuned using LoRA to achieve parameter-efficient adaptation. Extensive experimental results demonstrate that the proposed approach consistently outperforms baseline methods across multiple evaluation metrics, significantly improving both the accuracy and depth of reasoning, particularly in complex multi-hop and comparative reasoning scenarios.

</details>


### [19] [AlignAR: Generative Sentence Alignment for Arabic-English Parallel Corpora of Legal and Literary Texts](https://arxiv.org/abs/2512.21842)
*Baorong Huang,Ali Asiri*

Main category: cs.CL

TL;DR: 提出了AlignAR生成式句子对齐方法和包含复杂法律与文学文本的阿拉伯语-英语数据集，发现"简单"数据集缺乏区分能力，而LLM方法在"困难"子集上表现更优


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语-英语平行语料库稀缺，现有数据集主要包含简单的一对一映射，无法充分评估对齐方法，特别是在复杂文本上

Method: 提出了AlignAR生成式句子对齐方法，并构建了包含复杂法律和文学文本的新阿拉伯语-英语数据集，包含"简单"和"困难"两个子集

Result: 评估显示"简单"数据集缺乏区分对齐方法的能力；通过减少"困难"子集中的一对一映射，暴露了传统对齐方法的局限性；LLM方法表现出更强的鲁棒性，整体F1分数达到85.5%，比之前方法提高了9%

Conclusion: 高质量平行语料库对机器翻译研究和教学至关重要；传统对齐方法在复杂文本上存在局限性，而LLM方法在困难对齐任务中表现更优；开源数据集和代码有助于推动相关研究

Abstract: High-quality parallel corpora are essential for Machine Translation (MT) research and translation teaching. However, Arabic-English resources remain scarce and existing datasets mainly consist of simple one-to-one mappings. In this paper, we present AlignAR, a generative sentence alignment method, and a new Arabic-English dataset comprising complex legal and literary texts. Our evaluation demonstrates that "Easy" datasets lack the discriminatory power to fully assess alignment methods. By reducing one-to-one mappings in our "Hard" subset, we exposed the limitations of traditional alignment methods. In contrast, LLM-based approaches demonstrated superior robustness, achieving an overall F1-score of 85.5%, a 9% improvement over previous methods. Our datasets and codes are open-sourced at https://github.com/XXX.

</details>


### [20] [HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs](https://arxiv.org/abs/2512.21849)
*Jiaxin Liu,Peiyi Tu,Wenyu Chen,Yihong Zhuang,Xinxia Ling,Anji Zhou,Chenxi Wang,Zhuo Han,Zhengkai Yang,Junbo Zhao,Zenan Huang,Yuanyuan Wang*

Main category: cs.CL

TL;DR: HeartBench是一个评估中文大语言模型情感、文化和伦理智能的综合框架，基于真实心理咨询场景构建，发现现有模型在复杂社会情感场景中表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然在认知和推理任务上表现出色，但在处理复杂社会、情感和伦理细微差别方面存在明显不足。特别是在中文语言文化背景下，缺乏专门的评估框架和高质量的社会情感数据，阻碍了模型在拟人化智能方面的发展。

Method: 1. 与临床专家合作，基于真实心理咨询场景构建评估框架
2. 采用理论驱动的分类法，包含5个主要维度和15个次要能力
3. 实施案例特定的、基于量规的方法论
4. 通过"推理-评分"评估协议将抽象的人类特质转化为可测量的细粒度标准
5. 评估13个最先进的大语言模型
6. 使用难度分层的"困难集"进行性能分析

Result: 1. 评估的13个最先进模型存在显著的性能上限：即使是领先模型也只能达到专家定义理想分数的60%
2. 在涉及微妙情感潜台词和复杂伦理权衡的场景中，模型性能出现显著衰减
3. 通过难度分层的"困难集"分析，揭示了模型在处理复杂社会情感任务时的局限性

Conclusion: HeartBench为拟人化AI评估建立了标准化度量标准，并为构建高质量、与人类对齐的训练数据提供了方法论蓝图。研究结果表明当前中文大语言模型在情感、文化和伦理智能方面仍有显著提升空间，需要更专门的评估框架和训练数据来推动这一领域的发展。

Abstract: While Large Language Models (LLMs) have achieved remarkable success in cognitive and reasoning benchmarks, they exhibit a persistent deficit in anthropomorphic intelligence-the capacity to navigate complex social, emotional, and ethical nuances. This gap is particularly acute in the Chinese linguistic and cultural context, where a lack of specialized evaluation frameworks and high-quality socio-emotional data impedes progress. To address these limitations, we present HeartBench, a framework designed to evaluate the integrated emotional, cultural, and ethical dimensions of Chinese LLMs. Grounded in authentic psychological counseling scenarios and developed in collaboration with clinical experts, the benchmark is structured around a theory-driven taxonomy comprising five primary dimensions and 15 secondary capabilities. We implement a case-specific, rubric-based methodology that translates abstract human-like traits into granular, measurable criteria through a ``reasoning-before-scoring'' evaluation protocol. Our assessment of 13 state-of-the-art LLMs indicates a substantial performance ceiling: even leading models achieve only 60% of the expert-defined ideal score. Furthermore, analysis using a difficulty-stratified ``Hard Set'' reveals a significant performance decay in scenarios involving subtle emotional subtexts and complex ethical trade-offs. HeartBench establishes a standardized metric for anthropomorphic AI evaluation and provides a methodological blueprint for constructing high-quality, human-aligned training data.

</details>


### [21] [TimeBill: Time-Budgeted Inference for Large Language Models](https://arxiv.org/abs/2512.21859)
*Qi Fan,An Zou,Yehan Ma*

Main category: cs.CL

TL;DR: TimeBill：一个新颖的时间预算推理框架，通过自适应调整KV缓存淘汰率来平衡LLM推理效率与响应性能，以满足时间关键系统中的实时需求。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地部署在时间关键系统中（如机器人、自动驾驶、具身智能等），这些系统需要在给定时间预算内生成准确响应。然而，自回归生成过程使得端到端执行时间难以建模和估计，而现有的基于固定KV缓存淘汰率的高效推理方法难以适应具有不同时间预算的多样化任务。

Method: 1. 提出细粒度响应长度预测器（RLP）和执行时间估计器（ETE）来准确预测LLMs的端到端执行时间；2. 开发时间预算高效推理方法，基于执行时间预测和给定时间预算自适应调整KV缓存淘汰率。

Result: 通过大量实验证明，TimeBill在各种超限策略下都能提高任务完成率并保持响应性能，展示了其在时间预算推理方面的优势。

Conclusion: TimeBill框架成功解决了LLMs在时间关键系统中的推理效率与性能平衡问题，通过自适应KV缓存管理实现了在严格时间约束下的可靠推理。

Abstract: Large Language Models (LLMs) are increasingly deployed in time-critical systems, such as robotics, autonomous driving, embodied intelligence, and industrial automation, where generating accurate responses within a given time budget is crucial for decision-making, control, or safety-critical tasks. However, the auto-regressive generation process of LLMs makes it challenging to model and estimate the end-to-end execution time. Furthermore, existing efficient inference methods based on a fixed key-value (KV) cache eviction ratio struggle to adapt to varying tasks with diverse time budgets, where an improper eviction ratio may lead to incomplete inference or a drop in response performance. In this paper, we propose TimeBill, a novel time-budgeted inference framework for LLMs that balances the inference efficiency and response performance. To be more specific, we propose a fine-grained response length predictor (RLP) and an execution time estimator (ETE) to accurately predict the end-to-end execution time of LLMs. Following this, we develop a time-budgeted efficient inference approach that adaptively adjusts the KV cache eviction ratio based on execution time prediction and the given time budget. Finally, through extensive experiments, we demonstrate the advantages of TimeBill in improving task completion rate and maintaining response performance under various overrun strategies.

</details>


### [22] [Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?](https://arxiv.org/abs/2512.21871)
*Naen Xu,Jinghuai Zhang,Changjiang Li,Hengyu An,Chunyi Zhou,Jun Wang,Boyu Xu,Yuyuan Li,Tianyu Du,Shouling Ji*

Main category: cs.CL

TL;DR: 该论文评估了大型视觉语言模型处理版权内容的能力，发现现有模型存在明显缺陷，并提出了工具增强的防御框架来降低侵权风险。


<details>
  <summary>Details</summary>
Motivation: 随着大型视觉语言模型的广泛应用，处理版权内容时可能引发的侵权风险成为一个重要问题。需要评估这些模型能否准确识别并遵守版权法规，以避免法律和伦理后果。

Method: 构建了包含50,000个多模态查询-内容对的大规模基准数据集，涵盖书籍摘录、新闻报道、音乐歌词和代码文档等版权内容。数据集包含有版权声明和无版权声明两种场景，并覆盖四种版权声明类型。通过该数据集系统评估各种LVLMs的版权合规性。

Result: 评估发现，即使是当前最先进的闭源LVLMs，在识别和尊重版权内容方面也存在显著缺陷，即使面对版权声明时也是如此。为了解决这一限制，作者提出了工具增强的版权合规防御框架。

Conclusion: 开发版权感知的大型视觉语言模型对于确保负责任且合法地使用版权内容至关重要。论文提出的防御框架为降低侵权风险提供了有效解决方案。

Abstract: Large vision-language models (LVLMs) have achieved remarkable advancements in multimodal reasoning tasks. However, their widespread accessibility raises critical concerns about potential copyright infringement. Will LVLMs accurately recognize and comply with copyright regulations when encountering copyrighted content (i.e., user input, retrieved documents) in the context? Failure to comply with copyright regulations may lead to serious legal and ethical consequences, particularly when LVLMs generate responses based on copyrighted materials (e.g., retrieved book experts, news reports). In this paper, we present a comprehensive evaluation of various LVLMs, examining how they handle copyrighted content -- such as book excerpts, news articles, music lyrics, and code documentation when they are presented as visual inputs. To systematically measure copyright compliance, we introduce a large-scale benchmark dataset comprising 50,000 multimodal query-content pairs designed to evaluate how effectively LVLMs handle queries that could lead to copyright infringement. Given that real-world copyrighted content may or may not include a copyright notice, the dataset includes query-content pairs in two distinct scenarios: with and without a copyright notice. For the former, we extensively cover four types of copyright notices to account for different cases. Our evaluation reveals that even state-of-the-art closed-source LVLMs exhibit significant deficiencies in recognizing and respecting the copyrighted content, even when presented with the copyright notice. To solve this limitation, we introduce a novel tool-augmented defense framework for copyright compliance, which reduces infringement risks in all scenarios. Our findings underscore the importance of developing copyright-aware LVLMs to ensure the responsible and lawful use of copyrighted content.

</details>


### [23] [CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics](https://arxiv.org/abs/2512.21877)
*Vaibhav Devraj,Dhruv Kumar,Jagat Sesh Challa*

Main category: cs.CL

TL;DR: 提出了CricBench基准套件，用于评估LLM在板球数据分析领域的Text-to-SQL能力，包含英语和印地语查询，发现领域专业知识比通用基准表现更重要，且印地语查询有时表现优于英语。


<details>
  <summary>Details</summary>
Motivation: 板球作为全球第二大运动拥有25亿粉丝，但现有LLM在处理体育分析中的领域特定复杂性、模式变化和多语言需求方面能力不足，需要专门基准来评估LLM在该领域的表现。

Method: 1. 与板球和SQL领域专家合作手动编写复杂查询创建"黄金标准"数据集；2. 构建英语和印地语双语基准框架；3. 评估6个最先进模型（包括GPT-4o、Claude 3.7 Sonnet和开源模型）；4. 使用严格评估协议。

Result: 1. 开源推理模型DeepSeek R1表现最佳（50.6%），超越Claude 3.7 Sonnet（47.7%）和GPT-4o（33.7%）；2. 从通用基准（BIRD）到CricBench时所有模型准确率显著下降；3. 印地语混合查询常达到与英语相当或更高的准确率。

Conclusion: 通用基准的高性能不能保证在专业领域的成功，领域专业知识至关重要；多语言能力在专业SQL任务中具有价值，英语不一定是最佳提示语言；需要进一步研究提升LLM在专业领域的表现。

Abstract: Cricket is the second most popular sport globally, commanding a massive following of over 2.5 billion fans globally. Enthusiasts and analysts frequently seek advanced statistical insights, such as long-term historical performance trends or complex player comparisons, that are often unavailable through standard web searches. While Large Language Models (LLMs) have advanced significantly in Text-to-SQL tasks, their capability to handle the domain-specific nuances, complex schema variations, and multilingual requirements inherent to sports analytics remains under-explored. To investigate this potential capability gap, we present CricBench, a comprehensive benchmark suite for evaluating LLMs on specialized cricket data. To curate a "Gold Standard" dataset, we collaborate with domain experts in cricket and SQL to manually author complex queries, ensuring logical correctness. Recognizing linguistic diversity, we construct the benchmark in both English and Hindi, establishing a framework that is open for further extension to other regional languages. We evaluate six state-of-the-art models, including GPT-4o, Claude 3.7 Sonnet, and open-source models, using a strict evaluation protocol. Our results reveal that high performance on general benchmarks does not guarantee success in specialized domains. While the open-weights reasoning model DeepSeek R1 achieves state-of-the-art performance (50.6%), surpassing proprietary giants like Claude 3.7 Sonnet (47.7%) and GPT-4o (33.7%), it still exhibits a significant accuracy drop when moving from general benchmarks (BIRD) to CricBench. Furthermore, we observe that code-mixed Hindi queries frequently yield parity or higher accuracy compared to English, challenging the assumption that English is the optimal prompt language for specialized SQL tasks.

</details>


### [24] [Explainable Statute Prediction via Attention-based Model and LLM Prompting](https://arxiv.org/abs/2512.21902)
*Sachin Pawar,Girish Keshav Palshikar,Anindita Sinha Banerjee,Nitin Ramrakhiyani,Basit Ali*

Main category: cs.CL

TL;DR: 该论文研究了法律条文自动预测问题，提出了两种带解释的预测方法：基于句子注意力的AoS模型和基于大语言模型提示的LLMPrompt方法，并在两个数据集上进行了性能比较和解释质量评估。


<details>
  <summary>Details</summary>
Motivation: 法律条文自动预测有助于律师AI助手和法律问答系统等应用。为了让法律AI系统获得更好的用户接受度，预测结果需要附带人类可理解的解释。

Method: 提出了两种方法：1) AoS模型：使用句子注意力机制，基于句子变换器进行监督训练；2) LLMPrompt：使用大语言模型进行零样本预测，探索标准提示和思维链提示技术。两种方法都能生成人类可理解的解释。

Result: 在两个流行数据集上比较了两种方法的条文预测性能，并与多个基线模型进行了对比。通过自动反事实方法和人工评估评估了生成解释的质量。

Conclusion: 该研究为法律条文预测提供了两种带解释的方法，AoS使用小模型进行监督学习，LLMPrompt使用大模型进行零样本学习，两者都能生成可理解的解释，有助于提高法律AI系统的用户接受度。

Abstract: In this paper, we explore the problem of automatic statute prediction where for a given case description, a subset of relevant statutes are to be predicted. Here, the term "statute" refers to a section, a sub-section, or an article of any specific Act. Addressing this problem would be useful in several applications such as AI-assistant for lawyers and legal question answering system. For better user acceptance of such Legal AI systems, we believe the predictions should also be accompanied by human understandable explanations. We propose two techniques for addressing this problem of statute prediction with explanations -- (i) AoS (Attention-over-Sentences) which uses attention over sentences in a case description to predict statutes relevant for it and (ii) LLMPrompt which prompts an LLM to predict as well as explain relevance of a certain statute. AoS uses smaller language models, specifically sentence transformers and is trained in a supervised manner whereas LLMPrompt uses larger language models in a zero-shot manner and explores both standard as well as Chain-of-Thought (CoT) prompting techniques. Both these models produce explanations for their predictions in human understandable forms. We compare statute prediction performance of both the proposed techniques with each other as well as with a set of competent baselines, across two popular datasets. Also, we evaluate the quality of the generated explanations through an automated counter-factual manner as well as through human evaluation.

</details>


### [25] [Accelerate Speculative Decoding with Sparse Computation in Verification](https://arxiv.org/abs/2512.21911)
*Jikai Wang,Jianchao Tan,Yuxuan Hu,Jiayu Qin,Yerui Sun,Yuchen Xie,Xunliang Cai,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 提出稀疏验证框架，在推测解码的验证阶段联合稀疏化注意力、FFN和MoE组件，显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 推测解码通过并行验证多个草稿token加速自回归语言模型推理，但验证阶段在长上下文输入和MoE模型中成为主要计算瓶颈。现有稀疏化方法主要针对标准token-by-token自回归解码，未针对推测解码的验证阶段进行优化

Method: 系统地在推测解码的验证阶段采用不同稀疏方法，识别多维度结构化冗余，提出联合稀疏化注意力、FFN和MoE组件的稀疏验证框架，并引入跨草稿token和跨层检索重用策略进一步减少冗余计算

Result: 在摘要、问答和数学推理数据集上的广泛实验表明，该方法实现了有利的效率-准确性权衡，同时保持了稳定的接受长度

Conclusion: 提出的稀疏验证框架能有效减少推测解码验证阶段的计算瓶颈，为长上下文和MoE模型的高效推理提供了实用解决方案

Abstract: Speculative decoding accelerates autoregressive language model inference by verifying multiple draft tokens in parallel. However, the verification stage often becomes the dominant computational bottleneck, especially for long-context inputs and mixture-of-experts (MoE) models. Existing sparsification methods are designed primarily for standard token-by-token autoregressive decoding to remove substantial computational redundancy in LLMs. This work systematically adopts different sparse methods on the verification stage of the speculative decoding and identifies structured redundancy across multiple dimensions. Based on these observations, we propose a sparse verification framework that jointly sparsifies attention, FFN, and MoE components during the verification stage to reduce the dominant computation cost. The framework further incorporates an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without introducing additional training. Extensive experiments across summarization, question answering, and mathematical reasoning datasets demonstrate that the proposed methods achieve favorable efficiency-accuracy trade-offs, while maintaining stable acceptance length.

</details>


### [26] [SWE-RM: Execution-free Feedback For Software Engineering Agents](https://arxiv.org/abs/2512.21919)
*KaShun Shum,Binyuan Hui,Jiawei Chen,Lei Zhang,X. W.,Jiaxi Yang,Yuzhen Huang,Junyang Lin,Junxian He*

Main category: cs.CL

TL;DR: 该论文针对编码智能体开发中的反馈机制问题，提出了一种既适用于测试时扩展(TTS)又适用于强化学习(RL)的通用奖励模型SWE-RM，通过混合专家架构显著提升了软件工程智能体的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于执行的反馈（如单元测试）存在两个主要问题：1）需要可扩展且可靠的测试用例收集，2）反馈稀疏且无法有效区分都成功或都失败的轨迹。相比之下，基于奖励模型的执行无关反馈能提供更细粒度的信号，但这种方法在现实软件工程智能体中尚未得到充分探索。

Method: 作者首先发现两个在TTS性能相近的验证器在RL中可能表现迥异，因此识别出对RL训练至关重要的两个额外方面：分类准确性和校准。通过全面的控制实验，研究了训练数据规模、策略混合、数据源组成等因素对奖励模型性能的影响。基于这些研究，提出了SWE-RM奖励模型，采用混合专家架构，总参数量30B，推理时激活3B参数。

Result: SWE-RM显著提升了软件工程智能体在TTS和RL上的性能。在SWE-Bench Verified基准上，使用TTS将Qwen3-Coder-Flash的准确率从51.6%提升到62.0%，将Qwen3-Coder-Max从67.0%提升到74.6%，在开源模型中达到了新的最先进水平。

Conclusion: 该研究表明，通过考虑分类准确性和校准等关键因素，可以训练出既适用于TTS又适用于RL的稳健奖励模型。提出的SWE-RM模型通过混合专家架构有效提升了软件工程智能体的性能，为解决编码智能体开发中的反馈稀疏性问题提供了有效方案。

Abstract: Execution-based feedback like unit testing is widely used in the development of coding agents through test-time scaling (TTS) and reinforcement learning (RL). This paradigm requires scalable and reliable collection of unit test cases to provide accurate feedback, and the resulting feedback is often sparse and cannot effectively distinguish between trajectories that are both successful or both unsuccessful. In contrast, execution-free feedback from reward models can provide more fine-grained signals without depending on unit test cases. Despite this potential, execution-free feedback for realistic software engineering (SWE) agents remains underexplored. Aiming to develop versatile reward models that are effective across TTS and RL, however, we observe that two verifiers with nearly identical TTS performance can nevertheless yield very different results in RL. Intuitively, TTS primarily reflects the model's ability to select the best trajectory, but this ability does not necessarily generalize to RL. To address this limitation, we identify two additional aspects that are crucial for RL training: classification accuracy and calibration. We then conduct comprehensive controlled experiments to investigate how to train a robust reward model that performs well across these metrics. In particular, we analyze the impact of various factors such as training data scale, policy mixtures, and data source composition. Guided by these investigations, we introduce SWE-RM, an accurate and robust reward model adopting a mixture-of-experts architecture with 30B total parameters and 3B activated during inference. SWE-RM substantially improves SWE agents on both TTS and RL performance. For example, it increases the accuracy of Qwen3-Coder-Flash from 51.6% to 62.0%, and Qwen3-Coder-Max from 67.0% to 74.6% on SWE-Bench Verified using TTS, achieving new state-of-the-art performance among open-source models.

</details>


### [27] [Broken Words, Broken Performance: Effect of Tokenization on Performance of LLMs](https://arxiv.org/abs/2512.21933)
*Sachin Pawar,Manoj Apte,Kshitij Jadhav,Girish Keshav Palshikar,Nitin Ramrakhiyani*

Main category: cs.CL

TL;DR: 该论文研究了LLM分词对自然语言处理任务性能的影响，提出了一套量化分词惩罚的方法来评估分词质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型与传统NLP分词方式不同，会将自然单词拆分成多个token，作者假设这种分词方式会对LLM在各种NLP任务上的性能产生负面影响。

Method: 提出了一套惩罚函数，用于计算给定文本在特定LLM上的分词惩罚，量化分词质量的好坏程度。

Result: 在多个NLP任务和不同LLM上验证了分词惩罚假设的统计显著性。

Conclusion: LLM将自然单词拆分成多个token的分词方式确实对模型性能有负面影响，通过量化分词惩罚可以评估这种影响。

Abstract: Tokenization is the first step in training any Large Language Model (LLM), where the text is split into a sequence of tokens as per the model's fixed vocabulary. This tokenization in LLMs is different from the traditional tokenization in NLP where the text is split into a sequence of "natural" words. In LLMs, a natural word may also be broken into multiple tokens due to limited vocabulary size of the LLMs (e.g., Mistral's tokenizer splits "martial" into "mart" and "ial"). In this paper, we hypothesize that such breaking of natural words negatively impacts LLM performance on various NLP tasks. To quantify this effect, we propose a set of penalty functions that compute a tokenization penalty for a given text for a specific LLM, indicating how "bad" the tokenization is. We establish statistical significance of our hypothesis on multiple NLP tasks for a set of different LLMs.

</details>


### [28] [Self-attention vector output similarities reveal how machines pay attention](https://arxiv.org/abs/2512.21956)
*Tal Halevi,Yarden Tzach,Ronit D. Gross,Shalom Rosner,Ido Kanter*

Main category: cs.CL

TL;DR: 该研究提出了一种量化自注意力机制信息处理的新方法，通过在BERT-12架构上的分析，揭示了注意力机制在不同层和头中的语义处理模式，包括文本分割、语言特征识别和相似性分布演变。


<details>
  <summary>Details</summary>
Motivation: 虽然自注意力机制显著推动了自然语言处理的发展，但其具体的学习机制和量化表征仍然是一个开放的研究问题。研究者希望理解自注意力如何实现高级学习，并定量描述这一学习过程。

Method: 引入了一种量化自注意力机制信息处理的新方法，在BERT-12架构上进行分析。通过分析注意力图、构建上下文相似性矩阵（基于注意力头产生的向量空间的标量积），研究不同层和头中token向量的相似性分布。

Result: 1. 在最后几层，注意力图聚焦于句子分隔符token，这为基于语义特征的文本分割提供了实用方法。
2. 同一注意力块中的不同注意力头关注不同的语言特征，如识别文本中的token重复或识别常见token及其上下文。
3. 注意力层从初始的长距离相似性逐渐演变为短距离相似性，最终在同一句子内形成强相似性。
4. 每个注意力头倾向于关注文本中的独特token，并围绕该token构建相似性对。

Conclusion: 自注意力机制在BERT架构中表现出层次化的语义处理模式，不同注意力头专门化处理不同的语言特征，并且随着网络深度的增加，注意力从长距离依赖转向局部句子结构。这种量化分析方法为理解自注意力机制的工作原理提供了新的视角。

Abstract: The self-attention mechanism has significantly advanced the field of natural language processing, facilitating the development of advanced language-learning machines. Although its utility is widely acknowledged, the precise mechanisms of self-attention underlying its advanced learning and the quantitative characterization of this learning process remains an open research question. This study introduces a new approach for quantifying information processing within the self-attention mechanism. The analysis conducted on the BERT-12 architecture reveals that, in the final layers, the attention map focuses on sentence separator tokens, suggesting a practical approach to text segmentation based on semantic features. Based on the vector space emerging from the self-attention heads, a context similarity matrix, measuring the scalar product between two token vectors was derived, revealing distinct similarities between different token vector pairs within each head and layer. The findings demonstrated that different attention heads within an attention block focused on different linguistic characteristics, such as identifying token repetitions in a given text or recognizing a token of common appearance in the text and its surrounding context. This specialization is also reflected in the distribution of distances between token vectors with high similarity as the architecture progresses. The initial attention layers exhibit substantially long-range similarities; however, as the layers progress, a more short-range similarity develops, culminating in a preference for attention heads to create strong similarities within the same sentence. Finally, the behavior of individual heads was analyzed by examining the uniqueness of their most common tokens in their high similarity elements. Each head tends to focus on a unique token from the text and builds similarity pairs centered around it.

</details>


### [29] [Context as a Tool: Context Management for Long-Horizon SWE-Agents](https://arxiv.org/abs/2512.22087)
*Shukai Liu,Jian Yang,Bo Jiang,Yizhi Li,Jinyang Guo,Xianglong Liu,Bryan Dai*

Main category: cs.CL

TL;DR: CAT是一种新的上下文管理范式，将上下文维护提升为可调用的工具，帮助语言模型代理在软件工程任务中实现稳定、可扩展的长时程推理。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型代理在处理仓库级代码库的长时程交互任务时，通常采用仅追加式上下文维护或被动触发的压缩启发式方法，这会导致上下文爆炸、语义漂移和推理能力下降。

Method: 提出CAT上下文管理范式，构建结构化上下文工作空间（稳定任务语义、压缩的长期记忆、高保真短期交互），使代理能在适当时机主动将历史轨迹压缩为可操作的摘要。通过CAT-GENERATOR框架训练上下文感知模型SWE-Compressor。

Result: 在SWE-Bench-Verified上，SWE-Compressor达到57.6%的解决率，显著优于基于ReAct的代理和静态压缩基线，同时在有限上下文预算下保持稳定且可扩展的长时程推理能力。

Conclusion: CAT通过将上下文管理作为可调用工具集成到代理决策过程中，有效解决了长时程软件工程任务中的上下文管理问题，提升了代理的效率和稳定性。

Abstract: Agents based on large language models have recently shown strong potential on real-world software engineering (SWE) tasks that require long-horizon interaction with repository-scale codebases. However, most existing agents rely on append-only context maintenance or passively triggered compression heuristics, which often lead to context explosion, semantic drift, and degraded reasoning in long-running interactions. We propose CAT, a new context management paradigm that elevates context maintenance to a callable tool integrated into the decision-making process of agents. CAT formalizes a structured context workspace consisting of stable task semantics, condensed long-term memory, and high-fidelity short-term interactions, and enables agents to proactively compress historical trajectories into actionable summaries at appropriate milestones. To support context management for SWE-agents, we propose a trajectory-level supervision framework, CAT-GENERATOR, based on an offline data construction pipeline that injects context-management actions into complete interaction trajectories. Using this framework, we train a context-aware model, SWE-Compressor. Experiments on SWE-Bench-Verified demonstrate that SWE-Compressor reaches a 57.6% solved rate and significantly outperforms ReAct-based agents and static compression baselines, while maintaining stable and scalable long-horizon reasoning under a bounded context budget.

</details>


### [30] [Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis](https://arxiv.org/abs/2512.22100)
*Duygu Altinok*

Main category: cs.CL

TL;DR: TrGLUE是首个土耳其语自然语言理解综合基准测试，包含SentiTurca情感分析专用基准，旨在填补土耳其语缺乏类似GLUE基准的空白。


<details>
  <summary>Details</summary>
Motivation: 虽然英语有GLUE基准，中文有CLUE，法语有FLUE，日语有JGLUE，但土耳其语一直缺乏类似的综合性NLU评估基准，这阻碍了对土耳其语模型能力的全面评估。

Method: 创建土耳其本土语料库，采用半自动化标注流程：结合强大的LLM基础标注、跨模型一致性检查和后续人工验证，优先考虑语言自然性，减少翻译痕迹。

Result: 推出了TrGLUE基准测试和SentiTurca情感分析基准，提供基于Transformer模型的微调和评估代码，建立了可扩展、可复现的工作流程。

Conclusion: TrGLUE为土耳其语NLU建立了稳健的评估框架，为研究人员提供了宝贵资源，并为生成高质量半自动化数据集提供了见解。

Abstract: Evaluating the performance of various model architectures, such as transformers, large language models (LLMs), and other NLP systems, requires comprehensive benchmarks that measure performance across multiple dimensions. Among these, the evaluation of natural language understanding (NLU) is particularly critical as it serves as a fundamental criterion for assessing model capabilities. Thus, it is essential to establish benchmarks that enable thorough evaluation and analysis of NLU abilities from diverse perspectives. While the GLUE benchmark has set a standard for evaluating English NLU, similar benchmarks have been developed for other languages, such as CLUE for Chinese, FLUE for French, and JGLUE for Japanese. However, no comparable benchmark currently exists for the Turkish language. To address this gap, we introduce TrGLUE, a comprehensive benchmark encompassing a variety of NLU tasks for Turkish. In addition, we present SentiTurca, a specialized benchmark for sentiment analysis. To support researchers, we also provide fine-tuning and evaluation code for transformer-based models, facilitating the effective use of these benchmarks. TrGLUE comprises Turkish-native corpora curated to mirror the domains and task formulations of GLUE-style evaluations, with labels obtained through a semi-automated pipeline that combines strong LLM-based annotation, cross-model agreement checks, and subsequent human validation. This design prioritizes linguistic naturalness, minimizes direct translation artifacts, and yields a scalable, reproducible workflow. With TrGLUE, our goal is to establish a robust evaluation framework for Turkish NLU, empower researchers with valuable resources, and provide insights into generating high-quality semi-automated datasets.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [31] [Selective LLM-Guided Regularization for Enhancing Recommendation Models](https://arxiv.org/abs/2512.21526)
*Shanglin Yang,Zhan Shi*

Main category: cs.IR

TL;DR: 提出选择性LLM引导正则化框架，通过可训练门控机制仅在LLM预测可靠时激活基于LLM的成对排序监督，实现高效知识迁移，提升推荐准确性特别是在冷启动和长尾场景。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推荐方法存在明显缺陷：独立LLM推荐器成本高、有偏见且在用户-物品空间的大部分区域不可靠；全局知识蒸馏强迫下游模型模仿LLM预测，即使这种指导不准确。同时研究发现LLM在重排序和挑战性场景中表现优异，而非在所有情境下都有效。

Method: 提出选择性LLM引导正则化框架：1）基于用户历史长度、物品流行度和模型不确定性的可训练门控机制预测LLM可靠性；2）仅在LLM可靠时激活基于LLM的成对排序监督；3）所有LLM评分离线进行，知识迁移不增加推理成本。

Result: 在多个数据集上的实验表明，该选择性策略持续提升整体准确性，在冷启动和长尾场景中获得显著增益，优于全局蒸馏基线方法。

Conclusion: 选择性激活LLM监督的框架能够有效利用LLM的优势（特别是在挑战性场景），同时避免其不可靠预测带来的负面影响，实现了计算高效且模型无关的LLM知识迁移，显著提升了推荐系统性能。

Abstract: Large language models provide rich semantic priors and strong reasoning capabilities, making them promising auxiliary signals for recommendation. However, prevailing approaches either deploy LLMs as standalone recommender or apply global knowledge distillation, both of which suffer from inherent drawbacks. Standalone LLM recommender are costly, biased, and unreliable across large regions of the user item space, while global distillation forces the downstream model to imitate LLM predictions even when such guidance is inaccurate. Meanwhile, recent studies show that LLMs excel particularly in re-ranking and challenging scenarios, rather than uniformly across all contexts.We introduce Selective LLM Guided Regularization, a model-agnostic and computation efficient framework that activates LLM based pairwise ranking supervision only when a trainable gating mechanism informing by user history length, item popularity, and model uncertainty predicts the LLM to be reliable. All LLM scoring is performed offline, transferring knowledge without increasing inference cost. Experiments across multiple datasets show that this selective strategy consistently improves overall accuracy and yields substantial gains in cold start and long tail regimes, outperforming global distillation baselines.

</details>


### [32] [CEMG: Collaborative-Enhanced Multimodal Generative Recommendation](https://arxiv.org/abs/2512.21543)
*Yuzhen Lin,Hongyi Chen,Xuanjing Chen,Shaowen Wang,Ivonne Xu,Dongming Jiang*

Main category: cs.IR

TL;DR: CEMG是一个通过协作信号增强的多模态融合生成推荐框架，采用RQ-VAE离散化语义编码，使用LLM进行端到端生成推荐，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成推荐模型存在两个关键问题：1) 协作信号的浅层集成；2) 多模态特征的解耦融合。这些问题阻碍了真正全面的物品表示。

Method: 提出CEMG框架：1) 多模态融合层在协作信号指导下动态整合视觉和文本特征；2) 统一模态标记化阶段使用残差量化VAE将融合表示转换为离散语义代码；3) 端到端生成推荐阶段微调大语言模型自回归生成这些物品代码。

Result: 大量实验表明，CEMG在推荐性能上显著优于最先进的基线方法。

Conclusion: CEMG通过协作信号增强的多模态融合和离散语义编码，成功解决了生成推荐中的关键挑战，实现了更全面和有效的物品表示。

Abstract: Generative recommendation models often struggle with two key challenges: (1) the superficial integration of collaborative signals, and (2) the decoupled fusion of multimodal features. These limitations hinder the creation of a truly holistic item representation. To overcome this, we propose CEMG, a novel Collaborative-Enhaned Multimodal Generative Recommendation framework. Our approach features a Multimodal Fusion Layer that dynamically integrates visual and textual features under the guidance of collaborative signals. Subsequently, a Unified Modality Tokenization stage employs a Residual Quantization VAE (RQ-VAE) to convert this fused representation into discrete semantic codes. Finally, in the End-to-End Generative Recommendation stage, a large language model is fine-tuned to autoregressively generate these item codes. Extensive experiments demonstrate that CEMG significantly outperforms state-of-the-art baselines.

</details>


### [33] [LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model](https://arxiv.org/abs/2512.21595)
*Yinfu Feng,Yanjing Wu,Rong Xiao,Xiaoyi Zen*

Main category: cs.IR

TL;DR: LLM-I2I：利用大语言模型解决I2I推荐系统中数据稀疏性和噪声问题的数据中心化框架，显著提升推荐准确性，特别是在长尾商品上。


<details>
  <summary>Details</summary>
Motivation: 当前I2I推荐系统的改进存在两个方向：模型中心化方法（增加架构复杂度但提升计算成本和部署难度）和数据集中心化方法（成本低但受限于数据稀疏性和噪声问题）。需要一种既能提升性能又保持部署简便性的解决方案。

Method: 提出LLM-I2I框架，包含两个核心组件：1）基于LLM的生成器，为长尾商品合成用户-物品交互数据以缓解数据稀疏性；2）基于LLM的判别器，从真实和合成数据中过滤噪声交互。精炼后的数据用于训练现有I2I模型。

Result: 在行业（AEDS）和学术（ARD）数据集上评估，LLM-I2I持续提升推荐准确性，特别对长尾商品效果显著。在大型跨境电商平台部署后，召回数提升6.02%，商品交易总额提升1.22%。

Conclusion: 这项工作展示了LLMs在不修改模型架构的情况下增强数据中心化推荐系统的潜力，为I2I推荐系统提供了一种高效、可扩展的改进方案。

Abstract: Item-to-Item (I2I) recommendation models are widely used in real-world systems due to their scalability, real-time capabilities, and high recommendation quality. Research to enhance I2I performance focuses on two directions: 1) model-centric approaches, which adopt deeper architectures but risk increased computational costs and deployment complexity, and 2) data-centric methods, which refine training data without altering models, offering cost-effectiveness but struggling with data sparsity and noise. To address these challenges, we propose LLM-I2I, a data-centric framework leveraging Large Language Models (LLMs) to mitigate data quality issues. LLM-I2I includes (1) an LLM-based generator that synthesizes user-item interactions for long-tail items, alleviating data sparsity, and (2) an LLM-based discriminator that filters noisy interactions from real and synthetic data. The refined data is then fused to train I2I models. Evaluated on industry (AEDS) and academic (ARD) datasets, LLM-I2I consistently improves recommendation accuracy, particularly for long-tail items. Deployed on a large-scale cross-border e-commerce platform, it boosts recall number (RN) by 6.02% and gross merchandise value (GMV) by 1.22% over existing I2I models. This work highlights the potential of LLMs in enhancing data-centric recommendation systems without modifying model architectures.

</details>


### [34] [KG20C & KG20C-QA: Scholarly Knowledge Graph Benchmarks for Link Prediction and Question Answering](https://arxiv.org/abs/2512.21799)
*Hung-Nghiep Tran,Atsuhiro Takasu*

Main category: cs.IR

TL;DR: KG20C和KG20C-QA是两个用于学术数据问答研究的精选数据集，包括高质量学术知识图谱和对应的问答基准


<details>
  <summary>Details</summary>
Motivation: 需要为学术领域的问答研究提供高质量、可重复使用的数据集资源，支持知识图谱和文本模型的研究

Method: 从Microsoft Academic Graph中通过场地选择、质量过滤和模式定义构建KG20C知识图谱，然后基于此定义问答模板生成KG20C-QA数据集

Result: 创建了正式文档化的KG20C和KG20C-QA数据集，对标准知识图谱嵌入方法进行了基准测试，提供了可重复的评估协议

Conclusion: 这些数据集为研究社区提供了可重用、可扩展的资源，将促进学术领域的问答、推理和知识驱动应用研究

Abstract: In this paper, we present KG20C and KG20C-QA, two curated datasets for advancing question answering (QA) research on scholarly data. KG20C is a high-quality scholarly knowledge graph constructed from the Microsoft Academic Graph through targeted selection of venues, quality-based filtering, and schema definition. Although KG20C has been available online in non-peer-reviewed sources such as GitHub repository, this paper provides the first formal, peer-reviewed description of the dataset, including clear documentation of its construction and specifications. KG20C-QA is built upon KG20C to support QA tasks on scholarly data. We define a set of QA templates that convert graph triples into natural language question--answer pairs, producing a benchmark that can be used both with graph-based models such as knowledge graph embeddings and with text-based models such as large language models. We benchmark standard knowledge graph embedding methods on KG20C-QA, analyze performance across relation types, and provide reproducible evaluation protocols. By officially releasing these datasets with thorough documentation, we aim to contribute a reusable, extensible resource for the research community, enabling future work in QA, reasoning, and knowledge-driven applications in the scholarly domain. The full datasets will be released at https://github.com/tranhungnghiep/KG20C/ upon paper publication.

</details>


### [35] [Frozen LVLMs for Micro-Video Recommendation: A Systematic Study of Feature Extraction and Fusion](https://arxiv.org/abs/2512.21863)
*Huatuan Sun,Yunshan Ma,Changguang Wu,Yanxin Zhang,Pengfei Wang,Xiaoyu Du*

Main category: cs.IR

TL;DR: 该论文首次系统性地研究了在微视频推荐中如何整合冻结大型视频语言模型，提出了双重特征融合框架，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前在微视频推荐中，冻结的大型视频语言模型被用作固定的黑盒特征提取器，但缺乏对不同整合策略的系统性评估。需要研究如何最佳地利用这些模型与ID嵌入进行结合。

Method: 系统研究了两个关键设计维度：1) 与ID嵌入的整合策略（替换vs融合）；2) 特征提取范式（LVLM生成的标题vs中间解码器隐藏状态）。基于研究结果提出了双重特征融合框架，自适应地融合多层表示与ID嵌入。

Result: 实验发现三个关键原则：1) 中间隐藏状态优于基于标题的表示；2) ID嵌入捕捉了不可替代的协同信号，融合策略优于替换；3) 中间解码器特征在不同层间效果差异显著。DFF框架在两个真实世界微视频推荐基准上实现了最先进的性能。

Conclusion: 该研究为在微视频推荐系统中整合现成的大型视觉语言模型提供了原则性方法，表明中间层特征与ID嵌入的融合策略是最有效的整合方式。

Abstract: Frozen Large Video Language Models (LVLMs) are increasingly employed in micro-video recommendation due to their strong multimodal understanding. However, their integration lacks systematic empirical evaluation: practitioners typically deploy LVLMs as fixed black-box feature extractors without systematically comparing alternative representation strategies. To address this gap, we present the first systematic empirical study along two key design dimensions: (i) integration strategies with ID embeddings, specifically replacement versus fusion, and (ii) feature extraction paradigms, comparing LVLM-generated captions with intermediate decoder hidden states. Extensive experiments on representative LVLMs reveal three key principles: (1) intermediate hidden states consistently outperform caption-based representations, as natural-language summarization inevitably discards fine-grained visual semantics crucial for recommendation; (2) ID embeddings capture irreplaceable collaborative signals, rendering fusion strictly superior to replacement; and (3) the effectiveness of intermediate decoder features varies significantly across layers. Guided by these insights, we propose the Dual Feature Fusion (DFF) Framework, a lightweight and plug-and-play approach that adaptively fuses multi-layer representations from frozen LVLMs with item ID embeddings. DFF achieves state-of-the-art performance on two real-world micro-video recommendation benchmarks, consistently outperforming strong baselines and providing a principled approach to integrating off-the-shelf large vision-language models into micro-video recommender systems.

</details>
