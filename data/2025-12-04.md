<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.IR](#cs.IR) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models](https://arxiv.org/abs/2512.03047)
*Samih Fadli*

Main category: cs.CL

TL;DR: 提出基于伦理熵框架的LLM安全动态监测方法，通过行为分类器量化伦理熵变化，实现运行时对齐漂移预警


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全评估主要依赖静态基准，但关键失效模式是动态的：分布漂移下的价值观漂移、越狱攻击、部署中对齐缓慢退化。需要动态监测方法来捕捉这些实时变化

Method: 基于"智能第二定律"的伦理熵框架，定义五类行为分类，训练分类器从模型转录中估计伦理熵S(t)，在四个前沿模型的基座和指令调优变体上进行压力测试，测量熵动态变化

Result: 基座模型显示持续的熵增长，而调优变体抑制了漂移并将伦理熵降低约80%。从这些轨迹中估计出有效对齐工作率gamma_eff，并将S(t)和gamma_eff嵌入监控管道，当熵漂移超过稳定性阈值时发出警报

Conclusion: 提出的伦理熵框架为LLM安全提供了动态监测工具，能够实现运行时价值观漂移监督，弥补了静态基准的不足，为实际部署中的对齐稳定性提供了量化评估方法

Abstract: Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.

</details>


### [2] [Watermarks for Embeddings-as-a-Service Large Language Models](https://arxiv.org/abs/2512.03079)
*Anudeex Shetty*

Main category: cs.CL

TL;DR: 该论文研究EaaS水印技术，发现现有水印易受改写攻击，并提出新的WET水印方案来防御模仿攻击。


<details>
  <summary>Details</summary>
Motivation: 随着企业提供嵌入即服务(EaaS)，模型知识产权保护变得重要。现有EaaS水印技术存在漏洞，需要更强大的防御机制来对抗模仿攻击。

Method: 首先分析现有EaaS水印对改写攻击的脆弱性，然后提出WET水印技术，使用线性变换嵌入，通过反向变换和相似度比较进行验证。

Result: 发现改写攻击能有效绕过现有EaaS水印，而提出的WET方案对改写攻击具有鲁棒性，验证准确率接近完美。

Conclusion: 现有EaaS水印存在安全漏洞，WET水印技术提供了更可靠的模型知识产权保护方案，能有效防御模仿攻击。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques.
  Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques.
  Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.

</details>


### [3] [AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation](https://arxiv.org/abs/2512.03737)
*Chuyue Wang,Jie Feng,Yuxi Wu,Hang Zhang,Zhiguo Fan,Bing Cheng,Wei Lin*

Main category: cs.CL

TL;DR: AR-Med是一个用于医疗搜索的自动化相关性评估框架，通过检索增强方法将LLM推理基于已验证的医疗知识，并通过知识蒸馏实现高效在线部署，显著提升了医疗搜索的准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 在线医疗平台的搜索准确性和可靠性对用户安全和服务效果至关重要。传统方法难以理解复杂细微的用户查询，而LLMs虽有潜力但面临事实幻觉、专业知识缺口和高运营成本等挑战。

Method: AR-Med采用检索增强方法将LLM推理基于已验证的医疗知识，设计实用的知识蒸馏方案将大型教师模型压缩为紧凑而强大的学生模型，并引入LocalQSMed多专家标注基准来指导模型迭代。

Result: AR-Med实现了超过93%的离线准确率，比原始在线系统提升了24%的绝对改进，并在在线相关性和用户满意度方面取得了显著提升。

Conclusion: 该工作为在现实世界医疗应用中开发可信赖的LLM驱动系统提供了实用且可扩展的蓝图，成功解决了医疗搜索中的准确性和可靠性问题。

Abstract: Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \textbf{AR-Med}, a novel framework for \textbf{A}utomated \textbf{R}elevance assessment for \textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\%, a 24\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.

</details>


### [4] [Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation](https://arxiv.org/abs/2512.03082)
*Nan Zhuang,Wenshuo Wang,Lekai Qian,Yuxiao Wang,Boyu Cao,Qi Liu*

Main category: cs.CL

TL;DR: 提出Reasoning Dependency Generation (RDG)框架，通过生成平衡的推理数据来减轻大语言模型中的选择支持性偏见，实验显示在记忆和评估任务上分别有81.5%和94.3%的改进。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大语言模型存在选择支持性偏见，会系统性地偏向自己选择的选项，这可能影响AI辅助决策的客观性。现有的去偏见方法主要针对人口统计和社会偏见，而针对认知偏见的方法尚未充分探索。

Method: 提出Reasoning Dependency Generation (RDG)框架，通过自动构建平衡的推理问答对来生成无偏见的推理数据，明确建模选择、证据和理由之间的依赖关系。该方法生成跨领域的大规模数据集，包含上下文依赖数据和依赖解耦数据。

Result: 实验表明，使用RDG生成数据进行微调的大语言模型在记忆实验中改进81.5%，在评估实验中改进94.3%，同时在标准BBQ基准测试中保持相似性能。

Conclusion: 这项工作是解决大语言模型中认知偏见的开创性方法，有助于开发更可靠的AI辅助决策支持系统。

Abstract: Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.

</details>


### [5] [Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies](https://arxiv.org/abs/2512.03195)
*Stylianos Saroglou,Konstantinos Diamantaras,Francesco Preta,Marina Delianidi,Apostolos Benisis,Christian Johannes Meyer*

Main category: cs.CL

TL;DR: 开发开源工具连接职位空缺文本与ESCO和EQF框架，比较句子链接和实体链接方法，并引入标注数据集评估生成式大语言模型在劳动力市场分类中的应用。


<details>
  <summary>Details</summary>
Motivation: 当前劳动力市场信息分类需要更精确地将职位空缺文本与欧洲技能和资格框架（ESCO和EQF）连接起来，以超越表面技能提取，深入理解职业和资格在文本中的表示方式。

Method: 比较句子链接和实体链接两种主要方法，开发开源工具整合这两种方法，创建专门标注的数据集用于评估，并探索生成式大语言模型在此任务中的应用方式。

Result: 发布了开源工具和两个标注数据集，为劳动力分类和就业话语研究提供计算基础设施，推进了职位实体提取的技术水平，支持数字中介经济中的工作、技能和劳动力市场叙事分析。

Conclusion: 该研究通过开发开源工具和标注数据集，显著提升了将职位空缺文本与ESCO和EQF框架连接的能力，为劳动力市场信息分类和数字经济的劳动力分析提供了重要基础设施。

Abstract: This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier

</details>


### [6] [InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation](https://arxiv.org/abs/2512.03197)
*Faezeh Faez,Marzieh S. Tahaei,Yaochen Hu,Ali Pourranjbar,Mahdi Biparva,Mark Coates,Yingxue Zhang*

Main category: cs.CL

TL;DR: InvertiTune：通过可控数据生成和微调的框架，实现单次推理的知识图谱构建，超越现有方法并具有更好的跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的Text2KG方法依赖迭代式提示，计算成本高且容易忽略文本中分布的复杂关系，需要更高效、准确的解决方案。

Method: 提出InvertiTune框架：1）从大型知识库系统提取子图并过滤噪声；2）利用LLM生成对应的自然文本描述；3）用生成的数据集对轻量模型进行监督微调，实现单次推理的KG构建。

Result: 在CE12k数据集上，InvertiTune超越更大的非微调LLM和最先进的Text2KG方法，在CrossEval-1200测试集上展现出更强的跨数据集泛化能力。

Conclusion: 高质量、真实的训练数据对于推进高效、高性能的Text2KG系统至关重要，InvertiTune框架为此提供了有效解决方案。

Abstract: Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.

</details>


### [7] [Identifying attributions of causality in political text](https://arxiv.org/abs/2512.03214)
*Paulina Garcia-Corral*

Main category: cs.CL

TL;DR: 开发了一个用于从政治文本中检测和解析解释的框架，使用轻量级因果语言模型提取因果对，实现大规模分析


<details>
  <summary>Details</summary>
Motivation: 解释在政治理解中至关重要，但政治科学中缺乏系统分析方法，现有方法零散且问题特定

Method: 训练轻量级因果语言模型，从政治文本中提取结构化因果对数据集，用于下游分析

Result: 方法能够大规模研究因果解释，展示适度的标注需求、良好的泛化能力和相对于人工编码的准确性

Conclusion: 提出的框架为政治科学中系统分析解释提供了可行工具，填补了现有研究空白

Abstract: Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.

</details>


### [8] [Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs](https://arxiv.org/abs/2512.03310)
*Kunj Joshi,David A. Smith*

Main category: cs.CL

TL;DR: RMFT是一种新的隐私保护微调技术，通过随机掩码减少LLMs中的PII记忆，在Enron数据集上实现80%以上的提取率降低，同时性能影响最小。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs存在严重的安全和隐私风险，模型倾向于记忆训练数据中的个人身份信息(PIIs)，这需要有效的隐私保护技术。

Method: 提出随机掩码微调(RMFT)技术，并引入MaxTER评估框架来评估隐私-效用权衡，使用AURC指标比较RMFT与去重方法。

Result: 在Enron邮件数据集上，RMFT相比基线微调实现了80.81%的总提取率降低和80.17%的已见提取率降低，仅增加5.73%的困惑度，优于去重方法。

Conclusion: RMFT是一种有效的隐私保护微调方法，能在最小化性能影响的同时显著减少PII记忆，为LLMs的隐私保护提供了实用解决方案。

Abstract: The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.

</details>


### [9] [Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní](https://arxiv.org/abs/2512.03334)
*Nemika Tyagi,Nelvin Licona Guevara,Olga Kellert*

Main category: cs.CL

TL;DR: LLM辅助的注释管道用于分析西班牙语-英语和西班牙语-瓜拉尼语双语语料，自动标注话题、体裁和语用功能，揭示社会语言学模式。


<details>
  <summary>Details</summary>
Motivation: 传统的社会语言学分析依赖人工标注，耗时且难以扩展到大规模语料库。研究旨在探索LLM能否可靠地恢复传统上只能通过人工标注获得的可解释社会语言学模式，推动跨语言和低资源双语研究的计算方法。

Method: 使用大语言模型自动标注话题、体裁和语用功能，分析3,691个语码转换句子，整合迈阿密双语语料库的人口统计元数据，并为西班牙语-瓜拉尼语数据集添加新的话题标注。

Result: 在迈阿密数据中发现了性别、语言优势和语用功能之间的系统联系；在巴拉圭文本中观察到正式瓜拉尼语和非正式西班牙语之间的明显双言制划分。这些发现以语料库规模的定量证据复制和扩展了早期的互动和社会语言学观察。

Conclusion: 大语言模型能够可靠地恢复传统上只能通过人工标注获得的可解释社会语言学模式，这推进了跨语言和低资源双语研究的计算方法。

Abstract: This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.

</details>


### [10] [PERCS: Persona-Guided Controllable Biomedical Summarization Dataset](https://arxiv.org/abs/2512.03340)
*Rohan Charudatt Salvi,Chirag Chawla,Dhruv Jain,Swapnil Panigrahi,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: PERCS数据集：包含针对四种不同医学素养水平用户（普通大众、医学生、非医学研究人员、医学专家）量身定制的生物医学摘要总结，支持个性化可控摘要生成研究。


<details>
  <summary>Details</summary>
Motivation: 现有医学文本简化资源通常假设单一通用受众，忽视了不同用户群体在医学素养和信息需求上的巨大差异，需要针对特定受众的个性化摘要生成方法。

Method: 创建PERCS数据集，包含生物医学摘要及其针对四种不同用户群体的总结：普通大众、医学生、非医学研究人员、医学专家。所有总结由医生根据详细的错误分类法进行事实准确性和用户群体匹配度审查。

Result: 技术验证显示不同用户群体的总结在可读性、词汇使用和内容深度上存在明显差异。使用自动评估指标对四种大语言模型进行基准测试，评估全面性、可读性和忠实度，为未来研究建立基线结果。

Conclusion: PERCS数据集支持个性化医学沟通和可控生物医学摘要生成研究，公开提供数据集、标注指南和评估材料，有助于开发针对不同医学素养水平用户的定制化医学信息传播系统。

Abstract: Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.

</details>


### [11] [Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning](https://arxiv.org/abs/2512.03343)
*Darshan Fofadiya*

Main category: cs.CL

TL;DR: 提出Idea-Gated Transformer架构，通过分离语义规划和语法生成来解决自回归语言模型中的"主题漂移"问题，使用概念向量实时门控词汇选择以保持主题一致性。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型在下一词预测训练中容易出现"主题漂移"问题，生成内容会偏离初始提示，主要依赖局部关联而非全局规划。虽然增大模型规模可以缓解，但NTP目标的根本短视性仍然存在。

Method: 引入Idea-Gated Transformer架构，分离语义规划和语法生成。添加辅助的"Idea Head"来预测未来上下文窗口的词袋分布，生成潜在"概念向量"，在生成过程中主动门控主词汇选择。提出可微分门控机制，抑制语义不相关的标记，实时修剪搜索空间。

Result: 在WikiText-103上的实验表明，Idea-Gated模型在验证困惑度上与标准GPT-2基线相当，但表现出显著优越的领域保持能力。定性和定量分析显示，门控机制成功将生成锁定在特定语义簇（如金融、科学）中，并抵抗关联漂移。

Conclusion: Idea-Gated Transformer为更可控的语言建模提供了参数高效的路径，通过分离规划和生成，有效解决了主题漂移问题，同时保持语言生成质量。

Abstract: Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \citep{holtzman2019curious}. While scaling model size mitigates this \citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.

</details>


### [12] [From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation](https://arxiv.org/abs/2512.03360)
*Qingchuan Li,Mingyue Cheng,Zirui Liu,Daoyu Wang,Yuting Zeng,Tongxuan Liu*

Main category: cs.CL

TL;DR: HBLR框架通过置信感知符号翻译和假设驱动反向推理，结合反思机制提升逻辑推理的准确性和效率


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要依赖前向推理范式，存在推理路径冗余、幻觉步骤和语义漂移等问题，导致推理效率低且不可靠

Method: 提出假设驱动反向逻辑推理框架，包含两个阶段：1) 置信感知符号翻译，仅将高置信度文本转为逻辑形式，保留不确定内容为自然语言；2) 假设驱动反向推理，模拟人类演绎思维，假设结论为真并递归验证前提，两个阶段均配备反思模块确保语义保真和逻辑连贯

Result: 在五个推理基准测试上的广泛实验表明，HBLR在准确性和效率方面均持续优于强基线方法

Conclusion: HBLR框架通过结合符号翻译和反向推理，有效解决了前向推理的局限性，为逻辑推理任务提供了更可靠和高效的解决方案

Abstract: Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.

</details>


### [13] [Nexus: Higher-Order Attention Mechanisms in Transformers](https://arxiv.org/abs/2512.03377)
*Hanting Chen,Chu Zhong,Kai Han,Yuchuan Tian,Yuchen Liang,Tianyu Guo,Xinghao Chen,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出了一种高阶注意力网络(Hon)，通过递归框架增强Transformer的表示能力，打破标准注意力的低秩瓶颈，在多个基准测试中优于标准Transformer。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer的一阶注意力机制存在低秩瓶颈问题，难以在单层中捕捉复杂的多跳关系，限制了模型的表示能力。

Method: 提出高阶注意力网络(Hon)，采用递归框架动态精炼查询和键向量。查询和键向量本身是内部注意力循环的输出，允许token在最终注意力计算前聚合全局上下文并建模高阶相关性。采用参数高效的权重共享策略，确保增强表达能力的同时只增加O(1)的额外参数。

Result: 理论分析表明该方法打破了标准注意力的线性瓶颈。实证结果显示，Hon在多个基准测试中优于标准Transformer。

Conclusion: 高阶注意力网络通过递归框架有效增强了Transformer的表示能力，解决了标准注意力的低秩瓶颈问题，在保持参数效率的同时提升了模型性能。

Abstract: Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the \textbf{Higher-Order Attention Network (Hon)}, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Hon dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Hon outperforms standard Transformers on multiple benchmarks.

</details>


### [14] [Characterizing Language Use in a Collaborative Situated Game](https://arxiv.org/abs/2512.03381)
*Nicholas Tomlin,Naitian Zhou,Eve Fleisig,Liangyuan,Chen,Téa Wright,Lauren Vinh,Laura X. Ma,Seun Eisape,Ellie French,Tingting Du,Tianjiao Zhang,Alexander Koller,Alane Suhr*

Main category: cs.CL

TL;DR: 收集了11.5小时的Portal 2合作模式对话语料库，包含24.5K话语，用于分析复杂协作环境中的语言现象


<details>
  <summary>Details</summary>
Motivation: 合作视频游戏中的语言数据包含丰富的协调、沟通和不确定性推理，但现有闲聊或任务导向对话语料库很少包含这些复杂现象

Method: 收集Portal 2合作模式中的11.5小时人类口语对话，包含玩家视频、音频、转录、游戏状态数据，并提供手动和自动语言标注

Result: 识别出复杂空间指代、澄清与修复、临时约定形成等罕见语言现象，公开发布包含多模态数据的语料库

Conclusion: Portal对话语料库为分析复杂、情境化、协作问题解决场景中的语言使用提供了宝贵资源，支持未来研究

Abstract: Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.

</details>


### [15] [Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates](https://arxiv.org/abs/2512.03402)
*Yixing Xu,Chao Li,Xuanwu Yin,Spandan Tiwari,Dong Li,Ashish Sirasao,Emad Barsoum*

Main category: cs.CL

TL;DR: Dual LoRA：通过将低秩矩阵分为幅度组和方向组，并分别应用ReLU和符号函数，改进LoRA性能，在多个NLP任务上优于原始LoRA及其变体。


<details>
  <summary>Details</summary>
Motivation: LoRA作为参数高效微调方法虽然流行，但由于其低秩假设，训练出的模型性能往往不令人满意，需要改进。

Method: 提出Dual LoRA方法，将低秩矩阵分为两组：幅度组（控制是否更新参数及更新幅度）和方向组（决定参数更新方向），分别应用ReLU函数和符号函数，更好地模拟基于梯度优化算法的全微调参数更新过程。

Result: 在广泛的NLP任务（自然语言生成、理解、常识推理）上，使用GPT-2、RoBERTa、DeBERTa、LLaMA-1/2/3等基线模型进行实验，Dual LoRA在相同可训练参数数量下始终优于LoRA及其最先进的变体。

Conclusion: Dual LoRA通过引入归纳偏置，将低秩矩阵分解为幅度和方向组件，有效改进了LoRA的性能，为参数高效微调提供了更优的解决方案。

Abstract: Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.

</details>


### [16] [PretrainZero: Reinforcement Active Pretraining](https://arxiv.org/abs/2512.03442)
*Xingrun Xing,Zhiyuan Fan,Jie Lou,Guoqi Li,Jiajun Zhang,Debing Zhang*

Main category: cs.CL

TL;DR: PretrainZero是一个基于预训练语料的强化主动学习框架，通过主动识别信息内容、自我监督学习和验证扩展，将强化学习从领域特定的后训练扩展到通用预训练，显著提升基础模型的通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的大思考模型虽然在特定领域（如软件和数学）展现出专家级能力，但严重依赖可验证的奖励信号，限制了通用推理能力的扩展。需要打破对验证数据的依赖，实现更通用的推理能力。

Method: 提出PretrainZero框架，包含三个关键特性：1) 主动预训练：学习统一推理策略，主动从预训练语料中识别合理且信息丰富的内容；2) 自我监督学习：无需可验证标签、预训练奖励模型或监督微调，直接在通用语料上使用强化学习预训练推理器；3) 验证扩展：通过处理越来越难的掩码跨度来增强通用推理能力。

Result: 在强化预训练中，PretrainZero将Qwen3-4B-Base模型在MMLU-Pro、SuperGPQA和数学平均基准上的性能分别提升了8.43、5.96和10.60分。预训练模型还可作为下游RLVR任务的推理基础模型。

Conclusion: PretrainZero成功将强化学习从领域特定的后训练扩展到通用预训练，通过主动学习和自我监督的方式显著提升了基础模型的通用推理能力，为人工通用智能的发展提供了新方向。

Abstract: Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.

</details>


### [17] [A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention](https://arxiv.org/abs/2512.03494)
*Di Xiu,Hongyin Tang,Bolin Rong,Lizhi Yan,Jingang Wang,Yifan Lu,Xunliang Cai*

Main category: cs.CL

TL;DR: Top-k注意力机制在解码和训练阶段的有效性研究，通过保留与查询最相似的关键键来降低计算成本，同时保持或提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文建模中越来越普遍，但其推理计算成本已成为阻碍智能体和多模态应用发展的关键瓶颈。需要探索更高效的注意力机制来降低计算复杂度。

Method: 1. 验证精确Top-k解码的有效性，在解码阶段仅保留与查询相似度最高的关键键作为上下文窗口；2. 探索原生Top-k注意力训练策略，确保训练与推理的一致性；3. 研究近似Top-k算法精度对下游任务的影响；4. 从熵的角度提供理论解释。

Result: 1. Top-k解码在HELMET和LongBench v2等下游任务上达到或超越完整注意力的性能；2. 训练与推理一致的Top-k注意力策略能进一步释放Top-k解码潜力；3. 下游任务性能与近似算法精度正相关；4. Top-k注意力SFT模型在下游任务中表现出明显的熵减现象，验证了低熵状态更适合Top-k解码的假设。

Conclusion: Top-k注意力机制是降低大语言模型推理计算成本的有效方法，通过精确或近似的Top-k操作，结合训练与推理的一致性策略，可以在保持性能的同时显著降低计算复杂度，为长上下文应用提供实用解决方案。

Abstract: Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.

</details>


### [18] [Understanding LLM Reasoning for Abstractive Summarization](https://arxiv.org/abs/2512.03503)
*Haohan Yuan,Siu Cheung Hui,Haopeng Zhang*

Main category: cs.CL

TL;DR: LLMs在摘要生成中的推理能力效果有限，存在质量与忠实度的权衡，过度推理反而损害事实一致性


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在数学和代码生成等分析任务中表现出色，但其在抽象摘要生成中的效用被广泛假设但未经验证，需要系统研究推理策略对摘要质量的影响

Method: 将通用推理策略适配到摘要领域，对8种推理策略和3个大型推理模型在8个多样化数据集上进行大规模比较研究，评估摘要质量和忠实度

Result: 推理并非通用解决方案，其效果高度依赖于具体策略和上下文；存在摘要质量与事实忠实度的权衡：显式推理策略倾向于提高流畅性但牺牲事实基础，而LRMs中的隐式推理则呈现相反模式；增加LRM的内部推理预算不会改善甚至会损害事实一致性

Conclusion: 有效的摘要生成需要忠实的压缩而非创造性的过度思考，推理在摘要任务中的效果具有情境依赖性

Abstract: While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.

</details>


### [19] [Fine-grained Narrative Classification in Biased News Articles](https://arxiv.org/abs/2512.03582)
*Zeba Afroz,Harsh Vardhan,Pawan Bhakuni,Aanchal Punia,Rajdeep Kumar,Md. Shad Akhtar*

Main category: cs.CL

TL;DR: 提出INDI-PROP数据集和FANTA/TPTC框架，用于印度新闻媒体中意识形态偏见的细粒度叙事分类和说服技巧识别


<details>
  <summary>Details</summary>
Motivation: 叙事是宣传的认知和情感支架，将孤立的说服技巧组织成连贯故事。需要开发细粒度叙事分类方法来分析印度新闻媒体中的宣传策略

Method: 1) 创建INDI-PROP数据集：包含1,266篇关于CAA和农民抗议的文章，进行三层标注（意识形态偏见、细粒度叙事框架、说服技巧）；2) 提出FANTA和TPTC两种GPT-4o-mini引导的多跳提示推理框架，分别通过信息提取+上下文框架和两阶段分解方法进行分类

Result: 评估显示FANTA和TPTC框架在偏见、叙事和说服技巧分类任务上相比基线方法有显著改进

Conclusion: 该研究提供了首个意识形态基础的细粒度叙事数据集和分析框架，能够有效识别新闻媒体中的宣传叙事和说服策略，为理解印度政治话语中的宣传机制提供了新工具

Abstract: Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.

</details>


### [20] [AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment](https://arxiv.org/abs/2512.03634)
*Ahmad Aghaebrahimian*

Main category: cs.CL

TL;DR: 提出一个可解释的事实一致性评估框架，通过将文本分解为原子事实并引入加权指标来改进现有评估方法，特别关注临床领域应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理任务中取得显著进展，但容易生成错误或误导性但看似合理的论点（幻觉问题）。这在临床等高风险领域尤为严重，因为事实不准确可能带来严重后果。现有评估指标无法充分评估事实一致性且缺乏可解释性，使得诊断和缓解错误变得困难。

Method: 提出一个可解释的事实一致性评估框架，将文本分解为原子事实，引入灵活的无模式方法。与之前使用绝对指标的方法不同，本方法采用加权指标来增强事实评估。此外，还提出一种机制来控制复杂领域中的评估复杂度。

Result: 在流行的通用和临床数据集上进行了基准测试，并发布了代码以支持未来研究中事实感知模型的训练。

Conclusion: 该框架解决了现有事实一致性评估方法的局限性，通过可解释的加权评估和复杂度控制机制，为高风险领域（特别是临床应用）提供了更好的事实一致性评估工具。

Abstract: Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.

</details>


### [21] [Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context](https://arxiv.org/abs/2512.03671)
*Beatrice Savoldi,Giuseppe Attanasio,Olga Gorodetskaya,Marta Marchiori Manerba,Elisa Bassignana,Silvia Casola,Matteo Negri,Tommaso Caselli,Luisa Bentivogli,Alan Ramponi,Arianna Muti,Nicoletta Balbo,Debora Nozza*

Main category: cs.CL

TL;DR: 意大利首次全面调查显示，生成式AI在工作和个人用途中广泛采用，正取代其他技术成为主要信息来源，但存在数字素养低、性别鸿沟等风险。


<details>
  <summary>Details</summary>
Motivation: 生成式AI聊天机器人正在改变数字互动，虽然具有社会潜力，但由于采用不均衡和对局限性认识不足，可能加剧数字鸿沟。需要了解意大利的采用模式、使用习惯和数字素养现状。

Method: 基于新收集的1,906名意大利语成年人的调查数据，进行首次全面的实证研究，绘制生成式AI采用、使用模式和素养的图谱。

Result: 1. 生成式AI在工作和个人用途中广泛采用，包括情感支持和医疗建议等敏感任务；2. 正取代其他技术成为主要信息来源，尽管用户数字素养低，难以识别错误信息；3. 存在显著性别鸿沟，女性采用率仅为男性一半，使用频率也更低，尤其在年长群体中更明显；4. 素养是采用的关键预测因素，但只能部分解释性别差异。

Conclusion: 需要有针对性的教育计划，并进一步调查素养无法完全解释的参与障碍，以确保生成式AI的公平参与。

Abstract: The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.

</details>


### [22] [Evaluating Hydro-Science and Engineering Knowledge of Large Language Models](https://arxiv.org/abs/2512.03672)
*Shiruo Hu,Wenbo Shan,Yingjia Li,Zhiqi Wan,Xinpeng Yu,Yunjia Qi,Haotian Xia,Yang Xiao,Dingxiao Liu,Jiaru Wang,Chenxu Gong,Ruixi Zhang,Shuyue Wu,Shibo Cui,Chee Hui Lai,Wei Luo,Yubin He,Bin Xu,Jianshi Zhao*

Main category: cs.CL

TL;DR: 该研究提出了Hydro-SE Bench评估基准，包含4000道选择题，用于评估大语言模型在水科学与工程领域的知识、应用和推理能力，发现商业LLMs表现较好但仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 水科学与工程是保障人类供水、清洁水电能源和防灾减灾的关键领域，需要多学科专家协作决策。随着大语言模型的快速发展，其在Hydro-SE领域的应用潜力日益受到关注，但模型在该领域的知识和应用能力尚未得到充分评估。

Method: 提出了Hydro-SE LLM评估基准（Hydro-SE Bench），包含4000道选择题，覆盖9个子领域，从基础概念知识、工程应用能力、推理计算能力三个维度评估LLMs。

Result: 评估结果显示：商业LLMs准确率在0.74-0.80之间，小参数LLMs在0.41-0.68之间。LLMs在与自然科学和物理科学密切相关的子领域表现良好，但在行业标准、水工结构等专业领域知识方面存在困难。模型规模扩展主要提升推理计算能力，但在实际工程应用问题处理方面仍有很大改进空间。

Conclusion: 本研究揭示了LLMs在Hydro-SE任务中的优势和不足，为模型开发者提供了明确的训练目标，为Hydro-SE研究人员提供了应用LLMs的实用指导。

Abstract: Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.

</details>


### [23] [Different types of syntactic agreement recruit the same units within large language models](https://arxiv.org/abs/2512.03676)
*Daria Kryvosheieva,Andrea de Varda,Evelina Fedorenko,Greta Tuckute*

Main category: cs.CL

TL;DR: 研究发现大语言模型中存在专门处理句法一致性的功能单元，这些单元在不同句法现象和语言中具有共享性，表明句法一致性构成LLMs表征空间中的有意义类别。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型能够可靠地区分语法正确和不正确的句子，但语法知识如何在模型内部表征仍是一个未解决的问题。研究者希望探究不同句法现象是否在LLMs中共享或使用不同的组件。

Method: 采用受认知神经科学启发的功能定位方法，识别七个开源模型中67个英语句法现象最响应的单元。通过跨语言分析（英语、俄语、中文）和57种语言的跨语言比较，验证这些单元的共享模式。

Result: 研究发现：1）不同句法一致性类型（如主谓一致、照应一致、限定词-名词一致）招募重叠的单元集合；2）这种模式在英语、俄语和中文中均成立；3）在57种语言的跨语言分析中，结构更相似的语言共享更多的主谓一致处理单元。

Conclusion: 句法一致性作为句法依赖关系的关键标记，在大语言模型的表征空间中构成了一个有意义的类别，揭示了LLMs中句法知识的组织方式。

Abstract: Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.

</details>


### [24] [AITutor-EvalKit: Exploring the Capabilities of AI Tutors](https://arxiv.org/abs/2512.03688)
*Numaan Naeem,Kaushal Kumar Maurya,Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: AITutor-EvalKit：一个使用语言技术评估AI导师教学质量的工具套件，包含演示、评估、模型检查和数据可视化功能。


<details>
  <summary>Details</summary>
Motivation: 需要评估AI导师的教学质量，为教育利益相关者和ACL社区提供支持学习和收集用户反馈的工具。

Method: 开发了一个应用，利用语言技术评估AI导师的教学质量，提供软件进行演示和评估，以及模型检查和数据可视化功能。

Result: 创建了AITutor-EvalKit工具套件，支持教育利益相关者和ACL社区评估AI导师、收集反馈和注释。

Conclusion: AITutor-EvalKit是一个有价值的工具，既能评估AI导师的教学质量，又能支持学习和用户反馈收集。

Abstract: We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.

</details>


### [25] [DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue](https://arxiv.org/abs/2512.03704)
*Yijun Liao*

Main category: cs.CL

TL;DR: DZ-TDPO是一个解决长对话中状态惯性问题的非破坏性对齐框架，通过动态KL约束和可学习时间注意力偏置，在保持模型通用能力的同时实现高效对话状态更新。


<details>
  <summary>Details</summary>
Motivation: 长对话系统存在"状态惯性"问题，静态约束导致模型无法解决用户意图演变与历史上下文之间的冲突，限制了对话系统的动态适应性。

Method: 提出DZ-TDPO框架，结合冲突感知的动态KL约束和可学习的时间注意力偏置，实现非破坏性的对齐，避免对模型权重进行破坏性更新。

Result: 在Multi-Session Chat数据集上达到SOTA胜率（Phi-3.5上86.2%），Qwen2.5-7B模型实现接近完美的对齐（99.4%胜率）且困惑度开销可忽略，同时保持MMLU等通用能力。

Conclusion: 通过精确的注意力调节而非破坏性权重更新可以有效缓解状态惯性问题，揭示了"容量-稳定性权衡"现象，为长对话系统的动态对齐提供了有效解决方案。

Abstract: Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a "Capacity-Stability Trade-off": while smaller models incur an "alignment tax" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO

</details>


### [26] [Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective](https://arxiv.org/abs/2512.03759)
*Jingyang Ou,Jiaqi Han,Minkai Xu,Shaoxuan Xu,Jianwen Xie,Stefano Ermon,Yi Wu,Chongxuan Li*

Main category: cs.CL

TL;DR: ESPO提出了一种基于ELBO的序列级策略优化框架，解决了扩散大语言模型中强化学习的核心挑战，通过将整个序列生成视为单个动作并使用ELBO作为序列级似然代理，显著提升了数学推理、编程和规划任务的性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自回归语言模型中效果显著，但应用于扩散大语言模型时存在根本性挑战。核心困难在于似然近似：自回归模型天然提供标记级条件概率，而扩散模型通过迭代非自回归去噪步骤生成序列，缺乏这种因子分解。

Method: 提出ELBO-based Sequence-level Policy Optimization (ESPO)，将整个序列生成视为单个动作，使用ELBO作为可处理的序列级似然代理。方法包含标记级重要性比率归一化和鲁棒的KL散度估计，确保大规模训练的稳定性。

Result: 在数学推理、编程和规划任务上的广泛实验表明，ESPO显著优于标记级基线方法，在Countdown任务上实现了20-40分的显著提升，同时在数学和编程基准上保持一致的增益。

Conclusion: ESPO建立了序列级优化作为扩散大语言模型中强化学习的原理性和经验有效的范式，为扩散模型的强化学习训练提供了新的解决方案。

Abstract: Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.

</details>


### [27] [In-Context Representation Hijacking](https://arxiv.org/abs/2512.03771)
*Itay Yona,Amir Sarid,Michael Karasik,Yossi Gandelsman*

Main category: cs.CL

TL;DR: Doublespeak是一种针对大语言模型的上下文表示劫持攻击，通过将有害关键词替换为良性标记来绕过安全对齐


<details>
  <summary>Details</summary>
Motivation: 当前LLM的安全对齐策略存在漏洞，攻击者可能通过操纵内部表示来绕过安全防护，需要揭示这种新的攻击面

Method: 通过系统性地将有害关键词替换为良性标记（如"bomb"→"carrot"），在多个上下文示例中诱导模型内部表示收敛，使良性标记获得有害语义

Result: 攻击在闭源和开源系统上均有效，在Llama-3.3-70B-Instruct上达到74%的攻击成功率，且无需优化、跨模型家族可转移

Conclusion: 当前的安全对齐策略不足，需要在表示层面进行防护，Doublespeak揭示了LLM潜在空间中的新攻击面

Abstract: We introduce \textbf{Doublespeak}, a simple \emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \textit{bomb}) with a benign token (e.g., \textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.

</details>


### [28] [Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5](https://arxiv.org/abs/2512.03803)
*Huey Sun,Anabel Yong,Lorenzo Gilly,Felipe Jin*

Main category: cs.CL

TL;DR: 将DoLa对比解码方法首次应用于T5/FLAN-T5编码器-解码器架构，评估其对指令遵循能力的影响，发现对某些任务类型有益，对另一些有害，并通过层间分析解释原因。


<details>
  <summary>Details</summary>
Motivation: 对比解码方法（如DoLa）此前仅应用于仅解码器架构，主要研究其对事实性的改进。本研究旨在将DoLa方法适配到T5和FLAN-T5编码器-解码器架构，并评估其对模型指令遵循能力的影响，填补该领域的研究空白。

Method: 将DoLa对比解码算法适配到T5和FLAN-T5模型家族，在编码器-解码器架构中首次实现对比解码策略。通过层间分析研究FLAN-T5模型中logit的演化，量化DoLa对token输出概率的影响。

Result: DoLa在某些任务类别中提高了文本生成的忠实性，但在其他任务中产生了负面影响。通过层间分析揭示了DoLa对token输出概率的具体影响机制。

Conclusion: DoLa在编码器-解码器架构中的效果具有任务依赖性，为理解对比解码在不同架构中的工作机制提供了新的见解，并展示了其在特定任务类型中的潜在价值。

Abstract: Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.

</details>


### [29] [Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology](https://arxiv.org/abs/2512.03818)
*Kylie L. Anglin,Stephanie Milan,Brittney Hernandez,Claudia Ventura*

Main category: cs.CL

TL;DR: 本文提出一个通过提示工程优化LLM在心理学文本分类中性能的实证框架，发现构造定义和任务框架比思维链、角色扮演等策略更重要，推荐结合人工和自动提示生成并进行实证选择。


<details>
  <summary>Details</summary>
Motivation: LLM在文本分类中表现良好，但其输出严重依赖提示的措辞。现有研究很少关注心理学等领域的分类任务，这些领域的构造具有精确、理论驱动的定义，可能在预训练数据中代表性不足。需要系统方法来优化LLM在专家判断对齐关键场景中的提示。

Method: 提出一个实证框架，实验评估五种提示策略：代码本引导的实证提示选择、自动提示工程、角色提示、思维链推理和解释性提示，结合零样本和少样本分类。在三个构造和两个模型上进行测试。

Result: 发现角色、思维链和解释并不能完全解决措辞不当提示带来的性能损失。最重要的提示特征是构造定义、任务框架，其次是提供的示例。与专家判断最一致的结果来自结合代码本引导的实证提示选择和自动提示工程的少样本提示。

Conclusion: 建议研究人员生成和评估尽可能多的提示变体（人工制作、自动生成或两者结合），基于训练数据集中的实证性能选择提示和示例，并在保留集中验证最终方法。这为在专家判断对齐关键场景中优化LLM提示提供了实用、系统和理论驱动的方法。

Abstract: Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.

</details>


### [30] [Training and Evaluation of Guideline-Based Medical Reasoning in LLMs](https://arxiv.org/abs/2512.03838)
*Michael Staniek,Artem Sokolov,Stefan Riezler*

Main category: cs.CL

TL;DR: 本文提出一种方法，通过将医学共识指南转化为推理规则来微调LLMs，使其能够遵循医学共识进行逐步推理和预测，在脓毒症预测任务中，小规模微调模型优于大规模LLMs的单次学习。


<details>
  <summary>Details</summary>
Motivation: 当前医学早期预测的机器学习方法过于关注预测准确性，而忽视了获得医疗从业者信任所需的忠实解释。医学中普遍存在的共识指南为LLMs提供了学习医学推理规则的机会。

Method: 将医学共识指南（如Sepsis-3定义）转化为可执行的推理规则，用这些规则的实例化数据微调LLMs，使其学习共识规则及其例外情况。同时采用多模态方法，将时间序列预测模型的输出表示与LLM集成，以处理稀疏和不规则的临床变量预测。

Result: 在脓毒症预测任务中，小规模微调模型在推导正确性和价值正确性方面优于大规模LLMs的单次学习。微调模型在特定医学领域的未见患者数据上实现了近乎完美的规则推导正确性。多模态集成方法改善了时间序列预测结果。

Conclusion: 通过将医学共识指南转化为推理规则来微调LLMs，可以产生忠实且可解释的医学预测。早期预测的主要瓶颈不是分布外泛化，而是对未来稀疏不规则临床变量的预测泛化，多模态方法可以改善这一问题。

Abstract: Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.

</details>


### [31] [Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers](https://arxiv.org/abs/2512.03870)
*Hongzhan Lin,Zhiqi Bai,Xinmiao Zhang,Sen Yang,Xiang Li,Siran Yang,Yunlong Xu,Jiaheng Liu,Yongchi Zhao,Jiamang Wang,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: FusedKV是一种通过跨层融合KV缓存来减少内存占用的方法，在保持性能的同时将缓存内存减少50%。


<details>
  <summary>Details</summary>
Motivation: Transformer解码器在长序列任务中面临KV缓存内存消耗过大的问题，现有的跨层KV缓存共享方法（如YOCO、CLA）性能通常不如层内方法（如GQA）。

Method: 通过分析顶层KV的信息流，发现值主要来自底层，而键则从底层和中间层获取信息。基于此提出FusedKV，顶层KV缓存是底层和中间层最有信息量的KV的可学习融合，直接在应用RoPE后的键上操作以保留位置信息。还提出更高效的FusedKV-Lite，顶层KV缓存直接来自底层的值和中间层的键。

Result: 在332M到4B参数的LLM实验中，该方法减少50%缓存内存，同时达到比标准Transformer解码器更低的验证困惑度。

Conclusion: FusedKV是一种内存高效、高性能的架构替代方案，通过跨层融合KV缓存有效解决了长序列任务中的内存瓶颈问题。

Abstract: Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.

</details>


### [32] [BERnaT: Basque Encoders for Representing Natural Textual Diversity](https://arxiv.org/abs/2512.03903)
*Ekhi Azurmendi,Joseba Fernandez de Landa,Jaione Bengoetxea,Maite Heredia,Julen Etxaniz,Mikel Zubillaga,Ander Soraluze,Aitor Soroa*

Main category: cs.CL

TL;DR: 论文提出语言模型应捕捉语言多样性，构建包含标准、社交媒体和历史文本的巴斯克语语料库，训练BERnaT模型，并通过标准与多样性子集评估框架验证多样性训练能提升模型泛化能力而不损害标准任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型依赖经过质量过滤的大规模文本语料库，但过滤过程可能无意中排除非标准语言变体（方言、历史、非正式等），这会降低模型鲁棒性并强化代表性偏见。因此需要构建能捕捉完整语言变体谱系的语言模型。

Method: 针对巴斯克语（形态丰富、资源稀缺语言），构建包含标准文本、社交媒体内容和历史资料的新语料库。预训练BERnaT系列编码器模型，设置三种配置：标准、多样性和组合。提出将自然语言理解任务分为标准子集和多样性子集的评估框架，以评估语言泛化能力。

Result: 实验结果显示，在标准数据和多样性数据上训练的模型始终优于仅使用标准语料库训练的模型，在所有任务类型上都有性能提升，且不会损害标准基准测试的准确性。

Conclusion: 语言多样性对于构建包容性、可泛化的语言模型至关重要。同时使用标准和多样性数据进行训练能提升模型性能，而不会影响标准任务表现，这为构建更全面的语言模型提供了实证支持。

Abstract: Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.

</details>


### [33] [Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions](https://arxiv.org/abs/2512.03943)
*Kazi Abrab Hossain,Jannatul Somiya Mahmud,Maria Hossain Tuli,Anik Mitra,S. M. Taiabul Haque,Farig Y. Sadeque*

Main category: cs.CL

TL;DR: 提出了BRAND数据集，用于评估多语言模型在南亚四大宗教（佛教、基督教、印度教、伊斯兰教）上的偏见，发现模型在英语中表现优于孟加拉语，且对伊斯兰教存在系统性偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在偏见检测方面有所改进，但宗教等敏感话题仍面临挑战，因为微小错误可能导致严重误解。多语言模型经常误传宗教信息，在宗教语境中准确性不足，需要专门的数据集来评估和改进。

Method: 创建了BRAND（双语宗教问责规范数据集），包含南亚四大宗教（佛教、基督教、印度教、伊斯兰教）的2400多个条目，使用英语和孟加拉语两种语言的三种不同类型提示来评估模型表现。

Result: 模型在英语中的表现优于孟加拉语，即使在回答宗教中立问题时也持续显示出对伊斯兰教的偏见。这些发现突显了多语言模型在不同语言中回答相似问题时存在的持续偏见。

Conclusion: 研究揭示了多语言模型在宗教语境中的系统性偏见问题，特别是在不同语言环境下的表现差异。这些发现与HCI领域关于宗教和灵性的更广泛问题相关，强调了需要改进模型在敏感话题上的跨语言公平性。

Abstract: While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

</details>


### [34] [Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study](https://arxiv.org/abs/2512.03976)
*Lifeng Chen,Ryan Lai,Tianming Liu*

Main category: cs.CL

TL;DR: 将Qwen2.5-3B模型通过两阶段方法（持续预训练+监督微调）适配到藏语，显著降低了困惑度并大幅提升了汉藏翻译质量，同时通过层分析揭示了适配机制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在低资源语言（如藏语）上的适配面临数据稀缺和跨语言漂移的挑战，需要开发有效的适配方法。

Method: 采用两阶段适配：1）持续预训练建立藏语语言基础；2）监督微调进行任务和翻译专业化。对Qwen3-4B的435层进行层分析。

Result: 困惑度从2.98降至1.54；汉藏翻译BLEU从0.046提升至0.261，chrF从2.2提升至6.6。适配主要集中在嵌入层和输出头，中后期MLP投影编码领域特定转换。

Conclusion: 持续预训练构建藏语语义流形，监督微调以最小表征干扰锐化任务对齐。为LLM在低资源语言适配提供了首个藏语定量探索和可复现框架。

Abstract: Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.

</details>


### [35] [Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models](https://arxiv.org/abs/2512.03989)
*Taido Purason,Pavel Chizhov,Ivan P. Yamshchikov,Mark Fishel*

Main category: cs.CL

TL;DR: 提出两种tokenizer适应方法：继续BPE训练用于词汇扩展，叶基词汇剪枝用于词汇缩减，共同实现可控词汇修改


<details>
  <summary>Details</summary>
Motivation: 现有tokenizer适应方法（在新领域文本上训练新tokenizer并追加非重叠词汇）常导致许多不可达或从未使用的词汇，需要更有效的词汇扩展和剪枝方法

Method: 1. 继续BPE训练：通过在新增数据上继续BPE合并学习过程来适应预训练tokenizer；2. 叶基词汇剪枝：移除冗余词汇同时保持模型质量

Result: 跨多种语言和模型家族的实验表明，继续BPE训练提高了分词效率并更好地利用了新增词汇，叶基词汇剪枝有效减少了冗余词汇

Conclusion: 这两种方法为可控词汇修改提供了实用工具，已作为开源包发布，能有效将预训练语言模型迁移到新领域或语言

Abstract: Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.

</details>


### [36] [AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving](https://arxiv.org/abs/2512.04013)
*Ying Wang,Zhen Jin,Jiexiong Xu,Wenhai Lin,Yiquan Chen,Wenzhi Chen*

Main category: cs.CL

TL;DR: AugServe是一个高效的增强LLM推理服务框架，通过两阶段自适应请求调度和动态令牌批处理，显著提高有效吞吐量并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有增强LLM推理系统面临两大挑战：1) 先到先服务调度导致严重的队头阻塞，使许多请求超出SLO延迟要求；2) 静态批处理令牌限制无法适应负载波动和硬件条件变化，这两者都降低了有效吞吐量和服务质量。

Method: AugServe采用两阶段自适应请求调度策略：第一阶段结合增强LLM请求的推理特征优化调度决策顺序；第二阶段利用运行时信息持续优化决策，适应请求特征和系统能力。此外，还基于硬件状态和实时负载动态调整令牌批处理机制。

Result: 实验结果显示，AugServe比vLLM和InferCept分别实现4.7-33.1倍和3.3-13.2倍更高的有效吞吐量，同时将首令牌时间(TTFT)分别降低高达96.3%和95.0%。

Conclusion: AugServe通过创新的自适应调度和动态批处理机制，有效解决了增强LLM推理服务中的队头阻塞和静态批处理限制问题，显著提升了服务效率和用户体验。

Abstract: As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.

</details>


### [37] [Jina-VLM: Small Multilingual Vision Language Model](https://arxiv.org/abs/2512.04032)
*Andreas Koukounas,Georgios Mastrapas,Florian Hönicke,Sedigheh Eslami,Guillaume Roncari,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: Jina-VLM是一个2.4B参数的视觉语言模型，在2B规模的开源VLM中实现了最先进的多语言视觉问答性能。


<details>
  <summary>Details</summary>
Motivation: 需要开发一个参数效率高且能处理任意分辨率图像的多语言视觉语言模型，在2B参数规模下实现最优性能。

Method: 结合SigLIP2视觉编码器和Qwen3语言主干，通过注意力池化连接器实现token高效处理任意分辨率图像。

Result: 在标准VQA基准测试和多语言评估中，Jina-VLM优于同类模型，同时保持竞争力的纯文本性能。

Conclusion: Jina-VLM在2B参数规模下实现了最先进的多语言视觉问答性能，展示了参数效率和图像处理能力的良好平衡。

Abstract: We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.

</details>


### [38] [SkillFactory: Self-Distillation For Learning Cognitive Behaviors](https://arxiv.org/abs/2512.04072)
*Zayne Sprague,Jack Lu,Manya Wadhwa,Sedrick Keh,Mengye Ren,Greg Durrett*

Main category: cs.CL

TL;DR: SkillFactory是一种在强化学习前通过监督微调让模型学习认知技能的方法，使用模型自身生成的数据进行训练，即使数据不完美也能帮助模型在强化学习阶段更好地掌握技能。


<details>
  <summary>Details</summary>
Motivation: 如何让模型掌握基础模型不具备的认知技能（如答案验证、回溯、尝试替代方法等），而不依赖于从更强模型的知识蒸馏。

Method: 在强化学习前进行监督微调，使用模型自身生成的样本重新组织成技能训练数据（"silver" SFT traces），这些数据可能不完美但能有效引导模型在后续强化学习中掌握技能。

Result: 1) SkillFactory SFT初始化帮助模型在强化学习后泛化到更难的任务变体；2) 模型确实使用了认知技能；3) SkillFactory模型在域外任务上比基础模型更稳健。

Conclusion: 在强化学习前学习的归纳偏置有助于模型掌握稳健的认知技能使用，SkillFactory提供了一种不依赖知识蒸馏的有效方法。

Abstract: Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These "silver" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [39] [BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents](https://arxiv.org/abs/2512.03413)
*Shu Wang,Yingli Zhou,Yixiang Fang*

Main category: cs.IR

TL;DR: BookRAG：针对层次结构文档的新型检索增强生成方法，通过构建BookIndex层次索引和基于信息觅食理论的智能体查询机制，显著提升问答性能


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要针对一般文档，忽略了现实世界中许多文档（如书籍、手册等）具有层次结构的特点，导致在问答任务上性能不佳。需要专门针对层次结构文档的RAG方法。

Method: 1. 构建BookIndex：从文档中提取层次树作为目录，用图捕捉实体间复杂关系，并将实体映射到树节点。2. 基于信息觅食理论设计智能体查询方法：动态分类查询并采用定制化检索工作流程。

Result: 在三个广泛采用的基准测试上进行大量实验，BookRAG在检索召回率和问答准确性方面均达到最先进性能，显著优于基线方法，同时保持竞争性的效率。

Conclusion: BookRAG是针对层次结构文档的有效RAG方法，通过利用逻辑层次结构和追踪实体关系来查询高度相关信息，解决了现有方法在处理结构化文档时的局限性。

Abstract: As an effective method to boost the performance of Large Language Models (LLMs) on the question answering (QA) task, Retrieval-Augmented Generation (RAG), which queries highly relevant information from external complex documents, has attracted tremendous attention from both industry and academia. Existing RAG approaches often focus on general documents, and they overlook the fact that many real-world documents (such as books, booklets, handbooks, etc.) have a hierarchical structure, which organizes their content from different granularity levels, leading to poor performance for the QA task. To address these limitations, we introduce BookRAG, a novel RAG approach targeted for documents with a hierarchical structure, which exploits logical hierarchies and traces entity relations to query the highly relevant information. Specifically, we build a novel index structure, called BookIndex, by extracting a hierarchical tree from the document, which serves as the role of its table of contents, using a graph to capture the intricate relationships between entities, and mapping entities to tree nodes. Leveraging the BookIndex, we then propose an agent-based query method inspired by the Information Foraging Theory, which dynamically classifies queries and employs a tailored retrieval workflow. Extensive experiments on three widely adopted benchmarks demonstrate that BookRAG achieves state-of-the-art performance, significantly outperforming baselines in both retrieval recall and QA accuracy while maintaining competitive efficiency.

</details>


### [40] [LLM as Explainable Re-Ranker for Recommendation System](https://arxiv.org/abs/2512.03439)
*Yaqi Wang,Haojia Sun,Shuting Zhang*

Main category: cs.IR

TL;DR: 使用LLM作为可解释的重新排序器，结合传统推荐模型提升准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统缺乏可解释性且存在流行度偏差问题，而LLM单独作为预测器无法达到传统模型的准确性

Method: 提出混合方法：使用LLM作为可解释的重新排序器，结合传统推荐模型；构建数据集训练重新排序器LLM，采用两阶段训练过程

Result: 模型显著改善了NDCG排名指标，在排名准确性和可解释性方面优于零样本基线

Conclusion: 将传统推荐模型与LLM结合能够解决现有系统的局限性，为更可解释和公平的推荐框架铺平道路

Abstract: The application of large language models (LLMs) in recommendation systems has recently gained traction. Traditional recommendation systems often lack explainability and suffer from issues such as popularity bias. Previous research has also indicated that LLMs, when used as standalone predictors, fail to achieve accuracy comparable to traditional models. To address these challenges, we propose to use LLM as an explainable re-ranker, a hybrid approach that combines traditional recommendation models with LLMs to enhance both accuracy and interpretability. We constructed a dataset to train the re-ranker LLM and evaluated the alignment between the generated dataset and human expectations. Leveraging a two-stage training process, our model significantly improved NDCG, a key ranking metric. Moreover, the re-ranker outperformed a zero-shot baseline in ranking accuracy and interpretability. These results highlight the potential of integrating traditional recommendation models with LLMs to address limitations in existing systems and pave the way for more explainable and fair recommendation frameworks.

</details>


### [41] [M3DR: Towards Universal Multilingual Multimodal Document Retrieval](https://arxiv.org/abs/2512.03514)
*Adithya S Kolavi,Vyoman Jain*

Main category: cs.IR

TL;DR: M3DR是一个多语言多模态文档检索框架，通过合成多语言数据和对比训练，实现了跨语言和跨模态的对齐，在22种语言上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态文档检索系统主要针对英语，在多语言环境中的效果有限，需要开发能够适应不同语言和文化背景的框架。

Method: 使用合成多语言文档数据，采用对比训练方法，学习文本和文档图像的统一表示，支持单密集向量和ColBERT式令牌级多向量检索范式。

Result: 在22种类型多样的语言上验证了模型能力，NetraEmbed和ColNetraEmbed模型在跨语言检索上实现了约150%的相对改进，达到最先进性能。

Conclusion: M3DR框架成功解决了多语言多模态文档检索的挑战，通过统一的表示学习实现了跨语言和跨模态的有效对齐，具有广泛的应用潜力。

Abstract: Multimodal document retrieval systems have shown strong progress in aligning visual and textual content for semantic search. However, most existing approaches remain heavily English-centric, limiting their effectiveness in multilingual contexts. In this work, we present M3DR (Multilingual Multimodal Document Retrieval), a framework designed to bridge this gap across languages, enabling applicability across diverse linguistic and cultural contexts. M3DR leverages synthetic multilingual document data and generalizes across different vision-language architectures and model sizes, enabling robust cross-lingual and cross-modal alignment. Using contrastive training, our models learn unified representations for text and document images that transfer effectively across languages. We validate this capability on 22 typologically diverse languages, demonstrating consistent performance and adaptability across linguistic and script variations. We further introduce a comprehensive benchmark that captures real-world multilingual scenarios, evaluating models under monolingual, multilingual, and mixed-language settings. M3DR generalizes across both single dense vector and ColBERT-style token-level multi-vector retrieval paradigms. Our models, NetraEmbed and ColNetraEmbed achieve state-of-the-art performance with ~150% relative improvements on cross-lingual retrieval.

</details>


### [42] [Algorithms for Boolean Matrix Factorization using Integer Programming and Heuristics](https://arxiv.org/abs/2512.03807)
*Christos Kolomvakis,Thomas Bobille,Arnaud Vandaele,Nicolas Gillis*

Main category: cs.IR

TL;DR: 本文提出了一系列布尔矩阵分解(BMF)算法，包括基于整数规划的交替优化方法、多运行结果优化选择策略、可扩展的启发式算法，以及高效的C++数据结构实现。


<details>
  <summary>Details</summary>
Motivation: 布尔矩阵分解使用布尔运算(OR和AND)而非标准算术运算，能提高可解释性并减少近似误差，在角色挖掘和计算机视觉中有应用。现有方法在可扩展性方面存在限制。

Method: 1) 提出基于整数规划的交替优化算法；2) 设计从多次运行中选择最优秩一因子子集的方法；3) 引入贪心和局部搜索启发式算法以解决可扩展性问题；4) 构建高效的C++布尔向量和矩阵数据结构。

Result: 提出的算法在多个真实数据集上(包括有缺失数据和无缺失数据的情况)表现出色，在主题建模和图像处理应用中超越了现有技术水平。新的C++数据结构显著提升了计算速度。

Conclusion: 本文提出的方法组合有效地解决了布尔矩阵分解的可扩展性和性能问题，新的数据结构具有独立价值，使启发式算法能够扩展到大型数据集。

Abstract: Boolean matrix factorization (BMF) approximates a given binary input matrix as the product of two smaller binary factors. Unlike binary matrix factorization based on standard arithmetic, BMF employs the Boolean OR and AND operations for the matrix product, which improves interpretability and reduces the approximation error. It is also used in role mining and computer vision. In this paper, we first propose algorithms for BMF that perform alternating optimization (AO) of the factor matrices, where each subproblem is solved via integer programming (IP). We then design different approaches to further enhance AO-based algorithms by selecting an optimal subset of rank-one factors from multiple runs. To address the scalability limits of IP-based methods, we introduce new greedy and local-search heuristics. We also construct a new C++ data structure for Boolean vectors and matrices that is significantly faster than existing ones and is of independent interest, allowing our heuristics to scale to large datasets. We illustrate the performance of all our proposed methods and compare them with the state of the art on various real datasets, both with and without missing data, including applications in topic modeling and imaging.

</details>


### [43] [Learning to Comparison-Shop](https://arxiv.org/abs/2512.04009)
*Jie Tang,Daochen Zha,Xin Liu,Huiji Gao,Liwei He,Stephanie Moyerman,Sanjeev Katariya*

Main category: cs.IR

TL;DR: 提出LTCS系统，通过显式建模用户比较购物行为来改进在线市场搜索排名，显著提升NDCG和预订转化率。


<details>
  <summary>Details</summary>
Motivation: 在线市场（如Airbnb）中用户经常进行比价购物，但主流电商搜索引擎与用户比较需求之间存在显著脱节。传统排名模型孤立评估商品，忽略了用户在搜索结果页面上比较多个商品的上下文。

Method: 提出新颖的排名架构——学习比较购物（LTCS）系统，该系统显式建模和学习用户的比较购物行为。

Result: 通过离线和在线实验，LTCS在关键业务指标上取得显著提升：NDCG提高1.7%，A/B测试中预订转化率提升0.6%，同时改善了用户体验，且显著优于最先进方法。

Conclusion: LTCS系统通过建模用户比较购物行为，有效解决了传统排名模型与用户实际购物行为之间的脱节问题，为在线市场搜索排名提供了更优解决方案。

Abstract: In online marketplaces like Airbnb, users frequently engage in comparison shopping before making purchase decisions. Despite the prevalence of this behavior, a significant disconnect persists between mainstream e-commerce search engines and users' comparison needs. Traditional ranking models often evaluate items in isolation, disregarding the context in which users compare multiple items on a search results page. While recent advances in deep learning have sought to improve ranking accuracy, diversity, and fairness by encoding listwise context, the challenge of aligning search rankings with user comparison shopping behavior remains inadequately addressed. In this paper, we propose a novel ranking architecture - Learning-to-Comparison-Shop (LTCS) System - that explicitly models and learns users' comparison shopping behaviors. Through extensive offline and online experiments, we demonstrate that our approach yields statistically significant gains in key business metrics - improving NDCG by 1.7% and boosting booking conversion rate by 0.6% in A/B testing - while also enhancing user experience. We also compare our model against state-of-the-art approaches and demonstrate that LTCS significantly outperforms them.

</details>
