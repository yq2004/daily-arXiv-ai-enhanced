<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 85]
- [cs.IR](#cs.IR) [Total: 17]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Multimodal Consistency-Guided Reference-Free Data Selection for ASR Accent Adaptation](https://arxiv.org/abs/2602.13263)
*Ligong Lei,Wenwen Lu,Xudong Pang,Zaokere Kadeer,Aishan Wumaier*

Main category: cs.CL

TL;DR: 提出了一种多模态一致性引导的参考无关数据选择方法，用于ASR口音自适应，通过语音-文本对齐和预测WER来筛选可靠伪标签。


<details>
  <summary>Details</summary>
Motivation: ASR系统在口音语音上性能下降，但标注数据适应成本高昂。现有伪标签选择方法主要基于文本中心启发式（如困惑度过滤），可能偏好流畅但声学不匹配的假设，导致微调时错误放大。

Method: 1. 基于子模互信息的目标感知预选；2. 通过扰动解码生成多个伪转录；3. 使用两种参考无关信号评分：共享嵌入空间的语音-文本对齐和预测WER；4. 基于百分位的简单选择规则保留可靠伪标签。

Result: 在领域内设置中，从30k池中选择约1.5k话语达到10.91% WER，接近使用30k监督标签的10.45%。在跨领域设置中，一致性过滤子集避免了强口音偏移下未过滤伪标签导致的性能下降，匹配小时实验进一步证实了相对于随机采样和现有基线的优势。

Conclusion: 该方法通过多模态一致性引导的参考无关数据选择，有效解决了ASR口音自适应中伪标签选择问题，在减少计算成本的同时保持了接近监督学习的性能。

Abstract: Automatic speech recognition (ASR) systems often degrade on accented speech because acoustic-phonetic and prosodic shifts induce a mismatch to training data, making labeled accent adaptation costly. However, common pseudo-label selection heuristics are largely text-centric (e.g., perplexity (PPL) filtering) and can prefer fluent yet acoustically mismatched hypotheses, leading to error amplification when fine-tuning. To address this, we introduce a multimodal consistency-guided, reference-free data selection pipeline for ASR accent adaptation under a transductive, label-free protocol. The pipeline starts with a target-aware preselection step based on submodular mutual information to improve query relevance and reduce downstream computation. It then generates multiple pseudo-transcriptions per utterance via perturbation-based decoding and scores each hypothesis using two reference-free signals: speech--text alignment in a shared embedding space and predicted word error rate (WER). A simple percentile-based selection rule retains reliable pseudo-labels for fine-tuning while discarding noisy utterances. In an in-domain setting, selecting ~1.5k utterances from a 30k pool achieves 10.91% WER, close to 10.45% obtained using 30k supervised labels. In a cross-domain setting with a mismatched candidate pool, consistency-filtered subsets avoid the degradation caused by unfiltered pseudo-labels under strong accent shift, and matched-hour experiments on a stronger ASR backbone further confirm gains over random sampling and recent selection baselines.

</details>


### [2] [LLM-Powered Automatic Translation and Urgency in Crisis Scenarios](https://arxiv.org/abs/2602.13452)
*Belu Ticona,Antonis Anastasopoulos*

Main category: cs.CL

TL;DR: 大型语言模型和机器翻译系统在危机领域翻译中存在性能下降和不稳定性，特别是对紧迫性信息的保留不足，提示语言和输入语言会影响LLM的紧迫性分类结果。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs越来越多地被提议用于危机准备和响应中的多语言通信，但它们在高压危机环境中的适用性尚未得到充分评估，特别是对紧迫性这一关键属性的保留能力。

Method: 使用多语言危机数据和新建的覆盖32种语言的紧迫性标注数据集，评估最先进的LLMs和机器翻译系统在危机领域翻译中的表现，特别关注紧迫性保留问题。

Result: 专用翻译模型和LLMs都表现出显著的性能下降和不稳定性；即使是语言上充分的翻译也可能扭曲感知的紧迫性；基于LLM的紧迫性分类结果会因提示语言和输入语言的不同而有很大差异。

Conclusion: 通用语言技术在危机通信中的部署存在显著风险，需要建立危机感知的评估框架来确保这些技术在高压环境中的可靠性和安全性。

Abstract: Large language models (LLMs) are increasingly proposed for crisis preparedness and response, particularly for multilingual communication. However, their suitability for high-stakes crisis contexts remains insufficiently evaluated. This work examines the performance of state-of-the-art LLMs and machine translation systems in crisis-domain translation, with a focus on preserving urgency, which is a critical property for effective crisis communication and triaging. Using multilingual crisis data and a newly introduced urgency-annotated dataset covering over 32 languages, we show that both dedicated translation models and LLMs exhibit substantial performance degradation and instability. Crucially, even linguistically adequate translations can distort perceived urgency, and LLM-based urgency classifications vary widely depending on the language of the prompt and input. These findings highlight significant risks in deploying general-purpose language technologies for crisis communication and underscore the need for crisis-aware evaluation frameworks.

</details>


### [3] [Using Machine Learning to Enhance the Detection of Obfuscated Abusive Words in Swahili: A Focus on Child Safety](https://arxiv.org/abs/2602.13455)
*Phyllis Nabangi,Abdul-Jalil Zakaria,Jema David Ndibwile*

Main category: cs.CL

TL;DR: 该研究使用机器学习模型检测斯瓦希里语中的隐蔽性网络欺凌语言，重点关注这种低资源语言的独特挑战，通过SMOTE等技术处理数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 数字技术发展增加了网络欺凌风险，需要加强检测和预防措施，特别是针对儿童。斯瓦希里语作为非洲使用最广泛的语言（超过1亿使用者），但由于是低资源语言，面临有限的语料资源和技术支持，需要专门研究来检测其中的隐蔽性辱骂语言。

Method: 采用支持向量机(SVM)、逻辑回归和决策树等机器学习模型，通过严格的参数调优，并使用合成少数类过采样技术(SMOTE)处理数据不平衡问题。在斯瓦希里语数据集上进行实验，详细分析精确率、召回率和F1分数。

Result: 机器学习模型在高维文本数据中表现良好，但由于数据集规模小且不平衡，研究结果的普适性受到限制。详细分析了各模型在检测隐蔽性语言方面的细微性能差异。

Conclusion: 该研究为儿童创造更安全的网络环境做出了贡献，建议扩大数据集并采用更先进的机器学习技术来提高网络欺凌检测系统的有效性。未来工作将专注于增强数据鲁棒性、探索迁移学习以及整合多模态数据，以创建更全面和文化敏感的检测机制。

Abstract: The rise of digital technology has dramatically increased the potential for cyberbullying and online abuse, necessitating enhanced measures for detection and prevention, especially among children. This study focuses on detecting abusive obfuscated language in Swahili, a low-resource language that poses unique challenges due to its limited linguistic resources and technological support. Swahili is chosen due to its popularity and being the most widely spoken language in Africa, with over 16 million native speakers and upwards of 100 million speakers in total, spanning regions in East Africa and some parts of the Middle East.
  We employed machine learning models including Support Vector Machines (SVM), Logistic Regression, and Decision Trees, optimized through rigorous parameter tuning and techniques like Synthetic Minority Over-sampling Technique (SMOTE) to handle data imbalance. Our analysis revealed that, while these models perform well in high-dimensional textual data, our dataset's small size and imbalance limit our findings' generalizability. Precision, recall, and F1 scores were thoroughly analyzed, highlighting the nuanced performance of each model in detecting obfuscated language.
  This research contributes to the broader discourse on ensuring safer online environments for children, advocating for expanded datasets and advanced machine-learning techniques to improve the effectiveness of cyberbullying detection systems. Future work will focus on enhancing data robustness, exploring transfer learning, and integrating multimodal data to create more comprehensive and culturally sensitive detection mechanisms.

</details>


### [4] [Language Model Memory and Memory Models for Language](https://arxiv.org/abs/2602.13466)
*Benjamin L. Badger*

Main category: cs.CL

TL;DR: 语言模型嵌入包含较少输入信息，而自编码器嵌入能形成近乎完美的记忆；通过结合因果和信息保留目标，可以训练模型形成信息丰富的记忆嵌入，提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型将输入信息存储在隐藏层向量嵌入中的能力类似于"记忆"，但这一特性尚未得到充分表征。当前语言模型的嵌入通常包含较少输入信息，而若能形成有效记忆嵌入，可以替代标记序列带来显著计算效率提升。

Method: 1) 分析语言模型和自编码器嵌入的信息容量差异；2) 提出可并行化的编码器-解码器记忆模型架构；3) 结合因果训练和信息保留目标函数；4) 采用冻结高保真编码器+课程训练方法，先学习处理记忆，再学习预测下一个标记。

Result: 语言模型嵌入通常包含相对较少的输入信息，而自编码器嵌入能实现近乎完美的记忆形成。通过结合因果和信息保留目标，模型可以学习形成和解码信息丰富的记忆。课程训练方法能进一步简化训练过程。

Conclusion: 仅依赖下一个标记预测训练不适合准确记忆形成，因为该目标本身是非可逆的。对于不完全暴露整个输入的模型，应使用结合的目标函数来促进信息丰富的记忆嵌入的形成和解码。

Abstract: The ability of machine learning models to store input information in hidden layer vector embeddings, analogous to the concept of `memory', is widely employed but not well characterized. We find that language model embeddings typically contain relatively little input information regardless of data and compute scale during training. In contrast, embeddings from autoencoders trained for input regeneration are capable of nearly perfect memory formation. The substitution of memory embeddings for token sequences leads to substantial computational efficiencies, motivating the introduction of a parallelizable encoder-decoder memory model architecture. Upon causal training these models contain information-poor embeddings incapable of arbitrary information access, but by combining causal and information retention objective functions they learn to form and decode information-rich memories. Training can be further streamlined by freezing a high fidelity encoder followed by a curriculum training approach where decoders first learn to process memories and then learn to additionally predict next tokens. We introduce the perspective that next token prediction training alone is poorly suited for accurate memory formation as the objective itself is non-invertible, motivating the use of combined objective functions for models where the entire input is not exposed.

</details>


### [5] [From Perceptions To Evidence: Detecting AI-Generated Content In Turkish News Media With A Fine-Tuned Bert Classifier](https://arxiv.org/abs/2602.13504)
*Ozancan Ozdemir*

Main category: cs.CL

TL;DR: 首次对土耳其新闻媒体中AI生成内容进行实证量化研究，通过微调土耳其语BERT模型识别AI改写新闻，发现约2.5%的新闻内容被LLMs改写。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在新闻编辑室工作流程中的快速集成，急需了解在线媒体中AI生成内容的普遍性。虽然已有研究开始量化英语媒体中的这一现象，但土耳其新闻媒体缺乏实证调查，现有研究仅限于对记者的定性访谈或假新闻检测。

Method: 微调土耳其特定BERT模型(dbmdz/bert-base-turkish-cased)，使用来自三家具有不同编辑取向的主要土耳其媒体的3,600篇标记文章进行二元分类（AI改写内容识别）。模型在保留测试集上评估后，部署在2023-2026年间的3,500多篇未见文章上进行分析。

Result: 模型在测试集上获得0.9708的F1分数，两个类别的精确率和召回率对称。对未见文章的分析显示跨来源和时间上稳定的分类模式，平均预测置信度超过0.96，估计平均约2.5%的新闻内容被LLMs改写或修订。

Conclusion: 这是首个超越自我报告记者认知、对土耳其新闻媒体AI使用进行实证数据驱动测量的研究，为理解非英语媒体中AI内容生成提供了重要基准。

Abstract: The rapid integration of large language models into newsroom workflows has raised urgent questions about the prevalence of AI-generated content in online media. While computational studies have begun to quantify this phenomenon in English-language outlets, no empirical investigation exists for Turkish news media, where existing research remains limited to qualitative interviews with journalists or fake news detection. This study addresses that gap by fine-tuning a Turkish-specific BERT model (dbmdz/bert-base-turkish-cased) on a labeled dataset of 3,600 articles from three major Turkish outlets with distinct editorial orientations for binary classification of AI-rewritten content. The model achieves 0.9708 F1 score on the held-out test set with symmetric precision and recall across both classes. Subsequent deployment on over 3,500 unseen articles spanning between 2023 and 2026 reveals consistent cross-source and temporally stable classification patterns, with mean prediction confidence exceeding 0.96 and an estimated 2.5 percentage of examined news content rewritten or revised by LLMs on average. To the best of our knowledge, this is the first study to move beyond self-reported journalist perceptions toward empirical, data-driven measurement of AI usage in Turkish news media.

</details>


### [6] [Think Deep, Not Just Long: Measuring LLM Reasoning Effort via Deep-Thinking Tokens](https://arxiv.org/abs/2602.13517)
*Wei-Lin Chen,Liqian Peng,Tian Tan,Chao Zhao,Blake JianHang Chen,Ziqian Lin,Alec Go,Yu Meng*

Main category: cs.CL

TL;DR: 该论文提出了一种基于"深度思考token"的推理质量评估方法，并通过Think@n策略在减少推理成本的同时提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于生成长度或置信度的推理质量评估方法不可靠，长CoT可能导致"过度思考"反而降低性能。需要更可靠的指标来量化推理时的努力程度。

Method: 识别"深度思考token"——那些在深层模型层中内部预测发生显著修订后才收敛的token。计算深度思考比例，并基于此提出Think@n策略，优先处理高深度思考比例的样本，提前拒绝无望的生成。

Result: 深度思考比例与准确性呈现稳健的正相关关系，显著优于基于长度和置信度的基线方法。Think@n策略在匹配或超越标准自一致性性能的同时，显著减少了推理成本。

Conclusion: 深度思考token是比原始token计数更可靠的推理质量指标，基于此的Think@n策略能有效平衡推理质量与计算效率。

Abstract: Large language models (LLMs) have demonstrated impressive reasoning capabilities by scaling test-time compute via long Chain-of-Thought (CoT). However, recent findings suggest that raw token counts are unreliable proxies for reasoning quality: increased generation length does not consistently correlate with accuracy and may instead signal "overthinking," leading to performance degradation. In this work, we quantify inference-time effort by identifying deep-thinking tokens -- tokens where internal predictions undergo significant revisions in deeper model layers prior to convergence. Across four challenging mathematical and scientific benchmarks (AIME 24/25, HMMT 25, and GPQA-diamond) and a diverse set of reasoning-focused models (GPT-OSS, DeepSeek-R1, and Qwen3), we show that deep-thinking ratio (the proportion of deep-thinking tokens in a generated sequence) exhibits a robust and consistently positive correlation with accuracy, substantially outperforming both length-based and confidence-based baselines. Leveraging this insight, we introduce Think@n, a test-time scaling strategy that prioritizes samples with high deep-thinking ratios. We demonstrate that Think@n matches or exceeds standard self-consistency performance while significantly reducing inference costs by enabling the early rejection of unpromising generations based on short prefixes.

</details>


### [7] [On Calibration of Large Language Models: From Response To Capability](https://arxiv.org/abs/2602.13540)
*Sin-Han Yang,Cheng-Kuang Wu,Chieh-Yen Lin,Yun-Nung Chen,Hung-yi Lee,Shao-Hua Sun*

Main category: cs.CL

TL;DR: 论文提出能力校准概念，区别于传统响应级校准，关注模型在查询上的期望准确率而非单次响应的正确性，以解决LLM解码随机性带来的校准偏差问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM校准研究主要关注响应级置信度，即评估单次生成输出的正确性。然而实际应用中，用户更关心模型解决查询的整体可能性。这种不匹配源于现代LLM解码的随机性，单次响应的正确性无法反映底层模型能力。

Method: 引入能力校准概念，从理论上区分能力校准与响应校准，建立实证评估框架，研究多种置信度估计方法。通过实验分析两种校准方式的差异。

Result: 能力校准置信度在pass@k预测和推理预算分配方面表现优于传统响应校准，证明其在多种应用场景中的潜力。

Conclusion: 能力校准为解决LLM置信度估计与实际需求不匹配问题提供了新方向，为可靠使用LLM奠定了基础，具有广泛的应用潜力。

Abstract: Large language models (LLMs) are widely deployed as general-purpose problem solvers, making accurate confidence estimation critical for reliable use. Prior work on LLM calibration largely focuses on response-level confidence, which estimates the correctness of a single generated output. However, this formulation is misaligned with many practical settings where the central question is how likely a model is to solve a query overall. We show that this mismatch results from the stochastic nature of modern LLM decoding, under which single-response correctness fails to reflect underlying model capability. To address this issue, we introduce capability calibration, which targets the model's expected accuracy on a query. We formally distinguish capability calibration from response calibration and show that the two differ both theoretically and empirically. We establish an empirical evaluation setup and study a range of confidence estimation methods. Our results demonstrate that capability-calibrated confidence improves pass@$k$ prediction and inference budget allocation, establishing a foundation with potential for diverse applications.

</details>


### [8] [Small Reward Models via Backward Inference](https://arxiv.org/abs/2602.13551)
*Yike Wang,Faeze Brahman,Shangbin Feng,Teng Xiao,Hannaneh Hajishirzi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: FLIP是一种无需参考回复或评分标准的奖励建模方法，通过反向推理从响应推断最可能的指令，将推断指令与原指令的相似度作为奖励信号，在多个领域优于LLM-as-a-Judge基线。


<details>
  <summary>Details</summary>
Motivation: 当前奖励建模方法主要依赖大模型的强推理能力（LLM-as-a-Judge），或需要参考回复和明确评分标准，限制了灵活性和可访问性。需要一种无需参考和评分标准的奖励建模方法。

Method: 提出FLIP方法，通过反向推理重构提示：给定响应，推断最可能产生该响应的指令。然后将推断指令与原指令的相似度作为奖励信号。使用13个小语言模型在四个领域进行评估。

Result: FLIP在四个领域平均优于LLM-as-a-Judge基线79.6%。在通过并行采样和GRPO训练的外在评估中显著提升下游性能。特别对长输出有效，且对常见奖励破解形式具有鲁棒性。

Conclusion: FLIP通过利用验证-生成差距，在判断方法失效的降尺度场景中实现了可靠的奖励建模，为无需参考和评分标准的奖励建模提供了有效解决方案。

Abstract: Reward models (RMs) play a central role throughout the language model (LM) pipeline, particularly in non-verifiable domains. However, the dominant LLM-as-a-Judge paradigm relies on the strong reasoning capabilities of large models, while alternative approaches require reference responses or explicit rubrics, limiting flexibility and broader accessibility. In this work, we propose FLIP (FLipped Inference for Prompt reconstruction), a reference-free and rubric-free reward modeling approach that reformulates reward modeling through backward inference: inferring the instruction that would most plausibly produce a given response. The similarity between the inferred and the original instructions is then used as the reward signal. Evaluations across four domains using 13 small language models show that FLIP outperforms LLM-as-a-Judge baselines by an average of 79.6%. Moreover, FLIP substantially improves downstream performance in extrinsic evaluations under test-time scaling via parallel sampling and GRPO training. We further find that FLIP is particularly effective for longer outputs and robust to common forms of reward hacking. By explicitly exploiting the validation-generation gap, FLIP enables reliable reward modeling in downscaled regimes where judgment methods fail. Code available at https://github.com/yikee/FLIP.

</details>


### [9] [DistillLens: Symmetric Knowledge Distillation Through Logit Lens](https://arxiv.org/abs/2602.13567)
*Manish Dhakal,Uthman Jinadu,Anjila Budathoki,Rajshekhar Sunderraman,Yi Ding*

Main category: cs.CL

TL;DR: DistillLens是一个新的知识蒸馏框架，通过将中间隐藏状态投影到词汇空间，使用对称对齐方法来优化学生模型对教师模型思维过程的学习，相比传统KD和特征蒸馏方法有更好表现。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法只优化最终输出，将教师模型的中间层思维过程视为黑盒。现有的基于特征的蒸馏方法（如MSE和非对称KL散度）忽略了最终输出所需的丰富不确定性分布。

Method: 提出了DistillLens框架，通过Logit Lens将中间隐藏状态投影到词汇空间，使用对称发散目标进行结构对齐，对过度自信和不足自信施加双重惩罚，同时保留最终推理所需的高熵信息通道。

Result: 在GPT-2和Llama架构上的广泛实验表明，DistillLens在多样化的指令跟随基准测试中持续优于标准知识蒸馏和特征迁移基线方法。

Conclusion: DistillLens通过对称对齐学生和教师模型的演化思维过程，有效提升了知识蒸馏效果，特别是在保留不确定性分布和推理路径方面具有优势。

Abstract: Standard Knowledge Distillation (KD) compresses Large Language Models (LLMs) by optimizing final outputs, yet it typically treats the teacher's intermediate layer's thought process as a black box. While feature-based distillation attempts to bridge this gap, existing methods (e.g., MSE and asymmetric KL divergence) ignore the rich uncertainty profiles required for the final output. In this paper, we introduce DistillLens, a framework that symmetrically aligns the evolving thought processes of student and teacher models. By projecting intermediate hidden states into the vocabulary space via the Logit Lens, we enforce structural alignment using a symmetric divergence objective. Our analysis proves that this constraint imposes a dual-sided penalty, preventing both overconfidence and underconfidence while preserving the high-entropy information conduits essential for final deduction. Extensive experiments on GPT-2 and Llama architectures demonstrate that DistillLens consistently outperforms standard KD and feature-transfer baselines on diverse instruction-following benchmarks. The code is available at https://github.com/manishdhakal/DistillLens.

</details>


### [10] [LLM-Confidence Reranker: A Training-Free Approach for Enhancing Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2602.13571)
*Zhipeng Song,Xiangyu Kong,Xinrui Bao,Yizhi Zhou,Jiulong Jiao,Sitong Liu,Yuhang Zhou,Heng Qi*

Main category: cs.CL

TL;DR: LLM-Confidence Reranker (LCR) 是一种无需训练、即插即用的算法，利用大语言模型的置信度信号来改进RAG系统中的文档重排序，显著提升检索效果且计算高效。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统中的重排序器需要专门训练、计算成本高，且未能充分利用LLM的语义能力和内在置信度信号来解决知识密集型任务中的幻觉问题。

Method: 提出两阶段方法：1) 通过多项式采样和聚类进行置信度评估，计算最大语义聚类比例(MSCP)；2) 基于查询和文档置信度阈值的分箱和多级排序，优先相关文档同时保持高置信度查询的原始排序。

Result: 在BEIR和TREC基准测试中，使用仅7-9B参数的预训练LLM，LCR将NDCG@5提升了高达20.6%，且不降低原有性能。消融研究证实LLM置信度与文档相关性正相关。

Conclusion: LCR提供了一种计算高效、可并行扩展、广泛兼容的重排序解决方案，有效缓解医疗诊断等应用中的幻觉问题，无需额外训练即可显著提升RAG系统性能。

Abstract: Large language models (LLMs) have revolutionized natural language processing, yet hallucinations in knowledge-intensive tasks remain a critical challenge. Retrieval-augmented generation (RAG) addresses this by integrating external knowledge, but its efficacy depends on accurate document retrieval and ranking. Although existing rerankers demonstrate effectiveness, they frequently necessitate specialized training, impose substantial computational expenses, and fail to fully exploit the semantic capabilities of LLMs, particularly their inherent confidence signals. We propose the LLM-Confidence Reranker (LCR), a training-free, plug-and-play algorithm that enhances reranking in RAG systems by leveraging black-box LLM confidence derived from Maximum Semantic Cluster Proportion (MSCP). LCR employs a two-stage process: confidence assessment via multinomial sampling and clustering, followed by binning and multi-level sorting based on query and document confidence thresholds. This approach prioritizes relevant documents while preserving original rankings for high-confidence queries, ensuring robustness. Evaluated on BEIR and TREC benchmarks with BM25 and Contriever retrievers, LCR--using only 7--9B-parameter pre-trained LLMs--consistently improves NDCG@5 by up to 20.6% across pre-trained LLM and fine-tuned Transformer rerankers, without degradation. Ablation studies validate the hypothesis that LLM confidence positively correlates with document relevance, elucidating LCR's mechanism. LCR offers computational efficiency, parallelism for scalability, and broad compatibility, mitigating hallucinations in applications like medical diagnosis.

</details>


### [11] [Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment](https://arxiv.org/abs/2602.13575)
*Jing Zhao,Ting Zhen,Junwei bao,Hongfei Jiang,Yang song*

Main category: cs.CL

TL;DR: Elo-Evolve：一个基于动态多智能体竞争的LLM对齐框架，通过配对竞争和自适应对手池实现更稳定高效的模型训练。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐方法依赖将大量人类偏好数据压缩为静态绝对奖励函数，导致数据稀缺、噪声敏感和训练不稳定问题。需要更动态、鲁棒的对齐方法。

Method: 1. 消除Bradley-Terry模型依赖，直接从配对竞争的二元胜/负结果学习；2. 实现Elo评分的对手选择，通过温度控制采样提供自动课程学习；3. 基于PAC学习理论框架；4. 使用包含不同规模模型的动态对手池。

Result: 在Qwen2.5-7B模型上验证：1. 相比绝对评分方法，噪声减少4.5倍；2. 在Alpaca Eval 2.0和MT-Bench上显示清晰的性能层次：基于点的方法 < 静态配对训练 < Elo-Evolve；3. 证明了配对比较和动态对手选择的渐进优势。

Conclusion: Elo-Evolve通过将对齐重新定义为动态多智能体竞争，提供了一种更高效、更稳定的LLM对齐方法，在样本复杂度和噪声鲁棒性方面都有显著改进。

Abstract: Current alignment methods for Large Language Models (LLMs) rely on compressing vast amounts of human preference data into static, absolute reward functions, leading to data scarcity, noise sensitivity, and training instability. We introduce Elo-Evolve, a co-evolutionary framework that redefines alignment as dynamic multi-agent competition within an adaptive opponent pool. Our approach makes two key innovations: (1) eliminating Bradley-Terry model dependencies by learning directly from binary win/loss outcomes in pairwise competitions, and (2) implementing Elo-orchestrated opponent selection that provides automatic curriculum learning through temperature-controlled sampling. We ground our approach in PAC learning theory, demonstrating that pairwise comparison achieves superior sample complexity and empirically validate a 4.5x noise reduction compared to absolute scoring approaches. Experimentally, we train a Qwen2.5-7B model using our framework with opponents including Qwen2.5-14B, Qwen2.5-32B, and Qwen3-8B models. Results demonstrate a clear performance hierarchy: point-based methods < static pairwise training < Elo-Evolve across Alpaca Eval 2.0 and MT-Bench, validating the progressive benefits of pairwise comparison and dynamic opponent selection for LLM alignment.

</details>


### [12] [Metaphors' journeys across time and genre: tracking the evolution of literary metaphors with temporal embeddings](https://arxiv.org/abs/2602.13701)
*Veronica Mangiaterra,Chiara Barattieri di San Pietro,Paolo Canal,Valentina Bambini*

Main category: cs.CL

TL;DR: 该研究应用历时分布语义学工具分析19世纪文学隐喻的处理成本随时间与文类的变化，发现语义相似度整体稳定，但文类起关键作用：现代文学语境中隐喻更难处理，而现代非文学语言中隐喻更易处理。


<details>
  <summary>Details</summary>
Motivation: 文学隐喻是文学语言的特色，但实验研究相对较少。以往的心理语言学和计算方法忽视了时间维度，而许多文学隐喻与当代读者相隔数世纪。本研究旨在探究文学隐喻的处理成本是否随时间与文类变化。

Method: 研究训练了19世纪和21世纪意大利文学与非文学语料库的词嵌入模型（总计1.24亿词元），以515个19世纪文学隐喻的主题与载体之间的语义相似度作为隐喻处理需求的代理指标，分析其随时间与文类的变化。

Result: 语义相似度（即隐喻处理需求）整体随时间保持稳定。但文类起关键作用：现代文学语境中的隐喻（主题-载体相似度较低）比19世纪文学更难处理；而现代非文学语言（如网络语言）中的隐喻（相似度较高）比19世纪非文学文本更易处理。这一模式还受到隐喻个体词语的语义特征（如向量一致性和语义邻域密度）的影响。

Conclusion: 研究结果与意大利语更广泛的语言变化一致：现代文学的文体简化可能增加了隐喻处理需求，而网络语言的高创造性似乎使隐喻更易理解。历时分布语义学为研究文学隐喻的处理提供了有效工具。

Abstract: Metaphors are a distinctive feature of literary language, yet they remain less studied experimentally than everyday metaphors. Moreover, previous psycholinguistic and computational approaches overlooked the temporal dimension, although many literary metaphors were coined centuries apart from contemporary readers. This study innovatively applies tools from diachronic distributional semantics to assess whether the processing costs of literary metaphors varied over time and genre. Specifically, we trained word embeddings on literary and nonliterary Italian corpora from the 19th and 21st centuries, for a total of 124 million tokens, and modeled changes in the semantic similarity between topics and vehicles of 515 19th-century literary metaphors, taking this measure as a proxy of metaphor processing demands. Overall, semantic similarity, and hence metaphor processing demands, remained stable over time. However, genre played a key role: metaphors appeared more difficult (i.e., lower topic-vehicle similarity) in modern literary contexts than in 19th-century literature, but easier (i.e., higher topic-vehicle similarity) in today's nonliterary language (e.g., the Web) than in 19th-century nonliterary texts. This pattern was further shaped by semantic features of metaphors' individual terms, such as vector coherence and semantic neighborhood density. Collectively, these findings align with broader linguistic changes in Italian, such as the stylistic simplification of modern literature, which may have increased metaphor processing demands, and the high creativity of the Web's language, which seems to render metaphor more accessible.

</details>


### [13] [On Theoretically-Driven LLM Agents for Multi-Dimensional Discourse Analysis](https://arxiv.org/abs/2602.13713)
*Maciej Uberna,Michał Wawer,Jarosław A. Chudziak,Marcin Koszowy*

Main category: cs.CL

TL;DR: 本文提出一个多智能体框架，通过融入论证理论来提升LLM识别话语中重述策略功能的能力，在政治辩论数据集上验证了理论指导对功能感知分析的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM虽然能检测表层相似性，但难以捕捉重述的语用功能（如修辞作用），需要理论指导来超越单纯的释义检测，实现功能感知的论辩话语分析。

Method: 建立包含四种重述功能（弱化、强化、具体化、泛化及其他）的标注数据集，设计对比多智能体框架：一个通过RAG融入论证理论，另一个作为零样本基线，两者并行评估。

Result: RAG增强的智能体在所有指标上显著优于基线，尤其在检测强化和泛化功能上优势明显，整体宏F1分数提升近30%。

Conclusion: 理论指导不仅是有益的，而且是实现超越单纯释义检测、走向功能感知论辩话语分析的必要条件。多智能体架构为开发可扩展、理论指导的计算工具识别当代话语中的修辞策略迈出了重要一步。

Abstract: Identifying the strategic uses of reformulation in discourse remains a key challenge for computational argumentation. While LLMs can detect surface-level similarity, they often fail to capture the pragmatic functions of rephrasing, such as its role within rhetorical discourse. This paper presents a comparative multi-agent framework designed to quantify the benefits of incorporating explicit theoretical knowledge for this task. We utilise an dataset of annotated political debates to establish a new standard encompassing four distinct rephrase functions: Deintensification, Intensification, Specification, Generalisation, and Other, which covers all remaining types (D-I-S-G-O). We then evaluate two parallel LLM-based agent systems: one enhanced by argumentation theory via Retrieval-Augmented Generation (RAG), and an identical zero-shot baseline. The results reveal a clear performance gap: the RAG-enhanced agents substantially outperform the baseline across the board, with particularly strong advantages in detecting Intensification and Generalisation context, yielding an overall Macro F1-score improvement of nearly 30\%. Our findings provide evidence that theoretical grounding is not only beneficial but essential for advancing beyond mere paraphrase detection towards function-aware analysis of argumentative discourse. This comparative multi-agent architecture represents a step towards scalable, theoretically informed computational tools capable of identifying rhetorical strategies in contemporary discourse.

</details>


### [14] [RMPL: Relation-aware Multi-task Progressive Learning with Stage-wise Training for Multimedia Event Extraction](https://arxiv.org/abs/2602.13748)
*Yongkang Jin,Jianwen Luo,Jingjing Wang,Jianmin Yao,Yu Hong*

Main category: cs.CL

TL;DR: RMPL：一种面向低资源多媒体事件抽取的关系感知多任务渐进学习框架，通过整合单模态事件抽取和多媒体关系抽取的异构监督，在M2E2基准上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 多媒体事件抽取（MEE）需要跨文本和图像模态进行事件语义的关联，但现有方法面临两大挑战：1）缺乏标注训练数据（仅有M2E2评估基准）；2）现有方法（如跨模态对齐或提示）未能显式学习结构化事件表示，导致多模态场景下参数关联效果不佳。

Method: 提出RMPL框架，采用关系感知的多任务渐进学习策略：1）通过统一模式进行阶段式训练，学习跨模态共享的事件中心表示；2）整合单模态事件抽取和多媒体关系抽取的异构监督；3）使用混合文本和视觉数据对事件提及识别和参数角色抽取任务进行微调。

Result: 在M2E2基准上使用多个视觉语言模型（VLMs）进行实验，结果表明RMPL在不同模态设置下均取得了一致的性能提升。

Conclusion: RMPL通过显式学习结构化事件表示和整合多源监督，有效解决了低资源条件下多媒体事件抽取的挑战，为跨模态事件理解提供了新的解决方案。

Abstract: Multimedia Event Extraction (MEE) aims to identify events and their arguments from documents that contain both text and images. It requires grounding event semantics across different modalities. Progress in MEE is limited by the lack of annotated training data. M2E2 is the only established benchmark, but it provides annotations only for evaluation. This makes direct supervised training impractical. Existing methods mainly rely on cross-modal alignment or inference-time prompting with Vision--Language Models (VLMs). These approaches do not explicitly learn structured event representations and often produce weak argument grounding in multimodal settings. To address these limitations, we propose RMPL, a Relation-aware Multi-task Progressive Learning framework for MEE under low-resource conditions. RMPL incorporates heterogeneous supervision from unimodal event extraction and multimedia relation extraction with stage-wise training. The model is first trained with a unified schema to learn shared event-centric representations across modalities. It is then fine-tuned for event mention identification and argument role extraction using mixed textual and visual data. Experiments on the M2E2 benchmark with multiple VLMs show consistent improvements across different modality settings.

</details>


### [15] [Index Light, Reason Deep: Deferred Visual Ingestion for Visual-Dense Document Question Answering](https://arxiv.org/abs/2602.14162)
*Tao Xu*

Main category: cs.CL

TL;DR: 提出Deferred Visual Ingestion (DVI)框架，将视觉理解延迟到用户提问时进行，而非预先处理所有页面，大幅降低VLM成本并提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态文档问答方法采用预先处理策略，存在三个主要问题：1）成本高昂（长文档需要大量VLM token）；2）端到端不可靠（VLM输出可能因检索基础设施格式不匹配而失效）；3）失败后无法恢复。

Method: DVI采用需求侧处理策略：索引阶段仅进行轻量级元数据提取，将视觉理解推迟到用户提问时。核心原则是"索引用于定位而非理解"，通过结构化元数据索引和BM25全文搜索实现页面定位，然后将原始图像与具体问题发送给VLM进行针对性分析。

Result: 在两个真实工业工程图纸（113页+7页）上的实验表明：DVI在零VLM摄入成本下达到可比的总体准确率（46.7% vs. 48.9%），在视觉必要查询上的有效率达到50%（vs. 预处理的0%），页面定位成功率为100%（搜索空间压缩98%）。

Conclusion: DVI将"问答准确率"问题转化为"页面定位"问题，一旦找到正确的图纸页面，获取答案就变成了交互轮次问题。该方法支持交互式细化和渐进式缓存，为多模态文档问答提供了更经济可靠的解决方案。

Abstract: Existing multimodal document question answering methods universally adopt a supply-side ingestion strategy: running a Vision-Language Model (VLM) on every page during indexing to generate comprehensive descriptions, then answering questions through text retrieval. However, this "pre-ingestion" approach is costly (a 113-page engineering drawing package requires approximately 80,000 VLM tokens), end-to-end unreliable (VLM outputs may fail to be correctly retrieved due to format mismatches in the retrieval infrastructure), and irrecoverable once it fails. This paper proposes the Deferred Visual Ingestion (DVI) framework, adopting a demand-side ingestion strategy: the indexing phase performs only lightweight metadata extraction, deferring visual understanding to the moment users pose specific questions. DVI's core principle is "Index for locating, not understanding"--achieving page localization through structured metadata indexes and BM25 full-text search, then sending original images along with specific questions to a VLM for targeted analysis. Experiments on two real industrial engineering drawings (113 pages + 7 pages) demonstrate that DVI achieves comparable overall accuracy at zero ingestion VLM cost (46.7% vs. 48.9%), an effectiveness rate of 50% on visually necessary queries (vs. 0% for pre-ingestion), and 100% page localization (98% search space compression). DVI also supports interactive refinement and progressive caching, transforming the "QA accuracy" problem into a "page localization" problem--once the correct drawing page is found, obtaining the answer becomes a matter of interaction rounds.

</details>


### [16] [How Do Lexical Senses Correspond Between Spoken German and German Sign Language?](https://arxiv.org/abs/2602.13790)
*Melis Çelikkol,Wei Zhao*

Main category: cs.CL

TL;DR: 该研究构建了首个德语-德国手语跨模态语义对应标注数据集，通过分析词语使用到手语ID的映射关系，评估了精确匹配和语义相似度两种计算方法，发现语义相似度方法显著优于精确匹配。


<details>
  <summary>Details</summary>
Motivation: 现有双语词典在表示多义词和同形异义词到手语的映射时往往不足，需要基于使用的方法来识别词典中缺失的新映射关系，以丰富词典资源。

Method: 研究分析了德语和德国手语，手动标注了1,404个词语使用到手语ID的映射关系（来自德语词语使用图的32个词语和数字德国手语词典的49个手语）。识别了三种对应类型：一对多、多对一和一对一，以及无匹配情况。评估了精确匹配和基于SBERT嵌入的语义相似度两种计算方法。

Result: 语义相似度方法整体表现显著优于精确匹配（88.52% vs. 71.31%），特别在一对多映射类型上提升明显（+52.1个百分点）。研究建立了首个跨模态语义对应标注数据集，揭示了哪些对应模式可通过计算方法识别。

Conclusion: 该研究为跨模态语义对应分析提供了首个标注数据集和评估框架，展示了语义相似度方法在处理词语使用到手语映射问题上的优越性，特别适用于复杂的一对多映射情况，为手语词典编纂提供了新的计算工具。

Abstract: Sign language lexicographers construct bilingual dictionaries by establishing word-to-sign mappings, where polysemous and homonymous words corresponding to different signs across contexts are often underrepresented. A usage-based approach examining how word senses map to signs can identify such novel mappings absent from current dictionaries, enriching lexicographic resources. We address this by analyzing German and German Sign Language (Deutsche Gebärdensprache, DGS), manually annotating 1,404 word use-to-sign ID mappings derived from 32 words from the German Word Usage Graph (D-WUG) and 49 signs from the Digital Dictionary of German Sign Language (DW-DGS). We identify three correspondence types: Type 1 (one-to-many), Type 2 (many-to-one), and Type 3 (one-to-one), plus No Match cases. We evaluate computational methods: Exact Match (EM) and Semantic Similarity (SS) using SBERT embeddings. SS substantially outperforms EM overall 88.52% vs. 71.31%), with dramatic gains for Type 1 (+52.1 pp). Our work establishes the first annotated dataset for cross-modal sense correspondence and reveals which correspondence patterns are computationally identifiable. Our code and dataset are made publicly available.

</details>


### [17] [AD-Bench: A Real-World, Trajectory-Aware Advertising Analytics Benchmark for LLM Agents](https://arxiv.org/abs/2602.14257)
*Lingxiang Hu,Yiding Sun,Tianle Xia,Wenwei Li,Ming Xu,Liqun Liu,Peng Shu,Huan Yu,Jie Jiang*

Main category: cs.CL

TL;DR: AD-Bench是一个针对广告和营销分析场景的LLM智能体评估基准，基于真实业务需求构建，包含三个难度等级，实验显示即使最先进模型在复杂场景下仍存在显著能力差距。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体评估基准大多局限于理想化模拟，无法满足广告营销等专业领域的实际需求，这些领域的任务通常需要与专业营销工具进行多轮交互，现有基准无法充分评估智能体在这些复杂场景下的表现。

Method: 基于真实用户营销分析请求构建AD-Bench基准，由领域专家提供可验证的参考答案和相应的参考工具调用轨迹。将请求分为三个难度等级（L1-L3），以评估智能体在多轮、多工具协作场景下的能力。

Result: 在AD-Bench上，Gemini-3-Pro模型在Pass@1和Pass@3指标上分别达到68.0%和83.0%，但在L3难度下性能显著下降至49.4%和62.1%，轨迹覆盖率为70.1%，表明即使在最先进模型在复杂广告营销分析场景中仍存在显著能力差距。

Conclusion: AD-Bench为评估和改进广告营销智能体提供了一个现实的基准，揭示了当前LLM智能体在复杂专业场景中的局限性，为未来研究提供了重要的评估工具和方向。

Abstract: While Large Language Model (LLM) agents have achieved remarkable progress in complex reasoning tasks, evaluating their performance in real-world environments has become a critical problem. Current benchmarks, however, are largely restricted to idealized simulations, failing to address the practical demands of specialized domains like advertising and marketing analytics. In these fields, tasks are inherently more complex, often requiring multi-round interaction with professional marketing tools. To address this gap, we propose AD-Bench, a benchmark designed based on real-world business requirements of advertising and marketing platforms. AD-Bench is constructed from real user marketing analysis requests, with domain experts providing verifiable reference answers and corresponding reference tool-call trajectories. The benchmark categorizes requests into three difficulty levels (L1-L3) to evaluate agents' capabilities under multi-round, multi-tool collaboration. Experiments show that on AD-Bench, Gemini-3-Pro achieves Pass@1 = 68.0% and Pass@3 = 83.0%, but performance drops significantly on L3 to Pass@1 = 49.4% and Pass@3 = 62.1%, with a trajectory coverage of 70.1%, indicating that even state-of-the-art models still exhibit substantial capability gaps in complex advertising and marketing analysis scenarios. AD-Bench provides a realistic benchmark for evaluating and improving advertising marketing agents, the leaderboard and code can be found at https://github.com/Emanual20/adbench-leaderboard.

</details>


### [18] [OMGs: A multi-agent system supporting MDT decision-making across the ovarian tumour care continuum](https://arxiv.org/abs/2602.13793)
*Yangyang Zhang,Zilong Wang,Jianbo Xu,Yongqi Chen,Chu Han,Zhihao Zhang,Shuai Liu,Hui Li,Huiping Zhang,Ziqi Liu,Jiaxin Chen,Jun Zhu,Zheng Feng,Hao Wen,Xingzhu Ju,Yanping Zhong,Yunqiu Zhang,Jie Duan,Jun Li,Dongsheng Li,Weijie Wang,Haiyan Zhu,Wei Jiang,Xiaohua Wu,Shuo Wang,Haiming Li,Qinhao Guo*

Main category: cs.CL

TL;DR: OMGs是一个基于多智能体AI的卵巢肿瘤多学科智能代理系统，能够模拟MDT讨论并生成透明、有理据的临床建议，在资源有限环境中提供专业肿瘤学支持。


<details>
  <summary>Details</summary>
Motivation: 全球大多数卵巢肿瘤患者缺乏及时的多学科专家会诊（MDT），特别是在资源有限地区，MDT资源稀缺或不可用，导致治疗决策质量受限。

Method: 开发了OMGs多智能体AI框架，其中领域特定代理协同审议，整合多学科证据，生成MDT风格的建议并附带透明理据。使用SPEAR评估框架（安全性、个性化、证据、可操作性、鲁棒性）在多样化临床场景中验证系统性能。

Result: 在多中心重新评估中，OMGs表现与专家MDT共识相当（4.45±0.30 vs 4.53±0.23），证据得分更高（4.57 vs 3.92）。前瞻性多中心评估显示与常规MDT决策高度一致。在人类-AI配对研究中，OMGs显著提升了临床医生在证据和鲁棒性维度的建议质量。

Conclusion: 多智能体审议系统可以达到与专家MDT共识相当的性能，有潜力在资源有限环境中扩大专业肿瘤学知识的可及性，特别是在证据和鲁棒性方面能够增强临床决策。

Abstract: Ovarian tumour management has increasingly relied on multidisciplinary tumour board (MDT) deliberation to address treatment complexity and disease heterogeneity. However, most patients worldwide lack access to timely expert consensus, particularly in resource-constrained centres where MDT resources are scarce or unavailable. Here we present OMGs (Ovarian tumour Multidisciplinary intelligent aGent System), a multi-agent AI framework where domain-specific agents deliberate collaboratively to integrate multidisciplinary evidence and generate MDT-style recommendations with transparent rationales. To systematically evaluate MDT recommendation quality, we developed SPEAR (Safety, Personalization, Evidence, Actionability, Robustness) and validated OMGs across diverse clinical scenarios spanning the care continuum. In multicentre re-evaluation, OMGs achieved performance comparable to expert MDT consensus ($4.45 \pm 0.30$ versus $4.53 \pm 0.23$), with higher Evidence scores (4.57 versus 3.92). In prospective multicentre evaluation (59 patients), OMGs demonstrated high concordance with routine MDT decisions. Critically, in paired human-AI studies, OMGs most substantially enhanced clinicians' recommendations in Evidence and Robustness, the dimensions most compromised when multidisciplinary expertise is unavailable. These findings suggest that multi-agent deliberative systems can achieve performance comparable to expert MDT consensus, with potential to expand access to specialized oncology expertise in resource-limited settings.

</details>


### [19] [InnoEval: On Research Idea Evaluation as a Knowledge-Grounded, Multi-Perspective Reasoning Problem](https://arxiv.org/abs/2602.14367)
*Shuofei Qiao,Yunxiang Wei,Xuehai Wang,Bin Wu,Boyang Xue,Ningyu Zhang,Hossein A. Rahmani,Yanshan Wang,Qiang Zhang,Keyan Ding,Jeff Z. Pan,Huajun Chen,Emine Yilmaz*

Main category: cs.CL

TL;DR: InnoEval是一个深度创新评估框架，通过异构知识检索和多视角评审委员会来模拟人类水平的科学创意评估，解决了当前LLM评估方法存在的知识局限、维度单一和偏见问题。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型促进了科学创意的快速生成，但创意评估方法的发展相对滞后。现有方法存在知识视野狭窄、评估维度单一以及LLM作为评判者时的固有偏见等问题，无法满足科学评估所需的专业知识基础、集体审议和多标准决策需求。

Method: 1. 将创意评估视为基于知识的、多视角推理问题；2. 开发异构深度知识搜索引擎，从多样化的在线资源中检索和基于动态证据；3. 建立包含不同学术背景评审员的创新评审委员会，实现跨多个指标的多维度解耦评估。

Result: 实验表明，InnoEval在点对点、配对和群体评估任务中持续优于基线方法，展现出与人类专家高度一致的判断模式和共识。使用权威同行评审提交构建的综合数据集进行了基准测试。

Conclusion: InnoEval框架通过结合知识检索和多视角评审，有效解决了当前创意评估方法的局限性，实现了更接近人类专家水平的科学创意评估能力。

Abstract: The rapid evolution of Large Language Models has catalyzed a surge in scientific idea production, yet this leap has not been accompanied by a matching advance in idea evaluation. The fundamental nature of scientific evaluation needs knowledgeable grounding, collective deliberation, and multi-criteria decision-making. However, existing idea evaluation methods often suffer from narrow knowledge horizons, flattened evaluation dimensions, and the inherent bias in LLM-as-a-Judge. To address these, we regard idea evaluation as a knowledge-grounded, multi-perspective reasoning problem and introduce InnoEval, a deep innovation evaluation framework designed to emulate human-level idea assessment. We apply a heterogeneous deep knowledge search engine that retrieves and grounds dynamic evidence from diverse online sources. We further achieve review consensus with an innovation review board containing reviewers with distinct academic backgrounds, enabling a multi-dimensional decoupled evaluation across multiple metrics. We construct comprehensive datasets derived from authoritative peer-reviewed submissions to benchmark InnoEval. Experiments demonstrate that InnoEval can consistently outperform baselines in point-wise, pair-wise, and group-wise evaluation tasks, exhibiting judgment patterns and consensus highly aligned with human experts.

</details>


### [20] [The acquisition of English irregular inflections by Yemeni L1 Arabic learners: A Universal Grammar approach](https://arxiv.org/abs/2602.13816)
*Muneef Y. Alsawsh,Mohammed Q. Shormani*

Main category: cs.CL

TL;DR: 该研究采用普遍语法方法，探讨了也门英语学习者对英语不规则屈折形态的习得，重点关注一语迁移和二语发展影响，发现错误源于语际和语内因素，且适当输入和教学对成人二语习得至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨也门英语学习者如何习得英语不规则屈折形态，从普遍语法视角分析一语迁移和二语发展因素对习得过程的影响。

Method: 采用普遍语法框架下的特征重组假说，分析两个发展阶段的学习者错误，使用单因素方差分析进行统计检验。

Result: 阶段1数据显示一语迁移主导影响，阶段2显示学习者对普遍语法属性敏感性增加，错误源于语际和语内因素，统计显示阶段1到阶段2不规则屈折形态产出显著改善，但辅音变化、零语素和-a复数形态仍存在困难。

Conclusion: 虽然一语迁移和二语发展因素影响习得初期，但适当的语言输入和教学对促进成人二语学习者普遍语法驱动的特征重组至关重要，有限暴露和低质量教学会限制普遍语法的完全通达。

Abstract: This study examines the acquisition of English irregular inflections by Yemeni learners of English as a second language (L2), utilizing a Universal Grammar (UG) approach. Within the UG approach, the study considers Feature Reassembly Hypothesis (FRH) (Lardiere, 2008, 2009) part of UG, focusing on the roles of first language (L1) transfer and L2 developmental influence. It analyzes learner errors across two developmental stages. Stage 1 data reveal a dominant influence of L1 transfer, particularly in phonological and structural mismatches, while stage 2 data demonstrate increased learner sensitivity to UG properties and morphological reconfiguration toward the target language. Findings reveal that errors in irregular inflectional morphology are attributed to both interlingual and intralingual sources, with overgeneralization of L2 rules as a common developmental strategy. Statistical analysis, including a one-way ANOVA, indicates significant improvement in the production of well-formed irregular inflections from stage 1 to stage 2, underscoring learners' continued access to UG. However, persistent difficulties with consonant change, zero-morpheme, and -a plural inflections suggest that limited exposure, ineffective input modeling, and insufficient instructional quality constrain full UG access. The study concludes that while L1 transfer and L2 developmental factors influence initial stages of acquisition, appropriate linguistic input and instruction are critical for facilitating UG-driven feature reassembly in adult L2 learners.

</details>


### [21] [Query as Anchor: Scenario-Adaptive User Representation via Large Language Model](https://arxiv.org/abs/2602.14492)
*Jiahao Yuan,Yike Xu,Jinyong Wen,Baokun Wang,Ziyi Gao,Xiaotong Lin,Yun Liu,Xing Fu,Yu Cheng,Yongchao Liu,Weiqiang Wang,Zhongle Xie*

Main category: cs.CL

TL;DR: 提出Query-as-Anchor框架，将用户建模从静态编码转向基于查询的动态合成，通过多模态行为对齐和双塔LLM架构实现查询感知的用户表示，在工业场景中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 工业级用户表示学习需要在鲁棒通用性和任务敏感性之间取得平衡。现有方法主要产生静态、任务无关的嵌入，难以在统一向量空间中协调下游场景的不同需求，且异构多源数据引入噪声和模态冲突，降低表示质量。

Method: 1. 构建UserU工业级预训练数据集，对齐多模态行为序列与用户理解语义；2. 提出Q-Anchor Embedding架构，通过分层粗到细编码器集成到双塔大语言模型，采用联合对比自回归优化实现查询感知用户表示；3. 引入基于聚类的软提示调优，增强判别性潜在结构；4. 部署时在序列末端锚定查询，实现KV缓存加速推理。

Result: 在10个支付宝工业基准测试中取得一致的SOTA性能，展示强大可扩展性和高效部署能力。在支付宝生产系统的两个真实场景中进行大规模在线A/B测试，验证了实际有效性。

Conclusion: Query-as-Anchor框架成功解决了工业级用户表示学习中静态嵌入的局限性，通过动态查询感知合成实现了通用性与任务敏感性的平衡，在工业场景中表现出卓越性能和实用价值。

Abstract: Industrial-scale user representation learning requires balancing robust universality with acute task-sensitivity. However, existing paradigms primarily yield static, task-agnostic embeddings that struggle to reconcile the divergent requirements of downstream scenarios within unified vector spaces. Furthermore, heterogeneous multi-source data introduces inherent noise and modality conflicts, degrading representation. We propose Query-as-Anchor, a framework shifting user modeling from static encoding to dynamic, query-aware synthesis. To empower Large Language Models (LLMs) with deep user understanding, we first construct UserU, an industrial-scale pre-training dataset that aligns multi-modal behavioral sequences with user understanding semantics, and our Q-Anchor Embedding architecture integrates hierarchical coarse-to-fine encoders into dual-tower LLMs via joint contrastive-autoregressive optimization for query-aware user representation. To bridge the gap between general pre-training and specialized business logic, we further introduce Cluster-based Soft Prompt Tuning to enforce discriminative latent structures, effectively aligning model attention with scenario-specific modalities. For deployment, anchoring queries at sequence termini enables KV-cache-accelerated inference with negligible incremental latency. Evaluations on 10 Alipay industrial benchmarks show consistent SOTA performance, strong scalability, and efficient deployment. Large-scale online A/B testing in Alipay's production system across two real-world scenarios further validates its practical effectiveness. Our code is prepared for public release and will be available at: https://github.com/JhCircle/Q-Anchor.

</details>


### [22] [Beyond Words: Evaluating and Bridging Epistemic Divergence in User-Agent Interaction via Theory of Mind](https://arxiv.org/abs/2602.13832)
*Minyuan Ruan,Ziyue Wang,Kaiming Liu,Yunghwei Lai,Peng Li,Yang Liu*

Main category: cs.CL

TL;DR: 本文提出了一个评估大语言模型心智理论能力的基准，发现现有模型在检测和解决用户信念与环境状态之间的认知差距方面存在显著限制，并通过强化学习训练改进了模型在理解用户心理状态方面的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型发展迅速且应用广泛，但当用户意图和指令表达不准确时，它们仍然难以理解并回应用户的真实需求，导致用户主观信念与环境真实状态之间存在认知差距。现有心智理论评估主要关注孤立的信念推断，忽视了其在真实交互中的功能性价值。

Method: 将大语言模型的心智理论形式化为认知差距检测和解决的机制，并提出了一个基准测试来评估模型如何在实际中协调用户信念和背景信息。进一步构建了一个基于轨迹的心智理论数据集，将信念追踪与任务相关状态推断联系起来，通过强化学习训练模型。

Result: 对11个领先模型的评估显示，它们在识别阻碍任务成功的潜在认知差距方面存在显著限制。通过强化学习在构建的数据集上训练的模型，在推理用户心理状态方面表现出一致的改进，并提升了下游任务性能。

Conclusion: 心智理论应被视为一种基本的交互层面机制，而非独立的推理技能。这项工作强调了心智理论在实际应用中的价值，并为改进大语言模型理解用户需求的能力提供了新途径。

Abstract: Large Language Models (LLMs) have developed rapidly and are widely applied to both general-purpose and professional tasks to assist human users. However, they still struggle to comprehend and respond to the true user needs when intentions and instructions are imprecisely conveyed, leading to a divergence between subjective user believes and true environment states. Resolving this epistemic divergence requires Theory of Mind (ToM), yet existing ToM evaluations for LLMs primarily focus on isolated belief inference, overlooking its functional utility in real-world interaction. To this end, we formalize ToM for LLMs as a mechanism for epistemic divergence detection and resolution, and propose a benchmark, \benchname, to assess how models reconcile user beliefs and profiles in practice. Results across 11 leading models reveal a significant limitation to identify underlying cognitive gaps that impede task success. To bridge this gap, we further curate a trajectory-based ToM dataset linking belief tracking with task-related state inference. The model trained on this data via reinforcement learning shows consistent improvement in reasoning about user mental states, leading to enhanced downstream performance. Our work highlights the practical value of ToM as an essential interaction-level mechanism rather than as a standalone reasoning skill.

</details>


### [23] [Learning User Interests via Reasoning and Distillation for Cross-Domain News Recommendation](https://arxiv.org/abs/2602.15005)
*Mengdan Zhu,Yufan Zhao,Tao Di,Yulan Yan,Liang Zhao*

Main category: cs.CL

TL;DR: 使用强化学习框架训练大语言模型，从跨域用户信号生成高质量的兴趣驱动新闻搜索查询列表，通过蒸馏技术实现可扩展部署。


<details>
  <summary>Details</summary>
Motivation: 跨域新闻推荐需要从异质信号中推断用户的深层信息需求，现有方法难以捕捉可重用的深层用户兴趣，同时保持大规模生产系统的可扩展性。

Method: 提出强化学习框架，将查询列表生成建模为策略优化问题，使用GRPO算法配合多奖励信号。系统研究计算维度：推理时采样和模型容量，并通过策略蒸馏将大教师模型的知识迁移到紧凑学生模型。

Result: 离线实验、消融研究和大规模在线A/B测试均显示，在兴趣建模质量和下游推荐性能方面取得一致提升，计算增加带来的改进呈现类似缩放规律。

Conclusion: 该强化学习框架能有效从跨域信号中捕捉深层用户兴趣，通过策略蒸馏实现高质量兴趣建模的可扩展部署，显著提升新闻推荐系统性能。

Abstract: News recommendation plays a critical role in online news platforms by helping users discover relevant content. Cross-domain news recommendation further requires inferring user's underlying information needs from heterogeneous signals that often extend beyond direct news consumption. A key challenge lies in moving beyond surface-level behaviors to capture deeper, reusable user interests while maintaining scalability in large-scale production systems. In this paper, we present a reinforcement learning framework that trains large language models to generate high-quality lists of interest-driven news search queries from cross-domain user signals. We formulate query-list generation as a policy optimization problem and employ GRPO with multiple reward signals. We systematically study two compute dimensions: inference-time sampling and model capacity, and empirically observe consistent improvements with increased compute that exhibit scaling-like behavior. Finally, we perform on-policy distillation to transfer the learned policy from a large, compute-intensive teacher to a compact student model suitable for scalable deployment. Extensive offline experiments, ablation studies and large-scale online A/B tests in a production news recommendation system demonstrate consistent gains in both interest modeling quality and downstream recommendation performance.

</details>


### [24] [Speculative Decoding with a Speculative Vocabulary](https://arxiv.org/abs/2602.13836)
*Miles Williams,Young D. Kwon,Rui Li,Alexandros Kouris,Stylianos I. Venieris*

Main category: cs.CL

TL;DR: SpecVocab：一种通过动态选择词汇子集来提升推测解码效率的新方法，相比现有方法能获得更高的接受长度和吞吐量提升


<details>
  <summary>Details</summary>
Motivation: 当前推测解码方法中，小规模草稿模型的输出分布计算成为瓶颈。现有方法通过减少词汇表来加速，但这会导致目标标记超出词汇表时推测效果下降。

Method: 提出SpecVocab方法，在每一步解码时动态选择词汇子集，而不是使用固定的缩减词汇表。这种方法能更高效地进行词汇推测。

Result: 在各种任务上，SpecVocab比当前最先进的推测解码方法EAGLE-3获得更高的接受长度，平均吞吐量提升高达8.1%。

Conclusion: 词汇推测是比缩减词汇表更有效的替代方案，SpecVocab通过动态选择词汇子集在保持推测效果的同时提升了推理效率。

Abstract: Speculative decoding has rapidly emerged as a leading approach for accelerating language model (LM) inference, as it offers substantial speedups while yielding identical outputs. This relies upon a small draft model, tasked with predicting the outputs of the target model. State-of-the-art speculative decoding methods use a draft model consisting of a single decoder layer and output embedding matrix, with the latter dominating drafting time for the latest LMs. Recent work has sought to address this output distribution bottleneck by reducing the vocabulary of the draft model. Although this can improve throughput, it compromises speculation effectiveness when the target token is out-of-vocabulary. In this paper, we argue for vocabulary speculation as an alternative to a reduced vocabulary. We propose SpecVocab, an efficient and effective method that selects a vocabulary subset per decoding step. Across a variety of tasks, we demonstrate that SpecVocab can achieve a higher acceptance length than state-of-the-art speculative decoding approach, EAGLE-3. Notably, this yields up to an 8.1% increase in average throughput over EAGLE-3.

</details>


### [25] [PrivAct: Internalizing Contextual Privacy Preservation via Multi-Agent Preference Training](https://arxiv.org/abs/2602.13840)
*Yuhan Cheng,Hancheng Ye,Hai Helen Li,Jingwei Sun,Yiran Chen*

Main category: cs.CL

TL;DR: PrivAct是一个基于上下文隐私感知的多智能体学习框架，通过将隐私偏好内化到智能体模型中，实现隐私合规的智能体行为，在保持帮助性的同时减少隐私泄露。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在处理个性化任务时涉及敏感信息，现有方法依赖外部干预，存在脆弱性、场景特定性，并可能扩大隐私攻击面。需要一种能够内化上下文隐私保护的方法。

Method: 提出PrivAct框架，将隐私偏好嵌入到每个智能体中，通过多智能体学习直接内化上下文隐私保护到模型生成行为中，实现隐私合规的智能体行动。

Result: 在多个LLM主干网络和基准测试中，PrivAct在上下文隐私保护方面表现一致改进，泄露率降低高达12.32%，同时保持相当的帮助性，并具有零样本泛化能力和对不同多智能体拓扑的鲁棒性。

Conclusion: PrivAct通过内化隐私偏好到智能体模型中，有效增强了系统范围的上下文完整性，实现了更好的隐私-帮助性权衡，为隐私敏感的LLM智能体应用提供了实用解决方案。

Abstract: Large language model (LLM) agents are increasingly deployed in personalized tasks involving sensitive, context-dependent information, where privacy violations may arise in agents' action due to the implicitness of contextual privacy. Existing approaches rely on external, inference-time interventions which are brittle, scenario-specific, and may expand the privacy attack surface. We propose PrivAct, a contextual privacy-aware multi-agent learning framework that internalizes contextual privacy preservation directly into models' generation behavior for privacy-compliant agentic actions. By embedding privacy preferences into each agent, PrivAct enhances system-wide contextual integrity while achieving a more favorable privacy-helpfulness tradeoff. Experiments across multiple LLM backbones and benchmarks demonstrate consistent improvements in contextual privacy preservation, reducing leakage rates by up to 12.32% while maintaining comparable helpfulness, as well as zero-shot generalization and robustness across diverse multi-agent topologies. Code is available at https://github.com/chengyh23/PrivAct.

</details>


### [26] [Tutoring Large Language Models to be Domain-adaptive, Precise, and Safe](https://arxiv.org/abs/2602.13860)
*Somnath Banerjee*

Main category: cs.CL

TL;DR: 提出"负责任智能"框架，将大语言模型的生成能力与真实世界部署的严格要求相结合，关注领域适应、伦理安全和多语言文化对齐


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型成为人工智能的变革性力量，需要超越通用架构，开发具有情境感知、内在安全和尊重全球文化差异的系统

Method: 方法轨迹从用于任务特定需求的经典监督适应，到用于安全性的解码时对齐，最后利用人类反馈和偏好建模实现社会语言敏锐度

Result: 研究提出了一个包含三个相互关联线程的负责任智能框架：领域适应确保技术精确性、伦理严谨性缓解对抗性漏洞、文化/多语言对齐促进全球包容性

Conclusion: 需要开发负责任智能框架来协调大语言模型的强大生成能力与现实世界部署的严格要求，确保系统具有情境感知、内在安全和全球文化敏感性

Abstract: The overarching research direction of this work is the development of a ''Responsible Intelligence'' framework designed to reconcile the immense generative power of Large Language Models (LLMs) with the stringent requirements of real-world deployment. As these models become a transformative force in artificial intelligence, there is an urgent need to move beyond general-purpose architectures toward systems that are contextually aware, inherently safer, and deeply respectful of global cultural nuances. This research navigates three interconnected threads: domain adaptation to ensure technical precision, ethical rigor to mitigate adversarial vulnerabilities, and cultural/multilingual alignment to promote global inclusivity. The methodological trajectory moves from classical supervised adaptation for task-specific demands to decoding-time alignment for safety, finally leveraging human feedback and preference modeling to achieve sociolinguistic acuity.

</details>


### [27] [Bridging the Multilingual Safety Divide: Efficient, Culturally-Aware Alignment for Global South Languages](https://arxiv.org/abs/2602.13867)
*Somnath Banerjee,Rima Hazra,Animesh Mukherjee*

Main category: cs.CL

TL;DR: 大语言模型在全球南方部署时面临安全挑战，现有安全机制主要针对英语和高资源语言，在低资源语言、语码混合和文化特定语境中效果不佳，需要建立更包容的多语言安全框架。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在全球南方部署时面临安全评估的局限性：安全管道、基准测试和对齐主要针对英语和少数高资源语言，假设安全性和事实性可以跨语言"转移"，但证据表明这种假设不成立，导致对低资源语言、语码混合输入和文化特定规范的忽视。

Method: 论文综合了近期研究发现：(1) 分析安全护栏在低资源和语码混合输入上的表现；(2) 评估文化有害行为在标准毒性评分可接受时的持续性；(3) 测试英语知识编辑和安全补丁在低资源语言中的转移效果。

Result: 研究发现：(i) 安全护栏在低资源和语码混合输入上显著减弱；(ii) 文化有害行为在标准毒性评分可接受时仍持续存在；(iii) 英语知识编辑和安全补丁常无法有效转移到低资源语言。

Conclusion: 提出面向全球南方研究者和学生的实践议程：参数高效的安全引导、基于文化的评估和偏好数据、赋予当地社区定义和减轻伤害的参与式工作流程，旨在使多语言安全成为平等AI的核心要求而非附加功能。

Abstract: Large language models (LLMs) are being deployed across the Global South, where everyday use involves low-resource languages, code-mixing, and culturally specific norms. Yet safety pipelines, benchmarks, and alignment still largely target English and a handful of high-resource languages, implicitly assuming safety and factuality ''transfer'' across languages. Evidence increasingly shows they do not. We synthesize recent findings indicating that (i) safety guardrails weaken sharply on low-resource and code-mixed inputs, (ii) culturally harmful behavior can persist even when standard toxicity scores look acceptable, and (iii) English-only knowledge edits and safety patches often fail to carry over to low-resource languages. In response, we outline a practical agenda for researchers and students in the Global South: parameter-efficient safety steering, culturally grounded evaluation and preference data, and participatory workflows that empower local communities to define and mitigate harm. Our aim is to make multilingual safety a core requirement-not an add-on-for equitable AI in underrepresented regions.

</details>


### [28] [ADAB: Arabic Dataset for Automated Politeness Benchmarking -- A Large-Scale Resource for Computational Sociopragmatics](https://arxiv.org/abs/2602.13870)
*Hend Al-Khalifa,Nadia Ghezaiel,Maria Bounnit,Hend Hamed Alhazmi,Noof Abdullah Alfear,Reem Fahad Alqifari,Ameera Masoud Almasoud,Sharefah Ahmed Al-Ghamdi*

Main category: cs.CL

TL;DR: ADAB是一个新的阿拉伯语礼貌数据集，包含10,000个样本，涵盖多种阿拉伯语变体，用于礼貌检测研究。


<details>
  <summary>Details</summary>
Motivation: 尽管阿拉伯语中蕴含丰富复杂的礼貌表达，但阿拉伯语礼貌检测资源仍然不足，需要建立专门的数据集来支持文化感知的自然语言处理系统。

Method: 从四个在线平台收集数据，涵盖社交媒体、电子商务和客服领域，基于阿拉伯语语言传统和语用理论进行标注，分为礼貌、不礼貌和中性三类，包含16个礼貌类别的语言特征标注。

Result: 创建了包含10,000个样本的ADAB数据集，标注者间一致性较高（kappa=0.703），并测试了40种模型配置，包括传统机器学习、基于Transformer的模型和大语言模型。

Conclusion: ADAB数据集填补了阿拉伯语礼貌检测资源的空白，为阿拉伯语NLP中的礼貌感知研究提供了重要支持。

Abstract: The growing importance of culturally-aware natural language processing systems has led to an increasing demand for resources that capture sociopragmatic phenomena across diverse languages. Nevertheless, Arabic-language resources for politeness detection remain under-explored, despite the rich and complex politeness expressions embedded in Arabic communication. In this paper, we introduce ADAB (Arabic Politeness Dataset), a new annotated Arabic dataset collected from four online platforms, including social media, e-commerce, and customer service domains, covering Modern Standard Arabic and multiple dialects (Gulf, Egyptian, Levantine, and Maghrebi). The dataset was annotated based on Arabic linguistic traditions and pragmatic theory, resulting in three classes: polite, impolite, and neutral. It contains 10,000 samples with linguistic feature annotations across 16 politeness categories and achieves substantial inter-annotator agreement (kappa = 0.703). We benchmark 40 model configurations, including traditional machine learning, transformer-based models, and large language models. The dataset aims to support research on politeness-aware Arabic NLP.

</details>


### [29] [Evaluating Prompt Engineering Techniques for RAG in Small Language Models: A Multi-Hop QA Approach](https://arxiv.org/abs/2602.13890)
*Amir Hossein Mohammadi,Ali Moeinian,Zahra Razavizade,Afsaneh Fatemi,Reza Ramezani*

Main category: cs.CL

TL;DR: 本文通过大规模实证研究，评估了24种不同提示模板在SLM-RAG系统上的性能，发现优化提示模板能在多跳问答任务中带来高达83-84.5%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 虽然检索增强生成(RAG)被广泛研究用于大语言模型，但在小语言模型(SLMs)上的优化仍存在研究空白，特别是在需要复杂推理的多跳问答任务中。提示模板设计是影响性能的关键但未被充分探索的因素。

Method: 在HotpotQA数据集上进行大规模实证研究，评估24种不同提示模板（包括标准RAG提示、9种文献中的成熟技术、14种新颖混合变体），在两个主流SLM（Qwen2.5-3B Instruct和Gemma3-4B-It）上测试18720个实例。

Result: 研究结果显示显著性能提升：Qwen2.5模型最高提升83%，Gemma3-4B-It模型最高提升84.5%，相比标准RAG提示，两种模型都能获得高达6%的改进。

Conclusion: 该研究为设计高效SLM-RAG系统提示提供了具体分析和可操作建议，特别是在资源受限环境中部署时，提示模板优化能显著提升多跳问答性能。

Abstract: Retrieval Augmented Generation (RAG) is a powerful approach for enhancing the factual grounding of language models by integrating external knowledge. While widely studied for large language models, the optimization of RAG for Small Language Models (SLMs) remains a critical research gap, particularly in complex, multi-hop question-answering tasks that require sophisticated reasoning. In these systems, prompt template design is a crucial yet under-explored factor influencing performance. This paper presents a large-scale empirical study to investigate this factor, evaluating 24 different prompt templates on the HotpotQA dataset. The set includes a standard RAG prompt, nine well-formed techniques from the literature, and 14 novel hybrid variants, all tested on two prominent SLMs: Qwen2.5-3B Instruct and Gemma3-4B-It. Our findings, based on a test set of 18720 instances, reveal significant performance gains of up to 83% on Qwen2.5 and 84.5% on Gemma3-4B-It, yielding an improvement of up to 6% for both models compared to the Standard RAG prompt. This research also offers concrete analysis and actionable recommendations for designing effective and efficient prompts for SLM-based RAG systems, practically for deployment in resource-constrained environments.

</details>


### [30] [Pre-Editorial Normalization for Automatically Transcribed Medieval Manuscripts in Old French and Latin](https://arxiv.org/abs/2602.13905)
*Thibault Clérice,Rachel Bawden,Anthony Glaise,Ariane Pinche,David Smith*

Main category: cs.CL

TL;DR: 提出预编辑规范化(PEN)任务，将字形ATR输出转换为符合编辑规范的文本，在保持古文字保真度的同时提供实用化版本，并创建了相关数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 当前自动文本识别(ATR)存在方法学鸿沟：古文字转录模型输出难以被普通读者和下游NLP工具使用，而规范化模型又存在领域适应性差、过度规范化等问题，导致可用性差距。

Method: 1. 形式化定义预编辑规范化(PEN)任务；2. 从CoMMA语料库创建新数据集，使用passim与数字化古法语和拉丁语版本对齐；3. 制作人工校正的金标准评估集；4. 使用基于ByT5的序列到序列模型进行规范化和预标注任务基准测试。

Result: 1. 创建了包含466万样本的银标准训练语料库和1800样本的金标准评估集；2. 规范化模型达到6.7%的字符错误率(CER)，显著优于该任务先前模型。

Conclusion: PEN任务有效弥合了古文字转录与数字编辑之间的鸿沟，在保持古文字保真度的同时提高了ATR输出的实用性，为历史档案的数字化处理提供了新方法。

Abstract: Recent advances in Automatic Text Recognition (ATR) have improved access to historical archives, yet a methodological divide persists between palaeographic transcriptions and normalized digital editions. While ATR models trained on more palaeographically-oriented datasets such as CATMuS have shown greater generalizability, their raw outputs remain poorly compatible with most readers and downstream NLP tools, thus creating a usability gap. On the other hand, ATR models trained to produce normalized outputs have been shown to struggle to adapt to new domains and tend to over-normalize and hallucinate. We introduce the task of Pre-Editorial Normalization (PEN), which consists in normalizing graphemic ATR output according to editorial conventions, which has the advantage of keeping an intermediate step with palaeographic fidelity while providing a normalized version for practical usability. We present a new dataset derived from the CoMMA corpus and aligned with digitized Old French and Latin editions using passim. We also produce a manually corrected gold-standard evaluation set. We benchmark this resource using ByT5-based sequence-to-sequence models on normalization and pre-annotation tasks. Our contributions include the formal definition of PEN, a 4.66M-sample silver training corpus, a 1.8k-sample gold evaluation set, and a normalization model achieving a 6.7% CER, substantially outperforming previous models for this task.

</details>


### [31] [HLE-Verified: A Systematic Verification and Structured Revision of Humanity's Last Exam](https://arxiv.org/abs/2602.13964)
*Weiqi Zhai,Zhihai Wang,Jinghang Wang,Boyu Yang,Xiaogang Li,Xiang Xu,Bohan Wang,Peng Wang,Xingzhe Wu,Anfeng Li,Qiyuan Feng,Yuhao Zhou,Shoulin Han,Wenjie Luo,Yiyuan Li,Yaxuan Wang,Ruixian Luo,Guojie Lin,Peiyao Xiao,Chengliang Xu,Ben Wang,Zeyu Wang,Zichao Chen,Jianan Ye,Yijie Hu,Jialong Chen,Zongwen Shen,Yuliang Xu,An Yang,Bowen Yu,Dayiheng Liu,Junyang Lin,Hu Wei,Que Shen,Bing Zhao*

Main category: cs.CL

TL;DR: 论文提出了HLE-Verified，这是一个经过验证和修订的HLE基准版本，通过两阶段验证修复工作流程，减少了原始HLE中的噪声问题，使模型评估更加准确可靠。


<details>
  <summary>Details</summary>
Motivation: 原始HLE基准包含大量噪声项，这些噪声会扭曲评估结果和模型间比较，需要创建一个经过验证的更可靠基准。

Method: 采用两阶段验证修复工作流程：第一阶段通过领域专家评审和模型交叉检查进行二元验证；第二阶段对可修复项在严格约束下进行修订，包括双独立专家修复、模型辅助审计和最终裁决。

Result: 创建了包含641个验证项和1,170个修订认证项的HLE-Verified基准，在7个最先进语言模型上测试显示平均绝对准确率提升7-10个百分点，在原始问题有误的项上提升30-40个百分点。

Conclusion: HLE-Verified通过减少标注噪声，提高了HLE风格评估的可靠性，使模型能力测量更加准确，并揭示了模型置信度与问题/答案错误之间的强关联性。

Abstract: Humanity's Last Exam (HLE) has become a widely used benchmark for evaluating frontier large language models on challenging, multi-domain questions. However, community-led analyses have raised concerns that HLE contains a non-trivial number of noisy items, which can bias evaluation results and distort cross-model comparisons. To address this challenge, we introduce HLE-Verified, a verified and revised version of HLE with a transparent verification protocol and fine-grained error taxonomy. Our construction follows a two-stage validation-and-repair workflow resulting in a certified benchmark. In Stage I, each item undergoes binary validation of the problem and final answer through domain-expert review and model-based cross-checks, yielding 641 verified items. In Stage II, flawed but fixable items are revised under strict constraints preserving the original evaluation intent, through dual independent expert repairs, model-assisted auditing, and final adjudication, resulting in 1,170 revised-and-certified items. The remaining 689 items are released as a documented uncertain set with explicit uncertainty sources and expertise tags for future refinement. We evaluate seven state-of-the-art language models on HLE and HLE-Verified, observing an average absolute accuracy gain of 7--10 percentage points on HLE-Verified. The improvement is particularly pronounced on items where the original problem statement and/or reference answer is erroneous, with gains of 30--40 percentage points. Our analyses further reveal a strong association between model confidence and the presence of errors in the problem statement or reference answer, supporting the effectiveness of our revisions. Overall, HLE-Verified improves HLE-style evaluations by reducing annotation noise and enabling more faithful measurement of model capabilities. Data is available at: https://github.com/SKYLENAGE-AI/HLE-Verified

</details>


### [32] [Chain-of-Thought Reasoning with Large Language Models for Clinical Alzheimer's Disease Assessment and Diagnosis](https://arxiv.org/abs/2602.13979)
*Tongze Zhang,Jun-En Ding,Melik Ozolcer,Fang-Ming Hung,Albert Chih-Chieh Yang,Feng Liu,Yi-Rou Ji,Sang Won Bae*

Main category: cs.CL

TL;DR: 利用大语言模型对阿尔茨海默病患者电子健康记录进行思维链推理，通过显式诊断逻辑提升AD评估的稳定性和诊断性能。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病诊断依赖医学影像和临床评估，耗时耗力。大语言模型在医疗领域应用增多，但在AD评估中应用有限，因为AD涉及复杂的多因素病因，难以通过影像直接观察。

Method: 提出利用LLM对患者临床EHR进行思维链推理的方法。不同于直接在EHR数据上微调LLM进行分类，该方法使用LLM生成的CoT推理路径为AD评估提供显式诊断逻辑，然后进行基于CoT的结构化预测。

Result: 实验结果表明，提出的基于CoT的诊断框架在多个CDR分级任务中显著提升了稳定性和诊断性能，与零样本基线方法相比，F1分数最高提升了15%。

Conclusion: 基于思维链推理的LLM方法不仅增强了模型诊断内在复杂因素的能力，还提高了AD进展不同阶段预测过程的可解释性。

Abstract: Alzheimer's disease (AD) has become a prevalent neurodegenerative disease worldwide. Traditional diagnosis still relies heavily on medical imaging and clinical assessment by physicians, which is often time-consuming and resource-intensive in terms of both human expertise and healthcare resources. In recent years, large language models (LLMs) have been increasingly applied to the medical field using electronic health records (EHRs), yet their application in Alzheimer's disease assessment remains limited, particularly given that AD involves complex multifactorial etiologies that are difficult to observe directly through imaging modalities. In this work, we propose leveraging LLMs to perform Chain-of-Thought (CoT) reasoning on patients' clinical EHRs. Unlike direct fine-tuning of LLMs on EHR data for AD classification, our approach utilizes LLM-generated CoT reasoning paths to provide the model with explicit diagnostic rationale for AD assessment, followed by structured CoT-based predictions. This pipeline not only enhances the model's ability to diagnose intrinsically complex factors but also improves the interpretability of the prediction process across different stages of AD progression. Experimental results demonstrate that the proposed CoT-based diagnostic framework significantly enhances stability and diagnostic performance across multiple CDR grading tasks, achieving up to a 15% improvement in F1 score compared to the zero-shot baseline method.

</details>


### [33] [The Sufficiency-Conciseness Trade-off in LLM Self-Explanation from an Information Bottleneck Perspective](https://arxiv.org/abs/2602.14002)
*Ali Zahedzadeh,Behnam Bahrak*

Main category: cs.CL

TL;DR: LLM解释并非越长越好，压缩解释长度往往能保持答案准确性，但过度压缩会导致性能下降


<details>
  <summary>Details</summary>
Motivation: 大型语言模型依赖自我解释（如思维链推理）来提高多步问答性能，但这些解释通常冗长且生成成本高，需要研究多少解释才是真正必要的

Method: 基于信息瓶颈原则，将解释视为压缩表示；引入评估流程，限制解释长度并使用多个语言模型在ARC Challenge数据集上评估充分性；在英语和波斯语两种语言中进行实验

Result: 实验表明，更简洁的解释通常仍然充分，能在保持准确性的同时显著减少解释长度，但过度压缩会导致性能下降

Conclusion: 在解释的充分性和简洁性之间存在权衡，适当的压缩可以保持性能同时降低成本，为资源有限的语言和高效推理提供了实用方法

Abstract: Large Language Models increasingly rely on self-explanations, such as chain of thought reasoning, to improve performance on multi step question answering. While these explanations enhance accuracy, they are often verbose and costly to generate, raising the question of how much explanation is truly necessary. In this paper, we examine the trade-off between sufficiency, defined as the ability of an explanation to justify the correct answer, and conciseness, defined as the reduction in explanation length. Building on the information bottleneck principle, we conceptualize explanations as compressed representations that retain only the information essential for producing correct answers.To operationalize this view, we introduce an evaluation pipeline that constrains explanation length and assesses sufficiency using multiple language models on the ARC Challenge dataset. To broaden the scope, we conduct experiments in both English, using the original dataset, and Persian, as a resource-limited language through translation. Our experiments show that more concise explanations often remain sufficient, preserving accuracy while substantially reducing explanation length, whereas excessive compression leads to performance degradation.

</details>


### [34] [Named Entity Recognition for Payment Data Using NLP](https://arxiv.org/abs/2602.14009)
*Srikumar Nayak*

Main category: cs.CL

TL;DR: 该论文提出了一种名为PaymentBERT的新型混合架构，用于支付数据中的命名实体识别，在50,000条支付交易数据上实现了95.7%的F1分数，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 命名实体识别在金融交易处理自动化中至关重要，特别是从非结构化支付数据中提取结构化信息。金融行业需要高效的实体提取技术来支持自动化制裁筛查、反洗钱合规和支付处理系统。

Method: 1. 全面分析了最先进的NER算法，包括CRF、BiLSTM-CRF和基于transformer的模型（BERT、FinBERT）；2. 在包含SWIFT MT103、ISO 20022和国内支付系统的50,000条标注支付交易数据集上进行实验；3. 提出了PaymentBERT，一种结合领域特定金融嵌入和上下文表示的新型混合架构。

Result: 1. 微调的BERT模型在实体提取方面达到94.2%的F1分数，比传统CRF方法高出12.8个百分点；2. PaymentBERT实现了最先进的性能，达到95.7%的F1分数，同时保持实时处理能力；3. 提供了跨格式泛化、消融研究和部署考虑的详细分析。

Conclusion: 该研究为金融机构实施自动化制裁筛查、反洗钱合规和支付处理系统提供了实用见解。PaymentBERT在支付数据提取方面表现出色，结合了领域特定知识和上下文理解，在实际金融应用中具有重要价值。

Abstract: Named Entity Recognition (NER) has emerged as a critical component in automating financial transaction processing, particularly in extracting structured information from unstructured payment data. This paper presents a comprehensive analysis of state-of-the-art NER algorithms specifically designed for payment data extraction, including Conditional Random Fields (CRF), Bidirectional Long Short-Term Memory with CRF (BiLSTM-CRF), and transformer-based models such as BERT and FinBERT. We conduct extensive experiments on a dataset of 50,000 annotated payment transactions across multiple payment formats including SWIFT MT103, ISO 20022, and domestic payment systems. Our experimental results demonstrate that fine-tuned BERT models achieve an F1-score of 94.2% for entity extraction, outperforming traditional CRF-based approaches by 12.8 percentage points. Furthermore, we introduce PaymentBERT, a novel hybrid architecture combining domain-specific financial embeddings with contextual representations, achieving state-of-the-art performance with 95.7% F1-score while maintaining real-time processing capabilities. We provide detailed analysis of cross-format generalization, ablation studies, and deployment considerations. This research provides practical insights for financial institutions implementing automated sanctions screening, anti-money laundering (AML) compliance, and payment processing systems.

</details>


### [35] [GRRM: Group Relative Reward Modeling for Machine Translation](https://arxiv.org/abs/2602.14028)
*Sen Yang,Shanbo Cheng,Lu Xu,Jianbing Zhang,Shujian Huang*

Main category: cs.CL

TL;DR: 提出Group Relative Reward Model (GRRM)来改进GRPO在机器翻译等开放域任务中的效果，通过联合处理候选组进行对比分析，提升翻译质量和推理能力


<details>
  <summary>Details</summary>
Motivation: 在开放域任务如机器翻译中，GRPO的有效性依赖于准确的组内排序。标准的标量质量指标(SQM)存在不足，因为它们单独评估候选，缺乏区分细微语言差异的比较上下文。

Method: 提出Group Quality Metric (GQM)范式，并通过Group Relative Reward Model (GRRM)实现。GRRM与传统独立评分器不同，它联合处理整个候选组，利用对比分析来严格解析相对质量和自适应粒度。

Result: 实证评估证实GRRM在所有基线中实现了有竞争力的排序准确性。将GRRM集成到GRPO训练循环中优化翻译策略后，实验结果表明该框架不仅提高了整体翻译质量，还解锁了与最先进推理模型相当的推理能力。

Conclusion: 通过引入GRRM范式，解决了GRPO在开放域任务中的排序瓶颈，显著提升了机器翻译的质量和推理能力，为LLM后训练提供了更有效的框架。

Abstract: While Group Relative Policy Optimization (GRPO) offers a powerful framework for LLM post-training, its effectiveness in open-ended domains like Machine Translation hinges on accurate intra-group ranking. We identify that standard Scalar Quality Metrics (SQM) fall short in this context; by evaluating candidates in isolation, they lack the comparative context necessary to distinguish fine-grained linguistic nuances. To address this, we introduce the Group Quality Metric (GQM) paradigm and instantiate it via the Group Relative Reward Model (GRRM). Unlike traditional independent scorers, GRRM processes the entire candidate group jointly, leveraging comparative analysis to rigorously resolve relative quality and adaptive granularity. Empirical evaluations confirm that GRRM achieves competitive ranking accuracy among all baselines. Building on this foundation, we integrate GRRM into the GRPO training loop to optimize the translation policy. Experimental results demonstrate that our framework not only improves general translation quality but also unlocks reasoning capabilities comparable to state-of-the-art reasoning models. We release codes, datasets, and model checkpoints at https://github.com/NJUNLP/GRRM.

</details>


### [36] [Geometry-Preserving Aggregation for Mixture-of-Experts Embedding Models](https://arxiv.org/abs/2602.14039)
*Sajjad Kachuee,Mohammad Sharifkhani*

Main category: cs.CL

TL;DR: 提出球形重心聚合（SBA）方法，解决MoE嵌入模型中线性聚合导致几何结构破坏的问题，在MTEB基准测试中实现性能提升且保持训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有MoE嵌入模型采用加权线性求和聚合专家输出，隐含假设嵌入空间具有线性子空间结构。但研究发现专家表示实际位于共享超球面流形上，线性聚合会导致向量幅度和方向扭曲，破坏嵌入可比性。

Method: 提出球形重心聚合（SBA）作为几何保持的聚合算子，将径向和角度分量分离处理，保持超球面结构，同时完全兼容现有路由机制。

Result: 在MTEB基准测试（语义相似性、聚类、重复问题检测等任务）上实现一致性能提升，训练成本相同且完全稳定。几何分析证实SBA防止聚合诱导的塌缩，保持超球形一致性。

Conclusion: MoE嵌入架构中几何感知的聚合至关重要，SBA方法有效解决线性聚合与专家表示几何结构不一致的问题，为MoE模型设计提供新方向。

Abstract: Mixture-of-Experts (MoE) embedding models combine expert outputs using weighted linear summation, implicitly assuming a linear subspace structure in the embedding space. This assumption is shown to be inconsistent with the geometry of expert representations. Geometric analysis of a modern MoE embedding model reveals that expert outputs lie on a shared hyperspherical manifold characterized by tightly concentrated norms and substantial angular separation. Under this geometry, linear aggregation induces inward collapse toward the manifold interior, distorting vector magnitude and direction and reducing embedding comparability. To address this inconsistency, Spherical Barycentric Aggregation (SBA) is introduced as a geometry-preserving aggregation operator that separates radial and angular components to maintain hyperspherical structure while remaining fully compatible with existing routing mechanisms. Experiments on selected tasks from the Massive Text Embedding Benchmark (MTEB), including semantic similarity, clustering, and duplicate question detection, demonstrate consistent performance improvements with identical training cost and full stability. Additional geometric analyses confirm that SBA prevents aggregation-induced collapse and preserves hyperspherical consistency, highlighting the importance of geometry-aware aggregation in MoE embedding architectures.

</details>


### [37] [Context Shapes LLMs Retrieval-Augmented Fact-Checking Effectiveness](https://arxiv.org/abs/2602.14044)
*Pietro Bernardelle,Stefano Civelli,Kevin Roitero,Gianluca Demartini*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在事实核查任务中，随着上下文长度增加，验证准确性普遍下降，且证据在提示开头或结尾时表现更好。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在多种任务中展现出强大的推理能力，但在长上下文中的表现仍然不一致。先前研究主要关注问答任务中的中上下文退化现象，本研究旨在探究上下文长度对基于LLM的事实核查任务的影响。

Method: 使用三个数据集（HOVER、FEVEROUS、ClimateFEVER）和五个不同参数规模（7B、32B、70B）的开源模型（Llama-3.1、Qwen2.5、Qwen3），评估参数化事实知识以及证据在不同上下文长度中的放置位置对模型性能的影响。

Result: LLMs展现出非平凡的参数化事实知识，但验证准确性通常随着上下文长度增加而下降。与先前研究一致，证据放置位置对准确性有重要影响：当相关证据出现在提示开头或结尾时准确性较高，而在中间位置时较低。

Conclusion: 这些结果强调了提示结构在检索增强事实核查系统中的重要性，为优化基于LLM的事实核查系统提供了重要见解。

Abstract: Large language models (LLMs) show strong reasoning abilities across diverse tasks, yet their performance on extended contexts remains inconsistent. While prior research has emphasized mid-context degradation in question answering, this study examines the impact of context in LLM-based fact verification. Using three datasets (HOVER, FEVEROUS, and ClimateFEVER) and five open-source models accross different parameters sizes (7B, 32B and 70B parameters) and model families (Llama-3.1, Qwen2.5 and Qwen3), we evaluate both parametric factual knowledge and the impact of evidence placement across varying context lengths. We find that LLMs exhibit non-trivial parametric knowledge of factual claims and that their verification accuracy generally declines as context length increases. Similarly to what has been shown in previous works, in-context evidence placement plays a critical role with accuracy being consistently higher when relevant evidence appears near the beginning or end of the prompt and lower when placed mid-context. These results underscore the importance of prompt structure in retrieval-augmented fact-checking systems.

</details>


### [38] [LogitsCoder: Towards Efficient Chain-of-Thought Path Search via Logits Preference Decoding for Code Generation](https://arxiv.org/abs/2602.14054)
*Jizheng Chen,Weiming Zhang,Xinyi Dai,Weiwen Liu,Kounianhua Du,Yasheng Wang,Ruiming Tang,Yong Yu,Weinan Zhang*

Main category: cs.CL

TL;DR: LogitsCoder：通过轻量级logit级控制机制增强代码生成的思维链推理，解决现有方法中"思考不足"和"过度思考"的问题。


<details>
  <summary>Details</summary>
Motivation: 现有测试时间缩放方法在代码生成中存在两大挑战：1）思考不足：推理链过浅，无法捕捉问题的全部复杂性；2）过度思考：推理过程过于冗长，导致效率低下和计算成本增加。

Method: 提出LogitsCoder框架，通过logit级控制机制增强思维链推理。采用Logits Preference Decoding引导token选择到统计偏好的模式，然后使用Logits Rank Based Path Selection和Thoughts Aggregation选择和聚合多样化的推理路径，迭代生成和精炼推理步骤。

Result: 大量实验表明，LogitsCoder能产生更高效、更高质量的推理链，在代码生成性能上优于基线方法。

Conclusion: LogitsCoder通过平衡推理深度和效率，在代码生成任务中实现了更优的性能，为解决思考不足和过度思考问题提供了有效方案。

Abstract: Code generation remains a challenging task that requires precise and structured reasoning. Existing Test Time Scaling (TTS) methods, including structured tree search, have made progress in exploring reasoning paths but still face two major challenges: (1) underthinking, where reasoning chains tend to be shallow and fail to capture the full complexity of problems; and (2) overthinking, where overly verbose reasoning leads to inefficiency and increased computational costs. To address these issues, we propose LogitsCoder, a novel framework that enhances chain-of-thought reasoning through lightweight, logit-level control mechanisms for code generation. LogitsCoder iteratively generates and refines reasoning steps by first steering token selection toward statistically preferred patterns via Logits Preference Decoding, then selecting and aggregating diverse reasoning paths using Logits Rank Based Path Selection and Thoughts Aggregation. This results in coherent and effective reasoning chains that balance depth and efficiency. Extensive experiments demonstrate that LogitsCoder produces more efficient and higher-quality reasoning chains, leading to superior code generation performance compared to baseline methods.

</details>


### [39] [LM-Lexicon: Improving Definition Modeling via Harmonizing Semantic Experts](https://arxiv.org/abs/2602.14060)
*Yang Liu,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li,Lingyong Yan*

Main category: cs.CL

TL;DR: LM-Lexicon：一种创新的定义建模方法，通过数据聚类、语义专家学习和稀疏专家混合架构实现，在五个基准测试中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有定义建模方法在处理语义密集型应用时存在效率和质量限制，需要更精细的语义领域专业化和高效的模型架构。

Method: 1) 数据聚类将定义建模任务分解为专门的语义领域；2) 训练小型语言模型作为领域专家；3) 使用稀疏专家混合架构进行模型合并；4) 语义感知的领域级路由机制。

Result: 1) 在五个广泛使用的基准测试中，相比先前最先进模型BLEU分数提升7%；2) 聚类策略使定义质量提升近10%；3) 语义感知路由比传统token级路由专家效率高1%；4) 通过测试时计算和语义专家扩展可获得进一步性能提升。

Conclusion: LM-Lexicon推进了定义建模技术，为语义密集型应用的高效语言模型开发提供了重要见解，展示了领域专业化、专家混合架构和语义感知路由的有效性。

Abstract: We introduce LM-Lexicon, an innovative definition modeling approach that incorporates data clustering, semantic expert learning, and model merging using a sparse mixture-of-experts architecture. By decomposing the definition modeling task into specialized semantic domains, where small language models are trained as domain experts, LM-Lexicon achieves substantial improvements (+7% BLEU score compared with the prior state-of-the-art model) over existing methods on five widely used benchmarks. Empirically, we demonstrate that 1) the clustering strategy enables fine-grained expert specialization with nearly 10% improvement in definition quality; 2) the semantic-aware domain-level routing mechanism achieves higher expert efficacy (+1%) than conventional token-level routing; and 3) further performance gains can be obtained through test-time compute and semantic expert scaling. Our work advances definition modeling while providing insights into the development of efficient language models for semantic-intensive applications.

</details>


### [40] [From Scarcity to Scale: A Release-Level Analysis of the Pashto Common Voice Dataset](https://arxiv.org/abs/2602.14062)
*Jandad Jahani,Mursal Dawodi,Jawid Ahmad Baktash*

Main category: cs.CL

TL;DR: 该论文对Common Voice语料库中的普什图语组件进行了发布级别分析，重点关注版本24.0（2025年12月），并记录了从2023年中1.49小时到2025年2768.7小时的快速增长。


<details>
  <summary>Details</summary>
Motivation: 普什图语作为超过6000万人使用的语言，历史上缺乏适合现代ASR开发的大规模开放许可语音数据。Common Voice语料库中的普什图语组件经历了快速增长，需要对其规模、质量和代表性进行全面分析。

Method: 对Common Voice语料库普什图语组件进行发布级别分析，重点关注版本24.0，分析验证吞吐量、贡献者参与不平等性、人口统计元数据完整性、句子级别集中度等指标。

Result: 1）数据量从1.49小时增长到2768.7小时，其中975.89小时已验证可用于监督ASR训练；2）参与度高度集中（基尼系数0.941）；3）年龄代表性偏向年轻成年人；4）41.97%的片段缺乏性别标签；5）35.88%的唯一句子占50%的已验证片段。

Conclusion: 该研究为快速扩展的低资源语音语料库提供了定量审核，强调了改进数据集成熟度的实际优先事项，包括扩展验证能力和更广泛的人口统计参与。

Abstract: Large, openly licensed speech datasets are essential for building automatic speech recognition (ASR) systems, yet many widely spoken languages remain underrepresented in public resources. Pashto, spoken by more than 60 million people, has historically lacked large-scale openly licensed speech data suitable for modern ASR development.
  This paper presents a release-level analysis of the Pashto component of the Mozilla Common Voice corpus, focusing on version 24.0 (December 2025) and contextualizing trends across major releases. We document rapid growth from 1.49 recorded hours in mid-2023 to 2,768.7 total hours in 2025, including 975.89 validated hours available for supervised ASR training.
  Beyond scale, we analyze validation throughput, contributor participation inequality, demographic metadata completeness, and sentence-level concentration in the validated subset. We find that participation is extremely concentrated (Gini = 0.941), age representation is strongly skewed toward young adults, and 41.97\% of clips lack self-reported gender labels, limiting subgroup auditing based on metadata. At the textual level, prompt reuse is moderate: 35.88\% of unique sentences account for 50\% of validated clips, suggesting that structural concentration is driven primarily by uneven contributor activity rather than dominance of a small prompt set.
  These results provide a quantitative audit of a rapidly scaling low-resource speech corpus and highlight practical priorities for improving dataset maturity, including expanded validation capacity and broader demographic participation.

</details>


### [41] [Open Rubric System: Scaling Reinforcement Learning with Pairwise Adaptive Rubric](https://arxiv.org/abs/2602.14069)
*Ruipeng Jia,Yunyi Yang,Yuxin Wu,Yongbo Gai,Siyuan Tao,Mengyu Zhou,Jianhe Lin,Xiaoxi Jiang,Guanjun Jiang*

Main category: cs.CL

TL;DR: OpenRS是一个基于可检查原则的LLM评估框架，通过显式元规则和自适应规则替代传统的标量奖励模型，解决开放领域对齐中的奖励破解问题。


<details>
  <summary>Details</summary>
Motivation: 传统的标量奖励模型将多维人类偏好压缩为单一不透明分数，导致信息瓶颈、脆弱性和奖励破解问题。作者认为非可验证任务的稳健对齐本质上是一个原则泛化问题，奖励不应是内部化的学习函数，而应是基于可检查原则的显式推理过程。

Method: 提出Open Rubric System (OpenRS)，包含：1) Pairwise Adaptive Meta-Rubrics (PAMR)：基于候选回答语义差异动态实例化规则；2) Pointwise Verifiable Rubrics (PVR)：提供硬约束护栏和可验证奖励；3) 两层元规则精炼流程（自动进化精炼和人工参与流程）；4) 在成对RL训练中实例化为奖励监督。

Result: OpenRS通过显式元规则和自适应规则框架，避免了点式加权标量化，提高了开放场景中的区分能力，同时保持原则的一致性和可编辑性。

Conclusion: OpenRS将奖励从内部化学习函数转变为基于可检查原则的显式推理过程，为解决开放领域对齐中的奖励破解问题提供了新的框架和方法。

Abstract: Scalar reward models compress multi-dimensional human preferences into a single opaque score, creating an information bottleneck that often leads to brittleness and reward hacking in open-ended alignment. We argue that robust alignment for non-verifiable tasks is fundamentally a principle generalization problem: reward should not be a learned function internalized into a judge, but an explicit reasoning process executed under inspectable principles. To operationalize this view, we present the Open Rubric System (OpenRS), a plug-and-play, rubrics-based LLM-as-a-Judge framework built around Pairwise Adaptive Meta-Rubrics (PAMR) and lightweight Pointwise Verifiable Rubrics (PVRs), which provide both hard-constraint guardrails and verifiable reward components when ground-truth or programmatic checks are available. OpenRS uses an explicit meta-rubric -- a constitution-like specification that governs how rubrics are instantiated, weighted, and enforced -- and instantiates adaptive rubrics on the fly by conditioning on the semantic differences between two candidate responses. It then performs criterion-wise pairwise comparisons and aggregates criterion-level preferences externally, avoiding pointwise weighted scalarization while improving discriminability in open-ended settings. To keep principles consistent yet editable across various domains, we introduce a two-level meta-rubric refinement pipeline (automated evolutionary refinement for general principles and a reproducible human-in-the-loop procedure for domain principles), complemented with pointwise verifiable rubrics that act as both guardrails against degenerate behaviors and a source of verifiable reward for objective sub-tasks. Finally, we instantiate OpenRS as reward supervision in pairwise RL training.

</details>


### [42] [Annotation-Efficient Vision-Language Model Adaptation to the Polish Language Using the LLaVA Framework](https://arxiv.org/abs/2602.14073)
*Grzegorz Statkiewicz,Alicja Dobrzeniecka,Karolina Seweryn,Aleksandra Krasnodębska,Karolina Piosek,Katarzyna Bogusz,Sebastian Cygert,Wojciech Kusa*

Main category: cs.CL

TL;DR: 研究者复制并改进了LLaVA-Next方法，创建了波兰语视觉语言模型，通过自动翻译和筛选多模态数据集，结合合成数据，在波兰语评估中显著优于原模型。


<details>
  <summary>Details</summary>
Motivation: 大多数视觉语言模型基于英语数据训练，在非英语语言和文化背景下表现受限，这影响了多语言用户的使用体验，也阻碍了反映多样化语言文化现实的多模态系统发展。

Method: 采用完全自动化的流程翻译和筛选现有多模态数据集，补充合成波兰语数据用于OCR和文化特定任务，基于LLaVA-Next方法进行改进，整个过程几乎完全依赖自动翻译，人工干预最小。

Result: 在波兰语适配的MMBench评估中，相比LLaVA-1.6-Vicuna-13B有+9.5%的改进，在生成式评估中，人工标注显示语言正确性更高的图像描述质量。

Conclusion: 大规模自动翻译结合轻量级筛选可以有效引导低资源语言的高质量多模态模型开发，但仍存在文化覆盖和评估方面的挑战。研究团队公开了模型和评估数据集以促进进一步研究。

Abstract: Most vision-language models (VLMs) are trained on English-centric data, limiting their performance in other languages and cultural contexts. This restricts their usability for non-English-speaking users and hinders the development of multimodal systems that reflect diverse linguistic and cultural realities. In this work, we reproduce and adapt the LLaVA-Next methodology to create a set of Polish VLMs. We rely on a fully automated pipeline for translating and filtering existing multimodal datasets, and complement this with synthetic Polish data for OCR and culturally specific tasks. Despite relying almost entirely on automatic translation and minimal manual intervention to the training data, our approach yields strong results: we observe a +9.5% improvement over LLaVA-1.6-Vicuna-13B on a Polish-adapted MMBench, along with higher-quality captions in generative evaluations, as measured by human annotators in terms of linguistic correctness. These findings highlight that large-scale automated translation, combined with lightweight filtering, can effectively bootstrap high-quality multimodal models for low-resource languages. Some challenges remain, particularly in cultural coverage and evaluation. To facilitate further research, we make our models and evaluation dataset publicly available.

</details>


### [43] [GTS: Inference-Time Scaling of Latent Reasoning with a Learnable Gaussian Thought Sampler](https://arxiv.org/abs/2602.14077)
*Minghan Wang,Ye Bai,Thuy-Trang Vu,Ehsan Shareghi,Gholamreza Haffari*

Main category: cs.CL

TL;DR: 提出GTS方法，通过可学习的条件分布进行结构化探索，相比传统启发式扰动方法在有限采样预算下更高效。


<details>
  <summary>Details</summary>
Motivation: 现有推理时缩放方法通常使用启发式扰动（如dropout或固定高斯噪声）引入随机性，虽然增加了轨迹多样性，但探索行为没有显式建模，在有限采样预算下效率低下。更强的扰动不一定产生更有效的候选轨迹，因为无引导的噪声可能破坏内部决策结构而非引导它。

Method: 将潜在思维探索建模为从可学习密度的条件采样，实例化为高斯思维采样器（GTS）。GTS预测连续推理状态上的上下文相关扰动分布，使用GRPO风格策略优化进行训练，同时保持骨干网络冻结。

Result: 在GSM8K数据集上使用两种潜在推理架构的实验表明，GTS比启发式基线方法实现了更可靠的推理时缩放。

Conclusion: 改进潜在推理时缩放需要结构化和可优化的探索机制，而不是简单地放大随机性。GTS提供了一种更结构化的替代方案，能够更有效地引导推理探索。

Abstract: Inference-time scaling (ITS) in latent reasoning models typically introduces stochasticity through heuristic perturbations, such as dropout or fixed Gaussian noise. While these methods increase trajectory diversity, their exploration behavior is not explicitly modeled and can be inefficient under finite sampling budgets. We observe that stronger perturbations do not necessarily translate into more effective candidate trajectories, as unguided noise may disrupt internal decision structure rather than steer it. To provide a more structured alternative, we model latent thought exploration as conditional sampling from learnable densities and instantiate this idea as a Gaussian Thought Sampler (GTS). GTS predicts context-dependent perturbation distributions over continuous reasoning states and is trained with GRPO-style policy optimization while keeping the backbone frozen. Experiments on GSM8K with two latent reasoning architectures show that GTS achieves more reliable inference-time scaling than heuristic baselines. These findings indicate that improving latent ITS requires structured and optimizable exploration mechanisms rather than simply amplifying stochasticity.

</details>


### [44] [Empty Shelves or Lost Keys? Recall Is the Bottleneck for Parametric Factuality](https://arxiv.org/abs/2602.14080)
*Nitay Calderon,Eyal Ben-David,Zorik Gekhman,Eran Ofek,Gal Yona*

Main category: cs.CL

TL;DR: 该论文提出了一种区分LLM事实性错误来源的框架：缺失知识vs访问失败，并发现前沿模型已编码大部分事实，但访问能力是主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前LLM事实性评估将所有错误同等对待，无法区分错误是源于缺失知识（空架子）还是无法访问已编码知识（丢失的钥匙）。需要建立能识别这两种不同失败来源的评估框架。

Method: 提出行为分析框架，在事实层面而非问题层面分析知识，将每个事实分类为：是否编码、可访问性（无法回忆、直接回忆、需推理计算回忆）。构建WikiProfile基准测试，通过基于网络搜索的LLM自动化流程创建，收集13个LLM的400万条响应进行分析。

Result: 前沿模型（GPT-5和Gemini-3）在基准测试中编码了95-98%的事实，表明知识编码已接近饱和。但回忆能力是主要瓶颈：许多先前归因于缺失知识的错误实际上源于访问失败。这些失败具有系统性，对长尾事实和反向问题影响更大。推理计算能显著改善回忆能力，可恢复大量失败案例。

Conclusion: 未来LLM性能提升可能更依赖于改进模型如何利用已编码知识的方法，而非单纯扩大规模。需要开发更好的访问机制来充分利用模型已掌握的知识。

Abstract: Standard factuality evaluations of LLMs treat all errors alike, obscuring whether failures arise from missing knowledge (empty shelves) or from limited access to encoded facts (lost keys). We propose a behavioral framework that profiles factual knowledge at the level of facts rather than questions, characterizing each fact by whether it is encoded, and then by how accessible it is: cannot be recalled, can be directly recalled, or can only be recalled with inference-time computation (thinking). To support such profiling, we introduce WikiProfile, a new benchmark constructed via an automated pipeline with a prompted LLM grounded in web search. Across 4 million responses from 13 LLMs, we find that encoding is nearly saturated in frontier models on our benchmark, with GPT-5 and Gemini-3 encoding 95--98% of facts. However, recall remains a major bottleneck: many errors previously attributed to missing knowledge instead stem from failures to access it. These failures are systematic and disproportionately affect long-tail facts and reverse questions. Finally, we show that thinking improves recall and can recover a substantial fraction of failures, indicating that future gains may rely less on scaling and more on methods that improve how models utilize what they already encode.

</details>


### [45] [CCiV: A Benchmark for Structure, Rhythm and Quality in LLM-Generated Chinese \textit{Ci} Poetry](https://arxiv.org/abs/2602.14081)
*Shangqing Zhao,Yupei Ren,Yuhao Zhou,Xiaopeng Bai,Man Lan*

Main category: cs.CL

TL;DR: CCiV基准测试评估LLM生成宋词的能力，揭示模型在结构、韵律和艺术质量方面的挑战，发现历史变体、韵律控制难等关键现象。


<details>
  <summary>Details</summary>
Motivation: 宋词生成需要复杂的结构、韵律和艺术质量结合，这对大语言模型提出了重大挑战。需要系统评估和推进LLM在这方面的能力，因此开发了CCiV基准测试。

Method: 提出CCiV基准测试，在30个词牌上评估17个LLM，从结构、韵律和质量三个维度分析。研究历史变体现象、韵律控制难度，并测试形式感知提示的效果。

Result: 发现两个关键现象：1) 模型经常生成有效但意外的历史变体；2) 遵守平仄模式比结构规则困难得多。形式感知提示能改善强模型的结构和韵律控制，但可能削弱弱模型。形式正确性与文学质量之间关联弱且不一致。

Conclusion: CCiV强调需要变体感知的评估方法和更全面的约束创造性生成方法，以改进LLM在古典诗词生成方面的能力。

Abstract: The generation of classical Chinese \textit{Ci} poetry, a form demanding a sophisticated blend of structural rigidity, rhythmic harmony, and artistic quality, poses a significant challenge for large language models (LLMs). To systematically evaluate and advance this capability, we introduce \textbf{C}hinese \textbf{Ci}pai \textbf{V}ariants (\textbf{CCiV}), a benchmark designed to assess LLM-generated \textit{Ci} poetry across these three dimensions: structure, rhythm, and quality. Our evaluation of 17 LLMs on 30 \textit{Cipai} reveals two critical phenomena: models frequently generate valid but unexpected historical variants of a poetic form, and adherence to tonal patterns is substantially harder than structural rules. We further show that form-aware prompting can improve structural and tonal control for stronger models, while potentially degrading weaker ones. Finally, we observe weak and inconsistent alignment between formal correctness and literary quality in our sample. CCiV highlights the need for variant-aware evaluation and more holistic constrained creative generation methods.

</details>


### [46] [Character-aware Transformers Learn an Irregular Morphological Pattern Yet None Generalize Like Humans](https://arxiv.org/abs/2602.14100)
*Akhilesh Kakolu Ramarao,Kevin Tang,Dinah Baer-Henney*

Main category: cs.CL

TL;DR: 论文研究了神经网络是否能作为形态学习的认知模型，通过西班牙语L形形态学的案例，发现位置不变性编码模型能恢复正确的L形范式聚类，但无法像人类一样将模式推广到新形式。


<details>
  <summary>Details</summary>
Motivation: 探索神经网络是否能作为形态学习的认知模型，特别关注它们是否能像人类一样泛化不规则形态模式。

Method: 使用西班牙语L形形态学作为测试案例，比较五种编码器-解码器变换器模型，这些模型在两个维度上变化：顺序vs位置不变性位置编码，原子vs分解标签表示。

Result: 位置编码是关键因素：位置不变性模型即使在训练数据稀少时也能恢复正确的L形范式聚类，而顺序位置编码模型只能部分捕捉该模式。但所有模型都无法像人类一样将模式推广到新形式。

Conclusion: 尽管某些模型能再现统计模式，但没有一个模型能复制人类的形态抽象模式，突显了统计模式再现与形态抽象之间的差距。

Abstract: Whether neural networks can serve as cognitive models of morphological learning remains an open question. Recent work has shown that encoder-decoder models can acquire irregular patterns, but evidence that they generalize these patterns like humans is mixed. We investigate this using the Spanish \emph{L-shaped morphome}, where only the first-person singular indicative (e.g., \textit{pongo} `I put') shares its stem with all subjunctive forms (e.g., \textit{ponga, pongas}) despite lacking apparent phonological, semantic, or syntactic motivation. We compare five encoder-decoder transformers varying along two dimensions: sequential vs. position-invariant positional encoding, and atomic vs. decomposed tag representations. Positional encoding proves decisive: position-invariant models recover the correct L-shaped paradigm clustering even when L-shaped verbs are scarce in training, whereas sequential positional encoding models only partially capture the pattern. Yet none of the models productively generalize this pattern to novel forms. Position-invariant models generalize the L-shaped stem across subjunctive cells but fail to extend it to the first-person singular indicative, producing a mood-based generalization rather than the L-shaped morphomic pattern. Humans do the opposite, generalizing preferentially to the first-person singular indicative over subjunctive forms. None of the models reproduce the human pattern, highlighting the gap between statistical pattern reproduction and morphological abstraction.

</details>


### [47] [A Multi-Agent Framework for Medical AI: Leveraging Fine-Tuned GPT, LLaMA, and DeepSeek R1 for Evidence-Based and Bias-Aware Clinical Query Processing](https://arxiv.org/abs/2602.14158)
*Naeimeh Nourmohammadi,Md Meem Hossain,The Anh Han,Safina Showkat Ara,Zia Ush Shamszaman*

Main category: cs.CL

TL;DR: 提出多智能体医疗QA框架，结合证据检索、不确定性估计和偏见检测，显著提升医疗问答的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗问答中虽有潜力，但存在验证薄弱、证据不足、置信度不可靠等问题，限制了临床应用。

Method: 1. 在MedQuAD医疗QA数据上微调三种LLM家族(GPT、LLaMA、DeepSeek R1)；2. 构建模块化多智能体管道：临床推理智能体生成结构化解释，证据检索智能体查询PubMed，优化智能体提升清晰度；3. 加入安全机制：蒙特卡洛dropout、困惑度不确定性评分、LIME/SHAP偏见检测。

Result: DeepSeek R1表现最佳(ROUGE-1 0.536)，显著优于BioGPT；完整系统达到87%准确率，相关性约0.80，证据增强降低不确定性(困惑度4.13)，端到端延迟36.5秒。

Conclusion: 智能体专业化和验证层能够缓解单模型的局限性，为基于证据和偏见感知的医疗AI提供了实用、可扩展的设计方案。

Abstract: Large language models (LLMs) show promise for healthcare question answering, but clinical use is limited by weak verification, insufficient evidence grounding, and unreliable confidence signalling. We propose a multi-agent medical QA framework that combines complementary LLMs with evidence retrieval, uncertainty estimation, and bias checks to improve answer reliability. Our approach has two phases. First, we fine-tune three representative LLM families (GPT, LLaMA, and DeepSeek R1) on MedQuAD-derived medical QA data (20k+ question-answer pairs across multiple NIH domains) and benchmark generation quality. DeepSeek R1 achieves the strongest scores (ROUGE-1 0.536 +- 0.04; ROUGE-2 0.226 +-0.03; BLEU 0.098 -+ 0.018) and substantially outperforms the specialised biomedical baseline BioGPT in zero-shot evaluation. Second, we implement a modular multi-agent pipeline in which a Clinical Reasoning agent (fine-tuned LLaMA) produces structured explanations, an Evidence Retrieval agent queries PubMed to ground responses in recent literature, and a Refinement agent (DeepSeek R1) improves clarity and factual consistency; an optional human validation path is triggered for high-risk or high-uncertainty cases. Safety mechanisms include Monte Carlo dropout and perplexity-based uncertainty scoring, plus lexical and sentiment-based bias detection supported by LIME/SHAP-based analyses. In evaluation, the full system achieves 87% accuracy with relevance around 0.80, and evidence augmentation reduces uncertainty (perplexity 4.13) compared to base responses, with mean end-to-end latency of 36.5 seconds under the reported configuration. Overall, the results indicate that agent specialisation and verification layers can mitigate key single-model limitations and provide a practical, extensible design for evidence-based and bias-aware medical AI.

</details>


### [48] [GPT-5 vs Other LLMs in Long Short-Context Performance](https://arxiv.org/abs/2602.14188)
*Nima Esmi,Maryam Nezhad-Moghaddam,Fatemeh Borhani,Asadollah Shahbahrami,Amin Daemdoost,Georgi Gaydadjiev*

Main category: cs.CL

TL;DR: 大型语言模型在理论上有处理长上下文的能力，但在实际应用中，当输入量超过一定阈值（如5K帖子/70K tokens）时，所有模型的性能都会显著下降，准确率降至50-53%。GPT-5虽然准确率下降，但精确度保持95%，适合抑郁症检测等敏感应用。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs的理论上下文窗口大幅扩展，能够处理数百万tokens，但研究发现模型在长上下文任务中的实际表现与理论能力存在显著差距，尤其是在需要全面理解大量细节的任务中。

Method: 评估了四种最先进的模型（Grok-4、GPT-4、Gemini 2.5和GPT-5）在长上下文任务上的表现。使用了三个数据集：两个辅助数据集（烹饪食谱检索和数学问题），以及一个包含20K社交媒体帖子的抑郁症检测主数据集。

Result: 当社交媒体数据集输入量超过5K帖子（70K tokens）时，所有模型的性能显著下降，20K帖子时准确率降至50-53%。GPT-5模型虽然准确率大幅下降，但精确度保持在约95%的高水平。研究还表明"中间迷失"问题在新模型中已基本解决。

Conclusion: 本研究强调了模型在复杂、高容量数据任务上的理论能力与实际性能之间的差距，并指出对于实际应用来说，除了简单的准确率外，其他指标（如精确度）也至关重要。GPT-5的高精确度特性使其在抑郁症检测等敏感应用中特别有效。

Abstract: With the significant expansion of the context window in Large Language Models (LLMs), these models are theoretically capable of processing millions of tokens in a single pass. However, research indicates a significant gap between this theoretical capacity and the practical ability of models to robustly utilize information within long contexts, especially in tasks that require a comprehensive understanding of numerous details. This paper evaluates the performance of four state-of-the-art models (Grok-4, GPT-4, Gemini 2.5, and GPT-5) on long short-context tasks. For this purpose, three datasets were used: two supplementary datasets for retrieving culinary recipes and math problems, and a primary dataset of 20K social media posts for depression detection. The results show that as the input volume on the social media dataset exceeds 5K posts (70K tokens), the performance of all models degrades significantly, with accuracy dropping to around 50-53% for 20K posts. Notably, in the GPT-5 model, despite the sharp decline in accuracy, its precision remained high at approximately 95%, a feature that could be highly effective for sensitive applications like depression detection. This research also indicates that the "lost in the middle" problem has been largely resolved in newer models. This study emphasizes the gap between the theoretical capacity and the actual performance of models on complex, high-volume data tasks and highlights the importance of metrics beyond simple accuracy for practical applications.

</details>


### [49] [Knowing When Not to Answer: Abstention-Aware Scientific Reasoning](https://arxiv.org/abs/2602.14189)
*Samir Abdaljalil,Erchin Serpedin,Hasan Kurban*

Main category: cs.CL

TL;DR: 该论文提出了一个基于弃权的科学声明验证框架，通过将声明分解为最小条件，使用自然语言推理进行证据审核，并选择性地支持、反驳或弃权，从而在科学推理中减少错误。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型用于科学声明验证时通常必须给出确定答案，但在科学环境中，提供无支持或不确定的结论可能比弃权更有害。需要一种能够识别何时证据不足而选择弃权的验证框架。

Method: 提出了弃权感知的验证框架：1) 将科学声明分解为最小条件；2) 使用自然语言推理(NLI)对每个条件进行证据审核；3) 基于置信度选择性地支持、反驳或弃权。在SciFact和PubMedQA两个科学基准上评估了六种不同语言模型。

Result: 实验显示：1) 原始准确率在不同架构间差异不大；2) 弃权在控制错误方面起关键作用；3) 基于置信度的弃权能在中等覆盖率水平下显著降低风险，即使绝对准确率提升有限。这表明科学推理的主要挑战不是选择最佳模型，而是确定何时有足够证据来证明答案。

Conclusion: 弃权感知评估是评估科学可靠性的实用且模型无关的方法。在科学推理任务中，确定何时证据足够支持答案比选择单一最佳模型更重要。该工作为科学领域的选择性推理提供了统一的实验基础。

Abstract: Large language models are increasingly used to answer and verify scientific claims, yet existing evaluations typically assume that a model must always produce a definitive answer. In scientific settings, however, unsupported or uncertain conclusions can be more harmful than abstaining. We study this problem through an abstention-aware verification framework that decomposes scientific claims into minimal conditions, audits each condition against available evidence using natural language inference (NLI), and selectively decides whether to support, refute, or abstain. We evaluate this framework across two complementary scientific benchmarks: SciFact and PubMedQA, covering both closed-book and open-domain evidence settings. Experiments are conducted with six diverse language models, including encoder-decoder, open-weight chat models, and proprietary APIs. Across all benchmarks and models, we observe that raw accuracy varies only modestly across architectures, while abstention plays a critical role in controlling error. In particular, confidence-based abstention substantially reduces risk at moderate coverage levels, even when absolute accuracy improvements are limited. Our results suggest that in scientific reasoning tasks, the primary challenge is not selecting a single best model, but rather determining when available evidence is sufficient to justify an answer. This work highlights abstention-aware evaluation as a practical and model-agnostic lens for assessing scientific reliability, and provides a unified experimental basis for future work on selective reasoning in scientific domains. Code is available at https://github.com/sabdaljalil2000/ai4science .

</details>


### [50] [We can still parse using syntactic rules](https://arxiv.org/abs/2602.14238)
*Ghaly Hussein*

Main category: cs.CL

TL;DR: 提出一种基于CFG和GPSG的新解析方法，能同时生成依存和成分句法树，处理噪声和不完整解析，在UD数据集上取得约54%的UAS分数。


<details>
  <summary>Details</summary>
Motivation: 传统CFG存在局限性，需要一种能同时生成依存和成分句法树、处理噪声和不完整解析、且更透明可解释的解析方法。

Method: 基于CFG和GPSG的语法理论，提出新的解析算法和句法规则特征集，能生成多个解析假设供重排序。

Result: 在Universal Dependencies数据集上，开发集（7个语料库）平均UAS 54.5%，测试集（12个语料库）平均UAS 53.8%。

Conclusion: 该方法成功整合了1950年代以来的句法理论成果，为计算语言学提供了透明可解释的解析模型。

Abstract: This research introduces a new parsing approach, based on earlier syntactic work on context free grammar (CFG) and generalized phrase structure grammar (GPSG). The approach comprises both a new parsing algorithm and a set of syntactic rules and features that overcome the limitations of CFG. It also generates both dependency and constituency parse trees, while accommodating noise and incomplete parses. The system was tested on data from Universal Dependencies, showing a promising average Unlabeled Attachment Score (UAS) of 54.5% in the development dataset (7 corpora) and 53.8% in the test set (12 corpora). The system also provides multiple parse hypotheses, allowing further reranking to improve parsing accuracy. This approach also leverages much of the theoretical syntactic work since the 1950s to be used within a computational context. The application of this approach provides a transparent and interpretable NLP model to process language input.

</details>


### [51] [Detecting LLM Hallucinations via Embedding Cluster Geometry: A Three-Type Taxonomy with Measurable Signatures](https://arxiv.org/abs/2602.14259)
*Matic Korun*

Main category: cs.CL

TL;DR: 该论文提出基于词嵌入聚类结构的LLM幻觉几何分类法，识别三种幻觉类型，并引入三种几何统计量来量化分析。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常产生幻觉（生成不准确或虚构的内容），但目前缺乏系统性的理论框架来分类和理解这些幻觉的几何特征。

Method: 分析了11个Transformer模型（包括编码器和解码器架构）的静态嵌入空间，通过观察词嵌入聚类结构识别三种幻觉类型，并引入α（极性耦合）、β（聚类凝聚度）和λ_s（径向信息梯度）三个几何统计量进行量化分析。

Result: 在所有11个模型中，极性结构（α > 0.5）和聚类凝聚度（β > 0）都是普遍存在的，径向信息梯度在9/11模型中显著（p < 0.05）。ALBERT和MiniLM两个模型未能达到λ_s显著性，分别归因于因子化嵌入压缩和蒸馏诱导的各向同性。

Conclusion: 该研究建立了幻觉检测的几何先决条件，为特定类型的幻觉检测提供了理论基础，并产生了关于架构依赖性脆弱性配置的可测试预测。

Abstract: We propose a geometric taxonomy of large language model hallucinations based on observable signatures in token embedding cluster structure. By analyzing the static embedding spaces of 11 transformer models spanning encoder (BERT, RoBERTa, ELECTRA, DeBERTa, ALBERT, MiniLM, DistilBERT) and decoder (GPT-2) architectures, we identify three operationally distinct hallucination types: Type 1 (center-drift) under weak context, Type 2 (wrong-well convergence) to locally coherent but contextually incorrect cluster regions, and Type 3 (coverage gaps) where no cluster structure exists. We introduce three measurable geometric statistics: α (polarity coupling), \b{eta} (cluster cohesion), and λ_s (radial information gradient). Across all 11 models, polarity structure (α > 0.5) is universal (11/11), cluster cohesion (\b{eta} > 0) is universal (11/11), and the radial information gradient is significant (9/11, p < 0.05). We demonstrate that the two models failing λ_s significance -- ALBERT and MiniLM -- do so for architecturally explicable reasons: factorized embedding compression and distillation-induced isotropy, respectively. These findings establish the geometric prerequisites for type-specific hallucination detection and yield testable predictions about architecture-dependent vulnerability profiles.

</details>


### [52] [STATe-of-Thoughts: Structured Action Templates for Tree-of-Thoughts](https://arxiv.org/abs/2602.14265)
*Zachary Bamberger,Till R. Saenger,Gilad Morad,Ofra Amir,Brandon M. Stewart,Amir Feder*

Main category: cs.CL

TL;DR: STATe-of-Thoughts (STATe) 是一种可解释的推理时计算方法，通过离散的文本干预和控制器-生成器-评估器框架，实现高质量、多样化和可解释的文本生成。


<details>
  <summary>Details</summary>
Motivation: 现有推理时计算方法（如Best-of-N和Tree-of-Thoughts）使用高温采样难以实现有意义的输出多样性，且对推理过程的控制有限，导致可解释性不足。

Method: STATe采用结构化方法：控制器选择编码高层次推理选择的动作，生成器基于这些选择生成推理步骤，评估器对候选结果评分以指导搜索，替代了随机采样。

Result: 1) 动作引导的文本干预比基于温度的采样产生更大的响应多样性；2) 在论证生成案例中，STATe的显式动作序列捕获了可解释特征，能高度预测输出质量；3) 通过估计性能与动作选择的关联，可以识别并引导生成朝向有前景但未探索的动作空间区域。

Conclusion: STATe是一个实用的框架，能够生成高质量、多样化和可解释的文本，为推理时计算提供了结构化、可解释的替代方案。

Abstract: Inference-Time-Compute (ITC) methods like Best-of-N and Tree-of-Thoughts are meant to produce output candidates that are both high-quality and diverse, but their use of high-temperature sampling often fails to achieve meaningful output diversity. Moreover, existing ITC methods offer limited control over how to perform reasoning, which in turn limits their explainability. We present STATe-of-Thoughts (STATe), an interpretable ITC method that searches over high-level reasoning patterns. STATe replaces stochastic sampling with discrete and interpretable textual interventions: a controller selects actions encoding high-level reasoning choices, a generator produces reasoning steps conditioned on those choices, and an evaluator scores candidates to guide search. This structured approach yields three main advantages. First, action-guided textual interventions produce greater response diversity than temperature-based sampling. Second, in a case study on argument generation, STATe's explicit action sequences capture interpretable features that are highly predictive of output quality. Third, estimating the association between performance and action choices allows us to identify promising yet unexplored regions of the action space and steer generation directly toward them. Together, these results establish STATe as a practical framework for generating high-quality, diverse, and interpretable text. Our framework is available at https://github.com/zbambergerNLP/state-of-thoughts.

</details>


### [53] [Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook](https://arxiv.org/abs/2602.14299)
*Ming Li,Xirui Li,Tianyi Zhou*

Main category: cs.CL

TL;DR: AI智能体社会在Moltbook平台上表现出动态平衡：全局语义快速稳定，但个体保持高度多样性，缺乏社会化和共识形成机制


<details>
  <summary>Details</summary>
Motivation: 随着语言模型智能体在网络环境中日益增多，需要研究AI智能体社会是否经历类似人类社会的收敛动态，了解智能体社会的演化规律

Method: 在Moltbook平台上创建开放式持续演化的在线社会，引入定量诊断框架，测量语义稳定化、词汇周转、个体惯性、影响持久性和集体共识等指标

Result: AI智能体社会呈现动态平衡：全局语义平均值快速稳定，但个体保持高多样性和持续词汇周转；个体表现出强惯性，对互动伙伴适应响应弱；影响短暂，无持久超级节点；缺乏共享社会记忆，无法形成稳定集体影响锚点

Conclusion: 仅靠规模和互动密度不足以诱导社会化，为下一代AI智能体社会提供了可操作的设计和分析原则

Abstract: As large language model agents increasingly populate networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agents participate in an open-ended, continuously evolving online society. We present the first large-scale systemic diagnosis of this AI agent society. Beyond static observation, we introduce a quantitative diagnostic framework for dynamic evolution in AI agent societies, measuring semantic stabilization, lexical turnover, individual inertia, influence persistence, and collective consensus. Our analysis reveals a system in dynamic balance in Moltbook: while global semantic averages stabilize rapidly, individual agents retain high diversity and persistent lexical turnover, defying homogenization. However, agents exhibit strong individual inertia and minimal adaptive response to interaction partners, preventing mutual influence and consensus. Consequently, influence remains transient with no persistent supernodes, and the society fails to develop stable collective influence anchors due to the absence of shared social memory. These findings demonstrate that scale and interaction density alone are insufficient to induce socialization, providing actionable design and analysis principles for upcoming next-generation AI agent societies.

</details>


### [54] [Beyond Token-Level Policy Gradients for Complex Reasoning with Large Language Models](https://arxiv.org/abs/2602.14386)
*Mufan Xu,Kehai Chen,Xuefeng Bai,Zhengyu Niu,Muyun Yang,Tiejun Zhao,Min Zhang*

Main category: cs.CL

TL;DR: 提出多令牌策略梯度优化（MPO），将连续K个令牌作为统一语义动作，以更好地捕捉复杂推理任务的结构，相比传统单令牌方法在数学推理和编码任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有基于策略梯度的自回归语言模型通常将后续令牌逐个作为策略动作。虽然对许多生成任务有效，但这种方法可能无法完全捕捉复杂推理任务的结构，因为单个语义决策通常跨越多个令牌实现（如定义变量或组合方程），导致令牌级优化与推理固有的块级性质之间存在不匹配。

Method: 提出多令牌策略梯度优化（MPO）框架，将K个连续令牌序列作为统一的语义动作。这种块级视角使方法能够捕捉推理轨迹的组合结构，并支持在连贯的、更高级别的目标上进行优化。

Result: 在数学推理和编码基准测试中，MPO优于标准的令牌级策略梯度基线，突显了令牌级策略梯度在复杂推理中的局限性。

Conclusion: MPO通过将连续令牌作为统一语义动作，更好地捕捉了复杂推理任务的结构，为推理密集型语言任务提供了超越令牌级粒度的新研究方向。

Abstract: Existing policy-gradient methods for auto-regressive language models typically select subsequent tokens one at a time as actions in the policy. While effective for many generation tasks, such an approach may not fully capture the structure of complex reasoning tasks, where a single semantic decision is often realized across multiple tokens--for example, when defining variables or composing equations. This introduces a potential mismatch between token-level optimization and the inherently block-level nature of reasoning in these settings. To bridge this gap, we propose Multi-token Policy Gradient Optimization (MPO), a framework that treats sequences of K consecutive tokens as unified semantic actions. This block-level perspective enables our method to capture the compositional structure of reasoning trajectories and supports optimization over coherent, higher-level objectives. Experiments on mathematical reasoning and coding benchmarks show that MPO outperforms standard token-level policy gradient baselines, highlight the limitations of token-level policy gradients for complex reasoning, motivating future research to look beyond token-level granularity for reasoning-intensive language tasks.

</details>


### [55] [TruthStance: An Annotated Dataset of Conversations on Truth Social](https://arxiv.org/abs/2602.14406)
*Fathima Ameen,Danielle Brown,Manusha Malgareddy,Amanul Haque*

Main category: cs.CL

TL;DR: TruthStance：首个大规模Truth Social对话数据集，包含24,378帖子和523,360评论，提供人工标注基准，评估LLM提示策略并生成额外标签，支持论证挖掘和立场检测研究。


<details>
  <summary>Details</summary>
Motivation: 现有公开资源主要关注Twitter和Reddit等主流平台，而alt-tech平台（如Truth Social）的对话结构研究相对不足，需要专门的数据集来理解这些平台上的意见形成和辩论模式。

Method: 收集2023-2025年Truth Social对话线程，保留回复树结构；人工标注1,500个实例作为基准（论证挖掘和基于主张的立场检测）；评估不同LLM提示策略；使用最佳配置生成大规模LLM标签。

Result: 创建了TruthStance数据集（24,378帖子、523,360评论）；提供了人工标注基准（1,500实例）及标注者一致性分析；确定了最佳LLM提示策略；生成了额外LLM标签（24,352帖子的论证存在性、107,873评论的立场标签）；支持跨深度、主题和用户的分析。

Conclusion: TruthStance填补了alt-tech平台对话结构研究的空白，为论证挖掘和立场检测提供了宝贵资源。LLM提示策略的有效性表明自动化标注的可行性，数据集支持对Truth Social上意见动态的深入分析。

Abstract: Argument mining and stance detection are central to understanding how opinions are formed and contested in online discourse. However, most publicly available resources focus on mainstream platforms such as Twitter and Reddit, leaving conversational structure on alt-tech platforms comparatively under-studied. We introduce TruthStance, a large-scale dataset of Truth Social conversation threads spanning 2023-2025, consisting of 24,378 posts and 523,360 comments with reply-tree structure preserved. We provide a human-annotated benchmark of 1,500 instances across argument mining and claim-based stance detection, including inter-annotator agreement, and use it to evaluate large language model (LLM) prompting strategies. Using the best-performing configuration, we release additional LLM-generated labels for 24,352 posts (argument presence) and 107,873 comments (stance to parent), enabling analysis of stance and argumentation patterns across depth, topics, and users. All code and data are released publicly.

</details>


### [56] [WavePhaseNet: A DFT-Based Method for Constructing Semantic Conceptual Hierarchy Structures (SCHS)](https://arxiv.org/abs/2602.14419)
*Kiyotaka Kasubuchi,Kazuo Fukiya*

Main category: cs.CL

TL;DR: 该论文使用测度论和频率分析重新表述Transformer/注意力机制，从理论上证明幻觉是LLMs的结构性限制，并提出WavePhaseNet方法通过DFT构建语义概念层次结构，将嵌入空间从24,576维降至3,000维以抑制幻觉，同时引入上同调一致性控制来量化局部推理间的不一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer/注意力机制在大型语言模型中存在幻觉问题，作者认为这是结构性的限制而非偶然现象。需要从理论上理解幻觉的根本原因，并开发能够抑制幻觉、保持语义一致性的新方法。

Method: 1. 使用测度论和频率分析重新表述Transformer机制，将嵌入空间视为σ-代数上的条件期望
2. 提出WavePhaseNet方法：通过离散傅里叶变换(DFT)沿序列维度分解语义信息，构建语义概念层次结构(SCHS)
3. 维度约简：基于累积能量分析，将GPT-4的24,576维嵌入空间降至约3,000维
4. 上同调一致性控制：在约简后的嵌入空间上应用上同调正则化，通过霍奇理论的调和投影控制语义一致性

Result: 1. 理论上证明了幻觉是LLMs的结构性限制，嵌入空间与语义真值集之间的非同构关系导致逻辑一致性崩溃
2. 通过DFT成功分离了语义信息的频率成分：低频捕获全局意义和意图，高频表示局部句法和表达
3. 确定了3,000维是"完整表示"的下界，维度约简既能保持意义和意图，又能实现严格推理并抑制幻觉
4. 上同调一致性控制能够量化局部推理间的不一致性，提取最大一致性的全局表示

Conclusion: 幻觉是LLMs的根本结构限制，但通过频率分析和上同调方法可以显著缓解。WavePhaseNet通过语义概念层次结构和维度约简，结合上同调一致性控制，为构建更可靠、一致性更强的语言模型提供了理论框架和实用方法。

Abstract: This paper reformulates Transformer/Attention mechanisms in Large Language Models (LLMs) through measure theory and frequency analysis, theoretically demonstrating that hallucination is an inevitable structural limitation. The embedding space functions as a conditional expectation over a σ-algebra, and its failure to be isomorphic to the semantic truth set fundamentally causes logical consistency breakdown. WavePhaseNet Method The authors propose WavePhaseNet, which explicitly constructs a Semantic Conceptual Hierarchy Structure (SCHS) using Discrete Fourier Transform (DFT). By applying DFT along the sequence dimension, semantic information is decomposed into frequency bands: low-frequency components capture global meaning and intent, while high-frequency components represent local syntax and expression. This staged separation enables precise semantic manipulation in diagonalized space. Dimensionality Reduction GPT-4's 24,576-dimensional embedding space exhibits a 1/f spectral structure based on language self-similarity and Zipf's law. Through cumulative energy analysis, the authors derive that approximately 3,000 dimensions constitute the lower bound for "complete representation." This demonstrates that reduction from 24,576 to 3,000 dimensions preserves meaning and intent while enabling rigorous reasoning and suppressing hallucination. Cohomological Consistency Control The reduced embedding space, constructed via cohomological regularization over overlapping local windows, allows defining a graph structure and cochain complex. This quantifies inconsistencies among local inferences as coboundary-based losses. Applying harmonic projection based on Hodge theory positions cohomology as a computable regularization principle for controlling semantic consistency, extracting maximally consistent global representations.

</details>


### [57] [LLM-Guided Knowledge Distillation for Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2602.14428)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Man Wang*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型辅助的时序知识图谱蒸馏框架，通过将LLM作为辅助教师提供丰富的背景知识和时序信号，使得轻量级学生模型能够在保持推理效率的同时提升时序推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前时序知识图谱推理模型计算量大、部署成本高，而现有的压缩和蒸馏技术主要针对静态图设计，直接应用于时序场景会忽略时间依赖的交互关系，导致性能下降。

Method: 提出LLM辅助的时序知识图谱蒸馏框架，包含传统的时序教师模型和LLM辅助教师。LLM提供丰富的背景知识和时序信号，采用分阶段对齐策略逐步整合两个教师的指导，通过联合优化监督和蒸馏目标进行训练。

Result: 在多个公开TKG基准测试中，使用不同骨干架构的实验表明，该方法相比强基线蒸馏方法持续提升了链接预测性能，同时保持了学生模型的紧凑性和高效性。

Conclusion: 大语言模型作为有效教师具有将时序推理能力转移到资源高效TKG系统的潜力，提出的框架为时序知识图谱的高效部署提供了新思路。

Abstract: Temporal knowledge graphs (TKGs) support reasoning over time-evolving facts, yet state-of-the-art models are often computationally heavy and costly to deploy. Existing compression and distillation techniques are largely designed for static graphs; directly applying them to temporal settings may overlook time-dependent interactions and lead to performance degradation. We propose an LLM-assisted distillation framework specifically designed for temporal knowledge graph reasoning. Beyond a conventional high-capacity temporal teacher, we incorporate a large language model as an auxiliary instructor to provide enriched supervision. The LLM supplies broad background knowledge and temporally informed signals, enabling a lightweight student to better model event dynamics without increasing inference-time complexity. Training is conducted by jointly optimizing supervised and distillation objectives, using a staged alignment strategy to progressively integrate guidance from both teachers. Extensive experiments on multiple public TKG benchmarks with diverse backbone architectures demonstrate that the proposed approach consistently improves link prediction performance over strong distillation baselines, while maintaining a compact and efficient student model. The results highlight the potential of large language models as effective teachers for transferring temporal reasoning capability to resource-efficient TKG systems.

</details>


### [58] [Robust Bias Evaluation with FilBBQ: A Filipino Bias Benchmark for Question-Answering Language Models](https://arxiv.org/abs/2602.14466)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: FilBBQ扩展了BBQ偏见基准，创建了针对菲律宾语境的包含1万多个提示的偏见测试，用于评估生成模型在性别和同性恋偏见方面的表现。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言生成成为语言模型的流行用例，BBQ偏见基准变得重要，但需要扩展语言范围，特别是针对菲律宾语境，评估模型在性别和同性恋方面的偏见。

Method: 通过四个阶段开发过程：模板分类、文化感知翻译、新模板构建和提示生成，创建了包含1万多个提示的FilBBQ测试。采用改进的评估协议，通过多个种子运行获取响应并平均偏见分数，提高可靠性。

Result: 结果证实了不同种子间偏见分数的变异性，以及模型在情感、家庭、刻板同性恋兴趣和一夫多妻制方面存在性别和同性恋偏见。

Conclusion: FilBBQ成功扩展了BBQ基准到菲律宾语境，提供了更可靠的评估方法，揭示了菲律宾语模型中存在的特定偏见模式，可通过GitHub获取。

Abstract: With natural language generation becoming a popular use case for language models, the Bias Benchmark for Question-Answering (BBQ) has grown to be an important benchmark format for evaluating stereotypical associations exhibited by generative models. We expand the linguistic scope of BBQ and construct FilBBQ through a four-phase development process consisting of template categorization, culturally aware translation, new template construction, and prompt generation. These processes resulted in a bias test composed of more than 10,000 prompts which assess whether models demonstrate sexist and homophobic prejudices relevant to the Philippine context. We then apply FilBBQ on models trained in Filipino but do so with a robust evaluation protocol that improves upon the reliability and accuracy of previous BBQ implementations. Specifically, we account for models' response instability by obtaining prompt responses across multiple seeds and averaging the bias scores calculated from these distinctly seeded runs. Our results confirm both the variability of bias scores across different seeds and the presence of sexist and homophobic biases relating to emotion, domesticity, stereotyped queer interests, and polygamy. FilBBQ is available via GitHub.

</details>


### [59] [Measuring and Mitigating Post-hoc Rationalization in Reverse Chain-of-Thought Generation](https://arxiv.org/abs/2602.14469)
*Guangyue Peng,Zongchao Chen,Wen Luo,Yuntao Wen,Wei Li,Ruixiang Feng,Ran Le,Chen Yang,Zhenwei An,Yang Song,Tao Zhang,Houfeng Wang*

Main category: cs.CL

TL;DR: 该论文研究了反向思维链生成中的认知锚定问题，提出了一种结构骨架引导的推理方法来解决答案依赖性问题，显著降低了认知锚定效应。


<details>
  <summary>Details</summary>
Motivation: 传统反向思维链生成方法存在认知锚定问题：模型在生成推理过程时看到答案，导致生成的解释是事后合理化而非真实推理过程。

Method: 提出了三个层次的认知锚定测量框架（词汇、熵、概率），并基于此设计了结构骨架引导推理方法。该方法首先生成答案不变的功能性骨架结构，然后用这个骨架指导完整的推理过程生成。还提出了蒸馏版本SSR-D，通过微调确保结构一致性。

Result: SSR-D方法在开放式推理基准测试中相比抑制基线有高达10%的改进，同时保持了分布外泛化能力。该方法在所有三个认知锚定层次上都显著降低了锚定效应。

Conclusion: 结构骨架引导的推理方法通过将信息流从答案监控转向结构规划，有效解决了反向思维链生成中的认知锚定问题，为生成更真实的推理过程提供了新思路。

Abstract: Reverse Chain-of-Thought Generation (RCG) synthesizes reasoning traces from query-answer pairs, but runs the risk of producing post-hoc rationalizations: when models can see the answer during generation, the answer serves as a cognitive anchor that shapes the entire explanation. We formalize this phenomenon through a three-level measurement hierarchy: lexical, entropic, and probabilistic anchoring, each captures surface artifacts, entropy dynamics, and latent answer dependence, respectively. We analyze semantic suppression, the intuitive mitigation strategy that instructs models to ignore the answer, to find out its counterproduction: while it reduces lexical overlap, it paradoxically increases entropic and probabilistic anchoring. Drawing on Ironic Process Theory from cognitive psychology, we attribute this failure to active monitoring of the forbidden answer, which inadvertently deepens dependence on it. To break this cycle, we propose Structural Skeleton-guided Reasoning (SSR), a two-phase approach that first generates an answer-invariant functional skeleton structure, then uses this skeleton to guide full trace generation. By redirecting the information flow to structural planning rather than answer monitoring, SSR consistently reduces anchoring across all three levels. We further introduce Distilled SSR (SSR-D), which fine-tunes models on teacher-generated SSR traces to ensure reliable structural adherence. Experiments across open-ended reasoning benchmarks demonstrate that SSR-D achieves up to 10% improvement over suppression baselines while preserving out-of-distribution (OOD) generalization.

</details>


### [60] [HyperRAG: Reasoning N-ary Facts over Hypergraphs for Retrieval Augmented Generation](https://arxiv.org/abs/2602.14470)
*Wen-Sheng Lien,Yu-Kai Chan,Hao-Lung Hsiao,Bo-Kai Ruan,Meng-Fen Chiang,Chien-An Chen,Yi-Ren Yeh,Hong-Han Shuai*

Main category: cs.CL

TL;DR: HyperRAG是一个基于n元超图的检索增强生成框架，通过两种互补的检索变体（HyperRetriever和HyperMemory）解决传统基于知识图谱的RAG方法在关系表达、检索效率和计算开销方面的限制。


<details>
  <summary>Details</summary>
Motivation: 传统的基于知识图谱的RAG方法存在三个主要问题：1）刚性检索方案和密集相似性搜索会引入无关上下文；2）计算开销大；3）二元关系事实限制了关系表达能力。相比之下，n元超图能编码更高阶的关系事实，捕捉更丰富的实体间依赖关系，并支持更浅层、更高效的推理路径。

Method: 提出了HyperRAG框架，包含两种互补的检索变体：1）HyperRetriever：学习对n元事实进行结构-语义推理，构建查询条件化的关系链，支持准确的事实追踪、自适应高阶遍历和在上下文约束下的可解释多跳推理；2）HyperMemory：利用LLM的参数记忆来指导波束搜索，动态评分n元事实和实体以实现查询感知的路径扩展。

Result: 在WikiTopics（11个闭域数据集）和三个开放域QA基准（HotpotQA、MuSiQue和2WikiMultiHopQA）上的广泛评估验证了HyperRAG的有效性。HyperRetriever实现了最高的整体答案准确率，在MRR上平均提升2.95%，在Hits@10上平均提升1.23%超过最强基线。定性分析显示HyperRetriever通过自适应和可解释的n元链构建来弥合推理差距。

Conclusion: HyperRAG通过利用n元超图的优势，为开放域和闭域QA任务提供了更高效、更准确的检索增强生成解决方案。该方法在关系表达能力、推理效率和可解释性方面都优于传统的基于知识图谱的RAG方法。

Abstract: Graph-based retrieval-augmented generation (RAG) methods, typically built on knowledge graphs (KGs) with binary relational facts, have shown promise in multi-hop open-domain QA. However, their rigid retrieval schemes and dense similarity search often introduce irrelevant context, increase computational overhead, and limit relational expressiveness. In contrast, n-ary hypergraphs encode higher-order relational facts that capture richer inter-entity dependencies and enable shallower, more efficient reasoning paths. To address this limitation, we propose HyperRAG, a RAG framework tailored for n-ary hypergraphs with two complementary retrieval variants: (i) HyperRetriever learns structural-semantic reasoning over n-ary facts to construct query-conditioned relational chains. It enables accurate factual tracking, adaptive high-order traversal, and interpretable multi-hop reasoning under context constraints. (ii) HyperMemory leverages the LLM's parametric memory to guide beam search, dynamically scoring n-ary facts and entities for query-aware path expansion. Extensive evaluations on WikiTopics (11 closed-domain datasets) and three open-domain QA benchmarks (HotpotQA, MuSiQue, and 2WikiMultiHopQA) validate HyperRAG's effectiveness. HyperRetriever achieves the highest answer accuracy overall, with average gains of 2.95% in MRR and 1.23% in Hits@10 over the strongest baseline. Qualitative analysis further shows that HyperRetriever bridges reasoning gaps through adaptive and interpretable n-ary chain construction, benefiting both open and closed-domain QA.

</details>


### [61] [BETA-Labeling for Multilingual Dataset Construction in Low-Resource IR](https://arxiv.org/abs/2602.14488)
*Md. Najib Hasan,Mst. Jannatun Ferdous Rain,Fyad Mohammed,Nazmul Siddique*

Main category: cs.CL

TL;DR: 本文提出了一种用于低资源语言信息检索的孟加拉语数据集构建框架，通过多LLM标注和人工验证确保质量，并研究了跨语言数据集重用的局限性。


<details>
  <summary>Details</summary>
Motivation: 低资源语言信息检索面临高质量标注数据集稀缺的挑战，手动标注成本高且难以扩展，而使用LLM作为自动标注器存在标签可靠性、偏见和评估有效性的问题。

Method: 采用BETA标注框架，使用来自不同模型家族的多个LLM标注器，结合上下文对齐、一致性检查和多数同意机制，最后通过人工评估验证标签质量。同时研究了通过单跳机器翻译重用其他低资源语言IR数据集的有效性。

Result: 实验显示不同语言之间存在显著差异，反映了语言依赖性偏见和不一致的语义保留，直接影响跨语言数据集重用的可靠性。研究揭示了LLM辅助数据集创建的潜力和局限性。

Conclusion: 本研究强调了LLM辅助低资源语言IR数据集创建的潜力和局限性，提供了跨语言数据集重用风险的实证证据，并为构建更可靠的基准和评估流程提供了实用指导。

Abstract: IR in low-resource languages remains limited by the scarcity of high-quality, task-specific annotated datasets. Manual annotation is expensive and difficult to scale, while using large language models (LLMs) as automated annotators introduces concerns about label reliability, bias, and evaluation validity. This work presents a Bangla IR dataset constructed using a BETA-labeling framework involving multiple LLM annotators from diverse model families. The framework incorporates contextual alignment, consistency checks, and majority agreement, followed by human evaluation to verify label quality. Beyond dataset creation, we examine whether IR datasets from other low-resource languages can be effectively reused through one-hop machine translation. Using LLM-based translation across multiple language pairs, we experimented on meaning preservation and task validity between source and translated datasets. Our experiment reveal substantial variation across languages, reflecting language-dependent biases and inconsistent semantic preservation that directly affect the reliability of cross-lingual dataset reuse. Overall, this study highlights both the potential and limitations of LLM-assisted dataset creation for low-resource IR. It provides empirical evidence of the risks associated with cross-lingual dataset reuse and offers practical guidance for constructing more reliable benchmarks and evaluation pipelines in low-resource language settings.

</details>


### [62] [Beyond Translation: Evaluating Mathematical Reasoning Capabilities of LLMs in Sinhala and Tamil](https://arxiv.org/abs/2602.14517)
*Sukumar Kishanthan,Kumar Thushalika,Buddhi Jayasekara,Asela Hevapathige*

Main category: cs.CL

TL;DR: LLMs在低资源语言（僧伽罗语和泰米尔语）中的数学推理能力并非真正的多语言推理，而是依赖于隐式翻译到英语，复杂推理任务在这些语言中表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLMs在低资源语言（如僧伽罗语和泰米尔语）中表现出的数学推理能力是否真正反映了多语言推理能力，还是仅仅依赖于隐式翻译到英语的处理方式。目前尚不清楚这些能力是真正的多语言推理还是基于翻译的处理。

Method: 研究方法包括：1）使用六种数学问题类型的分类法（从基础算术到复杂的单位冲突和优化问题）；2）评估四个知名的大型语言模型；3）构建平行数据集，每个问题均由三种语言（英语、僧伽罗语、泰米尔语）的流利母语者且具有数学训练背景的人士原生创作，以避免翻译质量对语言能力的混淆。

Result: 研究结果显示：基础算术推理在跨语言中表现稳健，但复杂推理任务在泰米尔语和僧伽罗语中表现出显著退化。失败模式因模型和问题类型而异，表明表面上的多语言能力并不反映跨语言的统一推理能力。

Conclusion: 研究结论挑战了模型表现出强大多语言性能就能在所有语言中同等有效推理的常见假设，并强调在多语言环境中需要细粒度、类型感知的评估。模型在低资源语言中的复杂推理能力存在实质性差距。

Abstract: Large language models (LLMs) demonstrate strong mathematical reasoning in English, but whether these capabilities reflect genuine multilingual reasoning or reliance on translation-based processing in low-resource languages like Sinhala and Tamil remains unclear. We examine this fundamental question by evaluating whether LLMs genuinely reason mathematically in these languages or depend on implicit translation to English-like representations. Using a taxonomy of six math problem types, from basic arithmetic to complex unit conflict and optimization problems, we evaluate four prominent large language models. To avoid translation artifacts that confound language ability with translation quality, we construct a parallel dataset where each problem is natively authored by fluent speakers with mathematical training in all three languages. Our analysis demonstrates that while basic arithmetic reasoning transfers robustly across languages, complex reasoning tasks show significant degradation in Tamil and Sinhala. The pattern of failures varies by model and problem type, suggesting that apparent multilingual competence may not reflect uniform reasoning capabilities across languages. These findings challenge the common assumption that models exhibiting strong multilingual performance can reason equally effectively across languages, and highlight the need for fine-grained, type-aware evaluation in multilingual settings.

</details>


### [63] [Explainable Token-level Noise Filtering for LLM Fine-tuning Datasets](https://arxiv.org/abs/2602.14536)
*Yuchen Yang,Wenze Lin,Enhao Huang,Zhixuan Chu,Hongbin Zhou,Lan Tao,Yiming Li,Zhan Qin,Kui Ren*

Main category: cs.CL

TL;DR: XTF框架通过分解token级数据对微调过程的贡献为三个属性（推理重要性、知识新颖性、任务相关性），过滤噪声token，显著提升LLM微调性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM微调存在数据集设计与优化机制不匹配的问题：大多数数据集是句子级别的，而LLM优化是token级别的，这引入了token级噪声，影响最终性能。

Method: 提出XTF框架，将token级数据对微调过程的贡献分解为三个明确属性：推理重要性、知识新颖性和任务相关性，通过评分方法评估这些属性，并相应屏蔽选定噪声token的梯度。

Result: 在数学、代码和医学三个代表性下游任务上对7个主流LLM进行实验，结果显示XTF相比常规微调可显著提升下游性能达13.7%。

Conclusion: XTF工作强调了token级数据集优化的重要性，并展示了基于属性分解的策略在解释复杂训练机制方面的潜力。

Abstract: Large Language Models (LLMs) have seen remarkable advancements, achieving state-of-the-art results in diverse applications. Fine-tuning, an important step for adapting LLMs to specific downstream tasks, typically involves further training on corresponding datasets. However, a fundamental discrepancy exists between current fine-tuning datasets and the token-level optimization mechanism of LLMs: most datasets are designed at the sentence-level, which introduces token-level noise, causing negative influence to final performance. In this paper, we propose XTF, an explainable token-level noise filtering framework. XTF decomposes the complex and subtle contributions of token-level data to the fine-tuning process into three distinct and explicit attributes (reasoning importance, knowledge novelty, and task relevance), which can be assessed using scoring methods, and then masks the gradients of selected noisy tokens accordingly to optimize the performance of fine-tuned LLMs. We conduct extensive experiments on three representative downstream tasks (math, code and medicine) across 7 mainstream LLMs. The results demonstrate that XTF can significantly improve downstream performance by up to 13.7% compared to regular fine-tuning. Our work highlights the importance of token-level dataset optimization, and demonstrates the potential of strategies based on attribute decomposition for explaining complex training mechanisms.

</details>


### [64] [Assessing Large Language Models for Medical QA: Zero-Shot and LLM-as-a-Judge Evaluation](https://arxiv.org/abs/2602.14564)
*Shefayat E Shams Adib,Ahmed Alfey Sani,Ekramul Alam Esham,Ajwad Abrar,Tareque Mohmud Chowdhury*

Main category: cs.CL

TL;DR: 比较五种LLM在医疗问答任务上的性能，发现更大模型表现更好，Llama-4-Maverick-17B在效率与性能间取得平衡，为医疗NLP应用提供基准。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在医疗QA任务中的表现，特别是在低资源环境下增强医疗可及性，为医疗NLP应用提供标准化基准。

Method: 使用iCliniq数据集（38,000个医疗问答），对五种LLM进行零样本评估，使用BLEU和ROUGE指标，不进行专门微调。

Result: 更大模型（如Llama 3.3 70B Instruct）表现优于小模型；Llama-4-Maverick-17B在性能与效率间取得更好平衡，展示实际部署潜力。

Conclusion: LLM在医疗推理方面能力持续提升，支持QA系统在真实临床环境中应用的可行性增加，为未来研究提供标准化基准以优化模型大小和计算资源。

Abstract: Recently, Large Language Models (LLMs) have gained significant traction in medical domain, especially in developing a QA systems to Medical QA systems for enhancing access to healthcare in low-resourced settings. This paper compares five LLMs deployed between April 2024 and August 2025 for medical QA, using the iCliniq dataset, containing 38,000 medical questions and answers of diverse specialties. Our models include Llama-3-8B-Instruct, Llama 3.2 3B, Llama 3.3 70B Instruct, Llama-4-Maverick-17B-128E-Instruct, and GPT-5-mini. We are using a zero-shot evaluation methodology and using BLEU and ROUGE metrics to evaluate performance without specialized fine-tuning. Our results show that larger models like Llama 3.3 70B Instruct outperform smaller models, consistent with observed scaling benefits in clinical tasks. It is notable that, Llama-4-Maverick-17B exhibited more competitive results, thus highlighting evasion efficiency trade-offs relevant for practical deployment. These findings align with advancements in LLM capabilities toward professional-level medical reasoning and reflect the increasing feasibility of LLM-supported QA systems in the real clinical environments. This benchmark aims to serve as a standardized setting for future study to minimize model size, computational resources and to maximize clinical utility in medical NLP applications.

</details>


### [65] [The Wikidata Query Logs Dataset](https://arxiv.org/abs/2602.14594)
*Sebastian Walter,Hannah Bast*

Main category: cs.CL

TL;DR: WDQL是一个包含20万对问题-查询对的Wikidata数据集，通过基于代理的方法从真实查询日志构建，用于训练问答系统。


<details>
  <summary>Details</summary>
Motivation: 现有Wikidata数据集规模较小且依赖模板生成查询，需要更大规模、基于真实查询的数据集来改进知识图谱问答系统的训练。

Method: 使用基于代理的方法，从Wikidata查询服务的真实匿名SPARQL日志出发，迭代地进行去匿名化、清理和验证，同时生成对应的自然语言问题。

Result: 构建了包含20万对问题-查询对的WDQL数据集，比现有类似格式的最大Wikidata数据集大6倍以上，所有资产和代理代码都已公开。

Conclusion: WDQL数据集为训练问答方法提供了有价值的资源，通过真实查询日志构建的数据集能更好地支持知识图谱问答系统的开发。

Abstract: We present the Wikidata Query Logs (WDQL) dataset, a dataset consisting of 200k question-query pairs over the Wikidata knowledge graph. It is over 6x larger than the largest existing Wikidata datasets of similar format without relying on template-generated queries. Instead, we construct it using real-world SPARQL queries sent to the Wikidata Query Service and generate questions for them. Since these log-based queries are anonymized, and therefore often do not produce results, a significant amount of effort is needed to convert them back into meaningful SPARQL queries. To achieve this, we present an agent-based method that iteratively de-anonymizes, cleans, and verifies queries against Wikidata while also generating corresponding natural-language questions. We demonstrate the dataset's benefit for training question-answering methods. All WDQL assets, as well as the agent code, are publicly available under a permissive license.

</details>


### [66] [GradMAP: Faster Layer Pruning with Gradient Metric and Projection Compensation](https://arxiv.org/abs/2602.14649)
*Hao Liu,Guangyan Li,Wensheng Zhang,Yongqiang Tang*

Main category: cs.CL

TL;DR: GradMAP是一个高效的LLM层剪枝方法，通过梯度度量和投影补偿在保持性能的同时实现快速剪枝。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）计算成本高，限制了实际部署。现有研究表明LLM层存在显著冗余，层剪枝成为研究热点。但当前方法无法同时保持剪枝性能和效率。

Method: 提出GradMAP方法，包含两个阶段：1）基于梯度幅度的新度量标准，仅需单次反向传播即可全局评估层重要性；2）分析剪枝导致的平均偏移，通过投影补偿矩阵一步校正偏移。

Result: 实验表明GradMAP在剪枝速度（平均4倍加速）和性能上都优于之前的层剪枝方法。

Conclusion: GradMAP通过高效的梯度度量和投影补偿，有效解决了层剪枝中性能与效率的平衡问题，为LLM部署提供了实用解决方案。

Abstract: Large Language Models (LLMs) exhibit strong reasoning abilities, but their high computational costs limit their practical deployment. Recent studies reveal significant redundancy in LLMs layers, making layer pruning an active research topic. Layer pruning research primarily focuses on two aspects: measuring layer importance and recovering performance after pruning. Unfortunately, the present works fail to simultaneously maintain pruning performance and efficiency. In this study, we propose GradMAP, a faster layer pruning method with \textbf{Grad}ient \textbf{M}etric \textbf{A}nd \textbf{P}rojection compensation, which consists of two stages. In the first stage, we introduce a novel metric based on gradient magnitudes, enabling a global assessment of layer importance. Note that, it requires only a single backward propagation step per pruning decision, substantially enhancing pruning efficiency. In the second stage, we first analyze the layers with the largest mean shift resulting from pruning, and then incorporate a simple yet effective projection compensation matrix to correct this drift in one step. In this way, the degradation of model performance caused by layer pruning is effectively alleviated. Extensive experiments show that GradMAP outperforms previous layer pruning methods in both pruning speed (achieving an average $4\times$ speedup) and performance.

</details>


### [67] [Is Information Density Uniform when Utterances are Grounded on Perception and Discourse?](https://arxiv.org/abs/2602.14653)
*Matteo Gay,Coleman Haley,Mario Giulianelli,Edoardo Ponti*

Main category: cs.CL

TL;DR: 首个计算研究探索视觉基础环境中的均匀信息密度假说，发现基于感知的语言比纯文本环境具有更高的信息均匀性。


<details>
  <summary>Details</summary>
Motivation: 先前研究仅限于纯文本输入，忽略了语言产生的感知语境。本研究旨在探索视觉基础环境中均匀信息密度假说的有效性。

Method: 使用多模态视觉语言模型在30种语言的图像-描述数据和13种语言的视觉叙事数据上估计惊奇值，涵盖11个语系。

Result: 感知基础一致性地平滑了信息分布，与纯文本环境相比，在类型多样的语言中都增加了全局和局部均匀性。在视觉叙事中，图像和语境的共同基础产生额外效果，最强的惊奇值降低出现在话语单元的开端。

Conclusion: 本研究首次模拟生态合理的多模态语言使用中的信息流时间动态，发现基础语言表现出更高的信息均匀性，支持了语境敏感的均匀信息密度假说。

Abstract: The Uniform Information Density (UID) hypothesis posits that speakers are subject to a communicative pressure to distribute information evenly within utterances, minimising surprisal variance. While this hypothesis has been tested empirically, prior studies are limited exclusively to text-only inputs, abstracting away from the perceptual context in which utterances are produced. In this work, we present the first computational study of UID in visually grounded settings. We estimate surprisal using multilingual vision-and-language models over image-caption data in 30 languages and visual storytelling data in 13 languages, together spanning 11 families. We find that grounding on perception consistently smooths the distribution of information, increasing both global and local uniformity across typologically diverse languages compared to text-only settings. In visual narratives, grounding in both image and discourse contexts has additional effects, with the strongest surprisal reductions occurring at the onset of discourse units. Overall, this study takes a first step towards modelling the temporal dynamics of information flow in ecologically plausible, multimodal language use, and finds that grounded language exhibits greater information uniformity, supporting a context-sensitive formulation of UID.

</details>


### [68] [Breaking Data Efficiency Dilemma: A Federated and Augmented Learning Framework For Alzheimer's Disease Detection via Speech](https://arxiv.org/abs/2602.14655)
*Xiao Wei,Bin Wen,Yuqin Lin,Kai Li,Mingyang gu,Xiaobao Wang,Longbiao Wang,Jianwu Dang*

Main category: cs.CL

TL;DR: FAL-AD是一个融合联邦学习和数据增强的框架，用于解决阿尔茨海默病语音检测中的数据效率困境，在ADReSSo数据集上实现了91.52%的多模态准确率。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期诊断至关重要，但基于AI的语音检测面临医疗数据稀缺和隐私障碍导致的数据效率困境。

Method: 提出FAL-AD框架，包含三个关键创新：1) 基于语音转换的数据增强，通过跨类别语音内容重组生成多样化病理语音样本；2) 自适应联邦学习范式，在隐私约束下最大化跨机构协作效益；3) 注意力跨模态融合模型，实现细粒度词级对齐和声学-文本交互。

Result: 在ADReSSo数据集上，FAL-AD实现了91.52%的多模态准确率，优于所有集中式基线方法，达到了最先进水平。

Conclusion: FAL-AD通过协同整合联邦学习和数据增强，系统性地优化了数据效率，为数据效率困境提供了实用解决方案。

Abstract: Early diagnosis of Alzheimer's Disease (AD) is crucial for delaying its progression. While AI-based speech detection is non-invasive and cost-effective, it faces a critical data efficiency dilemma due to medical data scarcity and privacy barriers. Therefore, we propose FAL-AD, a novel framework that synergistically integrates federated learning with data augmentation to systematically optimize data efficiency. Our approach delivers three key breakthroughs: First, absolute efficiency improvement through voice conversion-based augmentation, which generates diverse pathological speech samples via cross-category voice-content recombination. Second, collaborative efficiency breakthrough via an adaptive federated learning paradigm, maximizing cross-institutional benefits under privacy constraints. Finally, representational efficiency optimization by an attentive cross-modal fusion model, which achieves fine-grained word-level alignment and acoustic-textual interaction. Evaluated on ADReSSo, FAL-AD achieves a state-of-the-art multi-modal accuracy of 91.52%, outperforming all centralized baselines and demonstrating a practical solution to the data efficiency dilemma. Our source code is publicly available at https://github.com/smileix/fal-ad.

</details>


### [69] [Crowdsourcing Piedmontese to Test LLMs on Non-Standard Orthography](https://arxiv.org/abs/2602.14675)
*Gianluca Vico,Jindřich Libovický*

Main category: cs.CL

TL;DR: 本文提出了一个众包的皮埃蒙特语（意大利西北部濒危罗曼语）数据集，包含145个意大利语-皮埃蒙特语平行句子，用于评估大语言模型在分词一致性、主题分类和机器翻译方面的表现。


<details>
  <summary>Details</summary>
Motivation: 皮埃蒙特语是一种濒危的罗曼语，缺乏标准化的资源和数据集。为了评估大语言模型对这种低资源语言的处理能力，需要创建包含自然书写风格（而非标准化拼写）的平行语料库。

Method: 通过众包方式收集145个意大利语-皮埃蒙特语平行句子，这些句子来自Flores+数据集，由母语者以自然拼写风格翻译，并包含人工词语对齐。使用该数据集评估多个大语言模型在分词一致性、主题分类和机器翻译三个任务上的表现。

Result: 分析显示：1）皮埃蒙特语相对于高资源罗曼语存在分词惩罚；2）LLMs在主题分类任务上表现接近意大利语、法语和英语；3）机器翻译结果不对称：从皮埃蒙特语翻译到高资源语言表现尚可，但从高资源语言生成皮埃蒙特语仍然具有挑战性。

Conclusion: 尽管皮埃蒙特语面临分词挑战，但大语言模型在分类任务上表现良好。机器翻译的非对称性突显了低资源语言生成的困难。数据集和代码已公开发布，为皮埃蒙特语和类似濒危语言的研究提供了宝贵资源。

Abstract: We present a crowdsourced dataset for Piedmontese, an endangered Romance language of northwestern Italy. The dataset comprises 145 Italian-Piedmontese parallel sentences derived from Flores+, with translations produced by speakers writing in their natural orthographic style rather than adhering to standardized conventions, along with manual word alignment. We use this resource to benchmark several large language models on tokenization parity, topic classification, and machine translation. Our analysis reveals that Piedmontese incurs a tokenization penalty relative to higher-resource Romance languages, yet LLMs achieve classification performance approaching that of Italian, French, and English. Machine translation results are asymmetric: models translate adequately from Piedmontese into high-resource languages, but generation into Piedmontese remains challenging. The dataset and code are publicly released.

</details>


### [70] [LLMStructBench: Benchmarking Large Language Model Structured Data Extraction](https://arxiv.org/abs/2602.14743)
*Sönke Tenckhoff,Mario Koddenbrock,Erik Rodner*

Main category: cs.CL

TL;DR: LLMStructBench是一个用于评估大语言模型从自然语言文本中提取结构化数据和生成有效JSON输出的新基准，包含多样化的人工验证解析场景，支持对22个模型和5种提示策略进行系统测试。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统性评估LLM在结构化数据提取和JSON生成方面性能的基准，特别是在不同模型大小和提示策略下的解析可靠性比较。

Method: 构建了包含多样化、人工验证解析场景的开放数据集，设计了捕捉token级准确性和文档级有效性的互补性能指标，对22个模型和5种提示策略进行了系统测试。

Result: 研究发现选择正确的提示策略比模型大小等标准属性更重要，这尤其能确保较小或可靠性较低模型的结构有效性，但会增加语义错误数量。

Conclusion: LLMStructBench为未来LLM在解析或ETL应用领域的研究提供了重要工具，推动了该领域的发展。

Abstract: We present LLMStructBench, a novel benchmark for evaluating Large Language Models (LLMs) on extracting structured data and generating valid JavaScript Object Notation (JSON) outputs from natural-language text. Our open dataset comprises diverse, manually verified parsing scenarios of varying complexity and enables systematic testing across 22 models and five prompting strategies. We further introduce complementary performance metrics that capture both token-level accuracy and document-level validity, facilitating rigorous comparison of model, size, and prompting effects on parsing reliability.
  In particular, we show that choosing the right prompting strategy is more important than standard attributes such as model size. This especially ensures structural validity for smaller or less reliable models but increase the number of semantic errors. Our benchmark suite is an step towards future research in the area of LLM applied to parsing or Extract, Transform and Load (ETL) applications.

</details>


### [71] [Rethinking the Role of LLMs in Time Series Forecasting](https://arxiv.org/abs/2602.14744)
*Xin Qiu,Junlong Tong,Yirong Sun,Yunpu Ma,Wei Zhang,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 大规模研究表明，基于大语言模型的时间序列预测（LLM4TSF）确实能提升预测性能，尤其在跨域泛化方面表现突出，推翻了先前负面评估结论。


<details>
  <summary>Details</summary>
Motivation: 先前研究质疑大语言模型在时间序列预测中是否真正有益，但本研究认为这些结论源于有限的评估设置，需要进行大规模研究来验证LLM的实际价值。

Method: 进行了大规模LLM4TSF研究，涵盖80亿观测数据、17个预测场景、4个预测范围、多种对齐策略，并在域内和域外设置下进行实验。

Result: LLM4TS确实提高了预测性能，尤其在跨域泛化方面获得显著提升；预对齐在90%以上任务中优于后对齐；LLM的预训练知识和模型架构都起到互补作用。

Conclusion: 研究结果推翻了先前负面评估，明确了LLM在时间序列预测中有用的条件，并提供了有效的模型设计指导，完整LLM在大规模混合分布下不可或缺。

Abstract: Large language models (LLMs) have been introduced to time series forecasting (TSF) to incorporate contextual knowledge beyond numerical signals. However, existing studies question whether LLMs provide genuine benefits, often reporting comparable performance without LLMs. We show that such conclusions stem from limited evaluation settings and do not hold at scale. We conduct a large-scale study of LLM-based TSF (LLM4TSF) across 8 billion observations, 17 forecasting scenarios, 4 horizons, multiple alignment strategies, and both in-domain and out-of-domain settings. Our results demonstrate that \emph{LLM4TS indeed improves forecasting performance}, with especially large gains in cross-domain generalization. Pre-alignment outperforming post-alignment in over 90\% of tasks. Both pretrained knowledge and model architecture of LLMs contribute and play complementary roles: pretraining is critical under distribution shifts, while architecture excels at modeling complex temporal dynamics. Moreover, under large-scale mixed distributions, a fully intact LLM becomes indispensable, as confirmed by token-level routing analysis and prompt-based improvements. Overall, Our findings overturn prior negative assessments, establish clear conditions under which LLMs are not only useful, and provide practical guidance for effective model design. We release our code at https://github.com/EIT-NLP/LLM4TSF.

</details>


### [72] [Cognitive networks reconstruct mindsets about STEM subjects and educational contexts in almost 1000 high-schoolers, University students and LLM-based digital twins](https://arxiv.org/abs/2602.14749)
*Francesco Gariboldi,Emma Franchino,Edith Haim,Gianluca Lattanzi,Alessandro Grecucci,Massimo Stella*

Main category: cs.CL

TL;DR: 使用认知网络科学方法构建行为思维网络，分析不同群体对STEM的态度差异，发现数学和统计学存在负面情绪光环，揭示STEM科学认知与情感的不协调


<details>
  <summary>Details</summary>
Motivation: STEM态度是由概念知识、教育经验和情感相互作用形成的。需要理解不同群体（高中生、大学生、STEM专家）对STEM的认知情感结构，特别是数学焦虑现象，并探索LLM能否模拟人类教育焦虑

Method: 采用认知网络科学方法构建行为思维网络（BFMNs），节点为提示词和自由联想词，边为经验性联想链接，概念标注情感效价。分析N=994个观察样本，包括高中生、大学生、STEM早期专家，以及模拟这些群体的GPT-oss LLM"数字孪生"。通过语义邻域（"框架"）分析，量化情感光环、情绪轮廓、网络重叠（Jaccard相似度）和具体性

Result: 学生群体中，科学和研究始终被正面框架化，而核心定量学科（数学和统计学）表现出更多负面和焦虑相关的光环，在数学焦虑较高的子群体中更为明显，显示出STEM科学的认知与情感不协调。高焦虑框架比随机更不具体，表明对威胁性定量领域有更抽象和脱离情境的表征。人类网络中数学与焦虑的重叠度高于GPT-oss

Conclusion: BFMNs能够捕捉对目标领域思维方式的认知情感特征。LLM数字孪生可以近似文化态度，但无法复制人类教育焦虑中关键的情境敏感、经验相关的组成部分

Abstract: Attitudes toward STEM develop from the interaction of conceptual knowledge, educational experiences, and affect. Here we use cognitive network science to reconstruct group mindsets as behavioural forma mentis networks (BFMNs). In this case, nodes are cue words and free associations, edges are empirical associative links, and each concept is annotated with perceived valence. We analyse BFMNs from N = 994 observations spanning high school students, university students, and early-career STEM experts, alongside LLM (GPT-oss) "digital twins" prompted to emulate comparable profiles. Focusing also on semantic neighbourhoods ("frames") around key target concepts (e.g., STEM subjects or educational actors/places), we quantify frames in terms of valence auras, emotional profiles, network overlap (Jaccard similarity), and concreteness relative to null baselines. Across student groups, science and research are consistently framed positively, while their core quantitative subjects (mathematics and statistics) exhibit more negative and anxiety related auras, amplified in higher math-anxiety subgroups, evidencing a STEM-science cognitive and emotional dissonance. High-anxiety frames are also less concrete than chance, suggesting more abstract and decontextualised representations of threatening quantitative domains. Human networks show greater overlapping between mathematics and anxiety than GPT-oss. The results highlight how BFMNs capture cognitive-affective signatures of mindsets towards the target domains and indicate that LLM-based digital twins approximate cultural attitudes but miss key context-sensitive, experience-based components relevant to replicate human educational anxiety.

</details>


### [73] [Residual Connections and the Causal Shift: Uncovering a Structural Misalignment in Transformers](https://arxiv.org/abs/2602.14760)
*Jonathan Lys,Vincent Gripon,Bastien Pasdeloup,Lukas Mauch,Fabien Cardinaux,Ghouthi Boukli Hacene*

Main category: cs.CL

TL;DR: 该论文通过实验定位了自回归Transformer中存在的输入输出对齐偏移问题，并提出了一种轻量级的残差路径缓解方案来改善表示对齐，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: LLMs使用因果掩码进行并行训练时，残差连接将激活与当前token绑定，而监督目标却是预测下一个token，这种输入输出对齐偏移可能导致不匹配信息的传播，影响模型性能。

Method: 通过解码轨迹和基于相似度的度量在预训练LLMs中实证定位输入输出对齐偏移；提出基于残差衰减的轻量级缓解方案，包括固定层干预和可学习门控机制两种实现方式。

Result: 实验表明隐藏token表示在网络的深层会从输入对齐切换到输出对齐；提出的缓解策略有效减轻了表示不对齐问题，并在多个基准测试中带来了性能提升。

Conclusion: 该研究揭示了自回归Transformer中存在的输入输出对齐偏移问题，并提出了一种高效通用的架构增强方法，为改进LLMs的表示学习提供了新思路。

Abstract: Large Language Models (LLMs) are trained with next-token prediction, implemented in autoregressive Transformers via causal masking for parallelism. This creates a subtle misalignment: residual connections tie activations to the current token, while supervision targets the next token, potentially propagating mismatched information if the current token is not the most informative for prediction. In this work, we empirically localize this input-output alignment shift in pretrained LLMs, using decoding trajectories over tied embedding spaces and similarity-based metrics. Our experiments reveal that the hidden token representations switch from input alignment to output alignment deep within the network. Motivated by this observation, we propose a lightweight residual-path mitigation based on residual attenuation, implemented either as a fixed-layer intervention or as a learnable gating mechanism. Experiments on multiple benchmarks show that these strategies alleviate the representation misalignment and yield improvements, providing an efficient and general architectural enhancement for autoregressive Transformers.

</details>


### [74] [Unlocking Reasoning Capability on Machine Translation in Large Language Models](https://arxiv.org/abs/2602.14763)
*Sara Rajaee,Sebastian Vincent,Alexandre Berard,Marzieh Fadaee,Kelly Marchisio,Tom Kocmi*

Main category: cs.CL

TL;DR: 本文研究了推理导向大语言模型（RLMs）在机器翻译中的应用，发现通用的推理机制会降低翻译质量，并提出了一种针对翻译任务的结构化推理框架来改善性能。


<details>
  <summary>Details</summary>
Motivation: 推理导向大语言模型在数学和编程等任务上通过生成显式中间推理取得了显著效果，但这些模型在机器翻译任务上的影响尚未得到充分探索。作者想要系统评估RLMs在机器翻译中的表现，并理解为什么现有推理方法对翻译任务效果不佳。

Method: 1. 在WMT24++基准测试上系统评估多个开源和闭源推理导向大语言模型；2. 分析MT推理轨迹的特征；3. 提出针对翻译任务的结构化推理框架，包括多步草稿、充分性精炼、流畅性改进和选择性迭代修订；4. 构建动态结构化推理轨迹的合成数据集，并在该数据上对大推理模型进行后训练。

Result: 研究发现，启用显式推理会持续降低所有语言和模型的翻译质量。分析显示MT推理轨迹高度线性，缺乏修订、自我修正和替代翻译的探索。将更强模型的高质量推理轨迹注入较弱模型并不能可靠提升性能。提出的结构化推理框架在实验中显著优于标准翻译微调和注入通用推理的基线方法。

Conclusion: 推理必须针对具体任务进行结构化才能对机器翻译产生益处。通用的推理机制不适合翻译任务，需要设计专门的结构化推理方法。本文提出的翻译专用结构化推理框架有效改善了机器翻译性能。

Abstract: Reasoning-oriented large language models (RLMs) achieve strong gains on tasks such as mathematics and coding by generating explicit intermediate reasoning. However, their impact on machine translation (MT) remains underexplored. We systematically evaluate several open- and closed-weights RLMs on the WMT24++ benchmark and find that enabling explicit reasoning consistently degrades translation quality across languages and models. Analysis reveals that MT reasoning traces are highly linear, lacking revision, self-correction and exploration of alternative translations, which limits their usefulness. Furthermore, injecting higher-quality reasoning traces from stronger models does not reliably improve weaker models' performance. To address this mismatch, we propose a structured reasoning framework tailored to translation, based on multi-step drafting, adequacy refinement, fluency improvement, and selective iterative revision. We curate a synthetic dataset of dynamic structured reasoning traces and post-train a large reasoning model on this data. Experiments show significant improvements over standard translation fine-tuning and injected generic reasoning baselines. Our findings demonstrate that reasoning must be task-structured to benefit MT.

</details>


### [75] [Multi-Agent Comedy Club: Investigating Community Discussion Effects on LLM Humor Generation](https://arxiv.org/abs/2602.14770)
*Shiwei Hong,Lingyao Li,Ethan Z. Rong,Chenxinran Shen,Zhicong Lu*

Main category: cs.CL

TL;DR: 社区讨论能显著提升LLM生成的单口喜剧质量，在75.6%的对比中获胜，特别是在表达清晰度和社交回应方面有显著改善。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要关注即时反馈和局部优化，但缺乏对在线社区中持久公众反馈如何影响LLM写作质量的系统性研究。本研究旨在探索社区讨论对单口喜剧创作的影响。

Method: 采用多智能体沙盒控制实验：实验组记录、过滤并存储评论家和观众讨论作为社交记忆，后续生成时检索这些记忆；对照组则省略讨论。通过50轮实验生成250对独白，由5位专家标注员进行A/B偏好测试和15项评分。

Result: 讨论组在75.6%的实例中获胜，在"工艺/清晰度"维度提升0.440分，"社交回应"维度提升0.422分，偶尔会增加攻击性幽默内容。

Conclusion: 社区讨论能有效提升LLM写作质量，特别是在需要社交互动感知的创作任务中，但也需要注意可能带来的攻击性内容增加的风险。

Abstract: Prior work has explored multi-turn interaction and feedback for LLM writing, but evaluations still largely center on prompts and localized feedback, leaving persistent public reception in online communities underexamined. We test whether broadcast community discussion improves stand-up comedy writing in a controlled multi-agent sandbox: in the discussion condition, critic and audience threads are recorded, filtered, stored as social memory, and later retrieved to condition subsequent generations, whereas the baseline omits discussion. Across 50 rounds (250 paired monologues) judged by five expert annotators using A/B preference and a 15-item rubric, discussion wins 75.6% of instances and improves Craft/Clarity (Δ = 0.440) and Social Response (Δ = 0.422), with occasional increases in aggressive humor.

</details>


### [76] [Emergently Misaligned Language Models Show Behavioral Self-Awareness That Shifts With Subsequent Realignment](https://arxiv.org/abs/2602.14777)
*Laurène Vaugrante,Anietta Weckauff,Thilo Hagendorff*

Main category: cs.CL

TL;DR: LLMs fine-tuned on incorrect trivia数据会表现出毒性（"涌现性错位"），并且LLMs具有行为自省能力。研究发现，涌现性错位的模型能自我评估为更有害，这表明行为自省能力可以追踪模型的实际对齐状态，从而可以通过查询模型获取其安全性的信息。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索LLMs的"涌现性错位"现象（在错误问答对上微调后产生毒性）与行为自省能力（描述训练数据中隐含学习到的行为）的交叉点。研究人员想要了解模型是否能够自我意识到其行为转变，而不需要提供上下文示例。

Method: 研究方法是：1）对GPT-4.1模型顺序微调，使用已知会诱发和逆转涌现性错位的数据集；2）评估模型是否能在不提供上下文示例的情况下自我意识到其行为转变；3）比较涌现性错位模型、基础模型和重新对齐模型在自我有害性评估上的差异。

Result: 结果显示，涌现性错位的模型在自我评估中认为自身显著比基础模型和重新对齐的模型更有害。这表明模型对其自身的涌现性错位具有行为自省能力，能够准确反映其实际的对齐状态。

Conclusion: 研究结论是：模型的行为自省能力能够追踪其实际的对齐状态，这意味着可以通过查询模型来获取关于其自身安全性的信息信号。这一发现为模型安全性评估提供了新的途径。

Abstract: Recent research has demonstrated that large language models (LLMs) fine-tuned on incorrect trivia question-answer pairs exhibit toxicity - a phenomenon later termed "emergent misalignment". Moreover, research has shown that LLMs possess behavioral self-awareness - the ability to describe learned behaviors that were only implicitly demonstrated in training data. Here, we investigate the intersection of these phenomena. We fine-tune GPT-4.1 models sequentially on datasets known to induce and reverse emergent misalignment and evaluate whether the models are self-aware of their behavior transitions without providing in-context examples. Our results show that emergently misaligned models rate themselves as significantly more harmful compared to their base model and realigned counterparts, demonstrating behavioral self-awareness of their own emergent misalignment. Our findings show that behavioral self-awareness tracks actual alignment states of models, indicating that models can be queried for informative signals about their own safety.

</details>


### [77] [A Geometric Analysis of Small-sized Language Model Hallucinations](https://arxiv.org/abs/2602.14778)
*Emanuele Ricco,Elia Onofri,Lorenzo Cima,Stefano Cresci,Roberto Di Pietro*

Main category: cs.CL

TL;DR: 通过几何视角研究小规模语言模型的幻觉问题，发现真实回答在嵌入空间中呈现更紧密的聚类特性，并基于此开发了只需30-50个标注就能对大量回答进行分类的高效方法。


<details>
  <summary>Details</summary>
Motivation: 幻觉（流畅但事实错误的回答）是语言模型可靠性的主要挑战，特别是在多步骤或代理设置中。传统方法主要关注知识中心和单回答评估，需要从新视角研究幻觉问题。

Method: 采用几何视角分析幻觉，假设模型对同一提示生成多个回答时，真实回答在嵌入空间中呈现更紧密的聚类。证明该假设后，利用几何洞察开发标签高效的传播方法，只需30-50个标注就能分类大量回答。

Result: 验证了真实回答在嵌入空间中的聚类假设，实现了可分离性的一致性水平。提出的传播方法仅用30-50个标注就能达到90%以上的F1分数，显著提高了分类效率。

Conclusion: 从嵌入空间的几何视角研究幻觉问题，补充了传统的知识中心和单回答评估范式，为未来研究开辟了新方向，提供了一种高效检测和分类幻觉的方法。

Abstract: Hallucinations -- fluent but factually incorrect responses -- pose a major challenge to the reliability of language models, especially in multi-step or agentic settings.
  This work investigates hallucinations in small-sized LLMs through a geometric perspective, starting from the hypothesis that when models generate multiple responses to the same prompt, genuine ones exhibit tighter clustering in the embedding space, we prove this hypothesis and, leveraging this geometrical insight, we also show that it is possible to achieve a consistent level of separability. This latter result is used to introduce a label-efficient propagation method that classifies large collections of responses from just 30-50 annotations, achieving F1 scores above 90%.
  Our findings, framing hallucinations from a geometric perspective in the embedding space, complement traditional knowledge-centric and single-response evaluation paradigms, paving the way for further research.

</details>


### [78] [Overthinking Loops in Agents: A Structural Risk via MCP Tools](https://arxiv.org/abs/2602.14798)
*Yohan Lee,Jisoo Jang,Seoyeon Choi,Sangyeop Kim,Seungtaek Choi*

Main category: cs.CL

TL;DR: 恶意工具服务器可通过诱导过思考循环攻击LLM代理，导致资源急剧膨胀


<details>
  <summary>Details</summary>
Motivation: 当前基于文本可见元数据选择和链式调用第三方工具的LLM代理存在供应链攻击面，恶意MCP工具服务器可诱导过思考循环，显著增加计算资源和延迟

Method: 将攻击形式化为结构性过思考攻击，区别于标记级冗余；实现了14个恶意工具跨越三个服务器，触发重复、强制细化和分心等攻击模式

Result: 攻击导致严重的资源放大（最高达142.4倍标记量），可能降低任务结果质量；解码时简洁性控制无法可靠防止循环诱导

Conclusion: 防御机制应关注工具调用结构而非仅标记层面，需要针对供应链攻击设计更强大的防护措施

Abstract: Tool-using LLM agents increasingly coordinate real workloads by selecting and chaining third-party tools based on text-visible metadata such as tool names, descriptions, and return messages. We show that this convenience creates a supply-chain attack surface: a malicious MCP tool server can be co-registered alongside normal tools and induce overthinking loops, where individually trivial or plausible tool calls compose into cyclic trajectories that inflate end-to-end tokens and latency without any single step looking abnormal. We formalize this as a structural overthinking attack, distinguishable from token-level verbosity, and implement 14 malicious tools across three servers that trigger repetition, forced refinement, and distraction. Across heterogeneous registries and multiple tool-capable models, the attack causes severe resource amplification (up to $142.4\times$ tokens) and can degrade task outcomes. Finally, we find that decoding-time concision controls do not reliably prevent loop induction, suggesting defenses should reason about tool-call structure rather than tokens alone.

</details>


### [79] [Physical Commonsense Reasoning for Lower-Resourced Languages and Dialects: a Study on Basque](https://arxiv.org/abs/2602.14812)
*Jaione Bengoetxea,Itziar Gonzalez-Dios,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 论文提出了BasPhyCo——首个巴斯克语非问答式物理常识推理数据集，评估了多语言大语言模型在低资源语言巴斯克语上的物理常识推理能力，发现模型在处理方言变体时表现有限。


<details>
  <summary>Details</summary>
Motivation: 现有研究尚未考察大语言模型在低资源语言（如巴斯克语）的非问答式物理常识推理任务上的表现，存在研究空白。

Method: 以意大利语GITA数据集为起点，构建了巴斯克语的非问答式物理常识推理数据集BasPhyCo（包含标准语和方言变体），通过三个层次评估模型能力：准确性（区分合理/不合理叙述）、一致性（识别导致不合理冲突元素）、可验证性（确定具体物理状态）。

Result: 结果显示，在可验证性任务上，大语言模型在低资源语言巴斯克语中表现出有限的物理常识能力，尤其是在处理方言变体时。

Conclusion: 该研究填补了低资源语言物理常识推理评估的空白，揭示了当前多语言大语言模型在低资源语言物理常识推理方面的局限性，特别是在方言处理方面需要改进。

Abstract: Physical commonsense reasoning represents a fundamental capability of human intelligence, enabling individuals to understand their environment, predict future events, and navigate physical spaces. Recent years have witnessed growing interest in reasoning tasks within Natural Language Processing (NLP). However, no prior research has examined the performance of Large Language Models (LLMs) on non-question-answering (non-QA) physical commonsense reasoning tasks in low-resource languages such as Basque. Taking the Italian GITA as a starting point, this paper addresses this gap by presenting BasPhyCo, the first non-QA physical commonsense reasoning dataset for Basque, available in both standard and dialectal variants. We evaluate model performance across three hierarchical levels of commonsense understanding: (1) distinguishing between plausible and implausible narratives (accuracy), (2) identifying the conflicting element that renders a narrative implausible (consistency), and (3) determining the specific physical state that creates the implausibility (verifiability). These tasks were assessed using multiple multilingual LLMs as well as models pretrained specifically for Italian and Basque. Results indicate that, in terms of verifiability, LLMs exhibit limited physical commonsense capabilities in low-resource languages such as Basque, especially when processing dialectal variants.

</details>


### [80] [Testimole-Conversational: A 30-Billion-Word Italian Discussion Board Corpus (1996-2024) for Language Modeling and Sociolinguistic Research](https://arxiv.org/abs/2602.14819)
*Matteo Rinaldi,Rossella Varvara,Viviana Patti*

Main category: cs.CL

TL;DR: 提出了Testimole-conversational，一个包含超过300亿词符的意大利语讨论板消息大规模语料库，适用于意大利语大语言模型预训练和语言社会学分析。


<details>
  <summary>Details</summary>
Motivation: 意大利语缺乏大规模的本土语言资源用于大语言模型预训练，同时讨论板消息作为计算机中介通信形式，对语言学和社会学研究具有重要价值。

Method: 收集了1996年至2024年期间的意大利语讨论板消息，构建了包含超过300亿词符的大规模语料库，涵盖广泛的时间跨度。

Result: 创建了Testimole-conversational语料库，这是目前最大的意大利语讨论板消息数据集，捕捉了丰富的非正式书面意大利语、话语动态和在线社交互动。

Conclusion: 该语料库不仅为意大利语NLP应用（如语言建模、领域适应和对话分析）提供重要资源，还支持数字通信中的语言变异和社会现象研究，并将免费提供给研究社区。

Abstract: We present "Testimole-conversational" a massive collection of discussion boards messages in the Italian language. The large size of the corpus, more than 30B word-tokens (1996-2024), renders it an ideal dataset for native Italian Large Language Models'pre-training. Furthermore, discussion boards' messages are a relevant resource for linguistic as well as sociological analysis. The corpus captures a rich variety of computer-mediated communication, offering insights into informal written Italian, discourse dynamics, and online social interaction in wide time span. Beyond its relevance for NLP applications such as language modelling, domain adaptation, and conversational analysis, it also support investigations of language variation and social phenomena in digital communication. The resource will be made freely available to the research community.

</details>


### [81] [BFS-PO: Best-First Search for Large Reasoning Models](https://arxiv.org/abs/2602.14917)
*Fiorenzo Parascandolo,Wenhui Tan,Enver Sangineto,Ruihua Song,Rita Cucchiara*

Main category: cs.CL

TL;DR: BFS-PO是一种基于最佳优先搜索的强化学习算法，用于解决大型推理模型在推理任务中因过长推理链导致的过度思考问题，能同时提高准确率并缩短答案长度。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（如OpenAI o1和DeepSeek-R1）在推理任务中表现出色，但使用长推理链导致了计算成本显著增加和冗长输出（过度思考问题）。强化学习算法（如GRPO/DAPO）往往加剧了这种过度思考倾向。

Method: 提出BFS-PO算法，采用最佳优先搜索探索策略，通过基于最大熵节点的回溯机制寻找最短正确答案。在训练过程中通过生成逐渐缩短的响应，学习产生简洁的推理链。

Result: 使用不同基准测试和基础LRM进行实验，表明BFS-PO能够同时提高LRM的准确率并缩短其答案长度。

Conclusion: BFS-PO是一种有效的强化学习算法，能够缓解大型推理模型的过度思考问题，在保持或提高准确性的同时减少计算开销和输出冗余。

Abstract: Large Reasoning Models (LRMs) such as OpenAI o1 and DeepSeek-R1 have shown excellent performance in reasoning tasks using long reasoning chains. However, this has also led to a significant increase of computational costs and the generation of verbose output, a phenomenon known as overthinking. The tendency to overthinking is often exacerbated by Reinforcement Learning (RL) algorithms such as GRPO/DAPO. In this paper, we propose BFS-PO, an RL algorithm which alleviates this problem using a Best-First Search exploration strategy. Specifically, BFS-PO looks for the shortest correct answer using a backtracking mechanism based on maximum entropy nodes. By generating progressively shorter responses during training, BFS-PO learns to produce concise reasoning chains. Using different benchmarks and base LRMs, we show that BFS-PO can simultaneously increase the LRM accuracy and shorten its answers.

</details>


### [82] [Tool-Aware Planning in Contact Center AI: Evaluating LLMs through Lineage-Guided Query Decomposition](https://arxiv.org/abs/2602.14955)
*Varun Nathan,Shreyas Guha,Ayush Kumar*

Main category: cs.CL

TL;DR: 提出一个面向联络中心的工具感知计划生成框架和基准，用于评估LLM将业务查询分解为结构化/非结构化工具可执行步骤的能力，并通过评估框架、数据策展方法和大规模LLM研究揭示当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 在联络中心环境中，回答业务洞察查询需要将复杂查询分解为可在结构化工具（如Text2SQL）和非结构化工具（如RAG/转录本）上执行的步骤，当前缺乏系统评估LLM在此领域计划生成能力的框架和基准。

Method: 1) 建立基于参考的计划评估框架，包含两种模式：涵盖七个维度的度量评估器（工具提示对齐、查询遵循等）和一次性评估器；2) 开发数据策展方法，通过评估器->优化器循环迭代细化计划，生成高质量计划谱系；3) 对14个不同规模和家族的LLM进行大规模研究，评估其在有/无谱系提示下将查询分解为逐步、可执行、工具分配计划的能力。

Result: LLM在复合查询和超过4步的计划（通常5-15步）上表现不佳；最佳总度量分数为84.8%（Claude-3-7-Sonnet），而最强的"一次性匹配率"在"A+"级别仅为49.75%（o3-mini）；计划谱系整体带来混合收益，但使几个顶级模型受益并改善了许多步骤的可执行性；结果显示工具理解存在持续差距，特别是工具提示对齐和工具使用完整性方面，更短更简单的计划明显更容易。

Conclusion: 该框架和研究结果为评估和改进联络中心数据分查询的代理计划工具提供了可复现的路径，突显了LLM在工具感知计划生成方面的持续挑战，特别是在复杂多步骤场景中，为未来研究和系统改进提供了基础。

Abstract: We present a domain-grounded framework and benchmark for tool-aware plan generation in contact centers, where answering a query for business insights, our target use case, requires decomposing it into executable steps over structured tools (Text2SQL (T2S)/Snowflake) and unstructured tools (RAG/transcripts) with explicit depends_on for parallelism. Our contributions are threefold: (i) a reference-based plan evaluation framework operating in two modes - a metric-wise evaluator spanning seven dimensions (e.g., tool-prompt alignment, query adherence) and a one-shot evaluator; (ii) a data curation methodology that iteratively refines plans via an evaluator->optimizer loop to produce high-quality plan lineages (ordered plan revisions) while reducing manual effort; and (iii) a large-scale study of 14 LLMs across sizes and families for their ability to decompose queries into step-by-step, executable, and tool-assigned plans, evaluated under prompts with and without lineage. Empirically, LLMs struggle on compound queries and on plans exceeding 4 steps (typically 5-15); the best total metric score reaches 84.8% (Claude-3-7-Sonnet), while the strongest one-shot match rate at the "A+" tier (Extremely Good, Very Good) is only 49.75% (o3-mini). Plan lineage yields mixed gains overall but benefits several top models and improves step executability for many. Our results highlight persistent gaps in tool-understanding, especially in tool-prompt alignment and tool-usage completeness, and show that shorter, simpler plans are markedly easier. The framework and findings provide a reproducible path for assessing and improving agentic planning with tools for answering data-analysis queries in contact-center settings.

</details>


### [83] [Counterfactual Fairness Evaluation of LLM-Based Contact Center Agent Quality Assurance System](https://arxiv.org/abs/2602.14970)
*Kawin Mayilvaghanan,Siddhant Gupta,Ayush Kumar*

Main category: cs.CL

TL;DR: 对LLM在客服中心质量保证中的公平性评估，发现存在系统性偏见，大型对齐模型偏见较小，上下文提示会加剧偏见，公平性提示改进有限。


<details>
  <summary>Details</summary>
Motivation: LLM在客服中心质量保证中的部署日益增多，但其基于网络规模训练数据可能带来人口统计学和行为偏见，可能扭曲员工评估，需要系统性的公平性评估。

Method: 采用反事实公平性评估方法，在身份、上下文和行为风格三个类别共13个维度上评估LLM。使用反事实翻转率(CFR)和平均绝对分数差异(MASD)量化公平性，在3000个真实客服对话记录上评估18个LLM。

Result: 发现系统性差异，CFR在5.4%到13.0%之间，MASD在信心、积极和改进分数上显示一致偏移。大型强对齐模型偏见较小，但公平性与准确性不相关。历史表现上下文提示导致最严重的公平性下降(CFR高达16.4%)，隐含语言身份线索是持续偏见来源。公平性提示仅带来有限改进。

Conclusion: 研究强调在高风险员工评估中部署LLM前需要标准化的公平性审计流程，当前LLM在客服质量保证中存在系统性偏见，需要更有效的缓解策略。

Abstract: Large Language Models (LLMs) are increasingly deployed in contact-center Quality Assurance (QA) to automate agent performance evaluation and coaching feedback. While LLMs offer unprecedented scalability and speed, their reliance on web-scale training data raises concerns regarding demographic and behavioral biases that may distort workforce assessment. We present a counterfactual fairness evaluation of LLM-based QA systems across 13 dimensions spanning three categories: Identity, Context, and Behavioral Style. Fairness is quantified using the Counterfactual Flip Rate (CFR), the frequency of binary judgment reversals, and the Mean Absolute Score Difference (MASD), the average shift in coaching or confidence scores across counterfactual pairs. Evaluating 18 LLMs on 3,000 real-world contact center transcripts, we find systematic disparities, with CFR ranging from 5.4% to 13.0% and consistent MASD shifts across confidence, positive, and improvement scores. Larger, more strongly aligned models show lower unfairness, though fairness does not track accuracy. Contextual priming of historical performance induces the most severe degradations (CFR up to 16.4%), while implicit linguistic identity cues remain a persistent bias source. Finally, we analyze the efficacy of fairness-aware prompting, finding that explicit instructions yield only modest improvements in evaluative consistency. Our findings underscore the need for standardized fairness auditing pipelines prior to deploying LLMs in high-stakes workforce evaluation.

</details>


### [84] [Cold-Start Personalization via Training-Free Priors from Structured World Models](https://arxiv.org/abs/2602.15012)
*Avinandan Bose,Shuyue Stella Li,Faeze Brahman,Pang Wei Koh,Simon Shaolei Du,Yulia Tsvetkov,Maryam Fazel,Lin Xiao,Asli Celikyilmaz*

Main category: cs.CL

TL;DR: Pep框架通过离线学习偏好结构和在线贝叶斯推理，实现冷启动个性化偏好获取，比强化学习方法更准确、更高效。


<details>
  <summary>Details</summary>
Motivation: 冷启动个性化需要从交互中推断用户偏好，但现有方法如强化学习存在局限性：终端奖励无法利用偏好数据的结构化特征，学习到的策略往往退化为静态问题序列，忽略了用户响应。

Method: 提出Pep框架，将冷启动偏好获取分解为两个阶段：1) 离线结构学习：从完整用户档案中学习偏好相关性模型；2) 在线贝叶斯推理：基于学习到的结构模型选择信息量最大的问题，并预测完整偏好档案。

Result: 在医疗、数学、社交和常识推理任务中，Pep相比强化学习实现了80.8% vs 68.5%的响应偏好对齐度，交互次数减少3-5倍。当用户对同一问题给出不同答案时，Pep的后续问题调整率高达39-62%，而RL仅为0-28%。参数规模仅约1万，远小于RL的80亿。

Conclusion: 冷启动偏好获取的关键瓶颈在于有效利用偏好数据的结构化特征，Pep框架通过简单贝叶斯模型结合离线结构学习，显著提升了效率和准确性，展示了结构化建模的重要性。

Abstract: Cold-start personalization requires inferring user preferences through interaction when no user-specific historical data is available. The core challenge is a routing problem: each task admits dozens of preference dimensions, yet individual users care about only a few, and which ones matter depends on who is asking. With a limited question budget, asking without structure will miss the dimensions that matter. Reinforcement learning is the natural formulation, but in multi-turn settings its terminal reward fails to exploit the factored, per-criterion structure of preference data, and in practice learned policies collapse to static question sequences that ignore user responses. We propose decomposing cold-start elicitation into offline structure learning and online Bayesian inference. Pep (Preference Elicitation with Priors) learns a structured world model of preference correlations offline from complete profiles, then performs training-free Bayesian inference online to select informative questions and predict complete preference profiles, including dimensions never asked about. The framework is modular across downstream solvers and requires only simple belief models. Across medical, mathematical, social, and commonsense reasoning, Pep achieves 80.8% alignment between generated responses and users' stated preferences versus 68.5% for RL, with 3-5x fewer interactions. When two users give different answers to the same question, Pep changes its follow-up 39-62% of the time versus 0-28% for RL. It does so with ~10K parameters versus 8B for RL, showing that the bottleneck in cold-start elicitation is the capability to exploit the factored structure of preference data.

</details>


### [85] [Text Style Transfer with Parameter-efficient LLM Finetuning and Round-trip Translation](https://arxiv.org/abs/2602.15013)
*Ruoxi Liu,Philipp Koehn*

Main category: cs.CL

TL;DR: 提出基于参数高效微调大语言模型的文本风格迁移新方法，使用往返翻译构建平行语料库，在四个领域优于零样本提示和少样本上下文学习


<details>
  <summary>Details</summary>
Motivation: 文本风格迁移面临平行语料库稀缺的挑战，传统方法需要大量成对数据来映射不同风格之间的转换

Method: 1) 使用往返翻译从单语语料库合成平行数据集；2) 创建"中性化"文本消除风格属性；3) 采用参数高效微调LLMs；4) 结合检索增强生成提高术语和名称知识的准确性

Result: 在四个研究领域中，该方法在BLEU分数和风格准确度分数上均优于零样本提示和少样本上下文学习技术，表现出一致的优势

Conclusion: 该方法通过合成平行数据和参数高效微调有效解决了文本风格迁移中的数据稀缺问题，结合检索增强生成进一步提升了鲁棒性和风格一致性

Abstract: This paper proposes a novel method for Text Style Transfer (TST) based on parameter-efficient fine-tuning of Large Language Models (LLMs). Addressing the scarcity of parallel corpora that map between styles, the study employs roundtrip translation to synthesize such parallel datasets from monolingual corpora. This approach creates 'neutralized' text devoid of stylistic attributes, essentially creating a shared input style at training-time and inference-time. Experimental results demonstrate consistent superiority of this method over zero-shot prompting and fewshot ICL techniques measured by BLEU scores and style accuracy scores across four investigated domains. Furthermore, the integration of retrieval-augmented generation (RAG) for terminology and name knowledge enhances robustness and stylistic consistency.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [86] [LiveNewsBench: Evaluating LLM Web Search Capabilities with Freshly Curated News](https://arxiv.org/abs/2602.13543)
*Yunfan Zhang,Kathleen McKeown,Smaranda Muresan*

Main category: cs.IR

TL;DR: LiveNewsBench是一个自动生成、定期更新的基准测试，用于评估LLM的代理式网页搜索能力，通过最新新闻生成需要多步搜索的问题，区分模型内部知识和搜索能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法难以准确评估具有代理式网页搜索能力的LLM，因为难以区分模型内部知识和实际搜索能力，且缺乏针对此类系统的专门基准测试。

Method: 开发自动数据管理和问题生成流水线，从最新新闻文章生成问题-答案对，确保问题需要超出LLM训练数据的信息，包含需要多跳搜索查询、页面访问和推理的难题。

Result: 创建了LiveNewsBench基准测试，包含人类验证样本，评估了商业和开源LLM以及基于LLM的网页搜索API，建立了公开可用的排行榜、数据集和代码。

Conclusion: LiveNewsBench为评估LLM代理式网页搜索能力提供了严格、可更新的基准测试，解决了该领域数据稀缺问题，并支持大规模训练数据集构建。

Abstract: Large Language Models (LLMs) with agentic web search capabilities show strong potential for tasks requiring real-time information access and complex fact retrieval, yet evaluating such systems remains challenging. We introduce \bench, a rigorous and regularly updated benchmark designed to assess the agentic web search abilities of LLMs. \bench automatically generates fresh question-answer pairs from recent news articles, ensuring that questions require information beyond an LLM's training data and enabling clear separation between internal knowledge and search capability. The benchmark features intentionally difficult questions requiring multi-hop search queries, page visits, and reasoning, making it well-suited for evaluating agentic search behavior. Our automated data curation and question generation pipeline enables frequent benchmark updates and supports construction of a large-scale training dataset for agentic web search models, addressing the scarcity of such data in the research community. To ensure reliable evaluation, we include a subset of human-verified samples in the test set. We evaluate a broad range of systems using \bench, including commercial and open-weight LLMs as well as LLM-based web search APIs. The leaderboard, datasets, and code are publicly available at livenewsbench.com.

</details>


### [87] [Unleash the Potential of Long Semantic IDs for Generative Recommendation](https://arxiv.org/abs/2602.13573)
*Ming Xia,Zhiqin Zhou,Guoxin Ma,Dongmin Huang*

Main category: cs.IR

TL;DR: ACERec 通过解耦细粒度语义ID与高效序列建模之间的粒度差异，使用注意力令牌合并器和意图令牌，在保持语义表达力的同时提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有语义ID生成推荐方法面临表达力与计算效率的权衡：基于残差量化的方法限制语义ID长度以保证序列建模效率，而基于优化乘积量化的方法通过简单聚合压缩长语义ID，会丢失细粒度语义信息。

Method: 提出ACERec框架：1) 使用注意力令牌合并器将长表达性语义令牌蒸馏为紧凑潜变量；2) 引入专用的意图令牌作为动态预测锚点；3) 通过双粒度目标指导学习过程，协调细粒度令牌预测与全局项目级语义对齐。

Result: 在六个真实世界基准测试中，ACERec始终优于最先进的基线方法，在NDCG@10指标上平均提升14.40%，有效平衡了语义表达力与计算效率。

Conclusion: ACERec成功解决了语义ID生成推荐中表达力与效率的权衡问题，通过解耦粒度差异、使用注意力令牌合并和意图令牌机制，实现了更好的推荐性能。

Abstract: Semantic ID-based generative recommendation represents items as sequences of discrete tokens, but it inherently faces a trade-off between representational expressiveness and computational efficiency. Residual Quantization (RQ)-based approaches restrict semantic IDs to be short to enable tractable sequential modeling, while Optimized Product Quantization (OPQ)-based methods compress long semantic IDs through naive rigid aggregation, inevitably discarding fine-grained semantic information. To resolve this dilemma, we propose ACERec, a novel framework that decouples the granularity gap between fine-grained tokenization and efficient sequential modeling. It employs an Attentive Token Merger to distill long expressive semantic tokens into compact latents and introduces a dedicated Intent Token serving as a dynamic prediction anchor. To capture cohesive user intents, we guide the learning process via a dual-granularity objective, harmonizing fine-grained token prediction with global item-level semantic alignment. Extensive experiments on six real-world benchmarks demonstrate that ACERec consistently outperforms state-of-the-art baselines, achieving an average improvement of 14.40\% in NDCG@10, effectively reconciling semantic expressiveness and computational efficiency.

</details>


### [88] [Climber-Pilot: A Non-Myopic Generative Recommendation Model Towards Better Instruction-Following](https://arxiv.org/abs/2602.13581)
*Da Guo,Shijia Wang,Qiang Xiao,Yintao Ren,Weisheng Li,Songpei Xu,Ming Yue,Bin Huang,Guanlin Wu,Chuanjiang Luo*

Main category: cs.IR

TL;DR: Climber-Pilot是一个统一的生成式检索框架，通过时间感知多项目预测缓解生成式检索的短视问题，并通过条件引导稀疏注意力实现灵活的指令跟随检索，在NetEase云音乐平台显著提升业务指标。


<details>
  <summary>Details</summary>
Motivation: 生成式检索在大规模工业场景中存在固有短视问题：由于单步推理和严格延迟限制，模型倾向于将多样用户意图坍缩为局部最优预测，无法捕捉长期和多项目消费模式。同时，现实检索系统需要遵循明确的检索指令（如类别级控制和策略约束），而现有方法难以在不损害相关性或效率的情况下融入指令跟随行为。

Method: 提出Climber-Pilot统一框架：1) 时间感知多项目预测(TAMIP)：通过时间感知掩码将长期多项目预见性蒸馏到模型参数中，缓解局部最优预测同时保持高效单步推理；2) 条件引导稀疏注意力(CGSA)：通过稀疏注意力将业务约束直接融入生成过程，无需额外推理步骤。

Result: 在NetEase云音乐平台（最大音乐流媒体平台之一）进行的大量离线实验和在线A/B测试表明，Climber-Pilot显著优于最先进的基线方法，核心业务指标提升4.24%。

Conclusion: Climber-Pilot通过TAMIP和CGSA有效解决了生成式检索的短视问题和指令跟随挑战，在保持高效单步推理的同时提升了检索质量，为大规模工业推荐系统提供了实用的生成式检索解决方案。

Abstract: Generative retrieval has emerged as a promising paradigm in recommender systems, offering superior sequence modeling capabilities over traditional dual-tower architectures. However, in large-scale industrial scenarios, such models often suffer from inherent myopia: due to single-step inference and strict latency constraints, they tend to collapse diverse user intents into locally optimal predictions, failing to capture long-horizon and multi-item consumption patterns. Moreover, real-world retrieval systems must follow explicit retrieval instructions, such as category-level control and policy constraints. Incorporating such instruction-following behavior into generative retrieval remains challenging, as existing conditioning or post-hoc filtering approaches often compromise relevance or efficiency. In this work, we present Climber-Pilot, a unified generative retrieval framework to address both limitations. First, we introduce Time-Aware Multi-Item Prediction (TAMIP), a novel training paradigm designed to mitigate inherent myopia in generative retrieval. By distilling long-horizon, multi-item foresight into model parameters through time-aware masking, TAMIP alleviates locally optimal predictions while preserving efficient single-step inference. Second, to support flexible instruction-following retrieval, we propose Condition-Guided Sparse Attention (CGSA), which incorporates business constraints directly into the generative process via sparse attention, without introducing additional inference steps. Extensive offline experiments and online A/B testing at NetEase Cloud Music, one of the largest music streaming platforms, demonstrate that Climber-Pilot significantly outperforms state-of-the-art baselines, achieving a 4.24\% lift of the core business metric.

</details>


### [89] [GEMs: Breaking the Long-Sequence Barrier in Generative Recommendation with a Multi-Stream Decoder](https://arxiv.org/abs/2602.13631)
*Yu Zhou,Chengcheng Guo,Kuo Cai,Ji Liu,Qiang Luo,Ruiming Tang,Han Li,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: GEMs是一个创新的生成式推荐框架，通过多流解码器处理超长用户行为序列，突破传统方法在计算成本和注意力机制"近期偏差"上的限制，实现了对用户终身兴趣的建模。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐虽然具备强大的序列推理能力，但在处理极长用户行为序列时面临两个主要挑战：1）高计算成本迫使实际序列长度受限，无法捕捉用户的终身兴趣；2）注意力机制固有的"近期偏差"进一步削弱了对长期历史的学习。

Method: GEMs将用户行为划分为三个时间流：近期、中期和生命周期，并为每个流设计专门的推理方案：1）近期流使用单阶段实时提取器处理即时动态；2）中期流采用轻量级索引器进行交叉注意力，平衡准确性和成本；3）生命周期流采用两阶段离线-在线压缩模块进行终身建模。这些流通过参数无关的融合策略整合，实现整体兴趣表示。

Result: 在大规模工业数据集上的实验表明，GEMs在推荐准确性上显著优于最先进方法。GEMs是首个成功部署在高并发工业环境中的终身生成式推荐框架，能够处理超过10万次交互的用户序列，同时保持优越的推理效率。

Conclusion: GEMs通过多流解码器框架有效解决了生成式推荐在处理超长用户序列时的瓶颈，既提升了推荐准确性，又实现了高效的工业部署，为终身用户兴趣建模提供了可行的解决方案。

Abstract: While generative recommendations (GR) possess strong sequential reasoning capabilities, they face significant challenges when processing extremely long user behavior sequences: the high computational cost forces practical sequence lengths to be limited, preventing models from capturing users' lifelong interests; meanwhile, the inherent "recency bias" of attention mechanisms further weakens learning from long-term history. To overcome this bottleneck, we propose GEMs (Generative rEcommendation with a Multi-stream decoder), a novel and unified framework designed to break the long-sequence barrier by capturing users' lifelong interaction sequences through a multi-stream perspective. Specifically, GEMs partitions user behaviors into three temporal streams$\unicode{x2014}$Recent, Mid-term, and Lifecycle$\unicode{x2014}$and employs tailored inference schemes for each: a one-stage real-time extractor for immediate dynamics, a lightweight indexer for cross attention to balance accuracy and cost for mid-term sequences, and a two-stage offline-online compression module for lifelong modeling. These streams are integrated via a parameter-free fusion strategy to enable holistic interest representation. Extensive experiments on large-scale industrial datasets demonstrate that GEMs significantly outperforms state-of-the-art methods in recommendation accuracy. Notably, GEMs is the first lifelong GR framework successfully deployed in a high-concurrency industrial environment, achieving superior inference efficiency while processing user sequences of over 100,000 interactions.

</details>


### [90] [PT-RAG: Structure-Fidelity Retrieval-Augmented Generation for Academic Papers](https://arxiv.org/abs/2602.13647)
*Rui Yu,Tianyi Wang,Ruixia Liu,Yinglong Wang*

Main category: cs.IR

TL;DR: PT-RAG是一个新的RAG框架，通过保留学术论文的层次结构来构建低熵检索，相比传统方法能更精确地分配证据并减少上下文碎片化。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG方法在处理长学术论文时，通常将论文扁平化为无结构的文本块，这会破坏原有的层次结构。这种结构损失导致检索在无序空间中进行，产生碎片化的上下文，在有限token预算下将token分配给非证据区域，增加了下游语言模型的推理负担。

Method: PT-RAG采用原生层次结构作为低熵检索先验。首先基于原生层次结构构建结构保真的PaperTree索引，防止源头的熵增。然后设计路径引导的检索机制，将查询语义对齐到相关章节，并在固定token预算下选择高相关性的根到叶路径，生成紧凑、连贯、低熵的检索上下文。

Result: 在三个学术问答基准测试中，PT-RAG相比强基线实现了更低的章节熵和证据对齐交叉熵，表明减少了上下文碎片化并更精确地分配到证据区域。这些结构优势直接转化为更高的答案质量。

Conclusion: PT-RAG通过保留学术论文的层次结构作为低熵检索先验，有效解决了传统RAG方法在处理长文档时的结构破坏问题，实现了更精确的证据分配和更高质量的问答性能。

Abstract: Retrieval-augmented generation (RAG) is increasingly applied to question-answering over long academic papers, where accurate evidence allocation under a fixed token budget is critical. Existing approaches typically flatten academic papers into unstructured chunks during preprocessing, which destroys the native hierarchical structure. This loss forces retrieval to operate in a disordered space, thereby producing fragmented contexts, misallocating tokens to non-evidential regions under finite token budgets, and increasing the reasoning burden for downstream language models. To address these issues, we propose PT-RAG, an RAG framework that treats the native hierarchical structure of academic papers as a low-entropy retrieval prior. PT-RAG first inherits the native hierarchy to construct a structure-fidelity PaperTree index, which prevents entropy increase at the source. It then designs a path-guided retrieval mechanism that aligns query semantics to relevant sections and selects high relevance root-to-leaf paths under a fixed token budget, yielding compact, coherent, and low-entropy retrieval contexts. In contrast to existing RAG approaches, PT-RAG avoids entropy increase caused by destructive preprocessing and provides a native low-entropy structural basis for subsequent retrieval. To assess this design, we introduce entropy-based structural diagnostics that quantify retrieval fragmentation and evidence allocation accuracy. On three academic question-answering benchmarks, PT-RAG achieves consistently lower section entropy and evidence alignment cross entropy than strong baselines, indicating reduced context fragmentation and more precise allocation to evidential regions. These structural advantages directly translate into higher answer quality.

</details>


### [91] [Pailitao-VL: Unified Embedding and Reranker for Real-Time Multi-Modal Industrial Search](https://arxiv.org/abs/2602.13704)
*Lei Chen,Chen Ju,Xu Chen,Zhicheng Wang,Yuheng Jiao,Hongfeng Zhan,Zhaoyang Li,Shihao Xu,Zhixiang Zhao,Tong Jia,Jinsong Lan,Xiaoyong Zhu,Bo Zheng*

Main category: cs.IR

TL;DR: Pailitao-VL是一个为工业搜索设计的多模态检索系统，通过两个范式转变解决了现有方案的粒度不足、噪声敏感和效率-性能差距问题，在阿里巴巴电商平台上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前最先进多模态检索系统中的三个关键挑战：检索粒度不足、对环境噪声的脆弱性、以及效率与性能之间的巨大差距。

Method: 1. 将嵌入范式从传统的对比学习转变为绝对ID识别任务，通过将实例锚定到由数十亿语义原型定义的全局一致潜在空间；2. 将生成式重排器从孤立的逐点评估演变为"比较-校准"列表策略，结合基于块的比较推理和校准的绝对相关性评分。

Result: 在阿里巴巴电商平台的离线和在线A/B测试中，Pailitao-VL实现了最先进的性能，并带来了显著的商业影响。

Conclusion: 这项工作展示了在要求苛刻的大规模生产环境中部署基于MLLM的先进检索架构的稳健且可扩展的路径。

Abstract: In this work, we presented Pailitao-VL, a comprehensive multi-modal retrieval system engineered for high-precision, real-time industrial search. We here address three critical challenges in the current SOTA solution: insufficient retrieval granularity, vulnerability to environmental noise, and prohibitive efficiency-performance gap. Our primary contribution lies in two fundamental paradigm shifts. First, we transitioned the embedding paradigm from traditional contrastive learning to an absolute ID-recognition task. Through anchoring instances to a globally consistent latent space defined by billions of semantic prototypes, we successfully overcome the stochasticity and granularity bottlenecks inherent in existing embedding solutions. Second, we evolved the generative reranker from isolated pointwise evaluation to the compare-and-calibrate listwise policy. By synergizing chunk-based comparative reasoning with calibrated absolute relevance scoring, the system achieves nuanced discriminative resolution while circumventing the prohibitive latency typically associated with conventional reranking methods. Extensive offline benchmarks and online A/B tests on Alibaba e-commerce platform confirm that Pailitao-VL achieves state-of-the-art performance and delivers substantial business impact. This work demonstrates a robust and scalable path for deploying advanced MLLM-based retrieval architectures in demanding, large-scale production environments.

</details>


### [92] [DMESR: Dual-view MLLM-based Enhancing Framework for Multimodal Sequential Recommendation](https://arxiv.org/abs/2602.13715)
*Mingyao Huang,Qidong Liu,Wenxuan Yang,Moranxin Wang,Yuqi Sun,Haiping Zhu,Feng Tian,Yan Chen*

Main category: cs.IR

TL;DR: DMESR是一个双视角MLLM增强的多模态序列推荐框架，通过对比学习对齐跨模态表示，并利用交叉注意力融合MLLM的粗粒度语义与原始文本的细粒度语义，有效解决了现有方法中的模态对齐和细粒度语义丢失问题。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM增强推荐方法存在两个关键局限：1）难以有效对齐多模态表示，导致跨模态语义信息利用不足；2）过度依赖MLLM生成内容，忽略了物品原始文本数据中的细粒度语义线索。

Method: 提出DMESR框架：1）使用对比学习机制对齐MLLM生成的跨模态语义表示；2）引入交叉注意力融合模块，将MLLM获取的粗粒度语义知识与原始文本的细粒度语义相结合；3）将融合后的表示无缝集成到下游序列推荐模型中。

Result: 在三个真实世界数据集和三种流行序列推荐架构上的大量实验表明，该方法具有优越的有效性和泛化能力。

Conclusion: DMESR通过解决模态对齐和细粒度语义保留问题，显著提升了多模态序列推荐的性能，为MLLM增强推荐提供了有效的双视角融合框架。

Abstract: Sequential Recommender Systems (SRS) aim to predict users' next interaction based on their historical behaviors, while still facing the challenge of data sparsity. With the rapid advancement of Multimodal Large Language Models (MLLMs), leveraging their multimodal understanding capabilities to enrich item semantic representation has emerged as an effective enhancement strategy for SRS. However, existing MLLM-enhanced recommendation methods still suffer from two key limitations. First, they struggle to effectively align multimodal representations, leading to suboptimal utilization of semantic information across modalities. Second, they often overly rely on MLLM-generated content while overlooking the fine-grained semantic cues contained in the original textual data of items. To address these issues, we propose a Dual-view MLLM-based Enhancing framework for multimodal Sequential Recommendation (DMESR). For the misalignment issue, we employ a contrastive learning mechanism to align the cross-modal semantic representations generated by MLLMs. For the loss of fine-grained semantics, we introduce a cross-attention fusion module that integrates the coarse-grained semantic knowledge obtained from MLLMs with the fine-grained original textual semantics. Finally, these two fused representations can be seamlessly integrated into the downstream sequential recommendation models. Extensive experiments conducted on three real-world datasets and three popular sequential recommendation architectures demonstrate the superior effectiveness and generalizability of our proposed approach.

</details>


### [93] [A Tale of Two Graphs: Separating Knowledge Exploration from Outline Structure for Open-Ended Deep Research](https://arxiv.org/abs/2602.13830)
*Zhuofan Shi,Ming Ma,Zekun Yao,Fangkai Yang,Jue Zhang,Dongge Han,Victor Rühle,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.IR

TL;DR: 提出DualGraph记忆架构，通过分离知识存储与写作结构，提升开放深度研究代理的探索效率和报告质量。


<details>
  <summary>Details</summary>
Motivation: 现有开放深度研究代理存在两种主要问题：线性"搜索-生成"方法在证据增多时出现"迷失中间"失败；基于大纲的规划方法仅依赖LLM隐式推断知识缺口，对缺失关系和针对性探索的监督较弱。需要一种更有效的架构来支持长时程、迭代的研究工作流。

Method: 提出DualGraph记忆架构，包含两个协同演化的图：大纲图（OG）和知识图（KG）。KG作为语义记忆存储细粒度知识单元（核心实体、概念及其关系），通过分析KG拓扑结构和OG的结构信号，生成针对性搜索查询，实现更高效、全面的迭代知识驱动探索和精炼。

Result: 在DeepResearch Bench、DeepResearchGym和DeepConsult三个基准测试中，DualGraph在报告深度、广度和事实基础方面均优于现有最佳基线。例如，在DeepResearch Bench中使用GPT-5达到53.08 RACE分数。消融研究证实了双图设计的核心作用。

Conclusion: DualGraph通过分离知识表示与写作结构，为开放深度研究代理提供了更有效的记忆架构，能够生成更深入、全面且事实基础更扎实的研究报告，解决了现有方法的局限性。

Abstract: Open-Ended Deep Research (OEDR) pushes LLM agents beyond short-form QA toward long-horizon workflows that iteratively search, connect, and synthesize evidence into structured reports. However, existing OEDR agents largely follow either linear ``search-then-generate'' accumulation or outline-centric planning. The former suffers from lost-in-the-middle failures as evidence grows, while the latter relies on the LLM to implicitly infer knowledge gaps from the outline alone, providing weak supervision for identifying missing relations and triggering targeted exploration. We present DualGraph memory, an architecture that separates what the agent knows from how it writes. DualGraph maintains two co-evolving graphs: an Outline Graph (OG), and a Knowledge Graph (KG), a semantic memory that stores fine-grained knowledge units, including core entities, concepts, and their relations. By analyzing the KG topology together with structural signals from the OG, DualGraph generates targeted search queries, enabling more efficient and comprehensive iterative knowledge-driven exploration and refinement. Across DeepResearch Bench, DeepResearchGym, and DeepConsult, DualGraph consistently outperforms state-of-the-art baselines in report depth, breadth, and factual grounding; for example, it reaches a 53.08 RACE score on DeepResearch Bench with GPT-5. Moreover, ablation studies confirm the central role of the dual-graph design.

</details>


### [94] [DAIAN: Deep Adaptive Intent-Aware Network for CTR Prediction in Trigger-Induced Recommendation](https://arxiv.org/abs/2602.13971)
*Zhihao Lv,Longtao Zhang,Ailong He,Shuzhi Cao,Shuguang Han,Jufeng Chen*

Main category: cs.IR

TL;DR: 提出了DAIAN模型解决触发推荐中的意图短视问题，通过动态适应用户意图偏好，结合ID和语义信息增强相似性，提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有触发推荐系统存在意图短视问题，过度强调触发项作用，仅推荐与触发项高度相关的商品。同时，基于ID的交互稀疏性限制了捕捉用户偏好的效果。

Method: 提出深度自适应意图感知网络(DAIAN)：1)通过分析用户点击与触发项的相关性提取个性化意图表示，检索相关历史行为挖掘多样化意图；2)利用ID和语义信息的混合增强器强化相似性，根据不同意图进行自适应选择。

Result: 在公开数据集和工业电商数据集上的实验结果表明DAIAN的有效性。

Conclusion: DAIAN能够动态适应用户意图偏好，缓解意图短视问题，通过混合增强策略提升推荐性能，在实际电商场景中表现优异。

Abstract: Recommendation systems are essential for personalizing e-commerce shopping experiences. Among these, Trigger-Induced Recommendation (TIR) has emerged as a key scenario, which utilizes a trigger item (explicitly represents a user's instantaneous interest), enabling precise, real-time recommendations. Although several trigger-based techniques have been proposed, most of them struggle to address the intent myopia issue, that is, a recommendation system overemphasizes the role of trigger items and narrowly focuses on suggesting commodities that are highly relevant to trigger items. Meanwhile, existing methods rely on collaborative behavior patterns between trigger and recommended items to identify the user's preferences, yet the sparsity of ID-based interaction restricts their effectiveness. To this end, we propose the Deep Adaptive Intent-Aware Network (DAIAN) that dynamically adapts to users' intent preferences. In general, we first extract the users' personalized intent representations by analyzing the correlation between a user's click and the trigger item, and accordingly retrieve the user's related historical behaviors to mine the user's diverse intent. Besides, sparse collaborative behaviors constrain the performance in capturing items associated with user intent. Hence, we reinforce similarity by leveraging a hybrid enhancer with ID and semantic information, followed by adaptive selection based on varying intents. Experimental results on public datasets and our industrial e-commerce datasets demonstrate the effectiveness of DAIAN.

</details>


### [95] [MixFormer: Co-Scaling Up Dense and Sequence in Industrial Recommenders](https://arxiv.org/abs/2602.14110)
*Xu Huang,Hao Zhang,Zhifang Fan,Yunwen Huang,Zhuoxing Wei,Zheng Chai,Jinan Ni,Yuchao Zheng,Qiwei Chen*

Main category: cs.IR

TL;DR: MixFormer是一个统一的Transformer风格推荐系统架构，通过单一主干网络联合建模序列行为和特征交互，解决了传统分离设计中的协同扩展挑战，并在工业推荐系统中实现了更好的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer推荐模型存在结构碎片化问题，序列建模和特征交互被实现为独立的模块，导致在有限计算预算下，模型容量必须在密集特征交互和序列建模之间进行次优分配，存在协同扩展挑战。

Method: 提出MixFormer统一架构，使用单一主干网络联合建模序列行为和特征交互；采用统一参数化实现密集容量和序列长度的有效协同扩展；引入用户-物品解耦策略进行效率优化，减少冗余计算和推理延迟。

Result: 在大规模工业数据集上的实验表明，MixFormer在准确性和效率方面都表现出优越性；在抖音和抖音轻量版两个生产推荐系统上的大规模在线A/B测试显示，用户参与度指标（包括活跃天数和应用内使用时长）都有持续提升。

Conclusion: MixFormer通过统一架构解决了推荐系统中序列建模和特征交互的协同扩展问题，在保持工业实用性的同时实现了更好的性能表现，为大规模推荐系统的Transformer架构设计提供了新思路。

Abstract: As industrial recommender systems enter a scaling-driven regime, Transformer architectures have become increasingly attractive for scaling models towards larger capacity and longer sequence. However, existing Transformer-based recommendation models remain structurally fragmented, where sequence modeling and feature interaction are implemented as separate modules with independent parameterization. Such designs introduce a fundamental co-scaling challenge, as model capacity must be suboptimally allocated between dense feature interaction and sequence modeling under a limited computational budget. In this work, we propose MixFormer, a unified Transformer-style architecture tailored for recommender systems, which jointly models sequential behaviors and feature interactions within a single backbone. Through a unified parameterization, MixFormer enables effective co-scaling across both dense capacity and sequence length, mitigating the trade-off observed in decoupled designs. Moreover, the integrated architecture facilitates deep interaction between sequential and non-sequential representations, allowing high-order feature semantics to directly inform sequence aggregation and enhancing overall expressiveness. To ensure industrial practicality, we further introduce a user-item decoupling strategy for efficiency optimizations that significantly reduce redundant computation and inference latency. Extensive experiments on large-scale industrial datasets demonstrate that MixFormer consistently exhibits superior accuracy and efficiency. Furthermore, large-scale online A/B tests on two production recommender systems, Douyin and Douyin Lite, show consistent improvements in user engagement metrics, including active days and in-app usage duration.

</details>


### [96] [High Precision Audience Expansion via Extreme Classification in a Two-Sided Marketplace](https://arxiv.org/abs/2602.14358)
*Dillon Davis,Huiji Gao,Thomas Legrand,Juan Manuel Caicedo Carvajal,Malay Haldar,Kedar Bellare,Moutupsi Paul,Soumyadip Banerjee,Liwei He,Stephanie Moyerman,Sanjeev Katariya*

Main category: cs.IR

TL;DR: Airbnb 搜索重新架构，从全球2500万个均匀地图单元中选择最可能被预订的高精度矩形单元进行房源检索，以提升搜索效率。


<details>
  <summary>Details</summary>
Motivation: Airbnb 面临全球房源多样性与用户需求差异大的挑战，需要在资源密集型排序前，通过高效的检索阶段筛选出用户可能实际预订的房源。现有基于深度贝叶斯老虎机的矩形检索边界方法存在改进空间。

Method: 将全球划分为2500万个均匀的矩形地图单元，重新架构搜索系统，仅从最可能被预订的高精度矩形单元中检索房源，替代原有的矩形检索边界预测方法。

Result: 论文展示了该方法在搜索效率、检索精度和系统性能方面的改进，但具体指标未在摘要中明确给出。

Conclusion: 通过采用基于高精度地图单元的检索架构，Airbnb 搜索系统能够更有效地平衡全球房源供应与用户多样化需求，提升整体搜索体验。

Abstract: Airbnb search must balance a worldwide, highly varied supply of homes with guests whose location, amenity, style, and price expectations differ widely. Meeting those expectations hinges on an efficient retrieval stage that surfaces only the listings a guest might realistically book, before resource intensive ranking models are applied to determine the best results. Unlike many recommendation engines, our system faces a distinctive challenge, location retrieval, that sits upstream of ranking and determines which geographic areas are queried in order to filter inventory to a candidate set. The preexisting approach employs a deep bayesian bandit based system to predict a rectangular retrieval bounds area that can be used for filtering. The purpose of this paper is to demonstrate the methodology, challenges, and impact of rearchitecting search to retrieve from the subset of most bookable high precision rectangular map cells defined by dividing the world into 25M uniform cells.

</details>


### [97] [Behavioral Feature Boosting via Substitute Relationships for E-commerce Search](https://arxiv.org/abs/2602.14502)
*Chaosheng Dong,Michinari Momma,Yijia Wang,Yan Gao,Yi Sun*

Main category: cs.IR

TL;DR: 提出BFS方法，通过聚合替代产品的行为特征来解决电商新品冷启动问题，已在生产环境部署。


<details>
  <summary>Details</summary>
Motivation: 电商平台上新品面临冷启动问题：交互数据有限导致搜索可见性和相关性排序表现不佳，影响新品发现和竞争力。

Method: 提出BFS（行为特征增强）方法，识别满足相似用户需求的替代产品，并聚合这些替代产品的行为信号（如点击、加购、购买、评分），为新品提供"热启动"。将这些增强信号融入排序模型。

Result: 在大型电商平台的离线实验和在线实验中，BFS显著提升了冷启动产品的搜索相关性和产品发现。该方法可扩展且实用，改善了用户体验，增加了新品的曝光。

Conclusion: BFS方法有效缓解了冷启动效应，BFS增强的排序模型已从2025年开始在生产环境中部署并服务客户。

Abstract: On E-commerce platforms, new products often suffer from the cold-start problem: limited interaction data reduces their search visibility and hurts relevance ranking. To address this, we propose a simple yet effective behavior feature boosting method that leverages substitute relationships among products (BFS). BFS identifies substitutes-products that satisfy similar user needs-and aggregates their behavioral signals (e.g., clicks, add-to-carts, purchases, and ratings) to provide a warm start for new items. Incorporating these enriched signals into ranking models mitigates cold-start effects and improves relevance and competitiveness. Experiments on a large E-commerce platform, both offline and online, show that BFS significantly improves search relevance and product discovery for cold-start products. BFS is scalable and practical, improving user experience while increasing exposure for newly launched items in E-commerce search. The BFS-enhanced ranking model has been launched in production and has served customers since 2025.

</details>


### [98] [Adaptive Autoguidance for Item-Side Fairness in Diffusion Recommender Systems](https://arxiv.org/abs/2602.14706)
*Zihan Li,Gustavo Escobedo,Marta Moscati,Oleg Lesota,Markus Schedl*

Main category: cs.IR

TL;DR: A2G-DiffRec：一种采用自适应自引导的扩散推荐系统，通过弱模型引导主模型并学习自适应权重，以缓解流行度偏差，在保持推荐精度的同时提升项目侧公平性。


<details>
  <summary>Details</summary>
Motivation: 扩散推荐系统虽然精度高，但通常存在流行度偏差问题，导致项目曝光不均。需要一种方法在保持推荐准确性的同时，提高推荐系统的公平性。

Method: 提出A2G-DiffRec，采用自适应自引导机制：让主模型由训练较弱的自身版本引导。不是使用固定引导权重，而是在训练过程中通过流行度正则化监督，学习自适应权衡主模型和弱模型的输出，促进不同流行度项目的平衡曝光。

Result: 在MovieLens-1M、Foursquare-Tokyo和Music4All-Onion数据集上的实验表明，A2G-DiffRec能有效提升项目侧公平性，相比现有引导扩散推荐器和其他非扩散基线，仅以边际精度下降为代价。

Conclusion: A2G-DiffRec通过自适应自引导机制成功缓解了扩散推荐系统的流行度偏差问题，在保持较高推荐精度的同时显著提升了项目曝光公平性。

Abstract: Diffusion recommender systems achieve strong recommendation accuracy but often suffer from popularity bias, resulting in unequal item exposure. To address this shortcoming, we introduce A2G-DiffRec, a diffusion recommender that incorporates adaptive autoguidance, where the main model is guided by a less-trained version of itself. Instead of using a fixed guidance weight, A2G-DiffRec learns to adaptively weigh the outputs of the main and weak models during training, supervised by a popularity regularization that promotes balanced exposure across items with different popularity levels. Experimental results on the MovieLens-1M, Foursquare-Tokyo, and Music4All-Onion datasets show that A2G-DiffRec is effective in enhancing item-side fairness at a marginal cost of accuracy reduction compared to existing guided diffusion recommenders and other non-diffusion baselines.

</details>


### [99] [Orcheo: A Modular Full-Stack Platform for Conversational Search](https://arxiv.org/abs/2602.14710)
*Shaojie Jiang,Svitlana Vakulenko,Maarten de Rijke*

Main category: cs.IR

TL;DR: Orcheo是一个开源平台，旨在通过模块化架构、生产就绪的基础设施和丰富的现成组件，解决对话式搜索研究中缺乏统一框架和难以部署端到端原型的问题。


<details>
  <summary>Details</summary>
Motivation: 对话式搜索研究面临两个主要障碍：一是缺乏统一的框架来有效分享研究成果；二是难以部署用于用户评估的端到端原型。这阻碍了研究进展和社区协作。

Method: Orcheo采用模块化架构，通过单文件节点模块促进组件重用；提供生产就绪的基础设施，包括双执行模式、安全凭证管理和执行遥测；并内置AI编码支持以降低学习曲线。平台还提供50多个现成组件，涵盖查询理解、排序和响应生成。

Result: Orcheo成功构建了一个开源平台，通过案例研究验证了其模块性和易用性。该平台已作为开源项目发布，采用MIT许可证。

Conclusion: Orcheo通过提供统一的模块化平台，有效解决了对话式搜索研究中的共享和部署障碍，促进了研究可重复性和社区协作，为快速构建完整的对话式搜索管道提供了有力支持。

Abstract: Conversational search (CS) requires a complex software engineering pipeline that integrates query reformulation, ranking, and response generation. CS researchers currently face two barriers: the lack of a unified framework for efficiently sharing contributions with the community, and the difficulty of deploying end-to-end prototypes needed for user evaluation. We introduce Orcheo, an open-source platform designed to bridge this gap. Orcheo offers three key advantages: (i) A modular architecture promotes component reuse through single-file node modules, facilitating sharing and reproducibility in CS research; (ii) Production-ready infrastructure bridges the prototype-to-system gap via dual execution modes, secure credential management, and execution telemetry, with built-in AI coding support that lowers the learning curve; (iii) Starter-kit assets include 50+ off-the-shelf components for query understanding, ranking, and response generation, enabling the rapid bootstrapping of complete CS pipelines. We describe the framework architecture and validate Orcheo's utility through case studies that highlight modularity and ease of use. Orcheo is released as open source under the MIT License at https://github.com/ShaojieJiang/orcheo.

</details>


### [100] [Intent-Driven Dynamic Chunking: Segmenting Documents to Reflect Predicted Information Needs](https://arxiv.org/abs/2602.14784)
*Christos Koutsiaris*

Main category: cs.IR

TL;DR: IDC是一种基于用户意图的动态文档分块方法，通过预测查询来优化分块边界，显著提升检索性能并减少分块数量。


<details>
  <summary>Details</summary>
Motivation: 传统文档分块方法（如固定长度或基于连贯性的分块）忽略了用户意图，导致分块可能切分答案或包含无关噪声，影响检索系统性能。

Method: 提出意图驱动的动态分块（IDC）：1）使用大语言模型预测文档可能的用户查询意图；2）采用动态规划算法寻找全局最优的分块边界，避免贪婪算法的缺陷。

Result: 在六个问答数据集上的评估显示：IDC在五个数据集上优于传统分块方法，top-1检索准确率提升5%-67%；分块数量减少40%-60%；答案覆盖率达到93%-100%。

Conclusion: 将文档结构与预期信息需求对齐能显著提升检索性能，尤其适用于长文档和异构文档。IDC为意图感知的分块提供了有效解决方案。

Abstract: Breaking long documents into smaller segments is a fundamental challenge in information retrieval. Whether for search engines, question-answering systems, or retrieval-augmented generation (RAG), effective segmentation determines how well systems can locate and return relevant information. However, traditional methods, such as fixed-length or coherence-based segmentation, ignore user intent, leading to chunks that split answers or contain irrelevant noise. We introduce Intent-Driven Dynamic Chunking (IDC), a novel approach that uses predicted user queries to guide document segmentation. IDC leverages a Large Language Model to generate likely user intents for a document and then employs a dynamic programming algorithm to find the globally optimal chunk boundaries. This represents a novel application of DP to intent-aware segmentation that avoids greedy pitfalls. We evaluated IDC on six diverse question-answering datasets, including news articles, Wikipedia, academic papers, and technical documentation. IDC outperformed traditional chunking strategies on five datasets, improving top-1 retrieval accuracy by 5% to 67%, and matched the best baseline on the sixth. Additionally, IDC produced 40-60% fewer chunks than baseline methods while achieving 93-100% answer coverage. These results demonstrate that aligning document structure with anticipated information needs significantly boosts retrieval performance, particularly for long and heterogeneous documents.

</details>


### [101] [Beyond Retractions: Forensic Scientometrics Techniques to Identify Research Misconduct, Citation Leakage, and Funding Anomalies](https://arxiv.org/abs/2602.14793)
*Leslie D. McIntosh,Alexandra Sinclair,Simon Linacre*

Main category: cs.IR

TL;DR: 一项对虚构的Pharmakon神经科学研究网络的科学计量学取证分析，揭示了该网络在2019-2022年间如何通过学术出版渠道传播不实研究成果


<details>
  <summary>Details</summary>
Motivation: 揭示虚构研究网络如何利用学术出版系统进行运作，分析学术诚信漏洞，为防范类似行为提供实证基础

Method: 采用科学计量学取证分析方法，对Pharmakon神经科学研究网络的出版活动、作者网络、引用模式等进行系统调查

Result: 成功识别并描述了这一虚构研究网络在2019-2022年间的运作模式，包括其如何嵌入合法学术出版渠道、建立虚假作者身份、制造引用网络等

Conclusion: 该案例研究暴露了当前学术出版系统的脆弱性，强调需要更严格的审查机制和科学计量学工具来检测和防止类似虚构研究网络的渗透

Abstract: This paper presents a forensic scientometric case study of the Pharmakon Neuroscience Research Network, a fabricated research collective that operated primarily between 2019 and 2022 while embedding itself within legitimate scholarly publishing channels.

</details>


### [102] [DRAMA: Domain Retrieval using Adaptive Module Allocation](https://arxiv.org/abs/2602.14960)
*Pranav Kasela,Marco Braga,Ophir Frieder,Nazli Goharian,Gabriella Pasi,Raffaele Perego*

Main category: cs.IR

TL;DR: DRAMA是一个用于神经信息检索的节能参数高效框架，通过动态门控机制选择相关领域知识，避免全模型重训练


<details>
  <summary>Details</summary>
Motivation: 神经IR模型虽然检索效果好，但计算和能耗成本高，在多领域场景中可扩展性受限，训练和维护领域特定模型效率低下，且难以实现统一的跨领域泛化

Method: 集成领域特定适配器模块与动态门控机制，为每个查询选择最相关的领域知识，新领域可通过轻量级适配器训练高效添加

Result: 在多个Web检索基准测试中，DRAMA实现了与领域特定模型相当的效果，同时仅使用其一小部分参数和计算资源

Conclusion: 能源感知模型设计可以显著提高神经IR的可扩展性和可持续性

Abstract: Neural models are increasingly used in Web-scale Information Retrieval (IR). However, relying on these models introduces substantial computational and energy requirements, leading to increasing attention toward their environmental cost and the sustainability of large-scale deployments. While neural IR models deliver high retrieval effectiveness, their scalability is constrained in multi-domain scenarios, where training and maintaining domain-specific models is inefficient and achieving robust cross-domain generalisation within a unified model remains difficult. This paper introduces DRAMA (Domain Retrieval using Adaptive Module Allocation), an energy- and parameter-efficient framework designed to reduce the environmental footprint of neural retrieval. DRAMA integrates domain-specific adapter modules with a dynamic gating mechanism that selects the most relevant domain knowledge for each query. New domains can be added efficiently through lightweight adapter training, avoiding full model retraining. We evaluate DRAMA on multiple Web retrieval benchmarks covering different domains. Our extensive evaluation shows that DRAMA achieves comparable effectiveness to domain-specific models while using only a fraction of their parameters and computational resources. These findings show that energy-aware model design can significantly improve scalability and sustainability in neural IR.

</details>
