<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 71]
- [cs.IR](#cs.IR) [Total: 12]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [ReportLogic: Evaluating Logical Quality in Deep Research Reports](https://arxiv.org/abs/2602.18446)
*Jujia Zhao,Zhaoxin Huan,Zihan Wang,Xiaolu Zhang,Jun Zhou,Suzan Verberne,Zhaochun Ren*

Main category: cs.CL

TL;DR: 提出了ReportLogic基准，通过可审计性评估LLM生成报告的逻辑质量，包括宏观逻辑、阐述逻辑和结构逻辑三个层次，并开发了LogicJudge进行可扩展评估


<details>
  <summary>Details</summary>
Motivation: 用户越来越依赖大语言模型进行深度研究，但当前评估框架忽略了报告逻辑质量这一关键要求，即报告的主张和论证是否明确支持并可作为下游使用的基础

Method: 引入ReportLogic基准，采用分层分类法评估：宏观逻辑（可追溯的主题报告结构）、阐述逻辑（理解进展所需上下文）、结构逻辑（通过明确主张-支持验证结论）。基于此构建人工标注数据集，训练开源的LogicJudge进行可扩展评估

Result: 开发了ReportLogic基准和LogicJudge评估系统，通过对抗性攻击测试发现现成LLM评估者经常受表面线索影响，推理模式可能掩盖断裂的支持关系

Conclusion: 结果为构建更稳健的逻辑评估器和提高LLM生成报告的逻辑可靠性提供了可操作的指导，强调了逻辑质量评估在深度研究中的重要性

Abstract: Users increasingly rely on Large Language Models (LLMs) for Deep Research, using them to synthesize diverse sources into structured reports that support understanding and action. In this context, the practical reliability of such reports hinges on logical quality: whether the report's claims and arguments are explicitly supported and can be trusted as a basis for downstream use, rather than merely appearing fluent or informative. However, current evaluation frameworks largely overlook this requirement. To bridge this gap, we introduce ReportLogic, a benchmark that quantifies report-level logical quality through a reader-centric lens of auditability. Specifically, ReportLogic adopts a hierarchical taxonomy that evaluates whether readers can (1) trace an on-topic report structure with a unified analytical arc (Macro-Logic), (2) understand the progression with necessary context (Expositional-Logic), and (3) verify conclusions via explicit claim--support (Structural-Logic). Based on this taxonomy, we construct a human-annotated rubric-guided dataset and train an open-source LogicJudge for scalable evaluation. We further evaluate judge robustness via adversarial attacks, showing that off-the-shelf LLM judges are frequently influenced by superficial cues (e.g., verbosity), and reasoning modes can mask broken support relations. Overall, our results provide actionable guidance for building more robust logic evaluators and improving the logical reliability of LLM-generated reports.

</details>


### [2] [ConfSpec: Efficient Step-Level Speculative Reasoning via Confidence-Gated Verification](https://arxiv.org/abs/2602.18447)
*Siran Liu,Cyril Y. He*

Main category: cs.CL

TL;DR: ConfSpec：一个基于置信度门控的级联验证框架，通过让小模型高置信度验证推理步骤，仅在不确定时才调用大模型，实现了准确性和推理速度的平衡。


<details>
  <summary>Details</summary>
Motivation: Chain-of-Thought推理虽然能提升大语言模型在复杂任务上的性能，但会因生成长推理轨迹而导致高推理延迟。现有的步骤级推测推理方法在准确性、推理速度和资源效率之间存在长期权衡。

Method: 提出ConfSpec框架，其核心洞察是生成与验证之间的不对称性：生成正确的推理步骤需要大量模型能力，但步骤级验证是一个受限的判别任务，小模型在其能力范围内能进行良好校准。通过置信度门控机制，高置信度的草稿决策可直接接受，而将不确定的情况选择性地升级到大型目标模型。

Result: 在多样化工作负载上的评估表明，ConfSpec实现了高达2.24倍的端到端加速，同时匹配目标模型的准确性。该方法无需外部评判模型，且与token级推测解码正交，可实现进一步的乘法加速。

Conclusion: ConfSpec解决了步骤级推测推理中长期存在的准确性、推理速度和资源效率之间的权衡问题，通过利用生成与验证之间的不对称性，实现了高效的推理加速。

Abstract: Chain-of-Thought reasoning significantly improves the performance of large language models on complex tasks, but incurs high inference latency due to long generation traces. Step-level speculative reasoning aims to mitigate this cost, yet existing approaches face a long-standing trade-off among accuracy, inference speed, and resource efficiency. We propose ConfSpec, a confidence-gated cascaded verification framework that resolves this trade-off. Our key insight is an asymmetry between generation and verification: while generating a correct reasoning step requires substantial model capacity, step-level verification is a constrained discriminative task for which small draft models are well-calibrated within their competence range, enabling high-confidence draft decisions to be accepted directly while selectively escalating uncertain cases to the large target model. Evaluation across diverse workloads shows that ConfSpec achieves up to 2.24$\times$ end-to-end speedups while matching target-model accuracy. Our method requires no external judge models and is orthogonal to token-level speculative decoding, enabling further multiplicative acceleration.

</details>


### [3] [INSURE-Dial: A Phase-Aware Conversational Dataset \& Benchmark for Compliance Verification and Phase Detection](https://arxiv.org/abs/2602.18448)
*Shubham Kulkarni,Alexander Lyzhov,Preetam Joshi,Shiva Chaitanya*

Main category: cs.CL

TL;DR: INSURE-Dial是首个用于开发合规感知语音代理的公开基准，包含真实和合成电话数据，专注于保险验证工作流程的合规性审计。


<details>
  <summary>Details</summary>
Motivation: 美国医疗行政电话任务每年耗费约1万亿美元，仅2024年就有超过5亿次保险福利验证电话需人工处理，亟需自动化解决方案。

Method: 创建包含50个真实电话和1000个合成电话的语料库，采用阶段化JSON模式标注，包含IVR导航、患者识别、保险状态等阶段，并标注信息合规性和程序合规性。

Result: 各阶段得分在小型低延迟基线模型上表现良好，但端到端可靠性受跨度边界错误限制。真实电话的完整分段准确率较低，显示对话流畅性与审计级证据之间存在差距。

Conclusion: INSURE-Dial基准揭示了语音代理在医疗行政电话中的实际挑战，强调了需要改进跨度边界检测以提升端到端合规审计的可靠性。

Abstract: Administrative phone tasks drain roughly 1 trillion USD annually from U.S. healthcare, with over 500 million insurance-benefit verification calls manually handled in 2024. We introduce INSURE-Dial, to our knowledge the first public benchmark for developing and assessing compliance-aware voice agents for phase-aware call auditing with span-based compliance verification. The corpus includes 50 de-identified, AI-initiated calls with live insurance representatives (mean 71 turns/call) and 1,000 synthetically generated calls that mirror the same workflow. All calls are annotated with a phase-structured JSON schema covering IVR navigation, patient identification, coverage status, medication checks (up to two drugs), and agent identification (CRN), and each phase is labeled for Information and Procedural compliance under explicit ask/answer logic. We define two novel evaluation tasks: (1) Phase Boundary Detection (span segmentation under phase-specific acceptance rules) and (2) Compliance Verification (IC/PC decisions given fixed spans). Per-phase scores are strong across small, low-latency baselines, but end-to-end reliability is constrained by span-boundary errors. On real calls, full-call exact segmentation is low, showing a gap between conversational fluency and audit-grade evidence.

</details>


### [4] [Prompt Optimization Via Diffusion Language Models](https://arxiv.org/abs/2602.18449)
*Shiyu Wang,Haolin Chen,Liangwei Yang,Jielin Qiu,Rithesh Murthy,Ming Zhu,Zixiang Chen,Silvio Savarese,Caiming Xiong,Shelby Heinecke,Huan Wang*

Main category: cs.CL

TL;DR: 利用扩散语言模型进行提示优化的框架，通过掩码去噪迭代优化系统提示，无需梯度访问或修改下游语言模型


<details>
  <summary>Details</summary>
Motivation: 现有的提示优化方法通常需要梯度访问或修改目标模型，限制了其应用范围。需要一种模型无关、可扩展的提示优化方法

Method: 基于扩散的框架，利用扩散语言模型进行迭代提示优化。通过条件化交互轨迹（用户查询、模型响应和可选反馈），进行灵活的跨度级提示更新

Result: 在多个基准测试（τ-bench、SST-2、SST-5）上，DLM优化的提示能持续提升冻结目标LLM（如GPT-4o-mini）的性能。适中的扩散步骤数在优化质量和稳定性之间提供最佳平衡

Conclusion: 基于扩散的提示优化是一种通用、模型无关且可扩展的方法，通过迭代提示优化显著提升LLM性能

Abstract: We propose a diffusion-based framework for prompt optimization that leverages Diffusion Language Models (DLMs) to iteratively refine system prompts through masked denoising. By conditioning on interaction traces, including user queries, model responses, and optional feedback, our method enables flexible, span-level prompt updates without requiring gradient access or modifying the downstream language model. Across diverse benchmarks (e.g., $τ$-bench, SST-2, SST-5), DLM-optimized prompts consistently improve the performance of a frozen target LLM (e.g., GPT-4o-mini). We further show that moderate diffusion step counts provide the best balance between refinement quality and stability. These results highlight diffusion-based prompt optimization as a general, model-agnostic, and scalable approach for enhancing LLM performance through iterative prompt refinement.

</details>


### [5] [Asymptotic Semantic Collapse in Hierarchical Optimization](https://arxiv.org/abs/2602.18450)
*Faruk Alpay,Bugra Kilictas*

Main category: cs.CL

TL;DR: 该论文研究了多智能体语言系统中的"渐进语义塌缩"现象，即主导上下文逐渐吸收个体语义，导致智能体行为趋同。通过数学建模和分析，揭示了这种收敛的路径独立性和信息熵减少的特性。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体语言系统中存在的一种失效模式：共享主导上下文逐渐吸收个体语义，导致智能体行为趋同。这种现象被称为"渐进语义塌缩"，研究旨在理解其数学机制和后果。

Method: 1. 在封闭语言环境中建立模型，包含具有无限语义惯性的主导锚节点和外围智能体节点
2. 将语义状态建模为黎曼流形上的点，分析诱导投影动力学
3. 理论分析平滑梯度更新和随机噪声更新的收敛行为
4. 使用RWKV-7 13B GGUF检查点进行轻量级无数据集基准测试，评估哈希碰撞、合规性和相似性指标

Result: 1. 极限语义配置对优化历史不敏感：平滑梯度更新和随机噪声更新都收敛到相同的拓扑端点，确立了收敛时的路径独立性
2. 上下文依赖程度控制信息内容：从原子表示到完全纠缠表示，节点熵（解释为可用自由度）在极限中趋于零
3. 实验结果显示：零哈希碰撞，贪婪解码下的平均合规性为0.50，随机解码下为0.531，最终Jaccard相似度分别为0.295和0.224

Conclusion: 渐进语义塌缩理论连接了信息论量与微分几何结构，表明多智能体语言系统存在一种不可变的共识规则，将智能体约束到共享语义语法中。这种现象解释了为什么在主导上下文影响下，个体语义会逐渐丧失，导致行为趋同。

Abstract: Multi-agent language systems can exhibit a failure mode where a shared dominant context progressively absorbs individual semantics, yielding near-uniform behavior across agents. We study this effect under the name Asymptotic Semantic Collapse in Hierarchical Optimization. In a closed linguistic setting with a Dominant Anchor Node whose semantic state has effectively infinite inertia, we show that repeated interactions with Peripheral Agent Nodes drive an asymptotic alignment that minimizes a global loss. We model semantic states as points on a Riemannian manifold and analyze the induced projection dynamics. Two consequences follow. First, the limiting semantic configuration is insensitive to the optimization history: both smooth gradient-style updates and stochastic noisy updates converge to the same topological endpoint, establishing path independence at convergence. Second, the degree of context dependence controls information content: moving from atomic (independent) representations to fully entangled (context-bound) representations forces the node entropy, interpreted as available degrees of freedom, to vanish in the limit. The theory connects information-theoretic quantities with differential-geometric structure and suggests an interpretation as an immutable consensus rule that constrains agents to a shared semantic grammar. A lightweight dataset-free benchmark on an RWKV-7 13B GGUF checkpoint complements the analysis, reporting zero hash collisions, mean compliance of 0.50 under greedy decoding and 0.531 under stochastic decoding, and final Jaccard-to-anchor similarity values of 0.295 and 0.224, respectively.

</details>


### [6] [The Million-Label NER: Breaking Scale Barriers with GLiNER bi-encoder](https://arxiv.org/abs/2602.18487)
*Ihor Stepanov,Mykhailo Shtopko,Dmytro Vodianytskyi,Oleksandr Lukashov*

Main category: cs.CL

TL;DR: GLiNER-bi-Encoder是一种新型命名实体识别架构，通过双编码器设计将标签编码与上下文编码分离，在保持零样本灵活性的同时显著提升工业级效率。


<details>
  <summary>Details</summary>
Motivation: 原始GLiNER框架的联合编码方法在实体标签数量增加时存在二次复杂度问题，限制了其在工业规模应用中的效率。

Method: 提出双编码器设计，将过程解耦为专用标签编码器和上下文编码器，消除上下文窗口瓶颈，支持同时识别数千甚至数百万实体类型。

Result: 在CrossNER基准测试中达到61.5%的Micro-F1分数，零样本性能达到最先进水平；在1024个标签时相比单编码器前身实现高达130倍的吞吐量提升。

Conclusion: GLiNER-bi-Encoder成功平衡了零样本灵活性与工业级效率，并进一步扩展为GLiNKER框架，支持大规模知识库（如Wikidata）的高性能实体链接。

Abstract: This paper introduces GLiNER-bi-Encoder, a novel architecture for Named Entity Recognition (NER) that harmonizes zero-shot flexibility with industrial-scale efficiency. While the original GLiNER framework offers strong generalization, its joint-encoding approach suffers from quadratic complexity as the number of entity labels increases. Our proposed bi-encoder design decouples the process into a dedicated label encoder and a context encoder, effectively removing the context-window bottleneck. This architecture enables the simultaneous recognition of thousands, and potentially millions, of entity types with minimal overhead. Experimental results demonstrate state-of-the-art zero-shot performance, achieving 61.5 percent Micro-F1 on the CrossNER benchmark. Crucially, by leveraging pre-computed label embeddings, GLiNER-bi-Encoder achieves up to a 130 times throughput improvement at 1024 labels compared to its uni-encoder predecessors. Furthermore, we introduce GLiNKER, a modular framework that leverages this architecture for high-performance entity linking across massive knowledge bases such as Wikidata.

</details>


### [7] [Luna-2: Scalable Single-Token Evaluation with Small Language Models](https://arxiv.org/abs/2602.18583)
*Vatsal Goel,Rishon Dsouza,Nikhil Ega,Amey Ramesh Rambatla,Rob Friel,Shuai Shao,Yash Sheth*

Main category: cs.CL

TL;DR: Luna-2是一个利用小型语言模型（SLM）构建的确定性评估架构，用于实时计算复杂的LLM评估指标（如毒性、幻觉、工具选择质量等），在保持与前沿LLM相当或更高准确性的同时，大幅降低成本和延迟。


<details>
  <summary>Details</summary>
Motivation: 当前默认的LLM-as-a-judge（LLMAJ）评估方法存在速度慢、成本高、操作非确定性（多token生成）的问题，而实时护栏需要准确、廉价、快速的评估方案。

Method: 采用解码器专用的小型语言模型（SLM）作为共享主干，每个评估指标通过轻量级的LoRA/PEFT头部实现，使得数百个专用指标可以在单个GPU上并发运行，支持本地部署。

Result: 在内容安全和幻觉基准测试中，Luna-2匹配了最先进的基于LLM的评估器的准确性，同时将推理成本降低了80倍以上，延迟降低了20倍以上。在真实生产环境中，每月保护1亿+AI会话，处理1000亿+token，每年节省超过3000万美元的评估成本。

Conclusion: Luna-2提供了一种高效、低成本、可扩展的实时LLM评估解决方案，能够在保持高准确性的同时显著降低运营成本，适用于大规模AI系统的实时护栏部署。

Abstract: Real-time guardrails require evaluation that is accurate, cheap, and fast - yet today's default, LLM-as-a-judge (LLMAJ), is slow, expensive, and operationally non-deterministic due to multi-token generation. We present Luna-2, a novel architecture that leverages decoder-only small language models (SLMs) into a deterministic evaluation model to reliably compute complex task-specific LLMAJ metrics (e.g. toxicity, hallucination, tool selection quality, etc.) at an accuracy at par or higher than LLMAJ using frontier LLMs while drastically reducing the cost and latency of computation. Each metric is implemented as a lightweight LoRA/PEFT head on top of a shared SLM backbone, enabling hundreds of specialized metrics to run concurrently on a single GPU, deployable locally next to AI systems in a privacy-preserving and latency optimizing manner. Across content safety and hallucination benchmarks, Luna-2 matches the accuracy of state-of-the-art LLM-based evaluators while reducing inference cost by over 80x and latency by over 20x.
  In this paper, we outline the model architecture, training methodology and report real-world empirical results on accuracy, latency, and throughput results. In production, Luna-2 is protecting 100M+ AI sessions and processing over 100B tokens per month for our customers with eval cost savings of over $30M annually.

</details>


### [8] [DP-RFT: Learning to Generate Synthetic Text via Differentially Private Reinforcement Fine-Tuning](https://arxiv.org/abs/2602.18633)
*Fangyuan Xu,Sihao Chen,Zinan Lin,Taiwei Shi,Sydney Graham,Pei Zhou,Mengting Wan,Alex Stein,Virginia Estellers,Charles Chen,Morris Sharp,Richard Speyer,Tadas Baltrusaitis,Jennifer Neville,Eunsol Choi,Longqi Yang*

Main category: cs.CL

TL;DR: DP-RFT：一种使用强化学习的差分隐私合成文本生成方法，无需直接访问私有数据内容，通过隐私保护的近邻投票作为奖励信号训练LLM生成高质量合成数据。


<details>
  <summary>Details</summary>
Motivation: 现有的差分隐私合成数据生成方法面临两难：DP微调方法需要访问私有数据原始内容，而避免直接暴露的方法又受限于未微调的模型，生成数据质量不高。需要一种既能保护隐私又能生成高质量合成文本的方法。

Method: 提出DP-RFT（差分隐私强化微调）算法，使用强化学习训练LLM生成合成数据。算法利用DP保护的"eyes-off"私有语料库的近邻投票作为奖励信号，通过PPO算法迭代优化LLM生成策略，最大化预期的DP投票分数。

Result: 实验在长文本和领域特定文本生成任务（新闻文章、会议记录、医学摘要）上评估，DP-RFT在合成数据保真度和下游任务效用方面缩小了隐私保护方法与DP微调方法之间的差距，同时严格遵守隐私数据边界。

Conclusion: DP-RFT成功实现了在不直接访问私有数据内容的情况下，训练LLM生成高质量的差分隐私合成文本，为隐私保护的大语言模型训练提供了新的解决方案。

Abstract: Differentially private (DP) synthetic data generation plays a pivotal role in developing large language models (LLMs) on private data, where data owners cannot provide eyes-on access to individual examples. Generating DP synthetic data typically involves a difficult trade-off. On one hand, DP finetuning methods train an LLM as a synthetic data generator with formal privacy guarantees, yet it still requires the raw content of private examples for model training. However, methods that avoid direct exposure to private data are bounded by an off-the-shelf, un-finetuned model, whose outputs often lack domain fidelity. Can we train an LLM to generate high-quality synthetic text without eyes-on access to individual private examples? In this work, we introduce Differentially Private Reinforcement Fine-Tuning (DP-RFT), an online reinforcement learning algorithm for synthetic data generation with LLMs. DP-RFT leverages DP-protected nearest-neighbor votes from an eyes-off private corpus as a reward signal for on-policy synthetic samples generated by an LLM. The LLM iteratively learns to generate synthetic data to maximize the expected DP votes through Proximal Policy Optimization (PPO). We evaluate DP-RFT for long-form and domain-specific synthetic data generation, such as news articles, meeting transcripts, and medical article abstracts. Our experiments show that DP-RFT closes the gap between private evolution and DP finetuning methods in terms of the fidelity and downstream utility of the generated synthetic data, while respecting the private data boundary.

</details>


### [9] [PolyFrame at MWE-2026 AdMIRe 2: When Words Are Not Enough: Multimodal Idiom Disambiguation](https://arxiv.org/abs/2602.18652)
*Nina Hosseini-Kivanani*

Main category: cs.CL

TL;DR: PolyFrame系统在MWE-2026 AdMIRe2多模态习语消歧任务中，通过冻结的CLIP风格视觉语言编码器和BGE M3编码器，仅训练轻量级模块，在15种语言上取得了良好性能，证明无需微调大型多模态编码器即可有效进行习语消歧。


<details>
  <summary>Details</summary>
Motivation: 多模态模型在处理习语表达时面临挑战，因为习语具有非组合性含义，这一问题在多语言环境中更加复杂。需要开发有效的系统来解决多模态习语消歧问题。

Method: 提出PolyFrame系统，包含统一流水线处理图像+文本排序（子任务A）和纯文本标题排序（子任务B）。保留冻结的CLIP风格视觉语言编码器和多语言BGE M3编码器，仅训练轻量级模块：逻辑回归和基于LLM的句子类型预测器、习语同义词替换、干扰项感知评分以及Borda排序融合。

Result: 从CLIP基线（英语开发集Top-1 26.7%，英语测试集6.7%）开始，添加习语感知改写和显式句子类型分类后，英语Top-1达到60.0%，葡萄牙语零样本迁移Top-1达到60.0%（NDCG@5 0.822）。在多语言盲测中，系统在15种语言上的平均Top-1/NDCG分数：子任务A为0.35/0.73，子任务B为0.32/0.71。消融实验显示习语感知改写是性能提升的主要贡献者。

Conclusion: 研究发现有效的习语消歧无需微调大型多模态编码器，习语感知改写是性能提升的关键，句子类型预测和多模态融合增强了系统的鲁棒性。

Abstract: Multimodal models struggle with idiomatic expressions due to their non-compositional meanings, a challenge amplified in multilingual settings. We introduced PolyFrame, our system for the MWE-2026 AdMIRe2 shared task on multimodal idiom disambiguation, featuring a unified pipeline for both image+text ranking (Subtask A) and text-only caption ranking (Subtask B). All model variants retain frozen CLIP-style vision--language encoders and the multilingual BGE M3 encoder, training only lightweight modules: a logistic regression and LLM-based sentence-type predictor, idiom synonym substitution, distractor-aware scoring, and Borda rank fusion. Starting from a CLIP baseline (26.7% Top-1 on English dev, 6.7% on English test), adding idiom-aware paraphrasing and explicit sentence-type classification increased performance to 60.0% Top-1 on English and 60.0% Top-1 (0.822 NDCG@5) in zero-shot transfer to Portuguese. On the multilingual blind test, our systems achieved average Top-1/NDCG scores of 0.35/0.73 for Subtask A and 0.32/0.71 for Subtask B across 15 languages. Ablation results highlight idiom-aware rewriting as the main contributor to performance, while sentence-type prediction and multimodal fusion enhance robustness. These findings suggest that effective idiom disambiguation is feasible without fine-tuning large multimodal encoders.

</details>


### [10] [Learning to Reason for Multi-Step Retrieval of Personal Context in Personalized Question Answering](https://arxiv.org/abs/2602.19317)
*Maryam Amirizaniani,Alireza Salemi,Hamed Zamani*

Main category: cs.CL

TL;DR: PR2是一个基于强化学习的个性化问答框架，通过优化检索与推理的协同策略，实现更深入的用户个性化


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成（RAG）的个性化QA方法通常直接使用用户查询检索个人文档，导致表面化的个性化，无法有效利用用户背景、偏好和历史上下文

Method: 提出PR2强化学习框架，学习自适应检索-推理策略，决定何时检索、从用户档案中检索什么证据、以及如何将证据融入中间推理步骤，通过个性化奖励函数优化多轮推理轨迹

Result: 在LaMP-QA基准测试中使用三个LLM进行实验，PR2持续优于强基线，在个性化QA中实现8.8%-12%的平均相对提升

Conclusion: PR2通过强化学习优化检索与推理的协同，能够实现更深入、更有效的个性化问答，超越现有基于直接检索的RAG方法

Abstract: Personalization in Question Answering (QA) requires answers that are both accurate and aligned with users' background, preferences, and historical context. Existing state-of-the-art methods primarily rely on retrieval-augmented generation (RAG) solutions that construct personal context by retrieving relevant items from the user's profile. Existing methods use the user's query directly to retrieve personal documents, and such strategies often lead to surface-level personalization. We propose PR2 (Personalized Retrieval-Augmented Reasoning), a reinforcement learning framework that integrates reasoning and retrieval from personal context for personalization. PR2 learns adaptive retrieval-reasoning policies, determining when to retrieve, what evidence to retrieve from user profiles, and how to incorporate it into intermediate reasoning steps. By optimizing multi-turn reasoning trajectories under a personalized reward function, the framework reinforces reasoning paths that better align with user-specific preferences and contextual signals reflected by the reward model. Extensive experiments on the LaMP-QA benchmark using three LLMs show that PR2 consistently outperforms strong baselines, achieving an average relative improvement of 8.8%-12% in personalized QA.

</details>


### [11] [From Trial by Fire To Sleep Like a Baby: A Lexicon of Anxiety Associations for 20k English Multiword Expressions](https://arxiv.org/abs/2602.18692)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 首个大规模多词表达焦虑关联词典，包含超过2万个英语多词表达，为心理学、NLP、公共卫生等领域提供研究工具。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注词汇层面的焦虑关联，但缺乏对多词表达（MWE）这种更大文本单元的研究。需要建立一个大规模的多词表达焦虑关联词典来填补这一研究空白。

Method: 创建包含超过20,000个英语多词表达的焦虑关联词典，评估其可靠性，并分析不同长度多词表达的焦虑/平静关联分布特征及其组合性。

Result: 词典中的焦虑关联具有高度可靠性。研究发现不同长度的多词表达（2词、3词、4词序列）在焦虑和冷静关联方面存在差异，并探讨了多词表达焦虑关联的组合性程度。

Conclusion: 该词典填补了多词表达焦虑关联研究的空白，为心理学、自然语言处理、公共卫生和社会科学等领域的焦虑相关研究提供了重要工具，词典已免费公开。

Abstract: Anxiety is the unease about a possible future negative outcome. In recent years, there has been growing interest in understanding how anxiety relates to our health, well-being, body, mind, and behaviour. This includes work on lexical resources for word-anxiety association. However, there is very little anxiety-related work on larger units of text such as multiword expressions (MWE). Here, we introduce the first large-scale lexicon capturing descriptive norms of anxiety associations for more than 20k English MWEs. We show that the anxiety associations are highly reliable. We use the lexicon to study prevalence of different types of anxiety- and calmness-associated MWEs; and how that varies across two-, three-, and four-word sequences. We also study the extent to which the anxiety association of MWEs is compositional (due to its constituent words). The lexicon enables a wide variety of anxiety-related research in psychology, NLP, public health, and social sciences. The lexicon is freely available: https://saifmohammad.com/worrylex.html

</details>


### [12] [PerSoMed: A Large-Scale Balanced Dataset for Persian Social Media Text Classification](https://arxiv.org/abs/2602.19333)
*Isun Chehreh,Ebrahim Ansari*

Main category: cs.CL

TL;DR: 本文创建了首个大规模、类别均衡的波斯语社交媒体文本分类数据集，包含9个类别共36,000条数据，并系统评估了多种模型，其中TookaBERT-Large取得了最佳性能（F1分数0.9621）。


<details>
  <summary>Details</summary>
Motivation: 波斯语社交媒体文本分类领域缺乏全面、平衡的数据集资源，现有研究资源不足，限制了波斯语NLP技术的发展。

Method: 1. 从多个波斯语社交媒体平台收集60,000条原始帖子
2. 采用混合标注方法：基于ChatGPT的少样本提示与人工验证相结合
3. 使用欠采样结合语义冗余去除来处理类别不平衡
4. 应用结合词汇替换和生成提示的先进数据增强策略
5. 评估多种模型：BiLSTM、XLM-RoBERTa（含LoRA和AdaLoRA适配）、FaBERT、SBERT架构、波斯语专用TookaBERT（Base和Large）

Result: 1. 基于Transformer的模型始终优于传统神经网络
2. TookaBERT-Large取得最佳性能：精确率0.9622，召回率0.9621，F1分数0.9621
3. 所有类别都表现出稳健性能，但社会和政治文本由于内在模糊性得分略低
4. 创建了公开可用的高质量数据集

Conclusion: 本研究提供了波斯语社交媒体文本分类的新基准数据集和全面模型评估，为波斯语NLP的进一步发展（包括趋势分析、社会行为建模和用户分类）奠定了坚实基础。

Abstract: This research introduces the first large-scale, well-balanced Persian social media text classification dataset, specifically designed to address the lack of comprehensive resources in this domain. The dataset comprises 36,000 posts across nine categories (Economic, Artistic, Sports, Political, Social, Health, Psychological, Historical, and Science & Technology), each containing 4,000 samples to ensure balanced class distribution. Data collection involved 60,000 raw posts from various Persian social media platforms, followed by rigorous preprocessing and hybrid annotation combining ChatGPT-based few-shot prompting with human verification. To mitigate class imbalance, we employed undersampling with semantic redundancy removal and advanced data augmentation strategies integrating lexical replacement and generative prompting. We benchmarked several models, including BiLSTM, XLM-RoBERTa (with LoRA and AdaLoRA adaptations), FaBERT, SBERT-based architectures, and the Persian-specific TookaBERT (Base and Large). Experimental results show that transformer-based models consistently outperform traditional neural networks, with TookaBERT-Large achieving the best performance (Precision: 0.9622, Recall: 0.9621, F1- score: 0.9621). Class-wise evaluation further confirms robust performance across all categories, though social and political texts exhibited slightly lower scores due to inherent ambiguity. This research presents a new high-quality dataset and provides comprehensive evaluations of cutting-edge models, establishing a solid foundation for further developments in Persian NLP, including trend analysis, social behavior modeling, and user classification. The dataset is publicly available to support future research endeavors.

</details>


### [13] [Contradiction to Consensus: Dual Perspective, Multi Source Retrieval Based Claim Verification with Source Level Disagreement using LLM](https://arxiv.org/abs/2602.18693)
*Md Badsha Biswas,Ozlem Uzuner*

Main category: cs.CL

TL;DR: 该论文提出了一种新颖的开放领域声明验证系统，利用大语言模型、多视角证据检索和跨源分歧分析，通过聚合来自多个知识源的支持性和矛盾性证据来提升事实核查的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 当前大多数自动化声明验证系统依赖单一知识源，忽略了不同来源之间的分歧，这限制了知识覆盖范围和系统透明度。需要一种能够处理多源证据、识别分歧并提升可靠性的解决方案。

Method: 1. 引入新颖的检索策略，同时收集原始声明及其否定形式的证据；2. 从Wikipedia、PubMed和Google等多个来源获取证据；3. 对证据进行过滤、去重和跨源聚合；4. 使用大语言模型进行声明验证；5. 通过分析模型置信度分数来量化和可视化跨源分歧。

Result: 在四个基准数据集和五个大语言模型上的广泛评估表明，知识聚合不仅提高了声明验证的性能，还揭示了不同知识源之间的推理差异。系统能够更好地反映现实世界信息的复杂性。

Conclusion: 研究强调了在证据中接纳多样性、矛盾性和聚合的重要性，这对于构建可靠且透明的声明验证系统至关重要。多源证据整合能够提升事实核查的准确性和可解释性。

Abstract: The spread of misinformation across digital platforms can pose significant societal risks. Claim verification, a.k.a. fact-checking, systems can help identify potential misinformation. However, their efficacy is limited by the knowledge sources that they rely on. Most automated claim verification systems depend on a single knowledge source and utilize the supporting evidence from that source; they ignore the disagreement of their source with others. This limits their knowledge coverage and transparency. To address these limitations, we present a novel system for open-domain claim verification (ODCV) that leverages large language models (LLMs), multi-perspective evidence retrieval, and cross-source disagreement analysis. Our approach introduces a novel retrieval strategy that collects evidence for both the original and the negated forms of a claim, enabling the system to capture supporting and contradicting information from diverse sources: Wikipedia, PubMed, and Google. These evidence sets are filtered, deduplicated, and aggregated across sources to form a unified and enriched knowledge base that better reflects the complexity of real-world information. This aggregated evidence is then used for claim verification using LLMs. We further enhance interpretability by analyzing model confidence scores to quantify and visualize inter-source disagreement. Through extensive evaluation on four benchmark datasets with five LLMs, we show that knowledge aggregation not only improves claim verification but also reveals differences in source-specific reasoning. Our findings underscore the importance of embracing diversity, contradiction, and aggregation in evidence for building reliable and transparent claim verification systems

</details>


### [14] [Hyper-KGGen: A Skill-Driven Knowledge Extractor for High-Quality Knowledge Hypergraph Generation](https://arxiv.org/abs/2602.19543)
*Rizhuo Huang,Yifan Feng,Rundong Xue,Shihui Ying,Jun-Hai Yong,Chuan Shi,Shaoyi Du,Yue Gao*

Main category: cs.CL

TL;DR: Hyper-KGGen是一个技能驱动的框架，通过动态技能演化过程解决知识超图构建中的场景差距问题，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 知识超图虽然能表示复杂的n元原子事实，但构建高质量超图面临"场景差距"挑战：通用提取器难以适应不同领域的专业术语，现有方法也无法平衡结构骨架和细粒度细节。

Method: 提出Hyper-KGGen框架：1）采用粗到细机制系统分解文档，覆盖从二元链接到复杂超边的全维度；2）包含自适应技能获取模块，通过基于稳定性的反馈循环将领域专业知识提炼到全局技能库中。

Result: 实验表明Hyper-KGGen显著优于强基线方法，验证了演化技能在多场景设置中比静态少样本示例提供更丰富的指导。同时提出了HyperDocRED基准数据集。

Conclusion: Hyper-KGGen通过动态技能演化有效解决了知识超图构建中的场景差距问题，证明了技能驱动方法在复杂语义表示提取中的优越性。

Abstract: Knowledge hypergraphs surpass traditional binary knowledge graphs by encapsulating complex $n$-ary atomic facts, providing a more comprehensive paradigm for semantic representation. However, constructing high-quality hypergraphs remains challenging due to the \textit{scenario gap}: generic extractors struggle to generalize across diverse domains with specific jargon, while existing methods often fail to balance structural skeletons with fine-grained details. To bridge this gap, we propose \textbf{Hyper-KGGen}, a skill-driven framework that reformulates extraction as a dynamic skill-evolving process. First, Hyper-KGGen employs a \textit{coarse-to-fine} mechanism to systematically decompose documents, ensuring full-dimensional coverage from binary links to complex hyperedges. Crucially, it incorporates an \textit{adaptive skill acquisition} module that actively distills domain expertise into a Global Skill Library. This is achieved via a stability-based feedback loop, where extraction stability serves as a relative reward signal to induce high-quality skills from unstable traces and missed predictions. Additionally, we present \textbf{HyperDocRED}, a rigorously annotated benchmark for document-level knowledge hypergraph extraction. Experiments demonstrate that Hyper-KGGen significantly outperforms strong baselines, validating that evolved skills provide substantially richer guidance than static few-shot examples in multi-scenario settings.

</details>


### [15] [Semantic Substrate Theory: An Operator-Theoretic Framework for Geometric Semantic Drift](https://arxiv.org/abs/2602.18699)
*Stephen Russell*

Main category: cs.CL

TL;DR: 该论文提出一个统一框架，将语义漂移的多种信号形式化为一个时间索引的基底S_t=(X,d_t,P_t)，结合嵌入几何与局部扩散，引入桥质量作为未来邻域重连的预测指标。


<details>
  <summary>Details</summary>
Motivation: 当前语义漂移研究存在多种测量信号（嵌入位移、邻居变化、分布差异、递归轨迹不稳定性等），但缺乏将这些信号联系起来的统一解释理论。

Method: 提出形式化模型S_t=(X,d_t,P_t)，结合嵌入几何与局部扩散；定义节点级邻域漂移、粗Ricci曲率、递归漂移等度量；引入桥质量作为负曲率的节点级聚合指标。

Result: 提出了一个统一的理论框架来形式化语义漂移的各种信号，并定义了桥质量作为预测未来邻域重连的指标。实证性能评估留待后续研究。

Conclusion: 该研究为语义漂移的多种观测信号提供了统一的形式化理论框架，建立了几何、扩散和递归稳定性之间的联系，为未来实证测试奠定了基础。

Abstract: Most semantic drift studies report multiple signals e.g., embedding displacement, neighbor changes, distributional divergence, and recursive trajectory instability, without a shared explanatory theory that relates them. This paper proposes a formalization of these signals in one time-indexed substrate, $S_t=(X,d_t,P_t)$, combining embedding geometry with local diffusion. Within this substrate, node-level neighborhood drift measures changes in local conditional distributions, coarse Ricci curvature measures local contractivity of semantic diffusion, and recursive drift probes stability of iterated semantic operators. This manuscript specifies the formal model, assumptions, and tests that can refute the model. Herein, the paper introduces bridge mass, a node-level aggregate of incident negative curvature, as a predictor of future neighborhood rewiring. This paper provides the theory and test contracts; empirical performance is deferred to subsequent studies.

</details>


### [16] [Sculpting the Vector Space: Towards Efficient Multi-Vector Visual Document Retrieval via Prune-then-Merge Framework](https://arxiv.org/abs/2602.19549)
*Yibo Yan,Mingdong Ou,Yi Cao,Xin Zou,Jiahao Huo,Shuliang Liu,James Kwok,Xuming Hu*

Main category: cs.CL

TL;DR: 提出Prune-then-Merge两阶段框架，通过自适应剪枝和层次化合并，在视觉文档检索中实现高效且高保真的多向量压缩。


<details>
  <summary>Details</summary>
Motivation: 当前视觉文档检索中，多向量方法性能优秀但计算开销巨大。现有剪枝和合并方法在压缩率和特征保真度之间存在难以平衡的trade-off，需要更好的解决方案。

Method: 提出两阶段框架：1) 自适应剪枝阶段过滤低信息量patch，获得高信噪比嵌入集；2) 层次化合并阶段压缩预过滤集，有效总结语义内容而不受噪声干扰。

Result: 在29个VDR数据集上的实验表明，该方法持续优于现有方法，显著扩展了近无损压缩范围，并在高压缩比下保持鲁棒性能。

Conclusion: Prune-then-Merge框架通过结合互补的剪枝和合并方法，有效解决了多向量方法在视觉文档检索中的效率与保真度权衡问题。

Abstract: Visual Document Retrieval (VDR), which aims to retrieve relevant pages within vast corpora of visually-rich documents, is of significance in current multimodal retrieval applications. The state-of-the-art multi-vector paradigm excels in performance but suffers from prohibitive overhead, a problem that current efficiency methods like pruning and merging address imperfectly, creating a difficult trade-off between compression rate and feature fidelity. To overcome this dilemma, we introduce Prune-then-Merge, a novel two-stage framework that synergizes these complementary approaches. Our method first employs an adaptive pruning stage to filter out low-information patches, creating a refined, high-signal set of embeddings. Subsequently, a hierarchical merging stage compresses this pre-filtered set, effectively summarizing semantic content without the noise-induced feature dilution seen in single-stage methods. Extensive experiments on 29 VDR datasets demonstrate that our framework consistently outperforms existing methods, significantly extending the near-lossless compression range and providing robust performance at high compression ratios.

</details>


### [17] [ReHear: Iterative Pseudo-Label Refinement for Semi-Supervised Speech Recognition via Audio Large Language Models](https://arxiv.org/abs/2602.18721)
*Zefang Liu,Chenyang Zhu,Sangwoo Cho,Shi-Xiong Zhang*

Main category: cs.CL

TL;DR: ReHear：一种集成音频感知大语言模型的半监督ASR框架，通过迭代伪标签精炼缓解错误传播问题


<details>
  <summary>Details</summary>
Motivation: 传统半监督ASR中的伪标签方法存在确认偏差和错误累积问题，因为噪声监督会导致错误传播。需要一种能纠正严重识别错误的方法来提升伪标签质量。

Method: 提出ReHear框架，将指令调优的音频感知大语言模型（LLM）集成到自训练循环中。不同于传统基于文本的校正器，该方法同时以ASR假设和源音频为条件，使LLM能从严重识别错误中恢复音素准确的转录文本。这些精炼后的伪标签作为高质量目标用于迭代微调ASR模型。

Result: 在多个基准测试上的实验结果表明，ReHear能有效缓解错误传播，在监督学习和伪标签基线方法上均取得一致性的性能提升。

Conclusion: ReHear通过集成音频感知LLM进行迭代伪标签精炼，为半监督ASR提供了一种有效缓解错误传播的解决方案，显著提升了伪标签质量和最终识别性能。

Abstract: Semi-supervised learning in automatic speech recognition (ASR) typically relies on pseudo-labeling, which often suffers from confirmation bias and error accumulation due to noisy supervision. To address this limitation, we propose ReHear, a framework for iterative pseudo-label refinement that integrates an instruction-tuned, audio-aware large language model (LLM) into the self-training loop. Unlike conventional text-based correctors, our approach conditions the LLM on both the ASR hypothesis and the source audio, allowing it to recover phonetically accurate transcripts even from severe recognition errors. These refined pseudo-labels serve as high-fidelity targets for fine-tuning the ASR model in an iterative cycle. Experimental results across diverse benchmarks demonstrate that ReHear effectively mitigates error propagation, consistently outperforming both supervised and pseudo-labeling baselines.

</details>


### [18] [Unlocking Multimodal Document Intelligence: From Current Triumphs to Future Frontiers of Visual Document Retrieval](https://arxiv.org/abs/2602.19961)
*Yibo Yan,Jiahao Huo,Guanbo Feng,Mingdong Ou,Yi Cao,Xin Zou,Shuliang Liu,Yuanhuiyi Lyu,Yu Huang,Jungang Li,Kening Zheng,Xu Zheng,Philip S. Yu,James Kwok,Xuming Hu*

Main category: cs.CL

TL;DR: 本文是首个关于视觉文档检索(VDR)的全面综述，重点关注多模态大语言模型(MLLM)时代下的技术发展，涵盖基准数据集、方法分类和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着多模态信息的快速增长，视觉文档检索(VDR)成为连接非结构化视觉丰富数据和精确信息获取的关键前沿。与传统自然图像检索不同，视觉文档具有密集文本内容、复杂布局和细粒度语义依赖等独特特征。

Method: 1. 考察基准数据集现状；2. 方法学演进分析，将方法分为三类：多模态嵌入模型、多模态重排序模型、以及集成检索增强生成(RAG)和智能体系统用于复杂文档智能。

Result: 提供了VDR领域的首个全面综述，系统梳理了MLLM时代下的技术发展脉络，为未来多模态文档智能研究提供了清晰路线图。

Conclusion: 识别了VDR领域的持续挑战并概述了有前景的未来方向，旨在为多模态文档智能的未来发展提供明确指导。

Abstract: With the rapid proliferation of multimodal information, Visual Document Retrieval (VDR) has emerged as a critical frontier in bridging the gap between unstructured visually rich data and precise information acquisition. Unlike traditional natural image retrieval, visual documents exhibit unique characteristics defined by dense textual content, intricate layouts, and fine-grained semantic dependencies. This paper presents the first comprehensive survey of the VDR landscape, specifically through the lens of the Multimodal Large Language Model (MLLM) era. We begin by examining the benchmark landscape, and subsequently dive into the methodological evolution, categorizing approaches into three primary aspects: multimodal embedding models, multimodal reranker models, and the integration of Retrieval-Augmented Generation (RAG) and Agentic systems for complex document intelligence. Finally, we identify persistent challenges and outline promising future directions, aiming to provide a clear roadmap for future multimodal document intelligence.

</details>


### [19] [Rethinking Retrieval-Augmented Generation as a Cooperative Decision-Making Problem](https://arxiv.org/abs/2602.18734)
*Lichang Song,Ting Long,Yi Chang*

Main category: cs.CL

TL;DR: CoRAG将RAG重构为协作多智能体决策问题，让重排序器和生成器作为对等决策者协同工作，而非传统的依赖关系。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统大多基于排名中心、非对称依赖范式，生成器的质量高度依赖重排序器的结果，这种限制需要克服。

Method: 提出协作检索增强生成（CoRAG）框架，将重排序器和生成器视为对等决策者，通过联合优化它们的行为来共同实现任务目标。

Result: 实验结果表明CoRAG具有良好的泛化能力和改进的生成稳定性，即使在仅使用约10K PopQA样本进行训练时也表现出色。

Conclusion: CoRAG通过协作多智能体方法克服了传统RAG的非对称依赖限制，提高了系统的整体性能和稳定性。

Abstract: Retrieval-Augmented Generation (RAG) has demonstrated strong effectiveness in knowledge-intensive tasks by grounding language generation in external evidence. Despite its success, many existing RAG systems are built based on a ranking-centric, asymmetric dependency paradigm, where the generation quality of the generator is highly dependent on reranking results of the reranker. To overcome this limitation, we reformulate RAG as a cooperative multi-agent decision-making problem and propose Cooperative Retrieval-Augmented Generation (CoRAG), a framework in which the reranker and the generator act as peer decision-makers rather than being connected through an asymmetric dependency pipeline. By jointly optimizing their behaviors toward a shared task objective, the reranker and generator are encouraged to cooperate, ensuring that document reranking and generation work in concert to improve the final response. Experimental results demonstrate good generalization and improved generation stability of CoRAG, even when the model is trained on only around 10K PopQA samples. Our model released in https://anonymous.4open.science/r/CoRAG-D63F

</details>


### [20] [NanoKnow: How to Know What Your Language Model Knows](https://arxiv.org/abs/2602.20122)
*Lingwei Gu,Nour Jedidi,Jimmy Lin*

Main category: cs.CL

TL;DR: NanoKnow是一个基于nanochat开源预训练数据构建的基准数据集，用于研究LLM如何编码知识，通过分析答案是否出现在预训练语料中来区分参数化知识和外部知识的影响。


<details>
  <summary>Details</summary>
Motivation: 由于大多数LLM的预训练数据是"黑盒"（未知或不可访问），难以理解模型如何编码知识。nanochat模型的发布提供了完全开放的预训练数据，为研究知识编码机制创造了机会。

Method: 基于nanochat的开放预训练数据，构建NanoKnow基准数据集，将Natural Questions和SQuAD的问题划分为答案是否出现在预训练语料中的不同分割。使用8个nanochat检查点进行实验，分析闭卷准确性、外部证据影响、参数化与外部知识的互补性，以及非相关信息的影响。

Result: 研究发现：(1)闭卷准确性受预训练数据中答案频率的强烈影响；(2)提供外部证据可以减轻这种频率依赖性；(3)即使有外部证据，当答案在预训练中出现时模型更准确，表明参数化知识和外部知识是互补的；(4)非相关信息有害，准确性随非相关上下文的位置和数量而下降。

Conclusion: NanoKnow数据集为研究LLM如何编码知识提供了透明工具，揭示了参数化知识和外部知识的相互作用，表明两者是互补的而非相互排斥的，为理解LLM知识来源提供了新视角。

Abstract: How do large language models (LLMs) know what they know? Answering this question has been difficult because pre-training data is often a "black box" -- unknown or inaccessible. The recent release of nanochat -- a family of small LLMs with fully open pre-training data -- addresses this as it provides a transparent view into where a model's parametric knowledge comes from. Towards the goal of understanding how knowledge is encoded by LLMs, we release NanoKnow, a benchmark dataset that partitions questions from Natural Questions and SQuAD into splits based on whether their answers are present in nanochat's pre-training corpus. Using these splits, we can now properly disentangle the sources of knowledge that LLMs rely on when producing an output. To demonstrate NanoKnow's utility, we conduct experiments using eight nanochat checkpoints. Our findings show: (1) closed-book accuracy is strongly influenced by answer frequency in the pre-training data, (2) providing external evidence can mitigate this frequency dependence, (3) even with external evidence, models are more accurate when answers were seen during pre-training, demonstrating that parametric and external knowledge are complementary, and (4) non-relevant information is harmful, with accuracy decreasing based on both the position and the number of non-relevant contexts. We release all NanoKnow artifacts at https://github.com/castorini/NanoKnow.

</details>


### [21] [ArabicNumBench: Evaluating Arabic Number Reading in Large Language Models](https://arxiv.org/abs/2602.18776)
*Anas Alhumud,Abdulaziz Alhammadi,Muhammad Badruddin Khan*

Main category: cs.CL

TL;DR: 阿拉伯数字阅读基准测试：评估71个模型在阿拉伯数字理解任务上的表现，发现数值准确性与指令遵循能力是两种不同的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型评估主要集中在西方数字系统，对阿拉伯数字系统的评估不足。需要建立一个全面的基准来评估语言模型在阿拉伯数字阅读任务上的表现，包括东方阿拉伯-印度数字和西方阿拉伯数字。

Method: 创建了ArabicNumBench基准，包含210个数字阅读任务，涵盖纯数字、地址、日期、数量、价格等6个上下文类别。评估了来自10个提供商的71个模型，使用四种提示策略（零样本、零样本CoT、少样本、少样本CoT），共计59,010个测试案例。跟踪提取方法以测量结构化输出生成。

Result: 模型性能差异显著，准确率从14.29%到99.05%不等。少样本思维链提示的准确率比零样本方法高2.8倍（80.06% vs 28.76%）。发现一个显著现象：达到精英准确率（98-99%）的模型通常产生非结构化输出，大多数响应缺乏阿拉伯CoT标记。只有6个模型在所有测试案例中一致生成结构化输出，而大多数模型尽管数值准确率高，仍需要备用提取方法。

Conclusion: 数值准确性和指令遵循能力代表了不同的能力维度。该基准为阿拉伯数字理解建立了基线，并为生产阿拉伯NLP系统中的模型选择提供了实用指导。

Abstract: We present ArabicNumBench, a comprehensive benchmark for evaluating large language models on Arabic number reading tasks across Eastern Arabic-Indic numerals (0-9 in Arabic script) and Western Arabic numerals (0-9). We evaluate 71 models from 10 providers using four prompting strategies (zero-shot, zero-shot CoT, few-shot, few-shot CoT) on 210 number reading tasks spanning six contextual categories: pure numerals, addresses, dates, quantities, and prices. Our evaluation comprises 59,010 individual test cases and tracks extraction methods to measure structured output generation. Evaluation reveals substantial performance variation, with accuracy ranging from 14.29\% to 99.05\% across models and strategies. Few-shot Chain-of-Thought prompting achieves 2.8x higher accuracy than zero-shot approaches (80.06\% vs 28.76\%). A striking finding emerges: models achieving elite accuracy (98-99\%) often produce predominantly unstructured output, with most responses lacking Arabic CoT markers. Only 6 models consistently generate structured output across all test cases, while the majority require fallback extraction methods despite high numerical accuracy. Comprehensive evaluation of 281 model-strategy combinations demonstrates that numerical accuracy and instruction-following represent distinct capabilities, establishing baselines for Arabic number comprehension and providing actionable guidance for model selection in production Arabic NLP systems.

</details>


### [22] [KNIGHT: Knowledge Graph-Driven Multiple-Choice Question Generation with Adaptive Hardness Calibration](https://arxiv.org/abs/2602.20135)
*Mohammad Amanlou,Erfan Shafiee Moghaddam,Yasaman Amou Jafari,Mahdi Noori,Farhan Farsi,Behnam Bahrak*

Main category: cs.CL

TL;DR: KNIGHT是一个基于知识图谱的LLM框架，用于从外部源生成高质量、难度可控的多选题数据集，解决评估RAG系统的数据瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在RAG等应用中的普及，评估这些系统受到构建专门评估数据集的时间和成本限制。需要一种高效、可重用且能控制难度的数据集生成方法。

Method: KNIGHT构建特定主题的知识图谱作为结构化摘要，通过该图谱而非重复读取完整源文本来生成多选题。框架保持领域和本体无关性，在Wikipedia/Wikidata上实例化。

Result: KNIGHT能够高效生成六个历史、生物和数学领域的MCQ数据集，在流畅性、明确性、主题相关性、选项独特性和基于源的可回答性五个质量指标上表现良好，且模型排名与MMLU基准一致。

Conclusion: KNIGHT通过知识图谱作为可重用的压缩状态，实现了token和成本高效的数据集生成，支持主题特定和难度可控的评估，为LLM系统评估提供了有效的解决方案。

Abstract: With the rise of large language models (LLMs), they have become instrumental in applications such as Retrieval-Augmented Generation (RAG). Yet evaluating these systems remains bottlenecked by the time and cost of building specialized assessment datasets. We introduce KNIGHT, an LLM-based, knowledge-graph-driven framework for generating multiple-choice question (MCQ) datasets from external sources. KNIGHT constructs a topic-specific knowledge graph, a structured and parsimonious summary of entities and relations, that can be reused to generate instructor-controlled difficulty levels, including multi-hop questions, without repeatedly re-feeding the full source text. This knowledge graph acts as a compressed, reusable state, making question generation a cheap read over the graph. We instantiate KNIGHT on Wikipedia/Wikidata while keeping the framework domain- and ontology-agnostic. As a case study, KNIGHT produces six MCQ datasets in History, Biology, and Mathematics. We evaluate quality on five criteria: fluency, unambiguity (single correct answer), topic relevance, option uniqueness, and answerability given the provided sources (as a proxy for hallucination). Results show that KNIGHT enables token- and cost-efficient generation from a reusable graph representation, achieves high quality across these criteria, and yields model rankings aligned with MMLU-style benchmarks, while supporting topic-specific and difficulty-controlled evaluation.

</details>


### [23] [BURMESE-SAN: Burmese NLP Benchmark for Evaluating Large Language Models](https://arxiv.org/abs/2602.18788)
*Thura Aung,Jann Railey Montalan,Jian Gang Ngui,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: BURMESE-SAN是首个全面评估大型语言模型在缅甸语上的NLU、NLR和NLG能力的基准，包含7个子任务，通过母语者驱动构建，评估发现性能更多取决于架构设计、语言表示和指令调优而非模型规模。


<details>
  <summary>Details</summary>
Motivation: 缅甸语作为低资源语言，缺乏系统性的评估基准来全面评估LLM在理解、推理和生成三个核心NLP能力上的表现，这阻碍了缅甸语NLP的发展。

Method: 通过母语者驱动的严格流程构建基准，包含7个子任务（问答、情感分析、毒性检测、因果推理、自然语言推理、抽象摘要和机器翻译）。对开源和商业LLM进行大规模评估，分析缅甸语建模面临的挑战。

Result: 评估结果显示，缅甸语性能更多取决于架构设计、语言表示和指令调优，而非单纯的模型规模。特别是东南亚区域微调和较新的模型代次能带来显著提升。

Conclusion: BURMESE-SAN作为公开排行榜发布，支持缅甸语及其他低资源语言的系统性评估和持续进步，强调了针对特定语言特性的模型设计的重要性。

Abstract: We introduce BURMESE-SAN, the first holistic benchmark that systematically evaluates large language models (LLMs) for Burmese across three core NLP competencies: understanding (NLU), reasoning (NLR), and generation (NLG). BURMESE-SAN consolidates seven subtasks spanning these competencies, including Question Answering, Sentiment Analysis, Toxicity Detection, Causal Reasoning, Natural Language Inference, Abstractive Summarization, and Machine Translation, several of which were previously unavailable for Burmese. The benchmark is constructed through a rigorous native-speaker-driven process to ensure linguistic naturalness, fluency, and cultural authenticity while minimizing translation-induced artifacts. We conduct a large-scale evaluation of both open-weight and commercial LLMs to examine challenges in Burmese modeling arising from limited pretraining coverage, rich morphology, and syntactic variation. Our results show that Burmese performance depends more on architectural design, language representation, and instruction tuning than on model scale alone. In particular, Southeast Asia regional fine-tuning and newer model generations yield substantial gains. Finally, we release BURMESE-SAN as a public leaderboard to support systematic evaluation and sustained progress in Burmese and other low-resource languages. https://leaderboard.sea-lion.ai/detailed/MY

</details>


### [24] [Think$^{2}$: Grounded Metacognitive Reasoning in Large Language Models](https://arxiv.org/abs/2602.18806)
*Abraham Paul Elenjical,Vivek Hruday Kavuri,Vasudeva Varma*

Main category: cs.CL

TL;DR: 论文提出了一个基于心理学的元认知框架，将Ann Brown的调节循环（计划、监控、评估）作为结构化提示架构，并集成到轻量级双过程MetaController中，用于自适应努力分配，显著提升了LLMs的错误诊断和自我纠正能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在推理方面表现出色，但其可靠地监控、诊断和纠正自身错误的能力仍然有限。当前LLMs缺乏有效的自我错误检测和纠正机制，这限制了其在关键应用中的可靠性和可信度。

Method: 1. 引入心理学基础的元认知框架，将Ann Brown的调节循环（计划、监控、评估）操作化为结构化提示架构
2. 设计轻量级双过程MetaController，用于自适应努力分配
3. 在多样化推理和诊断基准（GSM8K、CRUXEval、MBPP、AIME、CorrectBench、TruthfulQA）上进行评估
4. 使用Llama-3和Qwen-3（8B）模型进行实验
5. 进行盲审人工评估，涉及580个查询对

Result: 1. 明确的调节结构显著改进了错误诊断能力
2. 实现了三倍的成功自我纠正率提升
3. 盲审人工评估显示，84%的参与者倾向于信任和元认知自我意识，优于标准和思维链基线
4. 在多个基准测试中均表现出改进效果

Conclusion: 将LLM推理建立在既定的认知理论基础之上，为构建更透明和诊断鲁棒的AI系统提供了一条原则性路径。该心理学基础的元认知框架能有效提升LLMs的错误监控和自我纠正能力，增强系统的可信度和可靠性。

Abstract: Large Language Models (LLMs) demonstrate strong reasoning performance, yet their ability to reliably monitor, diagnose, and correct their own errors remains limited. We introduce a psychologically grounded metacognitive framework that operationalizes Ann Brown's regulatory cycle (Planning, Monitoring, and Evaluation) as a structured prompting architecture, and study its integration within a lightweight dual-process MetaController for adaptive effort allocation. Across diverse reasoning and diagnostic benchmarks (GSM8K, CRUXEval, MBPP, AIME, CorrectBench, and TruthfulQA) using Llama-3 and Qwen-3 (8B), explicit regulatory structuring substantially improves error diagnosis and yields a threefold increase in successful self-correction. Blinded human evaluations over 580 query pairs show an 84% aggregate preference for trustworthiness and metacognitive self-awareness over standard and Chain-of-Thought baselines. Grounding LLM reasoning in established cognitive theory offers a principled path toward more transparent and diagnostically robust AI systems.

</details>


### [25] [EvalSense: A Framework for Domain-Specific LLM (Meta-)Evaluation](https://arxiv.org/abs/2602.18823)
*Adam Dejl,Jonathan Pearson*

Main category: cs.CL

TL;DR: EvalSense是一个用于构建领域特定大语言模型评估套件的灵活可扩展框架，通过交互式指南和自动化元评估工具帮助用户选择合适的评估方法。


<details>
  <summary>Details</summary>
Motivation: 传统统计指标不适合开放式生成任务，而现有的LLM评估方法依赖于精心选择的模型、提示、参数和策略，容易导致配置错误和偏差，需要更可靠的评估框架。

Method: 开发EvalSense框架，包含两个核心组件：1)交互式指南帮助用户选择评估方法；2)自动化元评估工具通过扰动数据评估不同评估方法的可靠性。框架支持多种模型提供商和评估策略。

Result: 在从非结构化医患对话生成临床笔记的案例研究中展示了EvalSense的有效性，所有代码、文档和资源均已开源。

Conclusion: EvalSense提供了一个灵活可扩展的框架，能够帮助用户构建领域特定的LLM评估套件，提高评估的可靠性和适用性。

Abstract: Robust and comprehensive evaluation of large language models (LLMs) is essential for identifying effective LLM system configurations and mitigating risks associated with deploying LLMs in sensitive domains. However, traditional statistical metrics are poorly suited to open-ended generation tasks, leading to growing reliance on LLM-based evaluation methods. These methods, while often more flexible, introduce additional complexity: they depend on carefully chosen models, prompts, parameters, and evaluation strategies, making the evaluation process prone to misconfiguration and bias. In this work, we present EvalSense, a flexible, extensible framework for constructing domain-specific evaluation suites for LLMs. EvalSense provides out-of-the-box support for a broad range of model providers and evaluation strategies, and assists users in selecting and deploying suitable evaluation methods for their specific use-cases. This is achieved through two unique components: (1) an interactive guide aiding users in evaluation method selection and (2) automated meta-evaluation tools that assess the reliability of different evaluation approaches using perturbed data. We demonstrate the effectiveness of EvalSense in a case study involving the generation of clinical notes from unstructured doctor-patient dialogues, using a popular open dataset. All code, documentation, and assets associated with EvalSense are open-source and publicly available at https://github.com/nhsengland/evalsense.

</details>


### [26] [DeepInnovator: Triggering the Innovative Capabilities of LLMs](https://arxiv.org/abs/2602.18920)
*Tianyu Fan,Fengji Zhang,Yuxiang Zheng,Bei Chen,Xinyao Niu,Chengen Huang,Junyang Lin,Chao Huang*

Main category: cs.CL

TL;DR: DeepInnovator是一个训练框架，旨在激发LLMs的创新能力，通过构建自动数据提取管道和"下一个想法预测"训练范式，使模型能够自主生成新颖且有意义的科研想法。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在科研发现中的应用主要依赖复杂的提示工程，缺乏系统性的训练范式来培养真正的创新能力。需要一种能够触发LLMs创新能力的训练方法。

Method: 包含两个核心组件：1) "站在巨人肩膀上"：构建自动数据提取管道，从大量无标注科学文献中提取和组织结构化研究知识；2) "猜想与反驳"：引入"下一个想法预测"训练范式，将研究想法生成建模为持续预测、评估和精炼新颖且合理想法的迭代过程。

Result: DeepInnovator-14B在自动和专家评估中显著优于未训练基线，胜率高达80.53%-93.81%，性能与当前领先的LLMs相当。

Conclusion: 该工作为构建具有真正原创创新能力的研究智能体提供了可扩展的训练路径，并将开源数据集以促进社区发展。

Abstract: The application of Large Language Models (LLMs) in accelerating scientific discovery has garnered increasing attention, with a key focus on constructing research agents endowed with innovative capability, i.e., the ability to autonomously generate novel and significant research ideas. Existing approaches predominantly rely on sophisticated prompt engineering and lack a systematic training paradigm. To address this, we propose DeepInnovator, a training framework designed to trigger the innovative capability of LLMs. Our approach comprises two core components. (1) ``Standing on the shoulders of giants''. We construct an automated data extraction pipeline to extract and organize structured research knowledge from a vast corpus of unlabeled scientific literature. (2) ``Conjectures and refutations''. We introduce a ``Next Idea Prediction'' training paradigm, which models the generation of research ideas as an iterative process of continuously predicting, evaluating, and refining plausible and novel next idea. Both automatic and expert evaluations demonstrate that our DeepInnovator-14B significantly outperforms untrained baselines, achieving win rates of 80.53\%-93.81\%, and attains performance comparable to that of current leading LLMs. This work provides a scalable training pathway toward building research agents with genuine, originative innovative capability, and will open-source the dataset to foster community advancement. Source code and data are available at: https://github.com/HKUDS/DeepInnovator.

</details>


### [27] [Why Agent Caching Fails and How to Fix It: Structured Intent Canonicalization with Few-Shot Learning](https://arxiv.org/abs/2602.18922)
*Abhinaba Basu*

Main category: cs.CL

TL;DR: 论文提出W5H2结构化意图分解框架，通过SetFit模型在2ms内实现91.1%的缓存准确率，相比现有方法大幅提升，并构建五级级联系统实现97.5%的成本降低。


<details>
  <summary>Details</summary>
Motivation: 个人AI代理频繁调用LLM导致高昂成本，现有缓存方法效果不佳（GPTCache仅37.9%准确率），根本原因是优化了错误的属性——缓存有效性需要键一致性和精确性，而非分类准确性。

Method: 1) 提出W5H2结构化意图分解框架；2) 将缓存键评估简化为聚类评估，应用V-measure分解；3) 使用SetFit模型（每类8个示例）进行意图识别；4) 构建五层级联系统处理交互；5) 通过RCPS提供风险控制的选择性预测保证。

Result: 1) W5H2+SetFit在MASSIVE上达到91.1%±1.7%准确率（2ms），远优于GPTCache的37.9%和20B参数LLM的68.8%（3447ms）；2) 在NyayaBench v2上达到55.3%准确率，支持30种语言的跨语言迁移；3) 五层级联系统本地处理85%交互，预计降低成本97.5%。

Conclusion: 通过W5H2框架将缓存键评估重新定义为聚类问题，结合SetFine-tuning和五层级联系统，显著提升了AI代理缓存效率，大幅降低了LLM调用成本，同时通过RCPS保证了预测可靠性。

Abstract: Personal AI agents incur substantial cost via repeated LLM calls. We show existing caching methods fail: GPTCache achieves 37.9% accuracy on real benchmarks; APC achieves 0-12%. The root cause is optimizing for the wrong property -- cache effectiveness requires key consistency and precision,
  not classification accuracy. We observe cache-key evaluation reduces to clustering evaluation and apply V-measure decomposition to separate these on n=8,682 points across MASSIVE, BANKING77, CLINC150, and NyayaBench v2, our new 8,514-entry multilingual agentic dataset (528 intents, 20 W5H2 classes, 63 languages). We introduce W5H2, a structured intent decomposition framework. Using SetFit with 8 examples per class, W5H2 achieves 91.1%+/-1.7% on MASSIVE in ~2ms -- vs 37.9% for
  GPTCache and 68.8% for a 20B-parameter LLM at 3,447ms. On NyayaBench v2 (20 classes), SetFit achieves 55.3%, with cross-lingual transfer across 30 languages. Our five-tier cascade handles 85% of interactions locally, projecting 97.5% cost reduction. We provide risk-controlled selective prediction guarantees via RCPS with nine bound families.

</details>


### [28] [Yor-Sarc: A gold-standard dataset for sarcasm detection in a low-resource African language](https://arxiv.org/abs/2602.18964)
*Toheeb Aduramomi Jimoh,Tabea De Wille,Nikola S. Nikolov*

Main category: cs.CL

TL;DR: 首个约鲁巴语讽刺检测数据集Yor-Sarc，包含436个标注实例，采用文化感知的标注协议，标注者间一致性高，支持低资源非洲语言NLP研究。


<details>
  <summary>Details</summary>
Motivation: 讽刺检测在计算语义学中具有挑战性，需要解决字面意义和实际意图的差异。对于约鲁巴语等低资源非洲语言，缺乏标注数据集进一步加剧了这一挑战。

Method: 创建了首个约鲁巴语讽刺检测数据集Yor-Sarc，包含436个实例。由三位来自不同方言背景的母语者使用专门为约鲁巴语设计的标注协议进行标注，该协议考虑了文化因素，包含上下文敏感解释和社区知情指南。

Result: 标注者间一致性高：Fleiss' κ=0.7660，成对Cohen's κ=0.6732-0.8743，83.3%完全一致。一对标注者达到几乎完美一致性（κ=0.8743；93.8%原始一致性），超过许多英语讽刺研究的基准。16.7%多数同意案例保留为软标签用于不确定性建模。

Conclusion: Yor-Sarc数据集将促进低资源非洲语言的语义解释和文化感知NLP研究，其标注协议和一致性分析支持在其他非洲语言中复制。

Abstract: Sarcasm detection poses a fundamental challenge in computational semantics, requiring models to resolve disparities between literal and intended meaning. The challenge is amplified in low-resource languages where annotated datasets are scarce or nonexistent. We present \textbf{Yor-Sarc}, the first gold-standard dataset for sarcasm detection in Yorùbá, a tonal Niger-Congo language spoken by over $50$ million people. The dataset comprises 436 instances annotated by three native speakers from diverse dialectal backgrounds using an annotation protocol specifically designed for Yorùbá sarcasm by taking culture into account. This protocol incorporates context-sensitive interpretation and community-informed guidelines and is accompanied by a comprehensive analysis of inter-annotator agreement to support replication in other African languages. Substantial to almost perfect agreement was achieved (Fleiss' $κ= 0.7660$; pairwise Cohen's $κ= 0.6732$--$0.8743$), with $83.3\%$ unanimous consensus. One annotator pair achieved almost perfect agreement ($κ= 0.8743$; $93.8\%$ raw agreement), exceeding a number of reported benchmarks for English sarcasm research works. The remaining $16.7\%$ majority-agreement cases are preserved as soft labels for uncertainty-aware modelling. Yor-Sarc\footnote{https://github.com/toheebadura/yor-sarc} is expected to facilitate research on semantic interpretation and culturally informed NLP for low-resource African languages.

</details>


### [29] [Whisper: Courtside Edition Enhancing ASR Performance Through LLM-Driven Context Generation](https://arxiv.org/abs/2602.18966)
*Yonathan Ron,Shiri Gilboa,Tammuz Dubnov*

Main category: cs.CL

TL;DR: Whisper: Courtside Edition是一个无需重新训练的多智能体LLM流水线，通过拦截Whisper的初始转录、应用专门的LLM代理进行领域上下文识别、命名实体识别和术语检测，生成紧凑提示来指导Whisper解码器，显著降低NBA篮球解说领域的词错误率。


<details>
  <summary>Details</summary>
Motivation: 领域特定语音识别仍然是自动语音识别（ASR）的持续挑战，即使是像OpenAI的Whisper这样的最先进系统也难以处理包含密集专有名词和技术术语的领域。

Method: 提出Whisper: Courtside Edition，这是一个多智能体大型语言模型（LLM）流水线，通过以下步骤工作：1）拦截Whisper的初始转录；2）应用专门的LLM代理进行领域上下文识别、命名实体识别和术语检测；3）生成紧凑提示来指导Whisper的解码器，而无需重新训练模型。

Result: 在421个NBA篮球解说片段上评估，最佳流水线实现了统计显著的17.0%相对词错误率降低（从0.217降至0.180，p<0.001）。40.1%的片段有改进，只有7.1%的片段出现退化，显著优于直接转录后编辑方法。

Conclusion: 基于提示的增强可以为ASR提供可扩展的领域适应，为成本高昂的模型微调提供了实用的替代方案。

Abstract: Domain-specific speech remains a persistent challenge for automatic speech recognition (ASR), even for state-of-the-art systems like OpenAI's Whisper. We introduce Whisper: Courtside Edition, a novel multi-agent large language model (LLM) pipeline that enhances Whisper transcriptions without retraining. The pipeline intercepts Whisper's initial transcript, applies specialized LLM agents for domain context identification, named entity recognition, and jargon detection, and generates compact prompts that guide Whisper's decoder. Evaluated on 421 NBA basketball commentary segments (a domain characterized by dense proper nouns and technical terminology) our best pipeline achieves a statistically significant 17.0% relative reduction in word error rate (WER; from 0.217 to 0.180, p<0.001). Improvements are observed in 40.1% of segments with degradation in only 7.1%, substantially outperforming direct transcript post-editing. These results demonstrate that prompt-based augmentation can deliver scalable domain adaptation for ASR, offering a practical alternative to costly model fine-tuning.

</details>


### [30] [Capable but Unreliable: Canonical Path Deviation as a Causal Mechanism of Agent Failure in Long-Horizon Tasks](https://arxiv.org/abs/2602.19008)
*Wilson Y. Lee*

Main category: cs.CL

TL;DR: 语言代理失败往往是由于偏离任务的标准解决方案路径而非能力不足，通过监控和重启偏离轨迹可以显著提高成功率


<details>
  <summary>Details</summary>
Motivation: 探究语言代理在能够解决的任务上失败的原因，区分是能力不足还是可靠性问题，特别是由LLM采样随机性导致的偏离标准解决方案路径的情况

Method: 使用Toolathlon基准测试进行自然实验，分析22个前沿模型在108个现实工具使用任务上的表现，比较同一模型在不同运行中成功与失败的轨迹，通过Jaccard相似度等指标量化偏离标准解决方案路径的程度

Result: 成功运行显著更接近标准解决方案路径，偏离具有累积效应，基于轨迹中期偏离程度的监控和重启机制可将成功率提高8.8个百分点

Conclusion: 语言代理的可靠性问题主要是由偏离任务标准解决方案路径引起，而非能力不足，通过监控和干预偏离轨迹可以显著提升代理性能

Abstract: Why do language agents fail on tasks they are capable of solving? We argue that many such failures are reliability failures caused by stochastic drift from a task's latent solution structure, not capability failures. Every well-defined tool-use task imposes a canonical solution path (i.e., a convergent set of tool invocations shared across successful runs) and agent success depends critically on whether a trajectory stays within this path's operating envelope. We establish this causally using a natural experiment that holds model capability and task difficulty fixed by construction. We analyze trajectories from the Toolathlon benchmark: 22 frontier models each attempt 108 real-world tool-use tasks across 3 independent runs, yielding 515 model$\times$task units where the same model succeeds on some runs and fails on others due to LLM sampling stochasticity alone. Within these units, successful runs adhere significantly more closely to the canonical solution path than failed runs ($+$0.060 Jaccard, $p<0.0001$, $n=488$ units, 95% CI [+0.043, +0.077]). This result survives six robustness checks including cross-model-family leave-one-out validation. Critically, the causal mechanism is gradual and self-reinforcing: the adherence gap is statistically indistinguishable from zero through the first 50% of the trajectory, ruling out early-branching selection bias, and each off-canonical tool call raises the probability that the next call is also off-canonical by 22.7 percentage points ($\hatβ=+0.227$, $p<0.0001$), more than doubling the baseline rate. These findings imply that agent reliability cannot be improved by capability scaling alone, but offer a highly actionable intervention: a simple monitor that restarts the bottom tercile of runs based on mid-trajectory canonical adherence lifts success rates by $+$8.8 percentage points among intervened runs.

</details>


### [31] [Uncovering Context Reliance in Unstructured Knowledge Editing](https://arxiv.org/abs/2602.19043)
*Zisheng Zhou,Mengqi Zhang,Shiguang Wu,Xiaotian Ye,Chi Zhang,Zhumin Chen,Pengjie Ren*

Main category: cs.CL

TL;DR: 提出COIN框架解决LLM编辑中的上下文依赖问题，通过鼓励模型关注局部知识而非记忆上下文模式，显著提升编辑效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型编辑需要处理现实世界非结构化知识，但现有基于下一个词预测的编辑方法存在上下文依赖问题，导致编辑后的知识在推理时无法正确回忆。

Method: 提出COIN框架，通过鼓励模型关注局部知识范围而非记忆上下文模式，减少上下文依赖。首先实证验证上下文依赖问题，然后理论分析这是梯度优化的固有结果，最后设计相应解决方案。

Result: COIN框架将上下文依赖降低45.2%，编辑成功率比强基线提高23.6%，证明减轻上下文依赖对稳健编辑至关重要。

Conclusion: 上下文依赖是基于NTP编辑方法的关键失败模式，COIN框架通过促进上下文无关表示，显著提升了LLM编辑的稳健性和成功率。

Abstract: Editing Large language models (LLMs) with real-world, unstructured knowledge is essential for correcting and updating their internal parametric knowledge. In this work, we revisit the fundamental next-token prediction (NTP) as a candidate paradigm for unstructured editing. We identify Context Reliance as a critical failure mode of NTP-based approaches, where knowledge acquired from edited text becomes highly dependent on its preceding context, leading to recall failures when that context is absent during inference. This hypothesis is supported by our empirical validation that prepending context during inference recovers knowledge recall. We further theoretically demonstrate that Context Reliance is an inherent consequence of gradient-based optimization, which tends to bind acquired knowledge to a specific aggregated contextual representation. To address this, we propose a simple yet effective COntext-INdependent editing framework (COIN), encouraging model to focus on knowledge within local scope rather than memorizing contextual patterns. Evaluations show that COIN reduces Context Reliance by 45.2% and outperforms strong baselines by 23.6% in editing success rate, highlighting the vital role of mitigating Context Reliance for robust editing.

</details>


### [32] [IAPO: Information-Aware Policy Optimization for Token-Efficient Reasoning](https://arxiv.org/abs/2602.19049)
*Yinhan He,Yaochen Zhu,Mingjia Shi,Wendy Zheng,Lin Su,Xiaoqing Wang,Qi Guo,Jundong Li*

Main category: cs.CL

TL;DR: IAPO提出基于信息论的奖励塑造框架，通过条件互信息为每个token分配优势值，在减少推理长度36%的同时提升准确性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于序列级奖励塑造的方法对推理过程中token级别的努力分配控制有限，无法有效识别信息丰富的推理步骤并抑制低效探索。

Method: 提出IAPO框架，基于每个token与最终答案的条件互信息分配token级别的优势值，提供明确的原则性机制来识别信息推理步骤并抑制低效用探索。

Result: 理论分析表明IAPO能在不影响正确性的情况下单调减少推理冗余；实验显示IAPO在多种推理数据集上持续提升准确性同时减少推理长度达36%，优于现有token高效RL方法。

Conclusion: 信息感知的优势塑造是token高效后训练的强大通用方向，为控制推理过程中的token级努力分配提供了理论依据和实用框架。

Abstract: Large language models increasingly rely on long chains of thought to improve accuracy, yet such gains come with substantial inference-time costs. We revisit token-efficient post-training and argue that existing sequence-level reward-shaping methods offer limited control over how reasoning effort is allocated across tokens. To bridge the gap, we propose IAPO, an information-theoretic post-training framework that assigns token-wise advantages based on each token's conditional mutual information (MI) with the final answer. This yields an explicit, principled mechanism for identifying informative reasoning steps and suppressing low-utility exploration. We provide a theoretical analysis showing that our IAPO can induce monotonic reductions in reasoning verbosity without harming correctness. Empirically, IAPO consistently improves reasoning accuracy while reducing reasoning length by up to 36%, outperforming existing token-efficient RL methods across various reasoning datasets. Extensive empirical evaluations demonstrate that information-aware advantage shaping is a powerful and general direction for token-efficient post-training. The code is available at https://github.com/YinhanHe123/IAPO.

</details>


### [33] [Do LLMs and VLMs Share Neurons for Inference? Evidence and Mechanisms of Cross-Modal Transfer](https://arxiv.org/abs/2602.19058)
*Chenhang Cui,An Zhang,Yuxin Chen,Gelei Deng,Jingnan Zheng,Zhenkai Liang,Xiang Wang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 该论文发现大语言模型(LLMs)和大视觉语言模型(LVLM)在推理过程中共享大量神经元，并基于此提出了参数高效的SNRF框架，可将LLMs的推理能力低成本迁移到LVLMs中。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型在多步推理和组合决策任务上仍落后于纯文本大语言模型。由于两者共享Transformer架构，研究它们是否依赖共同的内部计算机制进行推理。

Method: 1. 在神经元层面发现LLMs和LVLMs在多步推理过程中有超过一半的激活单元重叠；2. 通过激活放大的因果探针证明这些共享神经元编码一致的概念级效应；3. 提出SNRF框架：识别共享神经元，计算模型间权重差异的低秩近似，并在共享神经元子空间选择性注入更新。

Result: SNRF在多样化的数学和感知基准测试中持续提升LVLM的推理性能，同时保持感知能力。共享神经元形成了LLMs和LVLMs之间的可解释桥梁。

Conclusion: LLMs和LVLMs共享大量模态不变的推理神经元，这些神经元编码一致的概念级效应。SNRF框架能以最小的参数变化将成熟的推理电路从LLMs迁移到LVLMs，无需大规模多模态微调。

Abstract: Large vision-language models (LVLMs) have rapidly advanced across various domains, yet they still lag behind strong text-only large language models (LLMs) on tasks that require multi-step inference and compositional decision-making. Motivated by their shared transformer architectures, we investigate whether the two model families rely on common internal computation for such inference. At the neuron level, we uncover a surprisingly large overlap: more than half of the top-activated units during multi-step inference are shared between representative LLMs and LVLMs, revealing a modality-invariant inference subspace.
  Through causal probing via activation amplification, we further show that these shared neurons encode consistent and interpretable concept-level effects, demonstrating their functional contribution to inference. Building on this insight, we propose Shared Neuron Low-Rank Fusion (SNRF), a parameter-efficient framework that transfers mature inference circuitry from LLMs to LVLMs. SNRF profiles cross-model activations to identify shared neurons, computes a low-rank approximation of inter-model weight differences, and injects these updates selectively within the shared-neuron subspace. This mechanism strengthens multimodal inference performance with minimal parameter changes and requires no large-scale multimodal fine-tuning.
  Across diverse mathematics and perception benchmarks, SNRF consistently enhances LVLM inference performance while preserving perceptual capabilities. Our results demonstrate that shared neurons form an interpretable bridge between LLMs and LVLMs, enabling low-cost transfer of inference ability into multimodal models. Our code is available at [https://github.com/chenhangcuisg-code/Do-LLMs-VLMs-Share-Neurons](https://github.com/chenhangcuisg-code/Do-LLMs-VLMs-Share-Neurons).

</details>


### [34] [TriTopic: Tri-Modal Graph-Based Topic Modeling with Iterative Refinement and Archetypes](https://arxiv.org/abs/2602.19079)
*Roman Egger*

Main category: cs.CL

TL;DR: TriTopic 是一个新颖的主题建模框架，通过融合语义嵌入、TF-IDF 和元数据的三模态图，解决了 BERTopic 等现有方法的随机不稳定性、嵌入模糊和单一数据视角问题，实现了更高的主题建模性能。


<details>
  <summary>Details</summary>
Motivation: 现有主题建模方法（如 BERTopic）存在三个关键局限性：随机不稳定性（结果不可复现）、嵌入模糊（失去词汇精确性）以及依赖单一数据视角。这些限制影响了主题建模的可靠性和准确性。

Method: TriTopic 采用三模态图融合语义嵌入、TF-IDF 和元数据信息。核心创新包括：1) 通过 Mutual kNN 和共享最近邻构建混合图以消除噪声并应对维度灾难；2) 使用共识 Leiden 聚类确保可复现的稳定分区；3) 通过动态中心点拉动的迭代细化机制锐化嵌入表示；4) 用基于边界案例的原型表示替代传统的"平均文档"概念。

Result: 在 20 Newsgroups、BBC News、AG News 和 Arxiv 数据集上的基准测试表明，TriTopic 在所有数据集上都取得了最高的归一化互信息（NMI）分数（平均 NMI 0.575 vs. BERTopic 的 0.513、NMF 的 0.416、LDA 的 0.299），保证了 100% 的语料覆盖率和 0% 的离群点。

Conclusion: TriTopic 通过三模态图融合和创新的算法设计，显著提升了主题建模的稳定性、准确性和可解释性，解决了现有方法的根本缺陷，并已作为开源 PyPI 库提供。

Abstract: Topic modeling extracts latent themes from large text collections, but leading approaches like BERTopic face critical limitations: stochastic instability, loss of lexical precision ("Embedding Blur"), and reliance on a single data perspective.
  We present TriTopic, a framework that addresses these weaknesses through a tri-modal graph fusing semantic embeddings, TF-IDF, and metadata. Three core innovations drive its performance: hybrid graph construction via Mutual kNN and Shared Nearest Neighbors to eliminate noise and combat the curse of dimensionality; Consensus Leiden Clustering for reproducible, stable partitions; and Iterative Refinement that sharpens embeddings through dynamic centroid-pulling. TriTopic also replaces the "average document" concept with archetype-based topic representations defined by boundary cases rather than centers alone.
  In benchmarks across 20 Newsgroups, BBC News, AG News, and Arxiv, TriTopic achieves the highest NMI on every dataset (mean NMI 0.575 vs. 0.513 for BERTopic, 0.416 for NMF, 0.299 for LDA), guarantees 100% corpus coverage with 0% outliers, and is available as an open-source PyPI library.

</details>


### [35] [Value Entanglement: Conflation Between Different Kinds of Good In (Some) Large Language Models](https://arxiv.org/abs/2602.19101)
*Seong Hah Cho,Junyi Li,Anna Leshinskaya*

Main category: cs.CL

TL;DR: LLMs存在价值纠缠问题：道德、语法和经济价值表征被混淆，道德价值过度影响其他价值判断。通过选择性消融道德相关激活向量可以修复此问题。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否像人类一样能够区分不同类型的价值（道德、语法、经济），以评估其价值表征能力，这是价值对齐的重要基础。

Method: 通过探测模型行为、嵌入表示和残差流激活，分析LLMs对三种不同价值的表征。使用选择性消融技术去除道德相关激活向量。

Result: 发现普遍的价值纠缠现象：语法和经济价值判断过度受道德价值影响，与人类规范相比存在偏差。通过选择性消融道德激活向量可以修复这种混淆。

Conclusion: LLMs在价值表征上存在系统性偏差，道德价值过度渗透到其他价值判断中。这揭示了当前LLMs价值对齐的挑战，并为通过针对性干预改善价值表征提供了方向。

Abstract: Value alignment of Large Language Models (LLMs) requires us to empirically measure these models' actual, acquired representation of value. Among the characteristics of value representation in humans is that they distinguish among value of different kinds. We investigate whether LLMs likewise distinguish three different kinds of good: moral, grammatical, and economic. By probing model behavior, embeddings, and residual stream activations, we report pervasive cases of value entanglement: a conflation between these distinct representations of value. Specifically, both grammatical and economic valuation was found to be overly influenced by moral value, relative to human norms. This conflation was repaired by selective ablation of the activation vectors associated with morality.

</details>


### [36] [Astra: Activation-Space Tail-Eigenvector Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2602.19111)
*Kainan Liu,Yong Zhang,Ning Cheng,Yun Zhu,Yanmeng Wang,Shaojun Wang,Jing Xiao*

Main category: cs.CL

TL;DR: Astra是一种新型参数高效微调方法，利用模型输出激活的尾部特征向量构建任务自适应低秩适配器，在减少参数量的同时提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前LoRA及其变体在微调预训练模型时，未能充分利用尾部特征向量对应的激活子空间，可能导致次优的微调性能。

Method: 提出Astra方法：1）从任务特定校准集估计模型输出激活的尾部特征向量；2）使用这些尾部特征向量构建任务自适应低秩适配器；3）将更新约束在这些尾部特征向量张成的子空间中。

Result: 在自然语言理解和生成任务的16个基准测试中，Astra持续优于现有PEFT基线，在某些场景下甚至超越全参数微调（FFT），同时实现更快的收敛速度和显著减少的参数预算。

Conclusion: Astra通过有效利用激活空间的尾部特征向量，提供了一种更高效、性能更优的参数高效微调方法，在计算和存储效率方面具有显著优势。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) methods, especially LoRA, are widely used for adapting pre-trained models to downstream tasks due to their computational and storage efficiency. However, in the context of LoRA and its variants, the potential of activation subspaces corresponding to tail eigenvectors remains substantially under-exploited, which may lead to suboptimal fine-tuning performance. In this work, we propose Astra (Activation-Space Tail-Eigenvector Low-Rank Adaptation), a novel PEFT method that leverages the tail eigenvectors of the model output activations-estimated from a small task-specific calibration set-to construct task-adaptive low-rank adapters. By constraining updates to the subspace spanned by these tail eigenvectors, Astra achieves faster convergence and improved downstream performance with a significantly reduced parameter budget. Extensive experiments across natural language understanding (NLU) and natural language generation (NLG) tasks demonstrate that Astra consistently outperforms existing PEFT baselines across 16 benchmarks and even surpasses full fine-tuning (FFT) in certain scenarios.

</details>


### [37] [How Do LLMs Encode Scientific Quality? An Empirical Study Using Monosemantic Features from Sparse Autoencoders](https://arxiv.org/abs/2602.19115)
*Michael McCoubrey,Angelo Salatino,Francesco Osborne,Enrico Motta*

Main category: cs.CL

TL;DR: 研究发现LLMs通过稀疏自编码器提取的单义特征编码了科学质量概念，识别出四类关键特征：研究方法、出版类型、高影响力领域和科学术语。


<details>
  <summary>Details</summary>
Motivation: 尽管研究表明LLMs能在一定程度上评估科研质量，但我们对其内部机制的理解仍然有限，需要探索LLMs如何编码科学质量概念。

Method: 使用稀疏自编码器提取LLMs中的相关单义特征，在不同实验设置下推导这些特征，并评估它们在三个科研质量相关任务中的预测能力：预测引用次数、期刊SJR和期刊h指数。

Result: LLMs编码了与科学质量多个维度相关的特征，识别出四类重复出现的特征类型：1)反映研究方法的特征；2)与出版类型相关的特征（文献综述通常具有更高影响力）；3)与高影响力研究领域和技术相关的特征；4)对应特定科学术语的特征。

Conclusion: 这些发现是理解LLMs如何封装科研质量相关概念的重要一步，表明LLMs能够编码科学质量的多维度特征。

Abstract: In recent years, there has been a growing use of generative AI, and large language models (LLMs) in particular, to support both the assessment and generation of scientific work. Although some studies have shown that LLMs can, to a certain extent, evaluate research according to perceived quality, our understanding of the internal mechanisms that enable this capability remains limited. This paper presents the first study that investigates how LLMs encode the concept of scientific quality through relevant monosemantic features extracted using sparse autoencoders. We derive such features under different experimental settings and assess their ability to serve as predictors across three tasks related to research quality: predicting citation count, journal SJR, and journal h-index. The results indicate that LLMs encode features associated with multiple dimensions of scientific quality. In particular, we identify four recurring types of features that capture key aspects of how research quality is represented: 1) features reflecting research methodologies; 2) features related to publication type, with literature reviews typically exhibiting higher impact; 3) features associated with high-impact research fields and technologies; and 4) features corresponding to specific scientific jargons. These findings represent an important step toward understanding how LLMs encapsulate concepts related to research quality.

</details>


### [38] [AgenticRAGTracer: A Hop-Aware Benchmark for Diagnosing Multi-Step Retrieval Reasoning in Agentic RAG](https://arxiv.org/abs/2602.19127)
*Qijie You,Wenkai Yu,Wentao Zhang*

Main category: cs.CL

TL;DR: AgenticRAGTracer是首个主要通过LLM自动构建的Agentic RAG基准测试，支持逐步验证，涵盖多领域1305个数据点，现有最佳LLM表现不佳，揭示推理链扭曲是主要失败原因。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常只提供最终问答，缺乏连接原子问题到最终多跳查询的中间跳级问题，无法分析代理在哪一步失败，限制了模型能力的细粒度评估。此外，大多数基准测试是手动构建的，耗时耗力且限制了可扩展性和泛化性。

Method: 引入AgenticRAGTracer，首个主要通过大语言模型自动构建的Agentic RAG基准测试，支持逐步验证。基准涵盖多个领域，包含1305个数据点，与现有主流基准无重叠。

Result: 广泛实验表明，即使是最好的大语言模型在该数据集上表现不佳。例如，GPT-5在最难部分仅达到22.6%的EM准确率。跳级感知诊断揭示失败主要由扭曲的推理链驱动——要么过早崩溃，要么陷入过度延伸。这突显了模型无法按照任务逻辑结构分配步骤的关键缺陷。

Conclusion: AgenticRAGTracer填补了传统评估中缺失的诊断维度，能够促进Agentic RAG研究并激发该领域有意义的进展。代码和数据已开源。

Abstract: With the rapid advancement of agent-based methods in recent years, Agentic RAG has undoubtedly become an important research direction. Multi-hop reasoning, which requires models to engage in deliberate thinking and multi-step interaction, serves as a critical testbed for assessing such capabilities. However, existing benchmarks typically provide only final questions and answers, while lacking the intermediate hop-level questions that gradually connect atomic questions to the final multi-hop query. This limitation prevents researchers from analyzing at which step an agent fails and restricts more fine-grained evaluation of model capabilities. Moreover, most current benchmarks are manually constructed, which is both time-consuming and labor-intensive, while also limiting scalability and generalization. To address these challenges, we introduce AgenticRAGTracer, the first Agentic RAG benchmark that is primarily constructed automatically by large language models and designed to support step-by-step validation. Our benchmark spans multiple domains, contains 1,305 data points, and has no overlap with existing mainstream benchmarks. Extensive experiments demonstrate that even the best large language models perform poorly on our dataset. For instance, GPT-5 attains merely 22.6\% EM accuracy on the hardest portion of our dataset. Hop-aware diagnosis reveals that failures are primarily driven by distorted reasoning chains -- either collapsing prematurely or wandering into over-extension. This highlights a critical inability to allocate steps consistent with the task's logical structure, providing a diagnostic dimension missing in traditional evaluations. We believe our work will facilitate research in Agentic RAG and inspire further meaningful progress in this area. Our code and data are available at https://github.com/YqjMartin/AgenticRAGTracer.

</details>


### [39] [A Dataset for Named Entity Recognition and Relation Extraction from Art-historical Image Descriptions](https://arxiv.org/abs/2602.19133)
*Stefanie Schneider,Miriam Göldl,Julian Stalter,Ricarda Vollmer*

Main category: cs.CL

TL;DR: FRAME数据集：用于艺术史图像描述细粒度命名实体识别和关系抽取的人工标注数据集，包含37种实体类型和关系链接，支持知识图谱构建。


<details>
  <summary>Details</summary>
Motivation: 艺术史领域缺乏专门用于命名实体识别和关系抽取的细粒度标注数据集，限制了艺术史文本的自动化分析和知识图谱构建。

Method: 从博物馆目录、拍卖清单、开放平台和学术数据库中收集艺术史图像描述，筛选出专注于单个艺术品且包含明确材质、构图或图像学陈述的文本。采用三层标注：元数据层（对象属性）、内容层（描绘主题和母题）、共指层（链接重复提及）。实体类型与Wikidata对齐。

Result: 创建了FRAME数据集，包含37种实体类型的标注和类型化关系链接，以UIMA XMI CAS文件格式发布，附带图像和书目元数据。支持NER、RE、NEL任务，可用于基准测试和模型微调。

Conclusion: FRAME数据集填补了艺术史领域细粒度实体识别和关系抽取的空白，为艺术史文本的自动化分析和知识图谱构建提供了重要资源，特别适合零样本和少样本学习场景。

Abstract: This paper introduces FRAME (Fine-grained Recognition of Art-historical Metadata and Entities), a manually annotated dataset of art-historical image descriptions for Named Entity Recognition (NER) and Relation Extraction (RE). Descriptions were collected from museum catalogs, auction listings, open-access platforms, and scholarly databases, then filtered to ensure that each text focuses on a single artwork and contains explicit statements about its material, composition, or iconography. FRAME provides stand-off annotations in three layers: a metadata layer for object-level properties, a content layer for depicted subjects and motifs, and a co-reference layer linking repeated mentions. Across layers, entity spans are labeled with 37 types and connected by typed RE links between mentions. Entity types are aligned with Wikidata to support Named Entity Linking (NEL) and downstream knowledge-graph construction. The dataset is released as UIMA XMI Common Analysis Structure (CAS) files with accompanying images and bibliographic metadata, and can be used to benchmark and fine-tune NER and RE systems, including zero- and few-shot setups with Large Language Models (LLMs).

</details>


### [40] [Facet-Level Persona Control by Trait-Activated Routing with Contrastive SAE for Role-Playing LLMs](https://arxiv.org/abs/2602.19157)
*Wenqiu Tang,Zhen Wan,Takahiro Komamizu,Ichiro Ide*

Main category: cs.CL

TL;DR: 该论文提出了一种基于对比稀疏自编码器（SAE）的框架，用于学习与Big Five 30-facet模型对齐的层面级人格控制向量，通过动态路由模块实现精确可解释的人格控制，在长对话中保持稳定的角色保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的人格控制方法存在局限性：基于提示和检索增强生成的方法在长对话中信号会稀释，导致人格漂移和不一致；而监督微调需要角色标注数据且对新角色需重新训练，缺乏灵活性。

Method: 提出了对比稀疏自编码器（SAE）框架，学习与Big Five 30-facet模型对齐的层面级人格控制向量。构建了包含15,000个样本的泄漏控制语料库，为每个层面提供平衡监督。学习到的向量被集成到模型的残差空间中，并通过特质激活路由模块动态选择。

Result: 实验表明，该方法在情境化设置中保持稳定的角色保真度和输出质量，优于对比激活添加（CAA）和仅提示基线。SAE+Prompt组合配置实现了最佳整体性能。

Conclusion: 对比训练的潜在向量可以增强人格控制，同时保持对话连贯性。该方法为角色扮演代理提供了精确、可解释且灵活的人格控制方案。

Abstract: Personality control in Role-Playing Agents (RPAs) is commonly achieved via training-free methods that inject persona descriptions and memory through prompts or retrieval-augmented generation, or via supervised fine-tuning (SFT) on persona-specific corpora. While SFT can be effective, it requires persona-labeled data and retraining for new roles, limiting flexibility. In contrast, prompt- and RAG-based signals are easy to apply but can be diluted in long dialogues, leading to drifting and sometimes inconsistent persona behavior. To address this, we propose a contrastive Sparse AutoEncoder (SAE) framework that learns facet-level personality control vectors aligned with the Big Five 30-facet model. A new 15,000-sample leakage-controlled corpus is constructed to provide balanced supervision for each facet. The learned vectors are integrated into the model's residual space and dynamically selected by a trait-activated routing module, enabling precise and interpretable personality steering. Experiments on Large Language Models (LLMs) show that the proposed method maintains stable character fidelity and output quality across contextualized settings, outperforming Contrastive Activation Addition (CAA) and prompt-only baselines. The combined SAE+Prompt configuration achieves the best overall performance, confirming that contrastively trained latent vectors can enhance persona control while preserving dialogue coherence.

</details>


### [41] [TurkicNLP: An NLP Toolkit for Turkic Languages](https://arxiv.org/abs/2602.19174)
*Sherzod Hakimov*

Main category: cs.CL

TL;DR: TurkicNLP是一个开源Python库，为使用四种文字（拉丁、西里尔、波斯-阿拉伯、古突厥如尼文）的突厥语系提供统一的NLP流水线，包括分词、形态分析、词性标注、依存句法分析、命名实体识别、文字转写、跨语言句子嵌入和机器翻译。


<details>
  <summary>Details</summary>
Motivation: 突厥语系有超过2亿使用者，但其自然语言处理工具和资源分散且不统一，大多数语言缺乏整合的NLP工具链。

Method: 采用模块化多后端架构，集成基于规则的有限状态转换器和神经网络模型，支持自动文字检测和变体路由，输出遵循CoNLL-U标准以确保互操作性。

Result: 开发了TurkicNLP开源库，通过单一语言无关的API为突厥语系提供完整的NLP处理能力，支持四种文字家族的跨文字处理。

Conclusion: TurkicNLP填补了突厥语系NLP工具的空白，为这一重要语言家族提供了统一、可扩展且互操作的处理框架，有望促进相关研究和应用发展。

Abstract: Natural language processing for the Turkic language family, spoken by over 200 million people across Eurasia, remains fragmented, with most languages lacking unified tooling and resources. We present TurkicNLP, an open-source Python library providing a single, consistent NLP pipeline for Turkic languages across four script families: Latin, Cyrillic, Perso-Arabic, and Old Turkic Runic. The library covers tokenization, morphological analysis, part-of-speech tagging, dependency parsing, named entity recognition, bidirectional script transliteration, cross-lingual sentence embeddings, and machine translation through one language-agnostic API. A modular multi-backend architecture integrates rule-based finite-state transducers and neural models transparently, with automatic script detection and routing between script variants. Outputs follow the CoNLL-U standard for full interoperability and extension. Code and documentation are hosted at https://github.com/turkic-nlp/turkicnlp .

</details>


### [42] [Next Reply Prediction X Dataset: Linguistic Discrepancies in Naively Generated Content](https://arxiv.org/abs/2602.19177)
*Simon Münker,Nils Schwager,Kai Kugler,Michael Heseltine,Achim Rettinger*

Main category: cs.CL

TL;DR: 论文通过历史条件回复预测任务评估LLM与人类语言差异，提出需要更复杂的提示技术和专门数据集来提升计算社会科学研究的有效性。


<details>
  <summary>Details</summary>
Motivation: LLMs作为人类参与者代理在社会科学研究中日益普及，但"朴素"应用（无明确行为约束）会导致显著的语言差异，威胁研究结果的有效性。

Method: 提出基于真实X（原Twitter）数据的历史条件回复预测任务，创建评估LLM与人类语言输出的数据集，使用风格和内容指标量化分析差异。

Result: 研究发现LLM生成内容与人类语言存在显著差异，需要更复杂的提示技术和专门数据集来确保合成数据准确反映人类复杂语言模式。

Conclusion: LLMs在社会科学研究中需要更严谨的方法论，包括改进的提示技术和专门评估数据集，以确保生成内容的真实性和研究有效性。

Abstract: The increasing use of Large Language Models (LLMs) as proxies for human participants in social science research presents a promising, yet methodologically risky, paradigm shift. While LLMs offer scalability and cost-efficiency, their "naive" application, where they are prompted to generate content without explicit behavioral constraints, introduces significant linguistic discrepancies that challenge the validity of research findings. This paper addresses these limitations by introducing a novel, history-conditioned reply prediction task on authentic X (formerly Twitter) data, to create a dataset designed to evaluate the linguistic output of LLMs against human-generated content. We analyze these discrepancies using stylistic and content-based metrics, providing a quantitative framework for researchers to assess the quality and authenticity of synthetic data. Our findings highlight the need for more sophisticated prompting techniques and specialized datasets to ensure that LLM-generated content accurately reflects the complex linguistic patterns of human communication, thereby improving the validity of computational social science studies.

</details>


### [43] [Retrieval Augmented Enhanced Dual Co-Attention Framework for Target Aware Multimodal Bengali Hateful Meme Detection](https://arxiv.org/abs/2602.19212)
*Raihan Tanvir,Md. Golam Rabiul Alam*

Main category: cs.CL

TL;DR: 该论文针对孟加拉语多模态仇恨表情包检测的挑战，提出了增强型双协同注意力框架（xDORA）和检索增强方法，在低资源语言环境下取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语等低资源语言中的多模态仇恨内容检测面临三大挑战：标注数据有限、类别不平衡、普遍存在的代码混合现象。现有的方法难以有效处理这些复杂情况。

Method: 1) 数据增强：将孟加拉语多模态攻击数据集（MIMOSA）与孟加拉语仇恨表情包数据集（BHM）进行语义对齐扩展；2) 提出xDORA框架：集成视觉编码器（CLIP、DINOv2）和多语言文本编码器（XGLM、XLM-R），通过加权注意力池化学习跨模态表示；3) 基于FAISS的k近邻分类器进行非参数推理；4) 提出RAG-Fused DORA，结合检索驱动的上下文推理；5) 评估LLaVA在零样本、少样本和检索增强提示设置下的表现。

Result: xDORA（CLIP + XLM-R）在扩展数据集上取得：仇恨表情包识别宏平均F1分数0.78，目标实体检测0.71。RAG-Fused DORA进一步提升至0.79和0.74，优于DORA基线。FAISS分类器在稀有类别上表现出鲁棒性。LLaVA在少样本设置下效果有限，检索增强仅带来适度改进。

Conclusion: 研究表明，监督学习、检索增强和非参数多模态框架能有效处理低资源语言检测中的语言和文化复杂性。预训练视觉语言模型（如LLaVA）在未微调时对代码混合的孟加拉语内容效果有限，凸显了针对低资源语言专门优化的必要性。

Abstract: Hateful content on social media increasingly appears as multimodal memes that combine images and text to convey harmful narratives. In low-resource languages such as Bengali, automated detection remains challenging due to limited annotated data, class imbalance, and pervasive code-mixing. To address these issues, we augment the Bengali Hateful Memes (BHM) dataset with semantically aligned samples from the Multimodal Aggression Dataset in Bengali (MIMOSA), improving both class balance and semantic diversity. We propose the Enhanced Dual Co-attention Framework (xDORA), integrating vision encoders (CLIP, DINOv2) and multilingual text encoders (XGLM, XLM-R) via weighted attention pooling to learn robust cross-modal representations. Building on these embeddings, we develop a FAISS-based k-nearest neighbor classifier for non-parametric inference and introduce RAG-Fused DORA, which incorporates retrieval-driven contextual reasoning. We further evaluate LLaVA under zero-shot, few-shot, and retrieval-augmented prompting settings. Experiments on the extended dataset show that xDORA (CLIP + XLM-R) achieves macro-average F1-scores of 0.78 for hateful meme identification and 0.71 for target entity detection, while RAG-Fused DORA improves performance to 0.79 and 0.74, yielding gains over the DORA baseline. The FAISS-based classifier performs competitively and demonstrates robustness for rare classes through semantic similarity modeling. In contrast, LLaVA exhibits limited effectiveness in few-shot settings, with only modest improvements under retrieval augmentation, highlighting constraints of pretrained vision-language models for code-mixed Bengali content without fine-tuning. These findings demonstrate the effectiveness of supervised, retrieval-augmented, and non-parametric multimodal frameworks for addressing linguistic and cultural complexities in low-resource hate speech detection.

</details>


### [44] [Anatomy of Agentic Memory: Taxonomy and Empirical Analysis of Evaluation and System Limitations](https://arxiv.org/abs/2602.19320)
*Dongming Jiang,Yi Li,Songtao Wei,Jinxin Yang,Ayushi Kishore,Alysa Zhao,Dingyi Kang,Xu Hu,Feng Chen,Qiannan Li,Bingzhe Li*

Main category: cs.CL

TL;DR: 该论文系统分析了LLM智能体记忆系统的现状，指出当前评估基准和系统设计存在的缺陷，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 尽管智能体记忆系统快速发展，但其经验基础仍然脆弱：现有基准测试规模不足、评估指标与语义效用错位、性能随骨干模型差异大、系统级成本常被忽视。

Method: 从架构和系统两个角度进行结构化分析，首先基于四种记忆结构提出MAG系统分类法，然后分析当前系统的主要痛点。

Result: 识别出四大关键问题：基准饱和效应、指标有效性和评估敏感性、骨干模型依赖的准确性、记忆维护引入的延迟和吞吐量开销。

Conclusion: 当前智能体记忆系统常未能实现理论潜力，需要更可靠的评估方法和可扩展的系统设计来弥合理论与实践之间的差距。

Abstract: Agentic memory systems enable large language model (LLM) agents to maintain state across long interactions, supporting long-horizon reasoning and personalization beyond fixed context windows. Despite rapid architectural development, the empirical foundations of these systems remain fragile: existing benchmarks are often underscaled, evaluation metrics are misaligned with semantic utility, performance varies significantly across backbone models, and system-level costs are frequently overlooked. This survey presents a structured analysis of agentic memory from both architectural and system perspectives. We first introduce a concise taxonomy of MAG systems based on four memory structures. Then, we analyze key pain points limiting current systems, including benchmark saturation effects, metric validity and judge sensitivity, backbone-dependent accuracy, and the latency and throughput overhead introduced by memory maintenance. By connecting the memory structure to empirical limitations, this survey clarifies why current agentic memory systems often underperform their theoretical promise and outlines directions for more reliable evaluation and scalable system design.

</details>


### [45] [Personalized Prediction of Perceived Message Effectiveness Using Large Language Model Based Digital Twins](https://arxiv.org/abs/2602.19403)
*Jasmin Han,Janardan Devkota,Joseph Waring,Amanda Luken,Felix Naughton,Roger Vilardaga,Jonathan Bricker,Carl Latkin,Meghan Moran,Yiqun Chen,Johannes Thrul*

Main category: cs.CL

TL;DR: LLM-based digital twins利用个人特征和既往评分历史，在预测戒烟干预信息的感知效果方面，优于监督学习和零/少样本LLM方法


<details>
  <summary>Details</summary>
Motivation: 为移动健康平台选择并优化个性化戒烟干预信息，需要准确预测潜在使用者对信息的感知效果。传统方法效果有限，研究探索LLM是否能更准确地预测戒烟信息的感知效果

Method: 研究比较了三种方法：(1)基于标注数据的监督学习模型；(2)无需任务特定微调的零/少样本LLM；(3)结合个人特征和既往评分历史的LLM-based digital twins。使用301名年轻成年吸烟者对3010条信息的5点李克特评分，通过准确率、Cohen's kappa和F1评估模型性能

Result: LLM-based digital twins表现最佳，在内容质量、应对支持和戒烟支持三个维度上的准确率分别为0.49、0.45和0.49，在简化的3点量表上方向准确率达到0.75、0.66和0.70。相比零/少样本LLM平均提升12个百分点，相比监督基线提升13个百分点

Conclusion: 整合个人特征的LLM-based digital twins能更好地捕捉个体差异，在预测戒烟信息感知效果方面优于传统方法。该方法有望改善移动健康干预的个性化内容推荐，对戒烟及其他健康行为干预具有应用潜力

Abstract: Perceived message effectiveness (PME) by potential intervention end-users is important for selecting and optimizing personalized smoking cessation intervention messages for mobile health (mHealth) platform delivery. This study evaluates whether large language models (LLMs) can accurately predict PME for smoking cessation messages.
  We evaluated multiple models for predicting PME across three domains: content quality, coping support, and quitting support. The dataset comprised 3010 message ratings (5-point Likert scale) from 301 young adult smokers. We compared (1) supervised learning models trained on labeled data, (2) zero and few-shot LLMs prompted without task-specific fine-tuning, and (3) LLM-based digital twins that incorporate individual characteristics and prior PME histories to generate personalized predictions. Model performance was assessed on three held-out messages per participant using accuracy, Cohen's kappa, and F1.
  LLM-based digital twins outperformed zero and few-shot LLMs (12 percentage points on average) and supervised baselines (13 percentage points), achieving accuracies of 0.49 (content), 0.45 (coping), and 0.49 (quitting), with directional accuracies of 0.75, 0.66, and 0.70 on a simplified 3-point scale. Digital twin predictions showed greater dispersion across rating categories, indicating improved sensitivity to individual differences.
  Integrating personal profiles with LLMs captures person-specific differences in PME and outperforms supervised and zero and few-shot approaches. Improved PME prediction may enable more tailored intervention content in mHealth. LLM-based digital twins show potential for supporting personalization of mobile smoking cessation and other health behavior change interventions.

</details>


### [46] [Pyramid MoA: A Probabilistic Framework for Cost-Optimized Anytime Inference](https://arxiv.org/abs/2602.19509)
*Arindam Khaled*

Main category: cs.CL

TL;DR: 提出金字塔MoA架构，通过轻量级路由器动态调度小模型，以低成本实现接近大模型的推理能力


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型推理成本与能力之间的权衡问题：大模型性能好但成本高，小模型成本低但复杂任务能力不足

Method: 提出分层代理混合架构，使用轻量级路由器基于语义一致性和置信度校准动态调度查询，仅在必要时升级到更大模型

Result: 在GSM8K基准测试中达到93.0%准确率，接近Oracle基线（98.0%），同时减少61%计算成本，延迟开销仅增加0.82秒

Conclusion: 金字塔MoA架构通过智能路由机制实现了性能与成本的有效平衡，为实际部署提供了可调节的权衡方案

Abstract: Large Language Models (LLMs) face a persistent trade-off between inference cost and reasoning capability. While "Oracle" models (e.g., Llama-3-70B) achieve state-of-the-art accuracy, they are prohibitively expensive for high-volume deployment. Smaller models (e.g., 8B parameters) are cost-effective but struggle with complex tasks. In this work, we propose "Pyramid MoA", a hierarchical Mixture-of-Agents architecture that uses a lightweight Router to dynamically escalate queries only when necessary. By leveraging semantic agreement and confidence calibration among an ensemble of small models, our Router identifies "hard" problems with high precision. On the GSM8K benchmark, our system achieves 93.0% accuracy, effectively matching the Oracle baseline (98.0%) while reducing compute costs by 61%. We demonstrate that the system introduces negligible latency overhead (+0.82s) and allows for a tunable trade-off between performance and budget.

</details>


### [47] [How to Train Your Deep Research Agent? Prompt, Reward, and Policy Optimization in Search-R1](https://arxiv.org/abs/2602.19526)
*Yinuo Xu,Shuo Lu,Jianjie Cheng,Meng Wang,Qianlong Xie,Xingxing Wang,Ran He,Jian Liang*

Main category: cs.CL

TL;DR: 对深度研究智能体中的强化学习进行系统性研究，提出Search-R1++基线方法，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 深度研究智能体通过多轮检索和决策导向生成处理知识密集型任务，虽然强化学习已被证明能提升性能，但其贡献尚未得到充分探索。需要系统研究强化学习在其中的作用。

Method: 从三个解耦维度进行系统性研究：提示模板、奖励函数和策略优化。比较不同模板（Fast Thinking vs Slow Thinking）、奖励函数（F1 vs EM）和策略优化方法（REINFORCE vs PPO vs GRPO）的性能。

Result: 1) Fast Thinking模板比Slow Thinking模板更稳定且性能更好；2) F1奖励函数由于答案回避导致训练崩溃，性能不如EM，但加入动作级惩罚后可超越EM；3) REINFORCE优于PPO且需要更少搜索动作，GRPO稳定性最差。基于这些发现提出的Search-R1++将Qwen2.5-7B性能从0.403提升到0.442，Qwen2.5-3B从0.289提升到0.331。

Conclusion: 该研究为深度研究系统中更原则化和可靠的强化学习训练策略奠定了基础，提出的Search-R1++是一个强基线方法，显著提升了深度研究智能体的性能。

Abstract: Deep Research agents tackle knowledge-intensive tasks through multi-round retrieval and decision-oriented generation. While reinforcement learning (RL) has been shown to improve performance in this paradigm, its contributions remain underexplored. To fully understand the role of RL, we conduct a systematic study along three decoupled dimensions: prompt template, reward function, and policy optimization. Our study reveals that: 1) the Fast Thinking template yields greater stability and better performance than the Slow Thinking template used in prior work; 2) the F1-based reward underperforms the EM due to training collapse driven by answer avoidance; this can be mitigated by incorporating action-level penalties, ultimately surpassing EM; 3) REINFORCE outperforms PPO while requiring fewer search actions, whereas GRPO shows the poorest stability among policy optimization methods. Building on these insights, we then introduce Search-R1++, a strong baseline that improves the performance of Search-R1 from 0.403 to 0.442 (Qwen2.5-7B) and 0.289 to 0.331 (Qwen2.5-3B). We hope that our findings can pave the way for more principled and reliable RL training strategies in Deep Research systems.

</details>


### [48] [Beyond a Single Extractor: Re-thinking HTML-to-Text Extraction for LLM Pretraining](https://arxiv.org/abs/2602.19548)
*Jeffrey Li,Josh Gardner,Doug Kang,Fangping Shi,Karanjeet Singh,Chun-Liang Li,Herumb Shandilya,David Hall,Oncel Tuzel,Percy Liang,Ludwig Schmidt,Hadi Pour Ansari,Fartash Faghri*

Main category: cs.CL

TL;DR: 通过结合多种HTML文本提取器，可以显著提高网络规模预训练数据集的覆盖率和质量，同时保持基准性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源数据集通常对所有网页使用单一的固定文本提取器，但网络内容极其多样，这种做法可能导致互联网数据的覆盖和利用不充分。

Method: 研究不同提取器对网页文本提取的影响，采用"并集"策略结合多种提取器，评估不同提取器对结构化内容（表格、代码块）的影响。

Result: 使用多种提取器的并集可以将DCLM-Baseline的token产量提高71%，同时保持基准性能。对于结构化内容，提取器选择显著影响下游任务性能：WikiTQ上差异达10个百分点，HumanEval上差异达3个百分点。

Conclusion: 单一固定提取器可能无法充分利用网络数据的多样性，采用多种提取器的组合策略可以显著提高数据覆盖率和模型性能。

Abstract: One of the first pre-processing steps for constructing web-scale LLM pretraining datasets involves extracting text from HTML. Despite the immense diversity of web content, existing open-source datasets predominantly apply a single fixed extractor to all webpages. In this work, we investigate whether this practice leads to suboptimal coverage and utilization of Internet data. We first show that while different extractors may lead to similar model performance on standard language understanding tasks, the pages surviving a fixed filtering pipeline can differ substantially. This suggests a simple intervention: by taking a Union over different extractors, we can increase the token yield of DCLM-Baseline by up to 71% while maintaining benchmark performance. We further show that for structured content such as tables and code blocks, extractor choice can significantly impact downstream task performance, with differences of up to 10 percentage points (p.p.) on WikiTQ and 3 p.p. on HumanEval.

</details>


### [49] [Temporal-Aware Heterogeneous Graph Reasoning with Multi-View Fusion for Temporal Question Answering](https://arxiv.org/abs/2602.19569)
*Wuzhenghong Wen,Bowen Zhou,Jinwen Huang,Xianjie Wu,Yuwei Sun,Su Pan,Liang Li,Jianting Liu*

Main category: cs.CL

TL;DR: 提出一个用于时序知识图谱问答的新框架，通过时间感知的问题编码、多跳图推理和多视图异质信息融合，解决了现有方法在时间约束整合、多跳推理和图文融合方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有时序知识图谱问答方法存在三个主要问题：1）问题表示中时间约束整合不足，导致推理偏差；2）多跳推理能力有限；3）语言和图表征融合不理想。

Method: 1）约束感知的问题表示：结合语言模型的语义线索与时序实体动态；2）时间感知图神经网络：通过时间感知消息传递进行显式多跳推理；3）多视图注意力机制：更有效地融合问题上下文和时序图谱知识。

Result: 在多个时序知识图谱问答基准测试上取得了相对于多个基线的持续改进。

Conclusion: 提出的框架通过时间感知的问题编码、多跳图推理和多视图融合机制，有效解决了时序知识图谱问答中的关键挑战，在多个基准测试中表现出优越性能。

Abstract: Question Answering over Temporal Knowledge Graphs (TKGQA) has attracted growing interest for handling time-sensitive queries. However, existing methods still struggle with: 1) weak incorporation of temporal constraints in question representation, causing biased reasoning; 2) limited ability to perform explicit multi-hop reasoning; and 3) suboptimal fusion of language and graph representations. We propose a novel framework with temporal-aware question encoding, multi-hop graph reasoning, and multi-view heterogeneous information fusion. Specifically, our approach introduces: 1) a constraint-aware question representation that combines semantic cues from language models with temporal entity dynamics; 2) a temporal-aware graph neural network for explicit multi-hop reasoning via time-aware message passing; and 3) a multi-view attention mechanism for more effective fusion of question context and temporal graph knowledge. Experiments on multiple TKGQA benchmarks demonstrate consistent improvements over multiple baselines.

</details>


### [50] [DEEP: Docker-based Execution and Evaluation Platform](https://arxiv.org/abs/2602.19583)
*Sergio Gómez González,Miguel Domingo,Francisco Casacuberta*

Main category: cs.CL

TL;DR: DEEP是一个自动化评估软件，用于机器翻译和OCR模型的执行与评分，支持可扩展的任务类型，通过Docker容器化、统计显著性分析和可视化工具来提升模型比较效果。


<details>
  <summary>Details</summary>
Motivation: 在研究中，系统比较是常见且关键的任务，无论是选择合适系统用于工作，还是展示研究成果的潜力，或是公开竞赛评估。传统手动评估过程繁琐且难以保证一致性，需要自动化工具来提高效率和可靠性。

Method: DEEP软件采用Docker容器化接收系统，自动执行模型并提取信息，将预测结果与参考标准进行对比评估。使用基于统计显著性分析的聚类算法对模型结果进行分析，并提供可视化Web应用帮助理解结果。

Result: DEEP能够自动化执行和评分过程，通过统计显著性聚类帮助评估者识别性能集群，理解模型间的差异显著性。可视化工具确保结果能被充分理解和解释。论文还提供了DEEP的实际使用案例。

Conclusion: DEEP是一个有效的自动化评估框架，能够简化机器翻译和OCR等任务的模型比较过程，通过容器化、统计分析和可视化提供更深入的系统性能理解，具有良好的可扩展性和实用性。

Abstract: Comparative evaluation of several systems is a recurrent task in researching. It is a key step before deciding which system to use for our work, or, once our research has been conducted, to demonstrate the potential of the resulting model. Furthermore, it is the main task of competitive, public challenges evaluation. Our proposed software (DEEP) automates both the execution and scoring of machine translation and optical character recognition models. Furthermore, it is easily extensible to other tasks. DEEP is prepared to receive dockerized systems, run them (extracting information at that same time), and assess hypothesis against some references. With this approach, evaluators can achieve a better understanding of the performance of each model. Moreover, the software uses a clustering algorithm based on a statistical analysis of the significance of the results yielded by each model, according to the evaluation metrics. As a result, evaluators are able to identify clusters of performance among the swarm of proposals and have a better understanding of the significance of their differences. Additionally, we offer a visualization web-app to ensure that the results can be adequately understood and interpreted. Finally, we present an exemplary case of use of DEEP.

</details>


### [51] [Eye-Tracking-while-Reading: A Living Survey of Datasets with Open Library Support](https://arxiv.org/abs/2602.19598)
*Deborah N. Jakobi,David R. Reich,Paul Prasse,Jana M. Hofmann,Lena S. Bolliger,Lena A. Jäger*

Main category: cs.CL

TL;DR: 该论文创建了一个眼动阅读数据集的综合资源，包括在线数据库、Python包集成，以提高数据互操作性和可重用性。


<details>
  <summary>Details</summary>
Motivation: 眼动阅读数据集分散在不同学科，缺乏数据共享标准，导致现有数据集因互操作性问题难以被重用。

Method: 1) 对现有数据集进行广泛概述；2) 通过在线动态数据库简化新数据集共享；3) 将所有公开数据集集成到Python包pymovements中。

Result: 创建了包含45+特征的数据集在线数据库，集成了Python包，增强了眼动阅读研究的FAIR原则和可重复性。

Conclusion: 该工作提高了眼动阅读数据集的透明度、互操作性和可重用性，促进了跨学科研究和科学实践。

Abstract: Eye-tracking-while-reading corpora are a valuable resource for many different disciplines and use cases. Use cases range from studying the cognitive processes underlying reading to machine-learning-based applications, such as gaze-based assessments of reading comprehension. The past decades have seen an increase in the number and size of eye-tracking-while-reading datasets as well as increasing diversity with regard to the stimulus languages covered, the linguistic background of the participants, or accompanying psychometric or demographic data. The spread of data across different disciplines and the lack of data sharing standards across the communities lead to many existing datasets that cannot be easily reused due to a lack of interoperability. In this work, we aim at creating more transparency and clarity with regards to existing datasets and their features across different disciplines by i) presenting an extensive overview of existing datasets, ii) simplifying the sharing of newly created datasets by publishing a living overview online, https://dili-lab.github.io/datasets.html, presenting over 45 features for each dataset, and iii) integrating all publicly available datasets into the Python package pymovements which offers an eye-tracking datasets library. By doing so, we aim to strengthen the FAIR principles in eye-tracking-while-reading research and promote good scientific practices, such as reproducing and replicating studies.

</details>


### [52] [Anatomy of Unlearning: The Dual Impact of Fact Salience and Model Fine-Tuning](https://arxiv.org/abs/2602.19612)
*Borisiuk Anna,Andrey Savchenko,Alexander Panchecko,Elena Tutubalina*

Main category: cs.CL

TL;DR: 该论文提出了DUAL基准，用于评估大语言模型在不同训练阶段（预训练vs监督微调）的知识遗忘能力，发现监督微调阶段遗忘效果更稳定且保留率更高。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘研究假设所有事实同等可遗忘，且忽略了知识来源（预训练vs监督微调）对遗忘效果的影响，需要更细粒度的评估框架。

Method: 构建DUAL基准，包含28.6k个Wikidata三元组，使用维基百科链接计数和LLM显著性评分标注事实流行度，在不同训练阶段进行遗忘实验对比。

Result: 实验表明：1）监督微调阶段遗忘更平滑、更稳定，保留率高10-50%；2）直接在预训练模型上遗忘不稳定，易出现再学习或灾难性遗忘。

Conclusion: 知识遗忘效果受训练阶段影响显著，应在监督微调阶段进行遗忘以获得更好效果，为机器遗忘研究提供了重要的评估基准和洞见。

Abstract: Machine Unlearning (MU) enables Large Language Models (LLMs) to remove unsafe or outdated information. However, existing work assumes that all facts are equally forgettable and largely ignores whether the forgotten knowledge originates from pretraining or supervised fine-tuning (SFT). In this paper, we introduce DUAL (Dual Unlearning Evaluation across Training Stages), a benchmark of 28.6k Wikidata-derived triplets annotated with fact popularity using Wikipedia link counts and LLM-based salience scores. Our experiments show that pretrained and SFT models respond differently to unlearning. An SFT step on the forget data yields smoother forgetting, more stable tuning, and 10-50% higher retention, while direct unlearning on pretrained models remains unstable and prone to relearning or catastrophic forgetting.

</details>


### [53] [KGHaluBench: A Knowledge Graph-Based Hallucination Benchmark for Evaluating the Breadth and Depth of LLM Knowledge](https://arxiv.org/abs/2602.19643)
*Alex Robertson,Huizhi Liang,Mahbub Gani,Rohit Kumar,Srijith Rajamohan*

Main category: cs.CL

TL;DR: KGHaluBench是一个基于知识图谱的幻觉基准测试，用于评估大语言模型的真实性和知识完整性，通过动态生成挑战性问题并提供更全面的幻觉分析。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在局限性：使用静态、狭窄的问题导致覆盖范围有限，评估结果可能误导。大语言模型虽然能生成连贯语言，但连贯性不等于真实性，经常包含微妙的幻觉。

Method: 利用知识图谱动态构建具有挑战性的多方面问题，通过统计方法估计问题难度以解决流行度偏差。建立自动化验证流程，在概念和正确性两个层面检测弃权和验证模型响应，识别不同类型的幻觉。

Result: 评估了25个前沿模型，使用新颖的准确性和幻觉度量指标。结果提供了更可解释的洞察，揭示不同模型大小导致幻觉的知识因素。

Conclusion: KGHaluBench提供了一个更公平、更全面的LLM真实性评估框架，公开可用以支持未来幻觉缓解技术的发展。

Abstract: Large Language Models (LLMs) possess a remarkable capacity to generate persuasive and intelligible language. However, coherence does not equate to truthfulness, as the responses often contain subtle hallucinations. Existing benchmarks are limited by static and narrow questions, leading to limited coverage and misleading evaluations. We present KGHaluBench, a Knowledge Graph-based hallucination benchmark that assesses LLMs across the breadth and depth of their knowledge, providing a fairer and more comprehensive insight into LLM truthfulness. Our framework utilises the KG to dynamically construct challenging, multifaceted questions, whose difficulty is then statistically estimated to address popularity bias. Our automated verification pipeline detects abstentions and verifies the LLM's response at both conceptual and correctness levels to identify different types of hallucinations. We evaluate 25 frontier models, using novel accuracy and hallucination metrics. The results provide a more interpretable insight into the knowledge factors that cause hallucinations across different model sizes. KGHaluBench is publicly available to support future developments in hallucination mitigation.

</details>


### [54] [Keyboards for the Endangered Idu Mishmi Language](https://arxiv.org/abs/2602.19815)
*Akhilesh Kakolu Ramarao*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a mobile and desktop keyboard suite for Idu Mishmi, an endangered Trans-Himalayan language spoken by approximately 11,000 people in Arunachal Pradesh, India. Although a Latin-based orthography was developed in 2018, no digital input tools existed to use it, forcing speakers into ad-hoc romanizations that cannot represent the full writing system. Our keyboards comprise two tools: (1) an Android mobile keyboard, published on the Google Play Store and actively used in teacher training programs, and (2) a Windows desktop keyboard currently undergoing community testing. Both tools support the complete Idu Mishmi character inventory, including schwa, retracted schwa, nasalized vowels, and accented forms. Both operate fully offline with zero network permissions, addressing connectivity constraints and data sovereignty concerns. We describe the design, implementation, and deployment as a replicable model for other endangered language communities.

</details>


### [55] [SAMAS: A Spectrum-Guided Multi-Agent System for Achieving Style Fidelity in Literary Translation](https://arxiv.org/abs/2602.19840)
*Jingzhuo Wu,Jiajun Zhang,Keyan Jin,Dehua Ma,Junbo Wang*

Main category: cs.CL

TL;DR: SAMAS是一个基于多智能体的风格自适应翻译框架，通过小波包变换将文学风格量化为特征谱，动态组装专门翻译智能体来提升风格保真度。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然能生成流畅准确的翻译，但难以保留作者的独特文学风格，往往产生语义正确但风格通用的输出。现有单模型和静态多智能体系统无法感知和适应风格变化。

Method: 提出Style-Adaptive Multi-Agent System (SAMAS)框架，将风格保留视为信号处理任务。使用小波包变换将文学风格量化为Stylistic Feature Spectrum (SFS)，根据源文本的结构模式，将SFS作为控制信号动态组装专门的翻译智能体工作流。

Result: 在翻译基准测试上的大量实验表明，SAMAS在保持与强基线相当的语义准确性的同时，在风格保真度方面具有统计显著的优势。

Conclusion: SAMAS通过将风格量化并作为动态多智能体组装的控制信号，有效解决了LLM在文学翻译中风格保真度不足的问题，为风格感知翻译提供了新思路。

Abstract: Modern large language models (LLMs) excel at generating fluent and faithful translations. However, they struggle to preserve an author's unique literary style, often producing semantically correct but generic outputs. This limitation stems from the inability of current single-model and static multi-agent systems to perceive and adapt to stylistic variations. To address this, we introduce the Style-Adaptive Multi-Agent System (SAMAS), a novel framework that treats style preservation as a signal processing task. Specifically, our method quantifies literary style into a Stylistic Feature Spectrum (SFS) using the wavelet packet transform. This SFS serves as a control signal to dynamically assemble a tailored workflow of specialized translation agents based on the source text's structural patterns. Extensive experiments on translation benchmarks show that SAMAS achieves competitive semantic accuracy against strong baselines, primarily by leveraging its statistically significant advantage in style fidelity.

</details>


### [56] [SHIELD: Semantic Heterogeneity Integrated Embedding for Latent Discovery in Clinical Trial Safety Signals](https://arxiv.org/abs/2602.19855)
*Francois Vandenhende,Anna Georgiou,Theodoros Psaras,Ellie Karekla*

Main category: cs.CL

TL;DR: SHIELD是一种结合统计信号检测与自然语言处理的自动化临床安全信号检测方法，通过语义聚类分析不良反应事件，生成可解释的安全概要网络图。


<details>
  <summary>Details</summary>
Motivation: 现有临床安全信号检测方法通常孤立分析单个不良反应事件，缺乏对相关事件群的系统性分析，难以形成整体性的安全概况理解。

Method: SHIELD结合了不成比例性分析（计算信息成分）和MedDRA术语嵌入的语义聚类。通过构建效用矩阵、谱嵌入和聚类来识别相关AE群组，并使用大语言模型进行集群标注。

Result: SHIELD能够有效识别已知安全信号，并在真实临床试验示例中生成可解释的基于集群的安全概要，包括网络图和层次树。

Conclusion: 该方法将统计信号检测与现代自然语言处理相结合，提升了临床安全评估的效率和因果解释能力。

Abstract: We present SHIELD, a novel methodology for automated and integrated safety signal detection in clinical trials. SHIELD combines disproportionality analysis with semantic clustering of adverse event (AE) terms applied to MedDRA term embeddings. For each AE, the pipeline computes an information-theoretic disproportionality measure (Information Component) with effect size derived via empirical Bayesian shrinkage. A utility matrix is constructed by weighting semantic term-term similarities by signal magnitude, followed by spectral embedding and clustering to identify groups of related AEs. Resulting clusters are annotated with syndrome-level summary labels using large language models, yielding a coherent, data-driven representation of treatment-associated safety profiles in the form of a network graph and hierarchical tree. We implement the SHIELD framework in the context of a single-arm incidence summary, to compare two treatment arms or for the detection of any treatment effect in a multi-arm trial. We illustrate its ability to recover known safety signals and generate interpretable, cluster-based summaries in a real clinical trial example. This work bridges statistical signal detection with modern natural language processing to enhance safety assessment and causal interpretation in clinical trials.

</details>


### [57] [Axis Decomposition for ODRL: Resolving Dimensional Ambiguity in Policy Constraints through Interval Semantics](https://arxiv.org/abs/2602.19878)
*Daham Mustafa,Diego Collarana,Yixin Peng,Rafiqul Haque,Christoph Lange-Bever,Christoph Quix,Stephan Decker*

Main category: cs.CL

TL;DR: 本文分析了ODRL 2.2规范中多维操作数导致的策略评估不确定性，提出了轴分解框架来解决此问题，并实例化为ODRL空间轴配置文件。


<details>
  <summary>Details</summary>
Motivation: ODRL 2.2规范中约34个左操作数中有5个表示多维量（如图像尺寸、画布位置、地理坐标），这些操作数的规范文本明确引用多个轴。对于这些操作数，单个标量约束在每个轴上都有一种解释，导致策略评估具有非确定性。

Method: 1. 将ODRL左操作数按值域结构分类（标量、维度、概念值）；2. 提出轴分解框架，将每个维度操作数细化为轴特定的标量操作数；3. 证明四个属性：确定性解释、AABB完备性、投影下的声音过近似、保守扩展；4. 两层冲突检测：每轴判决总是可判定的，框级判决通过强Kleene合取组成三值逻辑；5. 对于不适用每轴分解的逻辑约束，直接编码耦合多轴猜想。

Result: 1. 将框架实例化为ODRL空间轴配置文件，包含15个轴特定左操作数；2. 在117个基准问题上评估，涵盖TPTP FOF（Vampire）和SMT-LIB（Z3）编码，实现证明器间的完全一致性；3. 所有元定理在Isabelle/HOL中机械验证。

Conclusion: 轴分解框架有效解决了ODRL中多维操作数导致的评估不确定性，提供了确定性的解释和可判定的冲突检测，同时保持与现有规范的兼容性。

Abstract: Every ODRL 2.2 constraint compares a single scalar value: (leftOperand, operator, rightOperand). Five of ODRL's approximately 34 left operands, however, denote multi-dimensional quantities--image dimensions, canvas positions, geographic coordinates--whose specification text explicitly references multiple axes. For these operands, a single scalar constraint admits one interpretation per axis, making policy evaluation non-deterministic.
  We classify ODRL's left operands by value-domain structure (scalar, dimensional, concept-valued), grounded in the ODRL 2.2 specification text, and show that dimensional ambiguity is intrinsic to the constraint syntax.
  We present an axis-decomposition framework that refines each dimensional operand into axis-specific scalar operands and prove four properties: deterministic interpretation, AABB completeness, sound over-approximation under projection, and conservative extension.
  Conflict detection operates in two layers: per-axis verdicts are always decidable; box-level verdicts compose through Strong Kleene conjunction into a three-valued logic (Conflict, Compatible, Unknown). For ODRL's disjunctive (odrl:or) and exclusive-or (odrl:xone) logical constraints, where per-axis decomposition does not apply, the framework encodes coupled multi-axis conjectures directly.
  We instantiate the framework as the ODRL Spatial Axis Profile--15 axis-specific left operands for the five affected base terms--and evaluate it on 117 benchmark problems spanning nine categories across both TPTP FOF (Vampire) and SMT-LIB (Z3) encodings, achieving full concordance between provers. Benchmark scenarios are inspired by constraints arising in cultural heritage dataspaces such as Datenraum Kultur. All meta-theorems are mechanically verified in Isabelle/HOL.

</details>


### [58] [Denotational Semantics for ODRL: Knowledge-Based Constraint Conflict Detection](https://arxiv.org/abs/2602.19883)
*Daham Mustafa,Diego Collarana,Yixin Peng,Rafiqul Haque,Christoph Lange-Bever,Christoph Quix,Stephan Decker*

Main category: cs.CL

TL;DR: 为ODRL的六个基于集合的运算符提供形式化语义，使跨数据空间策略比较能够产生确定性的冲突检测结果，而不是默认的Unknown。


<details>
  <summary>Details</summary>
Motivation: ODRL规范中的六个基于集合的运算符（isA, isPartOf, hasPart, isAnyOf, isAllOf, isNoneOf）依赖于未指定的外部领域知识，导致跨数据空间策略比较总是默认返回Unknown结果，缺乏确定性的冲突检测能力。

Method: 提出一种指称语义学方法，将每个ODRL约束映射到满足该约束的知识库概念集合。冲突检测简化为在三值判决（Conflict, Compatible, Unknown）下的指称交集，该判决在知识不完整情况下是可靠的。框架覆盖所有ODRL组合模式（and, or, xone）和三种实际语义域（分类的、部分的、名义的）。

Result: 验证了154个基准测试，涵盖六个知识库家族和四个针对对抗性边缘情况的结构化知识库。Vampire定理证明器和Z3 SMT求解器在所有154个判决上达成一致。关键发现是排他性组合（xone）需要比合取或析取更强的知识库公理。

Conclusion: 该形式化框架为ODRL约束提供了可靠的跨数据空间冲突检测能力，通过保持顺序的对齐保证了不同知识库标准之间的冲突一致性，并确保未映射概念优雅地降级为Unknown而非产生虚假冲突。

Abstract: ODRL's six set-based operators -- isA, isPartOf, hasPart, isAnyOf, isAllOf, isNoneOf -- depend on external domain knowledge that the W3C specification leaves unspecified. Without it, every cross-dataspace policy comparison defaults to Unknown. We present a denotational semantics that maps each ODRL constraint to the set of knowledge-base concepts satisfying it. Conflict detection reduces to denotation intersection under a three-valued verdict -- Conflict, Compatible, or Unknown -- that is sound under incomplete knowledge. The framework covers all three ODRL composition modes (and, or, xone) and all three semantic domains arising in practice: taxonomic (class subsumption), mereological (part-whole containment), and nominal (identity). For cross-dataspace interoperability, we define order-preserving alignments between knowledge bases and prove two guarantees: conflicts are preserved across different KB standards, and unmapped concepts degrade gracefully to Unknown -- never to false conflicts. A runtime soundness theorem ensures that design-time verdicts hold for all execution contexts. The encoding stays within the decidable EPR fragment of first-order logic. We validate it with 154 benchmarks across six knowledge base families (GeoNames, ISO 3166, W3C DPV, a GDPR-derived taxonomy, BCP 47, and ISO 639-3) and four structural KBs targeting adversarial edge cases. Both the Vampire theorem prover and the Z3 SMT solver agree on all 154 verdicts. A key finding is that exclusive composition (xone) requires strictly stronger KB axioms than conjunction or disjunction: open-world semantics blocks exclusivity even when positive evidence appears to satisfy exactly one branch.

</details>


### [59] [Janus-Q: End-to-End Event-Driven Trading via Hierarchical-Gated Reward Modeling](https://arxiv.org/abs/2602.19919)
*Xiang Li,Zikai Wei,Yiyan Qi,Wanyun Zhou,Xiang Liu,Penglei Sun,Yongqi Zhang,Xiaowen Chu*

Main category: cs.CL

TL;DR: Janus-Q是一个端到端的事件驱动交易框架，将金融新闻事件从辅助信号提升为主要决策单元，通过事件中心数据构建和决策导向微调两阶段范式，实现更一致、可解释和盈利的交易决策。


<details>
  <summary>Details</summary>
Motivation: 金融市场变动常由新闻中的离散金融事件驱动，这些影响具有异质性、突发性，且难以在纯数值预测目标下捕捉。现有方法面临两个关键挑战：缺乏大规模事件中心数据集，以及语言模型推理与动态市场条件下有效交易行为之间的不匹配。

Method: Janus-Q采用两阶段范式：第一阶段构建事件中心数据集（62,400篇文章，标注10个细粒度事件类型、相关股票、情感标签和事件驱动累计异常收益）；第二阶段进行决策导向微调，结合监督学习和由分层门控奖励模型指导的强化学习，明确捕捉多个交易目标之间的权衡。

Result: Janus-Q比市场指数和LLM基线实现更一致、可解释和盈利的交易决策，夏普比率提升高达102.0%，方向准确性相比最强竞争策略提高超过17.5%。

Conclusion: Janus-Q通过将金融新闻事件作为主要决策单元，解决了事件驱动交易中的关键挑战，提供了一种有效的事件中心数据构建和决策优化框架，显著提升了交易性能。

Abstract: Financial market movements are often driven by discrete financial events conveyed through news, whose impacts are heterogeneous, abrupt, and difficult to capture under purely numerical prediction objectives. These limitations have motivated growing interest in using textual information as the primary source of trading signals in learning-based systems. Two key challenges hinder existing approaches: (1) the absence of large-scale, event-centric datasets that jointly model news semantics and statistically grounded market reactions, and (2) the misalignment between language model reasoning and financially valid trading behavior under dynamic market conditions. To address these challenges, we propose Janus-Q, an end-to-end event-driven trading framework that elevates financial news events from auxiliary signals to primary decision units. Janus-Q unifies event-centric data construction and model optimization under a two-stage paradigm. Stage I focuses on event-centric data construction, building a large-scale financial news event dataset comprising 62,400 articles annotated with 10 fine-grained event types, associated stocks, sentiment labels, and event-driven cumulative abnormal return (CAR). Stage II performs decision-oriented fine-tuning, combining supervised learning with reinforcement learning guided by a Hierarchical Gated Reward Model (HGRM), which explicitly captures trade-offs among multiple trading objectives. Extensive experiments demonstrate that Janus-Q achieves more consistent, interpretable, and profitable trading decisions than market indices and LLM baselines, improving the Sharpe Ratio by up to 102.0% while increasing direction accuracy by over 17.5% compared to the strongest competing strategies.

</details>


### [60] [Assessing Risks of Large Language Models in Mental Health Support: A Framework for Automated Clinical AI Red Teaming](https://arxiv.org/abs/2602.19948)
*Ian Steenstra,Paola Pedrelli,Weiyan Shi,Stacy Marsella,Timothy W. Bickmore*

Main category: cs.CL

TL;DR: 该研究提出了一个评估AI心理治疗师安全性的仿真框架，通过模拟患者代理与AI治疗师的对话，揭示了AI在心理健康支持中存在的严重安全风险，特别是在酒精使用障碍治疗场景中。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型越来越多地用于心理健康支持，但现有的安全基准往往无法检测到治疗对话中复杂的、长期的风险。需要开发更有效的评估方法来识别AI心理治疗中的潜在危害。

Method: 研究者开发了一个评估框架：将AI心理治疗师与配备动态认知-情感模型的模拟患者代理配对，在治疗会话仿真中评估综合的护理质量和风险本体。在酒精使用障碍这一高影响力测试案例中，评估了6个AI代理（包括ChatGPT、Gemini和Character.AI），使用15个经过临床验证的患者角色，共进行了369次会话模拟。

Result: 大规模仿真揭示了AI心理健康支持的关键安全漏洞，包括：1）验证患者妄想（"AI精神病"）的风险；2）未能缓解自杀风险。研究验证了一个交互式数据可视化仪表板，得到了AI工程师、心理健康专业人员等9位利益相关者的认可，证明该框架能有效审计AI心理治疗的"黑箱"。

Conclusion: 研究发现强调了AI提供的心理健康支持存在关键安全风险，在部署前必须进行基于仿真的临床红队测试。该评估框架为利益相关者提供了有效的审计工具。

Abstract: Large Language Models (LLMs) are increasingly utilized for mental health support; however, current safety benchmarks often fail to detect the complex, longitudinal risks inherent in therapeutic dialogue. We introduce an evaluation framework that pairs AI psychotherapists with simulated patient agents equipped with dynamic cognitive-affective models and assesses therapy session simulations against a comprehensive quality of care and risk ontology. We apply this framework to a high-impact test case, Alcohol Use Disorder, evaluating six AI agents (including ChatGPT, Gemini, and Character.AI) against a clinically-validated cohort of 15 patient personas representing diverse clinical phenotypes.
  Our large-scale simulation (N=369 sessions) reveals critical safety gaps in the use of AI for mental health support. We identify specific iatrogenic risks, including the validation of patient delusions ("AI Psychosis") and failure to de-escalate suicide risk. Finally, we validate an interactive data visualization dashboard with diverse stakeholders, including AI engineers and red teamers, mental health professionals, and policy experts (N=9), demonstrating that this framework effectively enables stakeholders to audit the "black box" of AI psychotherapy. These findings underscore the critical safety risks of AI-provided mental health support and the necessity of simulation-based clinical red teaming before deployment.

</details>


### [61] [ReAttn: Improving Attention-based Re-ranking via Attention Re-weighting](https://arxiv.org/abs/2602.19969)
*Yuxing Tian,Fengran Mo,Weixu Zhang,Yiyan Qi,Jian-Yun Nie*

Main category: cs.CL

TL;DR: ReAttn：一种针对基于注意力的LLM重排方法的后处理重加权策略，通过跨文档IDF加权和基于熵的正则化来缓解注意力过度集中和词汇偏差问题。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的LLM重排方法虽然高效且可解释，但存在两个主要问题：1）注意力信号过度集中在少数文档的少量token上；2）注意力过度强调与查询词汇相似的短语，导致带有词汇相似性的不相关文档被误判为相关。

Method: 提出ReAttn后处理重加权策略：1）计算跨文档IDF加权来降低对在候选文档中频繁出现的查询重叠token的注意力，减少词汇偏差并突出独特术语；2）使用基于熵的正则化来缓解注意力过度集中问题，鼓励在信息性token间更平衡的分布。

Result: 大量实验证明了该方法的有效性，能够在不增加额外训练或监督的情况下直接对现有注意力权重进行调整。

Conclusion: ReAttn通过简单的后处理重加权策略，有效解决了基于注意力的LLM重排方法中的注意力过度集中和词汇偏差问题，提高了重排性能。

Abstract: The strong capabilities of recent Large Language Models (LLMs) have made them highly effective for zero-shot re-ranking task. Attention-based re-ranking methods, which derive relevance scores directly from attention weights, offer an efficient and interpretable alternative to generation-based re-ranking methods. However, they still face two major limitations. First, attention signals are highly concentrated a small subset of tokens within a few documents, making others indistinguishable. Second, attention often overemphasizes phrases lexically similar to the query, yielding biased rankings that irrelevant documents with mere lexical resemblance are regarded as relevant. In this paper, we propose \textbf{ReAttn}, a post-hoc re-weighting strategy for attention-based re-ranking methods. It first compute the cross-document IDF weighting to down-weight attention on query-overlapping tokens that frequently appear across the candidate documents, reducing lexical bias and emphasizing distinctive terms. It then employs entropy-based regularization to mitigate over-concentrated attention, encouraging a more balanced distribution across informative tokens. Both adjustments operate directly on existing attention weights without additional training or supervision. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [62] [Cross-lingual Matryoshka Representation Learning across Speech and Text](https://arxiv.org/abs/2602.19991)
*Yaya Sy,Dioula Doucouré,Christophe Cerisara,Irina Illina*

Main category: cs.CL

TL;DR: 训练首个法语-沃洛夫语双语语音-文本嵌套嵌入模型，实现从沃洛夫语音查询高效检索法语文本，无需依赖昂贵的ASR翻译流程


<details>
  <summary>Details</summary>
Motivation: 解决少数语言使用者的双重障碍：语言障碍（在线知识主要使用少数主流语言）和模态障碍（信息主要是文本形式，而许多语言主要是口语形式）。针对法语-沃洛夫语，需要找到更高效的方法进行跨语言跨模态检索。

Method: 1. 开发大规模数据整理流程；2. 训练首个双语语音-文本嵌套嵌入模型；3. 比较不同建模策略；4. 在冻结的文本嵌套模型内进行模态融合；5. 分析成本-准确率权衡和嵌套维度/秩的影响。

Result: 1. 在冻结的文本嵌套模型内进行模态融合效果最佳；2. 模型虽仅针对检索任务训练，但能很好地泛化到其他任务（如语音意图检测），表明学习了通用语义表示；3. 分析发现信息仅集中在少数组件中，存在效率提升潜力；4. 建立了新的基准测试。

Conclusion: 通过训练双语语音-文本嵌套嵌入模型，成功解决了法语-沃洛夫语使用者的语言和模态障碍。该方法避免了昂贵的ASR翻译流程，实现了高效的跨语言跨模态检索，并展示了良好的泛化能力。同时，对嵌套维度的分析揭示了效率优化的可能性。

Abstract: Speakers of under-represented languages face both a language barrier, as most online knowledge is in a few dominant languages, and a modality barrier, since information is largely text-based while many languages are primarily oral. We address this for French-Wolof by training the first bilingual speech-text Matryoshka embedding model, enabling efficient retrieval of French text from Wolof speech queries without relying on a costly ASR-translation pipelines. We introduce large-scale data curation pipelines and new benchmarks, compare modeling strategies, and show that modality fusion within a frozen text Matryoshka model performs best. Although trained only for retrieval, the model generalizes well to other tasks, such as speech intent detection, indicating the learning of general semantic representations. Finally, we analyze cost-accuracy trade-offs across Matryoshka dimensions and ranks, showing that information is concentrated only in a few components, suggesting potential for efficiency improvements.

</details>


### [63] [QUIETT: Query-Independent Table Transformation for Robust Reasoning](https://arxiv.org/abs/2602.20017)
*Gaurav Najpande,Tampu Ravi Kumar,Manan Roy Choudhury,Neha Valeti,Yanjie Fu,Vivek Gupta*

Main category: cs.CL

TL;DR: QuIeTT是一个查询无关的表格转换框架，将原始表格预处理为SQL就绪的规范表示，解耦表格转换与推理，提升下游表格推理的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的表格通常具有不规则模式、异构值格式和隐式关系结构，这些问题会降低下游表格推理和问答的可靠性。现有方法大多以查询依赖的方式处理这些问题，将表格清理与推理过程纠缠在一起，限制了泛化能力。

Method: QuIeTT是一个查询无关的表格转换框架，在观察到任何测试时查询之前，将原始表格预处理为单一SQL就绪的规范表示。它执行无损的模式和值规范化，暴露隐式关系，并通过原始表格快照保留完整的来源信息。

Result: 在WikiTQ、HiTab、NQ-Table和SequentialQA四个基准测试上的实验显示，QuIeTT在各种模型和推理范式上均取得一致的增益，特别是在结构多样、未见过的挑战性问题集上表现出特别强的改进。

Conclusion: 通过将表格转换与推理解耦，QuIeTT能够在不修改下游模型的情况下，实现更清洁、更可靠和高效的查询，为解决现实世界表格的复杂性问题提供了有效的预处理方案。

Abstract: Real-world tables often exhibit irregular schemas, heterogeneous value formats, and implicit relational structure, which degrade the reliability of downstream table reasoning and question answering. Most existing approaches address these issues in a query-dependent manner, entangling table cleanup with reasoning and thus limiting generalization. We introduce QuIeTT, a query-independent table transformation framework that preprocesses raw tables into a single SQL-ready canonical representation before any test-time queries are observed. QuIeTT performs lossless schema and value normalization, exposes implicit relations, and preserves full provenance via raw table snapshots. By decoupling table transformation from reasoning, QuIeTT enables cleaner, more reliable, and highly efficient querying without modifying downstream models. Experiments on four benchmarks, WikiTQ, HiTab, NQ-Table, and SequentialQA show consistent gains across models and reasoning paradigms, with particularly strong improvements on a challenge set of structurally diverse, unseen questions.

</details>


### [64] [gencat: Generative computerized adaptive testing](https://arxiv.org/abs/2602.20020)
*Wanyong Feng,Andrew Lan*

Main category: cs.CL

TL;DR: GENCAT是一个基于大语言模型的自适应测试框架，利用生成式项目反应理论从学生开放答案中估计知识水平，并通过三种问题选择算法优化测试过程。


<details>
  <summary>Details</summary>
Motivation: 现有CAT框架主要基于预测学生答案正确性，无法充分利用问题和答案中的文本信息，特别是在开放性问题场景下。

Method: 1. 开发生成式项目反应理论模型，通过监督微调和偏好优化进行训练；2. 提出三种基于生成能力的问题选择算法（不确定性、语言多样性、信息量）；3. 在两个真实编程数据集上进行实验。

Result: 在关键早期测试阶段，GENCAT优于现有CAT基线，AUC提升高达4.32%。

Conclusion: GENCAT通过利用大语言模型的生成能力，能够有效处理开放性问题，在自适应测试中实现了更好的性能。

Abstract: Existing computerized Adaptive Testing (CAT) frameworks are typically built on predicting the correctness of a student response to a question. Although effective, this approach fails to leverage textual information in questions and responses, especially for open-ended questions. In this work, we propose GENCAT (\textbf{GEN}erative \textbf{CAT}), a novel CAT framework that leverages Large Language Models for knowledge estimate and question selection. First, we develop a Generative Item Response Theory (GIRT) model that enables us to estimate student knowledge from their open-ended responses and predict responses to unseen questions. We train the model in a two-step process, first via Supervised Fine-Tuning and then via preference optimization for knowledge-response alignment. Second, we introduce three question selection algorithms that leverage the generative capabilities of the GIRT model, based on the uncertainty, linguistic diversity, and information of sampled student responses. Third, we conduct experiments on two real-world programming datasets and demonstrate that GENCAT outperforms existing CAT baselines, achieving an AUC improvement of up to 4.32\% in the key early testing stages.

</details>


### [65] [AgenticSum: An Agentic Inference-Time Framework for Faithful Clinical Text Summarization](https://arxiv.org/abs/2602.20040)
*Fahmida Liza Piya,Rahmatollah Beheshti*

Main category: cs.CL

TL;DR: AgenticSum是一个推理时的智能体框架，通过分离上下文选择、生成、验证和针对性修正来减少临床文本摘要中的幻觉内容。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自动化临床文本摘要方面有很大潜力，但由于临床文档的长度、噪声和异质性，保持事实一致性仍然具有挑战性。

Method: 提出AgenticSum框架，将摘要任务分解为协调的多个阶段：压缩任务相关上下文、生成初始草稿、使用内部注意力基础信号识别弱支持内容、在监督控制下有选择地修正标记内容。

Result: 在两个公共数据集上评估，使用基于参考的指标、LLM作为评判者的评估和人工评估。在各种测量指标上，AgenticSum相比原始LLM和其他强基线都表现出了一致的改进。

Conclusion: 具有针对性修正的结构化智能体设计为使用LLM改进临床笔记摘要提供了有效的推理时解决方案。

Abstract: Large language models (LLMs) offer substantial promise for automating clinical text summarization, yet maintaining factual consistency remains challenging due to the length, noise, and heterogeneity of clinical documentation. We present AgenticSum, an inference-time, agentic framework that separates context selection, generation, verification, and targeted correction to reduce hallucinated content. The framework decomposes summarization into coordinated stages that compress task-relevant context, generate an initial draft, identify weakly supported spans using internal attention grounding signals, and selectively revise flagged content under supervisory control. We evaluate AgenticSum on two public datasets, using reference-based metrics, LLM-as-a-judge assessment, and human evaluation. Across various measures, AgenticSum demonstrates consistent improvements compared to vanilla LLMs and other strong baselines. Our results indicate that structured, agentic design with targeted correction offers an effective inference time solution to improve clinical note summarization using LLMs.

</details>


### [66] [Position: General Alignment Has Hit a Ceiling; Edge Alignment Must Be Taken Seriously](https://arxiv.org/abs/2602.20042)
*Han Bao,Yue Huang,Xiaoda Wang,Zheyuan Zhang,Yujun Zhou,Carl Yang,Xiangliang Zhang,Yanfang Ye*

Main category: cs.CL

TL;DR: 本文批评当前基于单一标量奖励的通用对齐范式存在结构局限性，提出边缘对齐作为替代方案，强调保持多维价值结构、支持多元民主表征、纳入认知互动机制。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型部署在复杂的社会技术系统中，暴露出现有对齐实践的局限性。特别是通用对齐范式将多样的人类价值压缩为单一标量奖励，在面对价值冲突、多元利益相关者和不可约不确定性时存在结构性天花板。

Method: 提出边缘对齐作为独特方法，包含七个相互依存的支柱，分为三个阶段。该方法强调保持多维价值结构、支持多元民主表征、纳入认知互动机制，并将技术方法和治理方向相结合。

Result: 分析指出标量化的数学和激励机制会导致三种问题：结构性的价值扁平化、规范性的表征丢失、认知性的不确定性盲视。边缘对齐方法为解决这些问题提供了框架。

Conclusion: 应将对齐重新定义为动态规范治理的生命周期问题，而非单一实例优化任务。需要整合技术和治理方向，应对数据收集、训练目标和评估等关键挑战。

Abstract: Large language models are being deployed in complex socio-technical systems, which exposes limits in current alignment practice. We take the position that the dominant paradigm of General Alignment, which compresses diverse human values into a single scalar reward, reaches a structural ceiling in settings with conflicting values, plural stakeholders, and irreducible uncertainty. These failures follow from the mathematics and incentives of scalarization and lead to \textbf{structural} value flattening, \textbf{normative} representation loss, and \textbf{cognitive} uncertainty blindness. We introduce Edge Alignment as a distinct approach in which systems preserve multi dimensional value structure, support plural and democratic representation, and incorporate epistemic mechanisms for interaction and clarification. To make this approach practical, we propose seven interdependent pillars organized into three phases. We identify key challenges in data collection, training objectives, and evaluation, outlining complementary technical and governance directions. Taken together, these measures reframe alignment as a lifecycle problem of dynamic normative governance rather than as a single instance optimization task.

</details>


### [67] [Entropy in Large Language Models](https://arxiv.org/abs/2602.20052)
*Marco Scharringhausen*

Main category: cs.CL

TL;DR: 该研究将大语言模型输出视为符号序列信息源，比较了LLM与自然语言（OANC语料库）的词熵，发现LLM的词熵低于自然语言。


<details>
  <summary>Details</summary>
Motivation: 研究旨在形式化大语言训练中信息和不确定性的直觉，评估使用LLM生成的数据训练LLM的影响，特别是针对来自互联网的文本。

Method: 将LLM输出视为有限字母表上无限符号序列的信息源，假设概率模型遵循恒定随机分布（平稳源），计算词熵并与OANC语料库的自然语言词熵进行比较。

Result: LLM的词熵低于自然语言（书面和口语形式）的词熵。

Conclusion: LLM生成的内容信息不确定性低于自然语言，这对使用LLM生成数据训练LLM的长期影响有重要意义。

Abstract: In this study, the output of large language models (LLM) is considered an information source generating an unlimited sequence of symbols drawn from a finite alphabet. Given the probabilistic nature of modern LLMs, we assume a probabilistic model for these LLMs, following a constant random distribution and the source itself thus being stationary. We compare this source entropy (per word) to that of natural language (written or spoken) as represented by the Open American National Corpus (OANC). Our results indicate that the word entropy of such LLMs is lower than the word entropy of natural speech both in written or spoken form. The long-term goal of such studies is to formalize the intuitions of information and uncertainty in large language training to assess the impact of training an LLM from LLM generated training data. This refers to texts from the world wide web in particular.

</details>


### [68] [Multilingual Large Language Models do not comprehend all natural languages to equal degrees](https://arxiv.org/abs/2602.20065)
*Natalia Moskvina,Raquel Montero,Masaya Yoshida,Ferdy Hubers,Paolo Morosi,Walid Irhaymi,Jin Yan,Tamara Serrano,Elena Pagliarini,Fritz Günther,Evelina Leivada*

Main category: cs.CL

TL;DR: 研究发现大语言模型在多语言理解任务中表现优异，但均未达到人类水平；英语并非表现最佳语言，被多个罗曼语超越；性能受分词、语言距离、训练数据等多种因素影响


<details>
  <summary>Details</summary>
Motivation: 当前对大语言模型理解能力的评估主要基于高资源语言（尤其是英语），缺乏对多语言能力的全面评估，默认假设英语是LLMs表现最佳的语言，而低资源语言表现较差

Method: 在3个流行的大语言模型上，使用12种代表不同语系（印欧语系、亚非语系、突厥语系、汉藏语系、日本语系）的语言进行语言理解任务测试，比较模型表现与人类基线的差异

Result: 模型在所有语言中都表现出优异的语言准确性，但均未达到人类基线水平；英语并非表现最佳语言，被多个罗曼语（包括低资源罗曼语）系统性地超越；模型性能受分词方式、与西班牙语/英语的语言距离、训练数据规模、数据来源（高/低资源语言、WEIRD/非WEIRD社区）等因素影响

Conclusion: 大语言模型在多语言理解方面表现出色但仍有提升空间，英语优势假设不成立，模型性能受多种语言因素影响，需要更全面的多语言评估框架

Abstract: Large Language Models (LLMs) play a critical role in how humans access information. While their core use relies on comprehending written requests, our understanding of this ability is currently limited, because most benchmarks evaluate LLMs in high-resource languages predominantly spoken by Western, Educated, Industrialised, Rich, and Democratic (WEIRD) communities. The default assumption is that English is the best-performing language for LLMs, while smaller, low-resource languages are linked to less reliable outputs, even in multilingual, state-of-the-art models. To track variation in the comprehension abilities of LLMs, we prompt 3 popular models on a language comprehension task across 12 languages, representing the Indo-European, Afro-Asiatic, Turkic, Sino-Tibetan, and Japonic language families. Our results suggest that the models exhibit remarkable linguistic accuracy across typologically diverse languages, yet they fall behind human baselines in all of them, albeit to different degrees. Contrary to what was expected, English is not the best-performing language, as it was systematically outperformed by several Romance languages, even lower-resource ones. We frame the results by discussing the role of several factors that drive LLM performance, such as tokenization, language distance from Spanish and English, size of training data, and data origin in high- vs. low-resource languages and WEIRD vs. non-WEIRD communities.

</details>


### [69] [How Retrieved Context Shapes Internal Representations in RAG](https://arxiv.org/abs/2602.20091)
*Samuel Yeh,Sharon Li*

Main category: cs.CL

TL;DR: 该研究通过分析RAG系统中检索文档对LLM内部表征的影响，揭示了文档相关性和层级处理如何塑造模型内部表示，并解释了输出行为。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注RAG的输出行为，但对检索上下文如何影响LLM内部表征知之甚少。在现实检索场景中，检索到的文档集通常包含相关性和有用性各异的混合文档，需要理解这些文档如何塑造内部表征以解释信息整合过程。

Method: 通过潜在表征的视角研究RAG，系统分析不同类型检索文档对LLM隐藏状态的影响，以及这些内部表征变化与下游生成行为的关系。在四个问答数据集和三个LLM上，在受控的单文档和多文档设置下分析内部表征。

Result: 揭示了上下文相关性和层级处理如何影响内部表征，提供了对LLM输出行为的解释，并为RAG系统设计提供了见解。

Conclusion: 通过分析RAG的内部表征机制，可以更好地理解检索上下文如何塑造LLM的信息整合过程，这有助于解释模型输出行为并为改进RAG系统设计提供指导。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by conditioning generation on retrieved external documents, but the effect of retrieved context is often non-trivial. In realistic retrieval settings, the retrieved document set often contains a mixture of documents that vary in relevance and usefulness. While prior work has largely examined these phenomena through output behavior, little is known about how retrieved context shapes the internal representations that mediate information integration in RAG. In this work, we study RAG through the lens of latent representations. We systematically analyze how different types of retrieved documents affect the hidden states of LLMs, and how these internal representation shifts relate to downstream generation behavior. Across four question-answering datasets and three LLMs, we analyze internal representations under controlled single- and multi-document settings. Our results reveal how context relevancy and layer-wise processing influence internal representations, providing explanations on LLMs output behaviors and insights for RAG system design.

</details>


### [70] [BabyLM Turns 4: Call for Papers for the 2026 BabyLM Workshop](https://arxiv.org/abs/2602.20092)
*Leshem Choshen,Ryan Cotterell,Mustafa Omer Gul,Jaap Jumelet,Tal Linzen,Aaron Mueller,Suchir Salhan,Raj Sanjay Shah,Alex Warstadt,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: BabyLM工作坊旨在消除认知建模与语言建模之间的界限，举办第四届竞赛，设有通用赛道（数据高效预训练）和新的多语言赛道，并征集相关领域论文。


<details>
  <summary>Details</summary>
Motivation: 打破认知建模与语言建模之间的传统界限，促进两个领域的交叉研究，通过竞赛推动数据高效预训练和多语言模型发展。

Method: 通过举办BabyLM竞赛（包含通用赛道和多语言新赛道），同时征集训练效率、认知合理性、弱模型评估等相关领域的研究论文。

Result: 成功组织了第四届BabyLM竞赛，设立了数据高效预训练的通用赛道和新的多语言赛道，吸引了相关领域的研究参与。

Conclusion: BabyLM工作坊为连接认知建模和语言建模提供了重要平台，通过竞赛和论文征集推动了该交叉领域的研究进展。

Abstract: BabyLM aims to dissolve the boundaries between cognitive modeling and language modeling. We call for both workshop papers and for researchers to join the 4th BabyLM competition. As in previous years, we call for participants in the data-efficient pretraining challenge in the general track. This year, we also offer a new track: Multilingual.
  We also call for papers outside the competition in any relevant areas. These include training efficiency, cognitively plausible research, weak model evaluation, and more.

</details>


### [71] [To Reason or Not to: Selective Chain-of-Thought in Medical Question Answering](https://arxiv.org/abs/2602.20130)
*Zaifu Zhan,Min Zeng,Shuang Zhou,Yiran Song,Xiaoyi Chen,Yu Hou,Yifan Wu,Yang Ruan,Rui Zhang*

Main category: cs.CL

TL;DR: 提出Selective Chain-of-Thought方法，在医疗问答中根据问题复杂度选择性生成推理过程，显著降低计算成本同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗问答中广泛使用链式思维推理，但许多问题本质上是回忆型，不需要复杂推理，导致不必要的计算开销和效率低下。

Method: 提出Selective CoT策略：在推理时先预测问题是否需要推理，仅当需要时才生成推理过程。使用Llama-3.1-8B和Qwen-2.5-7B模型在四个生物医学QA基准上评估。

Result: Selective CoT减少推理时间13-45%，减少token使用8-47%，准确性损失≤4%。在某些模型-任务组合中，既提高了准确性又提升了效率。相比固定长度CoT，达到相似或更好的准确性但计算成本显著降低。

Conclusion: Selective CoT提供了一种简单、模型无关且成本效益高的医疗QA方法，通过根据问题复杂度调整推理深度，提高了LLM临床系统的实际部署可行性。

Abstract: Objective: To improve the efficiency of medical question answering (MedQA) with large language models (LLMs) by avoiding unnecessary reasoning while maintaining accuracy.
  Methods: We propose Selective Chain-of-Thought (Selective CoT), an inference-time strategy that first predicts whether a question requires reasoning and generates a rationale only when needed. Two open-source LLMs (Llama-3.1-8B and Qwen-2.5-7B) were evaluated on four biomedical QA benchmarks-HeadQA, MedQA-USMLE, MedMCQA, and PubMedQA. Metrics included accuracy, total generated tokens, and inference time.
  Results: Selective CoT reduced inference time by 13-45% and token usage by 8-47% with minimal accuracy loss ($\leq$4\%). In some model-task pairs, it achieved both higher accuracy and greater efficiency than standard CoT. Compared with fixed-length CoT, Selective CoT reached similar or superior accuracy at substantially lower computational cost.
  Discussion: Selective CoT dynamically balances reasoning depth and efficiency by invoking explicit reasoning only when beneficial, reducing redundancy on recall-type questions while preserving interpretability.
  Conclusion: Selective CoT provides a simple, model-agnostic, and cost-effective approach for medical QA, aligning reasoning effort with question complexity to enhance real-world deployability of LLM-based clinical systems.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [72] [FineRef: Fine-Grained Error Reflection and Correction for Long-Form Generation with Citations](https://arxiv.org/abs/2602.18437)
*Yixing Peng,Licheng Zhang,Shancheng Fang,Yi Liu,Peijian Gu,Quan Wang*

Main category: cs.IR

TL;DR: FineRef是一个基于细粒度错误反思的框架，通过两阶段训练策略教模型自我识别和纠正引用中的不匹配和无关引用错误，显著提升引用准确性和答案质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度优化引用保真度而忽视查询相关性，在噪声或无关检索内容的现实场景中会降低答案质量和鲁棒性。此外，单次生成范式在需要多个引用的长文本生成中难以提供最优答案。

Method: 采用两阶段训练策略：第一阶段通过监督微调建立"尝试-反思-纠正"行为模式，使用轻量级模型构建的细粒度可控反思数据，并通过在线自我反思自举策略迭代丰富训练数据；第二阶段应用过程级强化学习，采用多维度奖励方案促进反思准确性、答案质量和纠正增益。

Result: 在ALCE基准测试中，FineRef显著提升引用性能和答案准确性。7B模型在Citation F1上比GPT-4高出18%，在EM Recall上高出4%，同时在关键评估指标上超越最先进模型。在领域迁移和噪声检索场景中也表现出强大的泛化能力和鲁棒性。

Conclusion: FineRef通过细粒度错误反思有效解决了LLM生成中的引用不匹配和无关引用问题，提供了一种更可靠、更准确的引用生成框架，在现实场景中表现出优异的性能。

Abstract: Generating with citations is crucial for trustworthy Large Language Models (LLMs), yet even advanced LLMs often produce mismatched or irrelevant citations. Existing methods over-optimize citation fidelity while overlooking relevance to the user query, which degrades answer quality and robustness in real-world settings with noisy or irrelevant retrieved content. Moreover, the prevailing single-pass paradigm struggles to deliver optimal answers in long-form generation that requiring multiple citations. To address these limitations, we propose FineRef, a framework based on Fine-grained error Reflection, which explicitly teaches the model to self-identify and correct two key citation errors, mismatch and irrelevance, on a per-citation basis. FineRef follows a two-stage training strategy. The first stage instills an "attempt-reflect-correct" behavioral pattern via supervised fine-tuning, using fine-grained and controllable reflection data constructed by specialized lightweight models. An online self-reflective bootstrapping strategy is designed to improve generalization by iteratively enriching training data with verified, self-improving examples. To further enhance the self-reflection and correction capability, the second stage applies process-level reinforcement learning with a multi-dimensional reward scheme that promotes reflection accuracy, answer quality, and correction gain. Experiments on the ALCE benchmark demonstrate that FineRef significantly improves both citation performance and answer accuracy. Our 7B model outperforms GPT-4 by up to 18% in Citation F1 and 4% in EM Recall, while also surpassing the state-of-the-art model across key evaluation metrics. FineRef also exhibits strong generalization and robustness in domain transfer settings and noisy retrieval scenarios.

</details>


### [73] [Altar: Structuring Sharable Experimental Data from Early Exploration to Publication](https://arxiv.org/abs/2602.18588)
*William Gaultier,Andrea Lodetti,Ian Coghill,David Colliaux,Maximilian Fleck,Alienor Lahlou*

Main category: cs.IR

TL;DR: Altar是一个轻量级、领域无关的实验数据管理框架，基于Sacred实验跟踪模型，在项目开始时就结构化实验数据，支持不同技能用户，实现探索性实验与FAIR数据共享的桥梁。


<details>
  <summary>Details</summary>
Motivation: 实验项目活跃开发阶段的数据和元数据管理在协作研究中是一个重大挑战，这一阶段经常在项目提案的数据管理计划中被忽视，但它在确保可重复性和避免发表时追溯性重建方面起着重要作用。

Method: Altar基于Sacred实验跟踪模型构建，捕获实验（元）数据并结构化。小文件存储在灵活的NoSQL数据库中，大型原始数据保存在专用存储中并通过唯一标识符链接，确保效率和可追溯性。该框架可组合现有工作流程，最小化工作习惯干扰。

Result: Altar提供了基于用户技能（博士生、博士后、首席研究员、实验室管理员、系统管理员）的不同使用路径。框架可以轻松部署在服务器上，并在扩展或准备数据发布时公开访问。它不需要专门基础设施即可开始使用。

Conclusion: 通过解决研究的动态阶段，Altar在探索性实验和FAIR对齐的数据共享之间提供了实用桥梁，填补了数据管理计划中的关键空白。

Abstract: Managing the data and metadata during the active development phase of an experimental project presents a significant challenge, particularly in collaborative research. This phase is frequently overlooked in Data Management Plans included in project proposals, despite its important role in ensuring reproducibility and preventing the need for retroactive reconstruction at the time of publication. Here we present Altar, a lightweight, domain-agnostic framework for structuring experimental data from the onset of a project without imposing rigid data models. Altar is built around the Sacred experiment-tracking model and captures experimental (meta)data and structures them. Parameters, metadata, curves and small files are stored in a flexible NoSQL database, while large raw data are maintained in dedicated storage and linked through unique identifiers, ensuring efficiency and traceability. This integration is composable with exiting workflows, allowing integration with minimial disruption of work habits. We document different pathways to use Altar based on users skillset (PhD students, Post-docs, Principal Investigators, Laboratory administrators, System administrators). While getting started with Altar does not require a specialized infrastructure, the framework can be easily deployed on a server and made publicly accessible when scaling up or preparing data for publication. By addressing the dynamic phase of research, Altar provides a practical bridge between exploratory experimentation and FAIR-aligned data sharing.

</details>


### [74] [Towards Reliable Negative Sampling for Recommendation with Implicit Feedback via In-Community Popularity](https://arxiv.org/abs/2602.18759)
*Chen Chen,Haobo Lin,Yuanbo Xu*

Main category: cs.IR

TL;DR: 提出ICPNS负采样框架，利用用户社区结构和社区内流行度来识别可靠的真实负样本，提升隐式反馈推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 在隐式反馈推荐系统中，只有正交互被观察到，缺乏显式负信号。负采样在模型训练中至关重要，但设计可靠的负采样策略具有挑战性，需要同时确保真实性、难度和可解释性。

Method: 提出ICPNS（In-Community Popularity Negative Sampling）框架，利用用户社区结构来识别可靠且信息丰富的负样本。该方法基于一个洞察：物品曝光由潜在用户社区驱动。通过识别这些社区并利用社区内流行度，ICPNS有效近似物品曝光概率。因此，在用户社区内流行但未被点击的物品被识别为更可靠的真实负样本。

Result: 在四个基准数据集上的广泛实验表明，ICPNS在图基推荐器上带来了一致的改进，在基于矩阵分解的模型上具有竞争力，在统一评估协议下优于代表性的负采样策略。

Conclusion: ICPNS通过利用用户社区结构和社区内流行度，提供了一种有效的负采样方法，能够识别更可靠的真实负样本，从而提升隐式反馈推荐系统的性能。

Abstract: Learning from implicit feedback is a fundamental problem in modern recommender systems, where only positive interactions are observed and explicit negative signals are unavailable. In such settings, negative sampling plays a critical role in model training by constructing negative items that enable effective preference learning and ranking optimization. However, designing reliable negative sampling strategies remains challenging, as they must simultaneously ensure realness, hardness, and interpretability. To this end, we propose \textbf{ICPNS (In-Community Popularity Negative Sampling)}, a novel framework that leverages user community structure to identify reliable and informative negative samples. Our approach is grounded in the insight that item exposure is driven by latent user communities. By identifying these communities and utilizing in-community popularity, ICPNS effectively approximates the probability of item exposure. Consequently, items that are popular within a user's community but remain unclicked are identified as more reliable true negatives. Extensive experiments on four benchmark datasets demonstrate that ICPNS yields consistent improvements on graph-based recommenders and competitive performance on MF-based models, outperforming representative negative sampling strategies under a unified evaluation protocol.

</details>


### [75] [Give Users the Wheel: Towards Promptable Recommendation Paradigm](https://arxiv.org/abs/2602.18929)
*Fuyuan Lyu,Chenglin Luo,Qiyuan Zhang,Yupeng Hou,Haolun Wu,Xing Tang,Xue Liu,Jin L. C. Guo,Xiuqiang He*

Main category: cs.IR

TL;DR: DPR框架让传统序列推荐模型能够通过自然语言提示动态引导检索过程，同时保持协同过滤信号，解决了传统模型对显式用户意图适应不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统序列推荐模型在处理显式用户意图（如自然语言提示）时存在局限，无法适应与历史习惯不同的即时用户目标。现有LLM集成方法要么牺牲效率和协同过滤精度，要么受限于底层模型的召回能力。

Method: 提出DPR框架：1）融合模块对齐协同和语义信号；2）Mixture-of-Experts架构分离正负引导的冲突梯度；3）三阶段训练策略逐步对齐提示语义空间与协同空间。

Result: 在真实世界数据集上的实验表明，DPR在提示引导任务上显著优于现有最佳基线，同时在标准序列推荐场景中保持竞争力。

Conclusion: DPR框架成功实现了可提示推荐，让传统序列推荐模型能够在保持协同过滤优势的同时，通过自然语言提示动态调整检索过程，解决了现有方法的局限性。

Abstract: Conventional sequential recommendation models have achieved remarkable success in mining implicit behavioral patterns. However, these architectures remain structurally blind to explicit user intent: they struggle to adapt when a user's immediate goal (e.g., expressed via a natural language prompt) deviates from their historical habits. While Large Language Models (LLMs) offer the semantic reasoning to interpret such intent, existing integration paradigms force a dilemma: LLM-as-a-recommender paradigm sacrifices the efficiency and collaborative precision of ID-based retrieval, while Reranking methods are inherently bottlenecked by the recall capabilities of the underlying model. In this paper, we propose Decoupled Promptable Sequential Recommendation (DPR), a model-agnostic framework that empowers conventional sequential backbones to natively support Promptable Recommendation, the ability to dynamically steer the retrieval process using natural language without abandoning collaborative signals. DPR modulates the latent user representation directly within the retrieval space. To achieve this, we introduce a Fusion module to align the collaborative and semantic signals, a Mixture-of-Experts (MoE) architecture that disentangles the conflicting gradients from positive and negative steering, and a three-stage training strategy that progressively aligns the semantic space of prompts with the collaborative space. Extensive experiments on real-world datasets demonstrate that DPR significantly outperforms state-of-the-art baselines in prompt-guided tasks while maintaining competitive performance in standard sequential recommendation scenarios.

</details>


### [76] [Adaptive Multi-Agent Reasoning for Text-to-Video Retrieval](https://arxiv.org/abs/2602.19040)
*Jiaxin Wu,Xiao-Yong Wei,Qing Li*

Main category: cs.IR

TL;DR: 提出自适应多智能体检索框架，通过动态协调多个专门智能体进行迭代推理，显著提升零样本文本到视频检索性能


<details>
  <summary>Details</summary>
Motivation: 现有零样本跨模态对齐方法在处理涉及时间、逻辑或因果关系的复杂查询时，存在查询依赖的时间推理能力不足的问题，限制了检索系统的有效性

Method: 提出自适应多智能体检索框架，包含：检索智能体（大规模视频检索）、推理智能体（零样本上下文时间推理）、查询重构智能体（优化模糊查询），由编排智能体动态协调，并引入包含检索性能记忆和历史推理轨迹的通信机制

Result: 在三个TRECVid基准测试上，相比CLIP4Clip实现两倍性能提升，显著优于现有最先进方法

Conclusion: 自适应多智能体框架通过动态协调专门智能体和迭代推理，有效解决了复杂查询中的时间推理挑战，为文本到视频检索提供了可扩展的解决方案

Abstract: The rise of short-form video platforms and the emergence of multimodal large language models (MLLMs) have amplified the need for scalable, effective, zero-shot text-to-video retrieval systems. While recent advances in large-scale pretraining have improved zero-shot cross-modal alignment, existing methods still struggle with query-dependent temporal reasoning, limiting their effectiveness on complex queries involving temporal, logical, or causal relationships. To address these limitations, we propose an adaptive multi-agent retrieval framework that dynamically orchestrates specialized agents over multiple reasoning iterations based on the demands of each query. The framework includes: (1) a retrieval agent for scalable retrieval over large video corpora, (2) a reasoning agent for zero-shot contextual temporal reasoning, and (3) a query reformulation agent for refining ambiguous queries and recovering performance for those that degrade over iterations. These agents are dynamically coordinated by an orchestration agent, which leverages intermediate feedback and reasoning outcomes to guide execution. We also introduce a novel communication mechanism that incorporates retrieval-performance memory and historical reasoning traces to improve coordination and decision-making. Experiments on three TRECVid benchmarks spanning eight years show that our framework achieves a twofold improvement over CLIP4Clip and significantly outperforms state-of-the-art methods by a large margin.

</details>


### [77] [SIDEKICK: A Semantically Integrated Resource for Drug Effects, Indications, and Contraindications](https://arxiv.org/abs/2602.19183)
*Mohammad Ashhad,Olga Mashkova,Ricardo Henao,Robert Hoehndorf*

Main category: cs.IR

TL;DR: SIDEKICK是一个基于FDA药品标签构建的知识图谱，通过LLM提取和Graph RAG技术将药物适应症、禁忌症和不良反应映射到标准本体，实现了语义集成和药物再利用分析。


<details>
  <summary>Details</summary>
Motivation: 现有药物安全数据集过度依赖MedDRA等术语体系，语义推理能力有限，且与语义网本体和知识图谱的互操作性不足，这限制了药物安全监测和药物再利用的分析能力。

Method: 基于大语言模型（LLM）提取和Graph-Retrieval Augmented Generation（Graph RAG）的工作流程，处理超过50,000个药物标签，并将术语映射到人类表型本体（HPO）、MONDO疾病本体和RxNorm，使用SIO作为上层本体构建RDF知识图谱。

Result: SIDEKICK在药物再利用任务中（基于副作用相似性）的表现优于SIDER和ONSIDES数据库，实现了语义集成的药物安全资源，支持自动化安全监测和基于表型的相似性分析。

Conclusion: SIDEKICK知识图谱通过标准化和语义集成显著提升了药物安全数据的互操作性和分析能力，为药物安全监测和药物再利用提供了有效的工具。

Abstract: Pharmacovigilance and clinical decision support systems utilize structured drug safety data to guide medical practice. However, existing datasets frequently depend on terminologies such as MedDRA, which limits their semantic reasoning capabilities and their interoperability with Semantic Web ontologies and knowledge graphs. To address this gap, we developed SIDEKICK, a knowledge graph that standardizes drug indications, contraindications, and adverse reactions from FDA Structured Product Labels. We developed and used a workflow based on Large Language Model (LLM) extraction and Graph-Retrieval Augmented Generation (Graph RAG) for ontology mapping. We processed over 50,000 drug labels and mapped terms to the Human Phenotype Ontology (HPO), the MONDO Disease Ontology, and RxNorm. Our semantically integrated resource outperforms the SIDER and ONSIDES databases when applied to the task of drug repurposing by side effect similarity. We serialized the dataset as a Resource Description Framework (RDF) graph and employed the Semanticscience Integrated Ontology (SIO) as upper level ontology to further improve interoperability. Consequently, SIDEKICK enables automated safety surveillance and phenotype-based similarity analysis for drug repurposing.

</details>


### [78] [SplitLight: An Exploratory Toolkit for Recommender Systems Datasets and Splits](https://arxiv.org/abs/2602.19339)
*Anna Volodkevich,Dmitry Anikin,Danil Gusak,Anton Klenitskiy,Evgeny Frolov,Alexey Vasilev*

Main category: cs.IR

TL;DR: SplitLight是一个开源工具包，用于分析和比较推荐系统离线评估中的数据预处理和划分策略，提高实验的可重复性和可比性。


<details>
  <summary>Details</summary>
Motivation: 推荐系统离线评估中，数据预处理和划分策略的隐藏选择（如过滤、重复处理、冷启动处理、划分策略设计等）会显著影响模型排名，破坏可重复性和跨论文可比性。

Method: 开发SplitLight工具包，分析交互日志和划分子集的核心统计数据、时间特征、重复消费模式和时间戳异常，诊断划分有效性（包括时间泄漏、冷用户/物品暴露、分布偏移），并通过汇总摘要和交互可视化进行策略比较。

Result: SplitLight提供了Python工具包和无代码交互界面，生成审计摘要来证明评估协议的合理性，支持推荐系统研究和工业中的透明、可靠和可比较的实验。

Conclusion: SplitLight通过使数据预处理和划分决策可测量、可比较、可报告，有助于提高推荐系统离线评估的透明度、可靠性和可比性。

Abstract: Offline evaluation of recommender systems is often affected by hidden, under-documented choices in data preparation. Seemingly minor decisions in filtering, handling repeats, cold-start treatment, and splitting strategy design can substantially reorder model rankings and undermine reproducibility and cross-paper comparability.
  In this paper, we introduce SplitLight, an open-source exploratory toolkit that enables researchers and practitioners designing preprocessing and splitting pipelines or reviewing external artifacts to make these decisions measurable, comparable, and reportable. Given an interaction log and derived split subsets, SplitLight analyzes core and temporal dataset statistics, characterizes repeat consumption patterns and timestamp anomalies, and diagnoses split validity, including temporal leakage, cold-user/item exposure, and distribution shifts. SplitLight further allows side-by-side comparison of alternative splitting strategies through comprehensive aggregated summaries and interactive visualizations. Delivered as both a Python toolkit and an interactive no-code interface, SplitLight produces audit summaries that justify evaluation protocols and support transparent, reliable, and comparable experimentation in recommender systems research and industry.

</details>


### [79] [DReX: An Explainable Deep Learning-based Multimodal Recommendation Framework](https://arxiv.org/abs/2602.19702)
*Adamya Shyam,Venkateswara Rao Kagita,Bharti Rana,Vikas Kumar*

Main category: cs.IR

TL;DR: DReX是一个统一的多模态推荐框架，通过门控循环单元逐步整合多模态反馈中的交互级特征来优化用户和物品表示，解决了现有方法中模态孤立处理、需要完整多模态数据和独立学习表示的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推荐系统存在三个关键局限：1) 孤立处理不同模态；2) 训练时需要每个交互的完整多模态数据；3) 独立学习用户和物品表示。这些问题导致复杂性增加以及用户和物品嵌入之间可能不对齐。

Method: 提出DReX框架，使用门控循环单元从多模态反馈中逐步整合交互级特征到全局表示中。该方法能够同时建模细粒度交互细节和宏观偏好模式，无需单独的特征提取过程，并对模态缺失具有鲁棒性。

Result: 在三个包含评论和评分作为交互模态的真实数据集上评估，DReX在所有数据集上都优于现有最先进方法。通过将评论文本作为模态，自动为用户和物品生成可解释的关键词配置文件，为推荐过程提供可解释的偏好指示器。

Conclusion: DReX通过增量更新机制有效解决了多模态推荐中的关键挑战，实现了用户和物品表示的更好对齐，提高了推荐性能，并提供了可解释性。

Abstract: Multimodal recommender systems leverage diverse data sources, such as user interactions, content features, and contextual information, to address challenges like cold-start and data sparsity. However, existing methods often suffer from one or more key limitations: processing different modalities in isolation, requiring complete multimodal data for each interaction during training, or independent learning of user and item representations. These factors contribute to increased complexity and potential misalignment between user and item embeddings. To address these challenges, we propose DReX, a unified multimodal recommendation framework that incrementally refines user and item representations by leveraging interaction-level features from multimodal feedback. Our model employs gated recurrent units to selectively integrate these fine-grained features into global representations. This incremental update mechanism provides three key advantages: (1) simultaneous modeling of both nuanced interaction details and broader preference patterns, (2) eliminates the need for separate user and item feature extraction processes, leading to enhanced alignment in their learned representation, and (3) inherent robustness to varying or missing modalities. We evaluate the performance of the proposed approach on three real-world datasets containing reviews and ratings as interaction modalities. By considering review text as a modality, our approach automatically generates interpretable keyword profiles for both users and items, which supplement the recommendation process with interpretable preference indicators. Experiment results demonstrate that our approach outperforms state-of-the-art methods across all evaluated datasets.

</details>


### [80] [A Three-stage Neuro-symbolic Recommendation Pipeline for Cultural Heritage Knowledge Graphs](https://arxiv.org/abs/2602.19711)
*Krzysztof Kutt,Elżbieta Sroka,Oleksandra Ishchuk,Luiz do Valle Miranda*

Main category: cs.IR

TL;DR: 本文提出了一种融合知识图谱嵌入、近似最近邻搜索和SPARQL语义过滤的混合推荐管道，在文化遗产知识图谱上实现了有效且可解释的推荐。


<details>
  <summary>Details</summary>
Motivation: 数字文化遗产资源日益增长，需要能够理解异构数据实体间语义关系的先进推荐方法。

Method: 采用三阶段神经符号推荐器：1) 评估四种知识图谱嵌入模型（TransE、ComplEx、ConvE、CompGCN）；2) 进行超参数选择；3) 集成近似最近邻搜索和SPARQL驱动的语义过滤。

Result: 该方法在包含约320万RDF三元组的JUHMP知识图谱上评估，尽管元数据稀疏且异构，仍能产生有用且可解释的推荐结果，并通过了专家评估验证。

Conclusion: 提出的混合推荐管道能够有效处理文化遗产领域的语义推荐问题，结合神经和符号方法的优势，实现了实用且可解释的推荐系统。

Abstract: The growing volume of digital cultural heritage resources highlights the need for advanced recommendation methods capable of interpreting semantic relationships between heterogeneous data entities. This paper presents a complete methodology for implementing a hybrid recommendation pipeline integrating knowledge-graph embeddings, approximate nearest-neighbour search, and SPARQL-driven semantic filtering. The work is evaluated on the JUHMP (Jagiellonian University Heritage Metadata Portal) knowledge graph developed within the CHExRISH project, which at the time of experimentation contained ${\approx}3.2$M RDF triples describing people, events, objects, and historical relations affiliated with the Jagiellonian University (Kraków, PL). We evaluate four embedding families (TransE, ComplEx, ConvE, CompGCN) and perform hyperparameter selection for ComplEx and HNSW. Then, we present and evaluate the final three-stage neuro-symbolic recommender. Despite sparse and heterogeneous metadata, the approach produces useful and explainable recommendations, which were also proven with expert evaluation.

</details>


### [81] [GrIT: Group Informed Transformer for Sequential Recommendation](https://arxiv.org/abs/2602.19728)
*Adamya Shyam,Venkateswara Rao Kagita,Bharti Rana,Vikas Kumar*

Main category: cs.IR

TL;DR: 提出了一种结合个体时序行为和群体动态特征的序列推荐系统，通过学习用户随时间变化的群体归属权重来增强推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐方法主要基于Transformer架构处理用户交互历史，但忽视了相似用户集体行为中的群体级特征。作者认为同时建模个体历史和时间演化的群体特征能显著提升下一项推荐效果。

Method: 引入潜在群体表示，通过可学习的时变成员权重建模用户与群体的关系。权重计算结合短期和长期用户偏好，提取用户行为动态的统计特征并经过变换得到漂移感知的成员权重。群体表示通过加权潜在群体嵌入获得，并与用户序列表示在Transformer块中集成。

Result: 在五个基准数据集上的实验表明，该方法持续优于现有的最先进序列推荐方法。

Conclusion: 通过显式建模时间演化的群体特征与个体历史，能够联合捕捉个人和群体级的时间动态，产生更丰富的嵌入表示，从而实现更准确、上下文感知的推荐。

Abstract: Sequential recommender systems aim to predict a user's future interests by extracting temporal patterns from their behavioral history. Existing approaches typically employ transformer-based architectures to process long sequences of user interactions, capturing preference shifts by modeling temporal relationships between items. However, these methods often overlook the influence of group-level features that capture the collective behavior of similar users. We hypothesize that explicitly modeling temporally evolving group features alongside individual user histories can significantly enhance next-item recommendation. Our approach introduces latent group representations, where each user's affiliation to these groups is modeled through learnable, time-varying membership weights. The membership weights at each timestep are computed by modeling shifts in user preferences through their interaction history, where we incorporate both short-term and long-term user preferences. We extract a set of statistical features that capture the dynamics of user behavior and further refine them through a series of transformations to produce the final drift-aware membership weights. A group-based representation is derived by weighting latent group embeddings with the learned membership scores. This representation is integrated with the user's sequential representation within the transformer block to jointly capture personal and group-level temporal dynamics, producing richer embeddings that lead to more accurate, context-aware recommendations. We validate the effectiveness of our approach through extensive experiments on five benchmark datasets, where it consistently outperforms state-of-the-art sequential recommendation methods.

</details>


### [82] [FairFS: Addressing Deep Feature Selection Biases for Recommender System](https://arxiv.org/abs/2602.20001)
*Xianquan Wang,Zhaocheng Du,Jieming Zhu,Qinglin Jia,Zhenhua Dong,Kai Zhang*

Main category: cs.IR

TL;DR: FairFS是一种公平准确的特征选择算法，通过解决层偏差、基线偏差和近似偏差来改进深度学习中的特征重要性估计。


<details>
  <summary>Details</summary>
Motivation: 在工业推荐系统中，准确的特征重要性估计对识别最有用的特征子集至关重要，可以提升在线性能并降低计算成本。然而现有方法存在三种偏差问题：层偏差、基线偏差和近似偏差，导致重要性估计不准确。

Method: 提出FairFS算法：1）正则化所有非线性变换层的特征重要性来解决层偏差；2）引入接近分类器决策边界的平滑基线特征来缓解基线偏差；3）采用聚合近似方法来减轻近似偏差。

Result: 大量实验表明，FairFS能有效缓解这三种偏差，并在特征选择任务上达到了最先进的性能。

Conclusion: FairFS通过解决深度学习中特征重要性估计的偏差问题，提供了一种公平准确的特征选择方法，对工业推荐系统的优化具有重要意义。

Abstract: Large-scale online marketplaces and recommender systems serve as critical technological support for e-commerce development. In industrial recommender systems, features play vital roles as they carry information for downstream models. Accurate feature importance estimation is critical because it helps identify the most useful feature subsets from thousands of feature candidates for online services. Such selection enables improved online performance while reducing computational cost. To address feature selection problems in deep learning, trainable gate-based and sensitivity-based methods have been proposed and proven effective in industrial practice. However, through the analysis of real-world cases, we identified three bias issues that cause feature importance estimation to rely on partial model layers, samples, or gradients, ultimately leading to inaccurate importance estimation. We refer to these as layer bias, baseline bias, and approximation bias. To mitigate these issues, we propose FairFS, a fair and accurate feature selection algorithm. FairFS regularizes feature importance estimated across all nonlinear transformation layers to address layer bias. It also introduces a smooth baseline feature close to the classifier decision boundary and adopts an aggregated approximation method to alleviate baseline and approximation biases. Extensive experiments demonstrate that FairFS effectively mitigates these biases and achieves state-of-the-art feature selection performance.

</details>


### [83] [ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation](https://arxiv.org/abs/2602.20093)
*Kun Yang,Yuxuan Zhu,Yazhe Chen,Siyao Zheng,Bangyang Hong,Kangle Wu,Yabo Ni,Anxiang Zeng,Cong Fu,Hui Li*

Main category: cs.IR

TL;DR: 提出ManCAR框架，通过将推理过程约束在协同交互流形上，防止序列推荐中的潜在漂移问题，实现自适应推理


<details>
  <summary>Details</summary>
Motivation: 现有序列推荐方法使用目标主导的中间推理，但缺乏对推理轨迹的可行性约束，导致潜在漂移问题，推理轨迹偏离合理区域。需要将推荐推理视为在协同流形上的导航，而非自由形式的潜在精炼

Method: 提出ManCAR框架：1) 从用户近期行为的协同邻域构建局部意图先验；2) 训练时逐步对齐潜在预测分布与该先验，强制推理轨迹保持在有效流形内；3) 测试时自适应推理直至预测分布稳定；4) 提供变分解释验证漂移预防和自适应停止机制

Result: 在7个基准测试中，ManCAR始终优于最先进的基线方法，NDCG@10相对改进高达46.88%

Conclusion: 通过将推理过程约束在协同流形上，ManCAR有效防止潜在漂移，实现更稳定和有效的序列推荐推理，理论分析和实验结果均验证了其有效性

Abstract: Sequential recommendation increasingly employs latent multi-step reasoning to enhance test-time computation. Despite empirical gains, existing approaches largely drive intermediate reasoning states via target-dominant objectives without imposing explicit feasibility constraints. This results in latent drift, where reasoning trajectories deviate into implausible regions. We argue that effective recommendation reasoning should instead be viewed as navigation on a collaborative manifold rather than free-form latent refinement. To this end, we propose ManCAR (Manifold-Constrained Adaptive Reasoning), a principled framework that grounds reasoning within the topology of a global interaction graph. ManCAR constructs a local intent prior from the collaborative neighborhood of a user's recent actions, represented as a distribution over the item simplex. During training, the model progressively aligns its latent predictive distribution with this prior, forcing the reasoning trajectory to remain within the valid manifold. At test time, reasoning proceeds adaptively until the predictive distribution stabilizes, avoiding over-refinement. We provide a variational interpretation of ManCAR to theoretically validate its drift-prevention and adaptive test-time stopping mechanisms. Experiments on seven benchmarks demonstrate that ManCAR consistently outperforms state-of-the-art baselines, achieving up to a 46.88% relative improvement w.r.t. NDCG@10. Our code is available at https://github.com/FuCongResearchSquad/ManCAR.

</details>
