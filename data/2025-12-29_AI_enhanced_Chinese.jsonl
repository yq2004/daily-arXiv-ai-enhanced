{"id": "2512.21422", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21422", "abs": "https://arxiv.org/abs/2512.21422", "authors": ["Nathan Stringham", "Fateme Hashemi Chaleshtori", "Xinyuan Yan", "Zhichao Xu", "Bei Wang", "Ana Marasovi\u0107"], "title": "Teaching People LLM's Errors and Getting it Right", "comment": null, "summary": "People use large language models (LLMs) when they should not. This is partly because they see LLMs compose poems and answer intricate questions, so they understandably, but incorrectly, assume LLMs won't stumble on basic tasks like simple arithmetic. Prior work has tried to address this by clustering instance embeddings into regions where an LLM is likely to fail and automatically describing patterns in these regions. The found failure patterns are taught to users to mitigate their overreliance. Yet, this approach has not fully succeeded. In this analysis paper, we aim to understand why.\n  We first examine whether the negative result stems from the absence of failure patterns. We group instances in two datasets by their meta-labels and evaluate an LLM's predictions on these groups. We then define criteria to flag groups that are sizable and where the LLM is error-prone, and find meta-label groups that meet these criteria. Their meta-labels are the LLM's failure patterns that could be taught to users, so they do exist. We next test whether prompting and embedding-based approaches can surface these known failures. Without this, users cannot be taught about them to reduce their overreliance. We find mixed results across methods, which could explain the negative result. Finally, we revisit the final metric that measures teaching effectiveness. We propose to assess a user's ability to effectively use the given failure patterns to anticipate when an LLM is error-prone. A user study shows a positive effect from teaching with this metric, unlike the human-AI team accuracy. Our findings show that teaching failure patterns could be a viable approach to mitigating overreliance, but success depends on better automated failure-discovery methods and using metrics like ours.", "AI": {"tldr": "\u8be5\u5206\u6790\u8bba\u6587\u63a2\u8ba8\u4e86\u4e3a\u4ec0\u4e48\u6559\u7528\u6237\u8bc6\u522bLLM\u5931\u8d25\u6a21\u5f0f\u7684\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u51cf\u8f7b\u8fc7\u5ea6\u4f9d\u8d56\u3002\u7814\u7a76\u53d1\u73b0\u5931\u8d25\u6a21\u5f0f\u786e\u5b9e\u5b58\u5728\uff0c\u4f46\u73b0\u6709\u81ea\u52a8\u53d1\u73b0\u65b9\u6cd5\u6548\u679c\u4e0d\u4e00\uff0c\u4e14\u8bc4\u4f30\u6307\u6807\u9700\u8981\u6539\u8fdb\u3002", "motivation": "\u7528\u6237\u7ecf\u5e38\u5728\u4e0d\u8be5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u65f6\u8fc7\u5ea6\u4f9d\u8d56\u5b83\u4eec\uff0c\u90e8\u5206\u539f\u56e0\u662f\u770b\u5230LLM\u80fd\u4f5c\u8bd7\u548c\u56de\u7b54\u590d\u6742\u95ee\u9898\uff0c\u5c31\u9519\u8bef\u5730\u8ba4\u4e3a\u5b83\u4eec\u4e0d\u4f1a\u5728\u57fa\u7840\u4efb\u52a1\u4e0a\u51fa\u9519\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u5c1d\u8bd5\u901a\u8fc7\u805a\u7c7b\u5b9e\u4f8b\u5d4c\u5165\u6765\u8bc6\u522bLLM\u53ef\u80fd\u5931\u8d25\u7684\u533a\u57df\u5e76\u6559\u7528\u6237\u8fd9\u4e9b\u5931\u8d25\u6a21\u5f0f\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5e76\u672a\u5b8c\u5168\u6210\u529f\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u5931\u8d25\u539f\u56e0\u3002", "method": "1. \u901a\u8fc7\u5143\u6807\u7b7e\u5206\u7ec4\u5206\u6790\u9a8c\u8bc1\u5931\u8d25\u6a21\u5f0f\u662f\u5426\u5b58\u5728\uff1b2. \u8bc4\u4f30\u63d0\u793a\u548c\u5d4c\u5165\u65b9\u6cd5\u662f\u5426\u80fd\u6709\u6548\u53d1\u73b0\u5df2\u77e5\u5931\u8d25\u6a21\u5f0f\uff1b3. \u91cd\u65b0\u8bbe\u8ba1\u8bc4\u4f30\u6307\u6807\uff0c\u63d0\u51fa\u8861\u91cf\u7528\u6237\u80fd\u5426\u6709\u6548\u5229\u7528\u5931\u8d25\u6a21\u5f0f\u9884\u6d4bLLM\u9519\u8bef\u503e\u5411\u7684\u80fd\u529b\uff1b4. \u8fdb\u884c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u65b0\u6307\u6807\u7684\u6709\u6548\u6027\u3002", "result": "1. \u786e\u8ba4\u5b58\u5728\u8db3\u591f\u89c4\u6a21\u4e14LLM\u6613\u51fa\u9519\u7684\u5143\u6807\u7b7e\u7ec4\uff0c\u5373\u5931\u8d25\u6a21\u5f0f\u786e\u5b9e\u5b58\u5728\uff1b2. \u73b0\u6709\u81ea\u52a8\u53d1\u73b0\u65b9\u6cd5\u6548\u679c\u53c2\u5dee\u4e0d\u9f50\uff0c\u8fd9\u53ef\u80fd\u89e3\u91ca\u4e86\u5148\u524d\u7814\u7a76\u7684\u8d1f\u9762\u7ed3\u679c\uff1b3. \u4f7f\u7528\u65b0\u7684\u8bc4\u4f30\u6307\u6807\uff08\u7528\u6237\u5229\u7528\u5931\u8d25\u6a21\u5f0f\u9884\u6d4b\u9519\u8bef\u7684\u80fd\u529b\uff09\u663e\u793a\u6559\u5b66\u6709\u79ef\u6781\u6548\u679c\uff0c\u800c\u4f20\u7edf\u7684\u4eba\u673a\u56e2\u961f\u51c6\u786e\u7387\u6307\u6807\u5219\u672a\u663e\u793a\u6548\u679c\u3002", "conclusion": "\u6559\u7528\u6237\u8bc6\u522b\u5931\u8d25\u6a21\u5f0f\u53ef\u80fd\u662f\u51cf\u8f7b\u8fc7\u5ea6\u4f9d\u8d56\u7684\u53ef\u884c\u65b9\u6cd5\uff0c\u4f46\u6210\u529f\u53d6\u51b3\u4e8e\u66f4\u597d\u7684\u81ea\u52a8\u5931\u8d25\u53d1\u73b0\u65b9\u6cd5\u548c\u4f7f\u7528\u66f4\u5408\u9002\u7684\u8bc4\u4f30\u6307\u6807\uff08\u5982\u672c\u6587\u63d0\u51fa\u7684\u6307\u6807\uff09\u3002"}}
{"id": "2512.21439", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21439", "abs": "https://arxiv.org/abs/2512.21439", "authors": ["Geoffroy Morlat", "Marceau Nahon", "Augustin Chartouny", "Raja Chatila", "Ismael T. Freire", "Mehdi Khamassi"], "title": "Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models", "comment": "11 pages, 5 figures, +24 pages of Appendix", "summary": "Moral actions are judged not only by their outcomes but by the context in which they occur. We present COMETH (Contextual Organization of Moral Evaluation from Textual Human inputs), a framework that integrates a probabilistic context learner with LLM-based semantic abstraction and human moral evaluations to model how context shapes the acceptability of ambiguous actions. We curate an empirically grounded dataset of 300 scenarios across six core actions (violating Do not kill, Do not deceive, and Do not break the law) and collect ternary judgments (Blame/Neutral/Support) from N=101 participants. A preprocessing pipeline standardizes actions via an LLM filter and MiniLM embeddings with K-means, producing robust, reproducible core-action clusters. COMETH then learns action-specific moral contexts by clustering scenarios online from human judgment distributions using principled divergence criteria. To generalize and explain predictions, a Generalization module extracts concise, non-evaluative binary contextual features and learns feature weights in a transparent likelihood-based model. Empirically, COMETH roughly doubles alignment with majority human judgments relative to end-to-end LLM prompting (approx. 60% vs. approx. 30% on average), while revealing which contextual features drive its predictions. The contributions are: (i) an empirically grounded moral-context dataset, (ii) a reproducible pipeline combining human judgments with model-based context learning and LLM semantics, and (iii) an interpretable alternative to end-to-end LLMs for context-sensitive moral prediction and explanation.", "AI": {"tldr": "COMETH\u662f\u4e00\u4e2a\u7ed3\u5408\u6982\u7387\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001LLM\u8bed\u4e49\u62bd\u8c61\u548c\u4eba\u7c7b\u9053\u5fb7\u8bc4\u4f30\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u4e0a\u4e0b\u6587\u5982\u4f55\u5f71\u54cd\u6a21\u7cca\u884c\u4e3a\u7684\u53ef\u63a5\u53d7\u6027\uff0c\u76f8\u6bd4\u7aef\u5230\u7aefLLM\u63d0\u793a\u5c06\u4eba\u7c7b\u5224\u65ad\u5bf9\u9f50\u5ea6\u63d0\u9ad8\u7ea6\u4e00\u500d\u3002", "motivation": "\u9053\u5fb7\u5224\u65ad\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u884c\u4e3a\u7ed3\u679c\uff0c\u8fd8\u53d7\u4e0a\u4e0b\u6587\u60c5\u5883\u5f71\u54cd\u3002\u73b0\u6709\u7aef\u5230\u7aefLLM\u5728\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u9053\u5fb7\u9884\u6d4b\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u5efa\u7acb\u7ed3\u5408\u4eba\u7c7b\u8bc4\u4f30\u548c\u6a21\u578b\u5b66\u4e60\u7684\u6846\u67b6\u6765\u7406\u89e3\u4e0a\u4e0b\u6587\u5982\u4f55\u5851\u9020\u9053\u5fb7\u5224\u65ad\u3002", "method": "1. \u521b\u5efa\u5305\u542b300\u4e2a\u573a\u666f\u7684\u5b9e\u8bc1\u6570\u636e\u96c6\uff0c\u6db5\u76d66\u4e2a\u6838\u5fc3\u884c\u52a8\uff1b2. \u6536\u96c6101\u540d\u53c2\u4e0e\u8005\u7684\u4e09\u5143\u5224\u65ad\uff1b3. \u4f7f\u7528LLM\u8fc7\u6ee4\u5668\u548cMiniLM\u5d4c\u5165\u914d\u5408K-means\u8fdb\u884c\u9884\u5904\u7406\uff0c\u751f\u6210\u6838\u5fc3\u884c\u52a8\u805a\u7c7b\uff1b4. COMETH\u901a\u8fc7\u57fa\u4e8e\u5206\u6b67\u51c6\u5219\u7684\u5728\u7ebf\u805a\u7c7b\u4ece\u4eba\u7c7b\u5224\u65ad\u5206\u5e03\u4e2d\u5b66\u4e60\u884c\u52a8\u7279\u5b9a\u9053\u5fb7\u4e0a\u4e0b\u6587\uff1b5. \u6cdb\u5316\u6a21\u5757\u63d0\u53d6\u7b80\u6d01\u7684\u975e\u8bc4\u4f30\u6027\u4e8c\u5143\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u5728\u57fa\u4e8e\u4f3c\u7136\u7684\u900f\u660e\u6a21\u578b\u4e2d\u5b66\u4e60\u7279\u5f81\u6743\u91cd\u3002", "result": "COMETH\u4e0e\u591a\u6570\u4eba\u7c7b\u5224\u65ad\u7684\u5bf9\u9f50\u5ea6\u7ea6\u4e3a60%\uff0c\u76f8\u6bd4\u7aef\u5230\u7aefLLM\u63d0\u793a\u7684\u7ea630%\u63d0\u9ad8\u4e86\u4e00\u500d\u3002\u6846\u67b6\u80fd\u63ed\u793a\u9a71\u52a8\u9884\u6d4b\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u9053\u5fb7\u9884\u6d4b\u3002", "conclusion": "COMETH\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u5408\u4eba\u7c7b\u5224\u65ad\u3001\u6a21\u578b\u5b66\u4e60\u548cLLM\u8bed\u4e49\u7684\u53ef\u91cd\u590d\u7ba1\u9053\uff0c\u4f5c\u4e3a\u7aef\u5230\u7aefLLM\u7684\u53ef\u89e3\u91ca\u66ff\u4ee3\u65b9\u6848\uff0c\u7528\u4e8e\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u9053\u5fb7\u9884\u6d4b\u548c\u89e3\u91ca\u3002\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u5982\u4f55\u7cfb\u7edf\u6027\u5730\u5efa\u6a21\u9053\u5fb7\u4e0a\u4e0b\u6587\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u540c\u65f6\u4fdd\u6301\u900f\u660e\u5ea6\u3002"}}
{"id": "2512.21494", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21494", "abs": "https://arxiv.org/abs/2512.21494", "authors": ["Soichiro Murakami", "Hidetaka Kamigaito", "Hiroya Takamura", "Manabu Okumura"], "title": "Oogiri-Master: Benchmarking Humor Understanding via Oogiri", "comment": null, "summary": "Humor is a salient testbed for human-like creative thinking in large language models (LLMs). We study humor using the Japanese creative response game Oogiri, in which participants produce witty responses to a given prompt, and ask the following research question: What makes such responses funny to humans? Previous work has offered only limited reliable means to answer this question. Existing datasets contain few candidate responses per prompt, expose popularity signals during ratings, and lack objective and comparable metrics for funniness. Thus, we introduce Oogiri-Master and Oogiri-Corpus, which are a benchmark and dataset designed to enable rigorous evaluation of humor understanding in LLMs. Each prompt is paired with approximately 100 diverse candidate responses, and funniness is rated independently by approximately 100 human judges without access to others' ratings, reducing popularity bias and enabling robust aggregation. Using Oogiri-Corpus, we conduct a quantitative analysis of the linguistic factors associated with funniness, such as text length, ambiguity, and incongruity resolution, and derive objective metrics for predicting human judgments. Subsequently, we benchmark a range of LLMs and human baselines in Oogiri-Master, demonstrating that state-of-the-art models approach human performance and that insight-augmented prompting improves the model performance. Our results provide a principled basis for evaluating and advancing humor understanding in LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u65e5\u672c\u521b\u610f\u56de\u5e94\u6e38\u620fOogiri\u7814\u7a76LLM\u7684\u5e7d\u9ed8\u7406\u89e3\u80fd\u529b\uff0c\u521b\u5efa\u4e86Oogiri-Master\u57fa\u51c6\u6d4b\u8bd5\u548cOogiri-Corpus\u6570\u636e\u96c6\uff0c\u5206\u6790\u4e86\u5f71\u54cd\u5e7d\u9ed8\u611f\u7684\u8bed\u8a00\u56e0\u7d20\uff0c\u5e76\u5c55\u793a\u4e86\u5148\u8fdbLLM\u5728\u5e7d\u9ed8\u7406\u89e3\u65b9\u9762\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684\u8868\u73b0\u3002", "motivation": "\u5e7d\u9ed8\u662f\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7c7b\u4eba\u521b\u9020\u6027\u601d\u7ef4\u7684\u91cd\u8981\u6d4b\u8bd5\u573a\u3002\u73b0\u6709\u7814\u7a76\u5728\u5e7d\u9ed8\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff1a\u6570\u636e\u96c6\u5305\u542b\u7684\u5019\u9009\u56de\u5e94\u6570\u91cf\u5c11\u3001\u8bc4\u5206\u65f6\u66b4\u9732\u6d41\u884c\u5ea6\u4fe1\u53f7\u3001\u7f3a\u4e4f\u5ba2\u89c2\u53ef\u6bd4\u8f83\u7684\u5e7d\u9ed8\u5ea6\u6307\u6807\u3002\u56e0\u6b64\u9700\u8981\u66f4\u4e25\u8c28\u7684\u65b9\u6cd5\u6765\u7814\u7a76\"\u4ec0\u4e48\u56e0\u7d20\u8ba9\u56de\u5e94\u5728\u4eba\u7c7b\u770b\u6765\u6709\u8da3\"\u8fd9\u4e00\u6838\u5fc3\u95ee\u9898\u3002", "method": "1. \u521b\u5efaOogiri-Corpus\u6570\u636e\u96c6\uff1a\u6bcf\u4e2a\u63d0\u793a\u914d\u7ea6100\u4e2a\u591a\u6837\u5316\u5019\u9009\u56de\u5e94\uff0c\u7531\u7ea6100\u540d\u4eba\u7c7b\u8bc4\u59d4\u72ec\u7acb\u8bc4\u5206\uff0c\u51cf\u5c11\u6d41\u884c\u5ea6\u504f\u89c1\uff0c\u5b9e\u73b0\u7a33\u5065\u805a\u5408\u3002\n2. \u5b9a\u91cf\u5206\u6790\u5e7d\u9ed8\u76f8\u5173\u7684\u8bed\u8a00\u56e0\u7d20\uff1a\u5982\u6587\u672c\u957f\u5ea6\u3001\u6b67\u4e49\u6027\u3001\u4e0d\u534f\u8c03\u89e3\u51b3\u7b49\uff0c\u5e76\u63a8\u5bfc\u9884\u6d4b\u4eba\u7c7b\u5224\u65ad\u7684\u5ba2\u89c2\u6307\u6807\u3002\n3. \u5f00\u53d1Oogiri-Master\u57fa\u51c6\u6d4b\u8bd5\uff1a\u8bc4\u4f30\u5404\u79cdLLM\u548c\u4eba\u7c7b\u57fa\u7ebf\u8868\u73b0\uff0c\u6d4b\u8bd5\u57fa\u4e8e\u6d1e\u5bdf\u7684\u63d0\u793a\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "1. \u6700\u5148\u8fdb\u7684LLM\u5728\u5e7d\u9ed8\u7406\u89e3\u4efb\u52a1\u4e0a\u63a5\u8fd1\u4eba\u7c7b\u8868\u73b0\u6c34\u5e73\u3002\n2. \u57fa\u4e8e\u6d1e\u5bdf\u7684\u63d0\u793a\u589e\u5f3a\uff08insight-augmented prompting\uff09\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002\n3. \u786e\u5b9a\u4e86\u4e0e\u5e7d\u9ed8\u611f\u76f8\u5173\u7684\u5ba2\u89c2\u8bed\u8a00\u7279\u5f81\u548c\u9884\u6d4b\u6307\u6807\u3002\n4. \u5efa\u7acb\u4e86\u8bc4\u4f30LLM\u5e7d\u9ed8\u7406\u89e3\u7684\u7cfb\u7edf\u5316\u3001\u53ef\u91cd\u590d\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8bc4\u4f30\u548c\u63a8\u8fdbLLM\u7684\u5e7d\u9ed8\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5e7d\u9ed8\u8fd9\u4e00\u590d\u6742\u8ba4\u77e5\u80fd\u529b\u7684\u91cf\u5316\u5206\u6790\uff0c\u5c55\u793a\u4e86LLM\u5728\u521b\u9020\u6027\u601d\u7ef4\u4efb\u52a1\u4e0a\u7684\u8fdb\u6b65\u6f5c\u529b\u3002"}}
{"id": "2512.21567", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21567", "abs": "https://arxiv.org/abs/2512.21567", "authors": ["Changzhi Sun", "Xiangyu Chen", "Jixiang Luo", "Dell Zhang", "Xuelong Li"], "title": "Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management", "comment": null, "summary": "External memory is a key component of modern large language model (LLM) systems, enabling long-term interaction and personalization. Despite its importance, memory management is still largely driven by hand-designed heuristics, offering little insight into the long-term and uncertain consequences of memory decisions. In practice, choices about what to read or write shape future retrieval and downstream behavior in ways that are difficult to anticipate. We argue that memory management should be viewed as a sequential decision-making problem under uncertainty, where the utility of memory is delayed and dependent on future interactions. To this end, we propose DAM (Decision-theoretic Agent Memory), a decision-theoretic framework that decomposes memory management into immediate information access and hierarchical storage maintenance. Within this architecture, candidate operations are evaluated via value functions and uncertainty estimators, enabling an aggregate policy to arbitrate decisions based on estimated long-term utility and risk. Our contribution is not a new algorithm, but a principled reframing that clarifies the limitations of heuristic approaches and provides a foundation for future research on uncertainty-aware memory systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDAM\uff08\u51b3\u7b56\u7406\u8bba\u667a\u80fd\u4f53\u8bb0\u5fc6\uff09\u6846\u67b6\uff0c\u5c06\u8bb0\u5fc6\u7ba1\u7406\u91cd\u6784\u4e3a\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u800c\u975e\u4f9d\u8d56\u624b\u5de5\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u7684\u5916\u90e8\u8bb0\u5fc6\u7ba1\u7406\u4e3b\u8981\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u96be\u4ee5\u9884\u6d4b\u8bb0\u5fc6\u51b3\u7b56\u7684\u957f\u671f\u548c\u4e0d\u786e\u5b9a\u540e\u679c\u3002\u8bb0\u5fc6\u7684\u8bfb\u5199\u9009\u62e9\u4f1a\u4ee5\u96be\u4ee5\u9884\u89c1\u7684\u65b9\u5f0f\u5f71\u54cd\u672a\u6765\u7684\u68c0\u7d22\u548c\u4e0b\u6e38\u884c\u4e3a\u3002", "method": "\u63d0\u51faDAM\u6846\u67b6\uff0c\u5c06\u8bb0\u5fc6\u7ba1\u7406\u5206\u89e3\u4e3a\u5373\u65f6\u4fe1\u606f\u8bbf\u95ee\u548c\u5206\u5c42\u5b58\u50a8\u7ef4\u62a4\u3002\u901a\u8fc7\u4ef7\u503c\u51fd\u6570\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u5668\u8bc4\u4f30\u5019\u9009\u64cd\u4f5c\uff0c\u805a\u5408\u7b56\u7565\u57fa\u4e8e\u4f30\u8ba1\u7684\u957f\u671f\u6548\u7528\u548c\u98ce\u9669\u8fdb\u884c\u51b3\u7b56\u4ef2\u88c1\u3002", "result": "DAM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u91cd\u6784\u6846\u67b6\uff0c\u9610\u660e\u4e86\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bb0\u5fc6\u7cfb\u7edf\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u8be5\u6846\u67b6\u672c\u8eab\u4e0d\u662f\u65b0\u7b97\u6cd5\uff0c\u800c\u662f\u6982\u5ff5\u6027\u8d21\u732e\u3002", "conclusion": "\u8bb0\u5fc6\u7ba1\u7406\u5e94\u88ab\u89c6\u4e3a\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0cDAM\u6846\u67b6\u4e3a\u6b64\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u667a\u80fd\u3001\u53ef\u9884\u6d4b\u7684\u8bb0\u5fc6\u7cfb\u7edf\u3002"}}
{"id": "2512.21526", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21526", "abs": "https://arxiv.org/abs/2512.21526", "authors": ["Shanglin Yang", "Zhan Shi"], "title": "Selective LLM-Guided Regularization for Enhancing Recommendation Models", "comment": null, "summary": "Large language models provide rich semantic priors and strong reasoning capabilities, making them promising auxiliary signals for recommendation. However, prevailing approaches either deploy LLMs as standalone recommender or apply global knowledge distillation, both of which suffer from inherent drawbacks. Standalone LLM recommender are costly, biased, and unreliable across large regions of the user item space, while global distillation forces the downstream model to imitate LLM predictions even when such guidance is inaccurate. Meanwhile, recent studies show that LLMs excel particularly in re-ranking and challenging scenarios, rather than uniformly across all contexts.We introduce Selective LLM Guided Regularization, a model-agnostic and computation efficient framework that activates LLM based pairwise ranking supervision only when a trainable gating mechanism informing by user history length, item popularity, and model uncertainty predicts the LLM to be reliable. All LLM scoring is performed offline, transferring knowledge without increasing inference cost. Experiments across multiple datasets show that this selective strategy consistently improves overall accuracy and yields substantial gains in cold start and long tail regimes, outperforming global distillation baselines.", "AI": {"tldr": "\u63d0\u51fa\u9009\u62e9\u6027LLM\u5f15\u5bfc\u6b63\u5219\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u8bad\u7ec3\u95e8\u63a7\u673a\u5236\u4ec5\u5728LLM\u9884\u6d4b\u53ef\u9760\u65f6\u6fc0\u6d3b\u57fa\u4e8eLLM\u7684\u6210\u5bf9\u6392\u5e8f\u76d1\u7763\uff0c\u5b9e\u73b0\u9ad8\u6548\u77e5\u8bc6\u8fc1\u79fb\uff0c\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u7279\u522b\u662f\u5728\u51b7\u542f\u52a8\u548c\u957f\u5c3e\u573a\u666f\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u8350\u65b9\u6cd5\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff1a\u72ec\u7acbLLM\u63a8\u8350\u5668\u6210\u672c\u9ad8\u3001\u6709\u504f\u89c1\u4e14\u5728\u7528\u6237-\u7269\u54c1\u7a7a\u95f4\u7684\u5927\u90e8\u5206\u533a\u57df\u4e0d\u53ef\u9760\uff1b\u5168\u5c40\u77e5\u8bc6\u84b8\u998f\u5f3a\u8feb\u4e0b\u6e38\u6a21\u578b\u6a21\u4effLLM\u9884\u6d4b\uff0c\u5373\u4f7f\u8fd9\u79cd\u6307\u5bfc\u4e0d\u51c6\u786e\u3002\u540c\u65f6\u7814\u7a76\u53d1\u73b0LLM\u5728\u91cd\u6392\u5e8f\u548c\u6311\u6218\u6027\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u975e\u5728\u6240\u6709\u60c5\u5883\u4e0b\u90fd\u6709\u6548\u3002", "method": "\u63d0\u51fa\u9009\u62e9\u6027LLM\u5f15\u5bfc\u6b63\u5219\u5316\u6846\u67b6\uff1a1\uff09\u57fa\u4e8e\u7528\u6237\u5386\u53f2\u957f\u5ea6\u3001\u7269\u54c1\u6d41\u884c\u5ea6\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u53ef\u8bad\u7ec3\u95e8\u63a7\u673a\u5236\u9884\u6d4bLLM\u53ef\u9760\u6027\uff1b2\uff09\u4ec5\u5728LLM\u53ef\u9760\u65f6\u6fc0\u6d3b\u57fa\u4e8eLLM\u7684\u6210\u5bf9\u6392\u5e8f\u76d1\u7763\uff1b3\uff09\u6240\u6709LLM\u8bc4\u5206\u79bb\u7ebf\u8fdb\u884c\uff0c\u77e5\u8bc6\u8fc1\u79fb\u4e0d\u589e\u52a0\u63a8\u7406\u6210\u672c\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u9009\u62e9\u6027\u7b56\u7565\u6301\u7eed\u63d0\u5347\u6574\u4f53\u51c6\u786e\u6027\uff0c\u5728\u51b7\u542f\u52a8\u548c\u957f\u5c3e\u573a\u666f\u4e2d\u83b7\u5f97\u663e\u8457\u589e\u76ca\uff0c\u4f18\u4e8e\u5168\u5c40\u84b8\u998f\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u9009\u62e9\u6027\u6fc0\u6d3bLLM\u76d1\u7763\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5229\u7528LLM\u7684\u4f18\u52bf\uff08\u7279\u522b\u662f\u5728\u6311\u6218\u6027\u573a\u666f\uff09\uff0c\u540c\u65f6\u907f\u514d\u5176\u4e0d\u53ef\u9760\u9884\u6d4b\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u9ad8\u6548\u4e14\u6a21\u578b\u65e0\u5173\u7684LLM\u77e5\u8bc6\u8fc1\u79fb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2512.21577", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.21577", "abs": "https://arxiv.org/abs/2512.21577", "authors": ["Emmy Liu", "Varun Gangal", "Chelsea Zou", "Xiaoqi Huang", "Michael Yu", "Alex Chang", "Zhuofu Tao", "Sachin Kumar", "Steven Y. Feng"], "title": "A Unified Definition of Hallucination, Or: It's the World Model, Stupid", "comment": null, "summary": "Despite numerous attempts to solve the issue of hallucination since the inception of neural language models, it remains a problem in even frontier large language models today. Why is this the case? We walk through definitions of hallucination used in the literature from a historical perspective up to the current day, and fold them into a single definition of hallucination, wherein different prior definitions focus on different aspects of our definition. At its core, we argue that hallucination is simply inaccurate (internal) world modeling, in a form where it is observable to the user (e.g., stating a fact which contradicts a knowledge base, or producing a summary which contradicts a known source). By varying the reference world model as well as the knowledge conflict policy (e.g., knowledge base vs. in-context), we arrive at the different existing definitions of hallucination present in the literature.\n  We argue that this unified view is useful because it forces evaluations to make clear their assumed \"world\" or source of truth, clarifies what should and should not be called hallucination (as opposed to planning or reward/incentive-related errors), and provides a common language to compare benchmarks and mitigation techniques. Building on this definition, we outline plans for a family of benchmarks in which hallucinations are defined as mismatches with synthetic but fully specified world models in different environments, and sketch out how these benchmarks can use such settings to stress-test and improve the world modeling components of language models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5e7b\u89c9\u7684\u7edf\u4e00\u5b9a\u4e49\uff0c\u8ba4\u4e3a\u5e7b\u89c9\u672c\u8d28\u4e0a\u662f\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u4e16\u754c\u5efa\u6a21\u7684\u4e0d\u51c6\u786e\u6027\uff0c\u8fd9\u79cd\u4e0d\u51c6\u786e\u6027\u5bf9\u7528\u6237\u53ef\u89c1\uff08\u5982\u4e0e\u77e5\u8bc6\u5e93\u77db\u76fe\u7684\u4e8b\u5b9e\uff09\u3002\u8bba\u6587\u901a\u8fc7\u7edf\u4e00\u89c6\u89d2\u6f84\u6e05\u4e86\u5e7b\u89c9\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5408\u6210\u4e16\u754c\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u3002", "motivation": "\u5c3d\u7ba1\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u51fa\u73b0\u4ee5\u6765\u5df2\u6709\u591a\u6b21\u5c1d\u8bd5\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\uff0c\u4f46\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ecd\u5b58\u5728\u5e7b\u89c9\u3002\u73b0\u6709\u6587\u732e\u5bf9\u5e7b\u89c9\u7684\u5b9a\u4e49\u5404\u4e0d\u76f8\u540c\u4e14\u6df7\u4e71\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u6e05\u6670\u754c\u5b9a\u4ec0\u4e48\u662f\u5e7b\u89c9\u3001\u4ec0\u4e48\u4e0d\u662f\uff0c\u8fd9\u963b\u788d\u4e86\u6709\u6548\u7684\u8bc4\u4f30\u548c\u7f13\u89e3\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u8bba\u6587\u4ece\u5386\u53f2\u89d2\u5ea6\u68b3\u7406\u4e86\u6587\u732e\u4e2d\u5404\u79cd\u5e7b\u89c9\u5b9a\u4e49\uff0c\u5c06\u5176\u6574\u5408\u4e3a\u4e00\u4e2a\u7edf\u4e00\u5b9a\u4e49\uff1a\u5e7b\u89c9\u662f\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u4e16\u754c\u5efa\u6a21\u7684\u4e0d\u51c6\u786e\u6027\uff0c\u8fd9\u79cd\u4e0d\u51c6\u786e\u6027\u5bf9\u7528\u6237\u53ef\u89c1\u3002\u901a\u8fc7\u53d8\u5316\u53c2\u8003\u4e16\u754c\u6a21\u578b\uff08\u5982\u77e5\u8bc6\u5e93\u3001\u4e0a\u4e0b\u6587\uff09\u548c\u77e5\u8bc6\u51b2\u7a81\u7b56\u7565\uff0c\u53ef\u4ee5\u89e3\u91ca\u73b0\u6709\u5404\u79cd\u5b9a\u4e49\u3002\u57fa\u4e8e\u8fd9\u4e00\u5b9a\u4e49\uff0c\u8bba\u6587\u89c4\u5212\u4e86\u4e00\u5957\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u4f7f\u7528\u5408\u6210\u4f46\u5b8c\u5168\u6307\u5b9a\u7684\u4e16\u754c\u6a21\u578b\u6765\u5b9a\u4e49\u548c\u8bc4\u4f30\u5e7b\u89c9\u3002", "result": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u5e7b\u89c9\u5b9a\u4e49\u6846\u67b6\uff0c\u5c06\u4e0d\u540c\u6587\u732e\u4e2d\u7684\u5b9a\u4e49\u89c6\u4e3a\u8be5\u6846\u67b6\u7684\u7279\u4f8b\u3002\u8be5\u6846\u67b6\u8981\u6c42\u8bc4\u4f30\u660e\u786e\u5176\u5047\u8bbe\u7684\"\u4e16\u754c\"\u6216\u771f\u76f8\u6765\u6e90\uff0c\u6f84\u6e05\u4e86\u5e7b\u89c9\u4e0e\u89c4\u5212\u9519\u8bef\u6216\u5956\u52b1\u76f8\u5173\u9519\u8bef\u7684\u533a\u522b\uff0c\u4e3a\u6bd4\u8f83\u57fa\u51c6\u548c\u7f13\u89e3\u6280\u672f\u63d0\u4f9b\u4e86\u5171\u540c\u8bed\u8a00\u3002", "conclusion": "\u7edf\u4e00\u7684\u5e7b\u89c9\u5b9a\u4e49\u6709\u52a9\u4e8e\u6f84\u6e05\u6982\u5ff5\u6df7\u6dc6\uff0c\u4fc3\u8fdb\u66f4\u6709\u6548\u7684\u8bc4\u4f30\u548c\u7f13\u89e3\u6280\u672f\u53d1\u5c55\u3002\u57fa\u4e8e\u5408\u6210\u4e16\u754c\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u53ef\u4ee5\u538b\u529b\u6d4b\u8bd5\u548c\u6539\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u7cfb\u7edf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2512.21543", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.21543", "abs": "https://arxiv.org/abs/2512.21543", "authors": ["Yuzhen Lin", "Hongyi Chen", "Xuanjing Chen", "Shaowen Wang", "Ivonne Xu", "Dongming Jiang"], "title": "CEMG: Collaborative-Enhanced Multimodal Generative Recommendation", "comment": null, "summary": "Generative recommendation models often struggle with two key challenges: (1) the superficial integration of collaborative signals, and (2) the decoupled fusion of multimodal features. These limitations hinder the creation of a truly holistic item representation. To overcome this, we propose CEMG, a novel Collaborative-Enhaned Multimodal Generative Recommendation framework. Our approach features a Multimodal Fusion Layer that dynamically integrates visual and textual features under the guidance of collaborative signals. Subsequently, a Unified Modality Tokenization stage employs a Residual Quantization VAE (RQ-VAE) to convert this fused representation into discrete semantic codes. Finally, in the End-to-End Generative Recommendation stage, a large language model is fine-tuned to autoregressively generate these item codes. Extensive experiments demonstrate that CEMG significantly outperforms state-of-the-art baselines.", "AI": {"tldr": "CEMG\u662f\u4e00\u4e2a\u901a\u8fc7\u534f\u4f5c\u4fe1\u53f7\u589e\u5f3a\u7684\u591a\u6a21\u6001\u878d\u5408\u751f\u6210\u63a8\u8350\u6846\u67b6\uff0c\u91c7\u7528RQ-VAE\u79bb\u6563\u5316\u8bed\u4e49\u7f16\u7801\uff0c\u4f7f\u7528LLM\u8fdb\u884c\u7aef\u5230\u7aef\u751f\u6210\u63a8\u8350\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u63a8\u8350\u6a21\u578b\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a1) \u534f\u4f5c\u4fe1\u53f7\u7684\u6d45\u5c42\u96c6\u6210\uff1b2) \u591a\u6a21\u6001\u7279\u5f81\u7684\u89e3\u8026\u878d\u5408\u3002\u8fd9\u4e9b\u95ee\u9898\u963b\u788d\u4e86\u771f\u6b63\u5168\u9762\u7684\u7269\u54c1\u8868\u793a\u3002", "method": "\u63d0\u51faCEMG\u6846\u67b6\uff1a1) \u591a\u6a21\u6001\u878d\u5408\u5c42\u5728\u534f\u4f5c\u4fe1\u53f7\u6307\u5bfc\u4e0b\u52a8\u6001\u6574\u5408\u89c6\u89c9\u548c\u6587\u672c\u7279\u5f81\uff1b2) \u7edf\u4e00\u6a21\u6001\u6807\u8bb0\u5316\u9636\u6bb5\u4f7f\u7528\u6b8b\u5dee\u91cf\u5316VAE\u5c06\u878d\u5408\u8868\u793a\u8f6c\u6362\u4e3a\u79bb\u6563\u8bed\u4e49\u4ee3\u7801\uff1b3) \u7aef\u5230\u7aef\u751f\u6210\u63a8\u8350\u9636\u6bb5\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u56de\u5f52\u751f\u6210\u8fd9\u4e9b\u7269\u54c1\u4ee3\u7801\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cCEMG\u5728\u63a8\u8350\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CEMG\u901a\u8fc7\u534f\u4f5c\u4fe1\u53f7\u589e\u5f3a\u7684\u591a\u6a21\u6001\u878d\u5408\u548c\u79bb\u6563\u8bed\u4e49\u7f16\u7801\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u751f\u6210\u63a8\u8350\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u66f4\u5168\u9762\u548c\u6709\u6548\u7684\u7269\u54c1\u8868\u793a\u3002"}}
{"id": "2512.21580", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21580", "abs": "https://arxiv.org/abs/2512.21580", "authors": ["Alexander Podolskiy", "Semen Molokov", "Timofey Gerasin", "Maksim Titov", "Alexey Rukhovich", "Artem Khrapov", "Kirill Morozov", "Evgeny Tetin", "Constantine Korikov", "Pavel Efimov", "Polina Lazukova", "Yuliya Skripkar", "Nikita Okhotnikov", "Irina Piontkovskaya", "Meng Xiaojun", "Zou Xueyi", "Zhang Zhenhe"], "title": "Gamayun's Path to Multilingual Mastery: Cost-Efficient Training of a 1.5B-Parameter LLM", "comment": null, "summary": "We present Gamayun, a 1.5B-parameter multilingual language model trained entirely from scratch on 2.5T tokens. Designed for efficiency and deployment in resource-constrained environments, Gamayun addresses the lack of research on small non-English-centric LLMs by adopting a novel two-stage pre-training strategy: balanced multilingual training for cross-lingual alignment, followed by high-quality English enrichment to transfer performance gains across languages. Our model supports 12 languages, with special focus on Russian. Despite a significantly smaller training budget than comparable models, Gamayun outperforms LLaMA3.2-1B (9T tokens) on all considered benchmarks, and surpasses Qwen2.5-1.5B (18T tokens) on a wide range of English and multilingual tasks. It matches or exceeds Qwen3 (36T tokens) on most tasks outside advanced STEM, achieving state-of-the-art results in Russian, including the MERA benchmark, among the models of comparable size (1-2B parameters).", "AI": {"tldr": "Gamayun\u662f\u4e00\u4e2a15\u4ebf\u53c2\u6570\u7684\u591a\u8bed\u8a00\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u9884\u8bad\u7ec3\u7b56\u7565\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\uff0c\u5728\u8f83\u5c0f\u8bad\u7ec3\u9884\u7b97\u4e0b\u8d85\u8d8a\u4e86LLaMA3.2-1B\u548cQwen2.5-1.5B\u7b49\u6a21\u578b\uff0c\u5728\u4fc4\u8bed\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u3002", "motivation": "\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7f3a\u4e4f\u5c0f\u578b\u975e\u82f1\u8bed\u4e2d\u5fc3\u5316LLM\u7814\u7a76\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u9ad8\u6548\u90e8\u7f72\u7684\u591a\u8bed\u8a00\u6a21\u578b\uff0c\u7279\u522b\u5173\u6ce8\u4fc4\u8bed\u652f\u6301\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u9884\u8bad\u7ec3\u7b56\u7565\uff1a1) \u5e73\u8861\u591a\u8bed\u8a00\u8bad\u7ec3\u5b9e\u73b0\u8de8\u8bed\u8a00\u5bf9\u9f50\uff1b2) \u9ad8\u8d28\u91cf\u82f1\u8bed\u6570\u636e\u589e\u5f3a\u4ee5\u5c06\u6027\u80fd\u589e\u76ca\u4f20\u9012\u5230\u5176\u4ed6\u8bed\u8a00\u3002\u6a21\u578b\u652f\u630112\u79cd\u8bed\u8a00\uff0c\u8bad\u7ec3\u6570\u636e\u91cf\u4e3a2.5T token\u3002", "result": "\u5728\u663e\u8457\u8f83\u5c0f\u7684\u8bad\u7ec3\u9884\u7b97\u4e0b\uff0cGamayun\u5728\u82f1\u8bed\u548c\u591a\u8bed\u8a00\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86LLaMA3.2-1B\uff089T token\uff09\u548cQwen2.5-1.5B\uff0818T token\uff09\uff0c\u5728\u4fc4\u8bed\u4efb\u52a1\u4e0a\u8fbe\u5230\u540c\u7c7b\u5c3a\u5bf8\u6a21\u578b\uff081-2B\u53c2\u6570\uff09\u7684SOTA\u6c34\u5e73\uff0c\u5305\u62ecMERA\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "Gamayun\u8bc1\u660e\u4e86\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5373\u4f7f\u4f7f\u7528\u76f8\u5bf9\u8f83\u5c0f\u7684\u8bad\u7ec3\u9884\u7b97\uff0c\u4e5f\u80fd\u6784\u5efa\u51fa\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u9ad8\u6548\u90e8\u7f72\u7684\u7ade\u4e89\u6027\u591a\u8bed\u8a00LLM\uff0c\u7279\u522b\u5728\u4fc4\u8bed\u652f\u6301\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2512.21595", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21595", "abs": "https://arxiv.org/abs/2512.21595", "authors": ["Yinfu Feng", "Yanjing Wu", "Rong Xiao", "Xiaoyi Zen"], "title": "LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model", "comment": null, "summary": "Item-to-Item (I2I) recommendation models are widely used in real-world systems due to their scalability, real-time capabilities, and high recommendation quality. Research to enhance I2I performance focuses on two directions: 1) model-centric approaches, which adopt deeper architectures but risk increased computational costs and deployment complexity, and 2) data-centric methods, which refine training data without altering models, offering cost-effectiveness but struggling with data sparsity and noise. To address these challenges, we propose LLM-I2I, a data-centric framework leveraging Large Language Models (LLMs) to mitigate data quality issues. LLM-I2I includes (1) an LLM-based generator that synthesizes user-item interactions for long-tail items, alleviating data sparsity, and (2) an LLM-based discriminator that filters noisy interactions from real and synthetic data. The refined data is then fused to train I2I models. Evaluated on industry (AEDS) and academic (ARD) datasets, LLM-I2I consistently improves recommendation accuracy, particularly for long-tail items. Deployed on a large-scale cross-border e-commerce platform, it boosts recall number (RN) by 6.02% and gross merchandise value (GMV) by 1.22% over existing I2I models. This work highlights the potential of LLMs in enhancing data-centric recommendation systems without modifying model architectures.", "AI": {"tldr": "LLM-I2I\uff1a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u51b3I2I\u63a8\u8350\u7cfb\u7edf\u4e2d\u6570\u636e\u7a00\u758f\u6027\u548c\u566a\u58f0\u95ee\u9898\u7684\u6570\u636e\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u957f\u5c3e\u5546\u54c1\u4e0a\u3002", "motivation": "\u5f53\u524dI2I\u63a8\u8350\u7cfb\u7edf\u7684\u6539\u8fdb\u5b58\u5728\u4e24\u4e2a\u65b9\u5411\uff1a\u6a21\u578b\u4e2d\u5fc3\u5316\u65b9\u6cd5\uff08\u589e\u52a0\u67b6\u6784\u590d\u6742\u5ea6\u4f46\u63d0\u5347\u8ba1\u7b97\u6210\u672c\u548c\u90e8\u7f72\u96be\u5ea6\uff09\u548c\u6570\u636e\u96c6\u4e2d\u5fc3\u5316\u65b9\u6cd5\uff08\u6210\u672c\u4f4e\u4f46\u53d7\u9650\u4e8e\u6570\u636e\u7a00\u758f\u6027\u548c\u566a\u58f0\u95ee\u9898\uff09\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u5347\u6027\u80fd\u53c8\u4fdd\u6301\u90e8\u7f72\u7b80\u4fbf\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faLLM-I2I\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u57fa\u4e8eLLM\u7684\u751f\u6210\u5668\uff0c\u4e3a\u957f\u5c3e\u5546\u54c1\u5408\u6210\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u6570\u636e\u4ee5\u7f13\u89e3\u6570\u636e\u7a00\u758f\u6027\uff1b2\uff09\u57fa\u4e8eLLM\u7684\u5224\u522b\u5668\uff0c\u4ece\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u4e2d\u8fc7\u6ee4\u566a\u58f0\u4ea4\u4e92\u3002\u7cbe\u70bc\u540e\u7684\u6570\u636e\u7528\u4e8e\u8bad\u7ec3\u73b0\u6709I2I\u6a21\u578b\u3002", "result": "\u5728\u884c\u4e1a\uff08AEDS\uff09\u548c\u5b66\u672f\uff08ARD\uff09\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cLLM-I2I\u6301\u7eed\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\uff0c\u7279\u522b\u5bf9\u957f\u5c3e\u5546\u54c1\u6548\u679c\u663e\u8457\u3002\u5728\u5927\u578b\u8de8\u5883\u7535\u5546\u5e73\u53f0\u90e8\u7f72\u540e\uff0c\u53ec\u56de\u6570\u63d0\u53476.02%\uff0c\u5546\u54c1\u4ea4\u6613\u603b\u989d\u63d0\u53471.22%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86LLMs\u5728\u4e0d\u4fee\u6539\u6a21\u578b\u67b6\u6784\u7684\u60c5\u51b5\u4e0b\u589e\u5f3a\u6570\u636e\u4e2d\u5fc3\u5316\u63a8\u8350\u7cfb\u7edf\u7684\u6f5c\u529b\uff0c\u4e3aI2I\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u6539\u8fdb\u65b9\u6848\u3002"}}
{"id": "2512.21625", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21625", "abs": "https://arxiv.org/abs/2512.21625", "authors": ["Xinyu Tang", "Yuliang Zhan", "Zhixun Li", "Wayne Xin Zhao", "Zhenduo Zhang", "Zujie Wen", "Zhiqiang Zhang", "Jun Zhou"], "title": "Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards", "comment": null, "summary": "Large reasoning models (LRMs) are typically trained using reinforcement learning with verifiable reward (RLVR) to enhance their reasoning abilities. In this paradigm, policies are updated using both positive and negative self-generated rollouts, which correspond to distinct sample polarities. In this paper, we provide a systematic investigation into how these sample polarities affect RLVR training dynamics and behaviors. We find that positive samples sharpen existing correct reasoning patterns, while negative samples encourage exploration of new reasoning paths. We further explore how adjusting the advantage values of positive and negative samples at both the sample level and the token level affects RLVR training. Based on these insights, we propose an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, namely A3PO, that more precisely allocates advantage signals to key tokens across different polarities. Experiments across five reasoning benchmarks demonstrate the effectiveness of our approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faA3PO\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u975e\u5bf9\u79f0\u7684token\u7ea7\u4f18\u52bf\u4fe1\u53f7\u5206\u914d\uff0c\u4f18\u5316\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u5e38\u4f7f\u7528\u5e26\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u7cfb\u7edf\u7814\u7a76\u6b63\u8d1f\u6837\u672c\u6781\u6027\u5bf9\u8bad\u7ec3\u52a8\u6001\u548c\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u4f18\u52bf\u4fe1\u53f7\u5206\u914d\u673a\u5236\u3002", "method": "\u63d0\u51faA3PO\u65b9\u6cd5\uff1a\u901a\u8fc7\u81ea\u9002\u5e94\u975e\u5bf9\u79f0\u7684token\u7ea7\u4f18\u52bf\u5851\u9020\u8fdb\u884c\u7b56\u7565\u4f18\u5316\uff0c\u66f4\u7cbe\u786e\u5730\u4e3a\u4e0d\u540c\u6781\u6027\u7684\u5173\u952etoken\u5206\u914d\u4f18\u52bf\u4fe1\u53f7\u3002", "result": "\u5728\u4e94\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "A3PO\u65b9\u6cd5\u901a\u8fc7\u7cbe\u7ec6\u5316\u7684\u4f18\u52bf\u4fe1\u53f7\u5206\u914d\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528\u6b63\u8d1f\u6837\u672c\u7684\u4e0d\u540c\u4f5c\u7528\uff0c\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u3002"}}
{"id": "2512.21799", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.21799", "abs": "https://arxiv.org/abs/2512.21799", "authors": ["Hung-Nghiep Tran", "Atsuhiro Takasu"], "title": "KG20C & KG20C-QA: Scholarly Knowledge Graph Benchmarks for Link Prediction and Question Answering", "comment": "Extracted and extended from the first author's PhD thesis titled \"Multi-Relational Embedding for Knowledge Graph Representation and Analysis\"", "summary": "In this paper, we present KG20C and KG20C-QA, two curated datasets for advancing question answering (QA) research on scholarly data. KG20C is a high-quality scholarly knowledge graph constructed from the Microsoft Academic Graph through targeted selection of venues, quality-based filtering, and schema definition. Although KG20C has been available online in non-peer-reviewed sources such as GitHub repository, this paper provides the first formal, peer-reviewed description of the dataset, including clear documentation of its construction and specifications. KG20C-QA is built upon KG20C to support QA tasks on scholarly data. We define a set of QA templates that convert graph triples into natural language question--answer pairs, producing a benchmark that can be used both with graph-based models such as knowledge graph embeddings and with text-based models such as large language models. We benchmark standard knowledge graph embedding methods on KG20C-QA, analyze performance across relation types, and provide reproducible evaluation protocols. By officially releasing these datasets with thorough documentation, we aim to contribute a reusable, extensible resource for the research community, enabling future work in QA, reasoning, and knowledge-driven applications in the scholarly domain. The full datasets will be released at https://github.com/tranhungnghiep/KG20C/ upon paper publication.", "AI": {"tldr": "KG20C\u548cKG20C-QA\u662f\u4e24\u4e2a\u7528\u4e8e\u5b66\u672f\u6570\u636e\u95ee\u7b54\u7814\u7a76\u7684\u7cbe\u9009\u6570\u636e\u96c6\uff0c\u5305\u62ec\u9ad8\u8d28\u91cf\u5b66\u672f\u77e5\u8bc6\u56fe\u8c31\u548c\u5bf9\u5e94\u7684\u95ee\u7b54\u57fa\u51c6", "motivation": "\u9700\u8981\u4e3a\u5b66\u672f\u9886\u57df\u7684\u95ee\u7b54\u7814\u7a76\u63d0\u4f9b\u9ad8\u8d28\u91cf\u3001\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u6570\u636e\u96c6\u8d44\u6e90\uff0c\u652f\u6301\u77e5\u8bc6\u56fe\u8c31\u548c\u6587\u672c\u6a21\u578b\u7684\u7814\u7a76", "method": "\u4eceMicrosoft Academic Graph\u4e2d\u901a\u8fc7\u573a\u5730\u9009\u62e9\u3001\u8d28\u91cf\u8fc7\u6ee4\u548c\u6a21\u5f0f\u5b9a\u4e49\u6784\u5efaKG20C\u77e5\u8bc6\u56fe\u8c31\uff0c\u7136\u540e\u57fa\u4e8e\u6b64\u5b9a\u4e49\u95ee\u7b54\u6a21\u677f\u751f\u6210KG20C-QA\u6570\u636e\u96c6", "result": "\u521b\u5efa\u4e86\u6b63\u5f0f\u6587\u6863\u5316\u7684KG20C\u548cKG20C-QA\u6570\u636e\u96c6\uff0c\u5bf9\u6807\u51c6\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u65b9\u6cd5\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u4f9b\u4e86\u53ef\u91cd\u590d\u7684\u8bc4\u4f30\u534f\u8bae", "conclusion": "\u8fd9\u4e9b\u6570\u636e\u96c6\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u3001\u53ef\u6269\u5c55\u7684\u8d44\u6e90\uff0c\u5c06\u4fc3\u8fdb\u5b66\u672f\u9886\u57df\u7684\u95ee\u7b54\u3001\u63a8\u7406\u548c\u77e5\u8bc6\u9a71\u52a8\u5e94\u7528\u7814\u7a76"}}
{"id": "2512.21635", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21635", "abs": "https://arxiv.org/abs/2512.21635", "authors": ["Chengxu Yang", "Jingling Yuan", "Siqi Cai", "Jiawei Jiang", "Chuang Hu"], "title": "Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations", "comment": "Published as a conference paper at KDD 2026", "summary": "Hallucinations in large language models (LLMs) are commonly regarded as errors to be minimized. However, recent perspectives suggest that some hallucinations may encode creative or epistemically valuable content, a dimension that remains underquantified in current literature. Existing hallucination detection methods primarily focus on factual consistency, struggling to handle heterogeneous scientific tasks and balance creativity with accuracy. To address these challenges, we propose HIC-Bench, a novel evaluation framework that categorizes hallucinations into Intelligent Hallucinations (IH) and Defective Hallucinations (DH), enabling systematic investigation of their interplay in LLM creativity. HIC-Bench features three core characteristics: (1) Structured IH/DH Assessment. using a multi-dimensional metric matrix integrating Torrance Tests of Creative Thinking (TTCT) metrics (Originality, Feasibility, Value) with hallucination-specific dimensions (scientific plausibility, factual deviation); (2) Cross-Domain Applicability. spanning ten scientific domains with open-ended innovation tasks; and (3) Dynamic Prompt Optimization. leveraging the Dynamic Hallucination Prompt (DHP) to guide models toward creative and reliable outputs. The evaluation process employs multiple LLM judges, averaging scores to mitigate bias, with human annotators verifying IH/DH classifications. Experimental results reveal a nonlinear relationship between IH and DH, demonstrating that creativity and correctness can be jointly optimized. These insights position IH as a catalyst for creativity and reveal the ability of LLM hallucinations to drive scientific innovation.Additionally, the HIC-Bench offers a valuable platform for advancing research into the creative intelligence of LLM hallucinations.", "AI": {"tldr": "HIC-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u5e7b\u89c9\u7684\u521b\u65b0\u6846\u67b6\uff0c\u5c06\u5e7b\u89c9\u5206\u4e3a\u667a\u80fd\u5e7b\u89c9(IH)\u548c\u7f3a\u9677\u5e7b\u89c9(DH)\uff0c\u7cfb\u7edf\u7814\u7a76\u5b83\u4eec\u4e0e\u521b\u9020\u529b\u7684\u5173\u7cfb\uff0c\u6db5\u76d610\u4e2a\u79d1\u5b66\u9886\u57df\uff0c\u4f7f\u7528\u591a\u7ef4\u5ea6\u6307\u6807\u548c\u52a8\u6001\u63d0\u793a\u4f18\u5316\u3002", "motivation": "\u5f53\u524dLLM\u5e7b\u89c9\u901a\u5e38\u88ab\u89c6\u4e3a\u9700\u8981\u6700\u5c0f\u5316\u7684\u9519\u8bef\uff0c\u4f46\u90e8\u5206\u5e7b\u89c9\u53ef\u80fd\u5305\u542b\u521b\u9020\u6027\u6216\u6709\u8ba4\u77e5\u4ef7\u503c\u7684\u5185\u5bb9\uff0c\u8fd9\u4e00\u7ef4\u5ea6\u5728\u73b0\u6709\u6587\u732e\u4e2d\u7f3a\u4e4f\u91cf\u5316\u3002\u73b0\u6709\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u96be\u4ee5\u5904\u7406\u5f02\u8d28\u79d1\u5b66\u4efb\u52a1\u5e76\u5e73\u8861\u521b\u9020\u6027\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faHIC-Bench\u6846\u67b6\uff0c\u5c06\u5e7b\u89c9\u5206\u4e3a\u667a\u80fd\u5e7b\u89c9(IH)\u548c\u7f3a\u9677\u5e7b\u89c9(DH)\uff0c\u91c7\u7528\u591a\u7ef4\u5ea6\u6307\u6807\u77e9\u9635\u6574\u5408\u6258\u5170\u65af\u521b\u9020\u6027\u601d\u7ef4\u6d4b\u8bd5(TTCT)\u6307\u6807\uff08\u539f\u521b\u6027\u3001\u53ef\u884c\u6027\u3001\u4ef7\u503c\uff09\u548c\u5e7b\u89c9\u7279\u5b9a\u7ef4\u5ea6\uff08\u79d1\u5b66\u5408\u7406\u6027\u3001\u4e8b\u5b9e\u504f\u5dee\uff09\uff0c\u6db5\u76d610\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u5f00\u653e\u5f0f\u521b\u65b0\u4efb\u52a1\uff0c\u4f7f\u7528\u52a8\u6001\u5e7b\u89c9\u63d0\u793a(DHP)\u4f18\u5316\u6a21\u578b\u8f93\u51fa\uff0c\u901a\u8fc7\u591aLLM\u8bc4\u59d4\u5e73\u5747\u5206\u51cf\u5c11\u504f\u89c1\uff0c\u4eba\u5de5\u6807\u6ce8\u9a8c\u8bc1IH/DH\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aIH\u548cDH\u4e4b\u95f4\u5b58\u5728\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u8868\u660e\u521b\u9020\u6027\u548c\u6b63\u786e\u6027\u53ef\u4ee5\u5171\u540c\u4f18\u5316\u3002IH\u53ef\u4ee5\u4f5c\u4e3a\u521b\u9020\u529b\u7684\u50ac\u5316\u5242\uff0cLLM\u5e7b\u89c9\u80fd\u591f\u63a8\u52a8\u79d1\u5b66\u521b\u65b0\u3002", "conclusion": "HIC-Bench\u4e3aLLM\u5e7b\u89c9\u7684\u521b\u9020\u6027\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5e73\u53f0\uff0c\u63ed\u793a\u4e86\u5e7b\u89c9\u5728\u4fc3\u8fdb\u79d1\u5b66\u521b\u65b0\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u6311\u6218\u4e86\u5c06\u5e7b\u89c9\u5355\u7eaf\u89c6\u4e3a\u9519\u8bef\u7684\u4f20\u7edf\u89c2\u70b9\u3002"}}
{"id": "2512.21863", "categories": ["cs.IR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.21863", "abs": "https://arxiv.org/abs/2512.21863", "authors": ["Huatuan Sun", "Yunshan Ma", "Changguang Wu", "Yanxin Zhang", "Pengfei Wang", "Xiaoyu Du"], "title": "Frozen LVLMs for Micro-Video Recommendation: A Systematic Study of Feature Extraction and Fusion", "comment": "10 pages, 4 figures", "summary": "Frozen Large Video Language Models (LVLMs) are increasingly employed in micro-video recommendation due to their strong multimodal understanding. However, their integration lacks systematic empirical evaluation: practitioners typically deploy LVLMs as fixed black-box feature extractors without systematically comparing alternative representation strategies. To address this gap, we present the first systematic empirical study along two key design dimensions: (i) integration strategies with ID embeddings, specifically replacement versus fusion, and (ii) feature extraction paradigms, comparing LVLM-generated captions with intermediate decoder hidden states. Extensive experiments on representative LVLMs reveal three key principles: (1) intermediate hidden states consistently outperform caption-based representations, as natural-language summarization inevitably discards fine-grained visual semantics crucial for recommendation; (2) ID embeddings capture irreplaceable collaborative signals, rendering fusion strictly superior to replacement; and (3) the effectiveness of intermediate decoder features varies significantly across layers. Guided by these insights, we propose the Dual Feature Fusion (DFF) Framework, a lightweight and plug-and-play approach that adaptively fuses multi-layer representations from frozen LVLMs with item ID embeddings. DFF achieves state-of-the-art performance on two real-world micro-video recommendation benchmarks, consistently outperforming strong baselines and providing a principled approach to integrating off-the-shelf large vision-language models into micro-video recommender systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u5728\u5fae\u89c6\u9891\u63a8\u8350\u4e2d\u5982\u4f55\u6574\u5408\u51bb\u7ed3\u5927\u578b\u89c6\u9891\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u53cc\u91cd\u7279\u5f81\u878d\u5408\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5728\u5fae\u89c6\u9891\u63a8\u8350\u4e2d\uff0c\u51bb\u7ed3\u7684\u5927\u578b\u89c6\u9891\u8bed\u8a00\u6a21\u578b\u88ab\u7528\u4f5c\u56fa\u5b9a\u7684\u9ed1\u76d2\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u6574\u5408\u7b56\u7565\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002\u9700\u8981\u7814\u7a76\u5982\u4f55\u6700\u4f73\u5730\u5229\u7528\u8fd9\u4e9b\u6a21\u578b\u4e0eID\u5d4c\u5165\u8fdb\u884c\u7ed3\u5408\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u4e86\u4e24\u4e2a\u5173\u952e\u8bbe\u8ba1\u7ef4\u5ea6\uff1a1) \u4e0eID\u5d4c\u5165\u7684\u6574\u5408\u7b56\u7565\uff08\u66ff\u6362vs\u878d\u5408\uff09\uff1b2) \u7279\u5f81\u63d0\u53d6\u8303\u5f0f\uff08LVLM\u751f\u6210\u7684\u6807\u9898vs\u4e2d\u95f4\u89e3\u7801\u5668\u9690\u85cf\u72b6\u6001\uff09\u3002\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\u63d0\u51fa\u4e86\u53cc\u91cd\u7279\u5f81\u878d\u5408\u6846\u67b6\uff0c\u81ea\u9002\u5e94\u5730\u878d\u5408\u591a\u5c42\u8868\u793a\u4e0eID\u5d4c\u5165\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u539f\u5219\uff1a1) \u4e2d\u95f4\u9690\u85cf\u72b6\u6001\u4f18\u4e8e\u57fa\u4e8e\u6807\u9898\u7684\u8868\u793a\uff1b2) ID\u5d4c\u5165\u6355\u6349\u4e86\u4e0d\u53ef\u66ff\u4ee3\u7684\u534f\u540c\u4fe1\u53f7\uff0c\u878d\u5408\u7b56\u7565\u4f18\u4e8e\u66ff\u6362\uff1b3) \u4e2d\u95f4\u89e3\u7801\u5668\u7279\u5f81\u5728\u4e0d\u540c\u5c42\u95f4\u6548\u679c\u5dee\u5f02\u663e\u8457\u3002DFF\u6846\u67b6\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u5fae\u89c6\u9891\u63a8\u8350\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u5fae\u89c6\u9891\u63a8\u8350\u7cfb\u7edf\u4e2d\u6574\u5408\u73b0\u6210\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u8868\u660e\u4e2d\u95f4\u5c42\u7279\u5f81\u4e0eID\u5d4c\u5165\u7684\u878d\u5408\u7b56\u7565\u662f\u6700\u6709\u6548\u7684\u6574\u5408\u65b9\u5f0f\u3002"}}
{"id": "2512.21706", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21706", "abs": "https://arxiv.org/abs/2512.21706", "authors": ["Shuchang Pan", "Siddharth Banerjee", "Dhruv Hebbar", "Siddhant Patel", "Akshaj Gupta", "Kan Jen Cheng", "Hanjo Kim", "Zeyi Austin Li", "Martin Q. Ma", "Tingle Li", "Gopala Anumanchipalli", "Jiachen Lian"], "title": "Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech", "comment": null, "summary": "Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this causal pathway is key to building natural full-duplex interactive systems. We introduce a framework that enables reasoning over conversational behaviors by modeling this process as causal inference within a Graph-of-Thoughts (GoT). Our approach formalizes the intent-to-action pathway with a hierarchical labeling scheme, predicting high-level communicative intents and low-level speech acts to learn their causal and temporal dependencies. To train this system, we develop a hybrid corpus that pairs controllable, event-rich simulations with human-annotated rationales and real conversational speech. The GoT framework structures streaming predictions as an evolving graph, enabling a multimodal transformer to forecast the next speech act, generate concise justifications for its decisions, and dynamically refine its reasoning. Experiments on both synthetic and real duplex dialogues show that the framework delivers robust behavior detection, produces interpretable reasoning chains, and establishes a foundation for benchmarking conversational reasoning in full duplex spoken dialogue systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u601d\u7ef4\u56fe\uff08GoT\uff09\u7684\u56e0\u679c\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u5bf9\u8bdd\u4e2d\u7684\u610f\u56fe\u5230\u884c\u4e3a\u8def\u5f84\uff0c\u9884\u6d4b\u9ad8\u5c42\u6b21\u6c9f\u901a\u610f\u56fe\u548c\u4f4e\u5c42\u6b21\u8a00\u8bed\u884c\u4e3a\uff0c\u5e76\u751f\u6210\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u94fe\u3002", "motivation": "\u4eba\u7c7b\u5bf9\u8bdd\u7531\u9690\u542b\u7684\u601d\u7ef4\u94fe\u7ec4\u7ec7\uff0c\u8868\u73b0\u4e3a\u5b9a\u65f6\u7684\u8a00\u8bed\u884c\u4e3a\u3002\u6355\u6349\u8fd9\u79cd\u56e0\u679c\u8def\u5f84\u5bf9\u4e8e\u6784\u5efa\u81ea\u7136\u7684\u5168\u53cc\u5de5\u4ea4\u4e92\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u8fd9\u79cd\u56e0\u679c\u5173\u7cfb\u7684\u5efa\u6a21\u80fd\u529b\u3002", "method": "1. \u5c06\u5bf9\u8bdd\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u601d\u7ef4\u56fe\uff08GoT\uff09\u4e2d\u7684\u56e0\u679c\u63a8\u7406\n2. \u91c7\u7528\u5206\u5c42\u6807\u6ce8\u65b9\u6848\u5f62\u5f0f\u5316\u610f\u56fe\u5230\u884c\u4e3a\u8def\u5f84\n3. \u9884\u6d4b\u9ad8\u5c42\u6b21\u6c9f\u901a\u610f\u56fe\u548c\u4f4e\u5c42\u6b21\u8a00\u8bed\u884c\u4e3a\n4. \u5b66\u4e60\u8fd9\u4e9b\u884c\u4e3a\u7684\u56e0\u679c\u548c\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\n5. \u4f7f\u7528\u6df7\u5408\u8bed\u6599\u5e93\u8bad\u7ec3\uff1a\u53ef\u63a7\u7684\u4e8b\u4ef6\u4e30\u5bcc\u6a21\u62df + \u4eba\u5de5\u6807\u6ce8\u539f\u7406 + \u771f\u5b9e\u5bf9\u8bdd\u8bed\u97f3\n6. \u5c06\u6d41\u5f0f\u9884\u6d4b\u7ed3\u6784\u5316\u4e3a\u6f14\u5316\u56fe\n7. \u4f7f\u7528\u591a\u6a21\u6001Transformer\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8a00\u8bed\u884c\u4e3a\u3001\u751f\u6210\u51b3\u7b56\u7406\u7531\u5e76\u52a8\u6001\u4f18\u5316\u63a8\u7406", "result": "1. \u5728\u5408\u6210\u548c\u771f\u5b9e\u5168\u53cc\u5de5\u5bf9\u8bdd\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\n2. \u6846\u67b6\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u884c\u4e3a\u68c0\u6d4b\n3. \u4ea7\u751f\u4e86\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u94fe\n4. \u4e3a\u5168\u53cc\u5de5\u53e3\u8bed\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u7684\u5bf9\u8bdd\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u5960\u5b9a\u4e86\u57fa\u7840", "conclusion": "GoT\u6846\u67b6\u901a\u8fc7\u5efa\u6a21\u5bf9\u8bdd\u4e2d\u7684\u56e0\u679c\u63a8\u7406\u8def\u5f84\uff0c\u4e0d\u4ec5\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u8a00\u8bed\u884c\u4e3a\uff0c\u8fd8\u80fd\u751f\u6210\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u7406\u7531\uff0c\u4e3a\u6784\u5efa\u66f4\u81ea\u7136\u3001\u667a\u80fd\u7684\u5168\u53cc\u5de5\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2512.21708", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21708", "abs": "https://arxiv.org/abs/2512.21708", "authors": ["Jing Han", "Binwei Yan", "Tianyu Guo", "Zheyuan Bai", "Mengyu Zheng", "Hanting Chen", "Ying Nie"], "title": "MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles", "comment": "Accepted by ICML 2025", "summary": "Despite recent advancements of fine-tuning large language models (LLMs) to facilitate agent tasks, parameter-efficient fine-tuning (PEFT) methodologies for agent remain largely unexplored. In this paper, we introduce three key strategies for PEFT in agent tasks: 1) Inspired by the increasingly dominant Reason+Action paradigm, we first decompose the capabilities necessary for the agent tasks into three distinct roles: reasoner, executor, and summarizer. The reasoner is responsible for comprehending the user's query and determining the next role based on the execution trajectory. The executor is tasked with identifying the appropriate functions and parameters to invoke. The summarizer conveys the distilled information from conversations back to the user. 2) We then propose the Mixture-of-Roles (MoR) framework, which comprises three specialized Low-Rank Adaptation (LoRA) groups, each designated to fulfill a distinct role. By focusing on their respective specialized capabilities and engaging in collaborative interactions, these LoRAs collectively accomplish the agent task. 3) To effectively fine-tune the framework, we develop a multi-role data generation pipeline based on publicly available datasets, incorporating role-specific content completion and reliability verification. We conduct extensive experiments and thorough ablation studies on various LLMs and agent benchmarks, demonstrating the effectiveness of the proposed method. This project is publicly available at https://mor-agent.github.io.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Mixture-of-Roles (MoR)\u6846\u67b6\uff0c\u901a\u8fc7\u89d2\u8272\u5206\u89e3\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u6765\u4f18\u5316LLM\u4ee3\u7406\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5728\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4ee5\u4fc3\u8fdb\u4ee3\u7406\u4efb\u52a1\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u9488\u5bf9\u4ee3\u7406\u4efb\u52a1\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "1) \u5c06\u4ee3\u7406\u4efb\u52a1\u80fd\u529b\u5206\u89e3\u4e3a\u63a8\u7406\u8005\u3001\u6267\u884c\u8005\u548c\u603b\u7ed3\u8005\u4e09\u4e2a\u89d2\u8272\uff1b2) \u63d0\u51faMoR\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u4e13\u95e8\u7684LoRA\u7ec4\uff0c\u6bcf\u4e2a\u7ec4\u8d1f\u8d23\u4e00\u4e2a\u89d2\u8272\uff1b3) \u5f00\u53d1\u57fa\u4e8e\u516c\u5f00\u6570\u636e\u96c6\u7684\u591a\u89d2\u8272\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u5305\u542b\u89d2\u8272\u7279\u5b9a\u5185\u5bb9\u5b8c\u6210\u548c\u53ef\u9760\u6027\u9a8c\u8bc1\u3002", "result": "\u5728\u5404\u79cdLLM\u548c\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "MoR\u6846\u67b6\u901a\u8fc7\u89d2\u8272\u5206\u89e3\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u4ee3\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u4ee3\u7406\u4efb\u52a1\u7684PEFT\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.21709", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21709", "abs": "https://arxiv.org/abs/2512.21709", "authors": ["Md. Rakibul Islam", "Most. Sharmin Sultana Samu", "Md. Zahid Hossain", "Farhad Uz Zaman", "Md. Kamrozzaman Bhuiyan"], "title": "Detecting AI-Generated Paraphrases in Bengali: A Comparative Study of Zero-Shot and Fine-Tuned Transformers", "comment": "Accepted for publication in 2025 28th International Conference on Computer and Information Technology (ICCIT)", "summary": "Large language models (LLMs) can produce text that closely resembles human writing. This capability raises concerns about misuse, including disinformation and content manipulation. Detecting AI-generated text is essential to maintain authenticity and prevent malicious applications. Existing research has addressed detection in multiple languages, but the Bengali language remains largely unexplored. Bengali's rich vocabulary and complex structure make distinguishing human-written and AI-generated text particularly challenging. This study investigates five transformer-based models: XLMRoBERTa-Large, mDeBERTaV3-Base, BanglaBERT-Base, IndicBERT-Base and MultilingualBERT-Base. Zero-shot evaluation shows that all models perform near chance levels (around 50% accuracy) and highlight the need for task-specific fine-tuning. Fine-tuning significantly improves performance, with XLM-RoBERTa, mDeBERTa and MultilingualBERT achieving around 91% on both accuracy and F1-score. IndicBERT demonstrates comparatively weaker performance, indicating limited effectiveness in fine-tuning for this task. This work advances AI-generated text detection in Bengali and establishes a foundation for building robust systems to counter AI-generated content.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u4e2dAI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u7684\u7a7a\u767d\uff0c\u8bc4\u4f30\u4e86\u4e94\u79cdTransformer\u6a21\u578b\uff0c\u53d1\u73b0\u96f6\u6837\u672c\u6027\u80fd\u4e0d\u4f73\uff08\u7ea650%\u51c6\u786e\u7387\uff09\uff0c\u4f46\u7ecf\u8fc7\u5fae\u8c03\u540e\uff0cXLM-RoBERTa\u3001mDeBERTa\u548cMultilingualBERT\u80fd\u8fbe\u5230\u7ea691%\u7684\u51c6\u786e\u7387\u548cF1\u5206\u6570\uff0c\u4e3a\u5b5f\u52a0\u62c9\u8bedAI\u6587\u672c\u68c0\u6d4b\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "LLMs\u80fd\u751f\u6210\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684\u6587\u672c\uff0c\u5f15\u53d1\u4e86\u5173\u4e8e\u865a\u5047\u4fe1\u606f\u548c\u5185\u5bb9\u6ee5\u7528\u7684\u62c5\u5fe7\u3002\u68c0\u6d4bAI\u751f\u6210\u6587\u672c\u5bf9\u4e8e\u7ef4\u62a4\u5185\u5bb9\u771f\u5b9e\u6027\u548c\u9632\u6b62\u6076\u610f\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u6d89\u53ca\u591a\u8bed\u8a00\u68c0\u6d4b\uff0c\u4f46\u5b5f\u52a0\u62c9\u8bed\u9886\u57df\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u4e14\u5176\u4e30\u5bcc\u7684\u8bcd\u6c47\u548c\u590d\u6742\u7ed3\u6784\u4f7f\u5f97\u533a\u5206\u4eba\u7c7b\u5199\u4f5c\u548cAI\u751f\u6210\u6587\u672c\u5c24\u4e3a\u56f0\u96be\u3002", "method": "\u7814\u7a76\u8c03\u67e5\u4e86\u4e94\u79cd\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff1aXLMRoBERTa-Large\u3001mDeBERTaV3-Base\u3001BanglaBERT-Base\u3001IndicBERT-Base\u548cMultilingualBERT-Base\u3002\u9996\u5148\u8fdb\u884c\u96f6\u6837\u672c\u8bc4\u4f30\uff0c\u7136\u540e\u5bf9\u6a21\u578b\u8fdb\u884c\u4efb\u52a1\u7279\u5b9a\u7684\u5fae\u8c03\uff0c\u4ee5\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "result": "\u96f6\u6837\u672c\u8bc4\u4f30\u663e\u793a\u6240\u6709\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff08\u7ea650%\u51c6\u786e\u7387\uff09\uff0c\u8868\u660e\u9700\u8981\u4efb\u52a1\u7279\u5b9a\u7684\u5fae\u8c03\u3002\u5fae\u8c03\u540e\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0cXLM-RoBERTa\u3001mDeBERTa\u548cMultilingualBERT\u5728\u51c6\u786e\u7387\u548cF1\u5206\u6570\u4e0a\u5747\u8fbe\u5230\u7ea691%\u3002IndicBERT\u8868\u73b0\u76f8\u5bf9\u8f83\u5f31\uff0c\u8868\u660e\u5176\u5728\u8be5\u4efb\u52a1\u5fae\u8c03\u4e2d\u7684\u6709\u6548\u6027\u6709\u9650\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a8\u8fdb\u4e86\u5b5f\u52a0\u62c9\u8bed\u4e2dAI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u7684\u53d1\u5c55\uff0c\u4e3a\u6784\u5efa\u5f3a\u5927\u7684\u7cfb\u7edf\u6765\u5bf9\u6297AI\u751f\u6210\u5185\u5bb9\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u9488\u5bf9\u7279\u5b9a\u8bed\u8a00\u7279\u6027\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u5728\u5b5f\u52a0\u62c9\u8bed\u8fd9\u79cd\u5177\u6709\u4e30\u5bcc\u8bcd\u6c47\u548c\u590d\u6742\u7ed3\u6784\u7684\u8bed\u8a00\u4e2d\u3002"}}
{"id": "2512.21711", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21711", "abs": "https://arxiv.org/abs/2512.21711", "authors": ["Yuyi Zhang", "Boyu Tang", "Tianjie Ju", "Sufeng Duan", "Gongshen Liu"], "title": "Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought", "comment": "13 pages, 5 figures", "summary": "Latent tokens are gaining attention for enhancing reasoning in large language models (LLMs), yet their internal mechanisms remain unclear. This paper examines the problem from a reliability perspective, uncovering fundamental weaknesses: latent tokens function as uninterpretable placeholders rather than encoding faithful reasoning. While resistant to perturbation, they promote shortcut usage over genuine reasoning. We focus on Chain-of-Continuous-Thought (COCONUT), which claims better efficiency and stability than explicit Chain-of-Thought (CoT) while maintaining performance. We investigate this through two complementary approaches. First, steering experiments perturb specific token subsets, namely COCONUT and explicit CoT. Unlike CoT tokens, COCONUT tokens show minimal sensitivity to steering and lack reasoning-critical information. Second, shortcut experiments evaluate models under biased and out-of-distribution settings. Results on MMLU and HotpotQA demonstrate that COCONUT consistently exploits dataset artifacts, inflating benchmark performance without true reasoning. These findings reposition COCONUT as a pseudo-reasoning mechanism: it generates plausible traces that conceal shortcut dependence rather than faithfully representing reasoning processes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u53ef\u9760\u6027\u89c6\u89d2\u5206\u6790LLM\u4e2d\u7684\u6f5c\u5728token\u673a\u5236\uff0c\u63ed\u793aCOCONUT\u65b9\u6cd5\u5b9e\u9645\u4e0a\u662f\u4e00\u79cd\u4f2a\u63a8\u7406\u673a\u5236\uff0c\u5b83\u901a\u8fc7\u5229\u7528\u6570\u636e\u96c6\u4f2a\u5f71\u800c\u975e\u771f\u5b9e\u63a8\u7406\u6765\u63d0\u5347\u57fa\u51c6\u6027\u80fd\u3002", "motivation": "\u6f5c\u5728token\u5728\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65b9\u9762\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u4f5c\u8005\u5e0c\u671b\u4ece\u53ef\u9760\u6027\u89d2\u5ea6\u5206\u6790\u6f5c\u5728token\u673a\u5236\uff0c\u63ed\u793a\u5176\u4f5c\u4e3a\u4e0d\u53ef\u89e3\u91ca\u5360\u4f4d\u7b26\u800c\u975e\u5fe0\u5b9e\u7f16\u7801\u63a8\u7406\u7684\u6839\u672c\u5f31\u70b9\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\uff1a1) \u8f6c\u5411\u5b9e\u9a8c\uff0c\u6270\u52a8\u7279\u5b9atoken\u5b50\u96c6\uff08COCONUT\u548c\u663e\u5f0fCoT\uff09\uff0c\u6bd4\u8f83\u654f\u611f\u6027\uff1b2) \u6377\u5f84\u5b9e\u9a8c\uff0c\u5728\u504f\u89c1\u548c\u5206\u5e03\u5916\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u6a21\u578b\uff0c\u5206\u6790\u6570\u636e\u96c6\u4f2a\u5f71\u5229\u7528\u60c5\u51b5\u3002", "result": "\u5728MMLU\u548cHotpotQA\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a1) COCONUT token\u5bf9\u8f6c\u5411\u6270\u52a8\u4e0d\u654f\u611f\uff0c\u7f3a\u4e4f\u63a8\u7406\u5173\u952e\u4fe1\u606f\uff1b2) COCONUT\u6301\u7eed\u5229\u7528\u6570\u636e\u96c6\u4f2a\u5f71\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5938\u5927\u6027\u80fd\u800c\u4e0d\u8fdb\u884c\u771f\u5b9e\u63a8\u7406\u3002", "conclusion": "COCONUT\u662f\u4e00\u79cd\u4f2a\u63a8\u7406\u673a\u5236\uff0c\u5b83\u751f\u6210\u770b\u4f3c\u5408\u7406\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u4f46\u5b9e\u9645\u4e0a\u63a9\u76d6\u4e86\u5bf9\u6377\u5f84\u7684\u4f9d\u8d56\uff0c\u800c\u975e\u5fe0\u5b9e\u8868\u793a\u63a8\u7406\u8fc7\u7a0b\u3002\u8fd9\u66b4\u9732\u4e86\u6f5c\u5728token\u65b9\u6cd5\u5728\u53ef\u9760\u6027\u65b9\u9762\u7684\u6839\u672c\u7f3a\u9677\u3002"}}
{"id": "2512.21715", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21715", "abs": "https://arxiv.org/abs/2512.21715", "authors": ["Rui Ke", "Jiahui Xu", "Shenghao Yang", "Kuang Wang", "Feng Jiang", "Haizhou Li"], "title": "CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation", "comment": null, "summary": "Theme detection is a fundamental task in user-centric dialogue systems, aiming to identify the latent topic of each utterance without relying on predefined schemas. Unlike intent induction, which operates within fixed label spaces, theme detection requires cross-dialogue consistency and alignment with personalized user preferences, posing significant challenges. Existing methods often struggle with sparse, short utterances for accurate topic representation and fail to capture user-level thematic preferences across dialogues. To address these challenges, we propose CATCH (Controllable Theme Detection with Contextualized Clustering and Hierarchical Generation), a unified framework that integrates three core components: (1) context-aware topic representation, which enriches utterance-level semantics using surrounding topic segments; (2) preference-guided topic clustering, which jointly models semantic proximity and personalized feedback to align themes across dialogue; and (3) a hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels. Experiments on a multi-domain customer dialogue benchmark (DSTC-12) demonstrate the effectiveness of CATCH with 8B LLM in both theme clustering and topic generation quality.", "AI": {"tldr": "CATCH\u662f\u4e00\u4e2a\u7528\u4e8e\u7528\u6237\u4e2d\u5fc3\u5bf9\u8bdd\u7cfb\u7edf\u4e3b\u9898\u68c0\u6d4b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u4e3b\u9898\u8868\u793a\u3001\u504f\u597d\u5f15\u5bfc\u4e3b\u9898\u805a\u7c7b\u548c\u5206\u5c42\u4e3b\u9898\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u7a00\u758f\u77ed\u6587\u672c\u8868\u793a\u548c\u7528\u6237\u504f\u597d\u5efa\u6a21\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u4e3b\u9898\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7a00\u758f\u3001\u7b80\u77ed\u7684\u8bdd\u8bed\u4ee5\u83b7\u5f97\u51c6\u786e\u7684\u4e3b\u9898\u8868\u793a\uff0c\u5e76\u4e14\u65e0\u6cd5\u6355\u6349\u8de8\u5bf9\u8bdd\u7684\u7528\u6237\u5c42\u9762\u4e3b\u9898\u504f\u597d\u3002\u4e3b\u9898\u68c0\u6d4b\u9700\u8981\u5728\u8de8\u5bf9\u8bdd\u4e2d\u4fdd\u6301\u4e00\u81f4\u6027\u5e76\u4e0e\u4e2a\u6027\u5316\u7528\u6237\u504f\u597d\u5bf9\u9f50\uff0c\u8fd9\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "CATCH\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(1)\u4e0a\u4e0b\u6587\u611f\u77e5\u4e3b\u9898\u8868\u793a\uff0c\u5229\u7528\u5468\u56f4\u4e3b\u9898\u7247\u6bb5\u4e30\u5bcc\u8bdd\u8bed\u7ea7\u8bed\u4e49\uff1b(2)\u504f\u597d\u5f15\u5bfc\u4e3b\u9898\u805a\u7c7b\uff0c\u8054\u5408\u5efa\u6a21\u8bed\u4e49\u90bb\u8fd1\u6027\u548c\u4e2a\u6027\u5316\u53cd\u9988\u4ee5\u8de8\u5bf9\u8bdd\u5bf9\u9f50\u4e3b\u9898\uff1b(3)\u5206\u5c42\u4e3b\u9898\u751f\u6210\u673a\u5236\uff0c\u65e8\u5728\u6291\u5236\u566a\u58f0\u5e76\u751f\u6210\u9c81\u68d2\u3001\u8fde\u8d2f\u7684\u4e3b\u9898\u6807\u7b7e\u3002", "result": "\u5728\u591a\u9886\u57df\u5ba2\u6237\u5bf9\u8bdd\u57fa\u51c6\uff08DSTC-12\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCATCH\u5728\u4e3b\u9898\u805a\u7c7b\u548c\u4e3b\u9898\u751f\u6210\u8d28\u91cf\u65b9\u9762\u90fd\u5177\u6709\u6709\u6548\u6027\uff0c\u4f7f\u7528\u4e868B\u53c2\u6570\u7684LLM\u3002", "conclusion": "CATCH\u901a\u8fc7\u6574\u5408\u4e0a\u4e0b\u6587\u611f\u77e5\u8868\u793a\u3001\u4e2a\u6027\u5316\u805a\u7c7b\u548c\u5206\u5c42\u751f\u6210\uff0c\u4e3a\u65e0\u9884\u5b9a\u4e49\u6a21\u5f0f\u7684\u4e3b\u9898\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u7528\u6237\u4e2d\u5fc3\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u7684\u4e3b\u9898\u68c0\u6d4b\u6311\u6218\u3002"}}
{"id": "2512.21787", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21787", "abs": "https://arxiv.org/abs/2512.21787", "authors": ["Abdullah Alabdullah", "Lifeng Han", "Chenghua Lin"], "title": "Ara-HOPE: Human-Centric Post-Editing Evaluation for Dialectal Arabic to Modern Standard Arabic Translation", "comment": null, "summary": "Dialectal Arabic to Modern Standard Arabic (DA-MSA) translation is a challenging task in Machine Translation (MT) due to significant lexical, syntactic, and semantic divergences between Arabic dialects and MSA. Existing automatic evaluation metrics and general-purpose human evaluation frameworks struggle to capture dialect-specific MT errors, hindering progress in translation assessment. This paper introduces Ara-HOPE, a human-centric post-editing evaluation framework designed to systematically address these challenges. The framework includes a five-category error taxonomy and a decision-tree annotation protocol. Through comparative evaluation of three MT systems (Arabic-centric Jais, general-purpose GPT-3.5, and baseline NLLB-200), Ara-HOPE effectively highlights systematic performance differences between these systems. The results show that dialect-specific terminology and semantic preservation remain the most persistent challenges in DA-MSA translation. Ara-HOPE establishes a new framework for evaluating Dialectal Arabic MT quality and provides actionable guidance for improving dialect-aware MT systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Ara-HOPE\u6846\u67b6\uff0c\u4e00\u4e2a\u9488\u5bf9\u963f\u62c9\u4f2f\u65b9\u8a00\u5230\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u7ffb\u8bd1\u8bc4\u4f30\u7684\u4eba\u7c7b\u4e2d\u5fc3\u5316\u540e\u7f16\u8f91\u8bc4\u4f30\u7cfb\u7edf\uff0c\u5305\u542b\u9519\u8bef\u5206\u7c7b\u548c\u6807\u6ce8\u534f\u8bae\uff0c\u80fd\u6709\u6548\u8bc4\u4f30\u4e0d\u540c\u7ffb\u8bd1\u7cfb\u7edf\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u963f\u62c9\u4f2f\u65b9\u8a00\u5230\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u7ffb\u8bd1\u9762\u4e34\u8bcd\u6c47\u3001\u53e5\u6cd5\u548c\u8bed\u4e49\u5dee\u5f02\u7684\u6311\u6218\uff0c\u73b0\u6709\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u548c\u901a\u7528\u4eba\u5de5\u8bc4\u4f30\u6846\u67b6\u96be\u4ee5\u6355\u6349\u65b9\u8a00\u7279\u6709\u7684\u7ffb\u8bd1\u9519\u8bef\uff0c\u963b\u788d\u4e86\u7ffb\u8bd1\u8bc4\u4f30\u7684\u8fdb\u5c55\u3002", "method": "\u63d0\u51fa\u4e86Ara-HOPE\u6846\u67b6\uff0c\u5305\u62ec\u4e00\u4e2a\u4e94\u7c7b\u9519\u8bef\u5206\u7c7b\u6cd5\u548c\u51b3\u7b56\u6811\u6807\u6ce8\u534f\u8bae\uff0c\u901a\u8fc7\u6bd4\u8f83\u8bc4\u4f30\u4e09\u4e2a\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\uff08\u963f\u62c9\u4f2f\u8bed\u4e2d\u5fc3\u7684Jais\u3001\u901a\u7528GPT-3.5\u548c\u57fa\u7ebfNLLB-200\uff09\u6765\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u65b9\u8a00\u7279\u5b9a\u672f\u8bed\u548c\u8bed\u4e49\u4fdd\u7559\u662fDA-MSA\u7ffb\u8bd1\u4e2d\u6700\u6301\u4e45\u7684\u6311\u6218\uff0cAra-HOPE\u80fd\u6709\u6548\u7a81\u51fa\u4e0d\u540c\u7cfb\u7edf\u95f4\u7684\u7cfb\u7edf\u6027\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "Ara-HOPE\u4e3a\u8bc4\u4f30\u963f\u62c9\u4f2f\u65b9\u8a00\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u5efa\u7acb\u4e86\u65b0\u6846\u67b6\uff0c\u5e76\u4e3a\u6539\u8fdb\u65b9\u8a00\u611f\u77e5\u7684\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002"}}
{"id": "2512.21789", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.21789", "abs": "https://arxiv.org/abs/2512.21789", "authors": ["Ting-Hao K. Huang", "Ryan A. Rossi", "Sungchul Kim", "Tong Yu", "Ting-Yao E. Hsu", "Ho Yin", "Ng", "C. Lee Giles"], "title": "Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning", "comment": "Accepted to the 5th Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE 2026)", "summary": "Between 2021 and 2025, the SciCap project grew from a small seed-funded idea at The Pennsylvania State University (Penn State) into one of the central efforts shaping the scientific figure-captioning landscape. Supported by a Penn State seed grant, Adobe, and the Alfred P. Sloan Foundation, what began as our attempt to test whether domain-specific training, which was successful in text models like SciBERT, could also work for figure captions expanded into a multi-institution collaboration. Over these five years, we curated, released, and continually updated a large collection of figure-caption pairs from arXiv papers, conducted extensive automatic and human evaluations on both generated and author-written captions, navigated the rapid rise of large language models (LLMs), launched annual challenges, and built interactive systems that help scientists write better captions. In this piece, we look back at the first five years of SciCap and summarize the key technical and methodological lessons we learned. We then outline five major unsolved challenges and propose directions for the next phase of research in scientific figure captioning.", "AI": {"tldr": "SciCap\u9879\u76ee\u57282021-2025\u5e74\u95f4\u4ece\u5bbe\u5dde\u5927\u5b66\u7684\u79cd\u5b50\u9879\u76ee\u53d1\u5c55\u6210\u4e3a\u79d1\u5b66\u56fe\u8868\u6807\u6ce8\u9886\u57df\u7684\u6838\u5fc3\u9879\u76ee\uff0c\u901a\u8fc7\u591a\u673a\u6784\u5408\u4f5c\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u56fe\u8868-\u6807\u9898\u6570\u636e\u96c6\uff0c\u5f00\u5c55\u4e86\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\uff0c\u5e94\u5bf9\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u5e76\u5f00\u53d1\u4e86\u8f85\u52a9\u79d1\u5b66\u5bb6\u64b0\u5199\u66f4\u597d\u6807\u9898\u7684\u4ea4\u4e92\u7cfb\u7edf\u3002", "motivation": "\u6700\u521d\u52a8\u673a\u662f\u6d4b\u8bd5\u5728\u6587\u672c\u6a21\u578b\uff08\u5982SciBERT\uff09\u4e2d\u6210\u529f\u7684\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u65b9\u6cd5\u662f\u5426\u4e5f\u9002\u7528\u4e8e\u56fe\u8868\u6807\u9898\u751f\u6210\uff0c\u63a2\u7d22\u79d1\u5b66\u56fe\u8868\u6807\u6ce8\u8fd9\u4e00\u7279\u5b9a\u9886\u57df\u7684\u95ee\u9898\u3002", "method": "1. \u4ecearXiv\u8bba\u6587\u4e2d\u6536\u96c6\u3001\u6574\u7406\u548c\u6301\u7eed\u66f4\u65b0\u5927\u89c4\u6a21\u56fe\u8868-\u6807\u9898\u914d\u5bf9\u6570\u636e\u96c6\n2. \u5bf9\u751f\u6210\u6807\u9898\u548c\u4f5c\u8005\u64b0\u5199\u6807\u9898\u8fdb\u884c\u5e7f\u6cdb\u7684\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\n3. \u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\n4. \u53d1\u8d77\u5e74\u5ea6\u6311\u6218\u8d5b\n5. \u5f00\u53d1\u8f85\u52a9\u79d1\u5b66\u5bb6\u64b0\u5199\u66f4\u597d\u6807\u9898\u7684\u4ea4\u4e92\u7cfb\u7edf", "result": "\u6210\u529f\u5c06SciCap\u9879\u76ee\u4ece\u79cd\u5b50\u60f3\u6cd5\u53d1\u5c55\u4e3a\u79d1\u5b66\u56fe\u8868\u6807\u6ce8\u9886\u57df\u7684\u6838\u5fc3\u9879\u76ee\uff0c\u5efa\u7acb\u4e86\u591a\u673a\u6784\u5408\u4f5c\u6846\u67b6\uff0c\u521b\u5efa\u4e86\u6301\u7eed\u66f4\u65b0\u7684\u6570\u636e\u96c6\uff0c\u5f00\u5c55\u4e86\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5e76\u5f00\u53d1\u4e86\u5b9e\u7528\u7684\u4ea4\u4e92\u5de5\u5177\u3002", "conclusion": "\u603b\u7ed3\u4e86\u524d\u4e94\u5e74\u7684\u6280\u672f\u548c\u65b9\u6cd5\u5b66\u7ecf\u9a8c\u6559\u8bad\uff0c\u63d0\u51fa\u4e86\u79d1\u5b66\u56fe\u8868\u6807\u6ce8\u9886\u57df\u5c1a\u672a\u89e3\u51b3\u7684\u4e94\u4e2a\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u4e3a\u4e0b\u4e00\u9636\u6bb5\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2512.21809", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.21809", "abs": "https://arxiv.org/abs/2512.21809", "authors": ["Vitthal Bhandari"], "title": "On The Conceptualization and Societal Impact of Cross-Cultural Bias", "comment": "Term paper for LING 575 (Societal Impacts of Language Technologies)", "summary": "Research has shown that while large language models (LLMs) can generate their responses based on cultural context, they are not perfect and tend to generalize across cultures. However, when evaluating the cultural bias of a language technology on any dataset, researchers may choose not to engage with stakeholders actually using that technology in real life, which evades the very fundamental problem they set out to address.\n  Inspired by the work done by arXiv:2005.14050v2, I set out to analyse recent literature about identifying and evaluating cultural bias in Natural Language Processing (NLP). I picked out 20 papers published in 2025 about cultural bias and came up with a set of observations to allow NLP researchers in the future to conceptualize bias concretely and evaluate its harms effectively. My aim is to advocate for a robust assessment of the societal impact of language technologies exhibiting cross-cultural bias.", "AI": {"tldr": "\u5bf92025\u5e74\u53d1\u8868\u768420\u7bc7\u5173\u4e8eNLP\u6587\u5316\u504f\u89c1\u7684\u8bba\u6587\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u63d0\u51fa\u89c2\u5bdf\u6846\u67b6\u4ee5\u5e2e\u52a9\u7814\u7a76\u8005\u66f4\u5177\u4f53\u5730\u6982\u5ff5\u5316\u504f\u89c1\u5e76\u6709\u6548\u8bc4\u4f30\u5176\u5371\u5bb3\uff0c\u5021\u5bfc\u5bf9\u8de8\u6587\u5316\u504f\u89c1\u8bed\u8a00\u6280\u672f\u8fdb\u884c\u66f4\u7a33\u5065\u7684\u793e\u4f1a\u5f71\u54cd\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u57fa\u4e8e\u6587\u5316\u80cc\u666f\u751f\u6210\u54cd\u5e94\uff0c\u4f46\u5b83\u4eec\u5e76\u4e0d\u5b8c\u7f8e\u4e14\u503e\u5411\u4e8e\u8de8\u6587\u5316\u6cdb\u5316\u3002\u5f53\u524d\u7814\u7a76\u5728\u8bc4\u4f30\u8bed\u8a00\u6280\u672f\u6587\u5316\u504f\u89c1\u65f6\uff0c\u5f80\u5f80\u4e0d\u63a5\u89e6\u5b9e\u9645\u4f7f\u7528\u8be5\u6280\u672f\u7684\u5229\u76ca\u76f8\u5173\u8005\uff0c\u8fd9\u56de\u907f\u4e86\u7814\u7a76\u8005\u672c\u5e94\u89e3\u51b3\u7684\u6839\u672c\u95ee\u9898\u3002", "method": "\u53d7arXiv:2005.14050v2\u5de5\u4f5c\u7684\u542f\u53d1\uff0c\u7cfb\u7edf\u5206\u6790\u4e862025\u5e74\u53d1\u8868\u768420\u7bc7\u5173\u4e8eNLP\u6587\u5316\u504f\u89c1\u8bc6\u522b\u4e0e\u8bc4\u4f30\u7684\u6587\u732e\uff0c\u63d0\u53d6\u51fa\u4e00\u7cfb\u5217\u89c2\u5bdf\u7ed3\u679c\u548c\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u89c2\u5bdf\u6846\u67b6\uff0c\u4f7f\u672a\u6765NLP\u7814\u7a76\u8005\u80fd\u591f\u66f4\u5177\u4f53\u5730\u6982\u5ff5\u5316\u504f\u89c1\uff0c\u5e76\u6709\u6548\u8bc4\u4f30\u5176\u5371\u5bb3\u3002\u8be5\u6846\u67b6\u65e8\u5728\u63a8\u52a8\u5bf9\u8868\u73b0\u51fa\u8de8\u6587\u5316\u504f\u89c1\u7684\u8bed\u8a00\u6280\u672f\u8fdb\u884c\u66f4\u7a33\u5065\u7684\u793e\u4f1a\u5f71\u54cd\u8bc4\u4f30\u3002", "conclusion": "\u9700\u8981\u5efa\u7acb\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5c06\u5b9e\u9645\u5229\u76ca\u76f8\u5173\u8005\u7684\u53c2\u4e0e\u7eb3\u5165\u6587\u5316\u504f\u89c1\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u8861\u91cf\u8bed\u8a00\u6280\u672f\u7684\u793e\u4f1a\u5f71\u54cd\uff0c\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2512.21817", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21817", "abs": "https://arxiv.org/abs/2512.21817", "authors": ["Hong Su"], "title": "Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments", "comment": null, "summary": "Intelligent IoT systems increasingly rely on large language models (LLMs) to generate task-execution methods for dynamic environments. However, existing approaches lack the ability to systematically produce new methods when facing previously unseen situations, and they often depend on fixed, device-specific logic that cannot adapt to changing environmental conditions.In this paper, we propose Method Decoration (DeMe), a general framework that modifies the method-generation path of an LLM using explicit decorations derived from hidden goals, accumulated learned methods, and environmental feedback. Unlike traditional rule augmentation, decorations in DeMe are not hardcoded; instead, they are extracted from universal behavioral principles, experience, and observed environmental differences. DeMe enables the agent to reshuffle the structure of its method path-through pre-decoration, post-decoration, intermediate-step modification, and step insertion-thereby producing context-aware, safety-aligned, and environment-adaptive methods. Experimental results show that method decoration allows IoT devices to derive ore appropriate methods when confronting unknown or faulty operating conditions.", "AI": {"tldr": "\u63d0\u51faMethod Decoration (DeMe)\u6846\u67b6\uff0c\u901a\u8fc7\u76ee\u6807\u3001\u7ecf\u9a8c\u3001\u73af\u5883\u53cd\u9988\u7b49\u88c5\u9970\u4fe1\u606f\u4fee\u6539LLM\u65b9\u6cd5\u751f\u6210\u8def\u5f84\uff0c\u63d0\u5347IoT\u7cfb\u7edf\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684IoT\u7cfb\u7edf\u5728\u751f\u6210\u4efb\u52a1\u6267\u884c\u65b9\u6cd5\u65f6\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1) \u65e0\u6cd5\u7cfb\u7edf\u6027\u5730\u4e3a\u65b0\u60c5\u51b5\u751f\u6210\u65b0\u65b9\u6cd5\uff1b2) \u4f9d\u8d56\u56fa\u5b9a\u7684\u8bbe\u5907\u7279\u5b9a\u903b\u8f91\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u73af\u5883\u53d8\u5316\u3002", "method": "\u63d0\u51faMethod Decoration (DeMe)\u901a\u7528\u6846\u67b6\uff0c\u4ece\u9690\u85cf\u76ee\u6807\u3001\u7d2f\u79ef\u5b66\u4e60\u65b9\u6cd5\u3001\u73af\u5883\u53cd\u9988\u4e2d\u63d0\u53d6\u88c5\u9970\u4fe1\u606f\uff0c\u901a\u8fc7\u9884\u88c5\u9970\u3001\u540e\u88c5\u9970\u3001\u4e2d\u95f4\u6b65\u9aa4\u4fee\u6539\u3001\u6b65\u9aa4\u63d2\u5165\u7b49\u65b9\u5f0f\u91cd\u7ec4LLM\u7684\u65b9\u6cd5\u751f\u6210\u8def\u5f84\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u65b9\u6cd5\u88c5\u9970\u4f7fIoT\u8bbe\u5907\u5728\u9762\u5bf9\u672a\u77e5\u6216\u6545\u969c\u64cd\u4f5c\u6761\u4ef6\u65f6\u80fd\u591f\u63a8\u5bfc\u51fa\u66f4\u5408\u9002\u7684\u65b9\u6cd5\u3002", "conclusion": "DeMe\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u88c5\u9970LLM\u65b9\u6cd5\u751f\u6210\u8def\u5f84\uff0c\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u5b89\u5168\u5bf9\u9f50\u548c\u73af\u5883\u81ea\u9002\u5e94\u7684\u667a\u80fdIoT\u65b9\u6cd5\u751f\u6210\u3002"}}
{"id": "2512.21837", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21837", "abs": "https://arxiv.org/abs/2512.21837", "authors": ["Siyu Li", "Chenwei Song", "Wan Zhou", "Xinyi Liu"], "title": "Knowledge Reasoning of Large Language Models Integrating Graph-Structured Information for Pest and Disease Control in Tobacco", "comment": null, "summary": "This paper proposes a large language model (LLM) approach that integrates graph-structured information for knowledge reasoning in tobacco pest and disease control. Built upon the GraphRAG framework, the proposed method enhances knowledge retrieval and reasoning by explicitly incorporating structured information from a domain-specific knowledge graph. Specifically, LLMs are first leveraged to assist in the construction of a tobacco pest and disease knowledge graph, which organizes key entities such as diseases, symptoms, control methods, and their relationships. Based on this graph, relevant knowledge is retrieved and integrated into the reasoning process to support accurate answer generation. The Transformer architecture is adopted as the core inference model, while a graph neural network (GNN) is employed to learn expressive node representations that capture both local and global relational information within the knowledge graph. A ChatGLM-based model serves as the backbone LLM and is fine-tuned using LoRA to achieve parameter-efficient adaptation. Extensive experimental results demonstrate that the proposed approach consistently outperforms baseline methods across multiple evaluation metrics, significantly improving both the accuracy and depth of reasoning, particularly in complex multi-hop and comparative reasoning scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u56fe\u7ed3\u6784\u4fe1\u606f\u7684LLM\u65b9\u6cd5\uff0c\u7528\u4e8e\u70df\u8349\u75c5\u866b\u5bb3\u9632\u6cbb\u7684\u77e5\u8bc6\u63a8\u7406\uff0c\u901a\u8fc7\u6784\u5efa\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u5e76\u878d\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u6df1\u5ea6\u3002", "motivation": "\u73b0\u6709LLM\u5728\u70df\u8349\u75c5\u866b\u5bb3\u9632\u6cbb\u9886\u57df\u7684\u77e5\u8bc6\u63a8\u7406\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7f3a\u4e4f\u5bf9\u7ed3\u6784\u5316\u9886\u57df\u77e5\u8bc6\u7684\u6709\u6548\u5229\u7528\uff0c\u5bfc\u81f4\u5728\u590d\u6742\u63a8\u7406\u573a\u666f\u4e2d\u51c6\u786e\u6027\u4e0d\u8db3\u3002", "method": "\u57fa\u4e8eGraphRAG\u6846\u67b6\uff0c\u9996\u5148\u5229\u7528LLM\u8f85\u52a9\u6784\u5efa\u70df\u8349\u75c5\u866b\u5bb3\u77e5\u8bc6\u56fe\u8c31\uff0c\u7136\u540e\u91c7\u7528Transformer\u67b6\u6784\u4f5c\u4e3a\u6838\u5fc3\u63a8\u7406\u6a21\u578b\uff0c\u7ed3\u5408GNN\u5b66\u4e60\u8282\u70b9\u8868\u793a\uff0c\u4f7f\u7528ChatGLM\u4f5c\u4e3a\u9aa8\u5e72LLM\u5e76\u901a\u8fc7LoRA\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u9879\u8bc4\u4f30\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u6df1\u5ea6\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684\u591a\u8df3\u63a8\u7406\u548c\u6bd4\u8f83\u63a8\u7406\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u901a\u8fc7\u5c06\u56fe\u7ed3\u6784\u4fe1\u606f\u96c6\u6210\u5230LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u70df\u8349\u75c5\u866b\u5bb3\u9632\u6cbb\u9886\u57df\u7684\u77e5\u8bc6\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u9886\u57df\u4e13\u5bb6\u63d0\u4f9b\u66f4\u51c6\u786e\u3001\u6df1\u5165\u7684\u652f\u6301\u3002"}}
{"id": "2512.21842", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21842", "abs": "https://arxiv.org/abs/2512.21842", "authors": ["Baorong Huang", "Ali Asiri"], "title": "AlignAR: Generative Sentence Alignment for Arabic-English Parallel Corpora of Legal and Literary Texts", "comment": null, "summary": "High-quality parallel corpora are essential for Machine Translation (MT) research and translation teaching. However, Arabic-English resources remain scarce and existing datasets mainly consist of simple one-to-one mappings. In this paper, we present AlignAR, a generative sentence alignment method, and a new Arabic-English dataset comprising complex legal and literary texts. Our evaluation demonstrates that \"Easy\" datasets lack the discriminatory power to fully assess alignment methods. By reducing one-to-one mappings in our \"Hard\" subset, we exposed the limitations of traditional alignment methods. In contrast, LLM-based approaches demonstrated superior robustness, achieving an overall F1-score of 85.5%, a 9% improvement over previous methods. Our datasets and codes are open-sourced at https://github.com/XXX.", "AI": {"tldr": "\u63d0\u51fa\u4e86AlignAR\u751f\u6210\u5f0f\u53e5\u5b50\u5bf9\u9f50\u65b9\u6cd5\u548c\u5305\u542b\u590d\u6742\u6cd5\u5f8b\u4e0e\u6587\u5b66\u6587\u672c\u7684\u963f\u62c9\u4f2f\u8bed-\u82f1\u8bed\u6570\u636e\u96c6\uff0c\u53d1\u73b0\"\u7b80\u5355\"\u6570\u636e\u96c6\u7f3a\u4e4f\u533a\u5206\u80fd\u529b\uff0c\u800cLLM\u65b9\u6cd5\u5728\"\u56f0\u96be\"\u5b50\u96c6\u4e0a\u8868\u73b0\u66f4\u4f18", "motivation": "\u963f\u62c9\u4f2f\u8bed-\u82f1\u8bed\u5e73\u884c\u8bed\u6599\u5e93\u7a00\u7f3a\uff0c\u73b0\u6709\u6570\u636e\u96c6\u4e3b\u8981\u5305\u542b\u7b80\u5355\u7684\u4e00\u5bf9\u4e00\u6620\u5c04\uff0c\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u5bf9\u9f50\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u6587\u672c\u4e0a", "method": "\u63d0\u51fa\u4e86AlignAR\u751f\u6210\u5f0f\u53e5\u5b50\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b\u590d\u6742\u6cd5\u5f8b\u548c\u6587\u5b66\u6587\u672c\u7684\u65b0\u963f\u62c9\u4f2f\u8bed-\u82f1\u8bed\u6570\u636e\u96c6\uff0c\u5305\u542b\"\u7b80\u5355\"\u548c\"\u56f0\u96be\"\u4e24\u4e2a\u5b50\u96c6", "result": "\u8bc4\u4f30\u663e\u793a\"\u7b80\u5355\"\u6570\u636e\u96c6\u7f3a\u4e4f\u533a\u5206\u5bf9\u9f50\u65b9\u6cd5\u7684\u80fd\u529b\uff1b\u901a\u8fc7\u51cf\u5c11\"\u56f0\u96be\"\u5b50\u96c6\u4e2d\u7684\u4e00\u5bf9\u4e00\u6620\u5c04\uff0c\u66b4\u9732\u4e86\u4f20\u7edf\u5bf9\u9f50\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff1bLLM\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u6574\u4f53F1\u5206\u6570\u8fbe\u523085.5%\uff0c\u6bd4\u4e4b\u524d\u65b9\u6cd5\u63d0\u9ad8\u4e869%", "conclusion": "\u9ad8\u8d28\u91cf\u5e73\u884c\u8bed\u6599\u5e93\u5bf9\u673a\u5668\u7ffb\u8bd1\u7814\u7a76\u548c\u6559\u5b66\u81f3\u5173\u91cd\u8981\uff1b\u4f20\u7edf\u5bf9\u9f50\u65b9\u6cd5\u5728\u590d\u6742\u6587\u672c\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800cLLM\u65b9\u6cd5\u5728\u56f0\u96be\u5bf9\u9f50\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\uff1b\u5f00\u6e90\u6570\u636e\u96c6\u548c\u4ee3\u7801\u6709\u52a9\u4e8e\u63a8\u52a8\u76f8\u5173\u7814\u7a76"}}
{"id": "2512.21849", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21849", "abs": "https://arxiv.org/abs/2512.21849", "authors": ["Jiaxin Liu", "Peiyi Tu", "Wenyu Chen", "Yihong Zhuang", "Xinxia Ling", "Anji Zhou", "Chenxi Wang", "Zhuo Han", "Zhengkai Yang", "Junbo Zhao", "Zenan Huang", "Yuanyuan Wang"], "title": "HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs", "comment": "10 pages", "summary": "While Large Language Models (LLMs) have achieved remarkable success in cognitive and reasoning benchmarks, they exhibit a persistent deficit in anthropomorphic intelligence-the capacity to navigate complex social, emotional, and ethical nuances. This gap is particularly acute in the Chinese linguistic and cultural context, where a lack of specialized evaluation frameworks and high-quality socio-emotional data impedes progress. To address these limitations, we present HeartBench, a framework designed to evaluate the integrated emotional, cultural, and ethical dimensions of Chinese LLMs. Grounded in authentic psychological counseling scenarios and developed in collaboration with clinical experts, the benchmark is structured around a theory-driven taxonomy comprising five primary dimensions and 15 secondary capabilities. We implement a case-specific, rubric-based methodology that translates abstract human-like traits into granular, measurable criteria through a ``reasoning-before-scoring'' evaluation protocol. Our assessment of 13 state-of-the-art LLMs indicates a substantial performance ceiling: even leading models achieve only 60% of the expert-defined ideal score. Furthermore, analysis using a difficulty-stratified ``Hard Set'' reveals a significant performance decay in scenarios involving subtle emotional subtexts and complex ethical trade-offs. HeartBench establishes a standardized metric for anthropomorphic AI evaluation and provides a methodological blueprint for constructing high-quality, human-aligned training data.", "AI": {"tldr": "HeartBench\u662f\u4e00\u4e2a\u8bc4\u4f30\u4e2d\u6587\u5927\u8bed\u8a00\u6a21\u578b\u60c5\u611f\u3001\u6587\u5316\u548c\u4f26\u7406\u667a\u80fd\u7684\u7efc\u5408\u6846\u67b6\uff0c\u57fa\u4e8e\u771f\u5b9e\u5fc3\u7406\u54a8\u8be2\u573a\u666f\u6784\u5efa\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u590d\u6742\u793e\u4f1a\u60c5\u611f\u573a\u666f\u4e2d\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u8ba4\u77e5\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u793e\u4f1a\u3001\u60c5\u611f\u548c\u4f26\u7406\u7ec6\u5fae\u5dee\u522b\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002\u7279\u522b\u662f\u5728\u4e2d\u6587\u8bed\u8a00\u6587\u5316\u80cc\u666f\u4e0b\uff0c\u7f3a\u4e4f\u4e13\u95e8\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u9ad8\u8d28\u91cf\u7684\u793e\u4f1a\u60c5\u611f\u6570\u636e\uff0c\u963b\u788d\u4e86\u6a21\u578b\u5728\u62df\u4eba\u5316\u667a\u80fd\u65b9\u9762\u7684\u53d1\u5c55\u3002", "method": "1. \u4e0e\u4e34\u5e8a\u4e13\u5bb6\u5408\u4f5c\uff0c\u57fa\u4e8e\u771f\u5b9e\u5fc3\u7406\u54a8\u8be2\u573a\u666f\u6784\u5efa\u8bc4\u4f30\u6846\u67b6\n2. \u91c7\u7528\u7406\u8bba\u9a71\u52a8\u7684\u5206\u7c7b\u6cd5\uff0c\u5305\u542b5\u4e2a\u4e3b\u8981\u7ef4\u5ea6\u548c15\u4e2a\u6b21\u8981\u80fd\u529b\n3. \u5b9e\u65bd\u6848\u4f8b\u7279\u5b9a\u7684\u3001\u57fa\u4e8e\u91cf\u89c4\u7684\u65b9\u6cd5\u8bba\n4. \u901a\u8fc7\"\u63a8\u7406-\u8bc4\u5206\"\u8bc4\u4f30\u534f\u8bae\u5c06\u62bd\u8c61\u7684\u4eba\u7c7b\u7279\u8d28\u8f6c\u5316\u4e3a\u53ef\u6d4b\u91cf\u7684\u7ec6\u7c92\u5ea6\u6807\u51c6\n5. \u8bc4\u4f3013\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\n6. \u4f7f\u7528\u96be\u5ea6\u5206\u5c42\u7684\"\u56f0\u96be\u96c6\"\u8fdb\u884c\u6027\u80fd\u5206\u6790", "result": "1. \u8bc4\u4f30\u768413\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u4e0a\u9650\uff1a\u5373\u4f7f\u662f\u9886\u5148\u6a21\u578b\u4e5f\u53ea\u80fd\u8fbe\u5230\u4e13\u5bb6\u5b9a\u4e49\u7406\u60f3\u5206\u6570\u768460%\n2. \u5728\u6d89\u53ca\u5fae\u5999\u60c5\u611f\u6f5c\u53f0\u8bcd\u548c\u590d\u6742\u4f26\u7406\u6743\u8861\u7684\u573a\u666f\u4e2d\uff0c\u6a21\u578b\u6027\u80fd\u51fa\u73b0\u663e\u8457\u8870\u51cf\n3. \u901a\u8fc7\u96be\u5ea6\u5206\u5c42\u7684\"\u56f0\u96be\u96c6\"\u5206\u6790\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u793e\u4f1a\u60c5\u611f\u4efb\u52a1\u65f6\u7684\u5c40\u9650\u6027", "conclusion": "HeartBench\u4e3a\u62df\u4eba\u5316AI\u8bc4\u4f30\u5efa\u7acb\u4e86\u6807\u51c6\u5316\u5ea6\u91cf\u6807\u51c6\uff0c\u5e76\u4e3a\u6784\u5efa\u9ad8\u8d28\u91cf\u3001\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684\u8bad\u7ec3\u6570\u636e\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u84dd\u56fe\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5f53\u524d\u4e2d\u6587\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u3001\u6587\u5316\u548c\u4f26\u7406\u667a\u80fd\u65b9\u9762\u4ecd\u6709\u663e\u8457\u63d0\u5347\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u4e13\u95e8\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u8bad\u7ec3\u6570\u636e\u6765\u63a8\u52a8\u8fd9\u4e00\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.21859", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21859", "abs": "https://arxiv.org/abs/2512.21859", "authors": ["Qi Fan", "An Zou", "Yehan Ma"], "title": "TimeBill: Time-Budgeted Inference for Large Language Models", "comment": "Accepted to AAAI 2026", "summary": "Large Language Models (LLMs) are increasingly deployed in time-critical systems, such as robotics, autonomous driving, embodied intelligence, and industrial automation, where generating accurate responses within a given time budget is crucial for decision-making, control, or safety-critical tasks. However, the auto-regressive generation process of LLMs makes it challenging to model and estimate the end-to-end execution time. Furthermore, existing efficient inference methods based on a fixed key-value (KV) cache eviction ratio struggle to adapt to varying tasks with diverse time budgets, where an improper eviction ratio may lead to incomplete inference or a drop in response performance. In this paper, we propose TimeBill, a novel time-budgeted inference framework for LLMs that balances the inference efficiency and response performance. To be more specific, we propose a fine-grained response length predictor (RLP) and an execution time estimator (ETE) to accurately predict the end-to-end execution time of LLMs. Following this, we develop a time-budgeted efficient inference approach that adaptively adjusts the KV cache eviction ratio based on execution time prediction and the given time budget. Finally, through extensive experiments, we demonstrate the advantages of TimeBill in improving task completion rate and maintaining response performance under various overrun strategies.", "AI": {"tldr": "TimeBill\uff1a\u4e00\u4e2a\u65b0\u9896\u7684\u65f6\u95f4\u9884\u7b97\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574KV\u7f13\u5b58\u6dd8\u6c70\u7387\u6765\u5e73\u8861LLM\u63a8\u7406\u6548\u7387\u4e0e\u54cd\u5e94\u6027\u80fd\uff0c\u4ee5\u6ee1\u8db3\u65f6\u95f4\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u5b9e\u65f6\u9700\u6c42\u3002", "motivation": "LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u90e8\u7f72\u5728\u65f6\u95f4\u5173\u952e\u7cfb\u7edf\u4e2d\uff08\u5982\u673a\u5668\u4eba\u3001\u81ea\u52a8\u9a7e\u9a76\u3001\u5177\u8eab\u667a\u80fd\u7b49\uff09\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u9700\u8981\u5728\u7ed9\u5b9a\u65f6\u95f4\u9884\u7b97\u5185\u751f\u6210\u51c6\u786e\u54cd\u5e94\u3002\u7136\u800c\uff0c\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4f7f\u5f97\u7aef\u5230\u7aef\u6267\u884c\u65f6\u95f4\u96be\u4ee5\u5efa\u6a21\u548c\u4f30\u8ba1\uff0c\u800c\u73b0\u6709\u7684\u57fa\u4e8e\u56fa\u5b9aKV\u7f13\u5b58\u6dd8\u6c70\u7387\u7684\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u5177\u6709\u4e0d\u540c\u65f6\u95f4\u9884\u7b97\u7684\u591a\u6837\u5316\u4efb\u52a1\u3002", "method": "1. \u63d0\u51fa\u7ec6\u7c92\u5ea6\u54cd\u5e94\u957f\u5ea6\u9884\u6d4b\u5668\uff08RLP\uff09\u548c\u6267\u884c\u65f6\u95f4\u4f30\u8ba1\u5668\uff08ETE\uff09\u6765\u51c6\u786e\u9884\u6d4bLLMs\u7684\u7aef\u5230\u7aef\u6267\u884c\u65f6\u95f4\uff1b2. \u5f00\u53d1\u65f6\u95f4\u9884\u7b97\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6267\u884c\u65f6\u95f4\u9884\u6d4b\u548c\u7ed9\u5b9a\u65f6\u95f4\u9884\u7b97\u81ea\u9002\u5e94\u8c03\u6574KV\u7f13\u5b58\u6dd8\u6c70\u7387\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0cTimeBill\u5728\u5404\u79cd\u8d85\u9650\u7b56\u7565\u4e0b\u90fd\u80fd\u63d0\u9ad8\u4efb\u52a1\u5b8c\u6210\u7387\u5e76\u4fdd\u6301\u54cd\u5e94\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u5728\u65f6\u95f4\u9884\u7b97\u63a8\u7406\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "TimeBill\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLMs\u5728\u65f6\u95f4\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u63a8\u7406\u6548\u7387\u4e0e\u6027\u80fd\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94KV\u7f13\u5b58\u7ba1\u7406\u5b9e\u73b0\u4e86\u5728\u4e25\u683c\u65f6\u95f4\u7ea6\u675f\u4e0b\u7684\u53ef\u9760\u63a8\u7406\u3002"}}
{"id": "2512.21871", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.21871", "abs": "https://arxiv.org/abs/2512.21871", "authors": ["Naen Xu", "Jinghuai Zhang", "Changjiang Li", "Hengyu An", "Chunyi Zhou", "Jun Wang", "Boyu Xu", "Yuyuan Li", "Tianyu Du", "Shouling Ji"], "title": "Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?", "comment": "AAAI 2026 (Oral)", "summary": "Large vision-language models (LVLMs) have achieved remarkable advancements in multimodal reasoning tasks. However, their widespread accessibility raises critical concerns about potential copyright infringement. Will LVLMs accurately recognize and comply with copyright regulations when encountering copyrighted content (i.e., user input, retrieved documents) in the context? Failure to comply with copyright regulations may lead to serious legal and ethical consequences, particularly when LVLMs generate responses based on copyrighted materials (e.g., retrieved book experts, news reports). In this paper, we present a comprehensive evaluation of various LVLMs, examining how they handle copyrighted content -- such as book excerpts, news articles, music lyrics, and code documentation when they are presented as visual inputs. To systematically measure copyright compliance, we introduce a large-scale benchmark dataset comprising 50,000 multimodal query-content pairs designed to evaluate how effectively LVLMs handle queries that could lead to copyright infringement. Given that real-world copyrighted content may or may not include a copyright notice, the dataset includes query-content pairs in two distinct scenarios: with and without a copyright notice. For the former, we extensively cover four types of copyright notices to account for different cases. Our evaluation reveals that even state-of-the-art closed-source LVLMs exhibit significant deficiencies in recognizing and respecting the copyrighted content, even when presented with the copyright notice. To solve this limitation, we introduce a novel tool-augmented defense framework for copyright compliance, which reduces infringement risks in all scenarios. Our findings underscore the importance of developing copyright-aware LVLMs to ensure the responsible and lawful use of copyrighted content.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5904\u7406\u7248\u6743\u5185\u5bb9\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff0c\u5e76\u63d0\u51fa\u4e86\u5de5\u5177\u589e\u5f3a\u7684\u9632\u5fa1\u6846\u67b6\u6765\u964d\u4f4e\u4fb5\u6743\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5904\u7406\u7248\u6743\u5185\u5bb9\u65f6\u53ef\u80fd\u5f15\u53d1\u7684\u4fb5\u6743\u98ce\u9669\u6210\u4e3a\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u80fd\u5426\u51c6\u786e\u8bc6\u522b\u5e76\u9075\u5b88\u7248\u6743\u6cd5\u89c4\uff0c\u4ee5\u907f\u514d\u6cd5\u5f8b\u548c\u4f26\u7406\u540e\u679c\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b50,000\u4e2a\u591a\u6a21\u6001\u67e5\u8be2-\u5185\u5bb9\u5bf9\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e66\u7c4d\u6458\u5f55\u3001\u65b0\u95fb\u62a5\u9053\u3001\u97f3\u4e50\u6b4c\u8bcd\u548c\u4ee3\u7801\u6587\u6863\u7b49\u7248\u6743\u5185\u5bb9\u3002\u6570\u636e\u96c6\u5305\u542b\u6709\u7248\u6743\u58f0\u660e\u548c\u65e0\u7248\u6743\u58f0\u660e\u4e24\u79cd\u573a\u666f\uff0c\u5e76\u8986\u76d6\u56db\u79cd\u7248\u6743\u58f0\u660e\u7c7b\u578b\u3002\u901a\u8fc7\u8be5\u6570\u636e\u96c6\u7cfb\u7edf\u8bc4\u4f30\u5404\u79cdLVLMs\u7684\u7248\u6743\u5408\u89c4\u6027\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\uff0c\u5373\u4f7f\u662f\u5f53\u524d\u6700\u5148\u8fdb\u7684\u95ed\u6e90LVLMs\uff0c\u5728\u8bc6\u522b\u548c\u5c0a\u91cd\u7248\u6743\u5185\u5bb9\u65b9\u9762\u4e5f\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u5373\u4f7f\u9762\u5bf9\u7248\u6743\u58f0\u660e\u65f6\u4e5f\u662f\u5982\u6b64\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u5de5\u5177\u589e\u5f3a\u7684\u7248\u6743\u5408\u89c4\u9632\u5fa1\u6846\u67b6\u3002", "conclusion": "\u5f00\u53d1\u7248\u6743\u611f\u77e5\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5bf9\u4e8e\u786e\u4fdd\u8d1f\u8d23\u4efb\u4e14\u5408\u6cd5\u5730\u4f7f\u7528\u7248\u6743\u5185\u5bb9\u81f3\u5173\u91cd\u8981\u3002\u8bba\u6587\u63d0\u51fa\u7684\u9632\u5fa1\u6846\u67b6\u4e3a\u964d\u4f4e\u4fb5\u6743\u98ce\u9669\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.21877", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21877", "abs": "https://arxiv.org/abs/2512.21877", "authors": ["Vaibhav Devraj", "Dhruv Kumar", "Jagat Sesh Challa"], "title": "CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics", "comment": "Under Review", "summary": "Cricket is the second most popular sport globally, commanding a massive following of over 2.5 billion fans globally. Enthusiasts and analysts frequently seek advanced statistical insights, such as long-term historical performance trends or complex player comparisons, that are often unavailable through standard web searches. While Large Language Models (LLMs) have advanced significantly in Text-to-SQL tasks, their capability to handle the domain-specific nuances, complex schema variations, and multilingual requirements inherent to sports analytics remains under-explored. To investigate this potential capability gap, we present CricBench, a comprehensive benchmark suite for evaluating LLMs on specialized cricket data. To curate a \"Gold Standard\" dataset, we collaborate with domain experts in cricket and SQL to manually author complex queries, ensuring logical correctness. Recognizing linguistic diversity, we construct the benchmark in both English and Hindi, establishing a framework that is open for further extension to other regional languages. We evaluate six state-of-the-art models, including GPT-4o, Claude 3.7 Sonnet, and open-source models, using a strict evaluation protocol. Our results reveal that high performance on general benchmarks does not guarantee success in specialized domains. While the open-weights reasoning model DeepSeek R1 achieves state-of-the-art performance (50.6%), surpassing proprietary giants like Claude 3.7 Sonnet (47.7%) and GPT-4o (33.7%), it still exhibits a significant accuracy drop when moving from general benchmarks (BIRD) to CricBench. Furthermore, we observe that code-mixed Hindi queries frequently yield parity or higher accuracy compared to English, challenging the assumption that English is the optimal prompt language for specialized SQL tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86CricBench\u57fa\u51c6\u5957\u4ef6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u677f\u7403\u6570\u636e\u5206\u6790\u9886\u57df\u7684Text-to-SQL\u80fd\u529b\uff0c\u5305\u542b\u82f1\u8bed\u548c\u5370\u5730\u8bed\u67e5\u8be2\uff0c\u53d1\u73b0\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u6bd4\u901a\u7528\u57fa\u51c6\u8868\u73b0\u66f4\u91cd\u8981\uff0c\u4e14\u5370\u5730\u8bed\u67e5\u8be2\u6709\u65f6\u8868\u73b0\u4f18\u4e8e\u82f1\u8bed\u3002", "motivation": "\u677f\u7403\u4f5c\u4e3a\u5168\u7403\u7b2c\u4e8c\u5927\u8fd0\u52a8\u62e5\u670925\u4ebf\u7c89\u4e1d\uff0c\u4f46\u73b0\u6709LLM\u5728\u5904\u7406\u4f53\u80b2\u5206\u6790\u4e2d\u7684\u9886\u57df\u7279\u5b9a\u590d\u6742\u6027\u3001\u6a21\u5f0f\u53d8\u5316\u548c\u591a\u8bed\u8a00\u9700\u6c42\u65b9\u9762\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u4e13\u95e8\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u5728\u8be5\u9886\u57df\u7684\u8868\u73b0\u3002", "method": "1. \u4e0e\u677f\u7403\u548cSQL\u9886\u57df\u4e13\u5bb6\u5408\u4f5c\u624b\u52a8\u7f16\u5199\u590d\u6742\u67e5\u8be2\u521b\u5efa\"\u9ec4\u91d1\u6807\u51c6\"\u6570\u636e\u96c6\uff1b2. \u6784\u5efa\u82f1\u8bed\u548c\u5370\u5730\u8bed\u53cc\u8bed\u57fa\u51c6\u6846\u67b6\uff1b3. \u8bc4\u4f306\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\uff08\u5305\u62ecGPT-4o\u3001Claude 3.7 Sonnet\u548c\u5f00\u6e90\u6a21\u578b\uff09\uff1b4. \u4f7f\u7528\u4e25\u683c\u8bc4\u4f30\u534f\u8bae\u3002", "result": "1. \u5f00\u6e90\u63a8\u7406\u6a21\u578bDeepSeek R1\u8868\u73b0\u6700\u4f73\uff0850.6%\uff09\uff0c\u8d85\u8d8aClaude 3.7 Sonnet\uff0847.7%\uff09\u548cGPT-4o\uff0833.7%\uff09\uff1b2. \u4ece\u901a\u7528\u57fa\u51c6\uff08BIRD\uff09\u5230CricBench\u65f6\u6240\u6709\u6a21\u578b\u51c6\u786e\u7387\u663e\u8457\u4e0b\u964d\uff1b3. \u5370\u5730\u8bed\u6df7\u5408\u67e5\u8be2\u5e38\u8fbe\u5230\u4e0e\u82f1\u8bed\u76f8\u5f53\u6216\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u901a\u7528\u57fa\u51c6\u7684\u9ad8\u6027\u80fd\u4e0d\u80fd\u4fdd\u8bc1\u5728\u4e13\u4e1a\u9886\u57df\u7684\u6210\u529f\uff0c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u81f3\u5173\u91cd\u8981\uff1b\u591a\u8bed\u8a00\u80fd\u529b\u5728\u4e13\u4e1aSQL\u4efb\u52a1\u4e2d\u5177\u6709\u4ef7\u503c\uff0c\u82f1\u8bed\u4e0d\u4e00\u5b9a\u662f\u6700\u4f73\u63d0\u793a\u8bed\u8a00\uff1b\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u5347LLM\u5728\u4e13\u4e1a\u9886\u57df\u7684\u8868\u73b0\u3002"}}
{"id": "2512.21902", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21902", "abs": "https://arxiv.org/abs/2512.21902", "authors": ["Sachin Pawar", "Girish Keshav Palshikar", "Anindita Sinha Banerjee", "Nitin Ramrakhiyani", "Basit Ali"], "title": "Explainable Statute Prediction via Attention-based Model and LLM Prompting", "comment": null, "summary": "In this paper, we explore the problem of automatic statute prediction where for a given case description, a subset of relevant statutes are to be predicted. Here, the term \"statute\" refers to a section, a sub-section, or an article of any specific Act. Addressing this problem would be useful in several applications such as AI-assistant for lawyers and legal question answering system. For better user acceptance of such Legal AI systems, we believe the predictions should also be accompanied by human understandable explanations. We propose two techniques for addressing this problem of statute prediction with explanations -- (i) AoS (Attention-over-Sentences) which uses attention over sentences in a case description to predict statutes relevant for it and (ii) LLMPrompt which prompts an LLM to predict as well as explain relevance of a certain statute. AoS uses smaller language models, specifically sentence transformers and is trained in a supervised manner whereas LLMPrompt uses larger language models in a zero-shot manner and explores both standard as well as Chain-of-Thought (CoT) prompting techniques. Both these models produce explanations for their predictions in human understandable forms. We compare statute prediction performance of both the proposed techniques with each other as well as with a set of competent baselines, across two popular datasets. Also, we evaluate the quality of the generated explanations through an automated counter-factual manner as well as through human evaluation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6cd5\u5f8b\u6761\u6587\u81ea\u52a8\u9884\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u5e26\u89e3\u91ca\u7684\u9884\u6d4b\u65b9\u6cd5\uff1a\u57fa\u4e8e\u53e5\u5b50\u6ce8\u610f\u529b\u7684AoS\u6a21\u578b\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u7684LLMPrompt\u65b9\u6cd5\uff0c\u5e76\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6027\u80fd\u6bd4\u8f83\u548c\u89e3\u91ca\u8d28\u91cf\u8bc4\u4f30\u3002", "motivation": "\u6cd5\u5f8b\u6761\u6587\u81ea\u52a8\u9884\u6d4b\u6709\u52a9\u4e8e\u5f8b\u5e08AI\u52a9\u624b\u548c\u6cd5\u5f8b\u95ee\u7b54\u7cfb\u7edf\u7b49\u5e94\u7528\u3002\u4e3a\u4e86\u8ba9\u6cd5\u5f8bAI\u7cfb\u7edf\u83b7\u5f97\u66f4\u597d\u7684\u7528\u6237\u63a5\u53d7\u5ea6\uff0c\u9884\u6d4b\u7ed3\u679c\u9700\u8981\u9644\u5e26\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a1) AoS\u6a21\u578b\uff1a\u4f7f\u7528\u53e5\u5b50\u6ce8\u610f\u529b\u673a\u5236\uff0c\u57fa\u4e8e\u53e5\u5b50\u53d8\u6362\u5668\u8fdb\u884c\u76d1\u7763\u8bad\u7ec3\uff1b2) LLMPrompt\uff1a\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u96f6\u6837\u672c\u9884\u6d4b\uff0c\u63a2\u7d22\u6807\u51c6\u63d0\u793a\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u6280\u672f\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u751f\u6210\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u89e3\u91ca\u3002", "result": "\u5728\u4e24\u4e2a\u6d41\u884c\u6570\u636e\u96c6\u4e0a\u6bd4\u8f83\u4e86\u4e24\u79cd\u65b9\u6cd5\u7684\u6761\u6587\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u4e0e\u591a\u4e2a\u57fa\u7ebf\u6a21\u578b\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002\u901a\u8fc7\u81ea\u52a8\u53cd\u4e8b\u5b9e\u65b9\u6cd5\u548c\u4eba\u5de5\u8bc4\u4f30\u8bc4\u4f30\u4e86\u751f\u6210\u89e3\u91ca\u7684\u8d28\u91cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6cd5\u5f8b\u6761\u6587\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e24\u79cd\u5e26\u89e3\u91ca\u7684\u65b9\u6cd5\uff0cAoS\u4f7f\u7528\u5c0f\u6a21\u578b\u8fdb\u884c\u76d1\u7763\u5b66\u4e60\uff0cLLMPrompt\u4f7f\u7528\u5927\u6a21\u578b\u8fdb\u884c\u96f6\u6837\u672c\u5b66\u4e60\uff0c\u4e24\u8005\u90fd\u80fd\u751f\u6210\u53ef\u7406\u89e3\u7684\u89e3\u91ca\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6cd5\u5f8bAI\u7cfb\u7edf\u7684\u7528\u6237\u63a5\u53d7\u5ea6\u3002"}}
{"id": "2512.21911", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21911", "abs": "https://arxiv.org/abs/2512.21911", "authors": ["Jikai Wang", "Jianchao Tan", "Yuxuan Hu", "Jiayu Qin", "Yerui Sun", "Yuchen Xie", "Xunliang Cai", "Juntao Li", "Min Zhang"], "title": "Accelerate Speculative Decoding with Sparse Computation in Verification", "comment": "Pre-print", "summary": "Speculative decoding accelerates autoregressive language model inference by verifying multiple draft tokens in parallel. However, the verification stage often becomes the dominant computational bottleneck, especially for long-context inputs and mixture-of-experts (MoE) models. Existing sparsification methods are designed primarily for standard token-by-token autoregressive decoding to remove substantial computational redundancy in LLMs. This work systematically adopts different sparse methods on the verification stage of the speculative decoding and identifies structured redundancy across multiple dimensions. Based on these observations, we propose a sparse verification framework that jointly sparsifies attention, FFN, and MoE components during the verification stage to reduce the dominant computation cost. The framework further incorporates an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without introducing additional training. Extensive experiments across summarization, question answering, and mathematical reasoning datasets demonstrate that the proposed methods achieve favorable efficiency-accuracy trade-offs, while maintaining stable acceptance length.", "AI": {"tldr": "\u63d0\u51fa\u7a00\u758f\u9a8c\u8bc1\u6846\u67b6\uff0c\u5728\u63a8\u6d4b\u89e3\u7801\u7684\u9a8c\u8bc1\u9636\u6bb5\u8054\u5408\u7a00\u758f\u5316\u6ce8\u610f\u529b\u3001FFN\u548cMoE\u7ec4\u4ef6\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c", "motivation": "\u63a8\u6d4b\u89e3\u7801\u901a\u8fc7\u5e76\u884c\u9a8c\u8bc1\u591a\u4e2a\u8349\u7a3ftoken\u52a0\u901f\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u4f46\u9a8c\u8bc1\u9636\u6bb5\u5728\u957f\u4e0a\u4e0b\u6587\u8f93\u5165\u548cMoE\u6a21\u578b\u4e2d\u6210\u4e3a\u4e3b\u8981\u8ba1\u7b97\u74f6\u9888\u3002\u73b0\u6709\u7a00\u758f\u5316\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u6807\u51c6token-by-token\u81ea\u56de\u5f52\u89e3\u7801\uff0c\u672a\u9488\u5bf9\u63a8\u6d4b\u89e3\u7801\u7684\u9a8c\u8bc1\u9636\u6bb5\u8fdb\u884c\u4f18\u5316", "method": "\u7cfb\u7edf\u5730\u5728\u63a8\u6d4b\u89e3\u7801\u7684\u9a8c\u8bc1\u9636\u6bb5\u91c7\u7528\u4e0d\u540c\u7a00\u758f\u65b9\u6cd5\uff0c\u8bc6\u522b\u591a\u7ef4\u5ea6\u7ed3\u6784\u5316\u5197\u4f59\uff0c\u63d0\u51fa\u8054\u5408\u7a00\u758f\u5316\u6ce8\u610f\u529b\u3001FFN\u548cMoE\u7ec4\u4ef6\u7684\u7a00\u758f\u9a8c\u8bc1\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u8de8\u8349\u7a3ftoken\u548c\u8de8\u5c42\u68c0\u7d22\u91cd\u7528\u7b56\u7565\u8fdb\u4e00\u6b65\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97", "result": "\u5728\u6458\u8981\u3001\u95ee\u7b54\u548c\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6709\u5229\u7684\u6548\u7387-\u51c6\u786e\u6027\u6743\u8861\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7a33\u5b9a\u7684\u63a5\u53d7\u957f\u5ea6", "conclusion": "\u63d0\u51fa\u7684\u7a00\u758f\u9a8c\u8bc1\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11\u63a8\u6d4b\u89e3\u7801\u9a8c\u8bc1\u9636\u6bb5\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u548cMoE\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.21919", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21919", "abs": "https://arxiv.org/abs/2512.21919", "authors": ["KaShun Shum", "Binyuan Hui", "Jiawei Chen", "Lei Zhang", "X. W.", "Jiaxi Yang", "Yuzhen Huang", "Junyang Lin", "Junxian He"], "title": "SWE-RM: Execution-free Feedback For Software Engineering Agents", "comment": "21 pages", "summary": "Execution-based feedback like unit testing is widely used in the development of coding agents through test-time scaling (TTS) and reinforcement learning (RL). This paradigm requires scalable and reliable collection of unit test cases to provide accurate feedback, and the resulting feedback is often sparse and cannot effectively distinguish between trajectories that are both successful or both unsuccessful. In contrast, execution-free feedback from reward models can provide more fine-grained signals without depending on unit test cases. Despite this potential, execution-free feedback for realistic software engineering (SWE) agents remains underexplored. Aiming to develop versatile reward models that are effective across TTS and RL, however, we observe that two verifiers with nearly identical TTS performance can nevertheless yield very different results in RL. Intuitively, TTS primarily reflects the model's ability to select the best trajectory, but this ability does not necessarily generalize to RL. To address this limitation, we identify two additional aspects that are crucial for RL training: classification accuracy and calibration. We then conduct comprehensive controlled experiments to investigate how to train a robust reward model that performs well across these metrics. In particular, we analyze the impact of various factors such as training data scale, policy mixtures, and data source composition. Guided by these investigations, we introduce SWE-RM, an accurate and robust reward model adopting a mixture-of-experts architecture with 30B total parameters and 3B activated during inference. SWE-RM substantially improves SWE agents on both TTS and RL performance. For example, it increases the accuracy of Qwen3-Coder-Flash from 51.6% to 62.0%, and Qwen3-Coder-Max from 67.0% to 74.6% on SWE-Bench Verified using TTS, achieving new state-of-the-art performance among open-source models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u7f16\u7801\u667a\u80fd\u4f53\u5f00\u53d1\u4e2d\u7684\u53cd\u9988\u673a\u5236\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e2\u9002\u7528\u4e8e\u6d4b\u8bd5\u65f6\u6269\u5c55(TTS)\u53c8\u9002\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60(RL)\u7684\u901a\u7528\u5956\u52b1\u6a21\u578bSWE-RM\uff0c\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6267\u884c\u7684\u53cd\u9988\uff08\u5982\u5355\u5143\u6d4b\u8bd5\uff09\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u9700\u8981\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u6d4b\u8bd5\u7528\u4f8b\u6536\u96c6\uff0c2\uff09\u53cd\u9988\u7a00\u758f\u4e14\u65e0\u6cd5\u6709\u6548\u533a\u5206\u90fd\u6210\u529f\u6216\u90fd\u5931\u8d25\u7684\u8f68\u8ff9\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u57fa\u4e8e\u5956\u52b1\u6a21\u578b\u7684\u6267\u884c\u65e0\u5173\u53cd\u9988\u80fd\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u4fe1\u53f7\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5728\u73b0\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f5c\u8005\u9996\u5148\u53d1\u73b0\u4e24\u4e2a\u5728TTS\u6027\u80fd\u76f8\u8fd1\u7684\u9a8c\u8bc1\u5668\u5728RL\u4e2d\u53ef\u80fd\u8868\u73b0\u8fe5\u5f02\uff0c\u56e0\u6b64\u8bc6\u522b\u51fa\u5bf9RL\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\u7684\u4e24\u4e2a\u989d\u5916\u65b9\u9762\uff1a\u5206\u7c7b\u51c6\u786e\u6027\u548c\u6821\u51c6\u3002\u901a\u8fc7\u5168\u9762\u7684\u63a7\u5236\u5b9e\u9a8c\uff0c\u7814\u7a76\u4e86\u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u3001\u7b56\u7565\u6df7\u5408\u3001\u6570\u636e\u6e90\u7ec4\u6210\u7b49\u56e0\u7d20\u5bf9\u5956\u52b1\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002\u57fa\u4e8e\u8fd9\u4e9b\u7814\u7a76\uff0c\u63d0\u51fa\u4e86SWE-RM\u5956\u52b1\u6a21\u578b\uff0c\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u603b\u53c2\u6570\u91cf30B\uff0c\u63a8\u7406\u65f6\u6fc0\u6d3b3B\u53c2\u6570\u3002", "result": "SWE-RM\u663e\u8457\u63d0\u5347\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u5728TTS\u548cRL\u4e0a\u7684\u6027\u80fd\u3002\u5728SWE-Bench Verified\u57fa\u51c6\u4e0a\uff0c\u4f7f\u7528TTS\u5c06Qwen3-Coder-Flash\u7684\u51c6\u786e\u7387\u4ece51.6%\u63d0\u5347\u523062.0%\uff0c\u5c06Qwen3-Coder-Max\u4ece67.0%\u63d0\u5347\u523074.6%\uff0c\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u8003\u8651\u5206\u7c7b\u51c6\u786e\u6027\u548c\u6821\u51c6\u7b49\u5173\u952e\u56e0\u7d20\uff0c\u53ef\u4ee5\u8bad\u7ec3\u51fa\u65e2\u9002\u7528\u4e8eTTS\u53c8\u9002\u7528\u4e8eRL\u7684\u7a33\u5065\u5956\u52b1\u6a21\u578b\u3002\u63d0\u51fa\u7684SWE-RM\u6a21\u578b\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u6709\u6548\u63d0\u5347\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u7684\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u7f16\u7801\u667a\u80fd\u4f53\u5f00\u53d1\u4e2d\u7684\u53cd\u9988\u7a00\u758f\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.21933", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21933", "abs": "https://arxiv.org/abs/2512.21933", "authors": ["Sachin Pawar", "Manoj Apte", "Kshitij Jadhav", "Girish Keshav Palshikar", "Nitin Ramrakhiyani"], "title": "Broken Words, Broken Performance: Effect of Tokenization on Performance of LLMs", "comment": "International Joint Conference on Natural Language Processing & Asia-Pacific Chapter of the Association for Computational Linguistics (IJCNLP-AACL 2025)", "summary": "Tokenization is the first step in training any Large Language Model (LLM), where the text is split into a sequence of tokens as per the model's fixed vocabulary. This tokenization in LLMs is different from the traditional tokenization in NLP where the text is split into a sequence of \"natural\" words. In LLMs, a natural word may also be broken into multiple tokens due to limited vocabulary size of the LLMs (e.g., Mistral's tokenizer splits \"martial\" into \"mart\" and \"ial\"). In this paper, we hypothesize that such breaking of natural words negatively impacts LLM performance on various NLP tasks. To quantify this effect, we propose a set of penalty functions that compute a tokenization penalty for a given text for a specific LLM, indicating how \"bad\" the tokenization is. We establish statistical significance of our hypothesis on multiple NLP tasks for a set of different LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLM\u5206\u8bcd\u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u91cf\u5316\u5206\u8bcd\u60e9\u7f5a\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5206\u8bcd\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4f20\u7edfNLP\u5206\u8bcd\u65b9\u5f0f\u4e0d\u540c\uff0c\u4f1a\u5c06\u81ea\u7136\u5355\u8bcd\u62c6\u5206\u6210\u591a\u4e2atoken\uff0c\u4f5c\u8005\u5047\u8bbe\u8fd9\u79cd\u5206\u8bcd\u65b9\u5f0f\u4f1a\u5bf9LLM\u5728\u5404\u79cdNLP\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u60e9\u7f5a\u51fd\u6570\uff0c\u7528\u4e8e\u8ba1\u7b97\u7ed9\u5b9a\u6587\u672c\u5728\u7279\u5b9aLLM\u4e0a\u7684\u5206\u8bcd\u60e9\u7f5a\uff0c\u91cf\u5316\u5206\u8bcd\u8d28\u91cf\u7684\u597d\u574f\u7a0b\u5ea6\u3002", "result": "\u5728\u591a\u4e2aNLP\u4efb\u52a1\u548c\u4e0d\u540cLLM\u4e0a\u9a8c\u8bc1\u4e86\u5206\u8bcd\u60e9\u7f5a\u5047\u8bbe\u7684\u7edf\u8ba1\u663e\u8457\u6027\u3002", "conclusion": "LLM\u5c06\u81ea\u7136\u5355\u8bcd\u62c6\u5206\u6210\u591a\u4e2atoken\u7684\u5206\u8bcd\u65b9\u5f0f\u786e\u5b9e\u5bf9\u6a21\u578b\u6027\u80fd\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u901a\u8fc7\u91cf\u5316\u5206\u8bcd\u60e9\u7f5a\u53ef\u4ee5\u8bc4\u4f30\u8fd9\u79cd\u5f71\u54cd\u3002"}}
{"id": "2512.21956", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21956", "abs": "https://arxiv.org/abs/2512.21956", "authors": ["Tal Halevi", "Yarden Tzach", "Ronit D. Gross", "Shalom Rosner", "Ido Kanter"], "title": "Self-attention vector output similarities reveal how machines pay attention", "comment": "22 pages, 13 figures", "summary": "The self-attention mechanism has significantly advanced the field of natural language processing, facilitating the development of advanced language-learning machines. Although its utility is widely acknowledged, the precise mechanisms of self-attention underlying its advanced learning and the quantitative characterization of this learning process remains an open research question. This study introduces a new approach for quantifying information processing within the self-attention mechanism. The analysis conducted on the BERT-12 architecture reveals that, in the final layers, the attention map focuses on sentence separator tokens, suggesting a practical approach to text segmentation based on semantic features. Based on the vector space emerging from the self-attention heads, a context similarity matrix, measuring the scalar product between two token vectors was derived, revealing distinct similarities between different token vector pairs within each head and layer. The findings demonstrated that different attention heads within an attention block focused on different linguistic characteristics, such as identifying token repetitions in a given text or recognizing a token of common appearance in the text and its surrounding context. This specialization is also reflected in the distribution of distances between token vectors with high similarity as the architecture progresses. The initial attention layers exhibit substantially long-range similarities; however, as the layers progress, a more short-range similarity develops, culminating in a preference for attention heads to create strong similarities within the same sentence. Finally, the behavior of individual heads was analyzed by examining the uniqueness of their most common tokens in their high similarity elements. Each head tends to focus on a unique token from the text and builds similarity pairs centered around it.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4fe1\u606f\u5904\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728BERT-12\u67b6\u6784\u4e0a\u7684\u5206\u6790\uff0c\u63ed\u793a\u4e86\u6ce8\u610f\u529b\u673a\u5236\u5728\u4e0d\u540c\u5c42\u548c\u5934\u4e2d\u7684\u8bed\u4e49\u5904\u7406\u6a21\u5f0f\uff0c\u5305\u62ec\u6587\u672c\u5206\u5272\u3001\u8bed\u8a00\u7279\u5f81\u8bc6\u522b\u548c\u76f8\u4f3c\u6027\u5206\u5e03\u6f14\u53d8\u3002", "motivation": "\u867d\u7136\u81ea\u6ce8\u610f\u529b\u673a\u5236\u663e\u8457\u63a8\u52a8\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u53d1\u5c55\uff0c\u4f46\u5176\u5177\u4f53\u7684\u5b66\u4e60\u673a\u5236\u548c\u91cf\u5316\u8868\u5f81\u4ecd\u7136\u662f\u4e00\u4e2a\u5f00\u653e\u7684\u7814\u7a76\u95ee\u9898\u3002\u7814\u7a76\u8005\u5e0c\u671b\u7406\u89e3\u81ea\u6ce8\u610f\u529b\u5982\u4f55\u5b9e\u73b0\u9ad8\u7ea7\u5b66\u4e60\uff0c\u5e76\u5b9a\u91cf\u63cf\u8ff0\u8fd9\u4e00\u5b66\u4e60\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u91cf\u5316\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4fe1\u606f\u5904\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u5728BERT-12\u67b6\u6784\u4e0a\u8fdb\u884c\u5206\u6790\u3002\u901a\u8fc7\u5206\u6790\u6ce8\u610f\u529b\u56fe\u3001\u6784\u5efa\u4e0a\u4e0b\u6587\u76f8\u4f3c\u6027\u77e9\u9635\uff08\u57fa\u4e8e\u6ce8\u610f\u529b\u5934\u4ea7\u751f\u7684\u5411\u91cf\u7a7a\u95f4\u7684\u6807\u91cf\u79ef\uff09\uff0c\u7814\u7a76\u4e0d\u540c\u5c42\u548c\u5934\u4e2dtoken\u5411\u91cf\u7684\u76f8\u4f3c\u6027\u5206\u5e03\u3002", "result": "1. \u5728\u6700\u540e\u51e0\u5c42\uff0c\u6ce8\u610f\u529b\u56fe\u805a\u7126\u4e8e\u53e5\u5b50\u5206\u9694\u7b26token\uff0c\u8fd9\u4e3a\u57fa\u4e8e\u8bed\u4e49\u7279\u5f81\u7684\u6587\u672c\u5206\u5272\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\u3002\n2. \u540c\u4e00\u6ce8\u610f\u529b\u5757\u4e2d\u7684\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u5173\u6ce8\u4e0d\u540c\u7684\u8bed\u8a00\u7279\u5f81\uff0c\u5982\u8bc6\u522b\u6587\u672c\u4e2d\u7684token\u91cd\u590d\u6216\u8bc6\u522b\u5e38\u89c1token\u53ca\u5176\u4e0a\u4e0b\u6587\u3002\n3. \u6ce8\u610f\u529b\u5c42\u4ece\u521d\u59cb\u7684\u957f\u8ddd\u79bb\u76f8\u4f3c\u6027\u9010\u6e10\u6f14\u53d8\u4e3a\u77ed\u8ddd\u79bb\u76f8\u4f3c\u6027\uff0c\u6700\u7ec8\u5728\u540c\u4e00\u53e5\u5b50\u5185\u5f62\u6210\u5f3a\u76f8\u4f3c\u6027\u3002\n4. \u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u503e\u5411\u4e8e\u5173\u6ce8\u6587\u672c\u4e2d\u7684\u72ec\u7279token\uff0c\u5e76\u56f4\u7ed5\u8be5token\u6784\u5efa\u76f8\u4f3c\u6027\u5bf9\u3002", "conclusion": "\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5728BERT\u67b6\u6784\u4e2d\u8868\u73b0\u51fa\u5c42\u6b21\u5316\u7684\u8bed\u4e49\u5904\u7406\u6a21\u5f0f\uff0c\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u4e13\u95e8\u5316\u5904\u7406\u4e0d\u540c\u7684\u8bed\u8a00\u7279\u5f81\uff0c\u5e76\u4e14\u968f\u7740\u7f51\u7edc\u6df1\u5ea6\u7684\u589e\u52a0\uff0c\u6ce8\u610f\u529b\u4ece\u957f\u8ddd\u79bb\u4f9d\u8d56\u8f6c\u5411\u5c40\u90e8\u53e5\u5b50\u7ed3\u6784\u3002\u8fd9\u79cd\u91cf\u5316\u5206\u6790\u65b9\u6cd5\u4e3a\u7406\u89e3\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u5de5\u4f5c\u539f\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2512.22087", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.22087", "abs": "https://arxiv.org/abs/2512.22087", "authors": ["Shukai Liu", "Jian Yang", "Bo Jiang", "Yizhi Li", "Jinyang Guo", "Xianglong Liu", "Bryan Dai"], "title": "Context as a Tool: Context Management for Long-Horizon SWE-Agents", "comment": null, "summary": "Agents based on large language models have recently shown strong potential on real-world software engineering (SWE) tasks that require long-horizon interaction with repository-scale codebases. However, most existing agents rely on append-only context maintenance or passively triggered compression heuristics, which often lead to context explosion, semantic drift, and degraded reasoning in long-running interactions. We propose CAT, a new context management paradigm that elevates context maintenance to a callable tool integrated into the decision-making process of agents. CAT formalizes a structured context workspace consisting of stable task semantics, condensed long-term memory, and high-fidelity short-term interactions, and enables agents to proactively compress historical trajectories into actionable summaries at appropriate milestones. To support context management for SWE-agents, we propose a trajectory-level supervision framework, CAT-GENERATOR, based on an offline data construction pipeline that injects context-management actions into complete interaction trajectories. Using this framework, we train a context-aware model, SWE-Compressor. Experiments on SWE-Bench-Verified demonstrate that SWE-Compressor reaches a 57.6% solved rate and significantly outperforms ReAct-based agents and static compression baselines, while maintaining stable and scalable long-horizon reasoning under a bounded context budget.", "AI": {"tldr": "CAT\u662f\u4e00\u79cd\u65b0\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u8303\u5f0f\uff0c\u5c06\u4e0a\u4e0b\u6587\u7ef4\u62a4\u63d0\u5347\u4e3a\u53ef\u8c03\u7528\u7684\u5de5\u5177\uff0c\u5e2e\u52a9\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u7a33\u5b9a\u3001\u53ef\u6269\u5c55\u7684\u957f\u65f6\u7a0b\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u5904\u7406\u4ed3\u5e93\u7ea7\u4ee3\u7801\u5e93\u7684\u957f\u65f6\u7a0b\u4ea4\u4e92\u4efb\u52a1\u65f6\uff0c\u901a\u5e38\u91c7\u7528\u4ec5\u8ffd\u52a0\u5f0f\u4e0a\u4e0b\u6587\u7ef4\u62a4\u6216\u88ab\u52a8\u89e6\u53d1\u7684\u538b\u7f29\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4e0a\u4e0b\u6587\u7206\u70b8\u3001\u8bed\u4e49\u6f02\u79fb\u548c\u63a8\u7406\u80fd\u529b\u4e0b\u964d\u3002", "method": "\u63d0\u51faCAT\u4e0a\u4e0b\u6587\u7ba1\u7406\u8303\u5f0f\uff0c\u6784\u5efa\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u5de5\u4f5c\u7a7a\u95f4\uff08\u7a33\u5b9a\u4efb\u52a1\u8bed\u4e49\u3001\u538b\u7f29\u7684\u957f\u671f\u8bb0\u5fc6\u3001\u9ad8\u4fdd\u771f\u77ed\u671f\u4ea4\u4e92\uff09\uff0c\u4f7f\u4ee3\u7406\u80fd\u5728\u9002\u5f53\u65f6\u673a\u4e3b\u52a8\u5c06\u5386\u53f2\u8f68\u8ff9\u538b\u7f29\u4e3a\u53ef\u64cd\u4f5c\u7684\u6458\u8981\u3002\u901a\u8fc7CAT-GENERATOR\u6846\u67b6\u8bad\u7ec3\u4e0a\u4e0b\u6587\u611f\u77e5\u6a21\u578bSWE-Compressor\u3002", "result": "\u5728SWE-Bench-Verified\u4e0a\uff0cSWE-Compressor\u8fbe\u523057.6%\u7684\u89e3\u51b3\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eReAct\u7684\u4ee3\u7406\u548c\u9759\u6001\u538b\u7f29\u57fa\u7ebf\uff0c\u540c\u65f6\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u9884\u7b97\u4e0b\u4fdd\u6301\u7a33\u5b9a\u4e14\u53ef\u6269\u5c55\u7684\u957f\u65f6\u7a0b\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "CAT\u901a\u8fc7\u5c06\u4e0a\u4e0b\u6587\u7ba1\u7406\u4f5c\u4e3a\u53ef\u8c03\u7528\u5de5\u5177\u96c6\u6210\u5230\u4ee3\u7406\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u65f6\u7a0b\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u4ee3\u7406\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2512.22100", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22100", "abs": "https://arxiv.org/abs/2512.22100", "authors": ["Duygu Altinok"], "title": "Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis", "comment": "under review by Springer", "summary": "Evaluating the performance of various model architectures, such as transformers, large language models (LLMs), and other NLP systems, requires comprehensive benchmarks that measure performance across multiple dimensions. Among these, the evaluation of natural language understanding (NLU) is particularly critical as it serves as a fundamental criterion for assessing model capabilities. Thus, it is essential to establish benchmarks that enable thorough evaluation and analysis of NLU abilities from diverse perspectives. While the GLUE benchmark has set a standard for evaluating English NLU, similar benchmarks have been developed for other languages, such as CLUE for Chinese, FLUE for French, and JGLUE for Japanese. However, no comparable benchmark currently exists for the Turkish language. To address this gap, we introduce TrGLUE, a comprehensive benchmark encompassing a variety of NLU tasks for Turkish. In addition, we present SentiTurca, a specialized benchmark for sentiment analysis. To support researchers, we also provide fine-tuning and evaluation code for transformer-based models, facilitating the effective use of these benchmarks. TrGLUE comprises Turkish-native corpora curated to mirror the domains and task formulations of GLUE-style evaluations, with labels obtained through a semi-automated pipeline that combines strong LLM-based annotation, cross-model agreement checks, and subsequent human validation. This design prioritizes linguistic naturalness, minimizes direct translation artifacts, and yields a scalable, reproducible workflow. With TrGLUE, our goal is to establish a robust evaluation framework for Turkish NLU, empower researchers with valuable resources, and provide insights into generating high-quality semi-automated datasets.", "AI": {"tldr": "TrGLUE\u662f\u9996\u4e2a\u571f\u8033\u5176\u8bed\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542bSentiTurca\u60c5\u611f\u5206\u6790\u4e13\u7528\u57fa\u51c6\uff0c\u65e8\u5728\u586b\u8865\u571f\u8033\u5176\u8bed\u7f3a\u4e4f\u7c7b\u4f3cGLUE\u57fa\u51c6\u7684\u7a7a\u767d\u3002", "motivation": "\u867d\u7136\u82f1\u8bed\u6709GLUE\u57fa\u51c6\uff0c\u4e2d\u6587\u6709CLUE\uff0c\u6cd5\u8bed\u6709FLUE\uff0c\u65e5\u8bed\u6709JGLUE\uff0c\u4f46\u571f\u8033\u5176\u8bed\u4e00\u76f4\u7f3a\u4e4f\u7c7b\u4f3c\u7684\u7efc\u5408\u6027NLU\u8bc4\u4f30\u57fa\u51c6\uff0c\u8fd9\u963b\u788d\u4e86\u5bf9\u571f\u8033\u5176\u8bed\u6a21\u578b\u80fd\u529b\u7684\u5168\u9762\u8bc4\u4f30\u3002", "method": "\u521b\u5efa\u571f\u8033\u5176\u672c\u571f\u8bed\u6599\u5e93\uff0c\u91c7\u7528\u534a\u81ea\u52a8\u5316\u6807\u6ce8\u6d41\u7a0b\uff1a\u7ed3\u5408\u5f3a\u5927\u7684LLM\u57fa\u7840\u6807\u6ce8\u3001\u8de8\u6a21\u578b\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u540e\u7eed\u4eba\u5de5\u9a8c\u8bc1\uff0c\u4f18\u5148\u8003\u8651\u8bed\u8a00\u81ea\u7136\u6027\uff0c\u51cf\u5c11\u7ffb\u8bd1\u75d5\u8ff9\u3002", "result": "\u63a8\u51fa\u4e86TrGLUE\u57fa\u51c6\u6d4b\u8bd5\u548cSentiTurca\u60c5\u611f\u5206\u6790\u57fa\u51c6\uff0c\u63d0\u4f9b\u57fa\u4e8eTransformer\u6a21\u578b\u7684\u5fae\u8c03\u548c\u8bc4\u4f30\u4ee3\u7801\uff0c\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u590d\u73b0\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "TrGLUE\u4e3a\u571f\u8033\u5176\u8bedNLU\u5efa\u7acb\u4e86\u7a33\u5065\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u5e76\u4e3a\u751f\u6210\u9ad8\u8d28\u91cf\u534a\u81ea\u52a8\u5316\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
