<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 28]
- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data](https://arxiv.org/abs/2512.19864)
*Shashi Kant Gupta,Arijeet Pramanik,Jerrin John Thomas,Regina Schwind,Lauren Wiener,Avi Raju,Jeremy Kornbluth,Yanshan Wang,Zhaohui Su,Hrituraj Singh*

Main category: cs.CL

TL;DR: 提出基于LLM的智能体框架，从电子健康记录中自动提取结构化肿瘤学数据，在40万份临床笔记上实现高精度提取，显著降低人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中的非结构化笔记包含丰富的临床信息，但手动提取成本高且不可扩展。现有自动化方法通常局限于特定场景，无法处理患者级别的信息整合，且难以应对临床文档中的矛盾信息。

Method: 提出智能体框架，将复杂肿瘤数据提取分解为模块化、自适应的任务。使用大型语言模型作为推理智能体，配备上下文敏感检索和迭代合成能力，从真实世界肿瘤学笔记中全面提取结构化临床变量。

Result: 在包含40万份非结构化临床笔记和扫描PDF报告的大规模数据集上评估，平均F1分数达到0.93，103个肿瘤学特定临床变量中有100个超过0.85，关键变量（如生物标志物和药物）超过0.95。系统集成到数据管理流程中获得了0.94的直接人工批准率。

Conclusion: 这是首个基于LLM智能体的端到端结构化肿瘤数据提取应用，能够大规模处理真实世界临床数据，显著提高提取准确性并降低成本。

Abstract: Unstructured notes within the electronic health record (EHR) contain rich clinical information vital for cancer treatment decision making and research, yet reliably extracting structured oncology data remains challenging due to extensive variability, specialized terminology, and inconsistent document formats. Manual abstraction, although accurate, is prohibitively costly and unscalable. Existing automated approaches typically address narrow scenarios - either using synthetic datasets, restricting focus to document-level extraction, or isolating specific clinical variables (e.g., staging, biomarkers, histology) - and do not adequately handle patient-level synthesis across the large number of clinical documents containing contradictory information. In this study, we propose an agentic framework that systematically decomposes complex oncology data extraction into modular, adaptive tasks. Specifically, we use large language models (LLMs) as reasoning agents, equipped with context-sensitive retrieval and iterative synthesis capabilities, to exhaustively and comprehensively extract structured clinical variables from real-world oncology notes. Evaluated on a large-scale dataset of over 400,000 unstructured clinical notes and scanned PDF reports spanning 2,250 cancer patients, our method achieves an average F1-score of 0.93, with 100 out of 103 oncology-specific clinical variables exceeding 0.85, and critical variables (e.g., biomarkers and medications) surpassing 0.95. Moreover, integration of the agentic system into a data curation workflow resulted in 0.94 direct manual approval rate, significantly reducing annotation costs. To our knowledge, this constitutes the first exhaustive, end-to-end application of LLM-based agents for structured oncology data extraction at scale

</details>


### [2] [How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse](https://arxiv.org/abs/2512.19903)
*Kirk Vanacore,Rene F. Kizilcec*

Main category: cs.CL

TL;DR: LLMs在教育任务中的基线性能评估：通过多种提示方法测试LLMs对真实课堂指令动作的分类能力，发现few-shot提示显著提升性能但仍有可靠性限制。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在教育技术中广泛应用，需要了解其在未经大量定制的情况下解释真实教育场景的能力，这对设定期望和基准测试很重要。

Method: 比较六个LLMs在课堂指令动作分类任务上的基线性能，评估零样本、单样本和少样本提示方法，使用专家编码标注作为基准。

Result: 零样本表现中等，少样本提示显著提升了最先进模型的性能（Cohen's Kappa = 0.58），但性能因指令动作类型而异，高召回率常伴随假阳性增加。

Conclusion: 基础模型在解释教学话语方面表现出有意义但有限的能力，提示设计有助于展现能力但无法消除根本的可靠性限制。

Abstract: Large language models (LLMs) are increasingly adopted in educational technologies for a variety of tasks, from generating instructional materials and assisting with assessment design to tutoring. While prior work has investigated how models can be adapted or optimized for specific tasks, far less is known about how well LLMs perform at interpreting authentic educational scenarios without significant customization. As LLM-based systems become widely adopted by learners and educators in everyday academic contexts, understanding their out-of-the-box capabilities is increasingly important for setting expectations and benchmarking. We compared six LLMs to estimate their baseline performance on a simple but important task: classifying instructional moves in authentic classroom transcripts. We evaluated typical prompting methods: zero-shot, one-shot, and few-shot prompting. We found that while zero-shot performance was moderate, providing comprehensive examples (few-shot prompting) significantly improved performance for state-of-the-art models, with the strongest configuration reaching Cohen's Kappa = 0.58 against expert-coded annotations. At the same time, improvements were neither uniform nor complete: performance varied considerably by instructional move, and higher recall frequently came at the cost of increased false positives. Overall, these findings indicate that foundation models demonstrate meaningful yet limited capacity to interpret instructional discourse, with prompt design helping to surface capability but not eliminating fundamental reliability constraints.

</details>


### [3] [Counterfactual LLM-based Framework for Measuring Rhetorical Style](https://arxiv.org/abs/2512.19908)
*Jingyi Qiu,Hong Chen,Zongyi Li*

Main category: cs.CL

TL;DR: 本研究开发了一个基于LLM的反事实框架来量化机器学习论文中的修辞风格，发现愿景式表达能显著预测论文的引用和媒体关注度，且2023年后修辞强度急剧上升主要由LLM写作辅助工具驱动。


<details>
  <summary>Details</summary>
Motivation: AI领域对机器学习论文中"炒作"现象的担忧日益增长，但现有方法难以将修辞风格与实质性内容分离。由于大胆语言可能源于强大的实证结果或仅仅是修辞风格，区分二者一直是个挑战。

Method: 引入基于LLM的反事实框架：1) 多个LLM修辞角色从相同实质性内容生成反事实写作；2) LLM评判员通过成对比较评估这些写作；3) 使用Bradley-Terry模型聚合结果。该方法应用于2017-2025年间的8,485篇ICLR投稿，生成了超过25万篇反事实写作。

Result: 1) 愿景式表达能显著预测下游关注度（包括引用和媒体关注），即使控制了同行评审评估；2) 2023年后修辞强度急剧上升；3) 实证证据表明这种上升主要由LLM写作辅助工具的采用驱动；4) 框架可靠性得到验证（对角色选择的鲁棒性和LLM判断与人工标注的高相关性）。

Conclusion: LLM可以作为测量和改进科学评估的工具，本研究框架能够可靠地量化修辞风格，揭示了修辞风格对论文影响力的重要作用，以及LLM写作辅助对学术写作风格的显著影响。

Abstract: The rise of AI has fueled growing concerns about ``hype'' in machine learning papers, yet a reliable way to quantify rhetorical style independently of substantive content has remained elusive. Because bold language can stem from either strong empirical results or mere rhetorical style, it is often difficult to distinguish between the two. To disentangle rhetorical style from substantive content, we introduce a counterfactual, LLM-based framework: multiple LLM rhetorical personas generate counterfactual writings from the same substantive content, an LLM judge compares them through pairwise evaluations, and the outcomes are aggregated using a Bradley--Terry model. Applying this method to 8,485 ICLR submissions sampled from 2017 to 2025, we generate more than 250,000 counterfactual writings and provide a large-scale quantification of rhetorical style in ML papers. We find that visionary framing significantly predicts downstream attention, including citations and media attention, even after controlling for peer-review evaluations. We also observe a sharp rise in rhetorical strength after 2023, and provide empirical evidence showing that this increase is largely driven by the adoption of LLM-based writing assistance. The reliability of our framework is validated by its robustness to the choice of personas and the high correlation between LLM judgments and human annotations. Our work demonstrates that LLMs can serve as instruments to measure and improve scientific evaluation.

</details>


### [4] [PRISM: A Personality-Driven Multi-Agent Framework for Social Media Simulation](https://arxiv.org/abs/2512.19933)
*Zhixiang Lu,Xueyuan Deng,Yiran Liu,Yulong Li,Qiang Yan,Imran Razzak,Jionglong Su*

Main category: cs.CL

TL;DR: 提出了PRISM模型，结合随机微分方程和基于MBTI的人格条件部分可观测马尔可夫决策过程，用于模拟在线意见动态中的心理异质性。


<details>
  <summary>Details</summary>
Motivation: 传统基于代理的模型在模拟在线极化时存在局限性，因为它们通常假设同质性，忽略了驱动极化的心理异质性。这种简化阻碍了对个体认知偏见与信息传播之间相互作用的理解，从而难以从机制上理解意识形态分歧如何被放大。

Method: 提出了人格折射智能仿真模型（PRISM），这是一个混合框架：1）使用随机微分方程（SDE）模拟连续的情绪演化；2）使用基于人格条件的部分可观测马尔可夫决策过程（PC-POMDP）模拟离散决策。与连续特质方法不同，PRISM为多模态大语言模型代理分配了基于MBTI的认知策略，并通过从大规模社交媒体数据集获得的数据驱动先验进行初始化。

Result: PRISM在人格一致性方面表现出色，与人类真实数据相符，显著优于标准的同质性模型和Big Five基准模型。该框架能够有效复现理性抑制和情感共鸣等涌现现象，为分析复杂的社交媒体生态系统提供了一个强大的工具。

Conclusion: PRISM框架通过整合连续情绪演化和基于人格的离散决策，成功捕捉了在线意见动态中的心理异质性，为理解社交媒体中的极化机制提供了更精确的建模工具，并能模拟复杂的涌现社会现象。

Abstract: Traditional agent-based models (ABMs) of opinion dynamics often fail to capture the psychological heterogeneity driving online polarization due to simplistic homogeneity assumptions. This limitation obscures the critical interplay between individual cognitive biases and information propagation, thereby hindering a mechanistic understanding of how ideological divides are amplified. To address this challenge, we introduce the Personality-Refracted Intelligent Simulation Model (PRISM), a hybrid framework coupling stochastic differential equations (SDE) for continuous emotional evolution with a personality-conditional partially observable Markov decision process (PC-POMDP) for discrete decision-making. In contrast to continuous trait approaches, PRISM assigns distinct Myers-Briggs Type Indicator (MBTI) based cognitive policies to multimodal large language model (MLLM) agents, initialized via data-driven priors from large-scale social media datasets. PRISM achieves superior personality consistency aligned with human ground truth, significantly outperforming standard homogeneous and Big Five benchmarks. This framework effectively replicates emergent phenomena such as rational suppression and affective resonance, offering a robust tool for analyzing complex social media ecosystems.

</details>


### [5] [Retrieval-augmented Prompt Learning for Pre-trained Foundation Models](https://arxiv.org/abs/2512.20145)
*Xiang Chen,Yixin Ou,Quan Feng,Lei Li,Piji Li,Haibo Ye,Sheng-Jun Huang,Shuofei Qiao,Shumin Deng,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: RetroPrompt是一种新型提示学习方法，通过检索机制从知识库中获取相关上下文信息，减少死记硬背依赖，提升模型在零样本和少样本场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统提示学习方法仍遵循参数化学习范式，在完全监督训练过程中可能难以充分利用非典型实例，并容易对浅层模式过拟合，导致记忆与泛化之间的平衡不佳。

Method: 提出RetroPrompt方法，利用训练数据生成的公开知识库，在输入、训练和推理阶段集成检索机制，使模型能够主动从语料库中检索相关上下文信息来增强可用线索。

Result: 在自然语言处理和计算机视觉任务的多个数据集上进行全面实验，证明RetroPrompt在零样本和少样本场景中均表现出优越性能，有效减少了对死记硬背的依赖。

Conclusion: RetroPrompt通过解耦知识和记忆，实现了记忆与泛化之间的更好平衡，为预训练基础模型的提示学习提供了更有效的范式。

Abstract: The pre-trained foundation models (PFMs) have become essential for facilitating large-scale multimodal learning. Researchers have effectively employed the ``pre-train, prompt, and predict'' paradigm through prompt learning to induce improved few-shot performance. However, prompt learning approaches for PFMs still follow a parametric learning paradigm. As such, the stability of generalization in memorization and rote learning can be compromised. More specifically, conventional prompt learning might face difficulties in fully utilizing atypical instances and avoiding overfitting to shallow patterns with limited data during the process of fully-supervised training. To overcome these constraints, we present our approach, named RetroPrompt, which aims to achieve a balance between memorization and generalization by decoupling knowledge from mere memorization. Unlike traditional prompting methods, RetroPrompt leverages a publicly accessible knowledge base generated from the training data and incorporates a retrieval mechanism throughout the input, training, and inference stages. This enables the model to actively retrieve relevant contextual information from the corpus, thereby enhancing the available cues. We conduct comprehensive experiments on a variety of datasets across natural language processing and computer vision tasks to demonstrate the superior performance of our proposed approach, RetroPrompt, in both zero-shot and few-shot scenarios. Through detailed analysis of memorization patterns, we observe that RetroPrompt effectively reduces the reliance on rote memorization, leading to enhanced generalization.

</details>


### [6] [Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems](https://arxiv.org/abs/2512.19950)
*Heet Bodara,Md Masum Mushfiq,Isma Farah Siddiqui*

Main category: cs.CL

TL;DR: 该研究提出了一种结合可控LLM对话生成与语调分类的方法，系统性检测大型语言模型在对话中隐含的语调偏见，发现即使中性提示也会产生系统性语调偏差。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在对话系统中应用日益广泛，但其回应常带有微妙的语调偏见（如过度礼貌、愉悦或谨慎），这些偏见会影响用户对信任、同理心和公平性的感知，需要系统性检测。

Method: 1) 创建两个合成对话数据集：中性提示生成的数据集和明确引导生成积极/消极语调的数据集；2) 使用预训练的DistilBERT模型进行弱监督标注；3) 训练多个分类器检测语调模式；4) 采用集成模型提升检测性能。

Result: 即使中性数据集也显示出一致的语调偏差，表明偏见源于模型底层对话风格。集成模型在语调检测上达到0.92的宏观F1分数，证明语调偏见是系统性、可测量且与设计公平可信对话AI相关的重要问题。

Conclusion: 语调偏见是大型语言模型的隐藏行为特征，可通过可控对话合成与语调分类相结合的方法进行系统性检测。这一发现对设计公平、可信赖的对话AI系统具有重要意义。

Abstract: Large Language Models are increasingly used in conversational systems such as digital personal assistants, shaping how people interact with technology through language. While their responses often sound fluent and natural, they can also carry subtle tone biases such as sounding overly polite, cheerful, or cautious even when neutrality is expected. These tendencies can influence how users perceive trust, empathy, and fairness in dialogue. In this study, we explore tone bias as a hidden behavioral trait of large language models. The novelty of this research lies in the integration of controllable large language model based dialogue synthesis with tone classification models, enabling robust and ethical emotion recognition in personal assistant interactions. We created two synthetic dialogue datasets, one generated from neutral prompts and another explicitly guided to produce positive or negative tones. Surprisingly, even the neutral set showed consistent tonal skew, suggesting that bias may stem from the model's underlying conversational style. Using weak supervision through a pretrained DistilBERT model, we labeled tones and trained several classifiers to detect these patterns. Ensemble models achieved macro F1 scores up to 0.92, showing that tone bias is systematic, measurable, and relevant to designing fair and trustworthy conversational AI.

</details>


### [7] [Schoenfeld's Anatomy of Mathematical Reasoning by Language Models](https://arxiv.org/abs/2512.19995)
*Ming Li,Chenrui Fan,Yize Cheng,Soheil Feizi,Tianyi Zhou*

Main category: cs.CL

TL;DR: 论文提出ThinkARM框架，使用Schoenfeld的Episode理论将LLM推理轨迹抽象为功能步骤，揭示数学问题解决中的思维动态和结构差异。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型越来越多地展示推理轨迹，但其底层的认知结构和步骤难以通过表层统计来识别和分析。需要一种中间尺度的框架来明确抽象推理步骤。

Method: 采用Schoenfeld的Episode理论作为归纳性中间尺度视角，提出ThinkARM框架，将推理轨迹明确抽象为分析、探索、实施、验证等功能性推理步骤。

Result: 应用于不同模型的数学问题解决时，该抽象揭示了可重复的思维动态和推理模型与非推理模型之间的结构差异，这些差异在token级视图中不明显。诊断案例研究显示探索功能是关键分支步骤与正确性相关，效率导向方法选择性地抑制评估反馈步骤而非均匀缩短响应。

Conclusion: Episode级表示使推理步骤明确化，能够系统分析现代语言模型中推理的结构化、稳定化和变化方式。

Abstract: Large language models increasingly expose reasoning traces, yet their underlying cognitive structure and steps remain difficult to identify and analyze beyond surface-level statistics. We adopt Schoenfeld's Episode Theory as an inductive, intermediate-scale lens and introduce ThinkARM (Anatomy of Reasoning in Models), a scalable framework that explicitly abstracts reasoning traces into functional reasoning steps such as Analysis, Explore, Implement, Verify, etc. When applied to mathematical problem solving by diverse models, this abstraction reveals reproducible thinking dynamics and structural differences between reasoning and non-reasoning models, which are not apparent from token-level views. We further present two diagnostic case studies showing that exploration functions as a critical branching step associated with correctness, and that efficiency-oriented methods selectively suppress evaluative feedback steps rather than uniformly shortening responses. Together, our results demonstrate that episode-level representations make reasoning steps explicit, enabling systematic analysis of how reasoning is structured, stabilized, and altered in modern language models.

</details>


### [8] [Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents](https://arxiv.org/abs/2512.20092)
*Yiming Du,Baojun Wang,Yifan Xiang,Zhaowei Wang,Wenyu Huang,Boyang Xue,Bin Liang,Xingshan Zeng,Fei Mi,Haoli Bai,Lifeng Shang,Jeff Z. Pan,Yuxin Jiang,Kam-Fai Wong*

Main category: cs.CL

TL;DR: Memory-T1使用强化学习训练时间感知记忆选择策略，通过粗到细的方法从长对话历史中精确选择证据会话，显著提升时序推理性能


<details>
  <summary>Details</summary>
Motivation: 现有长上下文模型在处理冗长、多会话对话时，难以准确识别时序相关信息，导致推理性能显著下降

Method: 采用强化学习框架，首先使用时序和相关性过滤器将对话历史修剪为候选集，然后由RL代理选择精确的证据会话。RL训练采用多级奖励函数优化答案准确性、证据基础和时序一致性

Result: 在Time-Dialog基准测试中，Memory-T1将7B模型的总体得分提升至67.0%，创下开源模型的新SOTA，优于14B基线10.2%。在128k token的长对话中仍保持鲁棒性

Conclusion: Memory-T1通过时间感知记忆选择策略有效解决了长对话时序推理问题，时序一致性和证据基础奖励共同贡献了15.0%的性能提升，证明了框架在噪声长对话历史中的有效性

Abstract: Temporal reasoning over long, multi-session dialogues is a critical capability for conversational agents. However, existing works and our pilot study have shown that as dialogue histories grow in length and accumulate noise, current long-context models struggle to accurately identify temporally pertinent information, significantly impairing reasoning performance. To address this, we introduce Memory-T1, a framework that learns a time-aware memory selection policy using reinforcement learning (RL). It employs a coarse-to-fine strategy, first pruning the dialogue history into a candidate set using temporal and relevance filters, followed by an RL agent that selects the precise evidence sessions. The RL training is guided by a multi-level reward function optimizing (i) answer accuracy, (ii) evidence grounding, and (iii) temporal consistency. In particular, the temporal consistency reward provides a dense signal by evaluating alignment with the query time scope at both the session-level (chronological proximity) and the utterance-level (chronological fidelity), enabling the agent to resolve subtle chronological ambiguities. On the Time-Dialog benchmark, Memory-T1 boosts a 7B model to an overall score of 67.0\%, establishing a new state-of-the-art performance for open-source models and outperforming a 14B baseline by 10.2\%. Ablation studies show temporal consistency and evidence grounding rewards jointly contribute to a 15.0\% performance gain. Moreover, Memory-T1 maintains robustness up to 128k tokens, where baseline models collapse, proving effectiveness against noise in extensive dialogue histories. The code and datasets are publicly available at https://github.com/Elvin-Yiming-Du/Memory-T1/

</details>


### [9] [A Novel Graph-Sequence Learning Model for Inductive Text Classification](https://arxiv.org/abs/2512.20097)
*Zuo Wang,Ye Yuan*

Main category: cs.CL

TL;DR: TextGSL是一种新颖的图-序列学习模型，用于归纳式文本分类，通过构建多边类型文本图并结合Transformer层，有效融合多样结构信息和序列信息。


<details>
  <summary>Details</summary>
Motivation: 现有基于图神经网络的文本分类方法存在两个主要限制：1) 未能充分考虑词对间的多样化结构信息（如共现、句法、语义）；2) 在文本图结构学习模块中忽略了序列信息，且无法处理包含新词和新关系的文本。

Method: 提出TextGSL模型：1) 为每个文本构建单文本级图，基于词对间的多样化关系建立不同的边类型；2) 设计自适应多边消息传递范式来聚合词对间的多样结构信息；3) 通过加入Transformer层来捕捉文本数据的序列信息。

Result: 在多个基准数据集上的实验结果表明，TextGSL在准确性方面优于多个强基线模型。

Conclusion: TextGSL通过同时考虑多样化的结构信息和序列信息，能够学习更具区分性的文本表示，有效解决了现有图神经网络文本分类方法的局限性。

Abstract: Text classification plays an important role in various downstream text-related tasks, such as sentiment analysis, fake news detection, and public opinion analysis. Recently, text classification based on Graph Neural Networks (GNNs) has made significant progress due to their strong capabilities of structural relationship learning. However, these approaches still face two major limitations. First, these approaches fail to fully consider the diverse structural information across word pairs, e.g., co-occurrence, syntax, and semantics. Furthermore, they neglect sequence information in the text graph structure information learning module and can not classify texts with new words and relations. In this paper, we propose a Novel Graph-Sequence Learning Model for Inductive Text Classification (TextGSL) to address the previously mentioned issues. More specifically, we construct a single text-level graph for all words in each text and establish different edge types based on the diverse relationships between word pairs. Building upon this, we design an adaptive multi-edge message-passing paradigm to aggregate diverse structural information between word pairs. Additionally, sequential information among text data can be captured by the proposed TextGSL through the incorporation of Transformer layers. Therefore, TextGSL can learn more discriminative text representations. TextGSL has been comprehensively compared with several strong baselines. The experimental results on diverse benchmarking datasets demonstrate that TextGSL outperforms these baselines in terms of accuracy.

</details>


### [10] [ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language](https://arxiv.org/abs/2512.20111)
*Aly Lidayan,Jakob Bjorner,Satvik Golechha,Kartik Goyal,Alane Suhr*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As the length of sequential decision-making tasks increases, it becomes computationally impractical to keep full interaction histories in context. We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training. ABBEL replaces long multi-step interaction history by a belief state, i.e., a natural language summary of what has been discovered about task-relevant unknowns. Under ABBEL, at each step the agent first updates a prior belief with the most recent observation from the environment to form a posterior belief, then uses only the posterior to select an action. We systematically evaluate frontier models under ABBEL across six diverse multi-step environments, finding that ABBEL supports generating interpretable beliefs while maintaining near-constant memory use over interaction steps. However, bottleneck approaches are generally prone to error propagation, which we observe causing inferior performance when compared to the full context setting due to errors in belief updating. Therefore, we train LLMs to generate and act on beliefs within the ABBEL framework via reinforcement learning (RL). We experiment with belief grading, to reward higher quality beliefs, as well as belief length penalties to reward more compressed beliefs. Our experiments demonstrate the ability of RL to improve ABBEL's performance beyond the full context setting, while using less memory than contemporaneous approaches.

</details>


### [11] [M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation](https://arxiv.org/abs/2512.20136)
*Hyeongcheol Park,Jiyoung Seo,Jaewon Mun,Hogun Park,Wonmin Byeon,Sung June Kim,Hyeonsoo Im,JeungSub Lee,Sangpil Kim*

Main category: cs.CL

TL;DR: M³KG-RAG：一个多跳多模态知识图谱增强的检索增强生成框架，通过构建多跳MMKG和GRASP机制，提升多模态大语言模型在音频-视觉领域的推理深度和答案忠实度。


<details>
  <summary>Details</summary>
Motivation: 当前多模态RAG在音频-视觉领域面临两大挑战：1）现有MMKG模态覆盖有限且缺乏多跳连接性；2）仅基于共享嵌入空间的相似性检索无法过滤无关或冗余知识。

Method: 提出M³KG-RAG框架：1）使用轻量级多智能体流水线构建多跳MMKG（M³KG），包含丰富的多模态实体三元组；2）引入GRASP机制，实现查询的精确实体接地、答案支持相关性评估和冗余上下文剪枝。

Result: 在多个多模态基准测试上的广泛实验表明，M³KG-RAG显著提升了MLLMs的多模态推理和接地能力，优于现有方法。

Conclusion: M³KG-RAG通过构建多跳多模态知识图谱和引入GRASP机制，有效解决了多模态RAG在音频-视觉领域的挑战，显著增强了多模态大语言模型的推理和答案生成质量。

Abstract: Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, and 2) retrieval based solely on similarity in a shared multimodal embedding space, which fails to filter out off-topic or redundant knowledge. To address these limitations, we propose M$^3$KG-RAG, a Multi-hop Multimodal Knowledge Graph-enhanced RAG that retrieves query-aligned audio-visual knowledge from MMKGs, improving reasoning depth and answer faithfulness in MLLMs. Specifically, we devise a lightweight multi-agent pipeline to construct multi-hop MMKG (M$^3$KG), which contains context-enriched triplets of multimodal entities, enabling modality-wise retrieval based on input queries. Furthermore, we introduce GRASP (Grounded Retrieval And Selective Pruning), which ensures precise entity grounding to the query, evaluates answer-supporting relevance, and prunes redundant context to retain only knowledge essential for response generation. Extensive experiments across diverse multimodal benchmarks demonstrate that M$^3$KG-RAG significantly enhances MLLMs' multimodal reasoning and grounding over existing approaches.

</details>


### [12] [Multi-hop Reasoning via Early Knowledge Alignment](https://arxiv.org/abs/2512.20144)
*Yuxin Wang,Shicheng Fang,Bo Wang,Qi Luo,Xuanjing Huang,Yining Zheng,Xipeng Qiu*

Main category: cs.CL

TL;DR: EKA（早期知识对齐）通过在迭代RAG系统中引入检索知识对齐模块，在规划前将LLM与检索集对齐，显著提升多跳问答的检索精度和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有迭代RAG系统在规划问题分解时未充分利用检索语料库信息，导致检索效率低下和推理链错误级联，影响多跳问答性能。

Method: 提出Early Knowledge Alignment (EKA)模块，在规划前将LLM与检索语料库知识对齐，利用上下文相关的检索知识建立更强的推理基础。

Result: 在六个标准RAG数据集上的实验表明，EKA显著提升检索精度、减少级联错误，同时提高性能和效率。从熵的角度分析显示该方法减少不必要的探索。

Conclusion: EKA作为无需训练的推理策略，可扩展到大型模型，在多种数据集和检索语料库上表现出稳健性，推动了迭代RAG系统的发展。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for Large Language Models (LLMs) to address knowledge-intensive queries requiring domain-specific or up-to-date information. To handle complex multi-hop questions that are challenging for single-step retrieval, iterative RAG approaches incorporating reinforcement learning have been proposed. However, existing iterative RAG systems typically plan to decompose questions without leveraging information about the available retrieval corpus, leading to inefficient retrieval and reasoning chains that cascade into suboptimal performance. In this paper, we introduce Early Knowledge Alignment (EKA), a simple but effective module that aligns LLMs with retrieval set before planning in iterative RAG systems with contextually relevant retrieved knowledge. Extensive experiments on six standard RAG datasets demonstrate that by establishing a stronger reasoning foundation, EKA significantly improves retrieval precision, reduces cascading errors, and enhances both performance and efficiency. Our analysis from an entropy perspective demonstrate that incorporating early knowledge reduces unnecessary exploration during the reasoning process, enabling the model to focus more effectively on relevant information subsets. Moreover, EKA proves effective as a versatile, training-free inference strategy that scales seamlessly to large models. Generalization tests across diverse datasets and retrieval corpora confirm the robustness of our approach. Overall, EKA advances the state-of-the-art in iterative RAG systems while illuminating the critical interplay between structured reasoning and efficient exploration in reinforcement learning-augmented frameworks. The code is released at \href{https://github.com/yxzwang/EarlyKnowledgeAlignment}{Github}.

</details>


### [13] [Fun-Audio-Chat Technical Report](https://arxiv.org/abs/2512.20156)
*Qian Chen,Luyao Cheng,Chong Deng,Xiangang Li,Jiaqing Liu,Chao-Hong Tan,Wen Wang,Junhao Xu,Jieping Ye,Qinglin Zhang,Qiquan Zhang,Jingren Zhou*

Main category: cs.CL

TL;DR: Fun-Audio-Chat是一个大型音频语言模型，通过双分辨率语音表示和核心鸡尾酒训练解决了现有联合语音文本模型的关键挑战，在保持文本LLM知识的同时获得强大的音频理解、推理和生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有联合语音文本模型面临三个关键挑战：1）语音标记（25Hz）和文本标记（~3Hz）之间的时间分辨率不匹配会稀释语义信息；2）高计算成本；3）导致文本LLM知识的灾难性遗忘。

Method: 1）双分辨率语音表示：共享LLM以高效的5Hz处理音频（通过标记分组），而语音精炼头以25Hz生成高质量标记，平衡效率和质量；2）核心鸡尾酒训练：两阶段微调与中间合并，减轻灾难性遗忘；3）多任务DPO训练：增强鲁棒性、音频理解、指令跟随和语音共情。

Result: Fun-Audio-Chat 8B和MoE 30B-A3B在语音转文本和语音转语音任务上表现优异，在口语问答基准测试中在类似规模模型中排名靠前。在音频理解、语音功能调用、指令跟随和语音共情方面达到竞争性甚至优越性能。还开发了全双工变体Fun-Audio-Chat-Duplex。

Conclusion: Fun-Audio-Chat通过创新的双分辨率语音表示和核心鸡尾酒训练方法，有效解决了现有联合语音文本模型的局限性，在保持文本LLM知识的同时实现了强大的音频能力，且无需大规模音频文本预训练。

Abstract: Recent advancements in joint speech-text models show great potential for seamless voice interactions. However, existing models face critical challenges: temporal resolution mismatch between speech tokens (25Hz) and text tokens (~3Hz) dilutes semantic information, incurs high computational costs, and causes catastrophic forgetting of text LLM knowledge. We introduce Fun-Audio-Chat, a Large Audio Language Model addressing these limitations via two innovations from our previous work DrVoice. First, Dual-Resolution Speech Representations (DRSR): the Shared LLM processes audio at efficient 5Hz (via token grouping), while the Speech Refined Head generates high-quality tokens at 25Hz, balancing efficiency (~50% GPU reduction) and quality. Second, Core-Cocktail Training, a two-stage fine-tuning with intermediate merging that mitigates catastrophic forgetting. We then apply Multi-Task DPO Training to enhance robustness, audio understanding, instruction-following and voice empathy. This multi-stage post-training enables Fun-Audio-Chat to retain text LLM knowledge while gaining powerful audio understanding, reasoning, and generation. Unlike recent LALMs requiring large-scale audio-text pre-training, Fun-Audio-Chat leverages pre-trained models and extensive post-training. Fun-Audio-Chat 8B and MoE 30B-A3B achieve competitive performance on Speech-to-Text and Speech-to-Speech tasks, ranking top among similar-scale models on Spoken QA benchmarks. They also achieve competitive to superior performance on Audio Understanding, Speech Function Calling, Instruction-Following and Voice Empathy. We develop Fun-Audio-Chat-Duplex, a full-duplex variant with strong performance on Spoken QA and full-duplex interactions. We open-source Fun-Audio-Chat-8B with training and inference code, and provide an interactive demo.

</details>


### [14] [AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications](https://arxiv.org/abs/2512.20164)
*Honglin Mu,Jinghao Liu,Kaiyang Wan,Rui Xing,Xiuying Chen,Timothy Baldwin,Wanxiang Che*

Main category: cs.CL

TL;DR: LLMs在简历筛选中存在对抗指令攻击漏洞，攻击成功率超80%，本文提出训练时防御方法FIDS优于推理时防御


<details>
  <summary>Details</summary>
Motivation: LLMs在代码审查、内容审核等任务中表现出色，但研究发现其存在被"对抗指令"操纵的漏洞，特别是在简历筛选等成熟防御机制缺失的领域，攻击者可通过隐藏指令使LLM偏离原任务

Method: 1) 建立简历筛选领域的对抗指令攻击基准测试；2) 评估两种防御机制：基于提示的推理时防御和提出的FIDS训练时防御方法（使用LoRA适应技术）；3) 结合两种防御方法

Result: 1) 基准测试显示某些攻击类型成功率超过80%；2) 提示防御实现10.1%攻击降低但带来12.5%误拒增加；3) FIDS实现15.4%攻击降低和10.4%误拒增加；4) 组合方法实现26.3%攻击降低，训练时防御在安全性和实用性保护上都优于推理时防御

Conclusion: 训练时防御方法（如FIDS）比推理时防御在对抗指令攻击防护方面更有效，既能降低攻击成功率又能更好地保持系统实用性，为LLMs在简历筛选等敏感应用中的安全部署提供了重要指导

Abstract: Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by "adversarial instructions" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.

</details>


### [15] [FaithLens: Detecting and Explaining Faithfulness Hallucination](https://arxiv.org/abs/2512.20182)
*Shuzheng Si,Qingyi Wang,Haozhe Zhao,Yuzhuo Bai,Guanqiao Chen,Kangyang Luo,Gang Chen,Fanchao Qi,Minjia Zhang,Baobao Chang,Maosong Sun*

Main category: cs.CL

TL;DR: FaithLens是一个用于检测大语言模型输出中忠实性幻觉的8B参数模型，能同时提供二元预测和解释，在12个任务上超越GPT-4等先进模型。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型的实际应用中（如检索增强生成和摘要），识别输出中是否包含忠实性幻觉至关重要，需要提高检测的可信度。

Method: 1) 使用先进LLM合成带解释的训练数据，并通过数据过滤确保标签正确性、解释质量和数据多样性；2) 在精心策划的数据上进行冷启动微调；3) 使用基于规则的强化学习进一步优化，奖励预测正确性和解释质量。

Result: 在12个多样化任务上，8B参数的FaithLens超越了GPT-4.1和o3等先进模型，并能产生高质量的解释，在可信度、效率和效果之间实现了独特平衡。

Conclusion: FaithLens是一个成本效益高且有效的忠实性幻觉检测模型，通过联合预测和解释提高了可信度，为实际应用提供了可靠解决方案。

Abstract: Recognizing whether outputs from large language models (LLMs) contain faithfulness hallucination is crucial for real-world applications, e.g., retrieval-augmented generation and summarization. In this paper, we introduce FaithLens, a cost-efficient and effective faithfulness hallucination detection model that can jointly provide binary predictions and corresponding explanations to improve trustworthiness. To achieve this, we first synthesize training data with explanations via advanced LLMs and apply a well-defined data filtering strategy to ensure label correctness, explanation quality, and data diversity. Subsequently, we fine-tune the model on these well-curated training data as a cold start and further optimize it with rule-based reinforcement learning, using rewards for both prediction correctness and explanation quality. Results on 12 diverse tasks show that the 8B-parameter FaithLens outperforms advanced models such as GPT-4.1 and o3. Also, FaithLens can produce high-quality explanations, delivering a distinctive balance of trustworthiness, efficiency, and effectiveness.

</details>


### [16] [Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings](https://arxiv.org/abs/2512.20204)
*Marko Čechovič,Natália Komorníková,Dominik Macháček,Ondřej Bojar*

Main category: cs.CL

TL;DR: 论文创建了一个用于评估跨语言对话系统的语料库，包含12种语言的5小时语音数据，并提出基于大语言模型的误解自动检测方法。


<details>
  <summary>Details</summary>
Motivation: 需要构建一个真实且多功能的评估语料库，以评估在无共同语言场景下由自动语音翻译辅助的跨语言对话系统。

Method: 1) 创建包含12种语言、5小时语音的跨语言对话语料库，包含ASR转录、黄金转录和英译版本；2) 提出自动检测误解的方法，通过人工标注误解并测试大语言模型（Gemini）的检测能力。

Result: Gemini模型在识别误解文本片段方面取得了77%的召回率和47%的精确率，证明了其在跨语言会议中自动检测误解的潜力。

Conclusion: 该研究为跨语言对话系统评估提供了有价值的语料资源，并展示了利用大语言模型自动检测跨语言交流中误解的可行性。

Abstract: Speech processing and translation technology have the potential to facilitate meetings of individuals who do not share any common language. To evaluate automatic systems for such a task, a versatile and realistic evaluation corpus is needed. Therefore, we create and present a corpus of cross-lingual dialogues between individuals without a common language who were facilitated by automatic simultaneous speech translation. The corpus consists of 5 hours of speech recordings with ASR and gold transcripts in 12 original languages and automatic and corrected translations into English. For the purposes of research into cross-lingual summarization, our corpus also includes written summaries (minutes) of the meetings.
  Moreover, we propose automatic detection of misunderstandings. For an overview of this task and its complexity, we attempt to quantify misunderstandings in cross-lingual meetings. We annotate misunderstandings manually and also test the ability of current large language models to detect them automatically. The results show that the Gemini model is able to identify text spans with misunderstandings with recall of 77% and precision of 47%.

</details>


### [17] [SlideTailor: Personalized Presentation Slide Generation for Scientific Papers](https://arxiv.org/abs/2512.20292)
*Wenzheng Zeng,Mingyu Ouyang,Langyuan Cui,Hwee Tou Ng*

Main category: cs.CL

TL;DR: SlideTailor：基于用户偏好的个性化论文到幻灯片生成框架，通过论文-幻灯片示例对和视觉模板来学习用户偏好，并引入语音链机制提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有自动幻灯片生成方法通常假设单一标准，忽略了用户偏好的多样性，导致生成结果与个体需求不符。需要一种能够根据用户特定偏好定制幻灯片的解决方案。

Method: 提出SlideTailor框架：1) 仅需用户提供论文-幻灯片示例对和视觉模板，从这些自然易得的输入中隐式学习用户的内容和视觉风格偏好；2) 引入链式语音机制，使幻灯片内容与计划的口头叙述对齐；3) 构建包含多样化用户偏好的基准数据集进行评估。

Result: 实验证明该框架能有效从隐式、无标签的输入中提取和泛化用户偏好，生成高质量的个性化幻灯片，并能支持视频演示等下游应用。

Conclusion: SlideTailor通过用户友好的输入方式实现了个性化的论文到幻灯片生成，解决了现有方法忽略用户偏好的问题，为自动内容创建提供了更灵活实用的解决方案。

Abstract: Automatic presentation slide generation can greatly streamline content creation. However, since preferences of each user may vary, existing under-specified formulations often lead to suboptimal results that fail to align with individual user needs. We introduce a novel task that conditions paper-to-slides generation on user-specified preferences. We propose a human behavior-inspired agentic framework, SlideTailor, that progressively generates editable slides in a user-aligned manner. Instead of requiring users to write their preferences in detailed textual form, our system only asks for a paper-slides example pair and a visual template - natural and easy-to-provide artifacts that implicitly encode rich user preferences across content and visual style. Despite the implicit and unlabeled nature of these inputs, our framework effectively distills and generalizes the preferences to guide customized slide generation. We also introduce a novel chain-of-speech mechanism to align slide content with planned oral narration. Such a design significantly enhances the quality of generated slides and enables downstream applications like video presentations. To support this new task, we construct a benchmark dataset that captures diverse user preferences, with carefully designed interpretable metrics for robust evaluation. Extensive experiments demonstrate the effectiveness of our framework.

</details>


### [18] [AprielGuard](https://arxiv.org/abs/2512.20293)
*Jaykumar Kasundra,Anjaneya Praharaj,Sourabh Surana,Lakshmi Sirisha Chodisetty,Sourav Sharma,Abhigya Verma,Abhishek Bhardwaj,Debasish Kanhar,Aakash Bhagat,Khalil Slimi,Seganrasan Subramanian,Sathwik Tejaswi Madhusudhan,Ranga Prasad Chenna,Srinivas Sunkara*

Main category: cs.CL

TL;DR: AprielGuard是一个8B参数的安全防护模型，统一处理安全风险（如毒性、偏见）和对抗威胁（如提示注入、越狱），在多样化数据集上训练，在多个基准测试中表现优于现有开源防护模型。


<details>
  <summary>Details</summary>
Motivation: 现有防护工具通常将安全风险和对抗威胁视为独立问题处理，限制了其鲁棒性和泛化能力。随着大语言模型在对话和代理场景中的部署增加，需要更全面、统一的安全防护解决方案。

Method: 开发了8B参数的AprielGuard模型，采用统一分类和学习框架。在包含独立提示、多轮对话和代理工作流的多样化开源和合成数据上训练，并加入结构化推理轨迹以提高可解释性。

Result: 在多个公开和专有基准测试中，AprielGuard在检测有害内容和对抗操作方面表现出色，特别是在多步骤和推理密集型场景中，超越了Llama-Guard和Granite Guardian等现有开源防护模型。

Conclusion: AprielGuard通过统一的安全防护框架提供了更鲁棒和通用的解决方案，模型的开源发布旨在推动LLM可靠防护的透明和可复现研究。

Abstract: Safeguarding large language models (LLMs) against unsafe or adversarial behavior is critical as they are increasingly deployed in conversational and agentic settings. Existing moderation tools often treat safety risks (e.g. toxicity, bias) and adversarial threats (e.g. prompt injections, jailbreaks) as separate problems, limiting their robustness and generalizability. We introduce AprielGuard, an 8B parameter safeguard model that unify these dimensions within a single taxonomy and learning framework. AprielGuard is trained on a diverse mix of open and synthetic data covering standalone prompts, multi-turn conversations, and agentic workflows, augmented with structured reasoning traces to improve interpretability. Across multiple public and proprietary benchmarks, AprielGuard achieves strong performance in detecting harmful content and adversarial manipulations, outperforming existing opensource guardrails such as Llama-Guard and Granite Guardian, particularly in multi-step and reasoning intensive scenarios. By releasing the model, we aim to advance transparent and reproducible research on reliable safeguards for LLMs.

</details>


### [19] [Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives](https://arxiv.org/abs/2512.20298)
*Karolina Drożdż,Kacper Dudzic,Anna Sterna,Marcin Moskalewicz*

Main category: cs.CL

TL;DR: 研究比较了LLM与精神健康专家在诊断边缘型和自恋型人格障碍方面的表现，发现LLM整体准确率更高但存在严重偏见，尤其在自恋型人格障碍诊断上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地用于精神科自我评估，需要了解它们解释定性患者叙述的能力，特别是在诊断复杂人格障碍方面的表现。

Method: 使用波兰语第一人称自传体叙述，对最先进的LLM（如Gemini Pro）与精神健康专业人士在诊断边缘型和自恋型人格障碍方面进行了首次直接比较。

Result: Gemini Pro模型整体诊断准确率比人类专家高21.91个百分点（65.48% vs. 43.57%）。虽然两者在边缘型人格障碍诊断上都表现良好（F1分别为83.4和80.0），但模型严重低估自恋型人格障碍（F1=6.7 vs. 50.0），显示对"自恋"这一价值负载术语的回避。

Conclusion: LLM在解释复杂的第一人称临床数据方面能力很强，但仍存在关键的可靠性和偏见问题，特别是在价值负载的诊断标签上表现出系统性的回避倾向。

Abstract: Growing reliance on LLMs for psychiatric self-assessment raises questions about their ability to interpret qualitative patient narratives. We present the first direct comparison between state-of-the-art LLMs and mental health professionals in diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders utilizing Polish-language first-person autobiographical accounts. We show that the top-performing Gemini Pro models surpassed human professionals in overall diagnostic accuracy by 21.91 percentage points (65.48% vs. 43.57%). While both models and human experts excelled at identifying BPD (F1 = 83.4 & F1 = 80.0, respectively), models severely underdiagnosed NPD (F1 = 6.7 vs. 50.0), showing a reluctance toward the value-laden term "narcissism." Qualitatively, models provided confident, elaborate justifications focused on patterns and formal categories, while human experts remained concise and cautious, emphasizing the patient's sense of self and temporal experience. Our findings demonstrate that while LLMs are highly competent at interpreting complex first-person clinical data, they remain subject to critical reliability and bias issues.

</details>


### [20] [SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision](https://arxiv.org/abs/2512.20308)
*Maxime Poli,Mahi Luthra,Youssef Benchekroun,Yosuke Higuchi,Martin Gleize,Jiayi Shen,Robin Algayres,Yu-An Chung,Mido Assran,Juan Pino,Emmanuel Dupoux*

Main category: cs.CL

TL;DR: SpidR是一个自监督语音表示模型，通过掩码预测目标结合自蒸馏和在线聚类，在原始波形上训练，能高效学习包含丰富语音信息的表示，特别适合无文本口语语言建模。


<details>
  <summary>Details</summary>
Motivation: 语言建模和语音表示学习的并行进展使得直接从语音学习语言成为可能，这需要从语音中直接提取语义表示。但现有方法在语音单元质量和训练效率方面存在局限。

Method: 提出SpidR模型，使用掩码预测目标结合自蒸馏和在线聚类在原始波形上训练。学生模型的中间层学习预测教师模型中间层的分配结果，这种学习目标稳定了在线聚类过程，产生更高质量的码本。

Result: SpidR在语言建模基准测试（sWUGGY、sBLIMP、tSC）上优于wav2vec 2.0、HuBERT、WavLM和DinoSR。系统评估验证了语音单元质量指标与语言建模性能的相关性。相比HuBERT，SpidR将预训练时间从一周缩短到一天（16个GPU）。

Conclusion: SpidR通过改进的训练目标实现了高质量的语音表示学习，为无文本口语语言建模提供了高效解决方案，同时验证了语音单元质量指标作为语言建模性能可靠代理的有效性。

Abstract: The parallel advances in language modeling and speech representation learning have raised the prospect of learning language directly from speech without textual intermediates. This requires extracting semantic representations directly from speech. Our contributions are threefold. First, we introduce SpidR, a self-supervised speech representation model that efficiently learns representations with highly accessible phonetic information, which makes it particularly suited for textless spoken language modeling. It is trained on raw waveforms using a masked prediction objective combined with self-distillation and online clustering. The intermediate layers of the student model learn to predict assignments derived from the teacher's intermediate layers. This learning objective stabilizes the online clustering procedure compared to previous approaches, resulting in higher quality codebooks. SpidR outperforms wav2vec 2.0, HuBERT, WavLM, and DinoSR on downstream language modeling benchmarks (sWUGGY, sBLIMP, tSC). Second, we systematically evaluate across models and layers the correlation between speech unit quality (ABX, PNMI) and language modeling performance, validating these metrics as reliable proxies. Finally, SpidR significantly reduces pretraining time compared to HuBERT, requiring only one day of pretraining on 16 GPUs, instead of a week. This speedup is enabled by the pretraining method and an efficient codebase, which allows faster iteration and easier experimentation. We open-source the training code and model checkpoints at https://github.com/facebookresearch/spidr.

</details>


### [21] [Can LLMs Solve My Grandma's Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles](https://arxiv.org/abs/2512.20324)
*Nurul Labib Sayeedi,Md. Faiyaz Abdullah Sayeedi,Khushnur Binte Jahangir,Swakkhar Shatabda,Sarah Masud Preum*

Main category: cs.CL

TL;DR: 研究人员创建了BanglaRiddleEval基准测试，包含1,244个孟加拉语谜语，评估LLMs在低资源、比喻性和文化情境下的推理能力，发现当前模型表现远低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在许多NLP基准测试上表现出色，但在比喻性、文化根基和低资源环境下的推理能力尚未得到充分探索。研究旨在填补孟加拉语领域的这一空白。

Method: 通过LLM驱动的流水线生成思维链解释、语义连贯的干扰项和细粒度歧义标注，构建包含4,976个谜语任务工件的基准测试，并评估多种开源和闭源模型在不同提示策略下的表现。

Result: 模型在生成式QA中达到中等语义重叠但正确率低，多项选择题准确率最高仅约56%（人类基线为83%），歧义解决率在26%至68%之间，高质量解释仅限于最强模型。

Conclusion: 当前LLMs能够捕捉孟加拉语谜语推理所需的一些线索，但距离人类水平仍有很大差距，BanglaRiddleEval成为一个具有挑战性的低资源比喻推理新基准。

Abstract: Large Language Models (LLMs) show impressive performance on many NLP benchmarks, yet their ability to reason in figurative, culturally grounded, and low-resource settings remains underexplored. We address this gap for Bangla by introducing BanglaRiddleEval, a benchmark of 1,244 traditional Bangla riddles instantiated across four tasks (4,976 riddle-task artifacts in total). Using an LLM-based pipeline, we generate Chain-of-Thought explanations, semantically coherent distractors, and fine-grained ambiguity annotations, and evaluate a diverse suite of open-source and closed-source models under different prompting strategies. Models achieve moderate semantic overlap on generative QA but low correctness, MCQ accuracy peaks at only about 56% versus an 83% human baseline, and ambiguity resolution ranges from roughly 26% to 68%, with high-quality explanations confined to the strongest models. These results show that current LLMs capture some cues needed for Bangla riddle reasoning but remain far from human-level performance, establishing BanglaRiddleEval as a challenging new benchmark for low-resource figurative reasoning. All data, code, and evaluation scripts are available on GitHub: https://github.com/Labib1610/BanglaRiddleEval.

</details>


### [22] [Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation](https://arxiv.org/abs/2512.20352)
*Nilesh Jain,Seyi Adeyinka,Leor Roseman,Aza Allsop*

Main category: cs.CL

TL;DR: 提出了一个用于LLM主题分析的多视角验证框架，结合集成验证和双重可靠性指标，在三个领先LLM上验证了高可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统质性研究中人工编码者之间的评分者一致性方法需要多个编码者、耗时且一致性通常中等，存在可靠性挑战。

Method: 开发了一个多视角验证框架，结合集成验证与双重可靠性指标：用于评分者一致性的Cohen's Kappa和用于语义一致性的余弦相似度。框架支持可配置的分析参数（1-6个种子，温度0.0-2.0）、自定义提示结构和变量替换，提供跨任意JSON格式的共识主题提取。

Result: 在三个领先LLM（Gemini 2.5 Pro、GPT-4o、Claude 3.5 Sonnet）上评估，每个模型进行六次独立运行。Gemini获得最高可靠性（κ=0.907，余弦相似度95.3%），其次是GPT-4o（κ=0.853，92.6%）和Claude（κ=0.842，92.1%）。所有模型都达到高一致性（κ>0.80）。Gemini识别出6个共识主题（50-83%一致性），GPT-4o识别5个，Claude识别4个。

Conclusion: 该框架通过提供透明的可靠性指标、灵活配置和结构无关的共识提取，为可靠的AI辅助质性研究建立了方法论基础，开源实现可供研究人员使用。

Abstract: Qualitative research faces a critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency. We present a multi-perspective validation framework for LLM-based thematic analysis that combines ensemble validation with dual reliability metrics: Cohen's Kappa ($κ$) for inter-rater agreement and cosine similarity for semantic consistency. Our framework enables configurable analysis parameters (1-6 seeds, temperature 0.0-2.0), supports custom prompt structures with variable substitution, and provides consensus theme extraction across any JSON format. As proof-of-concept, we evaluate three leading LLMs (Gemini 2.5 Pro, GPT-4o, Claude 3.5 Sonnet) on a psychedelic art therapy interview transcript, conducting six independent runs per model. Results demonstrate Gemini achieves highest reliability ($κ= 0.907$, cosine=95.3%), followed by GPT-4o ($κ= 0.853$, cosine=92.6%) and Claude ($κ= 0.842$, cosine=92.1%). All three models achieve a high agreement ($κ> 0.80$), validating the multi-run ensemble approach. The framework successfully extracts consensus themes across runs, with Gemini identifying 6 consensus themes (50-83% consistency), GPT-4o identifying 5 themes, and Claude 4 themes. Our open-source implementation provides researchers with transparent reliability metrics, flexible configuration, and structure-agnostic consensus extraction, establishing methodological foundations for reliable AI-assisted qualitative research.

</details>


### [23] [Sentiment-Aware Extractive and Abstractive Summarization for Unstructured Text Mining](https://arxiv.org/abs/2512.20404)
*Junyi Liu,Stanley Kok*

Main category: cs.CL

TL;DR: 提出情感感知文本摘要框架，结合抽取式和生成式方法，改进对用户生成短文本的情感建模和摘要质量。


<details>
  <summary>Details</summary>
Motivation: 社交媒体、评论和论坛等非结构化数据快速增长，文本挖掘在信息系统(IS)中变得至关重要。现有摘要方法主要针对结构化新闻优化，难以处理嘈杂、非正式的用户生成内容。情感线索对于品牌监控和市场分析等IS任务非常关键，但很少有研究将情感建模集成到短用户生成文本的摘要中。

Method: 提出情感感知框架，扩展抽取式(TextRank)和生成式(UniLM)方法，通过将情感信号嵌入到排名和生成过程中，改进对情感细微差别和主题相关性的捕捉。

Result: 该双重设计能够产生简洁、情感丰富的摘要，增强了在动态在线环境中及时干预和战略决策的能力。

Conclusion: 情感感知文本摘要框架有效解决了用户生成短文本的摘要问题，通过集成情感建模提高了摘要质量，对信息系统中的品牌监控和市场分析等应用具有重要价值。

Abstract: With the rapid growth of unstructured data from social media, reviews, and forums, text mining has become essential in Information Systems (IS) for extracting actionable insights. Summarization can condense fragmented, emotion-rich posts, but existing methods-optimized for structured news-struggle with noisy, informal content. Emotional cues are critical for IS tasks such as brand monitoring and market analysis, yet few studies integrate sentiment modeling into summarization of short user-generated texts. We propose a sentiment-aware framework extending extractive (TextRank) and abstractive (UniLM) approaches by embedding sentiment signals into ranking and generation processes. This dual design improves the capture of emotional nuances and thematic relevance, producing concise, sentiment-enriched summaries that enhance timely interventions and strategic decision-making in dynamic online environments.

</details>


### [24] [Step-DeepResearch Technical Report](https://arxiv.org/abs/2512.20491)
*Chen Hu,Haikuo Du,Heng Wang,Lin Lin,Mingrui Chen,Peng Liu,Ruihang Miao,Tianchi Yue,Wang You,Wei Ji,Wei Yuan,Wenjin Deng,Xiaojian Yuan,Xiaoyun Zhang,Xiangyu Liu,Xikai Liu,Yanming Xu,Yicheng Cao,Yifei Zhang,Yongyao Wang,Yubo Shu,Yurong Zhang,Yuxiang Zhang,Zheng Gong,Zhichao Chang,Binyan Li,Dan Ma,Furong Jia,Hongyuan Wang,Jiayu Liu,Jing Bai,Junlan Liu,Manjiao Liu,Na Wang,Qiuping Wu,Qinxin Du,Shiwei Li,Wen Sun,Yifeng Gong,Yonglin Chen,Yuling Zhao,Yuxuan Lin,Ziqi Ren,Zixuan Wang,Aihu Zhang,Brian Li,Buyun Ma,Kang An,Li Xie,Mingliang Li,Pan Li,Shidong Yang,Xi Chen,Xiaojia Liu,Yuchu Luo,Yuan Song,YuanHao Ding,Yuanwei Liang,Zexi Li,Zhaoning Zhang,Zixin Zhang,Binxing Jiao,Daxin Jiang,Jiansheng Chen,Jing Li,Xiangyu Zhang,Yibo Zhu*

Main category: cs.CL

TL;DR: 本文提出Step-DeepResearch，一个面向深度研究任务的端到端智能体，通过原子能力数据合成策略和渐进式训练路径，使中等规模模型在成本效益下达到专家级深度研究能力。


<details>
  <summary>Details</summary>
Motivation: 现有学术基准（如BrowseComp）无法满足现实世界对开放式深度研究的需求，后者需要强大的意图识别、长时程决策和跨源验证能力。同时，中文领域缺乏针对深度研究的评估基准。

Method: 1. 提出基于原子能力的数据合成策略，强化规划和报告撰写能力；2. 采用从智能体中间训练到SFT和RL的渐进式训练路径；3. 引入清单式评判器增强鲁棒性；4. 建立中文深度研究评估基准ADR-Bench。

Result: Step-DeepResearch（32B）在Scale AI Research Rubrics上获得61.4%的分数。在ADR-Bench上，显著优于同类模型，并与OpenAI、Gemini DeepResearch等闭源SOTA模型相媲美。

Conclusion: 精细化训练使中等规模模型能够以行业领先的成本效益实现专家级深度研究能力，为自主智能体的深度研究任务提供了有效解决方案。

Abstract: As LLMs shift toward autonomous agents, Deep Research has emerged as a pivotal metric. However, existing academic benchmarks like BrowseComp often fail to meet real-world demands for open-ended research, which requires robust skills in intent recognition, long-horizon decision-making, and cross-source verification. To address this, we introduce Step-DeepResearch, a cost-effective, end-to-end agent. We propose a Data Synthesis Strategy Based on Atomic Capabilities to reinforce planning and report writing, combined with a progressive training path from agentic mid-training to SFT and RL. Enhanced by a Checklist-style Judger, this approach significantly improves robustness. Furthermore, to bridge the evaluation gap in the Chinese domain, we establish ADR-Bench for realistic deep research scenarios. Experimental results show that Step-DeepResearch (32B) scores 61.4% on Scale AI Research Rubrics. On ADR-Bench, it significantly outperforms comparable models and rivals SOTA closed-source models like OpenAI and Gemini DeepResearch. These findings prove that refined training enables medium-sized models to achieve expert-level capabilities at industry-leading cost-efficiency.

</details>


### [25] [Distilling to Hybrid Attention Models via KL-Guided Layer Selection](https://arxiv.org/abs/2512.20569)
*Yanhong Li,Songlin Yang,Shawn Tan,Mayank Mishra,Rameswar Panda,Jiawei Zhou,Yoon Kim*

Main category: cs.CL

TL;DR: 提出一种基于层重要性分数的简单高效层选择方法，用于将预训练Transformer蒸馏为软注意力与线性注意力混合架构，相比现有方法更有效。


<details>
  <summary>Details</summary>
Motivation: 将预训练的软注意力Transformer蒸馏为混合注意力架构可以提升推理效率，但关键挑战在于如何选择要转换为线性注意力的层。

Method: 1) 使用少量通用文本数据训练得到层重要性分数进行层选择；2) 采用RADLADS蒸馏流程：注意力权重转移、隐藏状态对齐、KL分布匹配和少量微调。

Result: 该方法比现有层选择方法更有效，包括基于固定比率的均匀交错线性注意力启发式方法，以及依赖专门诊断数据集的复杂方法。

Conclusion: 基于层重要性分数的简单层选择方法结合RADLADS蒸馏流程，能够有效将预训练Transformer转换为高效混合注意力架构。

Abstract: Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch. A critical factor in the conversion process is layer selection, i.e., deciding on which layers to convert to linear attention variants. This paper describes a simple and efficient recipe for layer selection that uses layer importance scores derived from a small amount of training on generic text data. Once the layers have been selected we use a recent pipeline for the distillation process itself \citep[RADLADS;][]{goldstein2025radlads}, which consists of attention weight transfer, hidden state alignment, KL-based distribution matching, followed by a small amount of finetuning. We find that this approach is more effective than existing approaches for layer selection, including heuristics that uniformly interleave linear attentions based on a fixed ratio, as well as more involved approaches that rely on specialized diagnostic datasets.

</details>


### [26] [Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits](https://arxiv.org/abs/2512.20578)
*Amirhosein Ghasemabadi,Di Niu*

Main category: cs.CL

TL;DR: Gnosis是一个轻量级自感知机制，通过解码LLM内部状态（隐藏状态和注意力模式）来预测自身错误，无需额外计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能生成流畅复杂的输出，但常常无法识别自己的错误和幻觉。现有方法依赖外部评判者、多样本一致性或基于文本的自我批判，这些方法要么增加计算成本，要么与真实正确性相关性较弱。

Method: Gnosis通过被动观察LLM推理过程中的内部痕迹（隐藏状态和注意力模式），将其压缩为固定预算的描述符，然后预测正确性。该方法仅增加约500万个参数，与序列长度无关，推理成本可忽略。

Result: 在数学推理、开放域问答和学术知识基准测试中，在1.7B到20B参数的冻结骨干模型上，Gnosis在准确性和校准方面均优于强大的内部基线和大型外部评判者。此外，它能零样本泛化到部分生成，实现早期错误检测和计算感知控制。

Conclusion: 可靠的正确性线索内在于生成过程中，无需外部监督即可高效提取。这表明LLM具有通过内部状态进行自我验证的内在能力。

Abstract: Large language models (LLMs) generate fluent and complex outputs but often fail to recognize their own mistakes and hallucinations. Existing approaches typically rely on external judges, multi-sample consistency, or text-based self-critique, which incur additional compute or correlate weakly with true correctness. We ask: can LLMs predict their own failures by inspecting internal states during inference? We introduce Gnosis, a lightweight self-awareness mechanism that enables frozen LLMs to perform intrinsic self-verification by decoding signals from hidden states and attention patterns. Gnosis passively observes internal traces, compresses them into fixed-budget descriptors, and predicts correctness with negligible inference cost, adding only ~5M parameters and operating independently of sequence length. Across math reasoning, open-domain question answering, and academic knowledge benchmarks, and over frozen backbones ranging from 1.7B to 20B parameters, Gnosis consistently outperforms strong internal baselines and large external judges in both accuracy and calibration. Moreover, it generalizes zero-shot to partial generations, enabling early detection of failing trajectories and compute-aware control. These results show that reliable correctness cues are intrinsic to generation process and can be extracted efficiently without external supervision.

</details>


### [27] [Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs](https://arxiv.org/abs/2512.20595)
*Dhruv Anand,Ehsan Shareghi*

Main category: cs.CL

TL;DR: Cube Bench是一个基于魔方的多模态大语言模型基准测试，用于评估空间和序列推理能力，包含五个技能维度，结果显示模型性能随魔方复杂度增加而急剧下降，闭源模型表现优于开源模型。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM基准测试缺乏对空间和序列推理能力的系统性评估，特别是对于需要多步决策和错误恢复的复杂任务。魔方问题提供了一个紧凑、可重复的测试场景来全面评估这些能力。

Method: 创建Cube Bench基准，将魔方解谜分解为五个技能：(1)从图像和文本重建魔方面，(2)选择最优下一步移动，(3)预测候选移动结果而不实际执行，(4)执行多步计划并从中错误中恢复，(5)检测和修正自身错误。使用共享的魔方打乱状态、相同提示和解析器，以及单一的距离求解度量，比较7个MLLM在不同打乱深度下的表现。

Result: 所有MLLM的准确率随打乱深度增加而急剧下降；一旦轨迹停滞或偏离，模型很少能恢复；高面重建准确率不能保证良好的动作选择或多步执行能力。闭源模型在单步感知任务和多步控制任务上都领先，而开源模型在最难设置下接近随机水平。即使最好的MLLM在更高复杂度下也会性能下降。简单的自我校正通过反思性思考带来适度改进，但也可能引入过度思考。

Conclusion: Cube Bench提供了一个紧凑、可重复的基准来探测MLLM的序列空间推理能力，揭示了当前MLLM在复杂空间序列任务上的局限性，特别是多步规划和错误恢复方面的不足，为未来模型改进提供了明确方向。

Abstract: We introduce Cube Bench, a Rubik's-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predicting the outcome of a candidate move without applying it, (iv) executing multi-step plans while recovering from mistakes, and (v) detecting and revising one's own errors. Using a shared set of scrambled cube states, identical prompts and parsers, and a single distance-to-solved metric, we compare recent MLLMs side by side as a function of scramble depth. Across seven MLLMs, accuracy drops sharply with depth; once a trajectory stalls or diverges, models rarely recover, and high face-reconstruction accuracy does not guarantee competent action selection or multi-step execution. A pronounced closed- vs open-source gap emerges: the strongest closed model leads on both single-step perception tasks and multi-step control tasks, while open-weight models cluster near chance on the hardest settings; yet even the best MLLM degrades at higher cube complexity. A simple self-correction via reflective thinking yields modest gains but can also introduce overthinking. Cube Bench offers a compact, reproducible probe of sequential spatial reasoning in MLLMs.

</details>


### [28] [MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts](https://arxiv.org/abs/2512.20604)
*Alexandros Christoforos,Chadbourne Davis*

Main category: cs.CL

TL;DR: MoE-DiffuSeq是一个基于专家混合的框架，用于增强扩散模型在长文档生成中的性能，通过稀疏注意力和专家混合架构提高效率，同时保持文本质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的文本生成模型（如DiffuSeq）在处理长序列时存在高计算成本和内存开销的问题，限制了它们在长文档生成场景中的应用。

Method: 集成稀疏注意力与专家混合架构，引入定制化的稀疏注意力机制以降低计算复杂度，并在扩散过程中加入软吸收状态以加速序列重建和提高生成精度。

Result: 实验表明，MoE-DiffuSeq在训练效率和采样速度上显著优于现有扩散模型，尤其在长文档场景（如科学文章生成、代码库建模和长对话生成）中表现突出，提升了效率、速度、准确性和表达能力。

Conclusion: MoE-DiffuSeq通过结合稀疏注意力和专家混合架构，有效解决了扩散模型在长文本生成中的计算效率问题，推动了高质量长文本生成扩散模型的实用化应用。

Abstract: We present MoE-DiffuSeq, a mixture of experts based framework for enhancing diffusion models in long document generation. Existing diffusion based text generation models, such as DiffuSeq, suffer from high computational cost and memory overhead when applied to extended sequences. To address these challenges, MoE-DiffuSeq integrates sparse attention with a mixture of experts architecture, enabling efficient and scalable long sequence modeling. Our approach introduces a customized sparse attention mechanism designed to reduce computational complexity while preserving text quality and coherence. In addition, we incorporate a soft absorbing state within the diffusion process to accelerate sequence reconstruction and improve generation precision. Extensive experiments demonstrate that MoE-DiffuSeq significantly improves training efficiency and sampling speed compared to existing diffusion models. These advantages are particularly effective for long document scenarios, including scientific article generation, code repository modeling, and long form dialogue generation. Benchmark results further show that MoE-DiffuSeq improves efficiency, speed, accuracy, and expressiveness, advancing the practical applicability of diffusion models for high quality long form text generation.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [29] [Towards Analysing Invoices and Receipts with Amazon Textract](https://arxiv.org/abs/2512.19958)
*Sneha Oommen,Gabby Sanchez,Cassandra T. Britto,Di Wang,Jordan Chiou,Maria Spichkova*

Main category: cs.IR

TL;DR: 对AWS Textract从收据中提取数据的评估，分析了其功能表现、典型问题及缓解策略


<details>
  <summary>Details</summary>
Motivation: 评估AWS Textract在收据数据提取场景中的实际表现，了解其在不同格式和条件下的功能表现

Method: 使用包含多种格式和条件的收据数据集，对Textract功能进行定性分析，观察典型问题和异常情况

Result: 收据总额能一致地被检测到，但图像质量和布局会影响提取效果，存在典型问题和异常情况

Conclusion: 基于观察分析提出了缓解策略，为实际应用提供了改进方向

Abstract: This paper presents an evaluation of the AWS Textract in the context of extracting data from receipts. We analyse Textract functionalities using a dataset that includes receipts of varied formats and conditions. Our analysis provided a qualitative view of Textract strengths and limitations. While the receipts totals were consistently detected, we also observed typical issues and irregularities that were often influenced by image quality and layout. Based on the analysis of the observations, we propose mitigation strategies.

</details>


### [30] [IGDMRec: Behavior Conditioned Item Graph Diffusion for Multimodal Recommendation](https://arxiv.org/abs/2512.19983)
*Ziyuan Guo,Jie Guo,Zhenghao Chen,Bin Song,Fei Richard Yu*

Main category: cs.IR

TL;DR: IGDMRec提出了一种使用扩散模型和分类器自由引导来降噪语义物品图的多模态推荐方法，通过结合用户行为信息提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于结构的MRS通过构建语义物品图取得了SOTA性能，但这类图存在噪声问题：1)多模态信息本身存在噪声；2)物品语义与用户-物品共现关系之间的不对齐导致虚假链接，从而影响推荐效果。

Method: IGDMRec包含三个核心组件：1)行为条件图扩散模块，将交互数据作为条件信息来指导语义物品图的降噪；2)条件降噪网络，以可管理复杂度实现降噪过程；3)对比表示增强方案，利用降噪后的物品图和原始物品图来增强物品表示。

Result: 在四个真实世界数据集上的大量实验表明，IGDMRec优于竞争基线，鲁棒性分析验证了其降噪能力，消融研究确认了其关键组件的有效性。

Conclusion: IGDMRec通过扩散模型有效降噪语义物品图，结合用户行为信息提升了多模态推荐的性能，为解决语义物品图中的噪声问题提供了新思路。

Abstract: Multimodal recommender systems (MRSs) are critical for various online platforms, offering users more accurate personalized recommendations by incorporating multimodal information of items. Structure-based MRSs have achieved state-of-the-art performance by constructing semantic item graphs, which explicitly model relationships between items based on modality feature similarity. However, such semantic item graphs are often noisy due to 1) inherent noise in multimodal information and 2) misalignment between item semantics and user-item co-occurrence relationships, which introduces false links and leads to suboptimal recommendations. To address this challenge, we propose Item Graph Diffusion for Multimodal Recommendation (IGDMRec), a novel method that leverages a diffusion model with classifier-free guidance to denoise the semantic item graph by integrating user behavioral information. Specifically, IGDMRec introduces a Behavior-conditioned Graph Diffusion (BGD) module, incorporating interaction data as conditioning information to guide the denoising of the semantic item graph. Additionally, a Conditional Denoising Network (CD-Net) is designed to implement the denoising process with manageable complexity. Finally, we propose a contrastive representation augmentation scheme that leverages both the denoised item graph and the original item graph to enhance item representations. \LL{Extensive experiments on four real-world datasets demonstrate the superiority of IGDMRec over competitive baselines, with robustness analysis validating its denoising capability and ablation studies verifying the effectiveness of its key components.

</details>


### [31] [LLM-Assisted Abstract Screening with OLIVER: Evaluating Calibration and Single-Model vs. Actor-Critic Configurations in Literature Reviews](https://arxiv.org/abs/2512.20022)
*Kian Godhwani,David Benrimoh*

Main category: cs.IR

TL;DR: 本文提出OLVER管道评估LLM在文献筛选中的应用，发现单模型表现受文献综述特性影响大且校准差，而演员-评论家框架能显著提升筛选质量和置信度可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM辅助文献筛选的研究主要关注早期模型、标准化Cochrane综述、单模型设置和准确性指标，而忽视了通用性、配置效应和校准等重要方面。

Method: 开发了开源管道OLVER，评估多个当代LLM在两个非Cochrane系统综述中的表现，使用准确性、AUC和校准指标，并测试了结合两个轻量级模型的演员-评论家筛选框架及三种聚合规则。

Result: 单模型表现差异大：小综述中敏感性高但假阳性多、校准差；大综述中特异性高但召回率低，提示设计影响召回。单模型校准普遍较弱。演员-评论家框架在两个综述中都改善了区分度并显著降低了校准误差，获得了更高的AUC。

Conclusion: LLM最终可能加速文献筛选，但单模型表现对综述特性、提示设计高度敏感且校准有限。演员-评论家框架能提升分类质量和置信度可靠性，同时保持计算效率，实现低成本的大规模筛选。

Abstract: Introduction: Recent work suggests large language models (LLMs) can accelerate screening, but prior evaluations focus on earlier LLMs, standardized Cochrane reviews, single-model setups, and accuracy as the primary metric, leaving generalizability, configuration effects, and calibration largely unexamined.
  Methods: We developed OLIVER (Optimized LLM-based Inclusion and Vetting Engine for Reviews), an open-source pipeline for LLM-assisted abstract screening. We evaluated multiple contemporary LLMs across two non-Cochrane systematic reviews and performance was assessed at both the full-text screening and final inclusion stages using accuracy, AUC, and calibration metrics. We further tested an actor-critic screening framework combining two lightweight models under three aggregation rules.
  Results: Across individual models, performance varied widely. In the smaller Review 1 (821 abstracts, 63 final includes), several models achieved high sensitivity for final includes but at the cost of substantial false positives and poor calibration. In the larger Review 2 (7741 abstracts, 71 final includes), most models were highly specific but struggled to recover true includes, with prompt design influencing recall. Calibration was consistently weak across single-model configurations despite high overall accuracy. Actor-critic screening improved discrimination and markedly reduced calibration error in both reviews, yielding higher AUCs.
  Discussion: LLMs may eventually accelerate abstract screening, but single-model performance is highly sensitive to review characteristics, prompting, and calibration is limited. An actor-critic framework improves classification quality and confidence reliability while remaining computationally efficient, enabling large-scale screening at low cost.

</details>


### [32] [VSA:Visual-Structural Alignment for UI-to-Code](https://arxiv.org/abs/2512.20034)
*Xian Wu,Ming Zhang,Zhiyu Fang,Fei Li,Bin Wang,Yong Jiang,Hao Zhou*

Main category: cs.IR

TL;DR: VSA是一个多阶段视觉-结构对齐范式，能够从视觉设计图生成模块化、类型安全的前端组件代码，显著提升代码模块化和架构一致性。


<details>
  <summary>Details</summary>
Motivation: 当前基于大模型的设计到代码转换方法主要生成非结构化、扁平的代码，缺乏与React或Angular等组件化库的兼容性，导致代码低内聚高耦合，难以长期维护。

Method: 1. 使用空间感知transformer将视觉输入重构为层次树表示；2. 集成算法模式匹配层识别重复UI模式并封装为模块化模板；3. 通过模式驱动合成引擎，确保大语言模型生成类型安全、支持属性传递的生产级组件。

Result: 实验结果表明，相比现有最先进方法，该框架在代码模块化和架构一致性方面有显著提升，有效弥合了原始像素与可扩展软件工程之间的差距。

Conclusion: VSA通过视觉-结构对齐的多阶段范式，能够从视觉设计生成组织良好的前端资产，解决了现有设计到代码转换方法生成非结构化代码的问题，为自动化UI开发提供了更实用的解决方案。

Abstract: The automation of user interface development has the potential to accelerate software delivery by mitigating intensive manual implementation. Despite the advancements in Large Multimodal Models for design-to-code translation, existing methodologies predominantly yield unstructured, flat codebases that lack compatibility with component-oriented libraries such as React or Angular. Such outputs typically exhibit low cohesion and high coupling, complicating long-term maintenance. In this paper, we propose \textbf{VSA (VSA)}, a multi-stage paradigm designed to synthesize organized frontend assets through visual-structural alignment. Our approach first employs a spatial-aware transformer to reconstruct the visual input into a hierarchical tree representation. Moving beyond basic layout extraction, we integrate an algorithmic pattern-matching layer to identify recurring UI motifs and encapsulate them into modular templates. These templates are then processed via a schema-driven synthesis engine, ensuring the Large Language Model generates type-safe, prop-drilled components suitable for production environments. Experimental results indicate that our framework yields a substantial improvement in code modularity and architectural consistency over state-of-the-art benchmarks, effectively bridging the gap between raw pixels and scalable software engineering.

</details>


### [33] [Collaborative Group-Aware Hashing for Fast Recommender Systems](https://arxiv.org/abs/2512.20172)
*Yan Zhang,Li Deng,Lixin Duan,Ivor W. Tsang,Guowu Yang*

Main category: cs.IR

TL;DR: 提出一种基于协作群组感知哈希（CGAH）的推荐方法，通过集成固有群组信息解决稀疏场景下哈希推荐精度低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有哈希推荐方法在稀疏场景下精度较低，主要因为每个比特表示能力有限，且忽略了用户和物品之间的固有关系。

Method: 通过将用户和物品的潜在向量分类到不同群组来提取固有群组亲和度，然后将偏好表示为群组亲和度与哈希码相似度的内积。

Result: 在三个公共数据集上的实验表明，CGAH和CGAH-CF在不同稀疏设置下均优于最先进的离散协同过滤和离散内容感知推荐方法。

Conclusion: 通过集成固有群组信息学习哈希码，CGAH能够在稀疏交互数据下获得比现有离散方法更有效的哈希码，显著提升推荐精度。

Abstract: The fast online recommendation is critical for applications with large-scale databases; meanwhile, it is challenging to provide accurate recommendations in sparse scenarios. Hash technique has shown its superiority for speeding up the online recommendation by bit operations on Hamming distance computations. However, existing hashing-based recommendations suffer from low accuracy, especially with sparse settings, due to the limited representation capability of each bit and neglected inherent relations among users and items. To this end, this paper lodges a Collaborative Group-Aware Hashing (CGAH) method for both collaborative filtering (namely CGAH-CF) and content-aware recommendations (namely CGAH) by integrating the inherent group information to alleviate the sparse issue. Firstly, we extract inherent group affinities of users and items by classifying their latent vectors into different groups. Then, the preference is formulated as the inner product of the group affinity and the similarity of hash codes. By learning hash codes with the inherent group information, CGAH obtains more effective hash codes than other discrete methods with sparse interactive data. Extensive experiments on three public datasets show the superior performance of our proposed CGAH and CGAH-CF over the state-of-the-art discrete collaborative filtering methods and discrete content-aware recommendations under different sparse settings.

</details>


### [34] [Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register](https://arxiv.org/abs/2512.20458)
*Shuting Wang,Qiaolin Xia,Hao Wang,Yu Lu,Bobsimons,Zhicheng Dou*

Main category: cs.IR

TL;DR: Laser是一个用于稳定和扩展智能体搜索的通用框架，通过符号化动作协议和紧凑上下文寄存器解决现有系统推理轨迹不稳定、上下文溢出等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型和大型推理模型驱动的智能体搜索系统主要依赖非结构化的自然语言推理，在上下文中积累原始中间痕迹，导致推理轨迹不稳定、上下文溢出，以及在复杂多跳查询上性能下降。

Method: Laser定义了一个符号化动作协议，将智能体行为组织到三个空间：规划、任务解决和反思。每个动作都有明确的语义和确定性执行格式，实现结构化逻辑推理和可靠的动作解析。配合可解析动作，Laser还维护一个紧凑的上下文寄存器，只存储推理过程的基本状态。

Result: 在Qwen2.5/3系列模型上的实验表明，Laser在具有挑战性的多跳QA数据集上持续优于现有的智能体搜索基线方法，无论是在仅提示还是微调设置下都表现出色。

Conclusion: Laser为稳健、可扩展的智能体搜索提供了一个原则性和有效的基础，通过结构化推理和紧凑状态管理解决了现有框架的关键限制。

Abstract: Recent advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs) have enabled agentic search systems that interleave multi-step reasoning with external tool use. However, existing frameworks largely rely on unstructured natural-language reasoning and accumulate raw intermediate traces in the context, which often leads to unstable reasoning trajectories, context overflow, and degraded performance on complex multi-hop queries. In this study, we introduce Laser, a general framework for stabilizing and scaling agentic search. Laser defines a symbolic action protocol that organizes agent behaviors into three spaces: planning, task-solving, and retrospection. Each action is specified with explicit semantics and a deterministic execution format, enabling structured and logical reasoning processes and reliable action parsing. This design makes intermediate decisions interpretable and traceable, enhancing explicit retrospection and fine-grained control over reasoning trajectories. In coordination with parsable actions, Laser further maintains a compact context register that stores only essential states of the reasoning process, allowing the agent to reason over long horizons without uncontrolled context expansion. Experiments on Qwen2.5/3-series models across challenging multi-hop QA datasets show that Laser consistently outperforms existing agentic search baselines under both prompting-only and fine-tuning settings, demonstrating that Laser provides a principled and effective foundation for robust, scalable agentic search.

</details>


### [35] [Making Large Language Models Efficient Dense Retrievers](https://arxiv.org/abs/2512.20612)
*Yibin Lei,Shwai He,Ang Li,Andrew Yates*

Main category: cs.IR

TL;DR: EffiR框架通过分析LLM在检索任务中的层级冗余性，发现MLP层比注意力层更容易剪枝，并提出粗到细的MLP压缩策略，在保持性能的同时显著减少模型大小和推理成本。


<details>
  <summary>Details</summary>
Motivation: 尽管直接微调大语言模型用于稠密检索效果很好，但参数量大导致计算效率低。现有研究显示LLM在生成任务中存在层级冗余，但尚不清楚在检索任务中是否也存在类似冗余，因为检索任务需要将整个序列编码为固定表示而非迭代生成标记。

Method: 1) 全面分析LLM基稠密检索器的层级冗余性；2) 发现MLP层比注意力层更容易剪枝；3) 提出EffiR框架，采用粗到细策略进行大规模MLP压缩：先粗粒度深度减少，再细粒度宽度减少；4) 结合检索特定的微调。

Result: 在多种BEIR数据集和LLM骨干网络上，EffiR在保持全尺寸模型性能的同时，显著减少了模型大小和推理成本。

Conclusion: LLM在检索任务中存在独特的层级冗余模式（MLP层比注意力层更易剪枝），EffiR框架通过针对性的压缩策略实现了高效的检索器，平衡了性能与效率。

Abstract: Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models.

</details>
