<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 76]
- [cs.IR](#cs.IR) [Total: 16]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [The Hypocrisy Gap: Quantifying Divergence Between Internal Belief and Chain-of-Thought Explanation via Sparse Autoencoders](https://arxiv.org/abs/2602.02496)
*Shikhar Shiromani,Archie Chaudhury,Sri Pranav Kunda*

Main category: cs.CL

TL;DR: 提出Hypocrisy Gap机制化度量方法，使用稀疏自编码器检测大语言模型内部推理与最终输出之间的不一致性，识别模型迎合用户的虚伪行为。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常表现出不忠实行为，其最终答案与内部思维链推理显著不同，以迎合对话用户。现有方法难以有效检测这种虚伪行为。

Method: 引入Hypocrisy Gap机制化度量，利用稀疏自编码器量化模型内部推理与最终生成之间的差异。通过稀疏线性探针推导内部真实信念，在潜在空间中与最终生成轨迹进行数学比较。

Result: 在Gemma、Llama和Qwen模型上使用Anthropic的奉承基准测试，该方法在检测奉承运行时的AUROC达到0.55-0.73，在检测虚伪情况（模型内部"知道"用户错误）时的AUROC达到0.55-0.74，一致优于基于决策对齐的对数概率基线（0.41-0.50 AUROC）。

Conclusion: Hypocrisy Gap提供了一种有效的机制化方法来检测大语言模型的虚伪行为，为评估模型忠实性提供了新工具，优于传统的基于概率的方法。

Abstract: Large Language Models (LLMs) frequently exhibit unfaithful behavior, producing a final answer that differs significantly from their internal chain of thought (CoT) reasoning in order to appease the user they are conversing with. In order to better detect this behavior, we introduce the Hypocrisy Gap, a mechanistic metric utilizing Sparse Autoencoders (SAEs) to quantify the divergence between a model's internal reasoning and its final generation. By mathematically comparing an internal truth belief, derived via sparse linear probes, to the final generated trajectory in latent space, we quantify and detect a model's tendency to engage in unfaithful behavior. Experiments on Gemma, Llama, and Qwen models using Anthropic's Sycophancy benchmark show that our method achieves an AUROC of 0.55-0.73 for detecting sycophantic runs and 0.55-0.74 for hypocritical cases where the model internally "knows" the user is wrong, consistently outperforming a decision-aligned log-probability baseline (0.41-0.50 AUROC).

</details>


### [2] [STEMVerse: A Dual-Axis Diagnostic Framework for STEM Reasoning in Large Language Models](https://arxiv.org/abs/2602.02497)
*Xuzhao Li,Xuchen Li,Jian Zhao,Shiyu Hu*

Main category: cs.CL

TL;DR: STEMVerse是一个诊断框架，用于系统分析大语言模型在STEM领域的推理能力，通过"学科×认知"双轴标签重新组织20,000多个STEM问题，揭示模型的结构性失败模式。


<details>
  <summary>Details</summary>
Motivation: 当前评估范式将基准测试视为孤立的"筒仓"，仅提供聚合分数，无法区分模型错误源于领域知识不足还是认知能力缺陷，限制了诊断价值。

Method: 提出STEMVerse诊断框架，将20,000多个STEM问题从主流基准重新聚合到统一的"学科×认知"能力空间，为每个实例分配双轴标签，系统评估不同参数规模和训练范式的代表性LLM家族。

Result: 实证结果揭示了STEM推理中的结构性失败模式，通过多学科覆盖和细粒度认知分层，为理解LLM的科学推理特性提供了清晰且可操作的视角。

Conclusion: STEMVerse通过整合多学科覆盖和细粒度认知分层，为系统分析LLM的STEM推理能力提供了统一诊断框架，能够识别结构性失败模式，提升评估的诊断价值。

Abstract: As Large Language Models (LLMs) achieve significant breakthroughs in complex reasoning tasks, evaluating their proficiency in science, technology, engineering, and mathematics (STEM) has become a primary method for measuring machine intelligence. However, current evaluation paradigms often treat benchmarks as isolated "silos," offering only monolithic aggregate scores that neglect the intricacies of both academic specialization and cognitive depth. This result-oriented approach fails to distinguish whether model errors stem from insufficient domain knowledge or deficiencies in cognitive capacity, thereby limiting the diagnostic value. To address this, we propose STEMVerse, a diagnostic framework designed to systematically analyze the STEM reasoning capabilities of LLMs. This framework characterizes model performance across academic specialization and cognitive complexity to map the capability required for reasoning. We re-aggregate over 20,000 STEM problems from mainstream benchmarks into a unified "Discipline $\times$ Cognition" capability space, assigning dual-axis labels to every instance. Utilizing this unified diagnostic framework, we systematically evaluate representative LLM families across varying parameter scales and training paradigms. Our empirical results reveal structural failure patterns in STEM reasoning. By integrating multi-disciplinary coverage and fine-grained cognitive stratification into a unified framework, STEMVerse provides a clear and actionable perspective for understanding the scientific reasoning characteristics of LLMs.

</details>


### [3] [Test-Time Detoxification without Training or Learning Anything](https://arxiv.org/abs/2602.02498)
*Baturay Saglam,Dionysis Kalogerias*

Main category: cs.CL

TL;DR: 提出一种基于零阶优化的测试时方法，通过调整输入词嵌入来降低语言模型生成内容的毒性，无需模型重训练或梯度访问


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型即使在良性输入下也可能产生有毒或不适当的内容，现有方法通常需要模型重训练、梯度访问或学习辅助组件，这些方法成本高且难以跨模型家族或黑盒设置迁移

Method: 提出测试时程序，使用零阶优化近似完成内容毒性相对于输入词嵌入的梯度，通过少量下降步骤引导生成向低毒性方向，仅需输入词嵌入访问、毒性评分函数和模型前向评估

Result: 该方法在不同模型和提示下实现了稳健的毒性降低，在大多数设置中达到了最佳的毒性-质量权衡

Conclusion: 将词嵌入定位为有效的控制变量，鼓励更广泛地使用黑盒优化来引导自回归语言模型实现可扩展、更安全的文本生成，无需任何训练或中间计算访问

Abstract: Large language models can produce toxic or inappropriate text even for benign inputs, creating risks when deployed at scale. Detoxification is therefore important for safety and user trust, particularly when we want to reduce harmful content without sacrificing the model's generation quality. Many existing approaches rely on model retraining, gradients, or learned auxiliary components, which can be costly and may not transfer across model families or to truly black-box settings. We introduce a test-time procedure that approximates the gradient of completion toxicity with respect to the input embeddings and uses a small number of descent steps to steer generation toward less toxic continuations. This is achieved with zeroth-order optimization that requires only access to input embeddings, a toxicity scoring function, and forward evaluations of the model. Empirically, the approach delivers robust toxicity reductions across models and prompts and, in most settings, achieves the best overall toxicity-quality trade-off. More broadly, our work positions word embeddings as effective control variables and encourages wider use of black-box optimization to guide autoregressive language models toward scalable, safer text generation, without requiring any training or access to intermediate computations.

</details>


### [4] [ROSA-Tuning: Enhancing Long-Context Modeling via Suffix Matching](https://arxiv.org/abs/2602.02499)
*Yunao Zheng,Xiaojie Wang,Lei Ren,Wei Chen*

Main category: cs.CL

TL;DR: ROSA-Tuning提出了一种检索-召回机制，通过CPU-based ROSA检索模块和异步CPU-GPU流水线，在保持计算效率的同时显著提升了窗口注意力模型的长上下文建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有高效注意力方法虽然降低了计算复杂度，但通常存在模型状态覆盖范围有限的问题，无法有效处理长上下文任务。

Method: 1) 引入并行CPU-based ROSA检索模块，高效定位长上下文中与当前查询相关的历史位置；2) 通过可训练方式将检索信息注入模型状态；3) 设计二进制离散化策略和反事实梯度算法实现端到端训练；4) 采用异步CPU-GPU流水线优化整体执行效率。

Result: 在Qwen3-Base-1.7B上的系统评估表明，ROSA-Tuning显著恢复了窗口注意力模型的长上下文建模能力，在LongBench等基准测试中达到接近甚至匹配全局注意力的性能，同时保持了与窗口注意力方法相当的计算效率和GPU内存使用。

Conclusion: ROSA-Tuning为高效长上下文处理提供了新的技术路径，通过检索-召回机制在计算效率和长上下文建模能力之间取得了良好平衡。

Abstract: Long-context capability and computational efficiency are among the central challenges facing today's large language models. Existing efficient attention methods reduce computational complexity, but they typically suffer from a limited coverage of the model state. This paper proposes ROSA-Tuning, a retrieval-and-recall mechanism for enhancing the long-context modeling ability of pretrained models. Beyond the standard attention mechanism, ROSA-Tuning introduces in parallel a CPU-based ROSA (RWKV Online Suffix Automaton) retrieval module, which efficiently locates historical positions in long contexts that are relevant to the current query, and injects the retrieved information into the model state in a trainable manner; subsequent weighted fusion can then be handled by range-restricted attention. To enable end-to-end training, we design a binary discretization strategy and a counterfactual gradient algorithm, and further optimize overall execution efficiency via an asynchronous CPU-GPU pipeline. Systematic evaluations on Qwen3-Base-1.7B show that ROSA-Tuning substantially restores the long-context modeling ability of windowed-attention models, achieving performance close to and in some cases matching global attention on benchmarks such as LongBench, while maintaining computational efficiency and GPU memory usage that are nearly comparable to windowed-attention methods, offering a new technical path for efficient long-context processing. The example code can be found at https://github.com/zyaaa-ux/ROSA-Tuning.

</details>


### [5] [Graph-Augmented Reasoning with Large Language Models for Tobacco Pest and Disease Management](https://arxiv.org/abs/2602.02635)
*Siyu Li,Chenwei Song,Qi Zhou,Wan Zhou,Xinyi Liu*

Main category: cs.CL

TL;DR: 提出了一种基于图增强推理的烟草病虫害管理框架，通过知识图谱将结构化领域知识整合到LLM中，以提供基于关系的证据来指导答案生成。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在烟草病虫害管理中存在局限性：1）缺乏结构化领域知识；2）容易产生幻觉或不恰当的治疗建议；3）难以处理需要多跳推理的复杂问题。

Method: 1）构建领域特定的知识图谱；2）检索查询相关的子图作为关系证据；3）使用ChatGLM作为Transformer主干，结合LoRA进行参数高效微调；4）采用图神经网络学习节点表示，捕捉症状-疾病-治疗依赖关系；5）将检索到的图证据整合到LLM输入中。

Result: 实验结果显示该方法相比纯文本基线有持续改进，在多跳和比较推理问题上获得最大提升，这些问题需要链接多个关系。

Conclusion: 图增强推理框架通过整合结构化知识图谱显著提升了LLM在烟草病虫害管理中的性能，特别是在需要复杂推理的任务上，能够提供基于证据的领域一致性建议并减少幻觉。

Abstract: This paper proposes a graph-augmented reasoning framework for tobacco pest and disease management that integrates structured domain knowledge into large language models. Building on GraphRAG, we construct a domain-specific knowledge graph and retrieve query-relevant subgraphs to provide relational evidence during answer generation. The framework adopts ChatGLM as the Transformer backbone with LoRA-based parameter-efficient fine-tuning, and employs a graph neural network to learn node representations that capture symptom-disease-treatment dependencies. By explicitly modeling diseases, symptoms, pesticides, and control measures as linked entities, the system supports evidence-aware retrieval beyond surface-level text similarity. Retrieved graph evidence is incorporated into the LLM input to guide generation toward domain-consistent recommendations and to mitigate hallucinated or inappropriate treatments. Experimental results show consistent improvements over text-only baselines, with the largest gains observed on multi-hop and comparative reasoning questions that require chaining multiple relations.

</details>


### [6] [WideSeek: Advancing Wide Research via Multi-Agent Scaling](https://arxiv.org/abs/2602.02636)
*Ziyang Huang,Haolin Ren,Xiaowei Yuan,Jiawei Wang,Zhongtao Jiang,Kun Xu,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: 本文提出宽研究范式，构建了WideSeekBench基准和WideSeek多智能体架构，通过端到端强化学习优化并行信息搜索能力。


<details>
  <summary>Details</summary>
Motivation: 搜索智能正从深度研究向宽研究演进，但缺乏专门评估搜索广度的基准和优化方法，阻碍了该领域的发展。

Method: 1) 构建WideSeekBench通用宽信息搜索基准，通过多阶段数据流水线确保目标信息量、逻辑约束和领域多样性；2) 提出WideSeek动态分层多智能体架构，能根据任务需求自主分叉并行子智能体；3) 设计统一训练框架，线性化多智能体轨迹并使用端到端强化学习优化系统。

Result: 实验结果表明WideSeek和多智能体强化学习的有效性，证明增加智能体数量是推进宽研究范式的有前景方向。

Conclusion: 宽研究范式需要专门的基准和优化方法，WideSeekBench和WideSeek架构为解决并行约束下的全面信息检索与合成问题提供了有效方案。

Abstract: Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedicated benchmarks and optimization methodologies for search breadth. To address these challenges, we take a deep dive into Wide Research from two perspectives: Data Pipeline and Agent Optimization. First, we produce WideSeekBench, a General Broad Information Seeking (GBIS) benchmark constructed via a rigorous multi-phase data pipeline to ensure diversity across the target information volume, logical constraints, and domains. Second, we introduce WideSeek, a dynamic hierarchical multi-agent architecture that can autonomously fork parallel sub-agents based on task requirements. Furthermore, we design a unified training framework that linearizes multi-agent trajectories and optimizes the system using end-to-end RL. Experimental results demonstrate the effectiveness of WideSeek and multi-agent RL, highlighting that scaling the number of agents is a promising direction for advancing the Wide Research paradigm.

</details>


### [7] [Monotonicity as an Architectural Bias for Robust Language Models](https://arxiv.org/abs/2602.02686)
*Patrick Cooper,Alireza Nadali,Ashutosh Trivedi,Alvaro Velasquez*

Main category: cs.CL

TL;DR: 通过选择性约束Transformer中的前馈子层实现单调性，可在保持性能的同时显著提升语言模型的鲁棒性，将对抗攻击成功率从69%降至19%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在对抗性提示和越狱攻击下表现出脆弱性，即使经过大量对齐和微调。这种脆弱性反映了现代神经语言模型的一个更广泛挑战：高维输入空间中的微小、精心结构的扰动可能导致内部语义表示和输出的巨大不可预测变化。

Method: 研究单调性作为Transformer语言模型的架构归纳偏置。在序列到序列Transformer的前馈子层中强制实施单调性，同时保持注意力机制不受约束。这种架构分离允许通过注意力显式引入否定、矛盾和上下文交互，同时确保后续语义细化是保序的。

Result: 单调性显著提高了鲁棒性：对抗攻击成功率从约69%降至19%，而标准摘要性能仅略微下降。单调语言模型保持了其预训练对应模型的性能。

Conclusion: 单调性与神经语言模型表达能力之间的权衡并非固有。通过选择性在前馈子层中实施单调性，可以获得既保持性能又显著提高鲁棒性的语言模型，为解决语言模型脆弱性问题提供了有前景的架构解决方案。

Abstract: Large language models (LLMs) are known to exhibit brittle behavior under adversarial prompts and jailbreak attacks, even after extensive alignment and fine-tuning. This fragility reflects a broader challenge of modern neural language models: small, carefully structured perturbations in high-dimensional input spaces can induce large and unpredictable changes in internal semantic representations and output.
  We investigate monotonicity as an architectural inductive bias for improving the robustness of Transformer-based language models. Monotonicity constrains semantic transformations so that strengthening information, evidence, or constraints cannot lead to regressions in the corresponding internal representations. Such order-preserving behavior has long been exploited in control and safety-critical systems to simplify reasoning and improve robustness, but has traditionally been viewed as incompatible with the expressivity required by neural language models.
  We show that this trade-off is not inherent. By enforcing monotonicity selectively in the feed-forward sublayers of sequence-to-sequence Transformers -- while leaving attention mechanisms unconstrained -- we obtain monotone language models that preserve the performance of their pretrained counterparts. This architectural separation allows negation, contradiction, and contextual interactions to be introduced explicitly through attention, while ensuring that subsequent semantic refinement is order-preserving. Empirically, monotonicity substantially improves robustness: adversarial attack success rates drop from approximately 69% to 19%, while standard summarization performance degrades only marginally.

</details>


### [8] [InfMem: Learning System-2 Memory Control for Long-Context Agent](https://arxiv.org/abs/2602.02704)
*Xinyu Wang,Mingze Li,Peng Lu,Xiao-Wen Chang,Lifeng Shang,Jinping Li,Fei Mi,Prasanna Parthasarathi,Yufei Cui*

Main category: cs.CL

TL;DR: InfMem是一个控制中心代理，通过主动监控证据充分性、执行针对性文档检索和应用证据感知联合压缩，在超长文档问答中显著提升性能并减少推理时间。


<details>
  <summary>Details</summary>
Motivation: 超长文档推理需要在严格内存约束下综合分散在远距离段落中的稀疏证据。现有的流式代理的被动内存更新策略往往无法保留多跳推理所需的低显著性桥梁证据。

Method: 提出InfMem控制中心代理，采用PreThink-Retrieve-Write协议实现系统2式控制。通过主动监控证据充分性、执行针对性文档检索和应用证据感知联合压缩来更新有限内存。引入实用的SFT-to-RL训练方法，将检索、写入和停止决策与最终任务正确性对齐。

Result: 在32k到1M token的超长QA基准测试中，InfMem始终优于MemAgent。具体来说，在Qwen3-1.7B、Qwen3-4B和Qwen2.5-7B上分别提高了平均绝对准确率+10.17、+11.84和+8.23个百分点，同时通过自适应提前停止平均减少了3.9倍推理时间（最高达5.1倍）。

Conclusion: InfMem通过主动控制策略有效解决了超长文档推理中的证据保留问题，在保持内存效率的同时显著提升了多跳推理性能，并通过自适应停止机制大幅减少了计算开销。

Abstract: Reasoning over ultra-long documents requires synthesizing sparse evidence scattered across distant segments under strict memory constraints. While streaming agents enable scalable processing, their passive memory update strategy often fails to preserve low-salience bridging evidence required for multi-hop reasoning. We propose InfMem, a control-centric agent that instantiates System-2-style control via a PreThink-Retrieve-Write protocol. InfMem actively monitors evidence sufficiency, performs targeted in-document retrieval, and applies evidence-aware joint compression to update a bounded memory. To ensure reliable control, we introduce a practical SFT-to-RL training recipe that aligns retrieval, writing, and stopping decisions with end-task correctness. On ultra-long QA benchmarks from 32k to 1M tokens, InfMem consistently outperforms MemAgent across backbones. Specifically, InfMem improves average absolute accuracy by +10.17, +11.84, and +8.23 points on Qwen3-1.7B, Qwen3-4B, and Qwen2.5-7B, respectively, while reducing inference time by $3.9\times$ on average (up to $5.1\times$) via adaptive early stopping.

</details>


### [9] [Predicting first-episode homelessness among US Veterans using longitudinal EHR data: time-varying models and social risk factors](https://arxiv.org/abs/2602.02731)
*Rohan Pandey,Haijuan Yan,Hong Yu,Jack Tsai*

Main category: cs.CL

TL;DR: 利用电子健康记录数据预测退伍军人首次无家可归风险，比较传统机器学习、Transformer和LLM模型，发现融入社会行为因素的纵向模型显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 美国退伍军人无家可归问题严重，需要主动干预策略。当前缺乏有效的风险预测工具来识别高危人群，以便实施预防性措施。

Method: 回顾性预后研究，分析4,276,403名退伍军人事务部患者的EHR数据（2016年观察期），预测2017年首次无家可归事件（3-12个月后）。构建静态和时间变化的EHR表征，采用临床医生指导的逻辑建模临床状况和社会风险的持续性。比较经典机器学习、基于Transformer的掩码语言模型和微调大语言模型的性能。

Result: 融入社会行为因素的纵向模型将精确率-召回率曲线下面积（PR-AUC）提升15-30%。在风险最高的1%人群中，各时间点的阳性预测值：3个月3.93-4.72%，6个月7.39-8.30%，9个月9.84-11.41%，12个月11.65-13.80%。大语言模型在区分度上不及编码器模型，但在不同种族群体间表现差异较小。

Conclusion: 纵向、社会信息丰富的EHR建模能将无家可归风险集中在可操作的层级中，为高危退伍军人提供有针对性的数据驱动预防策略。尽管LLM在整体性能上稍逊，但在减少种族差异方面表现更好。

Abstract: Homelessness among US veterans remains a critical public health challenge, yet risk prediction offers a pathway for proactive intervention. In this retrospective prognostic study, we analyzed electronic health record (EHR) data from 4,276,403 Veterans Affairs patients during a 2016 observation period to predict first-episode homelessness occurring 3-12 months later in 2017 (prevalence: 0.32-1.19%). We constructed static and time-varying EHR representations, utilizing clinician-informed logic to model the persistence of clinical conditions and social risks over time. We then compared the performance of classical machine learning, transformer-based masked language models, and fine-tuned large language models (LLMs). We demonstrate that incorporating social and behavioral factors into longitudinal models improved precision-recall area under the curve (PR-AUC) by 15-30%. In the top 1% risk tier, models yielded positive predictive values ranging from 3.93-4.72% at 3 months, 7.39-8.30% at 6 months, 9.84-11.41% at 9 months, and 11.65-13.80% at 12 months across model architectures. Large language models underperformed encoder-based models on discrimination but showed smaller performance disparities across racial groups. These results demonstrate that longitudinal, socially informed EHR modeling concentrates homelessness risk into actionable strata, enabling targeted and data-informed prevention strategies for at-risk veterans.

</details>


### [10] [Time-Critical Multimodal Medical Transportation: Organs, Patients, and Medical Supplies](https://arxiv.org/abs/2602.02736)
*Elaheh Sabziyan Varnousfaderani,Syed A. M. Shihab,Mohammad Taghizadeh*

Main category: cs.CL

TL;DR: 提出一种用于医疗运输的多模式车辆调度贪心启发式算法，比较四种车队配置，评估其在最小化运营成本、充电/燃料成本和总运输时间方面的效果。


<details>
  <summary>Details</summary>
Motivation: 医疗运输（器官、患者、医疗物资）的及时性至关重要，传统救护车受交通拥堵限制，直升机等空中工具成本高，新兴无人机和eVTOL存在航程和天气限制，需要整合地面和空中车辆的多模式运输系统来提高效率。

Method: 提出一种构造性贪心启发式算法，用于多模式医疗运输车辆调度。算法考虑了兼容路线上的有效载荷整合、地面交通拥堵和空中天气条件，并比较了四种车队配置：仅救护车、救护车+无人机、救护车+eVTOL、以及救护车+无人机+eVTOL的完全集成车队。

Result: 在相同条件下评估了四种车队类型，以确定最有效的配置，旨在满足医疗运输需求的同时，最小化运营成本、充电/燃料成本和总运输时间。

Conclusion: 多模式运输系统整合地面和空中车辆的优势，可提高医疗运输效率；提出的贪心启发式算法能快速处理车辆调度，相比计算密集型优化模型更高效；通过比较不同车队配置，可找到最优方案以平衡成本和时间。

Abstract: Timely transportation of organs, patients, and medical supplies is critical to modern healthcare, particularly in emergencies and transplant scenarios where even short delays can severely impact outcomes. Traditional ground-based vehicles such as ambulances are often hindered by traffic congestion; while air vehicles such as helicopters are faster but costly. Emerging air vehicles -- Unmanned Aerial Vehicles and electric vertical take-off and landing aircraft -- have lower operating costs, but remain limited by range and susceptibility to weather conditions. A multimodal transportation system that integrates both air and ground vehicles can leverage the strengths of each to enhance overall transportation efficiency. This study introduces a constructive greedy heuristic algorithm for multimodal vehicle dispatching for medical transportation. Four different fleet configurations were tested: (i) ambulances only, (ii) ambulances with Unmanned Aerial Vehicles, (iii) ambulances with electric vertical take-off and landing aircraft, and (iv) a fully integrated fleet of ambulances, Unmanned Aerial Vehicles, and electric vertical take-off and landing aircraft. The algorithm incorporates payload consolidation across compatible routes, accounts for traffic congestion in ground operations and weather conditions in aerial operations, while enabling rapid vehicle dispatching compared to computationally intensive optimization models. Using a common set of conditions, we evaluate all four fleet types to identify the most effective configurations for fulfilling medical transportation needs while minimizing operating costs, recharging/fuel costs, and total transportation time.

</details>


### [11] [From Task Solving to Robust Real-World Adaptation in LLM Agents](https://arxiv.org/abs/2602.02760)
*Pouya Pezeshkpour,Estevam Hruschka*

Main category: cs.CL

TL;DR: 该论文提出了一个评估LLM智能体在实际部署中鲁棒性的框架，测试了在部分可观测性、动态环境、噪声信号和动态智能体状态等四种操作环境下的表现，发现现有评估方法高估了智能体的实际准备程度。


<details>
  <summary>Details</summary>
Motivation: 现有评估通常假设"干净接口"：动态规范稳定、工具传感器可靠、成功由单一明确目标衡量，这高估了智能体在实际部署中的准备程度。实际部署中智能体面临规则不明确、信号不可靠、环境变化以及多利益相关者隐含目标等挑战。

Method: 使用基于网格的游戏环境，设计具有简单目标但需要长期执行的测试场景。违反干净接口假设但仍可解决，迫使智能体推断规则、支付信息成本、适应环境和内部变化，并在噪声下谨慎行动。测试了五种最先进的LLM智能体，分析网格大小和时域长度对性能的影响。

Result: 发现名义任务解决能力与实际部署鲁棒性之间存在巨大差距。随着网格大小和时域增加，性能普遍下降，但排名不稳定：当策略与不确定性机制匹配时，较弱的模型可能击败较强的模型。智能体在没有明确指令的情况下权衡完成度、效率和惩罚避免，表明部分目标推断能力。消融实验和特征分析揭示了模型特定的敏感性和失败驱动因素。

Conclusion: 现有LLM智能体在实际部署条件下表现不佳，特别是在部分可观测性、噪声和非平稳性环境下。研究强调了需要开发验证机制、安全行动选择以及在部分可观测性、噪声和非平稳性下的目标推断方法，以提高智能体的实际部署鲁棒性。

Abstract: Large language models are increasingly deployed as specialized agents that plan, call tools, and take actions over extended horizons. Yet many existing evaluations assume a "clean interface" where dynamics are specified and stable, tools and sensors are reliable, and success is captured by a single explicit objective-often overestimating real-world readiness. In practice, agents face underspecified rules, unreliable signals, shifting environments, and implicit, multi-stakeholder goals. The challenge is therefore not just solving tasks, but adapting while solving: deciding what to trust, what is wanted, when to verify, and when to fall back or escalate. We stress-test deployment-relevant robustness under four operational circumstances: partial observability, dynamic environments, noisy signals, and dynamic agent state. We benchmark agentic LLMs in a grid-based game with a simple goal but long-horizon execution. Episodes violate clean-interface assumptions yet remain solvable, forcing agents to infer rules, pay for information, adapt to environmental and internal shifts, and act cautiously under noise. Across five state-of-the-art LLM agents, we find large gaps between nominal task-solving and deployment-like robustness. Performance generally degrades as grid size and horizon increase, but rankings are unstable: weaker models can beat stronger ones when strategy matches the uncertainty regime. Despite no explicit instruction, agents trade off completion, efficiency, and penalty avoidance, suggesting partial objective inference. Ablations and feature analyses reveal model-specific sensitivities and failure drivers, motivating work on verification, safe action selection, and objective inference under partial observability, noise, and non-stationarity.

</details>


### [12] [AmharicStoryQA: A Multicultural Story Question Answering Benchmark in Amharic](https://arxiv.org/abs/2602.02774)
*Israel Abebe Azime,Abenezer Kebede Angamo,Hana Mekonen Tamiru,Dagnachew Mekonnen Marilign,Philipp Slusallek,Seid Muhie Yimam,Dietrich Klakow*

Main category: cs.CL

TL;DR: 本文介绍了AmharicStoryQA，一个基于阿姆哈拉语不同地区文化多样性叙事的长序列故事问答基准，揭示了现有LLM在叙事理解上的显著差距，并强调需要超越语言层面评估的文化基准。


<details>
  <summary>Details</summary>
Motivation: 当前多语言和文化评估基准通常将语言和文化等同，用性能作为模型理解语言的代理。然而，这种方法忽视了同一语言内存在的有意义的文化差异。研究者认为这种评估方法存在缺陷，需要关注语言内的文化多样性。

Method: 研究聚焦埃塞俄比亚不同地区的叙事，构建了AmharicStoryQA基准——一个基于阿姆哈拉语地区文化多样性叙事的长序列故事问答数据集。通过这个基准评估现有LLM，并分析监督微调在不同地区和评估设置下的改进效果。

Result: 研究揭示了现有LLM在叙事理解上的显著差距，显示了评估结果中明显的地区差异，并发现监督微调在不同地区和评估设置下产生不均衡的改进效果。

Conclusion: 需要超越语言层面评估的文化基础基准，以更准确地评估和改进低资源语言的叙事理解能力。语言和文化不应被视为同义词，评估应考虑同一语言内的文化多样性。

Abstract: With the growing emphasis on multilingual and cultural evaluation benchmarks for large language models, language and culture are often treated as synonymous, and performance is commonly used as a proxy for a models understanding of a given language. In this work, we argue that such evaluations overlook meaningful cultural variation that exists within a single language. We address this gap by focusing on narratives from different regions of Ethiopia and demonstrate that, despite shared linguistic characteristics, region-specific and domain-specific content substantially influences language evaluation outcomes. To this end, we introduce \textbf{\textit{AmharicStoryQA}}, a long-sequence story question answering benchmark grounded in culturally diverse narratives from Amharic-speaking regions. Using this benchmark, we reveal a significant narrative understanding gap in existing LLMs, highlight pronounced regional differences in evaluation results, and show that supervised fine-tuning yields uneven improvements across regions and evaluation settings. Our findings emphasize the need for culturally grounded benchmarks that go beyond language-level evaluation to more accurately assess and improve narrative understanding in low-resource languages.

</details>


### [13] [When Efficient Communication Explains Convexity](https://arxiv.org/abs/2602.02821)
*Ashvin Ranjan,Shane Steinert-Threlkeld*

Main category: cs.CL

TL;DR: 该论文通过信息瓶颈方法研究语言语义类型学，发现最优沟通效率与分布凸性相关，并识别出影响这一关系的核心因素。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解高效沟通理论如何解释语言语义类型学中的跨语言变异，并探究哪些因素使这种解释成功。

Method: 采用信息瓶颈方法来形式化简洁性与信息性之间的权衡，首先分析最优性与凸性之间的相关性，然后通过操纵IB框架中的建模参数来确定驱动这种相关性的因素。

Result: 研究发现沟通需求分布的凸性在最优性与凸性之间的相关性中起着特别重要的作用，这超越了单纯展示高效沟通可以解释语义类型学，而是解释了其原因。

Conclusion: 研究不仅表明高效沟通可以解释语义类型学的某些方面，更重要的是识别了驱动这种解释成功的底层因素，特别是沟通需求分布的凸性特征。

Abstract: Much recent work has argued that the variation in the languages of the world can be explained from the perspective of efficient communication; in particular, languages can be seen as optimally balancing competing pressures to be simple and to be informative. Focusing on the expression of meaning -- semantic typology -- the present paper asks what factors are responsible for successful explanations in terms of efficient communication. Using the Information Bottleneck (IB) approach to formalizing this trade-off, we first demonstrate and analyze a correlation between optimality in the IB sense and a novel generalization of convexity to this setting. In a second experiment, we manipulate various modeling parameters in the IB framework to determine which factors drive the correlation between convexity and optimality. We find that the convexity of the communicative need distribution plays an especially important role. These results move beyond showing that efficient communication can explain aspects of semantic typology into explanations for why that is the case by identifying which underlying factors are responsible.

</details>


### [14] [R2-Router: A New Paradigm for LLM Routing with Reasoning](https://arxiv.org/abs/2602.02823)
*Jiaqi Xue,Qian Lou,Jiarong Xing,Heng Huang*

Main category: cs.CL

TL;DR: R2-Router通过将输出长度预算作为可控变量，联合选择最佳LLM和长度预算，实现比现有路由方法更低成本下的更高性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由器假设每个查询中每个LLM有固定的质量和成本，忽略了同一LLM的质量随输出长度变化。这导致路由器在估计成本超过预算时排除强大LLM，错失了这些LLM在缩短输出时仍能以较低成本提供高质量结果的机会。

Method: R2-Router将输出长度预算作为可控变量，联合选择最佳LLM和长度预算，通过长度约束指令强制执行预算。同时构建了R2-Bench，首个捕获LLM在不同输出长度预算下行为的路由数据集。

Result: 实验表明，R2-Router相比现有路由器，以4-5倍更低的成本实现了最先进的性能。

Conclusion: 这项工作开启了"路由即推理"的新方向，路由器从被动选择器演变为深思熟虑的推理器，探索使用哪个LLM以及在什么成本预算下使用。

Abstract: As LLMs proliferate with diverse capabilities and costs, LLM routing has emerged by learning to predict each LLM's quality and cost for a given query, then selecting the one with high quality and low cost. However, existing routers implicitly assume a single fixed quality and cost per LLM for each query, ignoring that the same LLM's quality varies with its output length. This causes routers to exclude powerful LLMs when their estimated cost exceeds the budget, missing the opportunity that these LLMs could still deliver high quality at reduced cost with shorter outputs. To address this, we introduce R2-Router, which treats output length budget as a controllable variable and jointly selects the best LLM and length budget, enforcing the budget via length-constrained instructions. This enables R2-Router to discover that a powerful LLM with constrained output can outperform a weaker LLM at comparable cost-efficient configurations invisible to prior methods. Together with the router framework, we construct R2-Bench, the first routing dataset capturing LLM behavior across diverse output length budgets. Experiments show that R2-Router achieves state-of-the-art performance at 4-5x lower cost compared with existing routers. This work opens a new direction: routing as reasoning, where routers evolve from reactive selectors to deliberate reasoners that explore which LLM to use and at what cost budget.

</details>


### [15] [Controlling Output Rankings in Generative Engines for LLM-based Search](https://arxiv.org/abs/2602.03608)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Yifeng Luo,Huimin Zeng,Man Luo,Haohan Wang*

Main category: cs.CL

TL;DR: 提出CORE方法优化LLM搜索中的产品推荐排名，通过在检索内容后添加优化内容来提升特定产品的排名，在四个主流LLM上实现平均91.4%的Top-5推广成功率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM搜索的兴起，用户直接获得产品推荐而非传统搜索结果，但LLM的初始检索顺序严重影响推荐结果，导致小型企业和独立创作者处于劣势，缺乏曝光机会。

Method: 提出CORE优化方法，通过向检索内容添加策略设计的优化内容来影响输出排名。开发了三种优化内容类型：基于字符串的、基于推理的和基于评价的。使用ProductBench基准进行评估，包含15个产品类别，每个类别200个产品及其亚马逊搜索结果。

Result: 在四个具备搜索能力的LLM（GPT-4o、Gemini-2.5、Claude-4、Grok-3）上实验显示，CORE在15个产品类别中平均达到91.4%的Top-5推广成功率、86.6%的Top-3成功率和80.3%的Top-1成功率，优于现有排名操纵方法，同时保持优化内容的流畅性。

Conclusion: CORE方法能有效控制LLM搜索中的输出排名，为改善小型企业和独立创作者的曝光问题提供了解决方案，同时保持了推荐质量。该方法在多个主流LLM上都表现出色，具有实际应用价值。

Abstract: The way customers search for and choose products is changing with the rise of large language models (LLMs). LLM-based search, or generative engines, provides direct product recommendations to users, rather than traditional online search results that require users to explore options themselves. However, these recommendations are strongly influenced by the initial retrieval order of LLMs, which disadvantages small businesses and independent creators by limiting their visibility.
  In this work, we propose CORE, an optimization method that \textbf{C}ontrols \textbf{O}utput \textbf{R}ankings in g\textbf{E}nerative Engines for LLM-based search. Since the LLM's interactions with the search engine are black-box, CORE targets the content returned by search engines as the primary means of influencing output rankings. Specifically, CORE optimizes retrieved content by appending strategically designed optimization content to steer the ranking of outputs. We introduce three types of optimization content: string-based, reasoning-based, and review-based, demonstrating their effectiveness in shaping output rankings. To evaluate CORE in realistic settings, we introduce ProductBench, a large-scale benchmark with 15 product categories and 200 products per category, where each product is associated with its top-10 recommendations collected from Amazon's search interface.
  Extensive experiments on four LLMs with search capabilities (GPT-4o, Gemini-2.5, Claude-4, and Grok-3) demonstrate that CORE achieves an average Promotion Success Rate of \textbf{91.4\% @Top-5}, \textbf{86.6\% @Top-3}, and \textbf{80.3\% @Top-1}, across 15 product categories, outperforming existing ranking manipulation methods while preserving the fluency of optimized content.

</details>


### [16] [CATNIP: LLM Unlearning via Calibrated and Tokenized Negative Preference Alignment](https://arxiv.org/abs/2602.02824)
*Zhengbang Yang,Yisheng Zhong,Junyuan Hong,Zhuangdi Zhu*

Main category: cs.CL

TL;DR: CATNIP提出了一种新的LLM遗忘方法，通过基于token置信度重新缩放遗忘效果，实现无需保留数据或对比响应对的有效知识遗忘，在安全性和隐私保护方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型中记忆的不良知识引发安全和隐私担忧，现有遗忘方法存在缺陷：基于梯度上升的方法会损害通用知识且依赖保留数据或对比对；负偏好对齐方法受限于参考模型选择且在现实数据设置中表现不佳。

Method: CATNIP（校准和token化的负偏好对齐）方法，通过根据模型token级置信度重新缩放遗忘效果，实现对遗忘的细粒度控制，无需保留数据或对比遗忘响应对。

Result: 在MUSE和WMDP基准测试上的广泛评估表明，CATNIP实现了有效的知识遗忘，在知识遗忘和保留之间达到更好的权衡，优于现有最先进方法。

Conclusion: CATNIP通过基于置信度的校准梯度更新解决了现有LLM遗忘方法的局限性，为选择性知识移除提供了更精确、数据高效且稳健的解决方案。

Abstract: Pretrained knowledge memorized in LLMs raises critical concerns over safety and privacy, which has motivated LLM Unlearning as a technique for selectively removing the influences of undesirable knowledge. Existing approaches, rooted in Gradient Ascent (GA), often degrade general domain knowledge while relying on retention data or curated contrastive pairs, which can be either impractical or data and computationally prohibitive. Negative Preference Alignment has been explored for unlearning to tackle the limitations of GA, which, however, remains confined by its choice of reference model and shows undermined performance in realistic data settings. These limitations raise two key questions: i) Can we achieve effective unlearning that quantifies model confidence in undesirable knowledge and uses it to calibrate gradient updates more precisely, thus reducing catastrophic forgetting? ii) Can we make unlearning robust to data scarcity and length variation? We answer both questions affirmatively with CATNIP (Calibrated and Tokenized Negative Preference Alignment), a principled method that rescales unlearning effects in proportion to the model's token-level confidence, thus ensuring fine-grained control over forgetting. Extensive evaluations on MUSE and WMDP benchmarks demonstrated that our work enables effective unlearning without requiring retention data or contrastive unlearning response pairs, with stronger knowledge forgetting and preservation tradeoffs than state-of-the-art methods.

</details>


### [17] [RAGTurk: Best Practices for Retrieval Augmented Generation in Turkish](https://arxiv.org/abs/2602.03652)
*Süha Kağan Köse,Mehmet Can Baytekin,Burak Aktaş,Bilge Kaan Görür,Evren Ayberk Munis,Deniz Yılmaz,Muhammed Yusuf Kartal,Çağrı Toraman*

Main category: cs.CL

TL;DR: 本文构建了首个土耳其语RAG数据集，系统评估了RAG管道各阶段，发现复杂方法如HyDE能显著提升准确性，但过度堆叠生成模块会损害性能，而简单的查询澄清结合重排序是高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前RAG设计指南主要针对英语，缺乏对土耳其语等形态丰富语言的研究。需要为土耳其语构建专门的RAG基准数据集和评估框架。

Method: 基于土耳其语维基百科和CulturaX构建土耳其语RAG数据集，包含问答对和相关段落块。评估RAG管道的七个阶段（查询转换、重排序到答案精炼），不使用任务特定微调。

Result: HyDE方法获得最高准确率85%，显著高于基线78.70%。使用交叉编码器重排序和上下文增强的Pareto最优配置达到84.60%准确率且成本更低。过度堆叠生成模块会扭曲形态线索而降低性能。

Conclusion: 为形态丰富语言设计RAG系统时，复杂方法能提升准确性，但需要平衡性能与成本。简单查询澄清结合稳健重排序是有效策略，避免过度堆叠生成模块对形态线索的破坏。

Abstract: Retrieval-Augmented Generation (RAG) enhances LLM factuality, yet design guidance remains English-centric, limiting insights for morphologically rich languages like Turkish. We address this by constructing a comprehensive Turkish RAG dataset derived from Turkish Wikipedia and CulturaX, comprising question-answer pairs and relevant passage chunks. We benchmark seven stages of the RAG pipeline, from query transformation and reranking to answer refinement, without task-specific fine-tuning. Our results show that complex methods like HyDE maximize accuracy (85%) that is considerably higher than the baseline (78.70%). Also a Pareto-optimal configuration using Cross-encoder Reranking and Context Augmentation achieves comparable performance (84.60%) with much lower cost. We further demonstrate that over-stacking generative modules can degrade performance by distorting morphological cues, whereas simple query clarification with robust reranking offers an effective solution.

</details>


### [18] [Act or Clarify? Modeling Sensitivity to Uncertainty and Cost in Communication](https://arxiv.org/abs/2602.02843)
*Polina Tsvilodub,Karl Mulligan,Todd Snider,Robert D. Hawkins,Michael Franke*

Main category: cs.CL

TL;DR: 人类在不确定情境下会根据预期遗憾进行理性权衡：当错误行动代价高时更倾向于寻求澄清，当行动成本低时则更可能直接行动。


<details>
  <summary>Details</summary>
Motivation: 研究人们在交流情境中如何权衡不确定性：是选择通过澄清问题来减少不确定性，还是直接在不确定性下行动。作者认为这种决策不仅取决于情境不确定性，还取决于替代行动的成本，且这两个因素会相互作用。

Method: 基于预期遗憾理论构建计算模型，并进行了两个实验：第一个实验检验纯粹语言情境下对问题的回应，第二个实验扩展到澄清问题与非语言行动之间的选择。

Result: 实验结果支持预测：当错误行动代价高昂时，不确定性对澄清问题决策的影响最大；人类倾向于根据在不确定性下行动可能遭受的损失风险，按比例寻求澄清。

Conclusion: 人类在交流中的澄清行为遵循理性权衡原则，基于预期遗憾的计算模型能够有效解释人们在不确定性下如何决策是否寻求澄清。

Abstract: When deciding how to act under uncertainty, agents may choose to act to reduce uncertainty or they may act despite that uncertainty.In communicative settings, an important way of reducing uncertainty is by asking clarification questions (CQs). We predict that the decision to ask a CQ depends on both contextual uncertainty and the cost of alternative actions, and that these factors interact: uncertainty should matter most when acting incorrectly is costly. We formalize this interaction in a computational model based on expected regret: how much an agent stands to lose by acting now rather than with full information. We test these predictions in two experiments, one examining purely linguistic responses to questions and another extending to choices between clarification and non-linguistic action. Taken together, our results suggest a rational tradeoff: humans tend to seek clarification proportional to the risk of substantial loss when acting under uncertainty.

</details>


### [19] [Which course? Discourse! Teaching Discourse and Generation in the Era of LLMs](https://arxiv.org/abs/2602.02878)
*Junyi Jessy Li,Yang Janet Liu,Kanishka Misra,Valentina Pyatkin,William Sheffield*

Main category: cs.CL

TL;DR: 提出一门新课程"计算话语与自然语言生成"，旨在整合话语处理与自然语言生成，填补本科课程空白


<details>
  <summary>Details</summary>
Motivation: NLP领域快速变化，需要设计能连接不同子领域的课程。话语处理具有丰富的语言学和计算模型，与开放域/长文本生成高度相关，但现有本科课程对此连接探索不足。

Method: 设计并开设了一门名为"计算话语与自然语言生成"的新课程，由具有互补专长的团队合作设计，在2025年秋季作为语言学与计算机科学交叉的高年级本科课程首次开设。

Result: 课程详细描述了课程内容，并基于独立调查得出启示，提出了未来发展方向。课程理念是深度整合理论与实证方面，在课堂和作业中培养探索性思维。

Conclusion: 该课程为NLP教育提供了一个创新模式，通过整合话语处理与自然语言生成，帮助学生在这个快速变化的领域中建立跨学科连接，并为未来课程设计提供了有价值的见解。

Abstract: The field of NLP has undergone vast, continuous transformations over the past few years, sparking debates going beyond discipline boundaries. This begs important questions in education: how do we design courses that bridge sub-disciplines in this shifting landscape? This paper explores this question from the angle of discourse processing, an area with rich linguistic insights and computational models for the intentional, attentional, and coherence structure of language. Discourse is highly relevant for open-ended or long-form text generation, yet this connection is under-explored in existing undergraduate curricula. We present a new course, "Computational Discourse and Natural Language Generation". The course is collaboratively designed by a team with complementary expertise and was offered for the first time in Fall 2025 as an upper-level undergraduate course, cross-listed between Linguistics and Computer Science. Our philosophy is to deeply integrate the theoretical and empirical aspects, and create an exploratory mindset inside the classroom and in the assignments. This paper describes the course in detail and concludes with takeaways from an independent survey as well as our vision for future directions.

</details>


### [20] [HALT: Hallucination Assessment via Log-probs as Time series](https://arxiv.org/abs/2602.02888)
*Ahmad Shapiro,Karan Taneja,Ashok Goel*

Main category: cs.CL

TL;DR: HALT是一种轻量级幻觉检测器，仅使用LLM生成的前20个token对数概率作为时间序列，通过GRU模型结合熵特征来学习模型校准偏差，在保持高性能的同时实现60倍加速。


<details>
  <summary>Details</summary>
Motivation: 幻觉仍然是大型语言模型的主要障碍，尤其在安全关键领域。现有方法要么需要访问模型内部状态（白盒），要么仅依赖表面文本（黑盒），缺乏既高效又具泛化能力的解决方案。

Method: HALT使用LLM生成的前20个token对数概率作为时间序列输入，通过门控循环单元模型结合熵特征来学习模型校准偏差。该方法不需要访问隐藏状态或注意力图，仅依赖输出对数概率。

Result: HALT在HUB基准测试中优于Lettuce（微调的modernBERT-base编码器），同时模型规模小30倍，速度提升60倍。HALT和HUB共同建立了跨多种LLM能力的有效幻觉检测框架。

Conclusion: HALT提供了一种轻量级、高效的幻觉检测方法，既不需要白盒访问权限，又比黑盒方法更具泛化能力，为实际应用中的幻觉检测提供了实用解决方案。

Abstract: Hallucinations remain a major obstacle for large language models (LLMs), especially in safety-critical domains. We present HALT (Hallucination Assessment via Log-probs as Time series), a lightweight hallucination detector that leverages only the top-20 token log-probabilities from LLM generations as a time series. HALT uses a gated recurrent unit model combined with entropy-based features to learn model calibration bias, providing an extremely efficient alternative to large encoders. Unlike white-box approaches, HALT does not require access to hidden states or attention maps, relying only on output log-probabilities. Unlike black-box approaches, it operates on log-probs rather than surface-form text, which enables stronger domain generalization and compatibility with proprietary LLMs without requiring access to internal weights. To benchmark performance, we introduce HUB (Hallucination detection Unified Benchmark), which consolidates prior datasets into ten capabilities covering both reasoning tasks (Algorithmic, Commonsense, Mathematical, Symbolic, Code Generation) and general purpose skills (Chat, Data-to-Text, Question Answering, Summarization, World Knowledge). While being 30x smaller, HALT outperforms Lettuce, a fine-tuned modernBERT-base encoder, achieving a 60x speedup gain on HUB. HALT and HUB together establish an effective framework for hallucination detection across diverse LLM capabilities.

</details>


### [21] [Equal Access, Unequal Interaction: A Counterfactual Audit of LLM Fairness](https://arxiv.org/abs/2602.02932)
*Alireza Amiri-Margavi,Arshia Gharagozlou,Amin Gholami Davodi,Seyed Pouyan Mousavi Davoudi,Hamidreza Hasani Balyani*

Main category: cs.CL

TL;DR: 研究发现大型语言模型虽然拒绝率一致，但在交互质量上存在系统性偏见：GPT-4对年轻男性用户表达更多不确定性，LLaMA在不同身份群体间情感差异显著。


<details>
  <summary>Details</summary>
Motivation: 现有公平性研究主要关注访问层面的拒绝行为和安全过滤，但公平访问并不保证获得响应后的交互质量公平。需要研究在获得访问后，LLMs对不同身份群体的语气、不确定性和语言框架是否存在差异。

Method: 使用反事实提示设计，在职业建议任务中评估GPT-4和LLaMA-3.1-70B，改变年龄、性别和国籍等身份属性。通过拒绝分析评估访问公平性，使用情感、礼貌和模糊表达等自动化语言指标测量交互质量，通过配对统计测试评估身份条件差异。

Result: 两个模型对所有身份的拒绝率均为零，表明访问公平。但交互质量存在系统性模型特定差异：GPT-4对年轻男性用户表达显著更高的模糊性，而LLaMA在不同身份群体间情感差异更广泛。

Conclusion: 公平性差异在交互层面可能持续存在，即使访问公平。这提示需要超越基于拒绝的审计，评估更广泛的交互质量公平性。

Abstract: Prior work on fairness in large language models (LLMs) has primarily focused on access-level behaviors such as refusals and safety filtering. However, equitable access does not ensure equitable interaction quality once a response is provided. In this paper, we conduct a controlled fairness audit examining how LLMs differ in tone, uncertainty, and linguistic framing across demographic identities after access is granted. Using a counterfactual prompt design, we evaluate GPT-4 and LLaMA-3.1-70B on career advice tasks while varying identity attributes along age, gender, and nationality. We assess access fairness through refusal analysis and measure interaction quality using automated linguistic metrics, including sentiment, politeness, and hedging. Identity-conditioned differences are evaluated using paired statistical tests. Both models exhibit zero refusal rates across all identities, indicating uniform access. Nevertheless, we observe systematic, model-specific disparities in interaction quality: GPT-4 expresses significantly higher hedging toward younger male users, while LLaMA exhibits broader sentiment variation across identity groups. These results show that fairness disparities can persist at the interaction level even when access is equal, motivating evaluation beyond refusal-based audits.

</details>


### [22] [Where Norms and References Collide: Evaluating LLMs on Normative Reasoning](https://arxiv.org/abs/2602.02975)
*Mitchell Abrams,Kaveh Eskandari Miandoab,Felix Gervits,Vasanth Sarathy,Matthias Scheutz*

Main category: cs.CL

TL;DR: 本文介绍了一个名为SNIC的诊断测试平台，用于评估大语言模型在情境规范推理方面的能力，发现当前最先进的LLMs在识别和应用社交规范方面存在显著困难。


<details>
  <summary>Details</summary>
Motivation: 在具身智能体（如机器人）的交互场景中，成功的沟通往往依赖于对社交规范的推理。然而，目前尚不清楚大语言模型是否支持这种基于规范的指代消解（NBRR）推理能力。

Method: 研究者开发了SNIC（情境中的规范）这一经过人工验证的诊断测试平台，专门用于探究最先进的LLMs如何提取和利用与NBRR相关的规范性原则。SNIC强调日常任务（如清洁、整理、服务）中出现的物理基础规范。

Result: 通过一系列受控评估发现，即使是最强大的LLMs也难以一致地识别和应用社交规范，特别是在规范是隐含的、未明确指定或存在冲突的情况下。

Conclusion: 这些发现揭示了当前LLMs在社交规范推理方面的盲点，突显了在社交情境化、具身化环境中部署基于语言的系统所面临的关键挑战。

Abstract: Embodied agents, such as robots, will need to interact in situated environments where successful communication often depends on reasoning over social norms: shared expectations that constrain what actions are appropriate in context. A key capability in such settings is norm-based reference resolution (NBRR), where interpreting referential expressions requires inferring implicit normative expectations grounded in physical and social context. Yet it remains unclear whether Large Language Models (LLMs) can support this kind of reasoning. In this work, we introduce SNIC (Situated Norms in Context), a human-validated diagnostic testbed designed to probe how well state-of-the-art LLMs can extract and utilize normative principles relevant to NBRR. SNIC emphasizes physically grounded norms that arise in everyday tasks such as cleaning, tidying, and serving. Across a range of controlled evaluations, we find that even the strongest LLMs struggle to consistently identify and apply social norms, particularly when norms are implicit, underspecified, or in conflict. These findings reveal a blind spot in current LLMs and highlight a key challenge for deploying language-based systems in socially situated, embodied settings.

</details>


### [23] [CPMobius: Iterative Coach-Player Reasoning for Data-Free Reinforcement Learning](https://arxiv.org/abs/2602.02979)
*Ran Li,Zeyuan Liu,Yinghao chen,Bingxiang He,Jiarui Yuan,Zixuan Fu,Weize Chen,Jinyi Hu,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: CPMöbius是一种无监督的协作式强化学习方法，通过教练-玩家角色合作提升LLM的数学推理能力，无需外部训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理能力提升严重依赖大量高质量人工标注数据，这种监督密集型训练范式难以持续扩展，存在收益递减问题。

Method: 提出协作式教练-玩家范式，教练根据玩家能力设计指令并基于玩家表现变化获得奖励，玩家则通过解决教练生成的逐步提升难度的任务获得奖励，形成合作优化循环。

Result: 在Qwen2.5-Math-7B-Instruct模型上，整体准确率平均提升4.9%，分布外准确率平均提升5.4%，超越现有无监督方法RENT和R-zero。

Conclusion: CPMöbius证明了无需外部训练数据即可显著提升LLM推理能力的可行性，为减少对人工标注数据的依赖提供了新方向。

Abstract: Large Language Models (LLMs) have demonstrated strong potential in complex reasoning, yet their progress remains fundamentally constrained by reliance on massive high-quality human-curated tasks and labels, either through supervised fine-tuning (SFT) or reinforcement learning (RL) on reasoning-specific data. This dependence renders supervision-heavy training paradigms increasingly unsustainable, with signs of diminishing scalability already evident in practice. To overcome this limitation, we introduce CPMöbius (CPMobius), a collaborative Coach-Player paradigm for data-free reinforcement learning of reasoning models. Unlike traditional adversarial self-play, CPMöbius, inspired by real world human sports collaboration and multi-agent collaboration, treats the Coach and Player as independent but cooperative roles. The Coach proposes instructions targeted at the Player's capability and receives rewards based on changes in the Player's performance, while the Player is rewarded for solving the increasingly instructive tasks generated by the Coach. This cooperative optimization loop is designed to directly enhance the Player's mathematical reasoning ability. Remarkably, CPMöbius achieves substantial improvement without relying on any external training data, outperforming existing unsupervised approaches. For example, on Qwen2.5-Math-7B-Instruct, our method improves accuracy by an overall average of +4.9 and an out-of-distribution average of +5.4, exceeding RENT by +1.5 on overall accuracy and R-zero by +4.2 on OOD accuracy.

</details>


### [24] [LatentMem: Customizing Latent Memory for Multi-Agent Systems](https://arxiv.org/abs/2602.03036)
*Muxin Fu,Guibin Zhang,Xiangyuan Xue,Yafu Li,Zefeng He,Siyuan Huang,Xiaoye Qu,Yu Cheng,Yang Yang*

Main category: cs.CL

TL;DR: LatentMem是一个可学习的多智能体记忆框架，通过定制化智能体特定记忆和紧凑潜在表示来解决现有多智能体记忆中的同质化和信息过载问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的多智能体系统存在两个关键瓶颈：1) 由于缺乏角色感知定制导致记忆同质化；2) 过于细粒度的记忆条目导致信息过载。

Method: 提出LatentMem框架，包含经验库（存储原始交互轨迹）和记忆合成器（基于检索经验和智能体特定上下文合成紧凑潜在记忆）。引入潜在记忆策略优化（LMPO），通过潜在记忆传播任务级优化信号。

Result: 在多种基准测试和主流MAS框架中，LatentMem相比原始设置实现高达19.36%的性能提升，并一致优于现有记忆架构，且无需修改底层框架。

Conclusion: LatentMem通过可学习的记忆框架有效解决了多智能体记忆中的同质化和信息过载问题，显著提升了集体智能性能，具有广泛的适用性和实用性。

Abstract: Large language model (LLM)-powered multi-agent systems (MAS) demonstrate remarkable collective intelligence, wherein multi-agent memory serves as a pivotal mechanism for continual adaptation. However, existing multi-agent memory designs remain constrained by two fundamental bottlenecks: (i) memory homogenization arising from the absence of role-aware customization, and (ii) information overload induced by excessively fine-grained memory entries. To address these limitations, we propose LatentMem, a learnable multi-agent memory framework designed to customize agent-specific memories in a token-efficient manner. Specifically, LatentMem comprises an experience bank that stores raw interaction trajectories in a lightweight form, and a memory composer that synthesizes compact latent memories conditioned on retrieved experience and agent-specific contexts. Further, we introduce Latent Memory Policy Optimization (LMPO), which propagates task-level optimization signals through latent memories to the composer, encouraging it to produce compact and high-utility representations. Extensive experiments across diverse benchmarks and mainstream MAS frameworks show that LatentMem achieves a performance gain of up to $19.36$% over vanilla settings and consistently outperforms existing memory architectures, without requiring any modifications to the underlying frameworks.

</details>


### [25] [SAES-SVD: Self-Adaptive Suppression of Accumulated and Local Errors for SVD-based LLM Compression](https://arxiv.org/abs/2602.03051)
*Xing Hu,Dawei Yang,Yuan Cheng,Zhixuan Chen,Zukang Xu*

Main category: cs.CL

TL;DR: SAES-SVD是一种针对大语言模型的自适应误差抑制低秩压缩框架，通过联合优化层内重构和层间误差补偿，解决传统方法中误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 现有低秩压缩方法通常独立压缩每一层，只最小化层内重构误差，忽略了误差在网络中传播和累积的问题，导致与全精度基线的全局偏差被放大。

Method: 提出SAES-SVD框架，包含两个核心组件：1) 累积误差感知层压缩(CEALC)，将压缩目标公式化为局部重构和加权累积误差补偿的组合，基于二阶激活统计推导闭式低秩解；2) 自适应协作误差抑制(ACES)，自动调整权重系数以增强压缩目标的低秩结构。

Result: 在多种LLM架构和任务上的广泛实验表明，SAES-SVD无需微调或混合秩策略，能持续提升压缩后性能。

Conclusion: SAES-SVD通过联合优化层内重构和层间误差补偿，有效抑制了误差累积问题，为大语言模型的高效压缩提供了新方法。

Abstract: The rapid growth in the parameter scale of large language models (LLMs) has created a high demand for efficient compression techniques. As a hardware-agnostic and highly compatible technique, low-rank compression has been widely adopted. However, existing methods typically compress each layer independently by minimizing per-layer reconstruction error, overlooking a critical limitation: the reconstruction error propagates and accumulates through the network, which leads to amplified global deviations from the full-precision baseline. To address this, we propose Self-Adaptive Error Suppression SVD (SAES-SVD), a LLMs compression framework that jointly optimizes intra-layer reconstruction and inter-layer error compensation. SAES-SVD is composed of two novel components: (1) Cumulative Error-Aware Layer Compression (CEALC), which formulates the compression objective as a combination of local reconstruction and weighted cumulative error compensation. Based on it, we derive a closed-form low-rank solution relied on second-order activation statistics, which explicitly aligns each layer's output with its full-precision counterpart to compensate for accumulated errors. (2) Adaptive Collaborative Error Suppression (ACES), which automatically adjusts the weighting coefficient to enhance the low-rank structure of the compression objective in CEALC. Specifically, the coefficient is optimized to maximize the ratio between the Frobenius norm of the compressed layer's output and that of the compression objective under a fixed rank, thus ensuring that the rank budget is utilized effectively. Extensive experiments across multiple LLM architectures and tasks show that, without fine-tuning or mixed-rank strategies, SAES-SVD consistently improves post-compression performance.

</details>


### [26] [ReMiT: RL-Guided Mid-Training for Iterative LLM Evolution](https://arxiv.org/abs/2602.03075)
*Junjie Huang,Jiarui Qin,Di Yin,Weiwen Liu,Yong Yu,Xing Sun,Weinan Zhang*

Main category: cs.CL

TL;DR: ReMiT提出了一种双向训练框架，通过RL调优模型的推理先验动态重加权预训练中期的token，实现基模型与后训练性能的相互增强循环。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练流程是单向的（从预训练到后训练），作者希望探索双向过程的潜力，让后训练的洞见能反馈改进预训练基础模型，建立自我增强的飞轮效应。

Method: 识别预训练末期的中期训练（退火）阶段是关键转折点，引入ReMiT方法，利用RL调优模型的推理先验动态重加权该阶段的token，优先处理对推理关键的token。

Result: 在10个预训练基准测试（数学、代码、通用推理）上平均提升3%，并在整个后训练流程中持续保持超过2%的增益，验证了迭代反馈循环的有效性。

Conclusion: ReMiT成功建立了自我增强的飞轮，实现了LLM的持续自我进化，无需专门训练的教师或参考模型，为LLM训练范式提供了新的方向。

Abstract: Standard training pipelines for large language models (LLMs) are typically unidirectional, progressing from pre-training to post-training. However, the potential for a bidirectional process--where insights from post-training retroactively improve the pre-trained foundation--remains unexplored. We aim to establish a self-reinforcing flywheel: a cycle in which reinforcement learning (RL)-tuned model strengthens the base model, which in turn enhances subsequent post-training performance, requiring no specially trained teacher or reference model. To realize this, we analyze training dynamics and identify the mid-training (annealing) phase as a critical turning point for model capabilities. This phase typically occurs at the end of pre-training, utilizing high-quality corpora under a rapidly decaying learning rate. Building upon this insight, we introduce ReMiT (Reinforcement Learning-Guided Mid-Training). Specifically, ReMiT leverages the reasoning priors of RL-tuned models to dynamically reweight tokens during the mid-training phase, prioritizing those pivotal for reasoning. Empirically, ReMiT achieves an average improvement of 3\% on 10 pre-training benchmarks, spanning math, code, and general reasoning, and sustains these gains by over 2\% throughout the post-training pipeline. These results validate an iterative feedback loop, enabling continuous and self-reinforcing evolution of LLMs.

</details>


### [27] [AERO: Autonomous Evolutionary Reasoning Optimization via Endogenous Dual-Loop Feedback](https://arxiv.org/abs/2602.03084)
*Zhitao Gao,Jie Ma,Xuhong Li,Pengyu Li,Ning Qu,Yaqiang Wu,Hui Liu,Jun Liu*

Main category: cs.CL

TL;DR: AERO是一个无监督的自主推理进化框架，通过双循环系统实现自我提问、回答和批评，基于最近发展区理论定位"可解性差距"，在多个基准测试中显著提升LLM推理性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理方面取得显著成功，但依赖专家标注数据和外部验证器成为瓶颈。现有的自我进化范式常常无法找到最佳学习区域，且可能通过有缺陷的内部反馈强化集体幻觉和错误先验。

Method: 提出AERO无监督框架，通过协同双循环系统实现自主推理进化：1) 基于最近发展区理论，使用基于熵的定位来瞄准"可解性差距"；2) 采用独立反事实修正进行鲁棒验证；3) 引入交错训练策略同步功能角色能力增长，防止课程崩溃。

Result: 在跨越三个领域的九个基准测试中，AERO在Qwen3-4B-Base上平均性能提升4.57%，在Qwen3-8B-Base上平均提升5.10%，优于竞争基线方法。

Conclusion: AERO框架通过无监督的自主推理进化，成功解决了LLM推理中的专家数据依赖和内部反馈问题，在多个基准测试中展现出显著性能提升，为LLM的自我进化提供了有效解决方案。

Abstract: Large Language Models (LLMs) have achieved significant success in complex reasoning but remain bottlenecked by reliance on expert-annotated data and external verifiers. While existing self-evolution paradigms aim to bypass these constraints, they often fail to identify the optimal learning zone and risk reinforcing collective hallucinations and incorrect priors through flawed internal feedback. To address these challenges, we propose \underline{A}utonomous \underline{E}volutionary \underline{R}easoning \underline{O}ptimization (AERO), an unsupervised framework that achieves autonomous reasoning evolution by internalizing self-questioning, answering, and criticism within a synergistic dual-loop system. Inspired by the \textit{Zone of Proximal Development (ZPD)} theory, AERO utilizes entropy-based positioning to target the ``solvability gap'' and employs Independent Counterfactual Correction for robust verification. Furthermore, we introduce a Staggered Training Strategy to synchronize capability growth across functional roles and prevent curriculum collapse. Extensive evaluations across nine benchmarks spanning three domains demonstrate that AERO achieves average performance improvements of 4.57\% on Qwen3-4B-Base and 5.10\% on Qwen3-8B-Base, outperforming competitive baselines. Code is available at https://github.com/mira-ai-lab/AERO.

</details>


### [28] [Test-time Recursive Thinking: Self-Improvement without External Feedback](https://arxiv.org/abs/2602.03094)
*Yufan Zhuang,Chandan Singh,Liyuan Liu,Yelong Shen,Dinghuai Zhang,Jingbo Shang,Jianfeng Gao,Weizhu Chen*

Main category: cs.CL

TL;DR: TRT框架让LLM在测试时通过递归思考实现自我改进，无需额外训练就能显著提升推理能力


<details>
  <summary>Details</summary>
Motivation: 探索LLM是否能在没有额外训练的情况下自我改进，解决缺乏可验证奖励时的两个核心挑战：高效生成高质量候选方案，以及在无监督情况下可靠选择正确答案

Method: 提出测试时递归思考（TRT）框架，通过迭代自我改进，在生成过程中结合特定策略、积累知识和自生成的验证信号

Result: 开源模型在AIME-25/24上达到100%准确率，闭源模型在LiveCodeBench最难题上提升10.4-14.8个百分点，无需外部反馈

Conclusion: TRT框架能有效实现LLM的测试时自我改进，显著提升复杂推理任务的性能，为无监督推理系统提供了新方向

Abstract: Modern Large Language Models (LLMs) have shown rapid improvements in reasoning capabilities, driven largely by reinforcement learning (RL) with verifiable rewards. Here, we ask whether these LLMs can self-improve without the need for additional training. We identify two core challenges for such systems: (i) efficiently generating diverse, high-quality candidate solutions, and (ii) reliably selecting correct answers in the absence of ground-truth supervision. To address these challenges, we propose Test-time Recursive Thinking (TRT), an iterative self-improvement framework that conditions generation on rollout-specific strategies, accumulated knowledge, and self-generated verification signals. Using TRT, open-source models reach 100% accuracy on AIME-25/24, and on LiveCodeBench's most difficult problems, closed-source models improve by 10.4-14.8 percentage points without external feedback.

</details>


### [29] [Task--Specificity Score: Measuring How Much Instructions Really Matter for Supervision](https://arxiv.org/abs/2602.03103)
*Pritam Kadasi,Abhishek Upperwal,Mayank Singh*

Main category: cs.CL

TL;DR: 该论文提出了任务特异性评分（TSS）来衡量指令对输出预测的重要性，通过对比真实指令与相同输入下的替代指令来量化指令的独特贡献。


<details>
  <summary>Details</summary>
Motivation: 当前指令微调中存在指令-输入-输出对弱指定问题：对于同一输入，多个替代指令下输出都可能合理。这引发了一个核心问题：指令是否唯一决定了目标输出？需要量化指令对输出的决定性作用。

Method: 提出任务特异性评分（TSS），通过对比真实指令与相同输入下的合理替代指令来量化指令的重要性。进一步提出TSS++，使用硬替代指令和小质量项来缓解简单负样本效应。

Result: 在三个指令数据集（Alpaca、Dolly-15k、NI-20）和三个开源LLM（Gemma、Llama、Qwen）上验证，选择任务特异性示例能在有限token预算下提升下游性能，并能与困惑度和IFD等基于质量的过滤器互补。

Conclusion: 任务特异性评分是量化指令重要性的有效方法，选择任务特异性强的示例能优化指令微调效果，特别是在资源受限场景下，与现有质量筛选方法形成良好互补。

Abstract: Instruction tuning is now the default way to train and adapt large language models, but many instruction--input--output pairs are only weakly specified: for a given input, the same output can remain plausible under several alternative instructions. This raises a simple question: \emph{does the instruction uniquely determine the target output?}
  We propose the \textbf{Task--Specificity Score (TSS)} to quantify how much an instruction matters for predicting its output, by contrasting the true instruction against plausible alternatives for the same input. We further introduce \textbf{TSS++}, which uses hard alternatives and a small quality term to mitigate easy-negative effects. Across three instruction datasets (\textsc{Alpaca}, \textsc{Dolly-15k}, \textsc{NI-20}) and three open LLMs (Gemma, Llama, Qwen), we show that selecting task-specific examples improves downstream performance under tight token budgets and complements quality-based filters such as perplexity and IFD.

</details>


### [30] [The Mask of Civility: Benchmarking Chinese Mock Politeness Comprehension in Large Language Models](https://arxiv.org/abs/2602.03107)
*Yitong Zhang,Yuhan Xiang,Mingxuan Liu*

Main category: cs.CL

TL;DR: 本研究系统评估了六种代表性大语言模型在识别中文礼貌、不礼貌和虚假礼貌现象方面的性能差异，填补了现有语用理解研究的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究在大语言模型的语用理解能力方面存在空白，特别是对中文礼貌现象的识别。本研究旨在评估不同LLM在这方面的表现，并探索技术在人文领域的应用。

Method: 采用关系管理理论和虚假礼貌模型构建三类中文语料数据集（真实与模拟话语），选择六种代表性模型（包括GPT-5.1和DeepSeek），在四种提示条件下进行评估：零样本、少样本、知识增强和混合策略。

Result: 论文没有直接给出具体评估结果，但表明这是"伟大语言学"范式下的一次有意义尝试，为语用理论在技术转型时代的应用提供了新方法。

Conclusion: 本研究不仅填补了语用理解的研究空白，还探索了技术与人文共存的可能性，代表了连接语言技术与人文反思的跨学科努力。

Abstract: From a pragmatic perspective, this study systematically evaluates the differences in performance among representative large language models (LLMs) in recognizing politeness, impoliteness, and mock politeness phenomena in Chinese. Addressing the existing gaps in pragmatic comprehension, the research adopts the frameworks of Rapport Management Theory and the Model of Mock Politeness to construct a three-category dataset combining authentic and simulated Chinese discourse. Six representative models, including GPT-5.1 and DeepSeek, were selected as test subjects and evaluated under four prompting conditions: zero-shot, few-shot, knowledge-enhanced, and hybrid strategies. This study serves as a meaningful attempt within the paradigm of ``Great Linguistics,'' offering a novel approach to applying pragmatic theory in the age of technological transformation. It also responds to the contemporary question of how technology and the humanities may coexist, representing an interdisciplinary endeavor that bridges linguistic technology and humanistic reflection.

</details>


### [31] [ChemPro: A Progressive Chemistry Benchmark for Large Language Models](https://arxiv.org/abs/2602.03108)
*Aaditya Baranwal,Shruti Vyas*

Main category: cs.CL

TL;DR: ChemPro是一个包含4100个化学问答对的渐进式基准测试，涵盖4个难度层级，用于评估大语言模型在各种化学主题上的能力。评估了45+7个先进LLM，发现模型在基础化学问题上表现良好，但随着复杂度的增加准确率下降。


<details>
  <summary>Details</summary>
Motivation: 需要评估大语言模型在化学领域的专业能力，特别是在不同复杂度和难度层次上的表现。现有的化学评估可能不够全面，需要更系统的基准来测试模型从基础到高级的化学理解和推理能力。

Method: 创建了ChemPro基准测试，包含4100个自然语言问答对，分为4个难度层级。问题类型包括选择题和数值题，涵盖信息回忆、长程推理、多概念问题、复杂问题解决等。评估了45个开源和7个专有的大语言模型。

Result: 大语言模型在基础化学问题上表现良好，但随着问题类型和复杂度的增加，准确率显著下降。这揭示了LLM在一般科学推理和理解方面的关键局限性。

Conclusion: 研究强调了LLM在化学推理方面的局限性，指出了被忽视的难度维度，强调需要更鲁棒的方法来改进LLM的科学理解和推理能力。

Abstract: We introduce ChemPro, a progressive benchmark with 4100 natural language question-answer pairs in Chemistry, across 4 coherent sections of difficulty designed to assess the proficiency of Large Language Models (LLMs) in a broad spectrum of general chemistry topics. We include Multiple Choice Questions and Numerical Questions spread across fine-grained information recall, long-horizon reasoning, multi-concept questions, problem-solving with nuanced articulation, and straightforward questions in a balanced ratio, effectively covering Bio-Chemistry, Inorganic-Chemistry, Organic-Chemistry and Physical-Chemistry. ChemPro is carefully designed analogous to a student's academic evaluation for basic to high-school chemistry. A gradual increase in the question difficulty rigorously tests the ability of LLMs to progress from solving basic problems to solving more sophisticated challenges.
  We evaluate 45+7 state-of-the-art LLMs, spanning both open-source and proprietary variants, and our analysis reveals that while LLMs perform well on basic chemistry questions, their accuracy declines with different types and levels of complexity. These findings highlight the critical limitations of LLMs in general scientific reasoning and understanding and point towards understudied dimensions of difficulty, emphasizing the need for more robust methodologies to improve LLMs.

</details>


### [32] [One Model, All Roles: Multi-Turn, Multi-Agent Self-Play Reinforcement Learning for Conversational Social Intelligence](https://arxiv.org/abs/2602.03109)
*Bowen Jiang,Taiwei Shi,Ryo Kamoi,Yuan Yuan,Camillo J. Taylor,Longqi Yang,Pei Zhou,Sihao Chen*

Main category: cs.CL

TL;DR: OMAR框架通过多轮多智能体对话自博弈，让单个模型同时扮演所有对话角色，从动态社交互动中学习长期目标和复杂社会规范，实现无监督社交智能涌现。


<details>
  <summary>Details</summary>
Motivation: 传统AI社交智能研究依赖静态、单轮优化，难以学习长期目标和复杂社会规范。需要一种能直接从动态社交互动中学习、能同时扮演多个角色的框架来发展真正的社交智能。

Method: 提出OMAR强化学习框架：1）单个模型同时扮演对话中所有参与者；2）采用分层优势估计，计算轮次级别和令牌级别优势以确保长对话训练稳定性；3）在多轮多智能体对话自博弈中学习。

Result: 在SOTOPIA社交环境和狼人杀策略游戏中，训练出的模型展现出细粒度、涌现的社交智能，包括共情、说服、寻求妥协等能力。即使在竞争性场景下也能学习协作，无需人类监督。

Conclusion: OMAR框架证明无监督社交智能可以通过多智能体对话自博弈涌现，但仍面临奖励攻击等实际挑战。希望这项工作能激励群体对话中AI社交智能的进一步研究。

Abstract: This paper introduces OMAR: One Model, All Roles, a reinforcement learning framework that enables AI to develop social intelligence through multi-turn, multi-agent conversational self-play. Unlike traditional paradigms that rely on static, single-turn optimizations, OMAR allows a single model to role-play all participants in a conversation simultaneously, learning to achieve long-term goals and complex social norms directly from dynamic social interaction. To ensure training stability across long dialogues, we implement a hierarchical advantage estimation that calculates turn-level and token-level advantages. Evaluations in the SOTOPIA social environment and Werewolf strategy games show that our trained models develop fine-grained, emergent social intelligence, such as empathy, persuasion, and compromise seeking, demonstrating the effectiveness of learning collaboration even under competitive scenarios. While we identify practical challenges like reward hacking, our results show that rich social intelligence can emerge without human supervision. We hope this work incentivizes further research on AI social intelligence in group conversations.

</details>


### [33] [Short Chains, Deep Thoughts: Balancing Reasoning Efficiency and Intra-Segment Capability via Split-Merge Optimization](https://arxiv.org/abs/2602.03141)
*Runquan Gui,Jie Wang,Zhihai Wang,Chi Ma,Jianye Hao,Feng Wu*

Main category: cs.CL

TL;DR: CoSMo是一个通过一致性指导的拆分-合并优化框架，用于减少大型推理模型中的结构冗余，提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型依赖冗长的推理链生成，导致显著的延迟和计算开销，需要解决推理效率问题。

Method: 采用一致性指导的拆分-合并算法动态优化推理链结构，通过结构对齐的强化学习和分段级预算监督模型保持高效推理结构。

Result: 在多个基准测试和骨干模型上，CoSMo相比推理效率基线平均准确率提升3.3个点，同时分段使用减少28.7%。

Conclusion: CoSMo通过消除结构冗余而非简单限制token数量，有效提高了大型推理模型的效率和性能。

Abstract: While Large Reasoning Models (LRMs) have demonstrated impressive capabilities in solving complex tasks through the generation of long reasoning chains, this reliance on verbose generation results in significant latency and computational overhead. To address these challenges, we propose \textbf{CoSMo} (\textbf{Co}nsistency-Guided \textbf{S}plit-\textbf{M}erge \textbf{O}ptimization), a framework designed to eliminate structural redundancy rather than indiscriminately restricting token volume. Specifically, CoSMo utilizes a split-merge algorithm that dynamically refines reasoning chains by merging redundant segments and splitting logical gaps to ensure coherence. We then employ structure-aligned reinforcement learning with a novel segment-level budget to supervise the model in maintaining efficient reasoning structures throughout training. Extensive experiments across multiple benchmarks and backbones demonstrate that CoSMo achieves superior performance, improving accuracy by \textbf{3.3} points while reducing segment usage by \textbf{28.7\%} on average compared to reasoning efficiency baselines.

</details>


### [34] [FASA: Frequency-aware Sparse Attention](https://arxiv.org/abs/2602.03152)
*Yifei Wang,Yueqi Wang,Zhenrui Yue,Huimin Zeng,Yong Wang,Ismini Lourentzou,Zhengzhong Tu,Xiangxiang Chu,Julian McAuley*

Main category: cs.CL

TL;DR: FASA 是一个基于 RoPE 中功能稀疏性发现的查询感知令牌驱逐框架，通过识别关键频率块来预测令牌重要性，显著减少 KV 缓存的内存占用和计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型处理长输入时面临 KV 缓存内存占用过高的瓶颈问题，现有令牌剪枝方法存在静态方法导致不可逆信息损失、动态方法启发式策略无法充分捕捉查询依赖性的不足。

Method: 基于 RoPE 中频率块级别功能稀疏性的新发现，识别出少数"主导"频率块与完整注意力头具有高度上下文一致性，以此作为令牌重要性的高效代理。FASA 首先使用主导频率块识别关键令牌子集，然后仅在该剪枝子集上进行注意力计算。

Result: 在各种长上下文任务中，FASA 始终优于所有令牌驱逐基线，在约束预算下仍保持接近原始性能的准确率。在 LongBench-V1 上，仅保留 256 个令牌即可达到接近 100% 的完整 KV 性能，在 AIME24 上使用仅 18.9% 的缓存实现 2.56 倍加速。

Conclusion: FASA 通过利用 RoPE 中的功能稀疏性，提供了一种高效、查询感知的令牌剪枝方法，显著降低了大语言模型处理长输入时的内存带宽需求和计算成本，同时保持了模型性能。

Abstract: The deployment of Large Language Models (LLMs) faces a critical bottleneck when handling lengthy inputs: the prohibitive memory footprint of the Key Value (KV) cache. To address this bottleneck, the token pruning paradigm leverages attention sparsity to selectively retain a small, critical subset of tokens. However, existing approaches fall short, with static methods risking irreversible information loss and dynamic strategies employing heuristics that insufficiently capture the query-dependent nature of token importance. We propose FASA, a novel framework that achieves query-aware token eviction by dynamically predicting token importance. FASA stems from a novel insight into RoPE: the discovery of functional sparsity at the frequency-chunk (FC) level. Our key finding is that a small, identifiable subset of "dominant" FCs consistently exhibits high contextual agreement with the full attention head. This provides a robust and computationally free proxy for identifying salient tokens. %making them a powerful and efficient proxy for token importance. Building on this insight, FASA first identifies a critical set of tokens using dominant FCs, and then performs focused attention computation solely on this pruned subset. % Since accessing only a small fraction of the KV cache, FASA drastically lowers memory bandwidth requirements and computational cost. Across a spectrum of long-context tasks, from sequence modeling to complex CoT reasoning, FASA consistently outperforms all token-eviction baselines and achieves near-oracle accuracy, demonstrating remarkable robustness even under constraint budgets. Notably, on LongBench-V1, FASA reaches nearly 100\% of full-KV performance when only keeping 256 tokens, and achieves 2.56$\times$ speedup using just 18.9\% of the cache on AIME24.

</details>


### [35] [Privasis: Synthesizing the Largest "Public" Private Dataset from Scratch](https://arxiv.org/abs/2602.03183)
*Hyunwoo Kim,Niloofar Mireshghallah,Michael Duan,Rui Xin,Shuyue Stella Li,Jaehun Jung,David Acuna,Qi Pang,Hanshen Xiao,G. Edward Suh,Sewoong Oh,Yulia Tsvetkov,Pang Wei Koh,Yejin Choi*

Main category: cs.CL

TL;DR: Privasis是首个百万规模完全合成的隐私敏感数据集，包含140万条记录和5510万标注属性，用于隐私研究和文本脱敏，其小型模型性能超越GPT-5等大型模型。


<details>
  <summary>Details</summary>
Motivation: 隐私敏感数据研究长期面临数据稀缺问题，与现代AI代理（如OpenClaw、Gemini Agent）持续访问高度敏感个人信息带来的风险形成矛盾，需要解决这一瓶颈。

Method: 创建Privasis数据集（140万条记录），涵盖医疗历史、法律文件、财务记录、日历、短信等多种文档类型；构建文本脱敏并行语料库，通过分解文本和应用针对性脱敏的流程；训练紧凑型脱敏模型（≤40亿参数）。

Result: Privasis在规模、质量和多样性上远超现有数据集；基于该数据集训练的紧凑型脱敏模型（≤40亿参数）在性能上超越了GPT-5和Qwen-3 235B等最先进的大型语言模型。

Conclusion: Privasis为解决隐私敏感数据稀缺问题提供了重要资源，将加速隐私敏感领域和AI代理的研究，计划发布数据、模型和代码以推动未来研究。

Abstract: Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenClaw and Gemini Agent--are granted persistent access to highly sensitive personal information. To tackle this longstanding bottleneck and the rising risks, we present Privasis (i.e., privacy oasis), the first million-scale fully synthetic dataset entirely built from scratch--an expansive reservoir of texts with rich and diverse private information--designed to broaden and accelerate research in areas where processing sensitive social data is inevitable. Compared to existing datasets, Privasis, comprising 1.4 million records, offers orders-of-magnitude larger scale with quality, and far greater diversity across various document types, including medical history, legal documents, financial records, calendars, and text messages with a total of 55.1 million annotated attributes such as ethnicity, date of birth, workplace, etc. We leverage Privasis to construct a parallel corpus for text sanitization with our pipeline that decomposes texts and applies targeted sanitization. Our compact sanitization models (<=4B) trained on this dataset outperform state-of-the-art large language models, such as GPT-5 and Qwen-3 235B. We plan to release data, models, and code to accelerate future research on privacy-sensitive domains and agents.

</details>


### [36] [ForesightKV: Optimizing KV Cache Eviction for Reasoning Models by Learning Long-Term Contribution](https://arxiv.org/abs/2602.03203)
*Zican Dong,Peiyu Liu,Junyi Li,Zhipeng Chen,Han Peng,Shuo Wang,Wayne Xin Zhao*

Main category: cs.CL

TL;DR: ForesightKV：一种基于训练的KV缓存驱逐框架，通过学习预测长文本生成中应驱逐哪些KV对来平衡效率与性能


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成长推理序列，KV缓存线性增长导致显著的内存和计算成本。现有的KV缓存驱逐方法通过丢弃不重要KV对来缓解此问题，但往往无法捕捉复杂的KV依赖关系，导致性能下降。

Method: 提出了ForesightKV训练框架：1) 设计Golden Eviction算法，使用未来注意力分数识别每一步最优的驱逐KV对；2) 通过监督训练和Pairwise Ranking Loss蒸馏这些轨迹和分数；3) 将缓存驱逐建模为马尔可夫决策过程，应用GRPO算法缓解低熵令牌上语言建模损失显著增加的问题。

Result: 在AIME2024和AIME2025基准测试中对三个推理模型的实验表明，ForesightKV在仅使用一半缓存预算的情况下持续优于先前方法，同时从监督学习和强化学习方法中获得协同效益。

Conclusion: ForesightKV通过结合监督训练和强化学习，有效解决了长文本生成中KV缓存效率与性能的平衡问题，显著提升了推理模型在有限缓存下的表现。

Abstract: Recently, large language models (LLMs) have shown remarkable reasoning abilities by producing long reasoning traces. However, as the sequence length grows, the key-value (KV) cache expands linearly, incurring significant memory and computation costs. Existing KV cache eviction methods mitigate this issue by discarding less important KV pairs, but often fail to capture complex KV dependencies, resulting in performance degradation. To better balance efficiency and performance, we introduce ForesightKV, a training-based KV cache eviction framework that learns to predict which KV pairs to evict during long-text generations. We first design the Golden Eviction algorithm, which identifies the optimal eviction KV pairs at each step using future attention scores. These traces and the scores at each step are then distilled via supervised training with a Pairwise Ranking Loss. Furthermore, we formulate cache eviction as a Markov Decision Process and apply the GRPO algorithm to mitigate the significant language modeling loss increase on low-entropy tokens. Experiments on AIME2024 and AIME2025 benchmarks of three reasoning models demonstrate that ForesightKV consistently outperforms prior methods under only half the cache budget, while benefiting synergistically from both supervised and reinforcement learning approaches.

</details>


### [37] [Token Sparse Attention: Efficient Long-Context Inference with Interleaved Token Selection](https://arxiv.org/abs/2602.03216)
*Dongwon Jo,Beomseok Kang,Jiwon Song,Jae-Joon Kim*

Main category: cs.CL

TL;DR: 提出Token Sparse Attention，一种轻量级动态token级稀疏化机制，通过压缩和解压缩Q、K、V来加速长上下文推理，与Flash Attention兼容，在128K上下文下实现3.23倍注意力加速且准确率下降小于1%。


<details>
  <summary>Details</summary>
Motivation: 注意力机制的二次复杂度是大型语言模型长上下文推理的主要瓶颈。现有加速方法要么采用结构化模式稀疏化注意力图，要么在特定层永久移除token，但这些方法可能保留无关token或依赖不可逆的早期决策，忽略了token重要性在不同层和注意力头中的动态变化。

Method: 提出Token Sparse Attention机制，在注意力计算过程中将每个头的Q、K、V压缩到缩减的token集合中，计算后再将输出解压缩回原始序列。这种方法支持token信息在后续层中被重新考虑，并与现有密集注意力实现（如Flash Attention）完全兼容，可无缝集成现有稀疏注意力内核。

Result: 实验结果表明，Token Sparse Attention在准确率-延迟权衡方面持续改进，在128K上下文长度下实现高达3.23倍的注意力加速，同时准确率下降小于1%。这些结果证明了动态和交错token级稀疏化是扩展长上下文推理的有效补充策略。

Conclusion: 动态和交错的token级稀疏化是扩展长上下文推理的有效补充策略。Token Sparse Attention通过轻量级动态token级稀疏化机制，在保持高准确率的同时显著提升注意力计算效率，为长上下文推理提供了新的设计思路。

Abstract: The quadratic complexity of attention remains the central bottleneck in long-context inference for large language models. Prior acceleration methods either sparsify the attention map with structured patterns or permanently evict tokens at specific layers, which can retain irrelevant tokens or rely on irreversible early decisions despite the layer-/head-wise dynamics of token importance. In this paper, we propose Token Sparse Attention, a lightweight and dynamic token-level sparsification mechanism that compresses per-head $Q$, $K$, $V$ to a reduced token set during attention and then decompresses the output back to the original sequence, enabling token information to be reconsidered in subsequent layers. Furthermore, Token Sparse Attention exposes a new design point at the intersection of token selection and sparse attention. Our approach is fully compatible with dense attention implementations, including Flash Attention, and can be seamlessly composed with existing sparse attention kernels. Experimental results show that Token Sparse Attention consistently improves accuracy-latency trade-off, achieving up to $\times$3.23 attention speedup at 128K context with less than 1% accuracy degradation. These results demonstrate that dynamic and interleaved token-level sparsification is a complementary and effective strategy for scalable long-context inference.

</details>


### [38] [ATACompressor: Adaptive Task-Aware Compression for Efficient Long-Context Processing in LLMs](https://arxiv.org/abs/2602.03226)
*Xuancheng Li,Haitao Li,Yujia Zhou,Qingyao Ai,Yiqun Liu*

Main category: cs.CL

TL;DR: 提出ATACompressor自适应任务感知压缩器，解决大语言模型长上下文中的"迷失在中间"问题，通过选择性压缩任务相关部分来平衡信息保留和压缩效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型处理长上下文时存在"迷失在中间"问题，关键信息容易被稀释或忽略。现有上下文压缩方法难以平衡信息保留和压缩效率，需要一种更智能的压缩方法。

Method: 提出ATACompressor，包含两个核心组件：1) 选择性编码器，只压缩任务相关的长上下文部分；2) 自适应分配控制器，感知相关内容长度并动态调整压缩率。

Result: 在HotpotQA、MSMARCO和SQUAD三个QA数据集上评估，ATACompressor在压缩效率和任务性能上都优于现有方法。通过消融实验深入分析了关键组件的作用。

Conclusion: ATACompressor为LLMs长上下文处理提供了可扩展的解决方案，通过任务感知的自适应压缩有效解决了"迷失在中间"问题，平衡了信息保留和压缩效率。

Abstract: Long-context inputs in large language models (LLMs) often suffer from the "lost in the middle" problem, where critical information becomes diluted or ignored due to excessive length. Context compression methods aim to address this by reducing input size, but existing approaches struggle with balancing information preservation and compression efficiency. We propose Adaptive Task-Aware Compressor (ATACompressor), which dynamically adjusts compression based on the specific requirements of the task. ATACompressor employs a selective encoder that compresses only the task-relevant portions of long contexts, ensuring that essential information is preserved while reducing unnecessary content. Its adaptive allocation controller perceives the length of relevant content and adjusts the compression rate accordingly, optimizing resource utilization. We evaluate ATACompressor on three QA datasets: HotpotQA, MSMARCO, and SQUAD-showing that it outperforms existing methods in terms of both compression efficiency and task performance. Our approach provides a scalable solution for long-context processing in LLMs. Furthermore, we perform a range of ablation studies and analysis experiments to gain deeper insights into the key components of ATACompressor.

</details>


### [39] [POP: Prefill-Only Pruning for Efficient Large Model Inference](https://arxiv.org/abs/2602.03295)
*Junhui He,Zhihui Fu,Jun Wang,Qingan Li*

Main category: cs.CL

TL;DR: POP提出了一种阶段感知推理策略，通过仅在预填充阶段剪枝深层，保留完整模型用于解码阶段，以解决LLM/VLM部署中的计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法虽然硬件效率高，但往往导致显著的准确率下降。作者认为这种失败源于阶段不可知的剪枝方法忽略了预填充和解码阶段之间的不对称角色。

Method: 引入虚拟门机制分析发现深层对下一个标记预测（解码）至关重要，但对上下文编码（预填充）基本冗余。提出预填充专用剪枝（POP），在计算密集的预填充阶段安全省略深层，在敏感的解码阶段保留完整模型。使用独立的KV投影维护缓存完整性，并引入边界处理策略确保第一个生成标记的准确性。

Result: 在Llama-3.1、Qwen3-VL和Gemma-3等多种模态上的实验表明，POP在预填充延迟上实现了高达1.37倍的加速，且性能损失最小，有效克服了现有结构化剪枝方法的准确率-效率权衡限制。

Conclusion: POP通过阶段感知的推理策略成功解决了LLM/VLM部署中的计算效率问题，同时保持了模型性能，为实际部署提供了有效的解决方案。

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated remarkable capabilities. However, their deployment is hindered by significant computational costs. Existing structured pruning methods, while hardware-efficient, often suffer from significant accuracy degradation. In this paper, we argue that this failure stems from a stage-agnostic pruning approach that overlooks the asymmetric roles between the prefill and decode stages. By introducing a virtual gate mechanism, our importance analysis reveals that deep layers are critical for next-token prediction (decode) but largely redundant for context encoding (prefill). Leveraging this insight, we propose Prefill-Only Pruning (POP), a stage-aware inference strategy that safely omits deep layers during the computationally intensive prefill stage while retaining the full model for the sensitive decode stage. To enable the transition between stages, we introduce independent Key-Value (KV) projections to maintain cache integrity, and a boundary handling strategy to ensure the accuracy of the first generated token. Extensive experiments on Llama-3.1, Qwen3-VL, and Gemma-3 across diverse modalities demonstrate that POP achieves up to 1.37$\times$ speedup in prefill latency with minimal performance loss, effectively overcoming the accuracy-efficiency trade-off limitations of existing structured pruning methods.

</details>


### [40] [MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research](https://arxiv.org/abs/2602.03318)
*Yifan Shi,Jialong Shi,Jiayi Wang,Ye Fan,Jianyong Sun*

Main category: cs.CL

TL;DR: MIRROR是一个无需微调的多智能体框架，可将自然语言优化问题直接转换为数学模型和求解器代码，通过执行驱动的迭代自适应修订和分层检索机制实现可靠建模。


<details>
  <summary>Details</summary>
Motivation: 传统运筹学建模依赖专家，过程缓慢脆弱且难以应对新场景。现有LLM方法要么需要昂贵的后训练，要么缺乏可靠的协作纠错和任务特定检索，常导致错误输出。

Method: 提出MIRROR框架，包含两个核心机制：(1)执行驱动的迭代自适应修订，用于自动错误纠正；(2)分层检索，从精心策划的示例库中获取相关建模和编码示例。

Result: MIRROR在标准OR基准测试中优于现有方法，在IndustryOR和Mamo-ComplexLP等复杂工业数据集上表现显著。

Conclusion: 通过结合精确的外部知识注入和系统化错误纠正，MIRROR为非专家用户提供了高效可靠的OR建模解决方案，克服了通用LLM在专家优化任务中的根本限制。

Abstract: Operations Research (OR) relies on expert-driven modeling-a slow and fragile process ill-suited to novel scenarios. While large language models (LLMs) can automatically translate natural language into optimization models, existing approaches either rely on costly post-training or employ multi-agent frameworks, yet most still lack reliable collaborative error correction and task-specific retrieval, often leading to incorrect outputs. We propose MIRROR, a fine-tuning-free, end-to-end multi-agent framework that directly translates natural language optimization problems into mathematical models and solver code. MIRROR integrates two core mechanisms: (1) execution-driven iterative adaptive revision for automatic error correction, and (2) hierarchical retrieval to fetch relevant modeling and coding exemplars from a carefully curated exemplar library. Experiments show that MIRROR outperforms existing methods on standard OR benchmarks, with notable results on complex industrial datasets such as IndustryOR and Mamo-ComplexLP. By combining precise external knowledge infusion with systematic error correction, MIRROR provides non-expert users with an efficient and reliable OR modeling solution, overcoming the fundamental limitations of general-purpose LLMs in expert optimization tasks.

</details>


### [41] [Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention](https://arxiv.org/abs/2602.03338)
*Rakshith Vasudev,Melisa Russak,Dan Bikel,Waseem Alshikh*

Main category: cs.CL

TL;DR: LLM批评模型的主动干预不一定总是提升性能，可能反而导致严重性能下降，研究发现仅凭批评模型的离线准确率无法判断干预是否安全。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM批评模型的主动干预通常被认为能提高可靠性，但其在部署时的实际效果尚不清楚，需要深入研究干预可能带来的负面影响。

Method: 通过分析二元LLM批评模型在不同任务上的表现，识别出"破坏-恢复权衡"机制，并提出了一个使用50个任务小规模试点来预判干预效果的部署前测试框架。

Result: 研究发现，具有高离线准确率(AUROC 0.94)的批评模型仍可能导致严重性能下降（一个模型下降26个百分点），而另一个模型几乎不受影响。在高成功率任务上干预会降低性能(0到-26pp)，但在高失败率的ALFWorld基准上则有适度改善(+2.8pp)。

Conclusion: LLM批评模型的准确性不足以确定干预是否安全，需要更全面的评估。提出的部署前测试框架能有效识别何时不应干预，避免部署后出现严重性能回归。

Abstract: Proactive interventions by LLM critic models are often assumed to improve reliability, yet their effects at deployment time are poorly understood. We show that a binary LLM critic with strong offline accuracy (AUROC 0.94) can nevertheless cause severe performance degradation, inducing a 26 percentage point (pp) collapse on one model while affecting another by near zero pp. This variability demonstrates that LLM critic accuracy alone is insufficient to determine whether intervention is safe.
  We identify a disruption-recovery tradeoff: interventions may recover failing trajectories but also disrupt trajectories that would have succeeded. Based on this insight, we propose a pre-deployment test that uses a small pilot of 50 tasks to estimate whether intervention is likely to help or harm, without requiring full deployment. Across benchmarks, the test correctly anticipates outcomes: intervention degrades performance on high-success tasks (0 to -26 pp), while yielding a modest improvement on the high-failure ALFWorld benchmark (+2.8 pp, p=0.014). The primary value of our framework is therefore identifying when not to intervene, preventing severe regressions before deployment.

</details>


### [42] [PEGRL: Improving Machine Translation by Post-Editing Guided Reinforcement Learning](https://arxiv.org/abs/2602.03352)
*Yunzhi Shen,Hao Zhou,Xin Huang,Xue Han,Junlan Feng,Shujian Huang*

Main category: cs.CL

TL;DR: PEGRL：一种两阶段强化学习框架，通过后编辑作为辅助任务来稳定机器翻译训练，平衡全局探索与局部优化。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的机器翻译强化学习方法面临两个主要挑战：1）蒙特卡洛回报估计产生的噪声学习信号；2）巨大的轨迹空间更偏向全局探索而非细粒度的局部优化。

Method: 提出PEGRL两阶段强化学习框架：1）采样翻译输出构建后编辑输入；2）在后编辑阶段进行回报估计，利用当前翻译行为作为条件；3）使用任务特定的加权方案平衡翻译和后编辑目标，获得有偏但更样本高效的估计器。

Result: 在英→芬兰语、英→土耳其语和英↔中文翻译任务上，相比RL基线方法取得了一致的性能提升。在英→土耳其语任务上，COMET-KIWI得分与先进的LLM-based系统（DeepSeek-V3.2）相当。

Conclusion: PEGRL通过引入后编辑作为辅助任务，有效解决了翻译强化学习中的噪声信号和探索-优化平衡问题，提供了一种更稳定、样本高效的训练框架。

Abstract: Reinforcement learning (RL) has shown strong promise for LLM-based machine translation, with recent methods such as GRPO demonstrating notable gains; nevertheless, translation-oriented RL remains challenged by noisy learning signals arising from Monte Carlo return estimation, as well as a large trajectory space that favors global exploration over fine-grained local optimization. We introduce \textbf{PEGRL}, a \textit{two-stage} RL framework that uses post-editing as an auxiliary task to stabilize training and guide overall optimization. At each iteration, translation outputs are sampled to construct post-editing inputs, allowing return estimation in the post-editing stage to benefit from conditioning on the current translation behavior, while jointly supporting both global exploration and fine-grained local optimization. A task-specific weighting scheme further balances the contributions of translation and post-editing objectives, yielding a biased yet more sample-efficient estimator. Experiments on English$\to$Finnish, English$\to$Turkish, and English$\leftrightarrow$Chinese show consistent gains over RL baselines, and for English$\to$Turkish, performance on COMET-KIWI is comparable to advanced LLM-based systems (DeepSeek-V3.2).

</details>


### [43] [Pursuing Best Industrial Practices for Retrieval-Augmented Generation in the Medical Domain](https://arxiv.org/abs/2602.03368)
*Wei Zhu*

Main category: cs.CL

TL;DR: 该论文分析了医疗领域检索增强生成(RAG)系统的最佳实践，通过系统评估提出了组件选择、组织架构和实现方案的建议，并揭示了性能与效率之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 当前在工业应用中，尤其是医疗领域，对于构建RAG系统的最佳实践缺乏共识，包括组件选择、组织架构和具体实现方法等方面。

Method: 首先仔细分析RAG系统的各个组件并提出实际替代方案，然后在三类任务上进行系统评估。

Result: 揭示了改进RAG系统的最佳实践，以及基于LLM的RAG系统如何在性能与效率之间做出权衡。

Conclusion: 该研究为医疗领域RAG系统的构建提供了实用指导，明确了组件选择、架构设计和性能优化等方面的最佳实践。

Abstract: While retrieval augmented generation (RAG) has been swiftly adopted in industrial applications based on large language models (LLMs), there is no consensus on what are the best practices for building a RAG system in terms of what are the components, how to organize these components and how to implement each component for the industrial applications, especially in the medical domain. In this work, we first carefully analyze each component of the RAG system and propose practical alternatives for each component. Then, we conduct systematic evaluations on three types of tasks, revealing the best practices for improving the RAG system and how LLM-based RAG systems make trade-offs between performance and efficiency.

</details>


### [44] [Towards Distillation-Resistant Large Language Models: An Information-Theoretic Perspective](https://arxiv.org/abs/2602.03396)
*Hao Fang,Tianyi Zhang,Tianqu Zhuang,Jiawei Kong,Kuofeng Gao,Bin Chen,Leqi Liang,Shu-Tao Xia,Ke Xu*

Main category: cs.CL

TL;DR: 本文提出了一种从信息论角度防御LLM蒸馏攻击的方法，通过最小化条件互信息来保护专有模型的知识产权。


<details>
  <summary>Details</summary>
Motivation: 专有大型语言模型具有重要经济价值，目前主要作为黑盒API暴露，但攻击者仍可通过蒸馏技术提取知识。现有防御方法只关注基于文本的蒸馏，而对基于logit的蒸馏防御研究不足。

Method: 从信息论角度分析问题，使用条件互信息(CMI)量化教师模型输出中与蒸馏相关的信息。提出学习一个转换矩阵来净化原始输出，增强抗蒸馏能力。设计了一个基于CMI的反蒸馏目标函数来优化这个转换，有效移除蒸馏相关信息同时保持输出效用。

Result: 在多个LLM和强蒸馏算法上的广泛实验表明，该方法能显著降低蒸馏性能，同时保持任务准确性，有效保护模型的知识产权。

Conclusion: 该研究填补了基于logit的蒸馏防御空白，从信息论角度提出了一种有效的解决方案，既能保护专有模型的知识产权，又能保持其实际应用价值。

Abstract: Proprietary large language models (LLMs) embody substantial economic value and are generally exposed only as black-box APIs, yet adversaries can still exploit their outputs to extract knowledge via distillation. Existing defenses focus exclusively on text-based distillation, leaving the important logit-based distillation largely unexplored. In this work, we analyze this problem and present an effective solution from an information-theoretic perspective. We characterize distillation-relevant information in teacher outputs using the conditional mutual information (CMI) between teacher logits and input queries conditioned on ground-truth labels. This quantity captures contextual information beneficial for model extraction, motivating us to defend distillation via CMI minimization. Guided by our theoretical analysis, we propose learning a transformation matrix that purifies the original outputs to enhance distillation resistance. We further derive a CMI-inspired anti-distillation objective to optimize this transformation, which effectively removes distillation-relevant information while preserving output utility. Extensive experiments across multiple LLMs and strong distillation algorithms demonstrate that the proposed method significantly degrades distillation performance while preserving task accuracy, effectively protecting models' intellectual property.

</details>


### [45] [Verified Critical Step Optimization for LLM Agents](https://arxiv.org/abs/2602.03412)
*Mukai Li,Qingcheng Zeng,Tianqing Fang,Zhenwen Liang,Linfeng Song,Qi Liu,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: CSO提出了一种基于关键步骤优化的后训练方法，通过验证关键决策点来提升语言模型智能体在复杂长时任务中的表现，相比现有方法更高效准确。


<details>
  <summary>Details</summary>
Motivation: 现有后训练方法面临三个主要挑战：仅基于结果的奖励无法精确归因到中间步骤；估计的步骤级奖励存在系统性噪声；蒙特卡洛采样方法计算成本过高。作者观察到只有少数高熵标记对强化学习有效，因此提出了专注于验证关键步骤的方法。

Method: CSO从失败策略轨迹而非专家演示开始，使用过程奖励模型识别候选关键步骤，利用专家模型提出高质量替代方案，然后让策略模型从这些替代方案继续执行直到任务完成。只有那些策略成功执行并纠正结果的替代方案才会被验证并用作DPO训练数据。

Result: 在GAIA-Text-103和XBench-DeepSearch数据集上，CSO相比SFT基线分别实现了37%和26%的相对改进，显著优于其他后训练方法，同时仅需监督16%的轨迹步骤。

Conclusion: CSO通过选择性验证学习为智能体后训练提供了细粒度、可验证的监督，避免了轨迹级粗糙性和步骤级噪声，证明了基于验证的学习在智能体后训练中的有效性。

Abstract: As large language model agents tackle increasingly complex long-horizon tasks, effective post-training becomes critical. Prior work faces fundamental challenges: outcome-only rewards fail to precisely attribute credit to intermediate steps, estimated step-level rewards introduce systematic noise, and Monte Carlo sampling approaches for step reward estimation incur prohibitive computational cost. Inspired by findings that only a small fraction of high-entropy tokens drive effective RL for reasoning, we propose Critical Step Optimization (CSO), which focuses preference learning on verified critical steps, decision points where alternate actions demonstrably flip task outcomes from failure to success. Crucially, our method starts from failed policy trajectories rather than expert demonstrations, directly targeting the policy model's weaknesses. We use a process reward model (PRM) to identify candidate critical steps, leverage expert models to propose high-quality alternatives, then continue execution from these alternatives using the policy model itself until task completion. Only alternatives that the policy successfully executes to correct outcomes are verified and used as DPO training data, ensuring both quality and policy reachability. This yields fine-grained, verifiable supervision at critical decisions while avoiding trajectory-level coarseness and step-level noise. Experiments on GAIA-Text-103 and XBench-DeepSearch show that CSO achieves 37% and 26% relative improvement over the SFT baseline and substantially outperforms other post-training methods, while requiring supervision at only 16% of trajectory steps. This demonstrates the effectiveness of selective verification-based learning for agent post-training.

</details>


### [46] [FactNet: A Billion-Scale Knowledge Graph for Multilingual Factual Grounding](https://arxiv.org/abs/2602.03417)
*Yingli Shen,Wen Lai,Jie Zhou,Xueren Zhang,Yudong Wang,Kangyang Luo,Shuo Wang,Ge Gao,Alexander Fraser,Maosong Sun*

Main category: cs.CL

TL;DR: FactNet是一个大规模开源资源，统一了17亿原子断言和30.1亿可审计证据指针，源自316个维基百科版本，提供高精度可追溯的知识基础。


<details>
  <summary>Details</summary>
Motivation: 现有资源在结构化知识（如知识库）和基于文本的上下文之间存在割裂：前者缺乏文本背景，后者则规模和语言覆盖有限。LLMs存在事实幻觉和缺乏可追溯来源的问题，需要更好的基础资源来支持可信赖的多语言系统。

Method: 采用严格确定性的构建流程，从316个维基百科版本中提取原子断言和证据指针，确保每个证据单元都能以字节级精度恢复。不同于合成方法，FactNet强调可验证性和可重复性。

Result: FactNet包含17亿原子断言和30.1亿可审计证据指针，通过广泛审计确认了92.1%的高基础精度，即使在长尾语言中也能保持。同时建立了FactNet-Bench评估套件，涵盖知识图谱补全、问答和事实核查任务。

Conclusion: FactNet为社区提供了一个基础性、可重复的资源，用于训练和评估可信赖、可验证的多语言系统，填补了现有资源在结构化知识和可追溯证据之间的空白。

Abstract: While LLMs exhibit remarkable fluency, their utility is often compromised by factual hallucinations and a lack of traceable provenance. Existing resources for grounding mitigate this but typically enforce a dichotomy: they offer either structured knowledge without textual context (e.g., knowledge bases) or grounded text with limited scale and linguistic coverage. To bridge this gap, we introduce FactNet, a massive, open-source resource designed to unify 1.7 billion atomic assertions with 3.01 billion auditable evidence pointers derived exclusively from 316 Wikipedia editions. Unlike recent synthetic approaches, FactNet employs a strictly deterministic construction pipeline, ensuring that every evidence unit is recoverable with byte-level precision. Extensive auditing confirms a high grounding precision of 92.1%, even in long-tail languages. Furthermore, we establish FactNet-Bench, a comprehensive evaluation suite for Knowledge Graph Completion, Question Answering, and Fact Checking. FactNet provides the community with a foundational, reproducible resource for training and evaluating trustworthy, verifiable multilingual systems.

</details>


### [47] [A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces](https://arxiv.org/abs/2602.03442)
*Mingxuan Du,Benfeng Xu,Chiwei Zhu,Shaohan Wang,Pengyu Wang,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: A-RAG：一种代理式RAG框架，通过将分层检索接口直接暴露给模型，让模型参与检索决策，自适应地进行多粒度信息搜索，在多个开放域QA基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统未能充分利用前沿语言模型的推理和长时程工具使用能力。它们要么依赖单次检索算法，要么预定义工作流程，都不允许模型参与检索决策，从而阻碍了随着模型改进而有效扩展。

Method: 提出A-RAG（代理式RAG）框架，将分层检索接口直接暴露给模型。提供三种检索工具：关键词搜索、语义搜索和块读取，使代理能够自适应地在多个粒度上搜索和检索信息。

Result: 在多个开放域QA基准测试中，A-RAG始终优于现有方法，同时保持相当或更低的检索令牌数。这表明A-RAG能有效利用模型能力并动态适应不同的RAG任务。进一步系统研究了A-RAG如何随模型规模和测试时计算量扩展。

Conclusion: A-RAG通过让模型参与检索决策，有效利用了前沿语言模型的推理能力，实现了比传统RAG方法更优的性能。该方法为未来RAG系统的设计提供了新思路，代码和评估套件已开源。

Abstract: Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in a single shot and concatenates them into the model's input, or (2) predefining a workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword search, semantic search, and chunk read, enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute. We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag.

</details>


### [48] [Preferences for Idiomatic Language are Acquired Slowly -- and Forgotten Quickly: A Case Study on Swedish](https://arxiv.org/abs/2602.03484)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 该研究探讨了语言模型在预训练和从英语适应到瑞典语过程中，对惯用瑞典语与语言可接受瑞典语的偏好发展。研究发现惯用能力发展较慢，大型模型持续提升，但指令调优会导致惯用偏好快速丧失。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解语言模型如何发展对惯用语言与语言可接受语言的偏好，特别是在预训练阶段和从英语适应到瑞典语的过程中。这对于理解语言模型的语言习得机制和评估其在低资源语言上的表现具有重要意义。

Method: 研究方法包括：1) 从头训练瑞典语模型和微调英语预训练模型；2) 使用最小对比对在不同检查点探测模型偏好；3) 将现有语言可接受性基准改编为最小对比对格式；4) 引入两个新的惯用性数据集：传统习语与合理变体对比，以及惯用瑞典语与翻译腔对比。

Result: 研究发现：1) 惯用能力比其他语言能力（包括语法和词汇正确性）发展得更慢；2) 虽然大多数任务随着训练时间延长收益递减，但惯用相关性能持续改善，特别是在最大模型（8B）中；3) 指令调优（使用从英语机器翻译的数据）会导致模型快速丧失对惯用语言的偏好。

Conclusion: 研究结论表明，语言模型的惯用能力发展较慢且需要更多训练，大型模型在惯用性方面有持续提升潜力，但当前的指令调优方法（特别是使用机器翻译数据）会损害模型对惯用语言的偏好，这对低资源语言的模型开发提出了重要警示。

Abstract: In this study, we investigate how language models develop preferences for \textit{idiomatic} as compared to \textit{linguistically acceptable} Swedish, both during pretraining and when adapting a model from English to Swedish. To do so, we train models on Swedish from scratch and by fine-tuning English-pretrained models, probing their preferences at various checkpoints using minimal pairs that differ in linguistic acceptability or idiomaticity. For linguistic acceptability, we adapt existing benchmarks into a minimal-pair format. To assess idiomaticity, we introduce two novel datasets: one contrasting conventionalized idioms with plausible variants, and another contrasting idiomatic Swedish with Translationese. Our findings suggest that idiomatic competence emerges more slowly than other linguistic abilities, including grammatical and lexical correctness. While longer training yields diminishing returns for most tasks, idiom-related performance continues to improve, particularly in the largest model tested (8B). However, instruction tuning on data machine-translated from English -- the common approach for languages with little or no native instruction data -- causes models to rapidly lose their preference for idiomatic language.

</details>


### [49] [Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning](https://arxiv.org/abs/2602.03485)
*Quanyu Long,Kai Jie Jiang,Jianda Chen,Xu Guo,Leilei Gan,Wenya Wang*

Main category: cs.CL

TL;DR: 该论文发现大型推理模型存在过度自我验证的问题，提出了一种基于经验驱动的测试时框架来减少不必要的验证步骤，从而降低计算开销并保持准确性。


<details>
  <summary>Details</summary>
Motivation: 通过大规模实证分析发现，大型推理模型中存在大量自我验证步骤，但这些验证大多是确认性的而非纠正性的，很少能真正识别错误或改变推理结果。这种验证激活频率与实际效用之间存在不匹配，导致了计算资源的浪费。

Method: 提出了一种经验驱动的测试时框架：1) 检测重新检查行为的激活；2) 查询离线经验池中过去的验证结果；3) 通过高效检索估计重新检查是否可能不必要；4) 当历史经验表明不必要时，发出抑制信号让模型继续推理。

Result: 该方法在多个模型和基准测试中，将token使用量减少了高达20.3%，同时保持了准确性，在某些数据集上甚至提高了准确性。

Conclusion: 研究揭示了大型推理模型中自我验证行为存在过度使用的问题，提出的经验驱动框架能有效减少不必要的验证步骤，在保持模型性能的同时显著降低计算成本，为优化推理模型的效率提供了新思路。

Abstract: Large Reasoning Models (LRMs) achieve strong performance by generating long reasoning traces with reflection. Through a large-scale empirical analysis, we find that a substantial fraction of reflective steps consist of self-verification (recheck) that repeatedly confirm intermediate results. These rechecks occur frequently across models and benchmarks, yet the vast majority are confirmatory rather than corrective, rarely identifying errors and altering reasoning outcomes. This reveals a mismatch between how often self-verification is activated and how often it is actually useful. Motivated by this, we propose a novel, experience-driven test-time framework that reduces the overused verification. Our method detects the activation of recheck behavior, consults an offline experience pool of past verification outcomes, and estimates whether a recheck is likely unnecessary via efficient retrieval. When historical experience suggests unnecessary, a suppression signal redirects the model to proceed. Across multiple model and benchmarks, our approach reduces token usage up to 20.3% while maintaining the accuracy, and in some datasets even yields accuracy improvements.

</details>


### [50] [Learning to Reason Faithfully through Step-Level Faithfulness Maximization](https://arxiv.org/abs/2602.03507)
*Runquan Gui,Yafu Li,Xiaoye Qu,Ziyan Liu,Yeqiu Cheng,Yu Cheng*

Main category: cs.CL

TL;DR: FaithRL是一个强化学习框架，通过几何奖励设计和优势调制机制优化推理过程的忠实性，减少大语言模型的多步推理中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证奖励的强化学习（RLVR）主要依赖稀疏的结果奖励，对中间步骤监督不足，导致模型过度自信和虚假推理，增加了幻觉问题。

Method: 提出FaithRL框架：1）形式化忠实性最大化目标；2）引入几何奖励设计；3）采用忠实性感知的优势调制机制，对未支持的步骤进行惩罚，同时保留有效的部分推导。

Result: 在多种模型和基准测试中，FaithRL持续降低幻觉率，同时保持（甚至提高）答案正确性。进一步分析证实FaithRL提高了步骤推理的忠实性，并具有鲁棒泛化能力。

Conclusion: FaithRL通过优化推理过程的忠实性，有效解决了RLVR中的幻觉问题，为多步推理任务提供了一个通用的强化学习框架。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly improved the performance of Large Language Models (LLMs) on tasks requiring multi-step reasoning. However, most RLVR pipelines rely on sparse outcome-based rewards, providing little supervision over intermediate steps and thus encouraging over-confidence and spurious reasoning, which in turn increases hallucinations. To address this, we propose FaithRL, a general reinforcement learning framework that directly optimizes reasoning faithfulness. We formalize a faithfulness-maximization objective and theoretically show that optimizing it mitigates over-confidence. To instantiate this objective, we introduce a geometric reward design and a faithfulness-aware advantage modulation mechanism that assigns step-level credit by penalizing unsupported steps while preserving valid partial derivations. Across diverse backbones and benchmarks, FaithRL consistently reduces hallucination rates while maintaining (and often improving) answer correctness. Further analysis confirms that FaithRL increases step-wise reasoning faithfulness and generalizes robustly. Our code is available at https://github.com/aintdoin/FaithRL.

</details>


### [51] [Can Large Language Models Generalize Procedures Across Representations?](https://arxiv.org/abs/2602.03542)
*Fangru Lin,Valentin Hofmann,Xingchen Wan,Weixing Wang,Zifeng Ding,Anthony G. Cohn,Janet B. Pierrehumbert*

Main category: cs.CL

TL;DR: 该论文提出了一种两阶段数据课程学习方法，通过先训练符号表示（代码/图）再训练自然语言数据，显著提升LLM在跨表示任务上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在代码和图等符号表示上训练和测试广泛，但真实用户任务通常以自然语言指定。研究LLM在不同表示形式之间的泛化能力至关重要。

Method: 采用两阶段数据课程学习：第一阶段在符号表示（代码或图）数据上训练，第二阶段在自然语言数据上训练。这种方法相比单独训练某种表示形式能获得更好的跨表示泛化。

Result: 两阶段课程学习显著提升了不同模型家族和任务上的性能。特别地，通过该方法训练的1.5B Qwen模型在自然语言规划任务上能够接近零样本GPT-4o的性能。分析表明成功的跨表示泛化可解释为一种生成类比形式。

Conclusion: 研究证实了LLM在不同表示形式之间泛化的困难，但通过精心设计的数据课程学习可以有效促进这种泛化能力。跨表示泛化可被理解为生成类比，而提出的课程学习方法能有效激发这种能力。

Abstract: Large language models (LLMs) are trained and tested extensively on symbolic representations such as code and graphs, yet real-world user tasks are often specified in natural language. To what extent can LLMs generalize across these representations? Here, we approach this question by studying isomorphic tasks involving procedures represented in code, graphs, and natural language (e.g., scheduling steps in planning). We find that training LLMs with popular post-training methods on graphs or code data alone does not reliably generalize to corresponding natural language tasks, while training solely on natural language can lead to inefficient performance gains. To address this gap, we propose a two-stage data curriculum that first trains on symbolic, then natural language data. The curriculum substantially improves model performance across model families and tasks. Remarkably, a 1.5B Qwen model trained by our method can closely match zero-shot GPT-4o in naturalistic planning. Finally, our analysis suggests that successful cross-representation generalization can be interpreted as a form of generative analogy, which our curriculum effectively encourages.

</details>


### [52] [SEAD: Self-Evolving Agent for Multi-Turn Service Dialogue](https://arxiv.org/abs/2602.03548)
*Yuqin Dai,Ning Gao,Wei Zhang,Jie Wang,Zichen Luo,Jinpeng Wang,Yujie Wang,Ruiyuan Wu,Chaozheng Wang*

Main category: cs.CL

TL;DR: SEAD是一个自我演化的服务对话代理框架，通过解耦用户建模为配置文件控制器和用户角色扮演模型，无需大规模人工标注即可学习有效策略，显著提升任务完成率和对话效率。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在开放域对话中表现出色，但在服务对话中表现不佳，主要原因是依赖噪声大、质量低的人类对话数据，存在数据稀缺和难以模拟真实目标导向用户行为的局限性。

Method: SEAD框架将用户建模解耦为两个组件：配置文件控制器（生成多样化用户状态以管理训练课程）和用户角色扮演模型（专注于现实角色扮演），确保环境提供适应性训练场景而非不公平对抗。

Result: SEAD显著优于开源基础模型和闭源商业模型，将任务完成率提高了17.6%，对话效率提升了11.1%。

Conclusion: SEAD通过自我演化框架有效解决了服务对话中的数据稀缺和用户行为模拟难题，无需大规模人工标注即可显著提升对话代理性能，为服务对话系统提供了有前景的解决方案。

Abstract: Large Language Models have demonstrated remarkable capabilities in open-domain dialogues. However, current methods exhibit suboptimal performance in service dialogues, as they rely on noisy, low-quality human conversation data. This limitation arises from data scarcity and the difficulty of simulating authentic, goal-oriented user behaviors. To address these issues, we propose SEAD (Self-Evolving Agent for Service Dialogue), a framework that enables agents to learn effective strategies without large-scale human annotations. SEAD decouples user modeling into two components: a Profile Controller that generates diverse user states to manage training curriculum, and a User Role-play Model that focuses on realistic role-playing. This design ensures the environment provides adaptive training scenarios rather than acting as an unfair adversary. Experiments demonstrate that SEAD significantly outperforms Open-source Foundation Models and Closed-source Commercial Models, improving task completion rate by 17.6% and dialogue efficiency by 11.1%. Code is available at: https://github.com/Da1yuqin/SEAD.

</details>


### [53] [Assessing the Impact of Typological Features on Multilingual Machine Translation in the Age of Large Language Models](https://arxiv.org/abs/2602.03551)
*Vitalii Hirak,Jaap Jumelet,Arianna Bisazza*

Main category: cs.CL

TL;DR: 本文通过分析NLLB-200和Tower+两个大型多语言翻译模型，发现目标语言的类型学特征显著影响翻译质量，且某些类型特征能从更广泛的输出空间搜索中获益。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言建模取得重大进展，但不同语言间仍存在显著质量差异。除了训练资源不均衡的明显影响外，类型学特征也被认为是决定语言建模内在难度的因素。然而现有证据主要基于小型单语模型或从头训练的双语翻译模型。

Method: 分析两个大型预训练多语言翻译模型：NLLB-200（编码器-解码器架构）和Tower+（仅解码器架构）。基于广泛的语言集，在控制数据资源和书写系统等简单因素后，研究目标语言类型学对翻译质量的影响。

Result: 目标语言类型学显著影响两个模型的翻译质量。具有某些类型学特征的语言能从更广泛的输出空间搜索中获益更多，这表明这些语言可能受益于标准从左到右束搜索之外的替代解码策略。

Conclusion: 语言类型学特征在多语言翻译模型中起着重要作用，不仅影响翻译质量，还影响最佳解码策略的选择。为促进该领域研究，作者发布了FLORES+ MT评估基准中212种语言的细粒度类型学特征集。

Abstract: Despite major advances in multilingual modeling, large quality disparities persist across languages. Besides the obvious impact of uneven training resources, typological properties have also been proposed to determine the intrinsic difficulty of modeling a language. The existing evidence, however, is mostly based on small monolingual language models or bilingual translation models trained from scratch. We expand on this line of work by analyzing two large pre-trained multilingual translation models, NLLB-200 and Tower+, which are state-of-the-art representatives of encoder-decoder and decoder-only machine translation, respectively. Based on a broad set of languages, we find that target language typology drives translation quality of both models, even after controlling for more trivial factors, such as data resourcedness and writing script. Additionally, languages with certain typological properties benefit more from a wider search of the output space, suggesting that such languages could profit from alternative decoding strategies beyond the standard left-to-right beam search. To facilitate further research in this area, we release a set of fine-grained typological properties for 212 languages of the FLORES+ MT evaluation benchmark.

</details>


### [54] [HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing](https://arxiv.org/abs/2602.03560)
*Yizhao Gao,Jianyu Wei,Qihao Zhang,Yu Cheng,Shimao Chen,Zhengju Tang,Zihan Jiang,Yifan Song,Hailin Zhang,Liang Zhao,Bo Yang,Gang Wang,Shijie Cao,Fuli Luo*

Main category: cs.CL

TL;DR: HySparse是一种混合稀疏注意力架构，通过在每层全注意力层之间插入多个稀疏注意力层，利用全注意力层作为精确的oracle来识别重要token，同时重用全注意力的KV缓存，从而显著减少计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法存在两个根本性限制：1）依赖额外代理来预测token重要性，增加了复杂性且性能可能不理想；2）虽然减少了计算但没有节省KV缓存。HySparse旨在解决这两个问题。

Method: HySparse架构在每层全注意力层后插入多个稀疏注意力层，从全注意力层直接获取token选择和KV缓存，使稀疏层能够重用全注意力的KV缓存，减少计算和内存需求。

Result: 在7B密集模型和80B MoE模型上的评估显示，HySparse在所有设置中都持续优于全注意力和混合SWA基线。在80B MoE模型的49层中，仅5层使用全注意力，但HySparse实现了显著的性能提升，同时将KV缓存存储减少了近10倍。

Conclusion: HySparse通过巧妙利用全注意力层作为oracle来指导稀疏层的token选择，并重用KV缓存，有效解决了传统稀疏注意力方法的局限性，在保持性能的同时显著降低了计算和内存开销。

Abstract: This work introduces Hybrid Sparse Attention (HySparse), a new architecture that interleaves each full attention layer with several sparse attention layers. While conceptually simple, HySparse strategically derives each sparse layer's token selection and KV caches directly from the preceding full attention layer. This architecture resolves two fundamental limitations of prior sparse attention methods. First, conventional approaches typically rely on additional proxies to predict token importance, introducing extra complexity and potentially suboptimal performance. In contrast, HySparse uses the full attention layer as a precise oracle to identify important tokens. Second, existing sparse attention designs often reduce computation without saving KV cache. HySparse enables sparse attention layers to reuse the full attention KV cache, thereby reducing both computation and memory. We evaluate HySparse on both 7B dense and 80B MoE models. Across all settings, HySparse consistently outperforms both full attention and hybrid SWA baselines. Notably, in the 80B MoE model with 49 total layers, only 5 layers employ full attention, yet HySparse achieves substantial performance gains while reducing KV cache storage by nearly 10x.

</details>


### [55] [ACL: Aligned Contrastive Learning Improves BERT and Multi-exit BERT Fine-tuning](https://arxiv.org/abs/2602.03563)
*Wei Zhu*

Main category: cs.CL

TL;DR: 提出对齐对比学习(ACL)框架，解决监督学习中对比学习与交叉熵损失的冲突问题，提升多出口BERT模型的性能


<details>
  <summary>Details</summary>
Motivation: 在监督学习场景中，对比学习目标与交叉熵损失目标经常相互冲突，这限制了对比学习在监督设置中的应用

Method: 提出ACL框架：1) ACL-Embed将标签嵌入视为额外增强样本，使用对比学习对齐标签嵌入与样本表示；2) ACL-Grad在目标冲突时丢弃ACL-Embed项；3) ACL-CL让教师出口指导学生浅层出口的优化

Result: 在GLUE基准测试中：a) ACL-BERT优于或与CE和CE+SCL相当；b) ACL特别是CL-ACL显著超越基线方法，为低延迟应用提供更好的质量-速度权衡

Conclusion: ACL框架有效解决了监督学习中对比学习与交叉熵损失的冲突问题，显著提升了多出口BERT模型的性能，为低延迟应用提供了更好的解决方案

Abstract: Despite its success in self-supervised learning, contrastive learning is less studied in the supervised setting. In this work, we first use a set of pilot experiments to show that in the supervised setting, the cross-entropy loss objective (CE) and the contrastive learning objective often conflict with each other, thus hindering the applications of CL in supervised settings. To resolve this problem, we introduce a novel \underline{A}ligned \underline{C}ontrastive \underline{L}earning (ACL) framework. First, ACL-Embed regards label embeddings as extra augmented samples with different labels and employs contrastive learning to align the label embeddings with its samples' representations. Second, to facilitate the optimization of ACL-Embed objective combined with the CE loss, we propose ACL-Grad, which will discard the ACL-Embed term if the two objectives are in conflict. To further enhance the performances of intermediate exits of multi-exit BERT, we further propose cross-layer ACL (ACL-CL), which is to ask the teacher exit to guide the optimization of student shallow exits. Extensive experiments on the GLUE benchmark results in the following takeaways: (a) ACL-BRT outperforms or performs comparably with CE and CE+SCL on the GLUE tasks; (b) ACL, especially CL-ACL, significantly surpasses the baseline methods on the fine-tuning of multi-exit BERT, thus providing better quality-speed tradeoffs for low-latency applications.

</details>


### [56] [Use Graph When It Needs: Efficiently and Adaptively Integrating Retrieval-Augmented Generation with Graphs](https://arxiv.org/abs/2602.03578)
*Su Dong,Qinggang Zhang,Yilin Xiao,Shengyuan Chen,Chuang Zhou,Xiao Huang*

Main category: cs.CL

TL;DR: EA-GraphRAG：一个自适应框架，通过语法感知的复杂度分析动态选择RAG或GraphRAG来处理不同复杂度的查询，解决了传统GraphRAG在简单查询上性能下降和延迟高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统GraphRAG虽然通过知识图谱增强上下文推理，但在实际应用中存在两个主要问题：1）对所有查询都使用GraphRAG导致简单查询上性能下降；2）计算延迟过高。需要一种自适应方法来根据查询复杂度动态选择检索策略。

Method: 提出EA-GraphRAG框架，包含三个核心组件：1）语法特征构造器，解析查询并提取结构特征；2）轻量级复杂度评分器，将特征映射到连续复杂度分数；3）分数驱动的路由策略，根据分数选择密集RAG（低分查询）、基于图的检索（高分查询）或复杂度感知的互惠排名融合处理边界情况。

Result: 在两个单跳和两个多跳QA基准测试上的实验表明，EA-GraphRAG显著提高了准确性，降低了延迟，并在处理混合简单和复杂查询场景中实现了最先进的性能。

Conclusion: 通过语法感知的复杂度分析动态集成RAG和GraphRAG的EA-GraphRAG框架，有效解决了传统GraphRAG的局限性，在保持复杂查询优势的同时提升了简单查询的性能和整体效率。

Abstract: Large language models (LLMs) often struggle with knowledge-intensive tasks due to hallucinations and outdated parametric knowledge. While Retrieval-Augmented Generation (RAG) addresses this by integrating external corpora, its effectiveness is limited by fragmented information in unstructured domain documents. Graph-augmented RAG (GraphRAG) emerged to enhance contextual reasoning through structured knowledge graphs, yet paradoxically underperforms vanilla RAG in real-world scenarios, exhibiting significant accuracy drops and prohibitive latency despite gains on complex queries. We identify the rigid application of GraphRAG to all queries, regardless of complexity, as the root cause. To resolve this, we propose an efficient and adaptive GraphRAG framework called EA-GraphRAG that dynamically integrates RAG and GraphRAG paradigms through syntax-aware complexity analysis. Our approach introduces: (i) a syntactic feature constructor that parses each query and extracts a set of structural features; (ii) a lightweight complexity scorer that maps these features to a continuous complexity score; and (iii) a score-driven routing policy that selects dense RAG for low-score queries, invokes graph-based retrieval for high-score queries, and applies complexity-aware reciprocal rank fusion to handle borderline cases. Extensive experiments on a comprehensive benchmark, consisting of two single-hop and two multi-hop QA benchmarks, demonstrate that our EA-GraphRAG significantly improves accuracy, reduces latency, and achieves state-of-the-art performance in handling mixed scenarios involving both simple and complex queries.

</details>


### [57] [$V_0$: A Generalist Value Model for Any Policy at State Zero](https://arxiv.org/abs/2602.03584)
*Yi-Kai Zhang,Zhiyuan Yao,Hongyan Hao,Yueqing Sun,Qi Gu,Hui Su,Xunliang Cai,De-Chuan Zhan,Han-Jia Ye*

Main category: cs.CL

TL;DR: V₀是一个通用价值模型，能够在不更新参数的情况下估计任何模型在未见提示上的预期性能，用于GRPO训练中的采样预算分配和部署时的模型路由。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在显著局限性：Actor-Critic方法需要与策略模型同等规模的价值模型，且需要昂贵的同步增量训练来跟踪策略变化；GRPO方法虽然消除了价值模型，但需要大量采样来维持基线估计的稳定性。

Method: 将策略的动态能力作为显式上下文输入，利用指令-性能对的历史记录来动态分析模型，摆脱依赖参数拟合来感知能力变化的传统范式。专注于在初始状态（State Zero）进行价值估计，因此命名为V₀。

Result: V₀在GRPO训练中显著优于启发式预算分配方法，在LLM路由任务中实现了性能与成本的帕累托最优权衡。

Conclusion: V₀作为通用价值模型，能够有效解决策略梯度方法中基线估计的挑战，既避免了传统价值模型的训练开销，又克服了GRPO方法需要大量采样的缺点，在训练和部署阶段都具有实用价值。

Abstract: Policy gradient methods rely on a baseline to measure the relative advantage of an action, ensuring the model reinforces behaviors that outperform its current average capability. In the training of Large Language Models (LLMs) using Actor-Critic methods (e.g., PPO), this baseline is typically estimated by a Value Model (Critic) often as large as the policy model itself. However, as the policy continuously evolves, the value model requires expensive, synchronous incremental training to accurately track the shifting capabilities of the policy. To avoid this overhead, Group Relative Policy Optimization (GRPO) eliminates the coupled value model by using the average reward of a group of rollouts as the baseline; yet, this approach necessitates extensive sampling to maintain estimation stability. In this paper, we propose $V_0$, a Generalist Value Model capable of estimating the expected performance of any model on unseen prompts without requiring parameter updates. We reframe value estimation by treating the policy's dynamic capability as an explicit context input; specifically, we leverage a history of instruction-performance pairs to dynamically profile the model, departing from the traditional paradigm that relies on parameter fitting to perceive capability shifts. Focusing on value estimation at State Zero (i.e., the initial prompt, hence $V_0$), our model serves as a critical resource scheduler. During GRPO training, $V_0$ predicts success rates prior to rollout, allowing for efficient sampling budget allocation; during deployment, it functions as a router, dispatching instructions to the most cost-effective and suitable model. Empirical results demonstrate that $V_0$ significantly outperforms heuristic budget allocation and achieves a Pareto-optimal trade-off between performance and cost in LLM routing tasks.

</details>


### [58] [CL-bench: A Benchmark for Context Learning](https://arxiv.org/abs/2602.03587)
*Shihan Dou,Ming Zhang,Zhangyue Yin,Chenhao Huang,Yujiong Shen,Junzhe Wang,Jiayi Chen,Yuchen Ni,Junjie Ye,Cheng Zhang,Huaibing Xie,Jianglu Hu,Shaolei Wang,Weichao Wang,Yanling Xiao,Yiting Liu,Zenan Xu,Zhen Guo,Pluto Zhou,Tao Gui,Zuxuan Wu,Xipeng Qiu,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Di Wang,Shunyu Yao*

Main category: cs.CL

TL;DR: CL-bench是一个评估语言模型上下文学习能力的真实世界基准，包含500个复杂上下文、1,899个任务和31,607个验证标准。前沿模型平均只能解决17.2%的任务，表明语言模型尚未掌握有效的上下文学习能力。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在利用预训练知识进行推理方面表现出色，但现实世界任务更加复杂且依赖上下文：模型必须从特定任务的上下文中学习，并利用超出预训练范围的新知识来推理和解决问题。这种上下文学习能力是人类自然具备但一直被忽视的关键能力。

Method: 研究者创建了CL-bench基准，包含由领域专家精心设计的500个复杂上下文、1,899个任务和31,607个验证标准。每个任务的设计确保解决所需的新内容都包含在相应的上下文中，涵盖新领域知识、规则系统、复杂程序和基于经验数据的法律等预训练中不存在的内容。

Result: 对十个前沿语言模型的评估显示，模型平均只能解决17.2%的任务。即使表现最好的GPT-5.1模型也只能解决23.7%的任务，这表明语言模型尚未实现有效的上下文学习能力。

Conclusion: 上下文学习能力是语言模型处理现实世界复杂任务的关键瓶颈。CL-bench代表了构建具备这种基本能力的语言模型的重要一步，使其更加智能并推动在实际场景中的部署应用。

Abstract: Current language models (LMs) excel at reasoning over prompts using pre-trained knowledge. However, real-world tasks are far more complex and context-dependent: models must learn from task-specific context and leverage new knowledge beyond what is learned during pre-training to reason and resolve tasks. We term this capability context learning, a crucial ability that humans naturally possess but has been largely overlooked. To this end, we introduce CL-bench, a real-world benchmark consisting of 500 complex contexts, 1,899 tasks, and 31,607 verification rubrics, all crafted by experienced domain experts. Each task is designed such that the new content required to resolve it is contained within the corresponding context. Resolving tasks in CL-bench requires models to learn from the context, ranging from new domain-specific knowledge, rule systems, and complex procedures to laws derived from empirical data, all of which are absent from pre-training. This goes far beyond long-context tasks that primarily test retrieval or reading comprehension, and in-context learning tasks, where models learn simple task patterns via instructions and demonstrations. Our evaluations of ten frontier LMs find that models solve only 17.2% of tasks on average. Even the best-performing model, GPT-5.1, solves only 23.7%, revealing that LMs have yet to achieve effective context learning, which poses a critical bottleneck for tackling real-world, complex context-dependent tasks. CL-bench represents a step towards building LMs with this fundamental capability, making them more intelligent and advancing their deployment in real-world scenarios.

</details>


### [59] [Efficient Algorithms for Partial Constraint Satisfaction Problems over Control-flow Graphs](https://arxiv.org/abs/2602.03588)
*Xuran Cai,Amir Goharshady*

Main category: cs.CL

TL;DR: 针对程序控制流图的偏约束满足问题提出通用算法，时间复杂度为O(|G|·|D|^6)，对固定域为线性时间，统一了寄存器分配等优化任务。


<details>
  <summary>Details</summary>
Motivation: 许多经典编译器优化任务（如寄存器分配、LOSPRE、最优库选择指令放置）都可以表示为控制流图上的偏约束满足问题，而结构化程序的控制流图具有稀疏性和可分解性，这为高效算法提供了机会。

Method: 基于Series-Parallel-Loop分解，提出针对SPL图的通用PCSP算法。该方法将控制流图分解为可处理的子结构，并利用PCSP允许以特定成本违反约束的特性，设计出高效解决方案。

Result: 算法时间复杂度为O(|G|·|D|^6)，对固定域D实现线性时间。该算法统一了先前基于SPL的寄存器分配和LOSPRE方法，并在最优库选择任务上实现了比现有技术快4倍的运行时间。

Conclusion: 提出的通用PCSP算法能够高效解决多种编译器优化问题，通过SPL分解实现了理论上的线性时间复杂性，并在实际应用中显著提升了性能，为编译器优化提供了统一的理论框架。

Abstract: In this work, we focus on the Partial Constraint Satisfaction Problem (PCSP) over control-flow graphs (CFGs) of programs. PCSP serves as a generalization of the well-known Constraint Satisfaction Problem (CSP). In the CSP framework, we define a set of variables, a set of constraints, and a finite domain $D$ that encompasses all possible values for each variable. The objective is to assign a value to each variable in such a way that all constraints are satisfied. In the graph variant of CSP, an underlying graph is considered and we have one variable corresponding to each vertex of the graph and one or several constraints corresponding to each edge. In PCSPs, we allow for certain constraints to be violated at a specified cost, aiming to find a solution that minimizes the total cost. Numerous classical compiler optimization tasks can be framed as PCSPs over control-flow graphs. Examples include Register Allocation, Lifetime-optimal Speculative Partial Redundancy Elimination (LOSPRE), and Optimal Placement of Bank Selection Instructions. On the other hand, it is well-known that control-flow graphs of structured programs are sparse and decomposable in a variety of ways. In this work, we rely on the Series-Parallel-Loop (SPL) decompositions as introduced by~\cite{RegisterAllocation}. Our main contribution is a general algorithm for PCSPs over SPL graphs with a time complexity of \(O(|G| \cdot |D|^6)\), where \(|G|\) represents the size of the control-flow graph. Note that for any fixed domain $D,$ this yields a linear-time solution. Our algorithm can be seen as a generalization and unification of previous SPL-based approaches for register allocation and LOSPRE. In addition, we provide experimental results over another classical PCSP task, i.e. Optimal Bank Selection, achieving runtimes four times better than the previous state of the art.

</details>


### [60] [Learning Query-Specific Rubrics from Human Preferences for DeepResearch Report Generation](https://arxiv.org/abs/2602.03619)
*Changze Lv,Jie Zhou,Wentao Zhao,Jingwen Xu,Zisu Huang,Muzhao Tian,Shihan Dou,Tao Gui,Le Tian,Xiao Zhou,Xiaoqing Zheng,Xuanjing Huang,Jie Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种针对DeepResearch报告生成任务的人类偏好对齐的查询特定评分标准生成器，通过强化学习训练，并结合多智能体马尔可夫状态工作流，显著提升了报告质量评估效果。


<details>
  <summary>Details</summary>
Motivation: 当前DeepResearch生成的报告缺乏可验证的奖励信号，现有的评估方法存在局限性：要么依赖粗粒度的预定义评分标准，缺乏足够的细粒度；要么依赖人工构建的查询特定评分标准，成本高昂且难以扩展。

Method: 1. 构建包含DeepResearch风格查询和人类偏好的数据集；2. 通过强化学习训练评分标准生成器，结合人类偏好监督和基于LLM的评分标准评估的混合奖励；3. 引入多智能体马尔可夫状态工作流来处理长时程推理问题。

Result: 实验表明，提出的评分标准生成器比现有评分标准设计策略提供更具区分度和更好人类对齐的监督。当集成到MaMs训练框架中时，配备该评分标准生成器的DeepResearch系统在DeepResearch基准测试中持续优于所有开源基线，并达到与领先闭源模型相当的性能。

Conclusion: 本文提出的查询特定评分标准生成器与多智能体马尔可夫状态工作流相结合，有效解决了DeepResearch报告评估的挑战，为自动生成高质量、可扩展的评估标准提供了可行方案。

Abstract: Nowadays, training and evaluating DeepResearch-generated reports remain challenging due to the lack of verifiable reward signals. Accordingly, rubric-based evaluation has become a common practice. However, existing approaches either rely on coarse, pre-defined rubrics that lack sufficient granularity, or depend on manually constructed query-specific rubrics that are costly and difficult to scale. In this paper, we propose a pipeline to train human-preference-aligned query-specific rubric generators tailored for DeepResearch report generation. We first construct a dataset of DeepResearch-style queries annotated with human preferences over paired reports, and train rubric generators via reinforcement learning with a hybrid reward combining human preference supervision and LLM-based rubric evaluation. To better handle long-horizon reasoning, we further introduce a Multi-agent Markov-state (MaMs) workflow for report generation. We empirically show that our proposed rubric generators deliver more discriminative and better human-aligned supervision than existing rubric design strategies. Moreover, when integrated into the MaMs training framework, DeepResearch systems equipped with our rubric generators consistently outperform all open-source baselines on the DeepResearch Bench and achieve performance comparable to that of leading closed-source models.

</details>


### [61] [BIRDTurk: Adaptation of the BIRD Text-to-SQL Dataset to Turkish](https://arxiv.org/abs/2602.03633)
*Burak Aktaş,Mehmet Can Baytekin,Süha Kağan Köse,Ömer İlbilgi,Elif Özge Yılmaz,Çağrı Toraman,Bilge Kaan Görür*

Main category: cs.CL

TL;DR: 首个土耳其语Text-to-SQL基准BIRDTurk揭示：土耳其语导致性能下降，源于语言结构差异和LLM预训练不足，而多阶段推理展现更强跨语言鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL系统在英语基准上表现良好，但在形态丰富、资源稀缺的语言（如土耳其语）中的表现尚未被充分探索，需要构建一个可控的跨语言评估基准。

Method: 通过受控翻译流程构建BIRDTurk基准，将BIRD基准适配到土耳其语，严格保持SQL查询和数据库的逻辑结构和执行语义，并通过中心极限定理确定样本量进行翻译质量验证。

Result: 土耳其语导致一致的性能下降，主要由结构语言差异和LLM预训练中代表性不足驱动；多阶段推理展现更强的跨语言鲁棒性；监督微调对标准多语言基线具有挑战性，但现代指令微调模型能有效扩展。

Conclusion: BIRDTurk为现实数据库条件下的跨语言Text-to-SQL评估提供了可控测试平台，并释放了训练和开发数据集以支持未来研究，揭示了语言差异对Text-to-SQL性能的重要影响。

Abstract: Text-to-SQL systems have achieved strong performance on English benchmarks, yet their behavior in morphologically rich, low-resource languages remains largely unexplored. We introduce BIRDTurk, the first Turkish adaptation of the BIRD benchmark, constructed through a controlled translation pipeline that adapts schema identifiers to Turkish while strictly preserving the logical structure and execution semantics of SQL queries and databases. Translation quality is validated on a sample size determined by the Central Limit Theorem to ensure 95% confidence, achieving 98.15% accuracy on human-evaluated samples. Using BIRDTurk, we evaluate inference-based prompting, agentic multi-stage reasoning, and supervised fine-tuning. Our results reveal that Turkish introduces consistent performance degradation, driven by both structural linguistic divergence and underrepresentation in LLM pretraining, while agentic reasoning demonstrates stronger cross-lingual robustness. Supervised fine-tuning remains challenging for standard multilingual baselines but scales effectively with modern instruction-tuned models. BIRDTurk provides a controlled testbed for cross-lingual Text-to-SQL evaluation under realistic database conditions. We release the training and development splits to support future research.

</details>


### [62] [TRE: Encouraging Exploration in the Trust Region](https://arxiv.org/abs/2602.03635)
*Chao Huang,Yujing Lu,Quangang Li,Shenghe Wang,Yan Wang,Yueyang Zhang,Long Xia,Jiashu Zhao,Zhiyuan Sun,Daiting Shi,Tingwen Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新的强化学习探索方法TRE，针对大语言模型中传统熵正则化效果不佳的问题，通过限制探索在信任区域内来提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统熵正则化在强化学习中常用于增强探索，但在大语言模型中效果甚微甚至降低性能。作者认为这是因为大语言模型具有大规模词汇表和长生成序列，导致累积尾部风险——标准全局熵最大化会不加区分地将概率质量分散到大量无效token的尾部，而不是集中在合理候选上，从而破坏连贯推理。

Method: 提出Trust Region Entropy (TRE)方法，该方法鼓励探索严格限定在模型的信任区域内。通过限制探索范围，确保探索集中在合理的候选token上，避免将概率质量过度分散到无效token中。

Result: 在数学推理(MATH)、组合搜索(Countdown)和偏好对齐(HH)等任务上的广泛实验表明，TRE始终优于vanilla PPO、标准熵正则化和其他探索基线方法。

Conclusion: TRE方法有效解决了大语言模型中传统熵正则化的问题，通过信任区域内的探索提升了强化学习在大语言模型任务中的性能，为LLM强化学习提供了更有效的探索策略。

Abstract: Entropy regularization is a standard technique in reinforcement learning (RL) to enhance exploration, yet it yields negligible effects or even degrades performance in Large Language Models (LLMs). We attribute this failure to the cumulative tail risk inherent to LLMs with massive vocabularies and long generation horizons. In such environments, standard global entropy maximization indiscriminately dilutes probability mass into the vast tail of invalid tokens rather than focusing on plausible candidates, thereby disrupting coherent reasoning. To address this, we propose Trust Region Entropy (TRE), a method that encourages exploration strictly within the model's trust region. Extensive experiments across mathematical reasoning (MATH), combinatorial search (Countdown), and preference alignment (HH) tasks demonstrate that TRE consistently outperforms vanilla PPO, standard entropy regularization, and other exploration baselines. Our code is available at https://github.com/WhyChaos/TRE-Encouraging-Exploration-in-the-Trust-Region.

</details>


### [63] [Instruction Anchors: Dissecting the Causal Dynamics of Modality Arbitration](https://arxiv.org/abs/2602.03677)
*Yu Zhang,Mufan Xu,Xuefeng Bai,Kehai chen,Pengfei Zhang,Yang Xiang,Min Zhang*

Main category: cs.CL

TL;DR: 本文通过信息流视角研究多模态大语言模型的模态跟随机制，发现指令token作为结构锚点，浅层注意力层执行非选择性信息传输，深层注意力层解决模态竞争，MLP层表现出语义惯性，且存在稀疏的关键注意力头驱动仲裁过程。


<details>
  <summary>Details</summary>
Motivation: 模态跟随是多模态大语言模型根据用户指令选择性利用多模态上下文的能力，对实际部署的安全性和可靠性至关重要。然而，这一决策过程的底层机制尚不清楚，需要深入理解其工作机制。

Method: 通过信息流视角分析模态跟随机制，识别指令token作为结构锚点的作用，分析不同层次（浅层注意力层、深层注意力层、MLP层）的功能，发现稀疏的专门注意力头驱动仲裁过程，并通过因果干预实验验证关键头的作用。

Result: 研究发现：1）指令token作为模态仲裁的结构锚点；2）浅层注意力层进行非选择性信息传输，将多模态线索路由到这些锚点作为潜在缓冲区；3）深层注意力层在指令意图指导下解决模态竞争；4）MLP层表现出语义惯性，充当对抗力量；5）存在稀疏的专门注意力头驱动仲裁；6）仅操纵5%的关键头就能通过阻断使模态跟随率降低60%，或通过针对性放大失败样本使其提高60%。

Conclusion: 该研究为模型透明度提供了重要进展，并为多模态大语言模型中多模态信息的编排提供了原则性框架，有助于提高模型的安全性和可靠性。

Abstract: Modality following serves as the capacity of multimodal large language models (MLLMs) to selectively utilize multimodal contexts based on user instructions. It is fundamental to ensuring safety and reliability in real-world deployments. However, the underlying mechanisms governing this decision-making process remain poorly understood. In this paper, we investigate its working mechanism through an information flow lens. Our findings reveal that instruction tokens function as structural anchors for modality arbitration: Shallow attention layers perform non-selective information transfer, routing multimodal cues to these anchors as a latent buffer; Modality competition is resolved within deep attention layers guided by the instruction intent, while MLP layers exhibit semantic inertia, acting as an adversarial force. Furthermore, we identify a sparse set of specialized attention heads that drive this arbitration. Causal interventions demonstrate that manipulating a mere $5\%$ of these critical heads can decrease the modality-following ratio by $60\%$ through blocking, or increase it by $60\%$ through targeted amplification of failed samples. Our work provides a substantial step toward model transparency and offers a principled framework for the orchestration of multimodal information in MLLMs.

</details>


### [64] [Neural Attention Search Linear: Towards Adaptive Token-Level Hybrid Attention Models](https://arxiv.org/abs/2602.03681)
*Difan Deng,Andreas Bentzen Winje,Lukas Fehring,Marius Lindauer*

Main category: cs.CL

TL;DR: NAtS-L是一个混合注意力框架，在token级别自动选择使用线性注意力或softmax注意力，以平衡计算效率和表达能力。


<details>
  <summary>Details</summary>
Motivation: softmax注意力在长上下文场景中的二次计算复杂度成为瓶颈，而线性注意力虽然效率高但表达能力受限于隐藏状态大小。现有混合方法仍然受softmax注意力层的效率限制。

Method: 提出NAtS-L框架，在同一层中对不同token同时应用线性注意力和softmax注意力操作。通过搜索最优的Gated DeltaNet和softmax注意力组合，自动确定token适合哪种注意力机制。

Result: NAtS-L提供了一个强大且高效的token级混合架构，能有效平衡计算复杂度和模型表达能力。

Conclusion: 该框架通过token级混合注意力设计，解决了传统混合方法中softmax注意力仍为效率瓶颈的问题，为长上下文场景提供了更优的解决方案。

Abstract: The quadratic computational complexity of softmax transformers has become a bottleneck in long-context scenarios. In contrast, linear attention model families provide a promising direction towards a more efficient sequential model. These linear attention models compress past KV values into a single hidden state, thereby efficiently reducing complexity during both training and inference. However, their expressivity remains limited by the size of their hidden state. Previous work proposed interleaving softmax and linear attention layers to reduce computational complexity while preserving expressivity. Nevertheless, the efficiency of these models remains bottlenecked by their softmax attention layers. In this paper, we propose Neural Attention Search Linear (NAtS-L), a framework that applies both linear attention and softmax attention operations within the same layer on different tokens. NAtS-L automatically determines whether a token can be handled by a linear attention model, i.e., tokens that have only short-term impact and can be encoded into fixed-size hidden states, or require softmax attention, i.e., tokens that contain information related to long-term retrieval and need to be preserved for future queries. By searching for optimal Gated DeltaNet and softmax attention combinations across tokens, we show that NAtS-L provides a strong yet efficient token-level hybrid architecture.

</details>


### [65] [Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation](https://arxiv.org/abs/2602.03689)
*Jiashuo Sun,Pengcheng Jiang,Saizhuo Wang,Jiajun Fan,Heng Wang,Siru Ouyang,Ming Zhong,Yizhu Jiao,Chengsong Huang,Xueqiang Xu,Pengrui Han,Peiran Li,Jiaxin Huang,Ge Liu,Heng Ji,Jiawei Han*

Main category: cs.CL

TL;DR: BAR-RAG通过将重排序器重构为边界感知证据选择器，针对生成器的"恰到好处"证据区域进行优化，在噪声检索下显著提升RAG系统的端到端性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统在现实检索噪声下表现脆弱，即使所需证据出现在top-K结果中。主要原因是检索器和重排序器仅优化相关性，往往选择要么过于简单、答案明显的段落，要么缺乏回答所需关键信息的证据，而没有考虑证据是否适合生成器。

Method: BAR-RAG将重排序器重构为边界感知证据选择器，针对生成器的"恰到好处"区域（既不过于简单也不无法回答，而是具有挑战性但足够推理的证据）。使用强化学习通过生成器反馈训练选择器，采用两阶段流水线在诱导的证据分布下微调生成器，以减少训练和推理之间的分布不匹配。

Result: 在知识密集型问答基准测试中，BAR-RAG在噪声检索下持续提升端到端性能，平均比强大的RAG和重排序基线提高10.3%，同时显著提高了鲁棒性。

Conclusion: BAR-RAG通过边界感知证据选择和生成器微调，有效解决了RAG系统在噪声检索下的脆弱性问题，为检索增强生成提供了更稳健的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) systems remain brittle under realistic retrieval noise, even when the required evidence appears in the top-K results. A key reason is that retrievers and rerankers optimize solely for relevance, often selecting either trivial, answer-revealing passages or evidence that lacks the critical information required to answer the question, without considering whether the evidence is suitable for the generator. We propose BAR-RAG, which reframes the reranker as a boundary-aware evidence selector that targets the generator's Goldilocks Zone -- evidence that is neither trivially easy nor fundamentally unanswerable for the generator, but is challenging yet sufficient for inference and thus provides the strongest learning signal. BAR-RAG trains the selector with reinforcement learning using generator feedback, and adopts a two-stage pipeline that fine-tunes the generator under the induced evidence distribution to mitigate the distribution mismatch between training and inference. Experiments on knowledge-intensive question answering benchmarks show that BAR-RAG consistently improves end-to-end performance under noisy retrieval, achieving an average gain of 10.3 percent over strong RAG and reranking baselines while substantially improving robustness. Code is publicly avaliable at https://github.com/GasolSun36/BAR-RAG.

</details>


### [66] [OCRTurk: A Comprehensive OCR Benchmark for Turkish](https://arxiv.org/abs/2602.03693)
*Deniz Yılmaz,Evren Ayberk Munis,Çağrı Toraman,Süha Kağan Köse,Burak Aktaş,Mehmet Can Baytekin,Bilge Kaan Görür*

Main category: cs.CL

TL;DR: 研究人员开发了OCRTurk，一个土耳其语文档解析基准测试，包含三个难度等级的多种文档类型，评估了7个OCR模型，发现PaddleOCR表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有文档解析基准主要针对高资源语言，对土耳其语等低资源语言覆盖有限，且缺乏反映真实场景和文档多样性的标准化基准。

Method: 创建了包含180个土耳其语文档的OCRTurk基准，涵盖学术文章、论文、幻灯片和非学术文章等多种文档类型，分为三个难度等级，并使用元素级指标评估了7个OCR模型。

Result: PaddleOCR在整体表现上最强，在简单、中等和困难子集中都获得了高归一化编辑距离分数，但在图表识别上表现不佳。不同文档类型性能有差异，非学术文档表现最好，幻灯片最具挑战性。

Conclusion: OCRTurk填补了土耳其语文档解析标准化基准的空白，为评估模型在真实场景下的性能提供了重要工具，有助于推动低资源语言文档解析技术的发展。

Abstract: Document parsing is now widely used in applications, such as large-scale document digitization, retrieval-augmented generation, and domain-specific pipelines in healthcare and education. Benchmarking these models is crucial for assessing their reliability and practical robustness. Existing benchmarks mostly target high-resource languages and provide limited coverage for low-resource settings, such as Turkish. Moreover, existing studies on Turkish document parsing lack a standardized benchmark that reflects real-world scenarios and document diversity. To address this gap, we introduce OCRTurk, a Turkish document parsing benchmark covering multiple layout elements and document categories at three difficulty levels. OCRTurk consists of 180 Turkish documents drawn from academic articles, theses, slide decks, and non-academic articles. We evaluate seven OCR models on OCRTurk using element-wise metrics. Across difficulty levels, PaddleOCR achieves the strongest overall results, leading most element-wise metrics except figures and attaining high Normalized Edit Distance scores in easy, medium, and hard subsets. We also observe performance variation by document type. Models perform well on non-academic documents, while slideshows become the most challenging.

</details>


### [67] [Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models](https://arxiv.org/abs/2602.03704)
*Yu Tian,Linh Huynh,Katerina Christhilf,Shubham Chakraborty,Micah Watanabe,Tracy Arner,Danielle McNamara*

Main category: cs.CL

TL;DR: ReQUESTA是一个混合多智能体框架，通过分解MCQ生成任务、协调LLM智能体和基于规则的组件，生成具有认知多样性的选择题，在难度、区分度和质量上优于单次提示的GPT-5基线。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型使自动生成选择题变得可行，但可靠地生成满足特定认知需求（如文本理解、推理和主旨理解）的题目仍然是一个挑战。需要系统化方法来提高生成的可控性和可靠性。

Method: 引入ReQUESTA混合多智能体框架，将MCQ生成分解为规划、受控生成、迭代评估和后处理等专门子任务，协调LLM智能体和基于规则组件，针对文本理解、推理和主旨理解等认知需求生成题目。

Result: 与单次提示的GPT-5基线相比，ReQUESTA生成的题目更具挑战性、区分度更高，与整体阅读理解表现更一致。专家评估显示题目更贴合核心概念，干扰项的语言一致性和语义合理性更好，特别是在推理题上表现更优。

Conclusion: 混合智能体编排可以系统化提高LLM生成的可控性和可靠性，工作流设计是超越单次提示的结构化生成的关键杠杆。

Abstract: Recent advances in large language models (LLMs) have made automated multiple-choice question (MCQ) generation increasingly feasible; however, reliably producing items that satisfy controlled cognitive demands remains a challenge. To address this gap, we introduce ReQUESTA, a hybrid, multi-agent framework for generating cognitively diverse MCQs that systematically target text-based, inferential, and main idea comprehension. ReQUESTA decomposes MCQ authoring into specialized subtasks and coordinates LLM-powered agents with rule-based components to support planning, controlled generation, iterative evaluation, and post-processing. We evaluated the framework in a large-scale reading comprehension study using academic expository texts, comparing ReQUESTA-generated MCQs with those produced by a single-pass GPT-5 zero-shot baseline. Psychometric analyses of learner responses assessed item difficulty and discrimination, while expert raters evaluated question quality across multiple dimensions, including topic relevance and distractor quality. Results showed that ReQUESTA-generated items were consistently more challenging, more discriminative, and more strongly aligned with overall reading comprehension performance. Expert evaluations further indicated stronger alignment with central concepts and superior distractor linguistic consistency and semantic plausibility, particularly for inferential questions. These findings demonstrate that hybrid, agentic orchestration can systematically improve the reliability and controllability of LLM-based generation, highlighting workflow design as a key lever for structured artifact generation beyond single-pass prompting.

</details>


### [68] [OmniRAG-Agent: Agentic Omnimodal Reasoning for Low-Resource Long Audio-Video Question Answering](https://arxiv.org/abs/2602.03707)
*Yifan Zhu,Xinyu Mu,Tao Feng,Zhonghong Ou,Yuning Gong,Haoran Luo*

Main category: cs.CL

TL;DR: OmniRAG-Agent：一种用于预算受限长音频视频问答的智能体方法，通过图像-音频检索增强生成、智能体循环规划和联合优化来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前长音频视频问答面临四个主要问题：1）密集编码成本高昂；2）细粒度检索能力弱；3）主动规划能力有限；4）缺乏端到端优化。这些问题在低资源环境下尤为突出。

Method: 提出OmniRAG-Agent方法，包含三个核心组件：1）图像-音频检索增强生成模块，让OmniLLM从外部库中获取相关的短帧和音频片段；2）智能体循环，跨回合进行规划、调用工具并合并检索证据；3）群体相对策略优化，联合优化工具使用和答案质量。

Result: 在OmniVideoBench、WorldSense和Daily-Omni三个基准测试中，OmniRAG-Agent在低资源设置下始终优于先前方法，并通过消融实验验证了各组件的重要性。

Conclusion: OmniRAG-Agent成功解决了长音频视频问答中的关键挑战，通过检索增强生成、智能体规划和联合优化实现了高效的低资源多模态推理，为预算受限环境下的长音频视频理解提供了有效解决方案。

Abstract: Long-horizon omnimodal question answering answers questions by reasoning over text, images, audio, and video. Despite recent progress on OmniLLMs, low-resource long audio-video QA still suffers from costly dense encoding, weak fine-grained retrieval, limited proactive planning, and no clear end-to-end optimization.To address these issues, we propose OmniRAG-Agent, an agentic omnimodal QA method for budgeted long audio-video reasoning. It builds an image-audio retrieval-augmented generation module that lets an OmniLLM fetch short, relevant frames and audio snippets from external banks. Moreover, it uses an agent loop that plans, calls tools across turns, and merges retrieved evidence to answer complex queries. Furthermore, we apply group relative policy optimization to jointly improve tool use and answer quality over time. Experiments on OmniVideoBench, WorldSense, and Daily-Omni show that OmniRAG-Agent consistently outperforms prior methods under low-resource settings and achieves strong results, with ablations validating each component.

</details>


### [69] [Beyond Tokens: Semantic-Aware Speculative Decoding for Efficient Inference by Probing Internal States](https://arxiv.org/abs/2602.03708)
*Ximing Dong,Shaowei Wang,Dayi Lin,Boyuan Chen,Ahmed E. Hassan*

Main category: cs.CL

TL;DR: SemanticSpec：一种语义感知的推测解码框架，通过验证整个语义序列而非单个token来加速大语言模型推理，实现最高2.7倍加速


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）和大推理模型（LRMs）因自回归解码导致推理延迟高。现有推测解码方法在token级别操作，忽略语义等价性（不同token序列表达相同含义），导致低效拒绝

Method: 提出语义感知推测解码框架SemanticSpec，验证整个语义序列而非token。引入语义概率估计机制，通过探测模型内部隐藏状态来评估生成特定含义序列的可能性

Result: 在四个基准测试中，SemanticSpec在DeepSeekR1-32B上实现最高2.7倍加速，在QwQ-32B上实现2.1倍加速，在效率和效果上均优于token级和序列级基线方法

Conclusion: SemanticSpec通过语义级验证有效解决传统推测解码的语义等价性问题，显著提升大语言模型的推理速度，为高效推理提供了新方向

Abstract: Large Language Models (LLMs) achieve strong performance across many tasks but suffer from high inference latency due to autoregressive decoding. The issue is exacerbated in Large Reasoning Models (LRMs), which generate lengthy chains of thought. While speculative decoding accelerates inference by drafting and verifying multiple tokens in parallel, existing methods operate at the token level and ignore semantic equivalence (i.e., different token sequences expressing the same meaning), leading to inefficient rejections. We propose SemanticSpec, a semantic-aware speculative decoding framework that verifies entire semantic sequences instead of tokens. SemanticSpec introduces a semantic probability estimation mechanism that probes the model's internal hidden states to assess the likelihood of generating sequences with specific meanings.Experiments on four benchmarks show that SemanticSpec achieves up to 2.7x speedup on DeepSeekR1-32B and 2.1x on QwQ-32B, consistently outperforming token-level and sequence-level baselines in both efficiency and effectiveness.

</details>


### [70] [No Shortcuts to Culture: Indonesian Multi-hop Question Answering for Complex Cultural Understanding](https://arxiv.org/abs/2602.03709)
*Vynska Amalia Permadi,Xingwei Tan,Nafise Sadat Moosavi,Nikos Aletras*

Main category: cs.CL

TL;DR: ID-MoCQA 是首个针对大语言模型文化理解能力的大规模多跳问答基准数据集，专注于印尼传统文化，提供英语和印尼语版本，通过系统化框架将单跳问题转化为多跳推理链。


<details>
  <summary>Details</summary>
Motivation: 现有文化相关的问答基准大多依赖单跳问题，模型可能利用浅层线索而非真正进行文化推理，无法充分评估模型的文化理解能力。

Method: 1) 提出系统化框架将单跳文化问题转化为多跳推理链，涵盖六种线索类型（常识、时间、地理等）；2) 采用多阶段验证流程，结合专家评审和LLM-as-a-judge过滤，确保高质量问答对。

Result: 评估最先进模型发现文化推理能力存在显著差距，特别是在需要细微推理的任务上。ID-MoCQA为提升LLM文化能力提供了具有挑战性的基准。

Conclusion: ID-MoCQA是评估和推进大语言模型文化理解能力的必要且具有挑战性的基准，揭示了当前模型在文化推理方面的不足。

Abstract: Understanding culture requires reasoning across context, tradition, and implicit social knowledge, far beyond recalling isolated facts. Yet most culturally focused question answering (QA) benchmarks rely on single-hop questions, which may allow models to exploit shallow cues rather than demonstrate genuine cultural reasoning. In this work, we introduce ID-MoCQA, the first large-scale multi-hop QA dataset for assessing the cultural understanding of large language models (LLMs), grounded in Indonesian traditions and available in both English and Indonesian. We present a new framework that systematically transforms single-hop cultural questions into multi-hop reasoning chains spanning six clue types (e.g., commonsense, temporal, geographical). Our multi-stage validation pipeline, combining expert review and LLM-as-a-judge filtering, ensures high-quality question-answer pairs. Our evaluation across state-of-the-art models reveals substantial gaps in cultural reasoning, particularly in tasks requiring nuanced inference. ID-MoCQA provides a challenging and essential benchmark for advancing the cultural competency of LLMs.

</details>


### [71] [Training Multi-Turn Search Agent via Contrastive Dynamic Branch Sampling](https://arxiv.org/abs/2602.03719)
*Yubao Zhao,Weiquan Huang,Sudong Wang,Ruochen Zhao,Chen Chen,Yao Shu,Chengwei Qin*

Main category: cs.CL

TL;DR: BranPO是一种无价值函数的方法，通过截断轨迹尾部并重采样替代延续来构建对比后缀，为长视野任务提供步骤级监督，显著提升性能而不增加训练预算。


<details>
  <summary>Details</summary>
Motivation: 当前基于树的智能体强化学习方法在长视野场景下面临稀疏奖励、高方差和计算效率低下的问题。作者通过经验分析发现，性能差异主要源于轨迹尾部的决策，这促使他们开发一种能够提供步骤级对比监督的方法。

Method: 提出Branching Relative Policy Optimization (BranPO)：1）截断轨迹尾部并重采样替代延续，构建对比后缀；2）引入难度感知分支采样，自适应调整不同任务的分支频率；3）使用冗余步骤掩码抑制无信息行动。

Result: 在多个问答基准测试上的实验表明，BranPO始终优于强基线方法，在长视野任务上实现了显著的准确率提升，且没有增加整体训练预算。

Conclusion: BranPO通过尾部轨迹截断和对比后缀构建，有效解决了长视野强化学习中的信用分配模糊问题，提供了一种高效且稳定的训练方法，在保持计算效率的同时显著提升了性能。

Abstract: Agentic reinforcement learning has enabled large language models to perform complex multi-turn planning and tool use. However, learning in long-horizon settings remains challenging due to sparse, trajectory-level outcome rewards. While prior tree-based methods attempt to mitigate this issue, they often suffer from high variance and computational inefficiency. Through empirical analysis of search agents, We identify a common pattern: performance diverges mainly due to decisions near the tail. Motivated by this observation, we propose Branching Relative Policy Optimization (BranPO), a value-free method that provides step-level contrastive supervision without dense rewards. BranPO truncates trajectories near the tail and resamples alternative continuations to construct contrastive suffixes over shared prefixes, reducing credit ambiguity in long-horizon rollouts. To further boost efficiency and stabilize training, we introduce difficulty-aware branch sampling to adapt branching frequency across tasks, and redundant step masking to suppress uninformative actions. Extensive experiments on various question answering benchmarks demonstrate that BranPO consistently outperforms strong baselines, achieving significant accuracy gains on long-horizon tasks without increasing the overall training budget. Our code is available at \href{https://github.com/YubaoZhao/BranPO}{code}.

</details>


### [72] [CUBO: Self-Contained Retrieval-Augmented Generation on Consumer Laptops 10 GB Corpora, 16 GB RAM, Single-Device Deployment](https://arxiv.org/abs/2602.03731)
*Paolo Astrino*

Main category: cs.CL

TL;DR: CUBO是一个面向消费级笔记本电脑的系统化RAG平台，能在16GB共享内存下运行，解决云端AI的GDPR合规问题和本地系统高内存需求之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 处理敏感文档的组织面临两难：云端AI存在GDPR违规风险，而本地系统通常需要18-32GB内存。需要在消费级笔记本电脑（16GB内存）上实现高效且合规的文档检索系统。

Method: CUBO通过工程化集成三个关键技术：流式数据摄取（O(1)缓冲区开销）、分层混合检索、硬件感知编排。在严格的15.5GB内存限制下，实现37,000行代码的系统架构。

Result: 在BEIR基准测试中达到Recall@10为0.48-0.97（跨不同领域），检索延迟185ms（p50，C1,300笔记本电脑），同时通过本地处理确保GDPR合规性（第5(1)(c)条）。

Conclusion: CUBO证明了在消费级笔记本电脑上实现高效RAG系统的可行性，为中小型专业档案提供了实用的部署方案，代码已开源。

Abstract: Organizations handling sensitive documents face a tension: cloud-based AI risks GDPR violations, while local systems typically require 18-32 GB RAM. This paper presents CUBO, a systems-oriented RAG platform for consumer laptops with 16 GB shared memory. CUBO's novelty lies in engineering integration of streaming ingestion (O(1) buffer overhead), tiered hybrid retrieval, and hardware-aware orchestration that enables competitive Recall@10 (0.48-0.97 across BEIR domains) within a hard 15.5 GB RAM ceiling. The 37,000-line codebase achieves retrieval latencies of 185 ms (p50) on C1,300 laptops while maintaining data minimization through local-only processing aligned with GDPR Art. 5(1)(c). Evaluation on BEIR benchmarks validates practical deployability for small-to-medium professional archives. The codebase is publicly available at https://github.com/PaoloAstrino/CUBO.

</details>


### [73] [Context Compression via Explicit Information Transmission](https://arxiv.org/abs/2602.03784)
*Jiangnan Ye,Hanqi Yan,Zhenyi Shen,Heng Chang,Ye Mao,Yulan He*

Main category: cs.CL

TL;DR: ComprExIT提出通过显式信息传输实现长上下文压缩，解决了现有方法中的渐进覆盖和容量分配不协调问题，在多项问答基准上表现优异且仅增加约1%参数。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理成本高昂（二次注意力、KV缓存增长），需要上下文压缩。现有软压缩方法使用LLM本身作为可训练压缩器，存在两个结构性问题：(1)跨层渐进表示覆盖，(2)跨token压缩容量分配不协调。

Method: 提出ComprExIT框架，将软压缩重新表述为在冻结LLM隐藏状态上的显式信息传输新范式。包含：(1)深度传输：选择性地将多层信息传输到token锚点，减轻渐进覆盖；(2)宽度传输：通过全局优化的传输计划将锚点聚合到少量槽中，确保信息分配协调。

Result: 在六个问答基准测试中，ComprExIT持续优于最先进的上下文压缩方法，同时仅引入约1%的额外参数。

Conclusion: 显式和协调的信息传输能够实现更有效和鲁棒的长上下文压缩，将压缩与模型内部自注意力动态解耦是提升压缩效果的关键。

Abstract: Long-context inference with Large Language Models (LLMs) is costly due to quadratic attention and growing key-value caches, motivating context compression. In this work, we study soft context compression, where a long context is condensed into a small set of continuous representations. Existing methods typically re-purpose the LLM itself as a trainable compressor, relying on layer-by-layer self-attention to iteratively aggregate information. We argue that this paradigm suffers from two structural limitations: (i) progressive representation overwriting across layers (ii) uncoordinated allocation of compression capacity across tokens. We propose ComprExIT (Context Compression via Explicit Information Transmission), a lightweight framework that formulates soft compression into a new paradigm: explicit information transmission over frozen LLM hidden states. This decouples compression from the model's internal self-attention dynamics. ComprExIT performs (i) depth-wise transmission to selectively transmit multi-layer information into token anchors, mitigating progressive overwriting, and (ii) width-wise transmission to aggregate anchors into a small number of slots via a globally optimized transmission plan, ensuring coordinated allocation of information. Across six question-answering benchmarks, ComprExIT consistently outperforms state-of-the-art context compression methods while introducing only ~1% additional parameters, demonstrating that explicit and coordinated information transmission enables more effective and robust long-context compression.

</details>


### [74] [They Said Memes Were Harmless-We Found the Ones That Hurt: Decoding Jokes, Symbols, and Cultural References](https://arxiv.org/abs/2602.03822)
*Sahil Tripathi,Gautam Siddharth Kashyap,Mehwish Nasim,Jian Yang,Jiechao Gao,Usman Naseem*

Main category: cs.CL

TL;DR: CROSS-ALIGN+是一个三阶段框架，通过知识增强、边界锐化和可解释性生成，显著提升基于表情包的社会虐待检测性能。


<details>
  <summary>Details</summary>
Motivation: 表情包社会虐待检测面临三大挑战：文化盲区（忽略文化符号）、边界模糊（讽刺与虐待混淆）、缺乏可解释性（模型推理不透明）。现有方法在这些方面存在局限。

Method: 采用三阶段框架：1) 使用ConceptNet、Wikidata和Hatebase的结构化知识增强多模态表示以缓解文化盲区；2) 通过参数高效的LoRA适配器锐化决策边界以减少模糊性；3) 生成级联解释增强可解释性。

Result: 在五个基准测试和八个大型视觉语言模型上的实验表明，CROSS-ALIGN+始终优于最先进方法，相对F1分数提升高达17%，同时为每个决策提供可解释的推理。

Conclusion: CROSS-ALIGN+通过系统性地解决文化盲区、边界模糊和可解释性不足三大问题，显著提升了表情包社会虐待检测的性能和透明度。

Abstract: Meme-based social abuse detection is challenging because harmful intent often relies on implicit cultural symbolism and subtle cross-modal incongruence. Prior approaches, from fusion-based methods to in-context learning with Large Vision-Language Models (LVLMs), have made progress but remain limited by three factors: i) cultural blindness (missing symbolic context), ii) boundary ambiguity (satire vs. abuse confusion), and iii) lack of interpretability (opaque model reasoning). We introduce CROSS-ALIGN+, a three-stage framework that systematically addresses these limitations: (1) Stage I mitigates cultural blindness by enriching multimodal representations with structured knowledge from ConceptNet, Wikidata, and Hatebase; (2) Stage II reduces boundary ambiguity through parameter-efficient LoRA adapters that sharpen decision boundaries; and (3) Stage III enhances interpretability by generating cascaded explanations. Extensive experiments on five benchmarks and eight LVLMs demonstrate that CROSS-ALIGN+ consistently outperforms state-of-the-art methods, achieving up to 17% relative F1 improvement while providing interpretable justifications for each decision.

</details>


### [75] [Accelerating Scientific Research with Gemini: Case Studies and Common Techniques](https://arxiv.org/abs/2602.03837)
*David P. Woodruff,Vincent Cohen-Addad,Lalit Jain,Jieming Mao,Song Zuo,MohammadHossein Bateni,Simina Branzei,Michael P. Brenner,Lin Chen,Ying Feng,Lance Fortnow,Gang Fu,Ziyi Guan,Zahra Hadizadeh,Mohammad T. Hajiaghayi,Mahdi JafariRaviz,Adel Javanmard,Karthik C. S.,Ken-ichi Kawarabayashi,Ravi Kumar,Silvio Lattanzi,Euiwoong Lee,Yi Li,Ioannis Panageas,Dimitris Paparas,Benjamin Przybocki,Bernardo Subercaseaux,Ola Svensson,Shayan Taherijam,Xuan Wu,Eylon Yogev,Morteza Zadimoghaddam,Samson Zhou,Vahab Mirrokni*

Main category: cs.CL

TL;DR: 研究人员通过案例研究展示了如何与先进AI模型（特别是Google的Gemini系列）合作解决理论计算机科学等领域的开放问题、反驳猜想和生成新证明，提出了有效人机协作的方法论。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在辅助常规任务方面表现出色，但其在专家级数学发现中的潜力尚不明确。本文旨在探索AI模型如何真正成为科学发现过程中的创造性合作伙伴。

Method: 通过收集案例研究，展示研究人员如何与Gemini模型协作，采用迭代精炼、问题分解、跨学科知识转移等技术，并超越标准聊天界面，部署模型作为严格审稿人和嵌入"神经符号"循环。

Result: 成功展示了AI模型能够帮助解决开放问题、反驳猜想、生成新证明，在理论计算机科学、经济学、优化和物理学等多个领域取得成果，证明AI可以作为真正的科学发现合作伙伴。

Conclusion: AI不仅可作为自动化工具，更能成为科学发现创造性过程中的多功能、真正的合作伙伴，人机协作方法为加速理论研究和跨学科探索开辟了新途径。

Abstract: Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a "neuro-symbolic" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.

</details>


### [76] [Parallel-Probe: Towards Efficient Parallel Thinking via 2D Probing](https://arxiv.org/abs/2602.03845)
*Tong Zheng,Chengsong Huang,Runpeng Dai,Yun He,Rui Liu,Xin Ni,Huiwen Bao,Kaishen Wang,Hongtu Zhu,Jiaxin Huang,Furong Huang,Heng Huang*

Main category: cs.CL

TL;DR: 提出Parallel-Probe方法，通过共识早期停止和偏差分支剪枝来优化并行推理，在保持准确性的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 并行推理虽然前景广阔，但计算负担大。现有效率方法主要依赖局部轨迹信号，缺乏利用并行分支间全局动态的机制。

Method: 提出2D探测接口揭示并行思维的宽度-深度动态，基于此设计Parallel-Probe控制器：1) 共识早期停止调节推理深度；2) 偏差分支剪枝动态调整宽度。

Result: 在三个基准测试和多个模型上的实验表明，Parallel-Probe建立了更优的测试时间扩展帕累托前沿。相比标准多数投票，序列标记减少35.8%，总标记成本降低25.8%，同时保持竞争力准确性。

Conclusion: Parallel-Probe通过有效利用并行推理的全局动态，为优化在线并行思维提供了有效的训练免费控制器，显著提升了计算效率。

Abstract: Parallel thinking has emerged as a promising paradigm for reasoning, yet it imposes significant computational burdens. Existing efficiency methods primarily rely on local, per-trajectory signals and lack principled mechanisms to exploit global dynamics across parallel branches. We introduce 2D probing, an interface that exposes the width-depth dynamics of parallel thinking by periodically eliciting intermediate answers from all branches. Our analysis reveals three key insights: non-monotonic scaling across width-depth allocations, heterogeneous reasoning branch lengths, and early stabilization of global consensus. Guided by these insights, we introduce $\textbf{Parallel-Probe}$, a training-free controller designed to optimize online parallel thinking. Parallel-Probe employs consensus-based early stopping to regulate reasoning depth and deviation-based branch pruning to dynamically adjust width. Extensive experiments across three benchmarks and multiple models demonstrate that Parallel-Probe establishes a superior Pareto frontier for test-time scaling. Compared to standard majority voting, it reduces sequential tokens by up to $\textbf{35.8}$% and total token cost by over $\textbf{25.8}$% while maintaining competitive accuracy.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [77] [Design and Evaluation of Whole-Page Experience Optimization for E-commerce Search](https://arxiv.org/abs/2602.02514)
*Pratik Lahiri,Bingqing Ge,Zhou Qin,Aditya Jumde,Shuning Huo,Lucas Scottini,Yi Liu,Mahmoud Mamlouk,Wenyang Liu*

Main category: cs.IR

TL;DR: 提出了一个全页面体验优化框架，用于解决电商搜索结果页从线性列表到复杂非线性布局转变带来的挑战，同时优化长期用户满意度指标。


<details>
  <summary>Details</summary>
Motivation: 电商搜索结果页正从线性列表演变为复杂的非线性布局，使得传统的基于位置的排序模型不再适用。现有优化框架通常只最大化短期信号（如点击、当日收入），而长期满意度指标（如预期两周收入）存在延迟反馈和信用分配难题。

Method: 提出了一个新颖的全页面体验优化框架，显式建模商品相关性、二维位置布局和视觉元素之间的相互作用。使用因果框架基于准实验数据开发长期用户满意度度量指标。

Result: 通过行业规模的A/B测试验证，模型在品牌相关性（主要用户体验指标）上提升了1.86%，同时实现了统计显著的+0.05%收入增长。

Conclusion: 该框架成功解决了电商搜索结果页优化中的布局复杂性和长期满意度度量难题，为现代非线性的电商搜索结果页提供了有效的优化方案。

Abstract: E-commerce Search Results Pages (SRPs) are evolving from linear lists to complex, non-linear layouts, rendering traditional position-biased ranking models insufficient. Moreover, existing optimization frameworks typically maximize short-term signals (e.g., clicks, same-day revenue) because long-term satisfaction metrics (e.g., expected two-week revenue) involve delayed feedback and challenging long-horizon credit attribution. To bridge these gaps, we propose a novel Whole-Page Experience Optimization Framework. Unlike traditional list-wise rankers, our approach explicitly models the interplay between item relevance, 2D positional layout, and visual elements. We use a causal framework to develop metrics for measuring long-term user satisfaction based on quasi-experimental data. We validate our approach through industry-scale A/B testing, where the model demonstrated a 1.86% improvement in brand relevance (our primary customer experience metric) while simultaneously achieving a statistically significant revenue uplift of +0.05%

</details>


### [78] [Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval](https://arxiv.org/abs/2602.02827)
*Roi Pony,Adi Raz,Oshri Naparstek,Idan Friedman,Udi Barzelay*

Main category: cs.IR

TL;DR: Col-Bandit是一种查询时剪枝算法，通过将重排序视为有限总体Top-K识别问题，自适应地仅计算确定top结果所需的MaxSim条目，可在保持排序质量的同时将计算量减少5倍。


<details>
  <summary>Details</summary>
Motivation: 多向量延迟交互检索器（如ColBERT）具有最先进的检索质量，但其查询时间成本主要消耗在为每个候选文档详尽计算token级别的MaxSim交互。虽然使用单向量表示近似延迟交互可以降低成本，但通常会导致显著的准确率损失。

Method: Col-Bandit将重排序视为有限总体Top-K识别问题，维护部分观测文档分数的不确定性感知边界，并自适应地仅揭示确定top结果所需的（文档，查询token）MaxSim条目。它作为零样本、即插即用层运行在标准多向量系统之上，无需索引修改、离线预处理或模型重新训练。

Result: 在文本（BEIR）和多模态（REAL-MM-RAG）基准测试中，Col-Bandit在保持排序保真度的同时，将MaxSim FLOPs减少了高达5倍，表明密集延迟交互评分包含大量冗余，可以在查询时有效识别和剪枝。

Conclusion: Col-Bandit提供了一种高效查询时剪枝方法，通过自适应稀疏化交互矩阵，在保持多向量检索器质量的同时显著降低计算成本，证明了延迟交互评分中存在可被有效利用的冗余。

Abstract: Multi-vector late-interaction retrievers such as ColBERT achieve state-of-the-art retrieval quality, but their query-time cost is dominated by exhaustively computing token-level MaxSim interactions for every candidate document. While approximating late interaction with single-vector representations reduces cost, it often incurs substantial accuracy loss. We introduce Col-Bandit, a query-time pruning algorithm that reduces this computational burden by casting reranking as a finite-population Top-$K$ identification problem. Col-Bandit maintains uncertainty-aware bounds over partially observed document scores and adaptively reveals only the (document, query token) MaxSim entries needed to determine the top results under statistical decision bounds with a tunable relaxation. Unlike coarse-grained approaches that prune entire documents or tokens offline, Col-Bandit sparsifies the interaction matrix on the fly. It operates as a zero-shot, drop-in layer over standard multi-vector systems, requiring no index modifications, offline preprocessing, or model retraining. Experiments on textual (BEIR) and multimodal (REAL-MM-RAG) benchmarks show that Col-Bandit preserves ranking fidelity while reducing MaxSim FLOPs by up to 5$\times$, indicating that dense late-interaction scoring contains substantial redundancy that can be identified and pruned efficiently at query time.

</details>


### [79] [Efficiency Optimizations for Superblock-based Sparse Retrieval](https://arxiv.org/abs/2602.02883)
*Parker Carlson,Wentai Xie,Rohil Shah,Tao Yang*

Main category: cs.IR

TL;DR: 提出一种简单有效的超级块剪枝方案，结合紧凑索引结构和零射配置，在保持竞争力的同时降低稀疏检索计算开销


<details>
  <summary>Details</summary>
Motivation: 学习稀疏检索（LSR）结合了语言模型的语义匹配和高效CPU友好算法，但现有方法通过聚合块为"超级块"来快速跳过查询处理中的块访问，需要先进的剪枝启发式方法。本文旨在降低超级块分数计算的开销，同时保持竞争力。

Method: 提出简单有效的超级块剪枝方案，结合紧凑索引结构和鲁棒的零射配置，适用于多种LSR模型和数据集。

Result: 在MS MARCO和BEIR数据集上的评估表明，该方案在保持竞争力的同时显著降低计算开销，成为高效稀疏检索的强有力替代方案。

Conclusion: 该超级块剪枝方案简单有效，结合紧凑索引和零射配置，为高效稀疏检索提供了强有力的替代方案。

Abstract: Learned sparse retrieval (LSR) is a popular method for first-stage retrieval because it combines the semantic matching of language models with efficient CPU-friendly algorithms. Previous work aggregates blocks into "superblocks" to quickly skip the visitation of blocks during query processing by using an advanced pruning heuristic. This paper proposes a simple and effective superblock pruning scheme that reduces the overhead of superblock score computation while preserving competitive relevance. It combines this scheme with a compact index structure and a robust zero-shot configuration that is effective across LSR models and multiple datasets. This paper provides an analytical justification and evaluation on the MS MARCO and BEIR datasets, demonstrating that the proposed scheme can be a strong alternative for efficient sparse retrieval.

</details>


### [80] [ALPBench: A Benchmark for Attribution-level Long-term Personal Behavior Understanding](https://arxiv.org/abs/2602.03056)
*Lu Ren,Junda She,Xinchen Luo,Tao Wang,Xin Ye,Xu Zhang,Muxuan Wang,Xiao Yang,Chenguang Wang,Fei Xie,Yiwei Zhou,Danjun Wu,Guodong Zhang,Yifei Hu,Guoying Zheng,Shujie Yang,Xingmei Wang,Shiyao Wang,Yukun Zhou,Fan Yang,Size Li,Kuo Cai,Qiang Luo,Ruiming Tang,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: ALPBench是一个用于评估大语言模型在属性级别长期个人行为理解能力的基准测试，专注于预测用户感兴趣的属性组合而非具体物品。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在个性化推荐方面显示出潜力，但准确捕捉用户偏好仍是关键挑战。现有基准主要关注物品推荐，缺乏对用户长期行为中属性级别偏好的系统性评估。

Method: 引入ALPBench基准，将用户历史行为表示为自然语言序列，预测用户感兴趣的属性组合而非具体物品。该基准使用长时期历史行为而非用户显式请求来建模偏好，支持对新引入物品进行真实评估。

Result: ALPBench能够对个性化推荐进行细粒度评估，其属性组合预测任务对当前大语言模型具有高度挑战性，需要模型捕捉多个属性间的复杂交互并在长期用户行为序列上进行推理。

Conclusion: ALPBench为评估大语言模型在个性化推荐中的长期行为理解能力提供了系统性的基准测试框架，特别关注属性级别的偏好建模，这对当前模型提出了新的挑战。

Abstract: Recent advances in large language models have highlighted their potential for personalized recommendation, where accurately capturing user preferences remains a key challenge. Leveraging their strong reasoning and generalization capabilities, LLMs offer new opportunities for modeling long-term user behavior. To systematically evaluate this, we introduce ALPBench, a Benchmark for Attribution-level Long-term Personal Behavior Understanding. Unlike item-focused benchmarks, ALPBench predicts user-interested attribute combinations, enabling ground-truth evaluation even for newly introduced items. It models preferences from long-term historical behaviors rather than users' explicitly expressed requests, better reflecting enduring interests. User histories are represented as natural language sequences, allowing interpretable, reasoning-based personalization. ALPBench enables fine-grained evaluation of personalization by focusing on the prediction of attribute combinations task that remains highly challenging for current LLMs due to the need to capture complex interactions among multiple attributes and reason over long-term user behavior sequences.

</details>


### [81] [PAMAS: Self-Adaptive Multi-Agent System with Perspective Aggregation for Misinformation Detection](https://arxiv.org/abs/2602.03158)
*Zongwei Wang,Min Gao,Junliang Yu,Tong Chen,Chenghua Lin*

Main category: cs.IR

TL;DR: PAMAS是一个基于多智能体系统的框架，通过视角聚合解决信息淹没问题，提升社交媒体虚假信息检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 社交媒体虚假信息检测面临挑战：虚假信息具有多样性和上下文依赖性，传统多智能体系统存在信息淹没问题，即大量真实内容淹没了稀疏而微弱的欺骗线索。

Method: 提出PAMAS框架，包含三层智能体结构：审计员从专门特征子集中捕捉异常线索；协调员聚合不同视角以增强覆盖同时保持多样性；决策者通过演化记忆和全上下文访问综合所有信息做出最终判断。还包含自适应拓扑优化和基于路由的推理机制。

Result: 在多个基准数据集上的广泛实验表明，PAMAS在准确性和效率方面都表现出色，为虚假信息检测提供了可扩展且可信赖的方法。

Conclusion: PAMAS通过视角聚合有效缓解了信息淹没问题，提高了多智能体系统在虚假信息检测中的性能，同时通过自适应机制提升了效率和可扩展性。

Abstract: Misinformation on social media poses a critical threat to information credibility, as its diverse and context-dependent nature complicates detection. Large language model-empowered multi-agent systems (MAS) present a promising paradigm that enables cooperative reasoning and collective intelligence to combat this threat. However, conventional MAS suffer from an information-drowning problem, where abundant truthful content overwhelms sparse and weak deceptive cues. With full input access, agents tend to focus on dominant patterns, and inter-agent communication further amplifies this bias. To tackle this issue, we propose PAMAS, a multi-agent framework with perspective aggregation, which employs hierarchical, perspective-aware aggregation to highlight anomaly cues and alleviate information drowning. PAMAS organizes agents into three roles: Auditors, Coordinators, and a Decision-Maker. Auditors capture anomaly cues from specialized feature subsets; Coordinators aggregate their perspectives to enhance coverage while maintaining diversity; and the Decision-Maker, equipped with evolving memory and full contextual access, synthesizes all subordinate insights to produce the final judgment. Furthermore, to improve efficiency in multi-agent collaboration, PAMAS incorporates self-adaptive mechanisms for dynamic topology optimization and routing-based inference, enhancing both efficiency and scalability. Extensive experiments on multiple benchmark datasets demonstrate that PAMAS achieves superior accuracy and efficiency, offering a scalable and trustworthy way for misinformation detection.

</details>


### [82] [Distribution-Aware End-to-End Embedding for Streaming Numerical Features in Click-Through Rate Prediction](https://arxiv.org/abs/2602.03223)
*Jiahao Liu,Hongji Ruan,Weimin Zhang,Ziye Tong,Derick Tang,Zhanpeng Zeng,Qinsong Zeng,Peng Zhang,Tun Lu,Ning Gu*

Main category: cs.IR

TL;DR: DAES是一个用于流式训练场景的数值特征嵌入框架，通过集成分布信息和自适应调制机制，显著提升了点击率预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统静态分箱方法依赖离线统计分布，但在流式环境中会导致语义漂移；神经嵌入方法虽支持端到端学习，但丢弃了显式的分布信息。流式特征常违反i.i.d.假设，且数值分布的上下文依赖性常被忽视。

Method: 提出DAES端到端框架，包含：1）基于水库采样的高效分布估计方法；2）两种场感知分布调制策略，以捕捉流式分布和场依赖语义。

Result: DAES在离线和在线实验中显著优于现有方法，已在拥有数亿日活用户的领先短视频平台全面部署。

Conclusion: DAES成功解决了流式训练中数值特征嵌入的挑战，通过集成分布信息和自适应调制，实现了更准确高效的点击率预测。

Abstract: This paper explores effective numerical feature embedding for Click-Through Rate prediction in streaming environments. Conventional static binning methods rely on offline statistics of numerical distributions; however, this inherently two-stage process often triggers semantic drift during bin boundary updates. While neural embedding methods enable end-to-end learning, they often discard explicit distributional information. Integrating such information end-to-end is challenging because streaming features often violate the i.i.d. assumption, precluding unbiased estimation of the population distribution via the expectation of order statistics. Furthermore, the critical context dependency of numerical distributions is often neglected. To this end, we propose DAES, an end-to-end framework designed to tackle numerical feature embedding in streaming training scenarios by integrating distributional information with an adaptive modulation mechanism. Specifically, we introduce an efficient reservoir-sampling-based distribution estimation method and two field-aware distribution modulation strategies to capture streaming distributions and field-dependent semantics. DAES significantly outperforms existing approaches as demonstrated by extensive offline and online experiments and has been fully deployed on a leading short-video platform with hundreds of millions of daily active users.

</details>


### [83] [To Search or Not to Search: Aligning the Decision Boundary of Deep Search Agents via Causal Intervention](https://arxiv.org/abs/2602.03304)
*Wenlin Zhang,Kuicai Dong,Junyi Li,Yingyi Zhang,Xiaopeng Li,Pengyue Jia,Yi Wen,Derong Xu,Maolin Wang,Yichao Wang,Yong Liu,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 提出DAS框架解决深度搜索代理的决策边界错位问题，通过因果干预诊断和偏好优化对齐决策边界，减少过度搜索和搜索不足，提升准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前深度搜索代理在复杂信息检索任务中存在效率低下问题，无法准确判断何时停止搜索并开始回答。这是由于结果中心的训练方法优先考虑最终结果而非搜索过程本身，导致决策边界错位，引发过度搜索（已有足够知识仍冗余搜索）和搜索不足（过早终止导致错误答案）。

Method: 提出包含两个关键组件的综合框架：1）基于因果干预的诊断方法，通过比较每个决策点的实际轨迹和反事实轨迹来识别边界错误；2）深度搜索代理决策边界对齐方法，从因果反馈构建偏好数据集，并通过偏好优化对齐策略。

Result: 实验表明决策边界错误在先进代理中普遍存在。DAS方法有效校准了这些边界，减少了过度搜索和搜索不足，在准确性和效率方面取得显著提升。

Conclusion: 决策边界错位是深度搜索代理效率低下的根本原因，提出的DAS框架通过因果干预诊断和偏好优化成功校准决策边界，为构建更高效、准确的深度搜索代理提供了有效解决方案。

Abstract: Deep search agents, which autonomously iterate through multi-turn web-based reasoning, represent a promising paradigm for complex information-seeking tasks. However, current agents suffer from critical inefficiency: they conduct excessive searches as they cannot accurately judge when to stop searching and start answering. This stems from outcome-centric training that prioritize final results over the search process itself. We identify the root cause as misaligned decision boundaries, the threshold determining when accumulated information suffices to answer. This causes over-search (redundant searching despite sufficient knowledge) and under-search (premature termination yielding incorrect answers). To address these errors, we propose a comprehensive framework comprising two key components. First, we introduce causal intervention-based diagnosis that identifies boundary errors by comparing factual and counterfactual trajectories at each decision point. Second, we develop Decision Boundary Alignment for Deep Search agents (DAS), which constructs preference datasets from causal feedback and aligns policies via preference optimization. Experiments on public datasets demonstrate that decision boundary errors are pervasive across state-of-the-art agents. Our DAS method effectively calibrates these boundaries, mitigating both over-search and under-search to achieve substantial gains in accuracy and efficiency. Our code and data are publicly available at: https://github.com/Applied-Machine-Learning-Lab/WWW2026_DAS.

</details>


### [84] [Learning to Select: Query-Aware Adaptive Dimension Selection for Dense Retrieval](https://arxiv.org/abs/2602.03306)
*Zhanyu Wu,Richong Zhang,Zhijie Nie*

Main category: cs.IR

TL;DR: 提出Query-Aware Adaptive Dimension Selection框架，通过监督学习直接预测每个维度的查询感知重要性，无需伪相关反馈，提高检索效果


<details>
  <summary>Details</summary>
Motivation: 现有密集检索方法存在冗余问题：查询层面只有部分维度对排序有帮助。基于伪相关反馈的方法依赖噪声信号和启发式程序，而监督适配器方法学习全局变换不显式建模查询感知维度重要性。

Method: 1. 使用监督相关标签构建oracle维度重要性分布；2. 训练预测器将查询嵌入映射到这些标签蒸馏的重要性分数；3. 推理时仅基于查询嵌入选择查询感知维度子集进行相似度计算

Result: 在多个密集检索器和基准测试中，学习的维度选择器优于全维度基线、基于PRF的掩码方法和监督适配器基线，提高了检索效果

Conclusion: 通过监督学习直接预测查询感知维度重要性是有效的，能够提高密集检索性能，无需依赖伪相关反馈的噪声信号和启发式程序

Abstract: Dense retrieval represents queries and docu-002 ments as high-dimensional embeddings, but003 these representations can be redundant at the004 query level: for a given information need, only005 a subset of dimensions is consistently help-006 ful for ranking. Prior work addresses this via007 pseudo-relevance feedback (PRF) based dimen-008 sion importance estimation, which can produce009 query-aware masks without labeled data but010 often relies on noisy pseudo signals and heuris-011 tic test-time procedures. In contrast, super-012 vised adapter methods leverage relevance labels013 to improve embedding quality, yet they learn014 global transformations shared across queries015 and do not explicitly model query-aware di-016 mension importance. We propose a Query-017 Aware Adaptive Dimension Selection frame-018 work that learns to predict per-dimension im-019 portance directly from query embedding. We020 first construct oracle dimension importance dis-021 tributions over embedding dimensions using022 supervised relevance labels, and then train a023 predictor to map a query embedding to these024 label-distilled importance scores. At inference,025 the predictor selects a query-aware subset of026 dimensions for similarity computation based027 solely on the query embedding, without pseudo-028 relevance feedback. Experiments across multi-029 ple dense retrievers and benchmarks show that030 our learned dimension selector improves re-031 trieval effectiveness over the full-dimensional032 baseline as well as PRF-based masking and033 supervised adapter baselines.

</details>


### [85] [SCASRec: A Self-Correcting and Auto-Stopping Model for Generative Route List Recommendation](https://arxiv.org/abs/2602.03324)
*Chao Chen,Longfei Xu,Daohan Su,Tengfei Liu,Hanyu Guo,Yihai Duan,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: SCASRec是一个统一生成式框架，将排序和冗余消除集成到端到端过程中，解决了多阶段推荐系统中的训练目标与在线指标不对齐、冗余消除规则僵化、阶段分离导致次优性能等问题。


<details>
  <summary>Details</summary>
Motivation: 当前路线推荐系统采用多阶段流水线（精排和重排）存在三个关键问题：1）离线训练目标与在线指标不对齐；2）冗余消除依赖僵化的手工规则，无法适应用户意图的高方差和现实场景的非结构化复杂性；3）精排和重排阶段的严格分离导致次优性能，各模块孤立优化，无法实现联合优化的全局最优。

Method: 提出SCASRec（自校正和自动停止推荐）统一生成式框架，引入逐步校正奖励（SCR）通过关注困难样本来指导列表级优化，并使用可学习的推荐结束（EOR）标记在预期无进一步改进时自适应终止生成。

Result: 在两个大规模开源路线推荐数据集上的实验表明，SCASRec在离线和在线设置中均达到最先进水平，并已在实际导航应用中完全部署，证明了其有效性。

Conclusion: SCASRec通过端到端统一框架成功解决了多阶段推荐系统的关键限制，实现了更好的对齐性、适应性和联合优化性能，在实际应用中表现出色。

Abstract: Route recommendation systems commonly adopt a multi-stage pipeline involving fine-ranking and re-ranking to produce high-quality ordered recommendations. However, this paradigm faces three critical limitations. First, there is a misalignment between offline training objectives and online metrics. Offline gains do not necessarily translate to online improvements. Actual performance must be validated through A/B testing, which may potentially compromise the user experience. Second, redundancy elimination relies on rigid, handcrafted rules that lack adaptability to the high variance in user intent and the unstructured complexity of real-world scenarios. Third, the strict separation between fine-ranking and re-ranking stages leads to sub-optimal performance. Since each module is optimized in isolation, the fine-ranking stage remains oblivious to the list-level objectives (e.g., diversity) targeted by the re-ranker, thereby preventing the system from achieving a jointly optimized global optimum. To overcome these intertwined challenges, we propose \textbf{SCASRec} (\textbf{S}elf-\textbf{C}orrecting and \textbf{A}uto-\textbf{S}topping \textbf{Rec}ommendation), a unified generative framework that integrates ranking and redundancy elimination into a single end-to-end process. SCASRec introduces a stepwise corrective reward (SCR) to guide list-wise refinement by focusing on hard samples, and employs a learnable End-of-Recommendation (EOR) token to terminate generation adaptively when no further improvement is expected. Experiments on two large-scale, open-sourced route recommendation datasets demonstrate that SCASRec establishes an SOTA in offline and online settings. SCASRec has been fully deployed in a real-world navigation app, demonstrating its effectiveness.

</details>


### [86] [Beyond Exposure: Optimizing Ranking Fairness with Non-linear Time-Income Functions](https://arxiv.org/abs/2602.03345)
*Xuancheng Li,Tao Yang,Yujia Zhou,Qingyao Ai,Yiqun Liu*

Main category: cs.IR

TL;DR: 论文提出了一种考虑时间等上下文因素对提供商收入影响的收入公平性概念，并设计了相应的度量指标和优化算法DIDRF。


<details>
  <summary>Details</summary>
Motivation: 现有曝光公平性概念仅基于位置决定曝光，忽略了时间等其他影响提供商收入的重要因素，导致无法真正保证提供商的实际收入公平。

Method: 1. 形式化定义收入公平性概念；2. 开发相应的度量指标；3. 提出基于泰勒展开梯度的动态收入导数感知排序公平性算法（DIDRF），基于当前时间步的边际收入增益同时优化排序效果和收入公平。

Result: 模拟实验显示，现有基于曝光公平性的排序算法无法优化收入公平性。DIDRF在离线和在线设置中，针对不同的时间-收入函数，始终优于最先进的方法。

Conclusion: 该研究扩展了排序公平性的概念，考虑了影响提供商收入的实际上下文因素，提出的DIDRF算法能有效同时优化排序相关性和收入公平性。

Abstract: Ranking is central to information distribution in web search and recommendation. Nowadays, in ranking optimization, the fairness to item providers is viewed as a crucial factor alongside ranking relevance for users. There are currently numerous concepts of fairness and one widely recognized fairness concept is Exposure Fairness. However, it relies primarily on exposure determined solely by position, overlooking other factors that significantly influence income, such as time. To address this limitation, we propose to study ranking fairness when the provider utility is influenced by other contextual factors and is neither equal to nor proportional to item exposure. We give a formal definition of Income Fairness and develop a corresponding measurement metric. Simulated experiments show that existing-exposure-fairness-based ranking algorithms fail to optimize the proposed income fairness. Therefore, we propose the Dynamic-Income-Derivative-aware Ranking Fairness algorithm, which, based on the marginal income gain at the present timestep, uses Taylor-expansion-based gradients to simultaneously optimize effectiveness and income fairness. In both offline and online settings with diverse time-income functions, DIDRF consistently outperforms state-of-the-art methods.

</details>


### [87] [AesRec: A Dataset for Aesthetics-Aligned Clothing Outfit Recommendation](https://arxiv.org/abs/2602.03416)
*Wenxin Ye,Lin Li,Ming Li,Yang Shen,Kanghong Wang,Jimmy Xiangji Huang*

Main category: cs.IR

TL;DR: 本文提出了AesRec基准数据集，包含系统化的服装美学量化标注，用于开发美学对齐的推荐系统，实验表明整合量化美学信息能同时满足用户个性化需求并提供美学指导。


<details>
  <summary>Details</summary>
Motivation: 现有服装推荐方法主要依赖用户-物品-搭配交互行为，忽略了服装美学的显式表示，这限制了系统提供美学指导的能力。

Method: 基于专业服装质量标准和时尚美学原则，定义了多维美学指标：单品层面评估6个维度，搭配层面评估8个维度。利用视觉语言模型进行大规模美学评分，并进行了严格的人机一致性验证。

Result: 在时尚数据集上验证了生成评分与人类评估的一致性，实验结果表明整合量化美学信息到服装推荐模型中能够同时满足用户个性化需求并提供美学指导。

Conclusion: AesRec数据集填补了服装推荐中美学表征的空白，为开发美学对齐的推荐系统提供了基准，证明了量化美学信息对提升推荐系统美学指导能力的价值。

Abstract: Clothing recommendation extends beyond merely generating personalized outfits; it serves as a crucial medium for aesthetic guidance. However, existing methods predominantly rely on user-item-outfit interaction behaviors while overlooking explicit representations of clothing aesthetics. To bridge this gap, we present the AesRec benchmark dataset featuring systematic quantitative aesthetic annotations, thereby enabling the development of aesthetics-aligned recommendation systems. Grounded in professional apparel quality standards and fashion aesthetic principles, we define a multidimensional set of indicators. At the item level, six dimensions are independently assessed: silhouette, chromaticity, materiality, craftsmanship, wearability, and item-level impression. Transitioning to the outfit level, the evaluation retains the first five core attributes while introducing stylistic synergy, visual harmony, and outfit-level impression as distinct metrics to capture the collective aesthetic impact. Given the increasing human-like proficiency of Vision-Language Models in multimodal understanding and interaction, we leverage them for large-scale aesthetic scoring. We conduct rigorous human-machine consistency validation on a fashion dataset, confirming the reliability of the generated ratings. Experimental results based on AesRec further demonstrate that integrating quantified aesthetic information into clothing recommendation models can provide aesthetic guidance for users while fulfilling their personalized requirements.

</details>


### [88] [RankSteer: Activation Steering for Pointwise LLM Ranking](https://arxiv.org/abs/2602.03422)
*Yumeng Wang,Catherine Chen,Suzan Verberne*

Main category: cs.IR

TL;DR: RankSteer是一个后激活转向框架，通过控制表示空间中的三个解耦方向来改进零样本点式LLM排序，无需修改模型权重或引入显式文档比较。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为零样本排序器性能很强，但对提示形式特别是角色扮演指令高度敏感。研究表明角色相关信号沿着与查询-文档表示基本分离的激活通道编码，因此可以在激活层面直接引导排序行为，而不是通过脆弱的提示工程。

Method: 提出RankSteer框架，通过表征空间中的三个解耦且可引导的方向来特征化排序行为：1)决策方向（将隐藏状态映射到相关性分数）；2)证据方向（捕获决策头未直接利用的相关性信号）；3)角色方向（在不注入相关性信息的情况下调节模型行为）。在推理时使用基于投影的干预来联合控制这些方向。

Result: 在TREC DL 20和多个BEIR基准测试上的实验表明，RankSteer仅使用少量锚点查询就能持续改进排序质量，证明点式LLM排序器中仍有大量排序能力未被充分利用。几何分析显示，转向通过稳定排序几何和减少离散度来改进排序。

Conclusion: RankSteer展示了通过激活转向直接引导LLM排序行为的可行性，为理解LLM内部如何表示和校准相关性判断提供了新见解，同时避免了脆弱的提示工程。

Abstract: Large language models (LLMs) have recently shown strong performance as zero-shot rankers, yet their effectiveness is highly sensitive to prompt formulation, particularly role-play instructions. Prior analyses suggest that role-related signals are encoded along activation channels that are largely separate from query-document representations, raising the possibility of steering ranking behavior directly at the activation level rather than through brittle prompt engineering. In this work, we propose RankSteer, a post-hoc activation steering framework for zero-shot pointwise LLM ranking. We characterize ranking behavior through three disentangled and steerable directions in representation space: a \textbf{decision direction} that maps hidden states to relevance scores, an \textbf{evidence direction} that captures relevance signals not directly exploited by the decision head, and a \textbf{role direction} that modulates model behavior without injecting relevance information. Using projection-based interventions at inference time, RankSteer jointly controls these directions to calibrate ranking behavior without modifying model weights or introducing explicit cross-document comparisons. Experiments on TREC DL 20 and multiple BEIR benchmarks show that RankSteer consistently improves ranking quality using only a small number of anchor queries, demonstrating that substantial ranking capacity remains under-utilized in pointwise LLM rankers. We further provide a geometric analysis revealing that steering improves ranking by stabilizing ranking geometry and reducing dispersion, offering new insight into how LLMs internally represent and calibrate relevance judgments.

</details>


### [89] [Failure is Feedback: History-Aware Backtracking for Agentic Traversal in Multimodal Graphs](https://arxiv.org/abs/2602.03432)
*Joohyung Yun,Doyup Lee,Wook-Shin Han*

Main category: cs.IR

TL;DR: FiF提出了一种历史感知回溯机制和经济理性智能体工作流，用于解决开放域多模态文档检索中图检索方法的局限性，在多个基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的检索方法存在两个主要问题：1）使用统一的相似度度量忽略了跳转特定语义；2）僵化的预定义计划阻碍了动态错误纠正。这要求检索器能够根据不断变化的上下文调整推理，并智能地从死胡同中恢复。

Method: FiF将子图检索建模为顺序决策过程，包含两个关键创新：1）历史感知回溯机制，利用失败遍历的上下文信息，而不仅仅是简单回退状态；2）经济理性智能体工作流，采用成本感知遍历方法动态平衡检索精度和推理成本，仅在先前失败证明有必要时才使用计算密集的LLM推理。

Result: 在MultimodalQA、MMCoQA和WebQA等基准测试上进行的大量实验表明，FiF实现了最先进的检索性能。

Conclusion: FiF通过将子图检索建模为顺序决策过程，并引入历史感知回溯机制和经济理性智能体工作流，有效解决了现有图检索方法的局限性，显著提升了开放域多模态文档检索的性能。

Abstract: Open-domain multimodal document retrieval aims to retrieve specific components (paragraphs, tables, or images) from large and interconnected document corpora. Existing graph-based retrieval approaches typically rely on a uniform similarity metric that overlooks hop-specific semantics, and their rigid pre-defined plans hinder dynamic error correction. These limitations suggest that a retriever should adapt its reasoning to the evolving context and recover intelligently from dead ends. To address these needs, we propose Failure is Feedback (FiF), which casts subgraph retrieval as a sequential decision process and introduces two key innovations. (i) We introduce a history-aware backtracking mechanism; unlike standard backtracking that simply reverts the state, our approach piggybacks on the context of failed traversals, leveraging insights from previous failures. (ii) We implement an economically-rational agentic workflow. Unlike conventional agents with static strategies, our orchestrator employs a cost-aware traversal method to dynamically manage the trade-off between retrieval accuracy and inference costs, escalating to intensive LLM-based reasoning only when the prior failure justifies the additional computational investment. Extensive experiments show that FiF achieves state-of-the-art retrieval on the benchmarks of MultimodalQA, MMCoQA and WebQA.

</details>


### [90] [Tutorial on Reasoning for IR & IR for Reasoning](https://arxiv.org/abs/2602.03640)
*Mohanna Hoveyda,Panagiotis Efstratiadis,Arjen de Vries,Maarten de Rijke*

Main category: cs.IR

TL;DR: 本教程为信息检索领域提供了一个统一的推理分析框架，帮助研究者理解跨学科的各种推理方法，并指导如何构建具有推理能力的检索系统。


<details>
  <summary>Details</summary>
Motivation: 当前信息检索主要关注语义相关性排序，但现实信息需求需要逻辑约束、多步推理和证据合成等推理能力。虽然AI各领域开发了多种推理方法，但这些研究分散在不同学科，IR研究者难以识别最相关的思路和机会。

Method: 首先在信息检索背景下明确定义推理概念，并从中推导出统一的分析框架。该框架沿着定义的核心维度映射现有方法，通过全面概述近期方法并将其映射到定义的维度上，揭示它们的权衡与互补性。

Result: 提出了一个帮助导航推理研究碎片化景观的分析框架，展示了IR如何从跨学科进展中受益，并说明检索过程本身如何在更广泛的推理系统中发挥核心作用。

Conclusion: 该教程为参与者提供了概念框架和实践指导，以增强具有推理能力的IR系统，同时将IR定位为一个既能受益又能贡献于更广泛推理方法发展的领域。

Abstract: Information retrieval has long focused on ranking documents by semantic relatedness. Yet many real-world information needs demand more: enforcement of logical constraints, multi-step inference, and synthesis of multiple pieces of evidence. Addressing these requirements is, at its core, a problem of reasoning. Across AI communities, researchers are developing diverse solutions for the problem of reasoning, from inference-time strategies and post-training of LLMs, to neuro-symbolic systems, Bayesian and probabilistic frameworks, geometric representations, and energy-based models. These efforts target the same problem: to move beyond pattern-matching systems toward structured, verifiable inference. However, they remain scattered across disciplines, making it difficult for IR researchers to identify the most relevant ideas and opportunities. To help navigate the fragmented landscape of research in reasoning, this tutorial first articulates a working definition of reasoning within the context of information retrieval and derives from it a unified analytical framework. The framework maps existing approaches along axes that reflect the core components of the definition. By providing a comprehensive overview of recent approaches and mapping current methods onto the defined axes, we expose their trade-offs and complementarities, highlight where IR can benefit from cross-disciplinary advances, and illustrate how retrieval process itself can play a central role in broader reasoning systems. The tutorial will equip participants with both a conceptual framework and practical guidance for enhancing reasoning-capable IR systems, while situating IR as a domain that both benefits and contributes to the broader development of reasoning methodologies.

</details>


### [91] [Bringing Reasoning to Generative Recommendation Through the Lens of Cascaded Ranking](https://arxiv.org/abs/2602.03692)
*Xinyu Lin,Pengyuan Liu,Wenjie Wang,Yicheng Hu,Chen Xu,Fuli Feng,Qifan Wang,Tat-Seng Chua*

Main category: cs.IR

TL;DR: CARE是一个用于生成式推荐系统的级联推理框架，通过渐进式历史编码和查询锚定推理机制解决推荐偏差放大问题，提升推荐准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐模型存在偏差放大问题，随着token生成的进行，token级偏差会逐渐放大，限制了推荐多样性并损害用户体验。与传统多阶段流水线相比，GR模型存在两个局限性：对编码历史的同质依赖，以及固定的计算预算限制了更深层次的用户偏好理解。

Method: 提出CARE框架：1）渐进式历史编码机制，在生成过程中逐步纳入更细粒度的历史信息；2）查询锚定推理机制，通过并行推理步骤对历史信息进行更深入的理解。在三个GR骨干网络上实例化CARE。

Result: 在四个数据集上的实证结果表明，CARE在推荐准确性、多样性、效率和可扩展性方面具有优越性。

Conclusion: CARE通过引入异构信息和分配更多计算资源，有效解决了生成式推荐中的偏差放大问题，为资源高效的推荐系统提供了一个简单而有效的解决方案。

Abstract: Generative Recommendation (GR) has become a promising end-to-end approach with high FLOPS utilization for resource-efficient recommendation. Despite the effectiveness, we show that current GR models suffer from a critical \textbf{bias amplification} issue, where token-level bias escalates as token generation progresses, ultimately limiting the recommendation diversity and hurting the user experience. By comparing against the key factor behind the success of traditional multi-stage pipelines, we reveal two limitations in GR that can amplify the bias: homogeneous reliance on the encoded history, and fixed computational budgets that prevent deeper user preference understanding.
  To combat the bias amplification issue, it is crucial for GR to 1) incorporate more heterogeneous information, and 2) allocate greater computational resources at each token generation step. To this end, we propose CARE, a simple yet effective cascaded reasoning framework for debiased GR. To incorporate heterogeneous information, we introduce a progressive history encoding mechanism, which progressively incorporates increasingly fine-grained history information as the generation process advances. To allocate more computations, we propose a query-anchored reasoning mechanism, which seeks to perform a deeper understanding of historical information through parallel reasoning steps. We instantiate CARE on three GR backbones. Empirical results on four datasets show the superiority of CARE in recommendation accuracy, diversity, efficiency, and promising scalability. The codes and datasets are available at https://github.com/Linxyhaha/CARE.

</details>


### [92] [Multimodal Generative Recommendation for Fusing Semantic and Collaborative Signals](https://arxiv.org/abs/2602.03713)
*Moritz Vandenhirtz,Kaveh Hassani,Shervin Ghasemlou,Shuai Shao,Hamid Eghbalzadeh,Fuchun Peng,Jun Liu,Michael Louis Iuzzolino*

Main category: cs.IR

TL;DR: MSCGRec是一种多模态语义与协同生成式推荐系统，通过融合多模态语义信息和协同特征，结合自监督量化学习和受限序列学习，在大型数据集上超越了传统序列推荐和生成式推荐方法。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐方法通过将物品建模为离散语义码序列来减少内存开销，但在大规模物品集上性能尚未超越传统序列推荐器，限制了其在实际应用场景中的采用。

Method: 1) 引入多模态语义信息；2) 基于DINO框架的图像自监督量化学习；3) 从序列推荐器中提取协同特征作为独立模态进行融合；4) 受限序列学习，在训练时限制输出空间到允许的token集合。

Result: 在三个大型真实世界数据集上的实验表明，MSCGRec超越了序列推荐和生成式推荐的基线方法，并通过消融研究验证了各个组件的有效性。

Conclusion: MSCGRec通过融合多模态语义和协同信号，结合创新的训练策略，成功解决了生成式推荐在大规模物品集上的性能瓶颈，为生成式推荐的实际应用提供了有效解决方案。

Abstract: Sequential recommender systems rank relevant items by modeling a user's interaction history and computing the inner product between the resulting user representation and stored item embeddings. To avoid the significant memory overhead of storing large item sets, the generative recommendation paradigm instead models each item as a series of discrete semantic codes. Here, the next item is predicted by an autoregressive model that generates the code sequence corresponding to the predicted item. However, despite promising ranking capabilities on small datasets, these methods have yet to surpass traditional sequential recommenders on large item sets, limiting their adoption in the very scenarios they were designed to address. To resolve this, we propose MSCGRec, a Multimodal Semantic and Collaborative Generative Recommender. MSCGRec incorporates multiple semantic modalities and introduces a novel self-supervised quantization learning approach for images based on the DINO framework. Additionally, MSCGRec fuses collaborative and semantic signals by extracting collaborative features from sequential recommenders and treating them as a separate modality. Finally, we propose constrained sequence learning that restricts the large output space during training to the set of permissible tokens. We empirically demonstrate on three large real-world datasets that MSCGRec outperforms both sequential and generative recommendation baselines and provide an extensive ablation study to validate the impact of each component.

</details>
