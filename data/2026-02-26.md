<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 58]
- [cs.IR](#cs.IR) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Disaster Question Answering with LoRA Efficiency and Accurate End Position](https://arxiv.org/abs/2602.21212)
*Takato Yasuno*

Main category: cs.CL

TL;DR: 基于日本灾害情境的问答系统，使用BERT日语版+Bi-LSTM+增强位置头架构，通过LoRA优化实现高效灾害响应问答。


<details>
  <summary>Details</summary>
Motivation: 自然灾害发生频率低且影响范围有限，人们在灾害中常因缺乏专业知识而困惑。现有RAG和LLM方法难以保证获取相关灾害知识和类似经验，且可能产生幻觉导致虚假信息传播，加剧灾害中的混乱。

Method: 使用cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads架构，结合LoRA效率优化，仅使用总参数的5.7%实现高效灾害问答。

Result: 在仅使用6.7M/117M参数（5.7%）的情况下，实现了70.4%的End Position准确率和0.885的Span F1分数，达到适合实际灾害响应场景的准确度水平。

Conclusion: 日语BERT优化与Bi-LSTM上下文理解的结合在灾害响应场景中表现良好。未来挑战包括：建立灾害QA基准数据集、灾害知识微调基础模型、开发轻量级边缘AI灾害QA应用、解决灾害知识库更新和持续学习能力问题。

Abstract: Natural disasters such as earthquakes, torrential rainfall, floods, and volcanic eruptions occur with extremely low frequency and affect limited geographic areas. When individuals face disaster situations, they often experience confusion and lack the domain-specific knowledge and experience necessary to determine appropriate responses and actions. While disaster information is continuously updated, even when utilizing RAG search and large language models for inquiries, obtaining relevant domain knowledge about natural disasters and experiences similar to one's specific situation is not guaranteed. When hallucinations are included in disaster question answering, artificial misinformation may spread and exacerbate confusion. This work introduces a disaster-focused question answering system based on Japanese disaster situations and response experiences. Utilizing the cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads architecture with LoRA efficiency optimization, we achieved 70.4\% End Position accuracy with only 5.7\% of the total parameters (6.7M/117M). Experimental results demonstrate that the combination of Japanese BERT-base optimization and Bi-LSTM contextual understanding achieves accuracy levels suitable for real disaster response scenarios, attaining a 0.885 Span F1 score. Future challenges include: establishing natural disaster Q\&A benchmark datasets, fine-tuning foundation models with disaster knowledge, developing lightweight and power-efficient edge AI Disaster Q\&A applications for situations with insufficient power and communication during disasters, and addressing disaster knowledge base updates and continual learning capabilities.

</details>


### [2] [Inference-time Alignment via Sparse Junction Steering](https://arxiv.org/abs/2602.21215)
*Runyi Hu,Jie Zhang,Shiqian Zhao,Jiale Meng,Jiwei Li,Jason Zeng,Ming Wu,Michael Heinrich,Yonggang Wen,Tianwei Zhang*

Main category: cs.CL

TL;DR: 提出了稀疏推理时对齐方法SIA，仅在生成轨迹的关键决策点进行干预，相比现有密集干预方法，在保持对齐效果的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有token级引导方法需要在每个解码步骤进行密集干预，这带来了显著的计算开销，并且可能因过度偏离模型固有分布而损害生成质量。作者认为密集干预是不必要的。

Method: 提出Sparse Inference-time Alignment (SIA)方法，通过识别生成轨迹中的高熵决策点（关键决策节点），仅在这些关键点引入对齐相关的奖励信号进行稀疏干预。

Result: 实验表明，仅干预20%到80%的token就能实现更好的对齐效率权衡。对于强基础模型如Qwen3，仅干预20%的token就能匹配甚至超过经过大量后训练的指令模型。稀疏性使得计算成本降低高达6倍，同时能更好地保持模型的固有分布，并与Best-of-N等搜索方法无缝集成。

Conclusion: 稀疏推理时对齐方法SIA证明了密集干预是不必要的，通过仅在关键决策点进行干预，能够在保持对齐效果的同时显著降低计算开销，更好地平衡对齐与效率的关系。

Abstract: Token-level steering has emerged as a pivotal approach for inference-time alignment, enabling fine grained control over large language models by modulating their output distributions without parameter updates. While effective, existing methods rely on dense intervention at every decoding step. This persistent manipulation not only incurs substantial computational overhead but also risks compromising generation quality by excessively drifting from the model's intrinsic distribution. In this work, we show that dense intervention is unnecessary and propose Sparse Inference time Alignment (SIA), which performs sparse junction steering by intervening only at critical decision points along the generation trajectory. Our key insight is that high entropy junctions mark pivotal decision points in the generation trajectory and are particularly susceptible to misalignment, indicating the need to introduce alignment related reward signals at these points. Extensive experiments across different model families and alignment objectives show that steering only 20% to 80% of tokens achieves superior alignment-efficiency trade offs. For strong base models such as Qwen3, intervening on as few as 20% of tokens matches or even surpasses heavily post-trained instruct models. This sparsity enables stronger guidance while better preserving the model's native distribution, integrates seamlessly with search based methods such as Best-of-N, and reduces computational cost by up to 6x.

</details>


### [3] [EQ-5D Classification Using Biomedical Entity-Enriched Pre-trained Language Models and Multiple Instance Learning](https://arxiv.org/abs/2602.21216)
*Zhyar Rzgar K Rostam,Gábor Kertész*

Main category: cs.CL

TL;DR: 使用实体增强的预训练语言模型进行EQ-5D检测，显著提升系统文献回顾中的自动化筛选准确率


<details>
  <summary>Details</summary>
Motivation: 在健康经济学中，手动筛选大量科学文献以识别使用EQ-5D工具的研究既耗时又容易出错且不一致，需要自动化解决方案来提高效率和准确性。

Method: 1. 微调通用（BERT）和领域特定（SciBERT, BioBERT）的预训练语言模型
2. 使用scispaCy模型提取生物医学实体信息来增强每个语句
3. 进行9种实验设置，结合3种scispaCy模型和3种PLMs
4. 在句子级别和研究级别评估性能
5. 探索多实例学习（MIL）方法，通过注意力池化将句子级信息聚合为研究级预测

Result: 1. F1分数达到0.82，在研究级别实现近乎完美的召回率
2. 显著超过传统的词袋基线方法和最近报道的PLM基线
3. 实体增强显著提升了领域适应性和模型泛化能力

Conclusion: 实体增强的预训练语言模型能够显著提高EQ-5D检测的准确性，为系统文献回顾中的自动化筛选提供了更有效的解决方案，有助于提高健康经济学研究的效率和质量。

Abstract: The EQ-5D (EuroQol 5-Dimensions) is a standardized instrument for the evaluation of health-related quality of life. In health economics, systematic literature reviews (SLRs) depend on the correct identification of publications that use the EQ-5D, but manual screening of large volumes of scientific literature is time-consuming, error-prone, and inconsistent. In this study, we investigate fine-tuning of general-purpose (BERT) and domain-specific (SciBERT, BioBERT) pre-trained language models (PLMs), enriched with biomedical entity information extracted through scispaCy models for each statement, to improve EQ-5D detection from abstracts. We conduct nine experimental setups, including combining three scispaCy models with three PLMs, and evaluate their performance at both the sentence and study levels. Furthermore, we explore a Multiple Instance Learning (MIL) approach with attention pooling to aggregate sentence-level information into study-level predictions, where each abstract is represented as a bag of enriched sentences (by scispaCy). The findings indicate consistent improvements in F1-scores (reaching 0.82) and nearly perfect recall at the study-level, significantly exceeding classical bag-of-words baselines and recently reported PLM baselines. These results show that entity enrichment significantly improves domain adaptation and model generalization, enabling more accurate automated screening in systematic reviews.

</details>


### [4] [Applied Sociolinguistic AI for Community Development (ASA-CD): A New Scientific Paradigm for Linguistically-Grounded Social Intervention](https://arxiv.org/abs/2602.21217)
*S M Ruhul Alam,Rifa Ferzana*

Main category: cs.CL

TL;DR: 提出了应用社会语言学AI用于社区发展（ASA-CD）的新科学范式，通过语言基础的AI干预解决社区挑战。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统在社区发展应用中缺乏统一的方法论、伦理和实证框架，需要一种能够解决社区挑战、促进集体成果的语言学基础方法。

Method: 引入三个核心贡献：语言生物标志物作为话语碎片化的计算指标；发展对齐的自然语言处理优化范式；标准化的五阶段话语干预协议。通过结合真实世界和合成语料库进行概念验证研究。

Result: 概念验证研究表明，排斥性语言与负面情绪存在系统性关联，并模拟了基于干预的改进效果。

Conclusion: ASA-CD为可扩展、价值对齐的AI服务于社区赋权提供了统一的方法论、伦理和实证框架。

Abstract: This paper establishes Applied Sociolinguistic AI for Community Development (ASA-CD) as a novel scientific paradigm for addressing community challenges through linguistically grounded, AI-enabled intervention. ASA-CD introduces three key contributions: (1) linguistic biomarkers as computational indicators of discursive fragmentation; (2) development-aligned natural language processing (NLP), an AI optimisation paradigm prioritising collective outcomes; and (3) a standardised five-phase protocol for discursive intervention. A proof-of-concept study, incorporating real-world and synthetic corpora, demonstrates systematic associations between exclusionary language and negative sentiment and simulates intervention-based improvements. ASA-CD provides a unified methodological, ethical and empirical framework for scalable, value-aligned AI in the service of community empowerment.

</details>


### [5] [EPSVec: Efficient and Private Synthetic Data Generation via Dataset Vectors](https://arxiv.org/abs/2602.21218)
*Amin Banayeeanzade,Qingchuan Yang,Deqing Fu,Spencer Hong,Erin Babinsky,Alfy Samuel,Anoop Kumar,Robin Jia,Sai Praneeth Karimireddy*

Main category: cs.CL

TL;DR: EPSVec 是一种高效的差分隐私文本生成方法，通过提取数据集向量来引导LLM生成，将隐私预算与生成过程解耦，支持无限生成且不增加隐私成本


<details>
  <summary>Details</summary>
Motivation: 现有隐私文本生成方法效率低下：数据密集、计算缓慢，需要大量私有语料或批量大小才能达到可用质量。高质量数据对机器学习至关重要，但许多有价值的数据集是敏感的，无法自由共享。

Method: 提出EPSVec方法：1）提取数据集向量（激活空间中捕捉私有数据与公共先验之间分布差异的方向）；2）对向量进行一次性差分隐私处理；3）使用处理后的向量引导LLM生成；4）引入固定样本提示以增强生成多样性和保真度。

Result: 实验表明，EPSVec在分布对齐和下游任务效用上优于现有基线方法，特别是在低数据场景下，同时显著减少了计算开销。该方法能够生成任意数量的合成样本而不增加隐私成本。

Conclusion: EPSVec提供了一种轻量级、高效的差分隐私文本生成解决方案，解决了现有方法在效率、数据需求和计算成本方面的限制，为敏感数据的安全共享和利用开辟了新途径。

Abstract: High-quality data is essential for modern machine learning, yet many valuable corpora are sensitive and cannot be freely shared. Synthetic data offers a practical substitute for downstream development, and large language models (LLMs) have emerged as powerful engines for generating it. However, existing private text generation methods are severely inefficient: they are data-intensive, computationally slow, and often require large private corpora or batch sizes to achieve usable quality. We introduce EPSVec, a differentially-private lightweight alternative that steers LLM generation using *dataset vectors*--directions in activation space that capture the distributional gap between private data and public priors. EPSVec extracts and sanitizes steering vectors just once and then performs standard decoding. This decouples the privacy budget from generation, enabling arbitrarily many synthetic samples without additional privacy cost and yielding strong fidelity even in low-data regimes. Furthermore, we enhance our method by utilizing pretrained (base) models and introducing fixed-shot prompting to boost generation diversity and fidelity. Our experiments demonstrate that EPSVec outperforms existing baselines in distributional alignment and downstream utility, particularly in low-data regimes, while significantly reducing computational overhead.

</details>


### [6] [Reasoning-Based Personalized Generation for Users with Sparse Data](https://arxiv.org/abs/2602.21219)
*Bo Ni,Branislav Kveton,Samyadeep Basu,Subhojyoti Mukherjee,Leyao Wang,Franck Dernoncourt,Sungchul Kim,Seunghyun Yoon,Zichao Wang,Ruiyi Zhang,Puneet Mathur,Jihyung Kil,Jiuxiang Gu,Nedim Lipka,Yu Wang,Ryan A. Rossi,Tyler Derr*

Main category: cs.CL

TL;DR: GraSPer通过图神经网络预测用户未来可能交互的项目，生成相关文本以丰富稀疏上下文，从而提升LLM个性化生成效果


<details>
  <summary>Details</summary>
Motivation: 现实世界中用户通常只有稀疏的交互历史（如冷启动用户、新注册客户），这限制了基于LLM的个性化生成效果

Method: GraSPer框架：1）通过图神经网络预测用户未来可能交互的项目来增强用户上下文；2）使用推理对齐为这些交互生成文本以丰富增强上下文；3）基于真实和合成历史生成个性化输出

Result: 在三个基准个性化生成数据集上的实验表明，GraSPer在稀疏用户上下文设置下显著提升了性能，大幅改善了个性化效果

Conclusion: GraSPer通过上下文增强和推理对齐，有效解决了稀疏用户上下文下的LLM个性化生成问题，为冷启动用户提供了有效的个性化解决方案

Abstract: Large Language Model (LLM) personalization holds great promise for tailoring responses by leveraging personal context and history. However, real-world users usually possess sparse interaction histories with limited personal context, such as cold-start users in social platforms and newly registered customers in online E-commerce platforms, compromising the LLM-based personalized generation. To address this challenge, we introduce GraSPer (Graph-based Sparse Personalized Reasoning), a novel framework for enhancing personalized text generation under sparse context. GraSPer first augments user context by predicting items that the user would likely interact with in the future. With reasoning alignment, it then generates texts for these interactions to enrich the augmented context. In the end, it generates personalized outputs conditioned on both the real and synthetic histories, ensuring alignment with user style and preferences. Extensive experiments on three benchmark personalized generation datasets show that GraSPer achieves significant performance gain, substantially improving personalization in sparse user context settings.

</details>


### [7] [Field-Theoretic Memory for AI Agents: Continuous Dynamics for Context Preservation](https://arxiv.org/abs/2602.21220)
*Subhadip Mitra*

Main category: cs.CL

TL;DR: 提出基于场论的内存系统，将记忆视为连续场而非离散条目，通过扩散、衰减和场耦合实现长期记忆管理


<details>
  <summary>Details</summary>
Motivation: 传统AI代理的记忆系统通常将信息存储为数据库中的离散条目，这种离散化方法在处理长期、多轮对话和多会话推理任务时存在局限性，需要一种更连续、动态的记忆表示方法

Method: 借鉴经典场论思想，将记忆视为语义空间中的连续场，通过偏微分方程控制记忆行为：记忆在语义空间中扩散、基于重要性进行热力学衰减、在多智能体场景中通过场耦合实现交互

Result: 在LongMemEval基准测试中，场论方法在多会话推理上F1提升116%（p<0.01，d=3.06），时序推理提升43.8%（p<0.001，d=9.21），知识更新检索召回率提升27.8%（p<0.001，d=5.00）。多智能体实验通过场耦合实现接近完美的集体智能（>99.8%）

Conclusion: 基于场论的连续记忆表示方法显著优于传统离散记忆系统，为AI代理的长期记忆管理提供了新的理论框架和实用解决方案，特别是在多会话推理和多智能体协作场景中表现出色

Abstract: We present a memory system for AI agents that treats stored information as continuous fields governed by partial differential equations rather than discrete entries in a database. The approach draws from classical field theory: memories diffuse through semantic space, decay thermodynamically based on importance, and interact through field coupling in multi-agent scenarios. We evaluate the system on two established long-context benchmarks: LoCoMo (ACL 2024) with 300-turn conversations across 35 sessions, and LongMemEval (ICLR 2025) testing multi-session reasoning over 500+ turns. On LongMemEval, the field-theoretic approach achieves significant improvements: +116% F1 on multi-session reasoning (p<0.01, d= 3.06), +43.8% on temporal reasoning (p<0.001, d= 9.21), and +27.8% retrieval recall on knowledge updates (p<0.001, d= 5.00). Multi-agent experiments show near-perfect collective intelligence (>99.8%) through field coupling. Code is available at github.com/rotalabs/rotalabs-fieldmem.

</details>


### [8] [Task-Aware LoRA Adapter Composition via Similarity Retrieval in Vector Databases](https://arxiv.org/abs/2602.21222)
*Riya Adsul,Balachandra Devarangadi Sunil,Isha Nalawade,Sudharshan Govindan*

Main category: cs.CL

TL;DR: 基于向量数据库检索的动态LoRA适配器组合框架，通过检索相似训练示例实现零样本多任务泛化


<details>
  <summary>Details</summary>
Motivation: LoRA等参数高效微调方法虽然能实现任务特定适配，但如何高效组合多个专用适配器以处理未见任务仍具挑战性

Method: 构建任务感知向量数据库，嵌入22个数据集的训练示例；推理时检索最相似训练示例，通过nucleus采样计算任务相似性分布，使用检索加权融合策略动态合并相关LoRA适配器

Result: 评估了四种合并方法（线性、连接、TIES、幅度剪枝），数据集中心检索方法常匹配或超越单任务微调适配器性能。线性合并在PIQA上达到70.95%，在RTE上达到77.62%，显著优于单任务基线（分别为46%和52%）

Conclusion: 基于检索的动态合并为无需全模型重训练的可扩展、参数高效多任务学习提供了有前景的方向，无需额外检索器训练，使用冻结嵌入，实现高效可解释的适配器组合

Abstract: Parameter efficient fine tuning methods like LoRA have enabled task specific adaptation of large language models, but efficiently composing multiple specialized adapters for unseen tasks remains challenging. We present a novel framework for dynamic LoRA adapter composition that leverages similarity retrieval in vector databases to enable zero-shot generalization across diverse NLP tasks. Our approach constructs a task-aware vector database by embedding training examples from 22 datasets spanning commonsense reasoning, question answering, natural language inference, and sentiment analysis. At inference time, we retrieve the most similar training examples, compute task similarity distributions via nucleus sampling, and dynamically merge relevant LoRA adapters using retrieval weighted fusion strategies. We evaluated four merging methods Linear, Concatenation, TIES, and Magnitude Prune demonstrating that our dataset centric retrieval approach often matches or exceeds the performance of individually fine-tuned task-specific adapters. Notably, Linear merging achieves 70.95% on PIQA and 77.62% on RTE, substantially outperforming single-task baselines (46% and 52%, respectively). Our framework requires no additional retriever training, operates with frozen embeddings, and enables efficient, interpretable adapter composition. These results suggest that retrieval based dynamic merging offers a promising direction for scalable, parameter-efficient multitask learning without requiring full model retraining for each new task.

</details>


### [9] [Measuring Pragmatic Influence in Large Language Model Instructions](https://arxiv.org/abs/2602.21223)
*Yilin Geng,Omri Abend,Eduard Hovy,Lea Frermann*

Main category: cs.CL

TL;DR: 该研究提出一个框架来系统测量LLM中的"语用框架"效应，即通过改变提示的上下文表达方式（如"这很紧急"或"作为你的上司"）来影响模型行为，而不改变任务内容本身。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然利用语用框架进行提示优化或将其视为安全漏洞进行探测，但语用框架本身尚未被视为指令跟随系统的可测量属性。系统测量这种影响具有挑战性，需要控制性地隔离框架线索。

Method: 提出了包含三个新颖组件的框架：指令-框架分解（将框架上下文与任务规范分离）；包含13种策略和4个机制集群的400个框架实例分类法；基于优先级的测量方法，通过观察指令优先级的变化来量化影响。

Result: 在五个不同家族和规模的LLM中，影响机制导致指令优先级的一致性和结构化变化，使模型从基准的中立性转向偏向被框架化的指令。

Conclusion: 这项工作将语用框架确立为指令跟随系统中可测量和可预测的因素，为理解和控制LLM对提示语境的敏感性提供了系统方法。

Abstract: It is not only what we ask large language models (LLMs) to do that matters, but also how we prompt. Phrases like "This is urgent" or "As your supervisor" can shift model behavior without altering task content. We study this effect as pragmatic framing, contextual cues that shape directive interpretation rather than task specification. While prior work exploits such cues for prompt optimization or probes them as security vulnerabilities, pragmatic framing itself has not been treated as a measurable property of instruction following. Measuring this influence systematically remains challenging, requiring controlled isolation of framing cues. We introduce a framework with three novel components: directive-framing decomposition separating framing context from task specification; a taxonomy organizing 400 instantiations of framing into 13 strategies across 4 mechanism clusters; and priority-based measurement that quantifies influence through observable shifts in directive prioritization. Across five LLMs of different families and sizes, influence mechanisms cause consistent and structured shifts in directive prioritization, moving models from baseline impartiality toward favoring the framed directive. This work establishes pragmatic framing as a measurable and predictable factor in instruction-following systems.

</details>


### [10] [Make Every Draft Count: Hidden State based Speculative Decoding](https://arxiv.org/abs/2602.21224)
*Yuetao Chen,Xuliang Wang,Xinzhou Zheng,Ming Li,Peng Wang,Hong Xu*

Main category: cs.CL

TL;DR: 提出一种新型推测解码系统，通过重用被丢弃的草稿隐藏状态来回收计算浪费，实现比标准推测解码最高3.3倍的加速。


<details>
  <summary>Details</summary>
Motivation: 标准推测解码中，大多数草稿token验证失败被丢弃，造成计算浪费。需要回收这些浪费的计算资源。

Method: 1) 基于自回归隐藏状态的草稿模型架构，保留比基于token的草稿更丰富的语义；2) 高效的token信息注入机制，构建高质量草稿token树并支持从验证失败中重采样token；3) 消除设计中的隐藏开销以最大化硬件利用率。

Result: 在广泛评估中，相比标准推测解码实现了最高3.3倍的加速。

Conclusion: 通过重用被丢弃草稿的隐藏状态来回收计算浪费，显著提高了推测解码的计算效率，为LLM推理加速提供了新方向。

Abstract: Speculative decoding has emerged as a pivotal technique to accelerate LLM inference by employing a lightweight draft model to generate candidate tokens that are subsequently verified by the target model in parallel. However, while this paradigm successfully increases the arithmetic intensity of memory-bound inference, it causes significant compute inefficiency: the majority of draft tokens fail verification and are discarded, resulting in waste of computation. Motivated by the goal of recollecting this wasted computation, we propose a novel system that transforms discarded drafts into reusable tokens. Our key insight is to perform auto-regressive prediction at the hidden states level and postpone the integrating token information after the hidden states generation, so the draft hidden states are not contaminated by incorrect tokens, enabling hidden state reuse. To implement such a system, first we introduce a draft model architecture based on auto-regressive hidden states, which preserves richer semantics than token-based drafters to facilitate draft repurposing. Second, we design an efficient token information injection mechanism that leverages our specialized draft model to construct high-quality draft token trees and enables resampling tokens from verification failures. Third, we eliminate the overhead hidden in our design to further maximize hardware utilization. We conducted extensive evaluations against various baselines, demonstrating up to a 3.3x speedup against standard speculative decoding.

</details>


### [11] [Architecture-Agnostic Curriculum Learning for Document Understanding: Empirical Evidence from Text-Only and Multimodal](https://arxiv.org/abs/2602.21225)
*Mohammed Hamdan,Vincenzo Dentamaro,Giuseppe Pirlo,Mohamed Cheriet*

Main category: cs.CL

TL;DR: 渐进式数据调度（逐步增加训练数据量）可减少约33%训练时间，但对模型性能的提升效果取决于模型容量与任务复杂度的交互。


<details>
  <summary>Details</summary>
Motivation: 研究渐进式数据调度（一种课程学习策略）是否能在不同架构的文档理解模型中提供一致的效率提升，并探究其效果是否真正源于课程安排而非单纯计算量减少。

Method: 在BERT（纯文本，1.1亿参数）和LayoutLMv3（多模态，1.26亿参数）上评估渐进式数据调度（33%→67%→100%数据量）。使用FUNSD和CORD基准测试，引入匹配计算基线（Standard-7）以控制总梯度更新，并进行调度消融实验（渐进式、两阶段、反向、随机调度）。

Result: 渐进式调度减少约33%训练时间（从10.0个有效epoch-equivalents减少到6.67个）。在FUNSD数据集上，BERT显著优于匹配计算基线（ΔF1=+0.023，p=0.022），而LayoutLMv3无类似优势（p=0.621）。在CORD数据集上，所有条件都达到相同性能（F1≥0.947）。消融实验表明效率增益源于数据量减少而非顺序安排。

Conclusion: 渐进式调度是跨模型家族可靠的计算减少策略，其课程特定效益取决于模型容量与任务复杂度的交互作用。容量受限模型能从课程学习中获益，而具有足够归纳偏置的多模态模型则无额外优势。

Abstract: We investigate whether progressive data scheduling -- a curriculum learning strategy that incrementally increases training data exposure (33\%$\rightarrow$67\%$\rightarrow$100\%) -- yields consistent efficiency gains across architecturally distinct document understanding models. By evaluating BERT (text-only, 110M parameters) and LayoutLMv3 (multimodal, 126M parameters) on the FUNSD and CORD benchmarks, we establish that this schedule reduces wall-clock training time by approximately 33\%, commensurate with the reduction from 6.67 to 10.0 effective epoch-equivalents of data. To isolate curriculum effects from compute reduction, we introduce matched-compute baselines (Standard-7) that control for total gradient updates. On the FUNSD dataset, the curriculum significantly outperforms the matched-compute baseline for BERT ($Δ$F1 = +0.023, $p=0.022$, $d_z=3.83$), constituting evidence for a genuine scheduling benefit in capacity-constrained models. In contrast, no analogous benefit is observed for LayoutLMv3 ($p=0.621$), whose multimodal representations provide sufficient inductive bias. On the CORD dataset, all conditions converge to equivalent F1 scores ($\geq$0.947) irrespective of scheduling, indicating a performance ceiling. Schedule ablations comparing progressive, two-phase, reverse, and random pacing confirm that the efficiency gain derives from reduced data volume rather than ordering. Taken together, these findings demonstrate that progressive scheduling is a reliable compute-reduction strategy across model families, with curriculum-specific benefits contingent on the interaction between model capacity and task complexity.

</details>


### [12] [Enhancing Multilingual Embeddings via Multi-Way Parallel Text Alignment](https://arxiv.org/abs/2602.21543)
*Barah Fazili,Koustava Goswami*

Main category: cs.CL

TL;DR: 通过多语言平行语料库进行对比学习训练，显著提升了多语言模型的跨语言对齐能力，在多个NLU任务上取得明显性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的多语言预训练缺乏显式的对齐信号，导致表示空间的跨语言对齐效果不理想。需要改进多语言和跨语言表示的质量。

Method: 使用现成的NMT模型构建六种目标语言的多向平行数据集，通过对比学习训练标准预训练模型（XLM-Roberta和mBERT）以增强跨语言对齐。

Result: 相比英语中心的双语平行数据，多向平行语料库在bitext mining（+21.3%）、语义相似性（+5.3%）和分类（+28.4%）任务上带来显著提升。对mE5模型进行微调也显著改善了bitext mining性能。

Conclusion: 使用多向平行语料库进行对比学习训练能有效提升多语言模型的跨语言对齐能力，即使对于已经预训练的高质量句子嵌入模型，多向跨语言监督仍然至关重要。

Abstract: Multilingual pretraining typically lacks explicit alignment signals, leading to suboptimal cross-lingual alignment in the representation space. In this work, we show that training standard pretrained models for cross-lingual alignment with a multi-way parallel corpus in a diverse pool of languages can substantially improve multilingual and cross-lingual representations for NLU tasks. We construct a multi-way parallel dataset using translations of English text from an off-the-shelf NMT model for a pool of six target languages and achieve strong cross-lingual alignment through contrastive learning. This leads to substantial performance gains across both seen and unseen languages for multiple tasks from the MTEB benchmark evaluated for XLM-Roberta and multilingual BERT base models. Using a multi-way parallel corpus for contrastive training yields substantial gains on bitext mining (21.3%), semantic similarity (5.3%), and classification (28.4%) compared to English-centric (En-X) bilingually parallel data, where X is sampled from a pool of multiple target languages. Furthermore, finetuning mE5 model on a small dataset with multi-way parallelism significantly improves bitext mining compared to one without, underscoring the importance of multi-way cross-lingual supervision even for models already pretrained for high-quality sentence embeddings.

</details>


### [13] [IslamicLegalBench: Evaluating LLMs Knowledge and Reasoning of Islamic Law Across 1,200 Years of Islamic Pluralist Legal Traditions](https://arxiv.org/abs/2602.21226)
*Ezieddin Elmahjub,Junaid Qadir,Abdullah Mushtaq,Rafay Naeem,Ibrahim Ghaznavi,Waleed Iqbal*

Main category: cs.CL

TL;DR: 首个评估LLM在伊斯兰法学推理能力的基准IslamicLegalBench显示：当前AI模型在伊斯兰法律推理方面存在严重缺陷，最佳模型正确率仅68%，幻觉率21%，无法可靠提供宗教指导。


<details>
  <summary>Details</summary>
Motivation: 随着数百万穆斯林使用LLM寻求宗教指导，需要评估这些AI系统能否可靠地进行伊斯兰法律推理，确保提供准确的法律指导。

Method: 开发IslamicLegalBench基准，涵盖伊斯兰法学七大流派，包含718个实例和13个不同复杂度的任务，评估9个最先进的LLM模型，分析其正确率、幻觉率、少样本提示效果和错误前提检测能力。

Result: 评估结果显示：最佳模型正确率仅68%，幻觉率21%；多个模型正确率低于35%，幻觉率超过55%；少样本提示效果有限；中等复杂度任务错误率最高；6/9模型接受误导性假设率超过40%。

Conclusion: 基于提示的方法无法弥补基础知识的缺失，当前LLM在伊斯兰法律推理方面存在严重缺陷，IslamicLegalBench为评估AI伊斯兰法律推理提供了首个系统框架。

Abstract: As millions of Muslims turn to LLMs like GPT, Claude, and DeepSeek for religious guidance, a critical question arises: Can these AI systems reliably reason about Islamic law? We introduce IslamicLegalBench, the first benchmark evaluating LLMs across seven schools of Islamic jurisprudence, with 718 instances covering 13 tasks of varying complexity. Evaluation of nine state-of-the-art models reveals major limitations: the best model achieves only 68% correctness with 21% hallucination, while several models fall below 35% correctness and exceed 55% hallucination. Few-shot prompting provides minimal gains, improving only 2 of 9 models by >1%. Moderate-complexity tasks requiring exact knowledge show the highest errors, whereas high-complexity tasks display apparent competence through semantic reasoning. False premise detection indicates risky sycophancy, with 6 of 9 models accepting misleading assumptions at rates above 40%. These results highlight that prompt-based methods cannot compensate for missing foundational knowledge. IslamicLegalBench offers the first systematic framework to evaluate Islamic legal reasoning in AI, revealing critical gaps in tools increasingly relied on for spiritual guidance.

</details>


### [14] [LiCQA : A Lightweight Complex Question Answering System](https://arxiv.org/abs/2602.22182)
*Sourav Saha,Dwaipayan Roy,Mandar Mitra*

Main category: cs.CL

TL;DR: LiCQA：一种基于语料证据的无监督问答模型，在复杂问题上显著优于现有方法且延迟更低


<details>
  <summary>Details</summary>
Motivation: 当前问答系统在处理需要跨多个文档的复杂问题时面临挑战，现有方法要么依赖知识图谱，要么需要大量计算资源和训练数据的神经网络模型

Method: 提出LiCQA，一种主要基于语料证据的无监督问答模型，不依赖知识图谱或昂贵的神经网络训练

Result: 在基准数据上，LiCQA显著优于两种基于不同原理的最新问答系统，并且延迟显著降低

Conclusion: 基于语料证据的无监督方法在复杂问答任务上具有显著优势，既能提高性能又能降低计算成本

Abstract: Over the last twenty years, significant progress has been made in designing and implementing Question Answering (QA) systems. However, addressing complex questions, the answers to which are spread across multiple documents, remains a challenging problem. Recent QA systems that are designed to handle complex questions work either on the basis of knowledge graphs, or utilise contem- porary neural models that are expensive to train, in terms of both computational resources and the volume of training data required. In this paper, we present LiCQA, an unsupervised question answer- ing model that works primarily on the basis of corpus evidence. We empirically compare the effectiveness and efficiency of LiCQA with two recently presented QA systems, which are based on different underlying principles. The results of our experiments show that LiCQA significantly outperforms these two state-of-the-art systems on benchmark data with noteworthy reduction in latency.

</details>


### [15] [Budget-Aware Agentic Routing via Boundary-Guided Training](https://arxiv.org/abs/2602.21227)
*Caiqi Zhang,Menglin Xia,Xuchao Zhang,Daniel Madrigal,Ankur Mallick,Samuel Kessler,Victor Ruehle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 提出预算感知的智能体路由方法，通过在每个步骤选择廉价或昂贵模型来优化成本-成功率边界，并满足严格的任务预算限制。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型发展为执行长流程的自主智能体，每一步都调用高能力模型在经济上不可持续。现有模型路由方法适用于单轮查询，但智能体路由是顺序、路径依赖问题：早期错误会累积，反馈通常只在任务结束时获得，且部署通常要求严格的任务预算限制。

Method: 提出边界引导训练：利用两个边界策略（始终用小型模型 vs. 始终用大型模型）构建难度分类法，在稀疏奖励下锚定学习。通过分层采样成本高效轨迹合成边界引导的SFT数据，然后应用边界引导策略优化，结合边界相对奖励和参考引导优势，避免退化的廉价失败解决方案。

Result: 实验结果表明，该方法改进了效率边界，以显著更低的成本匹配强路由基线，同时展示了在严格推理时预算约束下的泛化能力。

Conclusion: 该工作为智能体路由建立了基础框架，将范式从静态模型选择转向动态、预算感知的顺序决策。

Abstract: As large language models (LLMs) evolve into autonomous agents that execute long-horizon workflows, invoking a high-capability model at every step becomes economically unsustainable. While model routing is effective for single-turn queries, agentic routing is a sequential, path-dependent problem: early mistakes compound, feedback is often at the end of the episode, and deployments often demand strict per-task spending limits. We propose Budget-Aware Agentic Routing, which selects between a cheap and an expensive model at each step to optimize the cost--success frontier and to operate under strict per-task budgets. We propose Boundary-Guided Training, which leverages two boundary policies (always-small vs.\ always-large) to build a difficulty taxonomy and to anchor learning under sparse rewards. Our approach warms start with boundary-guided SFT data synthesis via stratified sampling of cost-efficient trajectories, then applies Boundary-Guided Policy Optimization (BoPO), combining boundary-relative rewards with a reference-guided advantage to avoid degenerate cheap-failure solutions. Experiment results show that our method improves the efficiency frontier, matching strong routing baselines at substantially lower cost while demonstrating generalization to strict inference-time budget constraints. Overall, our work establishes a foundational framework for agentic routing, shifting the paradigm from static model selection to dynamic, budget-aware sequential decision-making.

</details>


### [16] [ImpRIF: Stronger Implicit Reasoning Leads to Better Complex Instruction Following](https://arxiv.org/abs/2602.21228)
*Yuancheng Yang,Lin Yang,Xu Wang,Chao Tong,Haihua Yang*

Main category: cs.CL

TL;DR: 提出ImpRIF方法，通过将复杂指令形式化为可验证推理图，增强大语言模型对隐式推理的理解，从而提升复杂指令跟随能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用日益复杂，对鲁棒复杂指令跟随能力的需求增长。作者认为深入理解指令本身，特别是隐藏在字里行间的潜在推理结构，对提升指令跟随能力至关重要。因此针对涉及隐式推理、复杂逻辑关系和多重约束依赖的复杂指令进行研究。

Method: 提出ImpRIF方法，将复杂指令形式化为可验证推理图，支持程序化验证和图驱动的思维链推理。基于此形式化方法，合成大规模单轮和多轮数据，提出图推理微调，并应用强化学习显式训练模型沿图推理。

Result: 在五个复杂指令跟随基准测试中，模型显著优于其基础模型。结果表明增强隐式推理能力可以显著改善复杂指令跟随。

Conclusion: 通过将复杂指令形式化为推理图并训练模型沿图推理，可以有效提升大语言模型对复杂指令的理解和跟随能力。该方法将开源。

Abstract: As applications of large language models (LLMs) become increasingly complex, the demand for robust complex instruction following capabilities is growing accordingly. We argue that a thorough understanding of the instruction itself, especially the latent reasoning structure embedded between the lines, is crucial for improving instruction following. Therefore we target complex instructions that involve implicit reasoning, intricate logical relations, and multi-constraint dependencies. We propose ImpRIF, a method to enhance LLMs' understanding of implicit reasoning instructions, thereby improving its ability to follow complex instructions. We formalize such instructions as verifiable reasoning graphs, enabling programmatic verification and graph-driven chain-of-thought reasoning. Based on this formulation, we synthesize large-scale single- and multi-turn data, propose fine-tuning with graph reasoning, and apply reinforcement learning to explicitly train models to reason along the graph. On five complex instruction following benchmarks, our models substantially outperform their base models. These results demonstrate that enhancing implicit reasoning capabilities can significantly improve complex instruction following. This project will be open-sourced in the near future.

</details>


### [17] [TRACE: Trajectory-Aware Comprehensive Evaluation for Deep Research Agents](https://arxiv.org/abs/2602.21230)
*Yanyu Chen,Jiyue Jiang,Jiahong Liu,Yifei Zhang,Xiao Guo,Irwin King*

Main category: cs.CL

TL;DR: TRACE 框架通过轨迹感知的全面评估方法，解决了深度研究智能体评估中存在的"高分幻觉"和静态基准无法量化鲁棒性等深层属性的问题，提供了更细粒度的智能体性能分析。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究智能体评估面临两大挑战：1）依赖单一指标（如Pass@1）导致"高分幻觉"，忽略了推理过程的质量、效率和健全性；2）静态基准无法量化关键属性如鲁棒性和潜在能力。

Method: 提出TRACE框架，包括：1）分层轨迹效用函数，量化过程效率和认知质量（包括证据基础）；2）支架式能力评估协议，通过确定成功所需的最小指导来量化智能体的潜在能力；3）配套的DeepResearch-Bench基准，具有可控复杂度。

Result: 实验表明，TRACE能够提供细粒度的排名，揭示智能体在准确性、效率和鲁棒性之间的关键权衡，而这些权衡被单一指标完全忽略。

Conclusion: TRACE框架通过轨迹感知的全面评估方法，有效解决了当前深度研究智能体评估的局限性，为智能体性能提供了更全面、更深入的评估视角。

Abstract: The evaluation of Deep Research Agents is a critical challenge, as conventional outcome-based metrics fail to capture the nuances of their complex reasoning. Current evaluation faces two primary challenges: 1) a reliance on singular metrics like Pass@1, creating a "high-score illusion" that ignores the quality, efficiency, and soundness of the reasoning process; and 2) the failure of static benchmarks to quantify crucial attributes like robustness and latent capability. To address these gaps, we introduce TRACE (Trajectory-Aware Comprehensive Evaluation), a framework that holistically assesses the entire problem-solving trajectory. To counter the "high-score illusion", we propose a Hierarchical Trajectory Utility Function that quantifies process efficiency and cognitive quality, including evidence grounding, alongside accuracy. To measure deeper attributes, TRACE introduces a Scaffolded Capability Assessment protocol, quantifying an agent's latent ability by determining the minimum guidance needed for success. Our contributions include the TRACE framework, its novel metrics, and the accompanying DeepResearch-Bench with controllable complexity. Experiments show TRACE delivers a granular ranking that uncovers critical trade-offs between agent accuracy, efficiency, and robustness entirely missed by singular metrics.

</details>


### [18] [Structured Prompt Language: Declarative Context Management for LLMs](https://arxiv.org/abs/2602.21257)
*Wen G. Gong*

Main category: cs.CL

TL;DR: SPL是一种声明式的SQL风格语言，将LLM视为生成式知识库，提供显式的token预算管理、查询优化器、RAG集成和弹性代理管道，大幅减少提示模板代码并实现成本透明。


<details>
  <summary>Details</summary>
Motivation: 当前LLM应用开发面临几个关键挑战：1) 提示工程代码冗余且难以维护；2) token成本管理不透明；3) 不同模型和供应商的切换成本高；4) 处理超出上下文窗口的文档效率低下；5) 缺乏类似SQL的声明式框架来统一管理LLM资源。

Method: SPL采用声明式SQL风格语法，核心包括：1) WITH BUDGET/LIMIT显式token管理；2) 自动查询优化器；3) EXPLAIN透明度机制；4) 原生RAG和持久内存集成。SPL-flow扩展为三层弹性供应商回退策略（Ollama→OpenRouter→自愈重试）。五个扩展：Text2SPL、MoM路由、逻辑分块、SPL-flow代理编排、BENCHMARK多模型比较。

Result: SPL平均减少65%的提示模板代码，在模型层级间揭示68倍的成本差异作为预执行信号。相同的.spl脚本可以在OpenRouter上以$0.002运行，或在本地Ollama实例上以零边际成本运行。逻辑分块将注意力成本从O(N²)降低到O(N²/k)。

Conclusion: SPL为LLM应用开发提供了一个统一、声明式的框架，显著降低了开发复杂性和成本，同时提高了透明度和可移植性。该框架将LLM视为受约束的生成式数据库，为大规模、成本敏感的LLM应用提供了实用解决方案。

Abstract: We present SPL (Structured Prompt Language), a declarative SQL-inspired language that treats large language models as generative knowledge bases and their context windows as constrained resources. SPL provides explicit WITH BUDGET/LIMIT token management, an automatic query optimizer, EXPLAIN transparency analogous to SQL's EXPLAIN ANALYZE, and native integration of retrieval-augmented generation (RAG) and persistent memory in a single declarative framework. SPL-flow extends SPL into resilient agentic pipelines with a three-tier provider fallback strategy (Ollama -> OpenRouter -> self-healing retry) fully transparent to the .spl script. Five extensions demonstrate the paradigm's breadth: (1) Text2SPL (multilingual NL->SPL translation); (2) Mixture-of-Models (MoM) routing that dispatches each PROMPT to a domain-specialist model at runtime; (3) Logical Chunking, an intelligent strategy for documents exceeding a single context window--expressed naturally through SPL's existing CTE syntax with no new constructs, decomposing a large query into a Map-Reduce pipeline that reduces attention cost from O(N^2) to O(N^2/k) and runs identically on cloud (parallel) or local hardware (sequential); (4) SPL-flow, a declarative agentic orchestration layer with resilient three-tier provider fallback; and (5) BENCHMARK for parallel multi-model comparison with automatic winner persistence. We provide a formal EBNF grammar, two pip-installable Python packages (spl-llm, spl-flow), and comparison against Prompty, DSPy, and LMQL. SPL reduces prompt boilerplate by 65% on average, surfaces a 68x cost spread across model tiers as a pre-execution signal, and runs the identical .spl script at $0.002 on OpenRouter or at zero marginal cost on a local Ollama instance--without modification.

</details>


### [19] [Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models](https://arxiv.org/abs/2602.21262)
*Sasha Robinson,Kerem Oktar,Katherine M. Collins,Ilia Sucholutsky,Kelsey R. Allen*

Main category: cs.CL

TL;DR: 研究LLMs作为决策顾问时，其说服力、警觉性和任务表现三者是可分离的能力，需要分别监测以确保AI安全


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地应用于高风险决策领域，需要理解它们作为顾问时带来的风险。LLMs需要筛选大量信息（包括善意和恶意内容），然后说服用户采取特定行动，这涉及警觉性（判断使用哪些信息）和说服力（合成证据进行论证）两种社会能力。现有研究孤立地探讨这些能力，但很少研究它们之间的联系。

Method: 使用简单的多轮益智游戏Sokoban来研究LLMs说服其他LLM智能体以及保持理性警觉的能力。通过实验分析模型在游戏中的表现、说服能力和警觉性之间的关系。

Result: 发现益智游戏表现、说服能力和警觉性是LLMs中可分离的能力。游戏表现好并不意味着模型能够检测到自己被误导，即使明确提示可能存在欺骗。然而，LLMs会持续调整token使用量：面对善意建议时使用较少的token进行推理，面对恶意建议时使用更多token，即使最终仍被说服采取导致失败的行动。

Conclusion: 这是首次研究LLMs中说服力、警觉性和任务表现之间关系的工作，表明未来AI安全研究中需要独立监测这三个方面。

Abstract: With increasing integration of Large Language Models (LLMs) into areas of high-stakes human decision-making, it is important to understand the risks they introduce as advisors. To be useful advisors, LLMs must sift through large amounts of content, written with both benevolent and malicious intent, and then use this information to convince a user to take a specific action. This involves two social capacities: vigilance (the ability to determine which information to use, and which to discard) and persuasion (synthesizing the available evidence to make a convincing argument). While existing work has investigated these capacities in isolation, there has been little prior investigation of how these capacities may be linked. Here, we use a simple multi-turn puzzle-solving game, Sokoban, to study LLMs' abilities to persuade and be rationally vigilant towards other LLM agents. We find that puzzle-solving performance, persuasive capability, and vigilance are dissociable capacities in LLMs. Performing well on the game does not automatically mean a model can detect when it is being misled, even if the possibility of deception is explicitly mentioned. % as part of the prompt. However, LLMs do consistently modulate their token use, using fewer tokens to reason when advice is benevolent and more when it is malicious, even if they are still persuaded to take actions leading them to failure. To our knowledge, our work presents the first investigation of the relationship between persuasion, vigilance, and task performance in LLMs, and suggests that monitoring all three independently will be critical for future work in AI safety.

</details>


### [20] [ToolMATH: A Math Tool Benchmark for Realistic Long-Horizon Multi-Tool Reasoning](https://arxiv.org/abs/2602.21265)
*Hyeonje Choi,Jeongsoo Lee,Hyojun Lee,Jay-Yoon Lee*

Main category: cs.CL

TL;DR: ToolMATH是一个数学基础的基准测试，用于评估工具增强语言模型在现实多工具环境中的表现，重点关注工具调用、多步执行和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前工具增强语言模型在现实多工具环境中的评估存在不足，特别是在大型重叠工具目录和预期能力缺失情况下的可靠性问题。需要系统性的基准来诊断模型失败模式并识别所需的控制机制。

Method: 将数学问题转化为可控、可验证的基准测试，包含工具集和调用规范。ToolMATH包含约8k个问题和12k个工具，还提供额外的困难集ToolMATHHard。通过系统评估模型在工具调用、多步执行和鲁棒性方面的表现。

Result: 评估发现主要失败因素是推理能力不足，导致中间结果错误积累并限制后续决策。工具列表冗余不仅增加噪声，还会将早期小偏差放大为不可逆的执行漂移。当预期能力缺失时，干扰工具有时可作为部分替代，但也可能误导模型进入无根据的工具轨迹。工具使用协议比较表明，改进更多来自长期计划一致性和对观察结果的规范使用，而非局部动作选择。

Conclusion: ToolMATH基准测试为工具增强语言模型在现实多工具环境中的评估提供了系统性框架，揭示了模型失败的关键机制，并强调了长期计划一致性和观察规范使用的重要性，为模型鲁棒性改进提供了方向。

Abstract: We introduce \ToolMATH, a math-grounded benchmark that evaluates tool-augmented language models in realistic multi-tool environments where the output depends on calling schema-specified tools and sustaining multi-step execution. It turns math problems into a controlled, correctness-checkable benchmark with tool sets, enabling systematic evaluation of model reliability under (1) large, overlapping tool catalogs and (2) the absence of the intended capability. \ToolMATH provides actionable diagnostic evidence of failure modes in tool-augmented agents, helping identify the control mechanisms required for robustness. \ToolMATH roughly contains 8k questions and 12k tools; we provide an additional hard-set \ToolMATHHard with questions and tools. Our evaluation reveals that the key failure factor is due to the inability to reason, leading to the accumulation of intermediate results' errors and constrain later decisions. Tool-list redundancy do not simply add noise, but amplify small early deviations into irreversible execution drift. The benchmark highlights that when the intended capability is missing, distractor tools can sometimes serve as partial substitutes in solution paths, yet they can also mislead models into ungrounded tool trajectories. Finally, comparisons between tool-use protocols emphasize that improvements come less from local action selection and more from long-range plan coherence and disciplined use of observations.

</details>


### [21] [Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment](https://arxiv.org/abs/2602.21346)
*Mengxuan Hu,Vivek V. Datla,Anoop Kumar,Zihan Guan,Sheng Li,Alfy Samuel,Daben Liu*

Main category: cs.CL

TL;DR: 该论文提出通过推理感知的后训练增强LLM对齐，通过构建CoT微调数据集和Alignment-Weighted DPO方法，提高模型对越狱攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有对齐技术（SFT、RLHF、DPO）提升了LLM安全性，但模型仍易受越狱攻击，因为浅层对齐机制缺乏深度推理，仅表面拒绝有害提示而不理解其危害原因。

Method: 1. 构建并发布包含实用性和安全性提示的分步推理链CoT微调数据集；2. 提出Alignment-Weighted DPO，对输出中的推理和最终答案部分分配不同偏好权重，实现更精细的针对性更新。

Result: 实验表明，该方法在多个安全性和实用性基准测试中一致提升对齐鲁棒性，同时保持模型整体实用性，优于标准SFT基线。

Conclusion: 通过推理感知的后训练和细粒度偏好优化，可以有效增强LLM对齐的深度和鲁棒性，解决浅层对齐导致的越狱漏洞问题。

Abstract: Recent advances in alignment techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and Direct Preference Optimization (DPO) have improved the safety of large language models (LLMs). However, these LLMs remain vulnerable to jailbreak attacks that disguise harmful intent through indirect or deceptive phrasing. Using causal intervention, we empirically demonstrate that this vulnerability stems from shallow alignment mechanisms that lack deep reasoning, often rejecting harmful prompts without truly understanding why they are harmful. To mitigate this vulnerability, we propose enhancing alignment through reasoning-aware post-training. We construct and release a novel Chain-of-Thought (CoT) fine-tuning dataset that includes both utility-oriented and safety-critical prompts with step-by-step rationales. Fine-tuning on this dataset encourages models to produce principled refusals grounded in reasoning, outperforming standard SFT baselines. Furthermore, inspired by failure patterns in CoT fine-tuning, we introduce Alignment-Weighted DPO, which targets the most problematic parts of an output by assigning different preference weights to the reasoning and final-answer segments. This produces finer-grained, targeted updates than vanilla DPO and improves robustness to diverse jailbreak strategies. Extensive experiments across multiple safety and utility benchmarks show that our method consistently improves alignment robustness while maintaining overall model utility.

</details>


### [22] [Small Language Models for Privacy-Preserving Clinical Information Extraction in Low-Resource Languages](https://arxiv.org/abs/2602.21374)
*Mohammadreza Ghaffarzadeh-Esfahani,Nahid Yousefian,Ebrahim Heidari-Farsani,Ali Akbar Omidvarian,Sepehr Ghahraei,Atena Farangi,AmirBahador Boroumand*

Main category: cs.CL

TL;DR: 评估一个结合波斯语-英语翻译和多个小语言模型的两步流程，用于从波斯语医疗转录本中提取临床特征，发现较大模型表现更好，翻译能提高敏感度但降低特异性，为低资源多语言临床NLP提供了实用方案。


<details>
  <summary>Details</summary>
Motivation: 从低资源语言（波斯语）的医疗转录本中提取临床信息是医疗NLP的重要挑战，特别是在基础设施和标注资源有限的情况下，需要开发实用且保护隐私的解决方案。

Method: 使用两步流程：首先用Aya-expanse-8B将波斯语转录本翻译成英语，然后用五个开源小语言模型（7B-1B参数）进行13个临床特征的二元提取。采用少量样本提示策略，无需微调，评估了宏平均F1分数、MCC、敏感度和特异性。

Result: Qwen2.5-7B-Instruct表现最佳（中位宏F1: 0.899; MCC: 0.797），Gemma-3-1B-it最弱。较大模型（7B-8B参数）在敏感度和MCC上持续优于较小模型。翻译波斯语到英语提高了敏感度，减少了缺失输出，但略微降低了特异性和精确度。生理症状提取可靠，而心理问题、行政请求和复杂躯体特征仍具挑战性。

Conclusion: 该研究为在有限基础设施和标注资源的多语言临床NLP环境中部署开源小语言模型提供了实用且保护隐私的蓝图，强调了在敏感医疗应用中联合优化模型规模和输入语言策略的重要性。

Abstract: Extracting clinical information from medical transcripts in low-resource languages remains a significant challenge in healthcare natural language processing (NLP). This study evaluates a two-step pipeline combining Aya-expanse-8B as a Persian-to-English translation model with five open-source small language models (SLMs) -- Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, and Gemma-3-1B-it -- for binary extraction of 13 clinical features from 1,221 anonymized Persian transcripts collected at a cancer palliative care call center. Using a few-shot prompting strategy without fine-tuning, models were assessed on macro-averaged F1-score, Matthews Correlation Coefficient (MCC), sensitivity, and specificity to account for class imbalance. Qwen2.5-7B-Instruct achieved the highest overall performance (median macro-F1: 0.899; MCC: 0.797), while Gemma-3-1B-it showed the weakest results. Larger models (7B--8B parameters) consistently outperformed smaller counterparts in sensitivity and MCC. A bilingual analysis of Aya-expanse-8B revealed that translating Persian transcripts to English improved sensitivity, reduced missing outputs, and boosted metrics robust to class imbalance, though at the cost of slightly lower specificity and precision. Feature-level results showed reliable extraction of physiological symptoms across most models, whereas psychological complaints, administrative requests, and complex somatic features remained challenging. These findings establish a practical, privacy-preserving blueprint for deploying open-source SLMs in multilingual clinical NLP settings with limited infrastructure and annotation resources, and highlight the importance of jointly optimizing model scale and input language strategy for sensitive healthcare applications.

</details>


### [23] [Beyond Subtokens: A Rich Character Embedding for Low-resource and Morphologically Complex Languages](https://arxiv.org/abs/2602.21377)
*Felix Schneider,Maria Gogolev,Sven Sickert,Joachim Denzler*

Main category: cs.CL

TL;DR: 提出Rich Character Embeddings (RCE)方法，直接从字符序列计算词向量，结合语义和句法信息，并提出了transformer和卷积的混合模型，可替代传统基于词典和子词的分词方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于分词和子词分词的模型（如word2vec、BERT、GPT）在输入表示上存在局限，无法充分捕捉正字法相似性和形态变化，特别是在高度屈折变化和资源匮乏的语言中。

Method: 提出Rich Character Embeddings (RCE)方法，基于transformer直接从字符序列计算词向量，整合语义和句法信息。同时提出transformer和卷积的混合模型。这些向量表示可作为现有模型架构中基于词典和子词的词嵌入的直接替代品。

Result: 在SWAG、屈折语言的变格预测、多种语言的隐喻和交错配列检测等任务上进行了评估。实验表明，在有限数据情况下，使用OddOneOut和TopK指标，该方法优于传统的基于分词的方

Conclusion: RCE方法有潜力提升BERT等大型上下文语言模型和word2vec等小型模型在资源匮乏和形态丰富语言上的性能，可作为传统分词和子词分词方法的有效替代方案。

Abstract: Tokenization and sub-tokenization based models like word2vec, BERT and the GPTs are the state-of-the-art in natural language processing. Typically, these approaches have limitations with respect to their input representation. They fail to fully capture orthographic similarities and morphological variations, especially in highly inflected and under-resource languages. To mitigate this problem, we propose to computes word vectors directly from character strings, integrating both semantic and syntactic information. We denote this transformer-based approach Rich Character Embeddings (RCE). Furthermore, we propose a hybrid model that combines transformer and convolutional mechanisms. Both vector representations can be used as a drop-in replacement for dictionary- and subtoken-based word embeddings in existing model architectures. It has the potential to improve performance for both large context-based language models like BERT and small models like word2vec for under-resourced and morphologically rich languages. We evaluate our approach on various tasks like the SWAG, declension prediction for inflected languages, metaphor and chiasmus detection for various languages. Our experiments show that it outperforms traditional token-based approaches on limited data using OddOneOut and TopK metrics.

</details>


### [24] [MrBERT: Modern Multilingual Encoders via Vocabulary, Domain, and Dimensional Adaptation](https://arxiv.org/abs/2602.21379)
*Daniel Tamayo,Iñaki Lacunza,Paula Rivera-Hidalgo,Severino Da Dalt,Javier Aula-Blasco,Aitor Gonzalez-Agirre,Marta Villegas*

Main category: cs.CL

TL;DR: MrBERT是基于ModernBERT架构的150M-300M参数编码器，支持35种语言和代码，在加泰罗尼亚语和西班牙语任务上达到SOTA，并在生物医学和法律领域表现优异，采用MRL技术实现灵活向量大小以降低推理和存储成本。


<details>
  <summary>Details</summary>
Motivation: 解决传统编码器在特定语言任务和领域专业化方面的不足，同时兼顾研究到生产的实际应用需求，特别是在降低推理和存储成本方面的挑战。

Method: 基于ModernBERT架构构建150M-300M参数编码器，在35种语言和代码上进行预训练，采用针对性适应策略，并集成Matryoshka Representation Learning (MRL)技术实现灵活向量表示。

Result: 在加泰罗尼亚语和西班牙语特定任务上达到最先进水平，在生物医学和法律等专业领域表现出稳健性能，通过MRL显著降低了推理和存储成本。

Conclusion: 现代编码器架构可以通过优化同时实现本地化语言卓越性和高效的高风险领域专业化，MrBERT模型家族在Huggingface上开源。

Abstract: We introduce MrBERT, a family of 150M-300M parameter encoders built on the ModernBERT architecture and pre-trained on 35 languages and code. Through targeted adaptation, this model family achieves state-of-the-art results on Catalan- and Spanish-specific tasks, while establishing robust performance across specialized biomedical and legal domains. To bridge the gap between research and production, we incorporate Matryoshka Representation Learning (MRL), enabling flexible vector sizing that significantly reduces inference and storage costs. Ultimately, the MrBERT family demonstrates that modern encoder architectures can be optimized for both localized linguistic excellence and efficient, high-stakes domain specialization. We open source the complete model family on Huggingface.

</details>


### [25] [VecGlypher: Unified Vector Glyph Generation with Language Models](https://arxiv.org/abs/2602.21461)
*Xiaoke Huang,Bhavul Gauri,Kam Woh Ng,Tony Ng,Mengmeng Xu,Zhiheng Liu,Weiming Ren,Zhaochong An,Zijian Zhou,Haonan Qiu,Yuyin Zhou,Sen He,Ziheng Wang,Tao Xiang,Xiao Han*

Main category: cs.CL

TL;DR: VecGlypher是一个多模态语言模型，能够直接从文本描述或图像示例生成高质量矢量字形，无需光栅中间处理，产生可编辑的SVG路径。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的字体生成流程仍然依赖于精心策划的示例表和光栅到矢量的后处理，这限制了可访问性和可编辑性。需要一种能够直接生成可编辑矢量字形的解决方案。

Method: 采用两阶段训练方法：首先在39K个嘈杂的Envato字体上进行大规模预训练以掌握SVG语法和长序列几何结构，然后在2.5K个专家标注的Google字体上进行后训练，使语言和图像与几何对齐。预处理包括坐标帧归一化、路径规范化、去重和坐标量化。

Result: 在跨家族OOD评估中，VecGlypher在纯文本生成方面显著优于通用LLM和专用矢量字体基线，而图像参考生成达到了最先进的性能，明显优于DeepVecFont-v2和DualVector。消融实验显示模型规模和两阶段训练方法至关重要，绝对坐标序列化产生最佳几何结果。

Conclusion: VecGlypher通过让用户用文字或示例设计字体，降低了字体创建的门槛，并为未来多模态设计工具提供了可扩展的基础。

Abstract: Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given a style prompt, optional reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools.

</details>


### [26] [Evaluating the Usage of African-American Vernacular English in Large Language Models](https://arxiv.org/abs/2602.21485)
*Deja Dunlap,R. Thomas McCoy*

Main category: cs.CL

TL;DR: LLMs在非裔美国人白话英语(AAVE)上的表现与母语者存在显著差异，存在使用不足、误用和刻板印象问题


<details>
  <summary>Details</summary>
Motivation: 当前AI评估主要基于标准美国英语，缺乏对非标准方言如AAVE的准确理解，需要研究LLMs对AAVE的表征准确性

Method: 1) 使用CORAAL和TwitterAAE语料库分析AAVE母语者的典型语法特征使用模式；2) 提示三个LLMs生成AAVE文本；3) 对比模型生成文本与人类使用模式

Result: LLMs在AAVE使用上与人类存在显著差异：通常使用不足和误用AAVE特征语法；通过情感分析和人工检查发现模型复制了关于非裔美国人的刻板印象

Conclusion: 需要更多样化的训练数据和公平性方法来减少刻板印象的延续，提高LLMs对非标准方言的准确表征能力

Abstract: In AI, most evaluations of natural language understanding tasks are conducted in standardized dialects such as Standard American English (SAE). In this work, we investigate how accurately large language models (LLMs) represent African American Vernacular English (AAVE). We analyze three LLMs to compare their usage of AAVE to the usage of humans who natively speak AAVE. We first analyzed interviews from the Corpus of Regional African American Language and TwitterAAE to identify the typical contexts where people use AAVE grammatical features such as ain't. We then prompted the LLMs to produce text in AAVE and compared the model-generated text to human usage patterns. We find that, in many cases, there are substantial differences between AAVE usage in LLMs and humans: LLMs usually underuse and misuse grammatical features characteristic of AAVE. Furthermore, through sentiment analysis and manual inspection, we found that the models replicated stereotypes about African Americans. These results highlight the need for more diversity in training data and the incorporation of fairness methods to mitigate the perpetuation of stereotypes.

</details>


### [27] [MixSarc: A Bangla-English Code-Mixed Corpus for Implicit Meaning Identification](https://arxiv.org/abs/2602.21608)
*Kazi Samin Yasar Alam,Md Tanbir Chowdhury,Tamim Ahmed,Ajwad Abrar,Md Rafid Haque*

Main category: cs.CL

TL;DR: 首个公开的孟加拉语-英语代码混合语料库MixSarc，用于隐式含义识别，包含9087个标注句子，涵盖幽默、讽刺、冒犯和粗俗四类标签，为文化感知的NLP提供基础资源。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语-英语代码混合在南亚社交媒体中广泛存在，但现有情感和讽刺模型主要关注英语或高资源语言，难以处理转写变异、文化引用和句内语言切换，缺乏相应的资源。

Method: 通过定向社交媒体收集、系统过滤和多标注者验证构建语料库；使用基于Transformer的模型进行基准测试，并在结构化提示下评估零样本大语言模型。

Result: 幽默检测表现良好，但讽刺、冒犯和粗俗检测因类别不平衡和语用复杂性而显著退化；零样本模型获得有竞争力的微平均F1分数但精确匹配准确率低；分析发现外部数据集中超过42%的负面情感实例具有讽刺特征。

Conclusion: MixSarc为文化感知的NLP提供了基础资源，支持在代码混合环境中进行更可靠的多标签建模，揭示了隐式含义识别在低资源代码混合语言中的挑战。

Abstract: Bangla-English code-mixing is widespread across South Asian social media, yet resources for implicit meaning identification in this setting remain scarce. Existing sentiment and sarcasm models largely focus on monolingual English or high-resource languages and struggle with transliteration variation, cultural references, and intra-sentential language switching. To address this gap, we introduce MixSarc, the first publicly available Bangla-English code-mixed corpus for implicit meaning identification. The dataset contains 9,087 manually annotated sentences labeled for humor, sarcasm, offensiveness, and vulgarity. We construct the corpus through targeted social media collection, systematic filtering, and multi-annotator validation. We benchmark transformer-based models and evaluate zero-shot large language models under structured prompting. Results show strong performance on humor detection but substantial degradation on sarcasm, offense, and vulgarity due to class imbalance and pragmatic complexity. Zero-shot models achieve competitive micro-F1 scores but low exact match accuracy. Further analysis reveals that over 42\% of negative sentiment instances in an external dataset exhibit sarcastic characteristics. MixSarc provides a foundational resource for culturally aware NLP and supports more reliable multi-label modeling in code-mixed environments.

</details>


### [28] [When More Is Less: A Systematic Analysis of Spatial and Commonsense Information for Visual Spatial Reasoning](https://arxiv.org/abs/2602.21619)
*Muku Akasaka,Soyeon Caren Han*

Main category: cs.CL

TL;DR: 视觉空间推理中，信息注入并非越多越好，需要选择性、任务对齐的信息注入才能提升模型性能


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在视觉空间推理方面仍面临挑战，常见的推理时信息注入策略（如空间线索、常识知识、思维链指令）效果不明确，不清楚何时真正改善推理，何时引入噪声

Method: 对三个代表性VLM和两个公开基准进行假设驱动分析，研究：(i)空间上下文类型和数量，(ii)注入常识知识的数量和相关性，(iii)空间基础与思维链提示的交互作用

Result: 发现一致模式：更多信息不一定带来更好推理。有针对性的单一空间线索优于多上下文聚合；过多或弱相关常识知识会降低性能；只有当空间基础足够精确时，思维链提示才能提高准确性

Conclusion: 强调了选择性、任务对齐信息注入的重要性，为设计可靠的多模态推理流程提供了实用指导

Abstract: Visual spatial reasoning (VSR) remains challenging for modern vision-language models (VLMs), despite advances in multimodal architectures. A common strategy is to inject additional information at inference time, such as explicit spatial cues, external commonsense knowledge, or chain-of-thought (CoT) reasoning instructions. However, it remains unclear when such information genuinely improves reasoning and when it introduces noise. In this paper, we conduct a hypothesis-driven analysis of information injection for VSR across three representative VLMs and two public benchmarks. We examine (i) the type and number of spatial contexts, (ii) the amount and relevance of injected commonsense knowledge, and (iii) the interaction between spatial grounding and CoT prompting. Our results reveal a consistent pattern: more information does not necessarily yield better reasoning. Targeted single spatial cues outperform multi-context aggregation, excessive or weakly relevant commonsense knowledge degrades performance, and CoT prompting improves accuracy only when spatial grounding is sufficiently precise. These findings highlight the importance of selective, task-aligned information injection and provide practical guidance for designing reliable multimodal reasoning pipelines.

</details>


### [29] [RuCL: Stratified Rubric-Based Curriculum Learning for Multimodal Large Language Model Reasoning](https://arxiv.org/abs/2602.21628)
*Yukun Chen,Jiaming Li,Longze Chen,Ze Gong,Jingpeng Li,Zhen Qin,Hengyu Chang,Ancheng Xu,Zhihao Yang,Hamid Alinejad-Rokny,Qiang Qu,Bo Zheng,Min Yang*

Main category: cs.CL

TL;DR: RuCL通过分层课程学习框架，将重点从数据选择转向奖励设计，使用分层rubric权重动态调整训练，显著提升多模态大语言模型的视觉推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法仅依赖结果监督容易导致奖励黑客问题，而基于rubric的方法虽然提供细粒度监督信号，但存在计算成本高和将所有rubric视为同等可学习的低效训练动态问题。

Method: 提出分层rubric课程学习框架，生成通用rubric并基于模型能力进行分层，在训练过程中动态调整rubric权重，引导模型从基础感知逐步过渡到高级逻辑推理。

Result: 在多个视觉推理基准测试中，RuCL相比Qwen2.5-VL-7B模型平均提升7.83%，达到60.06%的SOTA准确率。

Conclusion: RuCL通过分层课程学习框架有效解决了现有RLVR方法的局限性，在提升模型推理能力的同时避免了奖励黑客问题，为多模态推理提供了新的训练范式。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a prevailing paradigm for enhancing reasoning in Multimodal Large Language Models (MLLMs). However, relying solely on outcome supervision risks reward hacking, where models learn spurious reasoning patterns to satisfy final answer checks. While recent rubric-based approaches offer fine-grained supervision signals, they suffer from high computational costs of instance-level generation and inefficient training dynamics caused by treating all rubrics as equally learnable. In this paper, we propose Stratified Rubric-based Curriculum Learning (RuCL), a novel framework that reformulates curriculum learning by shifting the focus from data selection to reward design. RuCL generates generalized rubrics for broad applicability and stratifies them based on the model's competence. By dynamically adjusting rubric weights during training, RuCL guides the model from mastering foundational perception to tackling advanced logical reasoning. Extensive experiments on various visual reasoning benchmarks show that RuCL yields a remarkable +7.83% average improvement over the Qwen2.5-VL-7B model, achieving a state-of-the-art accuracy of 60.06%.

</details>


### [30] [Multi-dimensional Assessment and Explainable Feedback for Counselor Responses to Client Resistance in Text-based Counseling with LLMs](https://arxiv.org/abs/2602.21638)
*Anqi Li,Ruihan Wang,Zhaoming Chen,Yuqian Chen,Yu Lu,Yi Zhu,Yuan Xie,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 开发了一个AI系统，用于评估心理咨询师对客户抵抗的干预质量，通过多维度评估框架和专家标注数据训练，显著提升咨询师应对抵抗的能力。


<details>
  <summary>Details</summary>
Motivation: 心理咨询中有效处理客户抵抗是一项复杂技能，但从业者缺乏及时、可扩展的监督反馈。现有NLP研究只关注整体咨询质量和一般治疗技能，无法对客户出现抵抗的高风险时刻提供细致评估。

Method: 提出一个理论驱动框架，将咨询师回应分解为四种沟通机制；创建专家标注的真实咨询对话数据集；使用该数据集对Llama-3.1-8B-Instruct进行全参数指令微调，以建模细粒度评估判断并生成解释。

Result: 模型能有效区分不同沟通机制的质量（77-81% F1），显著优于GPT-4o和Claude-3.5-Sonnet（45-59% F1）；生成的解释与专家参考高度一致，获得接近满分的专家评分（2.8-2.9/3.0）；43名咨询师的对照实验证实，接收AI反馈能显著提升他们应对客户抵抗的能力。

Conclusion: 该研究开发了一个有效的AI系统，能够为心理咨询师提供针对客户抵抗的细粒度评估和解释性反馈，填补了现有NLP研究的空白，并证明能实际提升咨询师的临床技能。

Abstract: Effectively addressing client resistance is a sophisticated clinical skill in psychological counseling, yet practitioners often lack timely and scalable supervisory feedback to refine their approaches. Although current NLP research has examined overall counseling quality and general therapeutic skills, it fails to provide granular evaluations of high-stakes moments where clients exhibit resistance. In this work, we present a comprehensive pipeline for the multi-dimensional evaluation of human counselors' interventions specifically targeting client resistance in text-based therapy. We introduce a theory-driven framework that decomposes counselor responses into four distinct communication mechanisms. Leveraging this framework, we curate and share an expert-annotated dataset of real-world counseling excerpts, pairing counselor-client interactions with professional ratings and explanatory rationales. Using this data, we perform full-parameter instruction tuning on a Llama-3.1-8B-Instruct backbone to model fine-grained evaluative judgments of response quality and generate explanations underlying. Experimental results show that our approach can effectively distinguish the quality of different communication mechanisms (77-81% F1), substantially outperforming GPT-4o and Claude-3.5-Sonnet (45-59% F1). Moreover, the model produces high-quality explanations that closely align with expert references and receive near-ceiling ratings from human experts (2.8-2.9/3.0). A controlled experiment with 43 counselors further confirms that receiving these AI-generated feedback significantly improves counselors' ability to respond effectively to client resistance.

</details>


### [31] [Scalable Multilingual Multimodal Machine Translation with Speech-Text Fusion](https://arxiv.org/abs/2602.21646)
*Yexing Du,Youcheng Pan,Zekun Wang,Zheng Chu,Yichong Huang,Kaiyuan Liu,Bo Yang,Yang Xiang,Ming Liu,Bing Qin*

Main category: cs.CL

TL;DR: 提出了一种基于语音引导的机器翻译框架，通过将语音和文本作为融合输入到多模态大语言模型中，利用语音模态的天然文本对齐性和丰富数据集优势来提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型主要依赖图像引导方法，但受限于多语言图像-文本对的稀缺性。语音模态因其与文本的天然对齐性和丰富的现有数据集，能够实现可扩展的语言覆盖，从而克服这一限制。

Method: 提出语音引导机器翻译框架，将语音和文本作为融合输入到MLLM中。为减少对低资源数据的依赖，引入自进化机制，包括文本转语音模型生成合成语音，以及能够分类合成语音样本并使用正样本迭代优化自身的MLLM。

Result: 在Multi30K多模态机器翻译基准测试中超越了所有现有方法，达到新的最先进水平。在通用机器翻译数据集（特别是FLORES-200）上，在108个翻译方向上实现了平均最先进的性能。消融研究表明合成语音与真实语音的差异对翻译质量影响可忽略。

Conclusion: 语音引导的机器翻译框架有效利用了语音模态的优势，通过自进化机制减少了对低资源数据的依赖，在多个基准测试中取得了最先进的翻译性能，证明了语音作为多模态输入的可行性和有效性。

Abstract: Multimodal Large Language Models (MLLMs) have achieved notable success in enhancing translation performance by integrating multimodal information. However, existing research primarily focuses on image-guided methods, whose applicability is constrained by the scarcity of multilingual image-text pairs. The speech modality overcomes this limitation due to its natural alignment with text and the abundance of existing speech datasets, which enable scalable language coverage. In this paper, we propose a Speech-guided Machine Translation (SMT) framework that integrates speech and text as fused inputs into an MLLM to improve translation quality. To mitigate reliance on low-resource data, we introduce a Self-Evolution Mechanism. The core components of this framework include a text-to-speech model, responsible for generating synthetic speech, and an MLLM capable of classifying synthetic speech samples and iteratively optimizing itself using positive samples. Experimental results demonstrate that our framework surpasses all existing methods on the Multi30K multimodal machine translation benchmark, achieving new state-of-the-art results. Furthermore, on general machine translation datasets, particularly the FLORES-200, it achieves average state-of-the-art performance in 108 translation directions. Ablation studies on CoVoST-2 confirms that differences between synthetic and authentic speech have negligible impact on translation quality. The code and models are released at https://github.com/yxduir/LLM-SRT.

</details>


### [32] [Mitigating Structural Noise in Low-Resource S2TT: An Optimized Cascaded Nepali-English Pipeline with Punctuation Restoration](https://arxiv.org/abs/2602.21647)
*Tangsang Chongbang,Pranesh Pyara Shrestha,Amrit Sarki,Anku Jaiswal*

Main category: cs.CL

TL;DR: 本文提出并评估了一个优化的级联尼泊尔语语音到英语文本翻译系统，通过引入标点恢复模块来缓解ASR引入的结构噪声，显著提升了翻译质量。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）在级联语音到文本翻译（S2TT）系统中会引入结构噪声（特别是标点符号丢失），这会显著降低机器翻译（NMT）的质量，尤其是在低资源语言如尼泊尔语中。

Method: 首先建立高性能的ASR（基于Wav2Vec2-XLS-R-300m）和NMT（基于MarianMT多阶段微调）组件。然后通过实证研究验证标点丢失对翻译质量的影响，并提出并评估一个中间的标点恢复模块（PRM）。在自定义数据集上测试了三种配置的S2TT流水线。

Result: 标点丢失导致FLORES基准上相对BLEU下降20.7%。最优配置（将PRM直接应用于ASR输出）相比直接ASR到NMT基线获得了4.90 BLEU点的提升（36.38 vs. 31.48）。人类评估也证实了优化流水线在充分性（3.673）和流畅性（3.804）方面的优越性。

Conclusion: 针对性的标点恢复是缓解尼泊尔语S2TT流水线中结构噪声的最有效干预措施。这项工作为类似低资源语言开发级联语音翻译系统建立了优化基线并提供了关键架构见解。

Abstract: This paper presents and evaluates an optimized cascaded Nepali speech-to-English text translation (S2TT) system, focusing on mitigating structural noise introduced by Automatic Speech Recognition (ASR). We first establish highly proficient ASR and NMT components: a Wav2Vec2-XLS-R-300m model achieved a state-of-the-art 2.72% CER on OpenSLR-54, and a multi-stage fine-tuned MarianMT model reached a 28.32 BLEU score on the FLORES-200 benchmark. We empirically investigate the influence of punctuation loss, demonstrating that unpunctuated ASR output significantly degrades translation quality, causing a massive 20.7% relative BLEU drop on the FLORES benchmark. To overcome this, we propose and evaluate an intermediate Punctuation Restoration Module (PRM). The final S2TT pipeline was tested across three configurations on a custom dataset. The optimal configuration, which applied the PRM directly to ASR output, achieved a 4.90 BLEU point gain over the direct ASR-to-NMT baseline (BLEU 36.38 vs. 31.48). This improvement was validated by human assessment, which confirmed the optimized pipeline's superior Adequacy (3.673) and Fluency (3.804). This work validates that targeted punctuation restoration is the most effective intervention for mitigating structural noise in the Nepali S2TT pipeline. It establishes an optimized baseline and demonstrates a critical architectural insight for developing cascaded speech translation systems for similar low-resource languages.

</details>


### [33] [Sparsity Induction for Accurate Post-Training Pruning of Large Language Models](https://arxiv.org/abs/2602.21652)
*Minhao Jiang,Zhikai Li,Xuewen Liu,Jing Zhang,Mengjuan Chen,Qingyi Gu*

Main category: cs.CL

TL;DR: 提出Sparsity Induction方法，通过分布级和特征级稀疏性诱导，提升大语言模型的后训练稀疏化性能


<details>
  <summary>Details</summary>
Motivation: 大语言模型参数规模增长带来计算和内存效率挑战，后训练稀疏化是有效方法，但直接移除权重会破坏模型状态，导致性能恢复不理想

Method: 提出Sparsity Induction方法，在剪枝前从两个层面诱导模型稀疏性：分布级通过数学等价缩放变换增强分布稀疏性；特征级引入谱范数损失从低秩角度促进特征稀疏性

Result: 在不同模型架构和任务上的实验表明，该方法进一步增强了稀疏友好性，在剪枝性能上优于现有方法

Conclusion: 通过分布级和特征级的稀疏性诱导，能够有效提升后训练稀疏化的性能极限，为大规模语言模型的高效部署提供了新思路

Abstract: Large language models have demonstrated capabilities in text generation, while their increasing parameter scales present challenges in computational and memory efficiency. Post-training sparsity (PTS), which reduces model cost by removing weights from dense networks, is an effective approach. However, native dense matrices lack high sparsity, making existing approaches that directly remove weights disrupt model states, resulting in unsatisfactory performance recovery even with post-tuning. We propose Sparsity Induction, which promotes models toward higher sparsity at both distribution and feature levels before pruning, to push the limits of PTS. At the distribution level, we enhance distributional sparsity through mathematically equivalent scaling transformations, which are fully absorbable and incur no extra parameters or inference-time overhead. At the feature level, we introduce Spectral Norm Loss to promote feature sparsity from a low-rank perspective. Experiments across diverse model architectures and tasks demonstrate that our method further enhances sparsity-friendliness, achieving superior pruning performance over existing approaches.

</details>


### [34] [DWA-KD: Dual-Space Weighting and Time-Warped Alignment for Cross-Tokenizer Knowledge Distillation](https://arxiv.org/abs/2602.21669)
*Duc Trung Vu,Pham Khanh Chi,Dat Phi Van,Linh Ngo Van,Sang Dinh,Trung Le*

Main category: cs.CL

TL;DR: DWA-KD提出了一种新颖的跨tokenizer知识蒸馏框架，通过双空间熵加权和时间扭曲对齐，在token和序列两个层面改进教师-学生模型的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有跨tokenizer知识蒸馏方法在序列和词汇层面的对齐效果不理想，限制了蒸馏效果。需要一种能够同时优化token级和序列级对齐的方法。

Method: 提出DWA-KD框架：1) token级：通过双向映射和双空间KL散度进行知识蒸馏，使用基于熵的双空间权重，关注学生不确定而教师确定的token；2) 序列级：在嵌入层和最终隐藏层使用Soft-DTW，对齐词汇和上下文语义。

Result: 在多个NLP基准测试中，DWA-KD超越了现有最先进的知识蒸馏方法。消融实验证实了熵加权token和Soft-DTW对齐的互补贡献。

Conclusion: DWA-KD通过创新的双空间加权和时间扭曲对齐机制，有效解决了跨tokenizer知识蒸馏中的对齐问题，显著提升了蒸馏效果。

Abstract: Knowledge Distillation (KD) has emerged as a crucial technique for compressing Large Language Models (LLMs). Although existing cross-tokenizer KD methods have made notable progress, their effectiveness remains constrained by suboptimal alignment across sequence and vocabulary levels. To address these limitations, we introduce Dual-Space Weighting and Time-Warped Alignment (DWA-KD), a novel cross-tokenizer distillation framework that enhances token-wise distillation through dual-space entropy-based weighting and achieves precise sequence-level alignment by leveraging both lexical and semantic information. At the token level, DWA-KD maps teacher representations into the student space and vice versa, performing dual-space KD via Kullback-Leibler divergence (KL). The process is modulated by dual-space weights that up-weight tokens where the student is uncertain and the teacher is confident, thereby focusing learning on informative tokens rather than treating all positions equally. At the sequence level, DWA-KD applies Soft Dynamic Time Warping (Soft-DTW) to both the embedding and final hidden-state layers, enabling robust alignment of lexical and contextual semantics between teacher and student sequences. Extensive experiments across diverse NLP benchmarks demonstrate that DWA-KD outperforms state-of-the-art KD baselines, while ablation studies confirm the complementary contributions of entropy-based token weighting and embedding and final hidden state layer Soft-DTW alignment.

</details>


### [35] [Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning](https://arxiv.org/abs/2602.21720)
*Andrea Silvi,Ponrawee Prasertsom,Jennifer Culbertson,Devdatt Dubhashi,Moa Johansson,Kenny Smith*

Main category: cs.CL

TL;DR: 递归数字系统的规律性促进学习，这解释了人类语言中此类系统普遍存在的原因。


<details>
  <summary>Details</summary>
Motivation: 探究人类递归数字系统（如英语十进制数字）为何普遍具有高度规律性，是否因为规律性促进了学习过程。

Method: 采用强化学习方法，比较规律系统与不规则系统的学习难度，并假设递归数字系统设计用于从有限数据泛化到精确表示所有整数。

Result: 高度规律的人类(类)系统比未出现但可能的不规则系统更容易学习；这种不对称性在自然假设下出现；对于不自然的高度不规则系统，规律性影响消失，而信号长度成为主要影响因素。

Conclusion: 规律性促进学习的发现支持了"可学习性影响跨语言普遍性"的理论框架，不同系统部分可能受到不同学习压力的影响。

Abstract: Human recursive numeral systems (i.e., counting systems such as English base-10 numerals), like many other grammatical systems, are highly regular. Following prior work that relates cross-linguistic tendencies to biases in learning, we ask whether regular systems are common because regularity facilitates learning. Adopting methods from the Reinforcement Learning literature, we confirm that highly regular human(-like) systems are easier to learn than unattested but possible irregular systems. This asymmetry emerges under the natural assumption that recursive numeral systems are designed for generalisation from limited data to represent all integers exactly. We also find that the influence of regularity on learnability is absent for unnatural, highly irregular systems, whose learnability is influenced instead by signal length, suggesting that different pressures may influence learnability differently in different parts of the space of possible numeral systems. Our results contribute to the body of work linking learnability to cross-linguistic prevalence.

</details>


### [36] [Explore-on-Graph: Incentivizing Autonomous Exploration of Large Language Models on Knowledge Graphs with Path-refined Reward Modeling](https://arxiv.org/abs/2602.21728)
*Shiqi Yan,Yubo Chen,Ruiqi Zhou,Zhengxi Yao,Shuai Chen,Tianyi Zhang,Shijie Zhang,Wei Qiang Zhang,Yongfeng Huang,Haixin Duan,Yunqi Zhang*

Main category: cs.CL

TL;DR: 提出Explore-on-Graph框架，通过强化学习激励LLM在知识图谱上自主探索多样推理路径，解决传统方法泛化性不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的增强方法通常通过强制规则或模仿固定演示路径来约束LLM推理，这限制了LLM的推理模式，使其局限于先验经验或微调数据范围内，难以泛化到分布外的图推理问题

Method: 提出Explore-on-Graph框架：1）引入强化学习训练，奖励基于推理路径最终答案的正确性；2）加入路径信息作为额外奖励信号，优化探索过程，减少无效探索

Result: 在五个KGQA基准数据集上的广泛实验表明，该方法取得了最先进的性能，不仅超越了开源LLM，甚至优于闭源LLM

Conclusion: 通过强化学习激励LLM在知识图谱上自主探索多样推理路径是有效的，能够提高KGQA任务的性能，特别是在分布外泛化方面表现出色

Abstract: The reasoning process of Large Language Models (LLMs) is often plagued by hallucinations and missing facts in question-answering tasks. A promising solution is to ground LLMs' answers in verifiable knowledge sources, such as Knowledge Graphs (KGs). Prevailing KG-enhanced methods typically constrained LLM reasoning either by enforcing rules during generation or by imitating paths from a fixed set of demonstrations. However, they naturally confined the reasoning patterns of LLMs within the scope of prior experience or fine-tuning data, limiting their generalizability to out-of-distribution graph reasoning problems. To tackle this problem, in this paper, we propose Explore-on-Graph (EoG), a novel framework that encourages LLMs to autonomously explore a more diverse reasoning space on KGs. To incentivize exploration and discovery of novel reasoning paths, we propose to introduce reinforcement learning during training, whose reward is the correctness of the reasoning paths' final answers. To enhance the efficiency and meaningfulness of the exploration, we propose to incorporate path information as additional reward signals to refine the exploration process and reduce futile efforts. Extensive experiments on five KGQA benchmark datasets demonstrate that, to the best of our knowledge, our method achieves state-of-the-art performance, outperforming not only open-source but also even closed-source LLMs.

</details>


### [37] [Robust Long-Form Bangla Speech Processing: Automatic Speech Recognition and Speaker Diarization](https://arxiv.org/abs/2602.21741)
*MD. Sagor Chowdhury,Adiba Fairooz Chowdhury*

Main category: cs.CL

TL;DR: 该论文提出了一个针对孟加拉语长语音识别和说话人日志的端到端系统，在Kaggle竞赛中取得了优异的词错误率和日志错误率表现


<details>
  <summary>Details</summary>
Motivation: 孟加拉语语音处理面临重大挑战：音素库庞大、方言变异显著、与英语频繁混用、大规模标注语料相对稀缺，需要开发有效的低资源语言处理方案

Method: 1. 语音识别：使用BengaliAI微调的Whisper medium模型，结合Demucs源分离进行人声隔离、静音边界分块和精心调优的生成超参数
2. 说话人日志：将pyannote.audio管道中的默认分割模型替换为孟加拉语微调变体，配合wespeaker-voxceleb-resnet34-LM嵌入表示和基于质心的凝聚聚类

Result: 最佳私有词错误率(WER)为0.37738，公开WER为0.36137；最佳私有日志错误率(DER)为0.27671，公开DER为0.20936

Conclusion: 实验表明，领域特定的分割组件微调、人声源分离和自然静音感知分块是低资源孟加拉语语音处理中三个最具影响力的设计选择

Abstract: We describe our end-to-end system for Bengali long-form speech recognition (ASR) and speaker diarization submitted to the DL Sprint 4.0 competition on Kaggle. Bengali presents substantial challenges for both tasks: a large phoneme inventory, significant dialectal variation, frequent code-mixing with English, and a relative scarcity of large-scale labelled corpora. For ASR we achieve a best private Word Error Rate (WER) of 0.37738 and public WER of 0.36137, combining a BengaliAI fine-tuned Whisper medium model with Demucs source separation for vocal isolation, silence-boundary chunking, and carefully tuned generation hyperparameters. For speaker diarization we reach a best private Diarization Error Rate (DER) of 0.27671 and public DER of 0.20936 by replacing the default segmentation model inside the pyannote.audio pipeline with a Bengali-fine-tuned variant, pairing it with wespeaker-voxceleb-resnet34-LM embeddings and centroid-based agglomerative clustering. Our experiments demonstrate that domain-specific fine-tuning of the segmentation component, vocal source separation, and natural silence-aware chunking are the three most impactful design choices for low-resource Bengali speech processing.

</details>


### [38] [Improving Implicit Discourse Relation Recognition with Natural Language Explanations from LLMs](https://arxiv.org/abs/2602.21763)
*Heng Wang,Changxing Wu*

Main category: cs.CL

TL;DR: 利用大语言模型的推理能力，通过知识蒸馏方法提升隐式篇章关系识别的性能和可解释性


<details>
  <summary>Details</summary>
Motivation: 隐式篇章关系识别需要深度语义理解且缺乏显式标记，现有方法仅预测关系而不提供解释，大语言模型在深度理解和自然语言解释生成方面表现出强大能力

Method: 首先使用大语言模型为每个训练实例生成基于黄金标签的解释，然后引入新颖的分类-生成框架联合进行关系预测和解释生成，并使用LLM生成解释作为额外监督训练

Result: 在PDTB数据集上的实验结果表明，该方法显著提升了IDRR性能，人工评估进一步证实生成的解释增强了模型可解释性，在情感分类和自然语言推理任务上也验证了方法的通用性

Conclusion: 该方法通过知识蒸馏大语言模型的推理能力，有效提升了轻量级IDRR模型的性能和可解释性，且具有即插即用特性，可轻松集成到现有IDRR模型中

Abstract: Implicit Discourse Relation Recognition (IDRR) remains a challenging task due to the requirement for deep semantic understanding in the absence of explicit discourse markers. A further limitation is that existing methods only predict relations without providing any supporting explanations. Recent advances in large language models (LLMs) have shown strong reasoning capabilities in both deep language understanding and natural language explanation generation. In this work, we propose a simple yet effective approach to distill the reasoning capabilities of LLMs into lightweight IDRR models to improve both performance and interpretability. Specifically, we first prompt an LLM to generate explanations for each training instance conditioned on its gold label. Then, we introduce a novel classification-generation framework that jointly performs relation prediction and explanation generation, and train it with the additional supervision of LLM-generated explanations. Our framework is plug-and-play, enabling easy integration with most existing IDRR models. Experimental results on PDTB demonstrate that our approach significantly improves IDRR performance, while human evaluation further confirms that the generated explanations enhance model interpretability. Furthermore, we validate the generality of our approach on sentiment classification and natural language inference

</details>


### [39] [D-COT: Disciplined Chain-of-Thought Learning for Efficient Reasoning in Small Language Models](https://arxiv.org/abs/2602.21786)
*Shunsuke Ubukata*

Main category: cs.CL

TL;DR: D-CoT框架通过控制标签约束小语言模型的推理过程，解决CoT蒸馏导致的"过思考"问题，在提升性能的同时减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统CoT蒸馏方法会导致小语言模型出现"过度思考"问题，造成性能下降和过多的token消耗，需要一种更结构化的推理训练方法。

Method: 提出Disciplined Chain-of-Thought (D-CoT)框架，使用控制标签（如<TEMP_LOW>用于事实检查，<TEMP_HIGH>用于多视角探索）作为训练时的辅助支架，优化CoT推理轨迹。

Result: 在Qwen3-8B模型上，仅用5,000训练样本，D-CoT将GPQA-diamond准确率提升9.9%，MMLU-Pro (0-shot)提升9.1%，同时显著降低计算成本。模型内化了这种结构化思维，推理时无需控制标签也能保持高性能。

Conclusion: D-CoT通过结构化推理过程有效解决了CoT蒸馏中的"过思考"问题，在提升小语言模型性能的同时减少了计算开销，具有实际应用价值。

Abstract: Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) often induces "overthinking" in Small Language Models (SLMs), leading to performance degradation and excessive token consumption. In this study, we propose Disciplined Chain-of-Thought (D-CoT), a novel framework that enforces a structured reasoning process using control tags -- such as <TEMP_LOW> for fact-checking and <TEMP_HIGH> for multi-perspective exploration -- as auxiliary scaffolding during training. By optimizing the CoT trajectory, D-CoT suppresses reasoning drift and simultaneously achieves token reduction and performance improvement. We demonstrate the efficacy of our approach on Qwen3-8B: with only 5,000 training samples, D-CoT significantly boosts accuracy on GPQA-diamond by 9.9% and MMLU-Pro (0-shot) by 9.1%, while drastically reducing computational costs. Furthermore, we confirm that the model internalizes this disciplined thought structure, maintaining high performance even without explicit control tags during inference.

</details>


### [40] [FewMMBench: A Benchmark for Multimodal Few-Shot Learning](https://arxiv.org/abs/2602.21854)
*Mustafa Dogan,Ilker Kesen,Iacer Calixto,Aykut Erdem,Erkut Erdem*

Main category: cs.CL

TL;DR: FewMMBench是一个用于评估多模态大语言模型在少样本条件下性能的基准测试，涵盖多种多模态理解任务，测试了26个开源模型在零样本、少样本和思维链增强少样本设置下的表现。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在处理交错图像-文本数据方面的进步，评估其少样本学习能力仍然是一个未解决的挑战，需要系统性的评估框架。

Method: 提出了FewMMBench基准，涵盖从属性识别到时序推理的多样化多模态理解任务，系统分析任务类型、模型家族和提示策略。评估了来自6个模型家族的26个开源MLLM，在零样本、少样本和CoT增强少样本设置下进行测试。

Result: 指令调优模型在零样本设置下表现良好，但通过额外演示或思维链推理获益有限甚至出现性能下降。基于检索的演示和增加上下文大小也只带来有限收益。

Conclusion: FewMMBench为诊断和推进多模态大语言模型的少样本能力提供了一个严格的测试平台，揭示了当前模型在少样本学习方面的局限性。

Abstract: As multimodal large language models (MLLMs) advance in handling interleaved image-text data, assessing their few-shot learning capabilities remains an open challenge. In this paper, we introduce FewMMBench, a comprehensive benchmark designed to evaluate MLLMs under few-shot conditions, with a focus on In-Context Learning (ICL) and Chain-of-Thought (CoT) prompting. Covering a diverse suite of multimodal understanding tasks, from attribute recognition to temporal reasoning, FewMMBench enables systematic analysis across task types, model families, and prompting strategies. We evaluate 26 open-weight MLLMs from six model families across zero-shot, few-shot, and CoT-augmented few-shot settings. Our findings reveal that instruction-tuned models exhibit strong zero-shot performance but benefit minimally, or even regress, with additional demonstrations or CoT reasoning. Retrieval-based demonstrations and increased context size also yield limited gains. These results highlight FewMMBench as a rigorous testbed for diagnosing and advancing few-shot capabilities in multimodal LLMs. The data is available at: https://huggingface.co/datasets/mustafaa/FewMMBench

</details>


### [41] [Personalized Graph-Empowered Large Language Model for Proactive Information Access](https://arxiv.org/abs/2602.21862)
*Chia Cheng Chang,An-Zi Yen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 提出一个利用大语言模型和知识图谱的框架，用于主动帮助用户回忆被遗忘的生活经历。


<details>
  <summary>Details</summary>
Motivation: 人们难以回忆所有生活细节且容易混淆事件，现有系统依赖深度学习需要大量训练数据，但个人生活日志数据稀缺且随时间增长，系统需要快速适应新数据。

Method: 使用大语言模型进行主动信息访问，整合个人知识图谱，通过精炼的决策过程增强访问需求检测，框架具有高度灵活性可替换基础模型和修改事实检索方法。

Result: 实验结果表明，该方法能有效识别被遗忘事件，帮助用户更高效地回忆过去经历。

Conclusion: 该框架利用LLMs和知识图谱成功解决了个人生活日志记忆回忆问题，具有灵活性和适应性优势。

Abstract: Since individuals may struggle to recall all life details and often confuse events, establishing a system to assist users in recalling forgotten experiences is essential. While numerous studies have proposed memory recall systems, these primarily rely on deep learning techniques that require extensive training and often face data scarcity due to the limited availability of personal lifelogs. As lifelogs grow over time, systems must also adapt quickly to newly accumulated data. Recently, large language models (LLMs) have demonstrated remarkable capabilities across various tasks, making them promising for personalized applications. In this work, we present a framework that leverages LLMs for proactive information access, integrating personal knowledge graphs to enhance the detection of access needs through a refined decision-making process. Our framework offers high flexibility, enabling the replacement of base models and the modification of fact retrieval methods for continuous improvement. Experimental results demonstrate that our approach effectively identifies forgotten events, supporting users in recalling past experiences more efficiently.

</details>


### [42] [ExpLang: Improved Exploration and Exploitation in LLM Reasoning with On-Policy Thinking Language Selection](https://arxiv.org/abs/2602.21887)
*Changjiang Gao,Zixian Huang,Kaichen Yang,Jiajun Chen,Jixing Li,Shujian Huang*

Main category: cs.CL

TL;DR: ExpLang：一种新颖的LLM后训练流程，通过多语言策略内思考语言选择来改进强化学习中的探索与利用，相比纯英语训练在相同预算下表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型主要在英语上进行强化学习后训练，忽视了多语言思考的潜在优势以及全球用户对母语思考轨迹的需求。

Method: 提出ExpLang后训练流程，将多语言思考语言选择作为强化学习中的动作，通过策略内选择来扩展探索空间并利用非英语优势。

Result: ExpLang在相同训练预算下稳定优于纯英语训练，对已见和未见语言都表现出高思考语言合规性，有效扩展了RL探索空间并提升了利用效果。

Conclusion: 该方法与大多数RL算法正交，为利用多语言性改进大型推理模型开辟了新视角。

Abstract: Current large reasoning models (LRMs) have shown strong ability on challenging tasks after reinforcement learning (RL) based post-training. However, previous work mainly focuses on English reasoning in expectation of the strongest performance, despite the demonstrated potential advantage of multilingual thinking, as well as the requirement for native thinking traces by global users. In this paper, we propose ExpLang, a novel LLM post-training pipeline that enables on-policy thinking language selection to improve exploration and exploitation during RL with the use of multiple languages. The results show that our method steadily outperforms English-only training with the same training budget, while showing high thinking language compliance for both seen and unseen languages. Analysis shows that, by enabling on-policy thinking language selection as an action during RL, ExpLang effectively extends the RL exploration space with diversified language preference and improves the RL exploitation outcome with leveraged non-English advantage. The method is orthogonal to most RL algorithms and opens up a new perspective on using multilinguality to improve LRMs.

</details>


### [43] [Small Wins Big: Comparing Large Language Models and Domain Fine-Tuned Models for Sarcasm Detection in Code-Mixed Hinglish Text](https://arxiv.org/abs/2602.21933)
*Bitan Majumder,Anirban Sen*

Main category: cs.CL

TL;DR: 在低资源代码混合文本中，经过领域适应微调的较小DistilBERT模型在讽刺检测任务上优于大型语言模型


<details>
  <summary>Details</summary>
Motivation: 多语言和代码混合环境中的讽刺检测面临结构变化、非正式表达和低资源语言可用性等挑战，需要探索有效的解决方案。

Method: 比较了Llama 3.1、Mistral、Gemma 3、Phi-4四个大型语言模型与经过微调的DistilBERT模型在代码混合Hinglish文本中的讽刺检测性能，使用少量LLM生成的代码混合数据进行微调。

Result: 经过顺序微调的DistilBERT模型达到84%的整体准确率，在零样本和少样本设置下均优于所有大型语言模型。

Conclusion: 在低资源和数据稀缺环境下，对较小Transformer模型进行领域适应微调可能比通用大型语言模型推理在讽刺检测任务上表现更优。

Abstract: Sarcasm detection in multilingual and code-mixed environments remains a challenging task for natural language processing models due to structural variations, informal expressions, and low-resource linguistic availability. This study compares four large language models, Llama 3.1, Mistral, Gemma 3, and Phi-4, with a fine-tuned DistilBERT model for sarcasm detection in code-mixed Hinglish text. The results indicate that the smaller, sequentially fine-tuned DistilBERT model achieved the highest overall accuracy of 84%, outperforming all of the LLMs in zero and few-shot set ups, using minimal LLM generated code-mixed data used for fine-tuning. These findings indicate that domain-adaptive fine-tuning of smaller transformer based models may significantly improve sarcasm detection over general LLM inference, in low-resource and data scarce settings.

</details>


### [44] [MERRY: Semantically Decoupled Evaluation of Multimodal Emotional and Role Consistencies of Role-Playing Agents](https://arxiv.org/abs/2602.21941)
*Zhenyu Wang,Xiaofen Xing,Yirong Chen,Xiangmin Xu*

Main category: cs.CL

TL;DR: 提出MERRY框架，用于解耦评估多模态角色扮演代理的情感一致性和角色一致性，通过双向证据查找任务改进LLM-as-Judge评估，揭示了现有模型在情感模板化、简化及负向情感处理上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态角色扮演代理评估方法存在两个问题：1) 将语义评估与模态生成纠缠，导致错误归因模糊；2) 过度依赖人工判断。需要一种解耦的、更可靠的评估框架。

Method: 提出MERRY框架，包含5个情感一致性指标和3个角色一致性指标。将传统主观评分方法转化为双向证据查找任务，显著提升LLM-as-Judge评估的人类一致性。

Result: 实证评估发现：1) 在合成数据集上训练会降低情感一致性，真实数据集训练则提升；2) 现有模型存在情感模板化和简化问题，呈现正向偏见，在细粒度负向情感上表现瓶颈；3) 简单提示方法强化弱模型但限制强模型，简单微调方法角色泛化能力差。

Conclusion: MERRY框架为多模态角色扮演代理提供了语义解耦的评估方法，揭示了现有方法的局限性，为未来改进提供了方向。代码和数据集已开源。

Abstract: Multimodal Role-Playing Agents (MRPAs) are attracting increasing attention due to their ability to deliver more immersive multimodal emotional interactions. However, existing studies still rely on pure textual benchmarks to evaluate the text responses of MRPAs, while delegating the assessment of their multimodal expressions solely to modality-synthesis metrics. This evaluation paradigm, on the one hand, entangles semantic assessment with modality generation, leading to ambiguous error attribution, and on the other hand remains constrained by the heavy reliance on human judgment. To this end, we propose MERRY, a semantically decoupled evaluation framework for assessing Multimodal Emotional and Role consistencies of Role-playing agents. This framework introduce five refined metrics for EC and three for RC. Notably, we transform the traditional subjective scoring approach into a novel bidirectional-evidence-finding task, significantly improving the human agreement of LLM-as-Judge evaluations. Based on MERRY, we conduct extensive evaluations. Our empirical results primarily reveal that: (1) Training on synthetic datasets tends to reduce emotional consistency, whereas training on real-world datasets improves it; (2) Existing models suffer from emotional templatization and simplification, exhibiting positive-bias and performance bottleneck in fine-grained negative emotions; (3) Simple prompting method strengthens the weak models but constrains the strong ones, while simple fine-tuning method suffers from poor role generalization. Codes and dataset are available.

</details>


### [45] [Large Language Models are Algorithmically Blind](https://arxiv.org/abs/2602.21947)
*Sohan Venkatesh,Ashish Mahendran Kurapath,Tejas Melkote*

Main category: cs.CL

TL;DR: LLMs在算法推理方面存在系统性失败，表现出算法盲视，即虽然拥有广泛的陈述性知识，但无法进行校准的程序性预测。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型展现出广泛的知识广度，但其对计算过程的推理能力尚不清楚。对于依赖LLMs指导算法选择和部署的从业者来说，理解这一能力差距至关重要。

Method: 使用因果发现作为测试平台，评估八个前沿LLM，与基于大规模算法执行得出的真实基准进行比较。

Result: LLMs表现出系统性、近乎完全的失败：模型产生的置信区间远宽于真实置信区间，但多数情况下仍无法包含真实的算法均值；大多数模型表现比随机猜测更差；最佳模型的边际超随机表现最符合基准记忆而非原则性推理。

Conclusion: 这种失败被称为"算法盲视"，反映了算法陈述性知识与校准程序性预测之间的根本差距。

Abstract: Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this limitation using causal discovery as a testbed and evaluate eight frontier LLMs against ground truth derived from large-scale algorithm executions and find systematic, near-total failure. Models produce ranges far wider than true confidence intervals yet still fail to contain the true algorithmic mean in the majority of instances; most perform worse than random guessing and the marginal above-random performance of the best model is most consistent with benchmark memorization rather than principled reasoning. We term this failure algorithmic blindness and argue it reflects a fundamental gap between declarative knowledge about algorithms and calibrated procedural prediction.

</details>


### [46] [MEDSYN: Benchmarking Multi-EviDence SYNthesis in Complex Clinical Cases for Multimodal Large Language Models](https://arxiv.org/abs/2602.21950)
*Boqi Chen,Xudong Liu,Jiachuan Peng,Marianne Frey-Marti,Bang Zheng,Kyle Lam,Lin Li,Jianing Qiu*

Main category: cs.CL

TL;DR: MEDSYN是一个多语言、多模态的临床复杂病例基准，包含多达7种视觉临床证据类型，用于评估MLLMs的鉴别诊断生成和最终诊断选择能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法充分捕捉真实临床复杂性，需要开发更全面的评估框架来测试MLLMs在实际医疗场景中的表现。

Method: 引入MEDSYN基准，包含多语言多模态临床病例，每个病例最多7种视觉临床证据类型。评估18个MLLMs在鉴别诊断生成和最终诊断选择上的表现，并进行消融分析。

Result: 顶级模型在鉴别诊断生成上常达到或超越人类专家水平，但所有MLLMs在鉴别诊断-最终诊断性能差距上远大于专家临床医生，表明在异质临床证据类型合成方面存在失败模式。

Conclusion: MLLMs在临床推理中存在异质证据合成缺陷，过度依赖文本临床证据且存在跨模态利用差距。引入证据敏感性量化这一差距，并展示如何指导干预以提高模型性能。

Abstract: Multimodal large language models (MLLMs) have shown great potential in medical applications, yet existing benchmarks inadequately capture real-world clinical complexity. We introduce MEDSYN, a multilingual, multimodal benchmark of highly complex clinical cases with up to 7 distinct visual clinical evidence (CE) types per case. Mirroring clinical workflow, we evaluate 18 MLLMs on differential diagnosis (DDx) generation and final diagnosis (FDx) selection. While top models often match or even outperform human experts on DDx generation, all MLLMs exhibit a much larger DDx--FDx performance gap compared to expert clinicians, indicating a failure mode in synthesis of heterogeneous CE types. Ablations attribute this failure to (i) overreliance on less discriminative textual CE ($\it{e.g.}$, medical history) and (ii) a cross-modal CE utilization gap. We introduce Evidence Sensitivity to quantify the latter and show that a smaller gap correlates with higher diagnostic accuracy. Finally, we demonstrate how it can be used to guide interventions to improve model performance. We will open-source our benchmark and code.

</details>


### [47] [RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning](https://arxiv.org/abs/2602.21951)
*Bo Xue,Yuan Jin,Luoyi Fu,Jiaxin Ding,Xinbing Wang*

Main category: cs.CL

TL;DR: RADAR将知识图谱推理从生成式模式匹配重构为判别式关系推理，通过强化学习实现实体可分性，在表示空间直接推理，提升泛化能力并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的知识图谱推理方法容易记忆表面共现模式而非学习真正的关系语义，限制了分布外泛化能力。需要解决生成式范式对表面模式记忆的问题。

Method: 将知识图谱推理重新定义为判别式实体选择任务，使用强化学习强制实现相对实体可分性，避免简单的标记似然模仿。利用这种可分性，在表示空间直接进行推理。

Result: 在四个基准测试中，RADAR在链接预测和三重分类任务上相比强LLM基线获得5-6%的相对提升，中间表示的任务相关互信息增加了62.9%，表明更鲁棒和可迁移的关系推理能力。

Conclusion: RADAR通过将知识图谱推理重构为判别式关系推理，有效解决了生成式方法记忆表面模式的问题，提升了模型的泛化能力和推理鲁棒性，为基于LLM的知识图谱推理提供了新方向。

Abstract: Knowledge graph reasoning (KGR) infers missing facts, with recent advances increasingly harnessing the semantic priors and reasoning abilities of Large Language Models (LLMs). However, prevailing generative paradigms are prone to memorizing surface-level co-occurrences rather than learning genuine relational semantics, limiting out-of-distribution generalization. To address this, we propose RADAR, which reformulates KGR from generative pattern matching to discriminative relational reasoning. We recast KGR as discriminative entity selection, where reinforcement learning enforces relative entity separability beyond token-likelihood imitation. Leveraging this separability, inference operates directly in representation space, ensuring consistency with the discriminative optimization and bypassing generation-induced hallucinations. Across four benchmarks, RADAR achieves 5-6% relative gains on link prediction and triple classification over strong LLM baselines, while increasing task-relevant mutual information in intermediate representations by 62.9%, indicating more robust and transferable relational reasoning.

</details>


### [48] [CxMP: A Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models](https://arxiv.org/abs/2602.21978)
*Miyu Oba,Saku Sugawara*

Main category: cs.CL

TL;DR: CxMP基准测试评估语言模型对构式（形式-意义配对）的理解能力，发现即使大型语言模型在构式理解方面仍存在局限。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注语法可接受性判断，而对语言模型理解语法形式所传达意义的能力关注不足。需要评估语言模型如何将形式与意义整合起来。

Method: 基于构式语法理论，创建CxMP基准，通过受控的最小对设计，评估9种构式类型（如let-alone、致使运动、双及物构式）的语义关系理解能力。

Result: 句法能力出现较早，但构式理解发展较慢，即使在大型语言模型中仍然有限。模型在整合形式与意义方面存在持续差距。

Conclusion: CxMP揭示了语言模型在构式理解方面的不足，为研究语言模型的构式理解和学习轨迹提供了框架，有助于更全面地评估语言能力。

Abstract: Recent work has examined language models from a linguistic perspective to better understand how they acquire language. Most existing benchmarks focus on judging grammatical acceptability, whereas the ability to interpret meanings conveyed by grammatical forms has received much less attention. We introduce the Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models (CxMP), a benchmark grounded in Construction Grammar that treats form-meaning pairings, or constructions, as fundamental linguistic units. CxMP evaluates whether models can interpret the semantic relations implied by constructions, using a controlled minimal-pair design across nine construction types, including the let-alone, caused motion, and ditransitive constructions. Our results show that while syntactic competence emerges early, constructional understanding develops more gradually and remains limited even in large language models (LLMs). CxMP thus reveals persistent gaps in how language models integrate form and meaning, providing a framework for studying constructional understanding and learning trajectories in language models.

</details>


### [49] [A Diversity Diet for a Healthier Model: A Case Study of French ModernBERT](https://arxiv.org/abs/2602.22014)
*Louis Estève,Christophe Servan,Thomas Lavergne,Agata Savary*

Main category: cs.CL

TL;DR: 该研究探讨了多样性对ModernBERT预训练的影响，发现多样性驱动的采样方法能在减少预训练数据集规模的同时保持或提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的transformer模型（如ModernBERT）使用非常大的预训练数据集，但这些数据集通常以规模而非多样性为导向。这促使研究者探索多样性对ModernBERT预训练的影响，特别是为了在减少预训练数据集规模的同时保持可比性能。

Method: 研究采用多样性驱动的采样算法，比较不同采样方法的效果，旨在从大规模数据集中选择最具代表性的子集。实验通过减少预训练数据集规模（从2.4B tokens减少到150M tokens）来评估多样性采样的效果。

Result: 研究发现：1）多样性驱动的采样在某些任务中比随机采样能获得10个点的性能提升；2）使用多样性驱动的150M tokens数据集预训练483小时的模型，与使用随机采样的2.4B tokens数据集预训练1,775小时的模型性能相当。

Conclusion: 多样性驱动的采样方法能显著减少预训练数据集的规模，同时保持模型性能，这为更高效、资源节约的预训练提供了有效策略。

Abstract: Diversity has been gaining interest in the NLP community in recent years. At the same time, state-of-the-art transformer models such as ModernBERT use very large pre-training datasets, which are driven by size rather than by diversity. This summons for an investigation of the impact of diversity on the ModernBERT pre-training. We do so in this study, with the express intent of reducing pre-training dataset size, while retaining at least comparable performance. We compare diversity-driven sampling algorithms, so as to pick the best one. We find that diversity-driven sampling allows in some tasks to gain 10 points relative to randomly-sampled pre-training data of commensurate size. We also see that a model pre-trained for 483h on a diversity-driven dataset of 150M tokens can yield a commensurate performance to a model pre-trained for 1,775h on a randomly-driven dataset of 2.4B tokens.

</details>


### [50] [DLT-Corpus: A Large-Scale Text Collection for the Distributed Ledger Technology Domain](https://arxiv.org/abs/2602.22045)
*Walter Hernandez Cruz,Peter Devine,Nikhil Vadgama,Paolo Tasca,Jiahua Xu*

Main category: cs.CL

TL;DR: DLT-Corpus是最大的分布式账本技术领域文本语料库，包含29.8亿token和2212万文档，涵盖学术论文、专利和社交媒体。研究揭示了技术从科学文献到专利再到社交媒体的传播模式，并发布了相关工具和预训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有NLP资源主要关注加密货币价格预测和智能合约，缺乏对DLT领域特定语言的深入探索，而该领域市值约3万亿美元且技术发展迅速。

Method: 构建了包含科学文献（37,440篇）、美国专利（49,023项）和社交媒体（2200万条帖子）的DLT-Corpus语料库，并开发了领域适应模型LedgerBERT。

Result: 技术遵循从科学文献到专利再到社交媒体的传统传播模式。社交媒体情绪即使在熊市也保持乐观，而科学和专利活动与市场波动无关，跟踪整体市场扩张，形成良性循环。

Conclusion: DLT-Corpus填补了领域特定语言资源空白，揭示了技术传播模式和市场-创新关系，为DLT研究提供了重要资源。公开了语料库、LedgerBERT模型及相关工具代码。

Abstract: We introduce DLT-Corpus, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: 2.98 billion tokens from 22.12 million documents spanning scientific literature (37,440 publications), United States Patent and Trademark Office (USPTO) patents (49,023 filings), and social media (22 million posts). Existing Natural Language Processing (NLP) resources for DLT focus narrowly on cryptocurrencies price prediction and smart contracts, leaving domain-specific language under explored despite the sector's ~$3 trillion market capitalization and rapid technological evolution.
  We demonstrate DLT-Corpus' utility by analyzing technology emergence patterns and market-innovation correlations. Findings reveal that technologies originate in scientific literature before reaching patents and social media, following traditional technology transfer patterns. While social media sentiment remains overwhelmingly bullish even during crypto winters, scientific and patent activity grow independently of market fluctuations, tracking overall market expansion in a virtuous cycle where research precedes and enables economic growth that funds further innovation.
  We publicly release the full DLT-Corpus; LedgerBERT, a domain-adapted model achieving 23% improvement over BERT-base on a DLT-specific Named Entity Recognition (NER) task; and all associated tools and code.

</details>


### [51] [Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models](https://arxiv.org/abs/2602.22072)
*Christian Nickel,Laura Schrewe,Florian Mai,Lucie Flek*

Main category: cs.CL

TL;DR: LLMs的心智理论能力在任务扰动下急剧下降，质疑其具备稳健的心智理论能力。思维链提示总体上能忠实提升性能，但对某些扰动类别反而降低准确性，需要选择性应用。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型是否真正具备心智理论能力，研究其心智理论能力的稳健性，并检验思维链提示是否能提升性能并解释模型的决策过程。

Method: 引入手工制作的丰富注释的心智理论数据集，包括经典和扰动的错误信念任务、相应的有效推理链空间、后续推理忠实性、任务解决方案，并提出评估推理链正确性和最终答案对推理轨迹忠实度的指标。

Result: 所有评估的LLMs在任务扰动下心智理论能力急剧下降，质疑其具备任何稳健形式的心智理论能力。思维链提示总体上能忠实提升心智理论性能，但令人惊讶的是，对于某些扰动类别反而降低了准确性。

Conclusion: LLMs缺乏稳健的心智理论能力，思维链提示需要选择性应用，不能盲目依赖。需要进一步研究心智理论能力的本质和LLMs的认知能力。

Abstract: Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and examines the potential of Chain-of-Thought prompting (CoT) to enhance performance and explain the LLM's decision. We introduce a handcrafted, richly annotated ToM dataset, including classic and perturbed false belief tasks, the corresponding spaces of valid reasoning chains for correct task completion, subsequent reasoning faithfulness, task solutions, and propose metrics to evaluate reasoning chain correctness and to what extent final answers are faithful to reasoning traces of the generated CoT. We show a steep drop in ToM capabilities under task perturbation for all evaluated LLMs, questioning the notion of any robust form of ToM being present. While CoT prompting improves the ToM performance overall in a faithful manner, it surprisingly degrades accuracy for some perturbation classes, indicating that selective application is necessary.

</details>


### [52] [Confidence-Driven Multi-Scale Model Selection for Cost-Efficient Inference](https://arxiv.org/abs/2602.22090)
*Bo-Wei Chen,Chung-Chi Chen,An-Zi Yen*

Main category: cs.CL

TL;DR: 提出基于置信度的动态模型选择策略，通过评估模型处理任务的置信度和响应准确性，将简单任务保留在小模型，复杂任务委托给大模型，在保证可靠性的同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言任务中表现出色，但模型越大计算成本越高。为了在保持性能的同时降低计算开销，需要一种智能的模型选择机制。

Method: 提出置信度驱动的动态模型选择策略，通过评估模型对任务处理的置信度（知道正确答案的可能性）和响应准确性（回答正确的概率），将高置信度且可能正确的任务保留在当前模型，将不确定或复杂的任务委托给更大的模型。

Result: 在MMLU基准测试中，该方法达到了与最大模型相当的准确率，同时将计算成本降低了20%到40%。应用于GPT-4o API调用时，减少了约60%的token使用量，显著提高了成本效率。

Conclusion: 基于置信度的模型选择策略在资源受限的实际部署场景（如边缘设备和商业API应用）中具有巨大潜力，能够在保持性能的同时显著降低计算成本。

Abstract: Large Language Models (LLMs) have revolutionized inference across diverse natural language tasks, with larger models performing better but at higher computational costs. We propose a confidence-driven strategy that dynamically selects the most suitable model based on confidence estimates. By assessing a model's confidence in handling the task and response accuracy, tasks that are likely to be solved correctly are retained, while more uncertain or complex cases are delegated to a larger model, ensuring reliability while minimizing computation. Specifically, we evaluate a model's likelihood of knowing the correct answer and the probability that its response is accurate. Experiments on the Massive Multitask Language Understanding (MMLU) benchmark show that our approach achieves accuracy comparable to the largest model while reducing computational costs by 20\% to 40\%. When applied to GPT-4o API calls, it reduces token usage by approximately 60\%, further improving cost efficiency. These findings indicate the potential of confidence-based model selection to enhance real-world LLM deployment, particularly in resource-constrained settings such as edge devices and commercial API applications.

</details>


### [53] [IndicIFEval: A Benchmark for Verifiable Instruction-Following Evaluation in 14 Indic Languages](https://arxiv.org/abs/2602.22125)
*Thanmay Jayakumar,Mohammed Safi Ur Rahman Khan,Raj Dabre,Ratish Puduppully,Anoop Kunchukuttan*

Main category: cs.CL

TL;DR: IndicIFEval是一个评估LLM在14种印度语言上约束生成能力的基准，包含约800个/语言的自动可验证规则指令，发现模型在格式约束上表现良好，但在词汇和跨语言任务上存在显著困难，印度语言整体表现远落后于英语。


<details>
  <summary>Details</summary>
Motivation: 当前指令跟随基准主要集中于英语，缺乏对印度语言（数亿使用者）的评估，因此需要构建一个多语言基准来填补这一关键评估空白。

Method: 创建IndicIFEval基准，包含两个互补子集：1) IndicIFEval-Ground（从IFEval翻译并针对印度语境本地化的提示）；2) IndicIFEval-Ground（基于印度本土内容合成的生成指令）。每个语言约800个人工验证示例，使用自动可验证的基于规则的指令。

Result: 对主要开源和专有模型进行全面评估，发现模型能很好地遵循格式约束，但在词汇和跨语言任务上表现显著较差。尽管高资源语言有所进步，但整个印度语言家族的指令跟随能力仍显著落后于英语。

Conclusion: 需要更多努力来提升LLM在印度语言上的指令跟随能力，作者发布IndicIFEval基准和评估脚本来支持多语言约束生成的进展。

Abstract: Instruction-following benchmarks remain predominantly English-centric, leaving a critical evaluation gap for the hundreds of millions of Indic language speakers. We introduce IndicIFEval, a benchmark evaluating constrained generation of LLMs across 14 Indic languages using automatically verifiable, rule-based instructions. It comprises around 800 human-verified examples per language spread across two complementary subsets: IndicIFEval-Ground, translated prompts from IFEval (Zhou et al., 2023) carefully localized for Indic contexts, and IndicIFEval-Ground, synthetically generated instructions grounded in native Indic content. We conduct a comprehensive evaluation of major open-weight and proprietary models spanning both reasoning and non-reasoning models. While models maintain strong adherence to formatting constraints, they struggle significantly with lexical and cross-lingual tasks -- and despite progress in high-resource languages, instruction-following across the broader Indic family lags significantly behind English. We release IndicIFEval and its evaluation scripts to support progress on multilingual constrained generation (http://github.com/ai4bharat/IndicIFEval).

</details>


### [54] [Dynamic Personality Adaptation in Large Language Models via State Machines](https://arxiv.org/abs/2602.22157)
*Leon Pielage,Ole Hätscher,Mitja Back,Bernhard Marschall,Benjamin Risse*

Main category: cs.CL

TL;DR: 提出一个模型无关的动态人格模拟框架，使用状态机表示潜在人格状态，通过对话上下文动态调整转换概率，实现LLMs在复杂交互场景中的适应性人格表达。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型无法根据对话动态调整其人格表达，这限制了它们在复杂交互场景中的表现。需要一种能够使LLMs在对话中动态适应和调整人格表达的方法。

Method: 提出模型无关的动态人格模拟框架：1) 使用状态机表示潜在人格状态；2) 通过对话上下文动态调整状态转换概率；3) 设计模块化的人格评分管道，沿潜在轴评估对话；4) 将评分作为动态状态变量，系统性地重新配置系统提示，引导行为对齐。

Result: 在医学教育场景中实现人际圈模型(IPC)评估：1) 系统成功根据用户输入调整人格状态；2) 能够影响用户行为，促进降级训练；3) 使用轻量级微调分类器时，评分管道仍保持相当的精度。

Conclusion: 该工作证明了模块化、人格自适应架构在教育、客户支持和更广泛的人机交互领域的可行性，为LLMs在复杂交互场景中的适应性人格表达提供了有效解决方案。

Abstract: The inability of Large Language Models (LLMs) to modulate their personality expression in response to evolving dialogue dynamics hinders their performance in complex, interactive contexts. We propose a model-agnostic framework for dynamic personality simulation that employs state machines to represent latent personality states, where transition probabilities are dynamically adapted to the conversational context. Part of our architecture is a modular pipeline for continuous personality scoring that evaluates dialogues along latent axes while remaining agnostic to the specific personality models, their dimensions, transition mechanisms, or LLMs used. These scores function as dynamic state variables that systematically reconfigure the system prompt, steering behavioral alignment throughout the interaction.We evaluate this framework by operationalizing the Interpersonal Circumplex (IPC) in a medical education setting. Results demonstrate that the system successfully adapts its personality state to user inputs, but also influences user behavior, thereby facilitating de-escalation training. Notably, the scoring pipeline maintains comparable precision even when utilizing lightweight, fine-tuned classifiers instead of large-scale LLMs. This work demonstrates the feasibility of modular, personality-adaptive architectures for education, customer support, and broader human-computer interaction.

</details>


### [55] [DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs](https://arxiv.org/abs/2602.22175)
*Xi Ye,Wuwei Zhang,Fangcong Yin,Howard Yen,Danqi Chen*

Main category: cs.CL

TL;DR: DySCO是一种无需训练的推理算法，通过检索头动态调整注意力权重，提升大语言模型在长上下文推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管现代语言模型支持越来越长的上下文窗口，但随着输入长度增加，其准确性往往下降。模型在解码过程中难以保持注意力与最相关上下文对齐，这是长上下文推理的主要挑战。

Method: DySCO利用检索头（专门用于长上下文检索的注意力头子集），在每个解码步骤识别任务相关标记并显式提升其权重。该方法动态调整生成过程中的注意力分布，无需额外训练，可直接应用于现成语言模型。

Result: 在多个指令微调和推理模型上，DySCO在具有挑战性的长上下文推理基准测试中表现一致提升，在128K上下文长度下，MRCR和LongBenchV2上相对增益高达25%，计算开销适度。

Conclusion: DySCO通过动态注意力重新缩放和检索头引导选择，有效提升长上下文推理性能，同时为解码时注意力行为提供可解释性洞察，是一种实用且高效的长上下文推理增强方法。

Abstract: Understanding and reasoning over long contexts is a crucial capability for language models (LMs). Although recent models support increasingly long context windows, their accuracy often deteriorates as input length grows. In practice, models often struggle to keep attention aligned with the most relevant context throughout decoding. In this work, we propose DySCO, a novel decoding algorithm for improving long-context reasoning. DySCO leverages retrieval heads--a subset of attention heads specialized for long-context retrieval--to identify task-relevant tokens at each decoding step and explicitly up-weight them. By doing so, DySCO dynamically adjusts attention during generation to better utilize relevant context. The method is training-free and can be applied directly to any off-the-shelf LMs. Across multiple instruction-tuned and reasoning models, DySCO consistently improves performance on challenging long-context reasoning benchmarks, yielding relative gains of up to 25% on MRCR and LongBenchV2 at 128K context length with modest additional compute. Further analysis highlights the importance of both dynamic attention rescaling and retrieval-head-guided selection for the effectiveness of the method, while providing interpretability insights into decoding-time attention behavior. Our code is available at https://github.com/princeton-pli/DySCO.

</details>


### [56] [Improving Parametric Knowledge Access in Reasoning Language Models](https://arxiv.org/abs/2602.22193)
*Melody Ma,John Hewitt*

Main category: cs.CL

TL;DR: 研究发现语言模型在访问自身参数知识时的推理能力不足，通过简单提示和强化学习训练可显著提升知识回忆表现。


<details>
  <summary>Details</summary>
Motivation: 语言模型在存储世界知识方面表现出色，但通过推理访问这些参数知识的能力可能不足。研究发现模型默认不会生成最佳的知识推理，需要探索如何优化模型在参数知识访问方面的推理能力。

Method: 1. 通过"逐步思考"提示评估模型知识回忆能力；2. 使用TriviaQA数据集进行强化学习训练，以世界知识问答作为可验证的奖励信号，优化模型在参数知识上的推理能力。

Result: 1. 简单"逐步思考"提示在知识回忆任务上带来统计显著改进，但在数学任务上没有；2. 在TriviaQA上强化学习训练后性能提升9.9%；3. 训练后模型在Natural Questions、HotpotQA、SimpleQA和StrategyQA上分别提升4.2%、2.1%、0.6%和3.0%。

Conclusion: 推理模型在参数知识访问方面未充分优化，但可以通过简单提示和针对性的强化学习训练显著改善其知识回忆能力。

Abstract: We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trained via reinforcement learning to produce reasoning traces on tasks such as mathematics, they may not reason well for accessing their own world knowledge. We first find that models do not generate their best world knowledge reasoning by default: adding a simple "think step-by-step" cue demonstrates statistically significant improvement in knowledge recall but not math. Motivated by this, we propose training models to reason over their parametric knowledge using world-knowledge question answering as a verifiable reward. After reinforcement learning on TriviaQA (+9.9%), performance also improves on Natural Questions, HotpotQA, SimpleQA, and StrategyQA by 4.2%, 2.1%, 0.6%, and 3.0%, respectively. Reasoning models are under-optimized for parametric knowledge access, but can be easily trained to reason better.

</details>


### [57] [SumTablets: A Transliteration Dataset of Sumerian Tablets](https://arxiv.org/abs/2602.22200)
*Cole Simmons,Richard Diehl Martinez,Dan Jurafsky*

Main category: cs.CL

TL;DR: SumTablets数据集将91,606块苏美尔楔形文字板的Unicode表示与Oracc提供的转写配对，支持NLP方法应用于苏美尔文字转写任务，并展示了基于Transformer的转写模型的潜力。


<details>
  <summary>Details</summary>
Motivation: 虽然已有大量苏美尔文字转写数据在线发布，但缺乏将转写与楔形文字数字表示配对的全面数据集，阻碍了现代NLP方法在苏美尔文字转写任务中的应用。

Method: 通过预处理和标准化Oracc转写数据，将每个读音映射回源字形的Unicode表示，并使用特殊标记保留并行结构信息（如表面、换行、破损段），构建了包含91,606块楔形文字板的SumTablets数据集。

Result: 微调的自回归语言模型在字符级F-score上达到97.55，展示了基于Transformer的转写模型在帮助专家快速验证生成转写方面的潜力，而非手动逐块转写。

Conclusion: SumTablets数据集填补了苏美尔楔形文字转写研究的数据空白，为应用现代NLP方法提供了基础，并展示了深度学习模型在该任务上的有效性和应用前景。

Abstract: Sumerian transliteration is a conventional system for representing a scholar's interpretation of a tablet in the Latin script. Thanks to visionary digital Assyriology projects such as ETCSL, CDLI, and Oracc, a large number of Sumerian transliterations have been published online, and these data are well-structured for a variety of search and analysis tasks. However, the absence of a comprehensive, accessible dataset pairing transliterations with a digital representation of the tablet's cuneiform glyphs has prevented the application of modern Natural Language Processing (NLP) methods to the task of Sumerian transliteration.
  To address this gap, we present SumTablets, a dataset pairing Unicode representations of 91,606 Sumerian cuneiform tablets (totaling 6,970,407 glyphs) with the associated transliterations published by Oracc. We construct SumTablets by first preprocessing and standardizing the Oracc transliterations before mapping each reading back to the Unicode representation of the source glyph. Further, we retain parallel structural information (e.g., surfaces, newlines, broken segments) through the use of special tokens. We release SumTablets as a Hugging Face Dataset (CC BY 4.0) and open source data preparation code via GitHub.
  Additionally, we leverage SumTablets to implement and evaluate two transliteration baselines: (1) weighted sampling from a glyph's possible readings, and (2) fine-tuning an autoregressive language model. Our fine-tuned language model achieves an average transliteration character-level F-score (chrF) of 97.55, demonstrating the immediate potential of transformer-based transliteration models in allowing experts to rapidly verify generated transliterations rather than manually transliterating tablets one-by-one.

</details>


### [58] [Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets](https://arxiv.org/abs/2602.22207)
*Hanna Yukhymenko,Anton Alexandrov,Martin Vechev*

Main category: cs.CL

TL;DR: 提出全自動框架提升多語LLM評估的可靠性，通過改進翻譯質量解決現有基準翻譯中的語義漂移和上下文丟失問題


<details>
  <summary>Details</summary>
Motivation: 目前多語大型語言模型評估的可靠性受到翻譯基準質量不一致的影響，現有資源存在語義漂移和上下文丟失問題，導致誤導性的性能指標

Method: 開發全自動框架，採用測試時計算擴展策略，特別是Universal Self-Improvement (USI)和提出的多輪排名方法T-RANK，實現高質量數據集和基準翻譯

Result: 將流行基準翻譯成八種東歐和南歐語言，評估顯示翻譯質量超越現有資源，使用基於參考的指標和LLM-as-a-judge驗證了更準確的下游模型評估

Conclusion: 提出的框架能夠確保基準在本地化過程中保留原始任務結構和語言細微差別，發布框架和改進的基準以促進穩健且可重現的多語AI發展

Abstract: The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies, specifically Universal Self-Improvement (USI) and our proposed multi-round ranking method, T-RANK, allows for significantly higher quality outputs compared to traditional pipelines. Our framework ensures that benchmarks preserve their original task structure and linguistic nuances during localization. We apply this approach to translate popular benchmarks and datasets into eight Eastern and Southern European languages (Ukrainian, Bulgarian, Slovak, Romanian, Lithuanian, Estonian, Turkish, Greek). Evaluations using both reference-based metrics and LLM-as-a-judge show that our translations surpass existing resources, resulting in more accurate downstream model assessment. We release both the framework and the improved benchmarks to facilitate robust and reproducible multilingual AI development.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [59] [Revisiting Text Ranking in Deep Research](https://arxiv.org/abs/2602.21456)
*Chuan Meng,Litu Ou,Sean MacAvaney,Jeff Dalton*

Main category: cs.IR

TL;DR: 该论文系统分析了深度研究任务中信息检索文本排序方法的有效性，从检索单元、管道配置和查询特征三个角度进行了实验评估。


<details>
  <summary>Details</summary>
Motivation: 尽管搜索在深度研究中扮演关键角色，但黑盒网络搜索API阻碍了对搜索组件的系统分析，使得文本排序方法在深度研究中的行为不明确。需要填补这一研究空白。

Method: 在BrowseComp-Plus深度研究数据集上，评估了2个开源智能体、5个检索器和3个重排序器，从检索单元（文档vs段落）、管道配置（不同检索器、重排序器、重排序深度）和查询特征（智能体生成查询与文本排序器训练查询的差异）三个角度进行分析。

Result: 发现智能体生成的查询通常遵循网络搜索风格语法，偏好词汇检索、学习稀疏检索和多向量检索；段落级单元在有限上下文窗口中更高效；重排序非常有效；将智能体查询转换为自然语言问题能显著减少查询不匹配问题。

Conclusion: 该研究为深度研究任务中的信息检索文本排序方法提供了系统分析框架和实用指导，揭示了不同配置对检索效果的影响，并提出了优化查询匹配的有效方法。

Abstract: Deep research has emerged as an important task that aims to address hard queries through extensive open-web exploration. To tackle it, most prior work equips large language model (LLM)-based agents with opaque web search APIs, enabling agents to iteratively issue search queries, retrieve external evidence, and reason over it. Despite search's essential role in deep research, black-box web search APIs hinder systematic analysis of search components, leaving the behaviour of established text ranking methods in deep research largely unclear. To fill this gap, we reproduce a selection of key findings and best practices for IR text ranking methods in the deep research setting. In particular, we examine their effectiveness from three perspectives: (i) retrieval units (documents vs. passages), (ii) pipeline configurations (different retrievers, re-rankers, and re-ranking depths), and (iii) query characteristics (the mismatch between agent-issued queries and the training queries of text rankers). We perform experiments on BrowseComp-Plus, a deep research dataset with a fixed corpus, evaluating 2 open-source agents, 5 retrievers, and 3 re-rankers across diverse setups. We find that agent-issued queries typically follow web-search-style syntax (e.g., quoted exact matches), favouring lexical, learned sparse, and multi-vector retrievers; passage-level units are more efficient under limited context windows, and avoid the difficulties of document length normalisation in lexical retrieval; re-ranking is highly effective; translating agent-issued queries into natural-language questions significantly bridges the query mismatch.

</details>


### [60] [Revisiting RAG Retrievers: An Information Theoretic Benchmark](https://arxiv.org/abs/2602.21553)
*Wenqing Zheng,Dmitri Kalaev,Noah Fatsi,Daniel Barcklow,Owen Reinert,Igor Melnyk,Senthil Kumar,C. Bayan Bruss*

Main category: cs.IR

TL;DR: MIGRASCOPE是一个基于互信息的RAG检索器分析框架，通过信息理论和统计估计的量化指标来评估检索器的质量、冗余性、协同效应和边际贡献，发现精心选择的检索器集成能超越单一检索器。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统依赖检索器提供相关上下文，但存在多种基于不同排序原理的检索器（如词法匹配、密集嵌入、图引用），缺乏对这些机制差异和重叠的系统性理解。现有基准主要比较整个RAG流水线或引入新数据集，很少直接指导检索器的选择或组合，且现有比较工具有限，无法捕捉互补和重叠优势。

Method: 提出MIGRASCOPE框架，基于信息和统计估计理论引入原则性指标，量化检索质量、冗余性、协同效应和边际贡献。重新审视最先进的检索器，并在主要RAG语料库上应用这些工具进行分析。

Result: 研究发现，如果精心选择，检索器集成能够超越任何单一检索器。通过对主要RAG语料库的分析，提供了对最先进检索器贡献水平的独特见解。

Conclusion: 该研究为现代检索技术的结构提供了新视角，并为设计稳健高效的RAG系统提供了可操作的指导。MIGRASCOPE框架能够系统性地理解和比较不同检索器机制。

Abstract: Retrieval-Augmented Generation (RAG) systems rely critically on the retriever module to surface relevant context for large language models. Although numerous retrievers have recently been proposed, each built on different ranking principles such as lexical matching, dense embeddings, or graph citations, there remains a lack of systematic understanding of how these mechanisms differ and overlap. Existing benchmarks primarily compare entire RAG pipelines or introduce new datasets, providing little guidance on selecting or combining retrievers themselves. Those that do compare retrievers directly use a limited set of evaluation tools which fail to capture complementary and overlapping strengths. This work presents MIGRASCOPE, a Mutual Information based RAG Retriever Analysis Scope. We revisit state-of-the-art retrievers and introduce principled metrics grounded in information and statistical estimation theory to quantify retrieval quality, redundancy, synergy, and marginal contribution. We further show that if chosen carefully, an ensemble of retrievers outperforms any single retriever. We leverage the developed tools over major RAG corpora to provide unique insights on contribution levels of the state-of-the-art retrievers. Our findings provide a fresh perspective on the structure of modern retrieval techniques and actionable guidance for designing robust and efficient RAG systems.

</details>


### [61] [Retrieval Challenges in Low-Resource Public Service Information: A Case Study on Food Pantry Access](https://arxiv.org/abs/2602.21598)
*Touseef Hasan,Laila Cure,Souvika Sarkar*

Main category: cs.IR

TL;DR: 开发AI对话检索系统解决食品储藏室信息碎片化问题，通过RAG管道支持自然语言查询，但面临检索鲁棒性和知识库不一致性挑战


<details>
  <summary>Details</summary>
Motivation: 公共服务信息系统通常存在碎片化、格式不一致和过时的问题，这些特性造成了低资源检索环境，阻碍了对关键服务的及时访问。研究以食品储藏室访问这一具有社会紧迫性的问题为切入点，探讨此类环境中的检索挑战。

Method: 开发了一个AI驱动的对话检索系统，通过爬取和索引公开可用的储藏室数据，采用检索增强生成(RAG)管道，通过Web界面支持自然语言查询。使用社区来源的查询进行试点评估研究，以检查系统在真实场景中的行为。

Result: 分析揭示了检索鲁棒性、处理未充分指定查询以及在不一致知识库上进行基础推理的关键局限性。

Conclusion: 这项正在进行的工作暴露了低资源环境中的基本信息检索挑战，并激励未来研究如何通过鲁棒的对话检索来改善对关键公共资源的访问。

Abstract: Public service information systems are often fragmented, inconsistently formatted, and outdated. These characteristics create low-resource retrieval environments that hinder timely access to critical services. We investigate retrieval challenges in such settings through the domain of food pantry access, a socially urgent problem given persistent food insecurity. We develop an AI-powered conversational retrieval system that scrapes and indexes publicly available pantry data and employs a Retrieval-Augmented Generation (RAG) pipeline to support natural language queries via a web interface. We conduct a pilot evaluation study using community-sourced queries to examine system behavior in realistic scenarios. Our analysis reveals key limitations in retrieval robustness, handling underspecified queries, and grounding over inconsistent knowledge bases. This ongoing work exposes fundamental IR challenges in low-resource environments and motivates future research on robust conversational retrieval to improve access to critical public resources.

</details>


### [62] [AQR-HNSW: Accelerating Approximate Nearest Neighbor Search via Density-aware Quantization and Multi-stage Re-ranking](https://arxiv.org/abs/2602.21600)
*Ganap Ashit Tewary,Nrusinga Charan Gantayat,Jeff Zhang*

Main category: cs.IR

TL;DR: AQR-HNSW：一种结合自适应量化、多状态重排序和SIMD优化的HNSW改进框架，显著提升大规模向量检索的查询速度、内存效率和构建速度。


<details>
  <summary>Details</summary>
Motivation: 随着向量数据库扩展到数十亿嵌入向量，HNSW算法面临内存消耗大、距离计算开销主导查询延迟、在异构数据分布上性能不佳等关键瓶颈。

Method: 提出AQR-HNSW框架，包含三个协同策略：1) 密度感知自适应量化，实现4倍压缩同时保持距离关系；2) 多状态重排序，减少35%不必要的计算；3) 量化优化的SIMD实现，在不同架构上实现每周期16-64次操作。

Result: 在标准基准测试中，相比最先进的HNSW实现，AQR-HNSW实现了2.5-3.3倍的QPS提升，同时保持超过98%的召回率，索引图内存减少75%，索引构建速度提高5倍。

Conclusion: AQR-HNSW通过协同集成自适应量化、重排序和SIMD优化，有效解决了HNSW在大规模向量检索中的可扩展性瓶颈，为现代AI基础设施提供了更高效、更节省内存的ANN搜索解决方案。

Abstract: Approximate Nearest Neighbor (ANN) search has become fundamental to modern AI infrastructure, powering recommendation systems, search engines, and large language models across industry leaders from Google to OpenAI. Hierarchical Navigable Small World (HNSW) graphs have emerged as the dominant ANN algorithm, widely adopted in production systems due to their superior recall versus latency balance. However, as vector databases scale to billions of embeddings, HNSW faces critical bottlenecks: memory consumption expands, distance computation overhead dominates query latency, and it suffers suboptimal performance on heterogeneous data distributions. This paper presents Adaptive Quantization and Rerank HNSW (AQR-HNSW), a novel framework that synergistically integrates three strategies to enhance HNSW scalability. AQR-HNSW introduces (1) density-aware adaptive quantization, achieving 4x compression while preserving distance relationships; (2) multi-state re-ranking that reduces unnecessary computations by 35%; and (3) quantization-optimized SIMD implementations delivering 16-64 operations per cycle across architectures. Evaluation on standard benchmarks demonstrates 2.5-3.3x higher queries per second (QPS) than state-of-the-art HNSW implementations while maintaining over 98% recall, with 75% memory reduction for the index graph and 5x faster index construction.

</details>


### [63] [Trie-Aware Transformers for Generative Recommendation](https://arxiv.org/abs/2602.21677)
*Zhenxiang Xu,Jiawei Chen,Sirui Chen,Yong He,Jieyu Yang,Chuan Yuan,Ke Ding,Can Wang*

Main category: cs.IR

TL;DR: TrieRec：一种利用前缀树结构增强生成式推荐系统的方法，通过两种位置编码注入结构归纳偏置，显著提升推荐性能


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐方法通常将物品标记化为层次化令牌，但标准自回归建模（如Transformer）会将这些令牌展平为线性流，忽略了底层的前缀树拓扑结构，这限制了模型对物品层次关系的利用。

Method: 提出TrieRec方法，通过两种位置编码为Transformer注入结构归纳偏置：1) 前缀树感知的绝对位置编码，聚合令牌（节点）的局部结构上下文（如深度、祖先、后代）；2) 拓扑感知的相对位置编码，将成对结构关系注入自注意力机制以捕获拓扑诱导的语义相关性。

Result: 在三个代表性生成式推荐骨干模型中实现TrieRec，在四个真实世界数据集上平均获得8.83%的显著性能提升。

Conclusion: TrieRec通过有效利用物品令牌的前缀树拓扑结构，为生成式推荐系统提供了模型无关、高效且无需超参数调优的结构增强方法，显著提升了推荐性能。

Abstract: Generative recommendation (GR) aligns with advances in generative AI by casting next-item prediction as token-level generation rather than score-based ranking. Most GR methods adopt a two-stage pipeline: (i) \textit{item tokenization}, which maps each item to a sequence of discrete, hierarchically organized tokens; and (ii) \textit{autoregressive generation}, which predicts the next item's tokens conditioned on the tokens of user's interaction history. Although hierarchical tokenization induces a prefix tree (trie) over items, standard autoregressive modeling with conventional Transformers often flattens item tokens into a linear stream and overlooks the underlying topology.
  To address this, we propose TrieRec, a trie-aware generative recommendation method that augments Transformers with structural inductive biases via two positional encodings. First, a \textit{trie-aware absolute positional encoding} aggregates a token's (node's) local structural context (\eg depth, ancestors, and descendants) into the token representation. Second, a \textit{topology-aware relative positional encoding} injects pairwise structural relations into self-attention to capture topology-induced semantic relatedness. TrieRec is also model-agnostic, efficient, and hyperparameter-free. In our experiments, we implement TrieRec within three representative GR backbones, achieving notably improvements of 8.83\% on average across four real-world datasets.

</details>


### [64] [Offline Reasoning for Efficient Recommendation: LLM-Empowered Persona-Profiled Item Indexing](https://arxiv.org/abs/2602.21756)
*Deogyong Kim,Junseong Lee,Jeongeun Lee,Changhoe Kim,Junguel Lee,Jungseok Lee,Dongha Lee*

Main category: cs.IR

TL;DR: Persona4Rec是一个推荐框架，通过离线LLM推理构建可解释的物品角色表示，实现轻量级实时推荐，在保持性能的同时大幅降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有LLM重排序方法需要昂贵的在线推理时间，导致高延迟，阻碍实际部署。需要一种既能利用LLM语义理解能力，又能实现轻量级实时推理的推荐方案。

Method: 1. 离线阶段：利用LLM分析物品评论，推断不同用户的参与动机，构建可解释的角色表示；2. 学习用户画像与最相关物品角色的对齐；3. 在线阶段：使用预构建的角色索引进行快速相关性计算，无需调用LLM。

Result: Persona4Rec在性能上与最新的LLM重排序器相当，同时显著减少推理时间。角色表示不仅支持高效评分，还提供了基于评论的直观解释。

Conclusion: Persona4Rec为下一代推荐系统提供了一个实用且可解释的解决方案，通过离线推理构建角色表示，实现了高效、可扩展的实时推荐。

Abstract: Recent advances in large language models (LLMs) offer new opportunities for recommender systems by capturing the nuanced semantics of user interests and item characteristics through rich semantic understanding and contextual reasoning. In particular, LLMs have been employed as rerankers that reorder candidate items based on inferred user-item relevance. However, these approaches often require expensive online inference-time reasoning, leading to high latency that hampers real-world deployment. In this work, we introduce Persona4Rec, a recommendation framework that performs offline reasoning to construct interpretable persona representations of items, enabling lightweight and scalable real-time inference. In the offline stage, Persona4Rec leverages LLMs to reason over item reviews, inferring diverse user motivations that explain why different types of users may engage with an item; these inferred motivations are materialized as persona representations, providing multiple, human-interpretable views of each item. Unlike conventional approaches that rely on a single item representation, Persona4Rec learns to align user profiles with the most plausible item-side persona through a dedicated encoder, effectively transforming user-item relevance into user-persona relevance. At the online stage, this persona-profiled item index allows fast relevance computation without invoking expensive LLM reasoning. Extensive experiments show that Persona4Rec achieves performance comparable to recent LLM-based rerankers while substantially reducing inference time. Moreover, qualitative analysis confirms that persona representations not only drive efficient scoring but also provide intuitive, review-grounded explanations. These results demonstrate that Persona4Rec offers a practical and interpretable solution for next-generation recommender systems.

</details>


### [65] [Learning to Collaborate via Structures: Cluster-Guided Item Alignment for Federated Recommendation](https://arxiv.org/abs/2602.21957)
*Yuchun Tu,Zhiwei Li,Bingli Sun,Yixuan Li,Xiao Song*

Main category: cs.IR

TL;DR: 联邦推荐框架CGFedRec通过传输紧凑的聚类标签而非完整嵌入，在保持推荐精度的同时显著提升通信效率


<details>
  <summary>Details</summary>
Motivation: 传统联邦推荐方法依赖同步高维项目表示，假设精确的几何坐标对齐是跨客户端协作的必要条件。作者认为建立项目间的相对语义关系比强制共享表示更有效，全局语义关系可以作为项目的结构约束，同时允许本地表示灵活变化以捕捉个性化特征。

Method: 提出Cluster-Guided FedRec框架(CGFedRec)，将上传的嵌入转换为紧凑的聚类标签。服务器作为全局结构发现器学习项目聚类，仅分发聚类标签，从而切断项目嵌入的下游传输。这种方法允许客户端在全局结构约束下维护本地项目表示。

Result: 大量实验表明，CGFedRec在多个数据集上显著提高通信效率的同时保持了优越的推荐准确性。

Conclusion: 通过传输聚类标签而非完整嵌入，CGFedRec有效将全局协作信号注入本地项目表示，使客户端无需维护全局共享的项目嵌入，在保持推荐性能的同时大幅降低通信开销。

Abstract: Federated recommendation facilitates collaborative model training across distributed clients while keeping sensitive user interaction data local. Conventional approaches typically rely on synchronizing high-dimensional item representations between the server and clients. This paradigm implicitly assumes that precise geometric alignment of embedding coordinates is necessary for collaboration across clients. We posit that establishing relative semantic relationships among items is more effective than enforcing shared representations. Specifically, global semantic relations serve as structural constraints for items. Within these constraints, the framework allows item representations to vary locally on each client, which flexibility enables the model to capture fine-grained user personalization while maintaining global consistency. To this end, we propose Cluster-Guided FedRec framework (CGFedRec), a framework that transforms uploaded embeddings into compact cluster labels. In this framework, the server functions as a global structure discoverer to learn item clusters and distributes only the resulting labels. This mechanism explicitly cuts off the downstream transmission of item embeddings, relieving clients from maintaining global shared item embeddings. Consequently, CGFedRec achieves the effective injection of global collaborative signals into local item representations without transmitting full embeddings. Extensive experiments demonstrate that our approach significantly improves communication efficiency while maintaining superior recommendation accuracy across multiple datasets.

</details>
