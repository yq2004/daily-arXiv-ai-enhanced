{"id": "2512.08082", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08082", "abs": "https://arxiv.org/abs/2512.08082", "authors": ["Vala Vakilian", "Zimeng Wang", "Ankit Singh Rawat", "Christos Thrampoulidis"], "title": "Short-Context Dominance: How Much Local Context Natural Language Actually Needs?", "comment": "38 pages, 7 figures, includes appendix and references", "summary": "We investigate the short-context dominance hypothesis: that for most sequences, a small local prefix suffices to predict their next tokens. Using large language models as statistical oracles, we measure the minimum context length (MCL) needed to reproduce accurate full-context predictions across datasets with sequences of varying lengths. For sequences with 1-7k tokens from long-context documents, we consistently find that 75-80% require only the last 96 tokens at most. Given the dominance of short-context tokens, we then ask whether it is possible to detect challenging long-context sequences for which a short local prefix does not suffice for prediction. We introduce a practical proxy to MCL, called Distributionally Aware MCL (DaMCL), that does not require knowledge of the actual next-token and is compatible with sampling strategies beyond greedy decoding. Our experiments validate that simple thresholding of the metric defining DaMCL achieves high performance in detecting long vs. short context sequences. Finally, to counter the bias that short-context dominance induces in LLM output distributions, we develop an intuitive decoding algorithm that leverages our detector to identify and boost tokens that are long-range-relevant. Across Q&A tasks and model architectures, we confirm that mitigating the bias improves performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9a8c\u8bc1\u4e86\"\u77ed\u4e0a\u4e0b\u6587\u4e3b\u5bfc\u5047\u8bf4\"\uff0c\u53d1\u73b075-80%\u7684\u957f\u5e8f\u5217\u4ec5\u9700\u6700\u540e96\u4e2atoken\u5373\u53ef\u51c6\u786e\u9884\u6d4b\uff0c\u5e76\u5f00\u53d1\u4e86DaMCL\u6307\u6807\u6765\u68c0\u6d4b\u9700\u8981\u957f\u4e0a\u4e0b\u6587\u7684\u6311\u6218\u6027\u5e8f\u5217\uff0c\u6700\u540e\u63d0\u51fa\u89e3\u7801\u7b97\u6cd5\u6765\u7f13\u89e3\u77ed\u4e0a\u4e0b\u6587\u504f\u89c1\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u9a8c\u8bc1\"\u77ed\u4e0a\u4e0b\u6587\u4e3b\u5bfc\u5047\u8bf4\"\u2014\u2014\u5373\u5bf9\u4e8e\u5927\u591a\u6570\u5e8f\u5217\uff0c\u4e00\u4e2a\u5c0f\u7684\u5c40\u90e8\u524d\u7f00\u5c31\u8db3\u4ee5\u9884\u6d4b\u4e0b\u4e00\u4e2atoken\u3002\u540c\u65f6\uff0c\u9700\u8981\u89e3\u51b3\u5982\u4f55\u68c0\u6d4b\u90a3\u4e9b\u9700\u8981\u957f\u4e0a\u4e0b\u6587\u7684\u6311\u6218\u6027\u5e8f\u5217\uff0c\u5e76\u7f13\u89e3\u77ed\u4e0a\u4e0b\u6587\u4e3b\u5bfc\u5e26\u6765\u7684LLM\u8f93\u51fa\u5206\u5e03\u504f\u89c1\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u7edf\u8ba1\u9884\u8a00\u673a\uff0c\u6d4b\u91cf\u91cd\u73b0\u51c6\u786e\u5168\u4e0a\u4e0b\u6587\u9884\u6d4b\u6240\u9700\u7684\u6700\u5c0f\u4e0a\u4e0b\u6587\u957f\u5ea6(MCL)\u3002\u5f15\u5165\u5206\u5e03\u611f\u77e5\u7684MCL(DaMCL)\u4f5c\u4e3a\u5b9e\u9645MCL\u7684\u4ee3\u7406\uff0c\u8be5\u6307\u6807\u4e0d\u9700\u8981\u77e5\u9053\u5b9e\u9645\u7684\u4e0b\u4e00\u4e2atoken\uff0c\u4e14\u517c\u5bb9\u8d2a\u5a6a\u89e3\u7801\u4ee5\u5916\u7684\u91c7\u6837\u7b56\u7565\u3002\u5f00\u53d1\u4e86\u57fa\u4e8eDaMCL\u9608\u503c\u68c0\u6d4b\u957f\u4e0a\u4e0b\u6587\u5e8f\u5217\u7684\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5229\u7528\u68c0\u6d4b\u5668\u8bc6\u522b\u548c\u63d0\u5347\u957f\u7a0b\u76f8\u5173token\u7684\u89e3\u7801\u7b97\u6cd5\u3002", "result": "\u5bf9\u4e8e1-7k token\u7684\u957f\u4e0a\u4e0b\u6587\u6587\u6863\u5e8f\u5217\uff0c75-80%\u4ec5\u9700\u6700\u540e96\u4e2atoken\u5373\u53ef\u51c6\u786e\u9884\u6d4b\u3002DaMCL\u6307\u6807\u80fd\u6709\u6548\u68c0\u6d4b\u9700\u8981\u957f\u4e0a\u4e0b\u6587\u7684\u6311\u6218\u6027\u5e8f\u5217\u3002\u63d0\u51fa\u7684\u89e3\u7801\u7b97\u6cd5\u5728\u95ee\u7b54\u4efb\u52a1\u548c\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e0a\u90fd\u80fd\u901a\u8fc7\u7f13\u89e3\u77ed\u4e0a\u4e0b\u6587\u504f\u89c1\u6765\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u77ed\u4e0a\u4e0b\u6587\u4e3b\u5bfc\u73b0\u8c61\u786e\u5b9e\u5b58\u5728\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7DaMCL\u6307\u6807\u68c0\u6d4b\u9700\u8981\u957f\u4e0a\u4e0b\u6587\u7684\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u89e3\u7801\u7b97\u6cd5\u7f13\u89e3\u7531\u6b64\u4ea7\u751f\u7684\u504f\u89c1\uff0c\u4ece\u800c\u63d0\u5347LLM\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2512.08088", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08088", "abs": "https://arxiv.org/abs/2512.08088", "authors": ["Eliot Brenner", "Dominic Seyler", "Manjunath Hegde", "Andrei Simion", "Koustuv Dasgupta", "Bing Xiang"], "title": "Adaptation of Embedding Models to Financial Filings via LLM Distillation", "comment": "In proceedings of LLM-Finance 2025 : The 2nd IEEE International Workshop on Large Language Models for Finance", "summary": "Despite advances in generative large language models (LLMs), practical application of specialized conversational AI agents remains constrained by computation costs, latency requirements, and the need for precise domain-specific relevance measures. While existing embedding models address the first two constraints, they underperform on information retrieval in specialized domains like finance. This paper introduces a scalable pipeline that trains specialized models from an unlabeled corpus using a general purpose retrieval embedding model as foundation. Our method yields an average of 27.7% improvement in MRR$\\texttt{@}$5, 44.6% improvement in mean DCG$\\texttt{@}$5 across 14 financial filing types measured over 21,800 query-document pairs, and improved NDCG on 3 of 4 document classes in FinanceBench. We adapt retrieval embeddings (bi-encoder) for RAG, not LLM generators, using LLM-judged relevance to distill domain knowledge into a compact retriever. There are prior works which pair synthetically generated queries with real passages to directly fine-tune the retrieval model. Our pipeline differs from these by introducing interaction between student and teacher models that interleaves retrieval-based mining of hard positive/negative examples from the unlabeled corpus with iterative retraining of the student model's weights using these examples. Each retrieval iteration uses the refined student model to mine the corpus for progressively harder training examples for the subsequent training iteration. The methodology provides a cost-effective solution to bridging the gap between general-purpose models and specialized domains without requiring labor-intensive human annotation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u7ba1\u9053\uff0c\u4f7f\u7528\u901a\u7528\u68c0\u7d22\u5d4c\u5165\u6a21\u578b\u4f5c\u4e3a\u57fa\u7840\uff0c\u4ece\u672a\u6807\u8bb0\u8bed\u6599\u5e93\u8bad\u7ec3\u4e13\u4e1a\u9886\u57df\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u91d1\u878d\u9886\u57df\u4fe1\u606f\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u6709\u8fdb\u6b65\uff0c\u4f46\u4e13\u4e1a\u5bf9\u8bddAI\u4ee3\u7406\u7684\u5b9e\u9645\u5e94\u7528\u4ecd\u53d7\u8ba1\u7b97\u6210\u672c\u3001\u5ef6\u8fdf\u8981\u6c42\u548c\u9700\u8981\u7cbe\u786e\u9886\u57df\u76f8\u5173\u5ea6\u6d4b\u91cf\u7684\u9650\u5236\u3002\u73b0\u6709\u5d4c\u5165\u6a21\u578b\u5728\u524d\u4e24\u4e2a\u7ea6\u675f\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u91d1\u878d\u7b49\u4e13\u4e1a\u9886\u57df\u7684\u4fe1\u606f\u68c0\u7d22\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u7ba1\u9053\uff0c\u4f7f\u7528\u901a\u7528\u68c0\u7d22\u5d4c\u5165\u6a21\u578b\u4f5c\u4e3a\u57fa\u7840\uff0c\u4ece\u672a\u6807\u8bb0\u8bed\u6599\u5e93\u8bad\u7ec3\u4e13\u4e1a\u6a21\u578b\u3002\u65b9\u6cd5\u91c7\u7528\u5e08\u751f\u6a21\u578b\u4ea4\u4e92\u673a\u5236\uff0c\u901a\u8fc7\u68c0\u7d22\u5f0f\u6316\u6398\u4ece\u672a\u6807\u8bb0\u8bed\u6599\u5e93\u4e2d\u83b7\u53d6\u96be\u6b63/\u8d1f\u4f8b\uff0c\u7136\u540e\u4f7f\u7528\u8fd9\u4e9b\u793a\u4f8b\u8fed\u4ee3\u91cd\u65b0\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\u6743\u91cd\u3002\u6bcf\u4e2a\u68c0\u7d22\u8fed\u4ee3\u4f7f\u7528\u7cbe\u70bc\u7684\u5b66\u751f\u6a21\u578b\u4ece\u8bed\u6599\u5e93\u4e2d\u6316\u6398\u9010\u6b65\u66f4\u96be\u7684\u8bad\u7ec3\u793a\u4f8b\u7528\u4e8e\u540e\u7eed\u8bad\u7ec3\u8fed\u4ee3\u3002", "result": "\u572814\u79cd\u8d22\u52a1\u6587\u4ef6\u7c7b\u578b\u4e0a\uff0c\u5e73\u5747MRR@5\u63d0\u534727.7%\uff0c\u5e73\u5747DCG@5\u63d0\u534744.6%\uff08\u57fa\u4e8e21,800\u4e2a\u67e5\u8be2-\u6587\u6863\u5bf9\uff09\u3002\u5728FinanceBench\u76844\u4e2a\u6587\u6863\u7c7b\u522b\u4e2d\uff0c\u67093\u4e2a\u7c7b\u522bNDCG\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u52b3\u52a8\u5bc6\u96c6\u578b\u4eba\u5de5\u6807\u6ce8\uff0c\u5c31\u80fd\u5f25\u5408\u901a\u7528\u6a21\u578b\u4e0e\u4e13\u4e1a\u9886\u57df\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u7279\u522b\u9002\u7528\u4e8eRAG\u7cfb\u7edf\u4e2d\u7684\u68c0\u7d22\u5d4c\u5165\u4f18\u5316\u3002"}}
{"id": "2512.08094", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08094", "abs": "https://arxiv.org/abs/2512.08094", "authors": ["Zifan Jiang", "Youngjoon Jang", "Liliane Momeni", "G\u00fcl Varol", "Sarah Ebling", "Andrew Zisserman"], "title": "Segment, Embed, and Align: A Universal Recipe for Aligning Subtitles to Signing", "comment": null, "summary": "The goal of this work is to develop a universal approach for aligning subtitles (i.e., spoken language text with corresponding timestamps) to continuous sign language videos. Prior approaches typically rely on end-to-end training tied to a specific language or dataset, which limits their generality. In contrast, our method Segment, Embed, and Align (SEA) provides a single framework that works across multiple languages and domains. SEA leverages two pretrained models: the first to segment a video frame sequence into individual signs and the second to embed the video clip of each sign into a shared latent space with text. Alignment is subsequently performed with a lightweight dynamic programming procedure that runs efficiently on CPUs within a minute, even for hour-long episodes. SEA is flexible and can adapt to a wide range of scenarios, utilizing resources from small lexicons to large continuous corpora. Experiments on four sign language datasets demonstrate state-of-the-art alignment performance, highlighting the potential of SEA to generate high-quality parallel data for advancing sign language processing. SEA's code and models are openly available.", "AI": {"tldr": "SEA\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u65b9\u6cd5\uff0c\u7528\u4e8e\u5c06\u5b57\u5e55\u4e0e\u8fde\u7eed\u624b\u8bed\u89c6\u9891\u5bf9\u9f50\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u6a21\u578b\u5206\u5272\u89c6\u9891\u3001\u5d4c\u5165\u5171\u4eab\u7a7a\u95f4\uff0c\u5e76\u4f7f\u7528\u8f7b\u91cf\u7ea7\u52a8\u6001\u89c4\u5212\u8fdb\u884c\u9ad8\u6548\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u7279\u5b9a\u8bed\u8a00\u6216\u6570\u636e\u96c6\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u9650\u5236\u4e86\u901a\u7528\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u591a\u79cd\u8bed\u8a00\u548c\u9886\u57df\u5de5\u4f5c\u7684\u901a\u7528\u5b57\u5e55\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "SEA\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6b65\u9aa4\uff1a1) \u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u5c06\u89c6\u9891\u5e27\u5e8f\u5217\u5206\u5272\u4e3a\u5355\u4e2a\u624b\u52bf\uff1b2) \u5c06\u6bcf\u4e2a\u624b\u52bf\u7684\u89c6\u9891\u7247\u6bb5\u5d4c\u5165\u5230\u4e0e\u6587\u672c\u5171\u4eab\u7684\u6f5c\u5728\u7a7a\u95f4\uff1b3) \u4f7f\u7528\u8f7b\u91cf\u7ea7\u52a8\u6001\u89c4\u5212\u7a0b\u5e8f\u8fdb\u884c\u5bf9\u9f50\uff0c\u5373\u4f7f\u5728\u5c0f\u65f6\u957f\u7684\u89c6\u9891\u4e0a\u4e5f\u80fd\u5728CPU\u4e0a\u4e00\u5206\u949f\u5185\u5b8c\u6210\u3002", "result": "\u5728\u56db\u4e2a\u624b\u8bed\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSEA\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5bf9\u9f50\u6027\u80fd\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u5e76\u884c\u6570\u636e\u4ee5\u63a8\u8fdb\u624b\u8bed\u5904\u7406\u7814\u7a76\u3002", "conclusion": "SEA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u3001\u901a\u7528\u7684\u6846\u67b6\uff0c\u80fd\u591f\u9002\u5e94\u4ece\u5c0f\u578b\u8bcd\u5178\u5230\u5927\u578b\u8fde\u7eed\u8bed\u6599\u5e93\u7684\u5404\u79cd\u573a\u666f\uff0c\u5176\u4ee3\u7801\u548c\u6a21\u578b\u5df2\u5f00\u6e90\uff0c\u6709\u671b\u63a8\u52a8\u624b\u8bed\u5904\u7406\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.08123", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08123", "abs": "https://arxiv.org/abs/2512.08123", "authors": ["Sampriti Soor", "Suklav Ghosh", "Arijit Sur"], "title": "Universal Adversarial Suffixes Using Calibrated Gumbel-Softmax Relaxation", "comment": "10 pages", "summary": "Language models (LMs) are often used as zero-shot or few-shot classifiers by scoring label words, but they remain fragile to adversarial prompts. Prior work typically optimizes task- or model-specific triggers, making results difficult to compare and limiting transferability. We study universal adversarial suffixes: short token sequences (4-10 tokens) that, when appended to any input, broadly reduce accuracy across tasks and models. Our approach learns the suffix in a differentiable \"soft\" form using Gumbel-Softmax relaxation and then discretizes it for inference. Training maximizes calibrated cross-entropy on the label region while masking gold tokens to prevent trivial leakage, with entropy regularization to avoid collapse. A single suffix trained on one model transfers effectively to others, consistently lowering both accuracy and calibrated confidence. Experiments on sentiment analysis, natural language inference, paraphrase detection, commonsense QA, and physical reasoning with Qwen2-1.5B, Phi-1.5, and TinyLlama-1.1B demonstrate consistent attack effectiveness and transfer across tasks and model families.", "AI": {"tldr": "\u63d0\u51fa\u901a\u7528\u5bf9\u6297\u540e\u7f00\u653b\u51fb\u65b9\u6cd5\uff1a\u901a\u8fc7\u53ef\u5fae\u4f18\u5316\u5b66\u4e60\u77edtoken\u5e8f\u5217\uff0c\u9644\u52a0\u5230\u4efb\u610f\u8f93\u5165\u4e0a\u53ef\u8de8\u4efb\u52a1\u548c\u6a21\u578b\u964d\u4f4e\u5206\u7c7b\u51c6\u786e\u7387", "motivation": "\u73b0\u6709\u5bf9\u6297\u63d0\u793a\u65b9\u6cd5\u901a\u5e38\u662f\u4efb\u52a1\u6216\u6a21\u578b\u7279\u5b9a\u7684\uff0c\u96be\u4ee5\u6bd4\u8f83\u4e14\u8fc1\u79fb\u6027\u5dee\uff0c\u9700\u8981\u7814\u7a76\u901a\u7528\u3001\u53ef\u8fc1\u79fb\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5", "method": "\u4f7f\u7528Gumbel-Softmax\u677e\u5f1b\u5b66\u4e60\u53ef\u5fae\u7684\"\u8f6f\"\u540e\u7f00\uff0c\u7136\u540e\u79bb\u6563\u5316\u7528\u4e8e\u63a8\u7406\uff1b\u8bad\u7ec3\u65f6\u6700\u5927\u5316\u6807\u7b7e\u533a\u57df\u7684\u6821\u51c6\u4ea4\u53c9\u71b5\uff0c\u540c\u65f6\u63a9\u7801\u9ec4\u91d1token\u9632\u6b62\u4fe1\u606f\u6cc4\u9732\uff0c\u5e76\u52a0\u5165\u71b5\u6b63\u5219\u5316\u907f\u514d\u5d29\u6e83", "result": "\u5728\u60c5\u611f\u5206\u6790\u3001\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u3001\u91ca\u4e49\u68c0\u6d4b\u3001\u5e38\u8bc6\u95ee\u7b54\u548c\u7269\u7406\u63a8\u7406\u7b49\u4efb\u52a1\u4e0a\uff0c\u4f7f\u7528Qwen2-1.5B\u3001Phi-1.5\u548cTinyLlama-1.1B\u6a21\u578b\u9a8c\u8bc1\u4e86\u653b\u51fb\u6709\u6548\u6027\u548c\u8de8\u4efb\u52a1\u3001\u8de8\u6a21\u578b\u5bb6\u65cf\u7684\u8fc1\u79fb\u6027", "conclusion": "\u901a\u7528\u5bf9\u6297\u540e\u7f00\u662f\u6709\u6548\u7684\u8de8\u4efb\u52a1\u3001\u8de8\u6a21\u578b\u653b\u51fb\u65b9\u6cd5\uff0c\u5355\u4e2a\u540e\u7f00\u5c31\u80fd\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u8fc1\u79fb\uff0c\u663e\u8457\u964d\u4f4e\u51c6\u786e\u7387\u548c\u6821\u51c6\u7f6e\u4fe1\u5ea6"}}
{"id": "2512.07846", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07846", "abs": "https://arxiv.org/abs/2512.07846", "authors": ["Guoyao Li", "Ran He", "Shusen Jing", "Kayhan Behdin", "Yubo Wang", "Sundara Raman Ramachandran", "Chanh Nguyen", "Jian Sheng", "Xiaojing Ma", "Chuanrui Zhu", "Sriram Vasudevan", "Muchen Wu", "Sayan Ghosh", "Lin Su", "Qingquan Song", "Xiaoqing Wang", "Zhipeng Wang", "Qing Lan", "Yanning Chen", "Jingwei Wu", "Luke Simon", "Wenjing Zhang", "Qi Guo", "Fedor Borisyuk"], "title": "MixLM: High-Throughput and Effective LLM Ranking via Text-Embedding Mix-Interaction", "comment": null, "summary": "Large language models (LLMs) excel at capturing semantic nuances and therefore show impressive relevance ranking performance in modern recommendation and search systems. However, they suffer from high computational overhead under industrial latency and throughput requirements. In particular, cross-encoder ranking systems often create long context prefill-heavy workloads, as the model has to be presented with the user, query and item information. To this end, we propose MixLM, a novel LLM-based ranking framework, which significantly improves the system throughput via reducing the input context length, while preserving the semantic strength of cross-encoder rankers. In contrast to a standard ranking system where the context is presented to the model as pure text, we propose to use mix-interaction, a mixture of text and embedding tokens to represent the input. Specifically, MixLM encodes all items in the catalog into a few embedding tokens and stores in a nearline cache. The encoded item descriptions are used during online inference, effectively reducing the item length from a few thousand text tokens to a few embedding tokens. We share insights from deploying our MixLM framework to a real-world search application at LinkedIn, including a detailed discussion of our training pipelines, as well as a thorough analysis of our online serving infrastructure optimization. Comparing with strong baselines, MixLM increased throughput by 10.0x under the same latency budget, while maintaining relevance metrics. The efficiency gains delivered by MixLM enabled full-traffic deployment of LLM-powered search, which resulted in a significant 0.47% increase in Daily Active Users (DAU) in online A/B tests.", "AI": {"tldr": "MixLM\u662f\u4e00\u79cd\u65b0\u9896\u7684LLM\u6392\u5e8f\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7269\u54c1\u63cf\u8ff0\u7f16\u7801\u4e3a\u5c11\u91cf\u5d4c\u5165token\u6765\u51cf\u5c11\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u5728\u4fdd\u6301\u76f8\u5173\u6027\u7684\u540c\u65f6\u5c06\u541e\u5410\u91cf\u63d0\u534710\u500d\uff0c\u5b9e\u73b0\u4e86LLM\u641c\u7d22\u7684\u5168\u6d41\u91cf\u90e8\u7f72\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u548c\u641c\u7d22\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5de5\u4e1a\u7ea7\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u8981\u6c42\u4e0b\u8ba1\u7b97\u5f00\u9500\u8fc7\u9ad8\u3002\u7279\u522b\u662f\u4ea4\u53c9\u7f16\u7801\u5668\u6392\u5e8f\u7cfb\u7edf\u901a\u5e38\u9700\u8981\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u9884\u586b\u5145\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u56e0\u4e3a\u6a21\u578b\u9700\u8981\u540c\u65f6\u5904\u7406\u7528\u6237\u3001\u67e5\u8be2\u548c\u7269\u54c1\u4fe1\u606f\u3002", "method": "\u63d0\u51faMixLM\u6846\u67b6\uff0c\u4f7f\u7528\u6df7\u5408\u4ea4\u4e92\uff08\u6587\u672c\u548c\u5d4c\u5165token\u7684\u6df7\u5408\uff09\u6765\u8868\u793a\u8f93\u5165\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u5c06\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u7269\u54c1\u7f16\u7801\u4e3a\u5c11\u91cf\u5d4c\u5165token\u5e76\u5b58\u50a8\u5728\u8fd1\u7ebf\u7f13\u5b58\u4e2d\uff0c\u5728\u7ebf\u63a8\u7406\u65f6\u4f7f\u7528\u7f16\u7801\u540e\u7684\u7269\u54c1\u63cf\u8ff0\uff0c\u4ece\u800c\u5c06\u7269\u54c1\u957f\u5ea6\u4ece\u6570\u5343\u4e2a\u6587\u672ctoken\u51cf\u5c11\u5230\u51e0\u4e2a\u5d4c\u5165token\u3002", "result": "\u5728LinkedIn\u771f\u5b9e\u641c\u7d22\u5e94\u7528\u4e2d\u90e8\u7f72MixLM\u6846\u67b6\uff0c\u5728\u76f8\u540c\u5ef6\u8fdf\u9884\u7b97\u4e0b\u541e\u5410\u91cf\u63d0\u534710.0\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5173\u6027\u6307\u6807\u3002\u6548\u7387\u63d0\u5347\u4f7fLLM\u641c\u7d22\u5b9e\u73b0\u5168\u6d41\u91cf\u90e8\u7f72\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u6bcf\u65e5\u6d3b\u8dc3\u7528\u6237\u663e\u8457\u589e\u52a00.47%\u3002", "conclusion": "MixLM\u901a\u8fc7\u51cf\u5c11\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\u663e\u8457\u63d0\u9ad8\u4e86LLM\u6392\u5e8f\u7cfb\u7edf\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4ea4\u53c9\u7f16\u7801\u5668\u6392\u5e8f\u5668\u7684\u8bed\u4e49\u5f3a\u5ea6\uff0c\u4e3a\u5de5\u4e1a\u7ea7LLM\u641c\u7d22\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.08131", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08131", "abs": "https://arxiv.org/abs/2512.08131", "authors": ["Sampriti Soor", "Suklav Ghosh", "Arijit Sur"], "title": "Universal Adversarial Suffixes for Language Models Using Reinforcement Learning with Calibrated Reward", "comment": "5 pages", "summary": "Language models are vulnerable to short adversarial suffixes that can reliably alter predictions. Previous works usually find such suffixes with gradient search or rule-based methods, but these are brittle and often tied to a single task or model. In this paper, a reinforcement learning framework is used where the suffix is treated as a policy and trained with Proximal Policy Optimization against a frozen model as a reward oracle. Rewards are shaped using calibrated cross-entropy, removing label bias and aggregating across surface forms to improve transferability. The proposed method is evaluated on five diverse NLP benchmark datasets, covering sentiment, natural language inference, paraphrase, and commonsense reasoning, using three distinct language models: Qwen2-1.5B Instruct, TinyLlama-1.1B Chat, and Phi-1.5. Results show that RL-trained suffixes consistently degrade accuracy and transfer more effectively across tasks and models than previous adversarial triggers of similar genres.", "AI": {"tldr": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3\u5bf9\u6297\u6027\u540e\u7f00\uff0c\u901a\u8fc7PPO\u7b97\u6cd5\u4f18\u5316\u540e\u7f00\u7b56\u7565\uff0c\u5728\u591a\u4e2aNLP\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u5b9e\u73b0\u66f4\u597d\u7684\u653b\u51fb\u6548\u679c\u548c\u8de8\u4efb\u52a1/\u6a21\u578b\u8fc1\u79fb\u80fd\u529b\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u77ed\u5bf9\u6297\u6027\u540e\u7f00\u7684\u5f71\u54cd\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\uff08\u68af\u5ea6\u641c\u7d22\u6216\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff09\u901a\u5e38\u8106\u5f31\u4e14\u5c40\u9650\u4e8e\u5355\u4e00\u4efb\u52a1\u6216\u6a21\u578b\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u548c\u53ef\u8fc1\u79fb\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u5bf9\u6297\u6027\u540e\u7f00\u89c6\u4e3a\u7b56\u7565\uff0c\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u51bb\u7ed3\u6a21\u578b\u4f5c\u4e3a\u5956\u52b1\u8ba1\u7b97\u5668\u3002\u901a\u8fc7\u6821\u51c6\u4ea4\u53c9\u71b5\u6765\u5851\u9020\u5956\u52b1\uff0c\u6d88\u9664\u6807\u7b7e\u504f\u5dee\u5e76\u805a\u5408\u4e0d\u540c\u8868\u9762\u5f62\u5f0f\u4ee5\u63d0\u9ad8\u53ef\u8fc1\u79fb\u6027\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u7684NLP\u57fa\u51c6\u6570\u636e\u96c6\uff08\u6db5\u76d6\u60c5\u611f\u5206\u6790\u3001\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u3001\u91ca\u4e49\u548c\u5e38\u8bc6\u63a8\u7406\uff09\u548c\u4e09\u4e2a\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\uff08Qwen2-1.5B Instruct\u3001TinyLlama-1.1B Chat\u3001Phi-1.5\uff09\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aRL\u8bad\u7ec3\u7684\u540e\u7f00\u80fd\u6301\u7eed\u964d\u4f4e\u6a21\u578b\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u6bd4\u7c7b\u4f3c\u7c7b\u578b\u7684\u5148\u524d\u5bf9\u6297\u6027\u89e6\u53d1\u5668\u5728\u8de8\u4efb\u52a1\u548c\u6a21\u578b\u8fc1\u79fb\u65b9\u9762\u66f4\u6709\u6548\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e3a\u751f\u6210\u5bf9\u6297\u6027\u540e\u7f00\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u8fc1\u79fb\u6027\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6a21\u578b\u95f4\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u653b\u51fb\u6548\u679c\u3002"}}
{"id": "2512.08073", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08073", "abs": "https://arxiv.org/abs/2512.08073", "authors": ["Jianping Zhang", "Han Qin", "Nathaniel Huber-Fliflet"], "title": "Detecting Privileged Documents by Ranking Connected Network Entities", "comment": null, "summary": "This paper presents a link analysis approach for identifying privileged documents by constructing a network of human entities derived from email header metadata. Entities are classified as either counsel or non-counsel based on a predefined list of known legal professionals. The core assumption is that individuals with frequent interactions with lawyers are more likely to participate in privileged communications. To quantify this likelihood, an algorithm assigns a score to each entity within the network. By utilizing both entity scores and the strength of their connections, the method enhances the identification of privileged documents. Experimental results demonstrate the algorithm's effectiveness in ranking legal entities for privileged document detection.", "AI": {"tldr": "\u57fa\u4e8e\u90ae\u4ef6\u5143\u6570\u636e\u6784\u5efa\u4eba\u9645\u5173\u7cfb\u7f51\u7edc\uff0c\u901a\u8fc7\u5206\u6790\u5b9e\u4f53\u4e0e\u5f8b\u5e08\u7684\u4e92\u52a8\u9891\u7387\u6765\u8bc6\u522b\u7279\u6743\u6587\u6863", "motivation": "\u5728\u6cd5\u5f8b\u6587\u6863\u5ba1\u67e5\u4e2d\uff0c\u8bc6\u522b\u7279\u6743\u6587\u6863\uff08\u5982\u5f8b\u5e08-\u5ba2\u6237\u4fdd\u5bc6\u901a\u4fe1\uff09\u662f\u91cd\u8981\u4f46\u8017\u65f6\u7684\u4efb\u52a1\u3002\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5173\u952e\u8bcd\u641c\u7d22\u6216\u4eba\u5de5\u5ba1\u67e5\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u5bb9\u6613\u9057\u6f0f\u3002", "method": "\u4ece\u90ae\u4ef6\u5934\u5143\u6570\u636e\u4e2d\u63d0\u53d6\u4eba\u7c7b\u5b9e\u4f53\u6784\u5efa\u7f51\u7edc\uff0c\u5c06\u5b9e\u4f53\u5206\u7c7b\u4e3a\u5f8b\u5e08\u548c\u975e\u5f8b\u5e08\u3002\u6838\u5fc3\u7b97\u6cd5\u5047\u8bbe\u4e0e\u5f8b\u5e08\u9891\u7e41\u4e92\u52a8\u7684\u4e2a\u4f53\u66f4\u53ef\u80fd\u53c2\u4e0e\u7279\u6743\u901a\u4fe1\uff0c\u901a\u8fc7\u8ba1\u7b97\u5b9e\u4f53\u5728\u7f51\u7edc\u4e2d\u7684\u5f97\u5206\u548c\u8fde\u63a5\u5f3a\u5ea6\u6765\u91cf\u5316\u8fd9\u79cd\u53ef\u80fd\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u7b97\u6cd5\u5728\u7279\u6743\u6587\u6863\u68c0\u6d4b\u4e2d\u5bf9\u6cd5\u5f8b\u5b9e\u4f53\u7684\u6392\u5e8f\u5177\u6709\u6709\u6548\u6027\uff0c\u80fd\u591f\u63d0\u5347\u7279\u6743\u6587\u6863\u7684\u8bc6\u522b\u51c6\u786e\u7387\u3002", "conclusion": "\u57fa\u4e8e\u94fe\u63a5\u5206\u6790\u7684\u65b9\u6cd5\u4e3a\u7279\u6743\u6587\u6863\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u901a\u8fc7\u5206\u6790\u5b9e\u4f53\u4e92\u52a8\u6a21\u5f0f\u80fd\u591f\u589e\u5f3a\u6587\u6863\u5ba1\u67e5\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2512.08193", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08193", "abs": "https://arxiv.org/abs/2512.08193", "authors": ["Jiwoo Park", "Ruoqi Liu", "Avani Jagdale", "Andrew Srisuwananukorn", "Jing Zhao", "Lang Li", "Ping Zhang", "Sachin Kumar"], "title": "ClinicalTrialsHub: Bridging Registries and Literature for Comprehensive Clinical Trial Access", "comment": null, "summary": "We present ClinicalTrialsHub, an interactive search-focused platform that consolidates all data from ClinicalTrials.gov and augments it by automatically extracting and structuring trial-relevant information from PubMed research articles. Our system effectively increases access to structured clinical trial data by 83.8% compared to relying on ClinicalTrials.gov alone, with potential to make access easier for patients, clinicians, researchers, and policymakers, advancing evidence-based medicine. ClinicalTrialsHub uses large language models such as GPT-5.1 and Gemini-3-Pro to enhance accessibility. The platform automatically parses full-text research articles to extract structured trial information, translates user queries into structured database searches, and provides an attributed question-answering system that generates evidence-grounded answers linked to specific source sentences. We demonstrate its utility through a user study involving clinicians, clinical researchers, and PhD students of pharmaceutical sciences and nursing, and a systematic automatic evaluation of its information extraction and question answering capabilities.", "AI": {"tldr": "ClinicalTrialsHub\u662f\u4e00\u4e2a\u6574\u5408ClinicalTrials.gov\u6570\u636e\u548cPubMed\u6587\u732e\u7684\u4ea4\u4e92\u5f0f\u4e34\u5e8a\u8bd5\u9a8c\u641c\u7d22\u5e73\u53f0\uff0c\u901a\u8fc7LLM\u81ea\u52a8\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\uff0c\u5c06\u53ef\u8bbf\u95ee\u7684\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\u589e\u52a083.8%", "motivation": "\u73b0\u6709\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\u5206\u6563\u5728ClinicalTrials.gov\u548cPubMed\u6587\u732e\u4e2d\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u641c\u7d22\u5e73\u53f0\uff0c\u9650\u5236\u4e86\u60a3\u8005\u3001\u4e34\u5e8a\u533b\u751f\u3001\u7814\u7a76\u4eba\u5458\u548c\u653f\u7b56\u5236\u5b9a\u8005\u83b7\u53d6\u8bc1\u636e\u533b\u5b66\u4fe1\u606f\u7684\u80fd\u529b", "method": "\u4f7f\u7528GPT-5.1\u548cGemini-3-Pro\u7b49\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u81ea\u52a8\u89e3\u6790PubMed\u5168\u6587\u7814\u7a76\u6587\u7ae0\u63d0\u53d6\u7ed3\u6784\u5316\u8bd5\u9a8c\u4fe1\u606f\uff0c\u5c06\u7528\u6237\u67e5\u8be2\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u6570\u636e\u5e93\u641c\u7d22\uff0c\u5e76\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u95ee\u7b54\u7cfb\u7edf", "result": "\u7cfb\u7edf\u5c06\u53ef\u8bbf\u95ee\u7684\u7ed3\u6784\u5316\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\u589e\u52a0\u4e8683.8%\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\uff08\u4e34\u5e8a\u533b\u751f\u3001\u7814\u7a76\u4eba\u5458\u3001\u836f\u5b66/\u62a4\u7406\u535a\u58eb\u751f\uff09\u548c\u7cfb\u7edf\u81ea\u52a8\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u4fe1\u606f\u63d0\u53d6\u548c\u95ee\u7b54\u80fd\u529b", "conclusion": "ClinicalTrialsHub\u901a\u8fc7\u6574\u5408\u548c\u589e\u5f3a\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\u8bbf\u95ee\uff0c\u4e3a\u60a3\u8005\u3001\u4e34\u5e8a\u533b\u751f\u3001\u7814\u7a76\u4eba\u5458\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc1\u636e\u533b\u5b66\u652f\u6301\u5e73\u53f0"}}
{"id": "2512.08078", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08078", "abs": "https://arxiv.org/abs/2512.08078", "authors": ["Qiang Mao", "Han Qin", "Robert Neary", "Charles Wang", "Fusheng Wei", "Jianping Zhang", "Nathaniel Huber-Fliflet"], "title": "A Comparative Study of Retrieval Methods in Azure AI Search", "comment": null, "summary": "Increasingly, attorneys are interested in moving beyond keyword and semantic search to improve the efficiency of how they find key information during a document review task. Large language models (LLMs) are now seen as tools that attorneys can use to ask natural language questions of their data during document review to receive accurate and concise answers. This study evaluates retrieval strategies within Microsoft Azure's Retrieval-Augmented Generation (RAG) framework to identify effective approaches for Early Case Assessment (ECA) in eDiscovery. During ECA, legal teams analyze data at the outset of a matter to gain a general understanding of the data and attempt to determine key facts and risks before beginning full-scale review. In this paper, we compare the performance of Azure AI Search's keyword, semantic, vector, hybrid, and hybrid-semantic retrieval methods. We then present the accuracy, relevance, and consistency of each method's AI-generated responses. Legal practitioners can use the results of this study to enhance how they select RAG configurations in the future.", "AI": {"tldr": "\u8bc4\u4f30Azure AI Search\u4e2d\u4e0d\u540c\u68c0\u7d22\u65b9\u6cd5\uff08\u5173\u952e\u8bcd\u3001\u8bed\u4e49\u3001\u5411\u91cf\u3001\u6df7\u5408\u3001\u6df7\u5408\u8bed\u4e49\uff09\u5728\u7535\u5b50\u53d6\u8bc1\u65e9\u671f\u6848\u4ef6\u8bc4\u4f30\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u6cd5\u5f8b\u4ece\u4e1a\u8005\u9009\u62e9RAG\u914d\u7f6e\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5f8b\u5e08\u5e0c\u671b\u8d85\u8d8a\u4f20\u7edf\u7684\u5173\u952e\u8bcd\u548c\u8bed\u4e49\u641c\u7d22\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u6765\u66f4\u9ad8\u6548\u5730\u67e5\u627e\u6587\u6863\u5ba1\u67e5\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u3002\u7535\u5b50\u53d6\u8bc1\u4e2d\u7684\u65e9\u671f\u6848\u4ef6\u8bc4\u4f30\u9700\u8981\u5feb\u901f\u7406\u89e3\u6570\u636e\u5e76\u786e\u5b9a\u5173\u952e\u4e8b\u5b9e\u548c\u98ce\u9669\u3002", "method": "\u5728Microsoft Azure\u7684RAG\u6846\u67b6\u5185\uff0c\u6bd4\u8f83Azure AI Search\u7684\u4e94\u79cd\u68c0\u7d22\u65b9\u6cd5\uff1a\u5173\u952e\u8bcd\u68c0\u7d22\u3001\u8bed\u4e49\u68c0\u7d22\u3001\u5411\u91cf\u68c0\u7d22\u3001\u6df7\u5408\u68c0\u7d22\u548c\u6df7\u5408\u8bed\u4e49\u68c0\u7d22\uff0c\u8bc4\u4f30\u6bcf\u79cd\u65b9\u6cd5\u5728\u65e9\u671f\u6848\u4ef6\u8bc4\u4f30\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u5448\u73b0\u4e86\u6bcf\u79cd\u68c0\u7d22\u65b9\u6cd5AI\u751f\u6210\u54cd\u5e94\u7684\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u4e00\u81f4\u6027\u7ed3\u679c\uff0c\u4e3a\u6cd5\u5f8b\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u4e0d\u540cRAG\u914d\u7f6e\u7684\u6027\u80fd\u6bd4\u8f83\u6570\u636e\u3002", "conclusion": "\u6cd5\u5f8b\u4ece\u4e1a\u8005\u53ef\u4ee5\u5229\u7528\u672c\u7814\u7a76\u7ed3\u679c\u6765\u4f18\u5316\u672a\u6765RAG\u914d\u7f6e\u7684\u9009\u62e9\uff0c\u4ece\u800c\u63d0\u9ad8\u7535\u5b50\u53d6\u8bc1\u65e9\u671f\u6848\u4ef6\u8bc4\u4f30\u7684\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2512.08404", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08404", "abs": "https://arxiv.org/abs/2512.08404", "authors": ["Sjoerd B. Stolwijk", "Mark Boukes", "Damian Trilling"], "title": "Are generative AI text annotations systematically biased?", "comment": "9 pages, 6 figures, 1 table; version submitted to the International Communication Association Annual Conference in Cape Town 2026", "summary": "This paper investigates bias in GLLM annotations by conceptually replicating manual annotations of Boukes (2024). Using various GLLMs (Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b) in combination with five different prompts for five concepts (political content, interactivity, rationality, incivility, and ideology). We find GLLMs perform adequate in terms of F1 scores, but differ from manual annotations in terms of prevalence, yield substantively different downstream results, and display systematic bias in that they overlap more with each other than with manual annotations. Differences in F1 scores fail to account for the degree of bias.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0GLLM\u5728\u6587\u672c\u6807\u6ce8\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u867d\u7136F1\u5206\u6570\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u4e0e\u4eba\u5de5\u6807\u6ce8\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u4e0d\u540cGLLM\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u9ad8\u4e8e\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u76f8\u4f3c\u5ea6", "motivation": "\u7814\u7a76\u65e8\u5728\u8c03\u67e5\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08GLLM\uff09\u5728\u6587\u672c\u6807\u6ce8\u4efb\u52a1\u4e2d\u662f\u5426\u5b58\u5728\u504f\u5dee\uff0c\u901a\u8fc7\u6982\u5ff5\u6027\u590d\u5236Boukes\uff082024\uff09\u7684\u4eba\u5de5\u6807\u6ce8\u7814\u7a76\u6765\u8bc4\u4f30GLLM\u6807\u6ce8\u7684\u53ef\u9760\u6027", "method": "\u4f7f\u7528\u56db\u79cd\u4e0d\u540c\u7684GLLM\uff08Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b\uff09\u7ed3\u5408\u4e94\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u8bcd\uff0c\u5bf9\u4e94\u4e2a\u6982\u5ff5\uff08\u653f\u6cbb\u5185\u5bb9\u3001\u4e92\u52a8\u6027\u3001\u7406\u6027\u3001\u4e0d\u6587\u660e\u6027\u3001\u610f\u8bc6\u5f62\u6001\uff09\u8fdb\u884c\u6587\u672c\u6807\u6ce8\uff0c\u5e76\u4e0e\u4eba\u5de5\u6807\u6ce8\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83", "result": "GLLM\u5728F1\u5206\u6570\u65b9\u9762\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5728\u6807\u6ce8\u5206\u5e03\uff08prevalence\uff09\u4e0a\u4e0e\u4eba\u5de5\u6807\u6ce8\u5b58\u5728\u5dee\u5f02\uff0c\u5bfc\u81f4\u4e0b\u6e38\u5206\u6790\u7ed3\u679c\u4e0d\u540c\uff0c\u4e14GLLM\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff08\u76f8\u4e92\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u9ad8\u4e8e\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u76f8\u4f3c\u5ea6\uff09\uff0cF1\u5206\u6570\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u8fd9\u79cd\u504f\u5dee\u7a0b\u5ea6", "conclusion": "GLLM\u5728\u6587\u672c\u6807\u6ce8\u4efb\u52a1\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u4ec5\u4f9d\u8d56F1\u5206\u6570\u7b49\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u4e0d\u8db3\u4ee5\u5168\u9762\u8bc4\u4f30\u6807\u6ce8\u8d28\u91cf\uff0c\u9700\u8981\u66f4\u7ec6\u81f4\u7684\u504f\u5dee\u5206\u6790\u6765\u786e\u4fdd\u7814\u7a76\u7ed3\u679c\u7684\u53ef\u9760\u6027"}}
{"id": "2512.08079", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08079", "abs": "https://arxiv.org/abs/2512.08079", "authors": ["Qiang Mao", "Fusheng Wei", "Robert Neary", "Charles Wang", "Han Qin", "Jianping Zhang", "Nathaniel Huber-Fliflet"], "title": "Leveraging Machine Learning and Large Language Models for Automated Image Clustering and Description in Legal Discovery", "comment": null, "summary": "The rapid increase in digital image creation and retention presents substantial challenges during legal discovery, digital archive, and content management. Corporations and legal teams must organize, analyze, and extract meaningful insights from large image collections under strict time pressures, making manual review impractical and costly. These demands have intensified interest in automated methods that can efficiently organize and describe large-scale image datasets. This paper presents a systematic investigation of automated cluster description generation through the integration of image clustering, image captioning, and large language models (LLMs). We apply K-means clustering to group images into 20 visually coherent clusters and generate base captions using the Azure AI Vision API. We then evaluate three critical dimensions of the cluster description process: (1) image sampling strategies, comparing random, centroid-based, stratified, hybrid, and density-based sampling against using all cluster images; (2) prompting techniques, contrasting standard prompting with chain-of-thought prompting; and (3) description generation methods, comparing LLM-based generation with traditional TF-IDF and template-based approaches. We assess description quality using semantic similarity and coverage metrics. Results show that strategic sampling with 20 images per cluster performs comparably to exhaustive inclusion while significantly reducing computational cost, with only stratified sampling showing modest degradation. LLM-based methods consistently outperform TF-IDF baselines, and standard prompts outperform chain-of-thought prompts for this task. These findings provide practical guidance for deploying scalable, accurate cluster description systems that support high-volume workflows in legal discovery and other domains requiring automated organization of large image collections.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u81ea\u52a8\u5316\u56fe\u50cf\u805a\u7c7b\u63cf\u8ff0\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u56fe\u50cf\u805a\u7c7b\u3001\u56fe\u50cf\u63cf\u8ff0\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6\u63d0\u4f9b\u9ad8\u6548\u7684\u7ec4\u7ec7\u548c\u63cf\u8ff0\u65b9\u6848\u3002", "motivation": "\u6570\u5b57\u56fe\u50cf\u6570\u91cf\u7684\u5feb\u901f\u589e\u957f\u7ed9\u6cd5\u5f8b\u53d1\u73b0\u3001\u6570\u5b57\u6863\u6848\u548c\u5185\u5bb9\u7ba1\u7406\u5e26\u6765\u4e86\u5de8\u5927\u6311\u6218\u3002\u4f01\u4e1a\u548c\u6cd5\u5f8b\u56e2\u961f\u9700\u8981\u5728\u4e25\u683c\u65f6\u95f4\u538b\u529b\u4e0b\u7ec4\u7ec7\u3001\u5206\u6790\u548c\u4ece\u5927\u578b\u56fe\u50cf\u96c6\u5408\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u89c1\u89e3\uff0c\u624b\u52a8\u5ba1\u67e5\u65e2\u4e0d\u5207\u5b9e\u9645\u53c8\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u9ad8\u6548\u7ec4\u7ec7\u548c\u63cf\u8ff0\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6\u3002", "method": "\u4f7f\u7528K-means\u805a\u7c7b\u5c06\u56fe\u50cf\u5206\u4e3a20\u4e2a\u89c6\u89c9\u4e00\u81f4\u7684\u7c07\uff0c\u901a\u8fc7Azure AI Vision API\u751f\u6210\u57fa\u7840\u63cf\u8ff0\u3002\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\uff1a(1) \u56fe\u50cf\u91c7\u6837\u7b56\u7565\uff1a\u968f\u673a\u3001\u57fa\u4e8e\u8d28\u5fc3\u3001\u5206\u5c42\u3001\u6df7\u5408\u548c\u57fa\u4e8e\u5bc6\u5ea6\u7684\u91c7\u6837\u4e0e\u4f7f\u7528\u6240\u6709\u56fe\u50cf\u5bf9\u6bd4\uff1b(2) \u63d0\u793a\u6280\u672f\uff1a\u6807\u51c6\u63d0\u793a\u4e0e\u601d\u7ef4\u94fe\u63d0\u793a\u5bf9\u6bd4\uff1b(3) \u63cf\u8ff0\u751f\u6210\u65b9\u6cd5\uff1a\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u4e0e\u4f20\u7edfTF-IDF\u548c\u57fa\u4e8e\u6a21\u677f\u7684\u65b9\u6cd5\u5bf9\u6bd4\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6bcf\u4e2a\u7c07\u4f7f\u752820\u5f20\u56fe\u50cf\u7684\u6218\u7565\u91c7\u6837\u4e0e\u7a77\u5c3d\u5305\u542b\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4ec5\u5206\u5c42\u91c7\u6837\u663e\u793a\u9002\u5ea6\u9000\u5316\u3002\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8eTF-IDF\u57fa\u7ebf\uff0c\u4e14\u6807\u51c6\u63d0\u793a\u5728\u6b64\u4efb\u52a1\u4e2d\u4f18\u4e8e\u601d\u7ef4\u94fe\u63d0\u793a\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u90e8\u7f72\u53ef\u6269\u5c55\u3001\u51c6\u786e\u7684\u805a\u7c7b\u63cf\u8ff0\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u652f\u6301\u6cd5\u5f8b\u53d1\u73b0\u548c\u5176\u4ed6\u9700\u8981\u81ea\u52a8\u5316\u7ec4\u7ec7\u5927\u578b\u56fe\u50cf\u96c6\u5408\u7684\u9886\u57df\u4e2d\u7684\u9ad8\u5bb9\u91cf\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2512.08440", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08440", "abs": "https://arxiv.org/abs/2512.08440", "authors": ["Jani\u00e7a Hackenbuchner", "Arda Tezcan", "Joke Daems"], "title": "What Triggers my Model? Contrastive Explanations Inform Gender Choices by Translation Models", "comment": null, "summary": "Interpretability can be implemented as a means to understand decisions taken by (black box) models, such as machine translation (MT) or large language models (LLMs). Yet, research in this area has been limited in relation to a manifested problem in these models: gender bias. With this research, we aim to move away from simply measuring bias to exploring its origins. Working with gender-ambiguous natural source data, this study examines which context, in the form of input tokens in the source sentence, influences (or triggers) the translation model choice of a certain gender inflection in the target language. To analyse this, we use contrastive explanations and compute saliency attribution. We first address the challenge of a lacking scoring threshold and specifically examine different attribution levels of source words on the model gender decisions in the translation. We compare salient source words with human perceptions of gender and demonstrate a noticeable overlap between human perceptions and model attribution. Additionally, we provide a linguistic analysis of salient words. Our work showcases the relevance of understanding model translation decisions in terms of gender, how this compares to human decisions and that this information should be leveraged to mitigate gender bias.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5bf9\u6bd4\u89e3\u91ca\u548c\u663e\u8457\u6027\u5f52\u56e0\u5206\u6790\uff0c\u63a2\u7d22\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u4e2d\u6027\u522b\u504f\u89c1\u7684\u8d77\u6e90\uff0c\u800c\u975e\u4ec5\u4ec5\u6d4b\u91cf\u504f\u89c1\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5f52\u56e0\u4e0e\u4eba\u7c7b\u611f\u77e5\u5b58\u5728\u663e\u8457\u91cd\u53e0\uff0c\u5e76\u63d0\u4f9b\u4e86\u663e\u8457\u8bcd\u8bed\u7684\u8bed\u8a00\u5b66\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7406\u89e3\u9ed1\u76d2\u6a21\u578b\u51b3\u7b56\uff0c\u4f46\u5728\u6027\u522b\u504f\u89c1\u8fd9\u4e00\u91cd\u8981\u95ee\u9898\u4e0a\u7814\u7a76\u6709\u9650\u3002\u7814\u7a76\u65e8\u5728\u4ece\u5355\u7eaf\u6d4b\u91cf\u504f\u89c1\u8f6c\u5411\u63a2\u7d22\u504f\u89c1\u7684\u8d77\u6e90\uff0c\u7406\u89e3\u54ea\u4e9b\u4e0a\u4e0b\u6587\u56e0\u7d20\u89e6\u53d1\u7ffb\u8bd1\u6a21\u578b\u9009\u62e9\u7279\u5b9a\u7684\u6027\u522b\u5c48\u6298\u53d8\u5316\u3002", "method": "\u4f7f\u7528\u6027\u522b\u6a21\u7cca\u7684\u81ea\u7136\u6e90\u6570\u636e\uff0c\u91c7\u7528\u5bf9\u6bd4\u89e3\u91ca\u65b9\u6cd5\u8ba1\u7b97\u663e\u8457\u6027\u5f52\u56e0\u3002\u9996\u5148\u89e3\u51b3\u7f3a\u4e4f\u8bc4\u5206\u9608\u503c\u7684\u95ee\u9898\uff0c\u5206\u6790\u4e0d\u540c\u5f52\u56e0\u6c34\u5e73\u7684\u6e90\u8bcd\u5bf9\u6a21\u578b\u6027\u522b\u51b3\u7b56\u7684\u5f71\u54cd\u3002\u5c06\u663e\u8457\u6e90\u8bcd\u4e0e\u4eba\u7c7b\u6027\u522b\u611f\u77e5\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u8fdb\u884c\u8bed\u8a00\u5b66\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5f52\u56e0\u4e0e\u4eba\u7c7b\u6027\u522b\u611f\u77e5\u5b58\u5728\u663e\u8457\u91cd\u53e0\uff0c\u8868\u660e\u6a21\u578b\u5728\u6027\u522b\u51b3\u7b56\u65f6\u5173\u6ce8\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u4e0a\u4e0b\u6587\u7ebf\u7d22\u3002\u8bed\u8a00\u5b66\u5206\u6790\u63ed\u793a\u4e86\u5f71\u54cd\u6027\u522b\u51b3\u7b56\u7684\u5177\u4f53\u8bcd\u8bed\u7279\u5f81\u3002", "conclusion": "\u7406\u89e3\u6a21\u578b\u5728\u6027\u522b\u65b9\u9762\u7684\u7ffb\u8bd1\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u4e9b\u4fe1\u606f\u5e94\u4e0e\u4eba\u7c7b\u51b3\u7b56\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u7528\u4e8e\u7f13\u89e3\u6027\u522b\u504f\u89c1\u3002\u7814\u7a76\u5c55\u793a\u4e86\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u63a2\u7d22\u504f\u89c1\u8d77\u6e90\u65b9\u9762\u7684\u4ef7\u503c\u3002"}}
{"id": "2512.08083", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08083", "abs": "https://arxiv.org/abs/2512.08083", "authors": ["Keith Huffman", "Jianping Zhang", "Nathaniel Huber-Fliflet", "Fusheng Wei", "Peter Gronvall"], "title": "Exploiting the Randomness of Large Language Models (LLM) in Text Classification Tasks: Locating Privileged Documents in Legal Matters", "comment": null, "summary": "In legal matters, text classification models are most often used to filter through large datasets in search of documents that meet certain pre-selected criteria like relevance to a certain subject matter, such as legally privileged communications and attorney-directed documents. In this context, large language models have demonstrated strong performance. This paper presents an empirical study investigating the role of randomness in LLM-based classification for attorney-client privileged document detection, focusing on four key dimensions: (1) the effectiveness of LLMs in identifying legally privileged documents, (2) the influence of randomness control parameters on classification outputs, (3) their impact on overall classification performance, and (4) a methodology for leveraging randomness to enhance accuracy. Experimental results showed that LLMs can identify privileged documents effectively, randomness control parameters have minimal impact on classification performance, and importantly, our developed methodology for leveraging randomness can have a significant impact on improving accuracy. Notably, this methodology that leverages randomness could also enhance a corporation's confidence in an LLM's output when incorporated into its sanctions-compliance processes. As organizations increasingly rely on LLMs to augment compliance workflows, reducing output variability helps build internal and regulatory confidence in LLM-derived sanctions-screening decisions.", "AI": {"tldr": "\u672c\u6587\u5b9e\u8bc1\u7814\u7a76\u4e86\u968f\u673a\u6027\u5728\u57fa\u4e8eLLM\u7684\u6cd5\u5f8b\u7279\u6743\u6587\u6863\u68c0\u6d4b\u5206\u7c7b\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0LLM\u80fd\u6709\u6548\u8bc6\u522b\u7279\u6743\u6587\u6863\uff0c\u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5bf9\u6027\u80fd\u5f71\u54cd\u5f88\u5c0f\uff0c\u800c\u5229\u7528\u968f\u673a\u6027\u7684\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u6cd5\u5f8b\u4e8b\u52a1\u4e2d\uff0c\u6587\u672c\u5206\u7c7b\u6a21\u578b\u5e38\u7528\u4e8e\u7b5b\u9009\u5927\u578b\u6570\u636e\u96c6\u4ee5\u67e5\u627e\u7b26\u5408\u7279\u5b9a\u6807\u51c6\uff08\u5982\u6cd5\u5f8b\u7279\u6743\u901a\u4fe1\u548c\u5f8b\u5e08\u6307\u5bfc\u6587\u4ef6\uff09\u7684\u6587\u6863\u3002\u867d\u7136LLM\u5728\u6b64\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u968f\u673a\u6027\u5bf9\u5176\u5206\u7c7b\u8f93\u51fa\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u7279\u522b\u662f\u5728\u6cd5\u5f8b\u7279\u6743\u6587\u6863\u68c0\u6d4b\u8fd9\u4e00\u5173\u952e\u5e94\u7528\u573a\u666f\u4e2d\u3002", "method": "\u672c\u6587\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u91cd\u70b9\u5173\u6ce8\u56db\u4e2a\u7ef4\u5ea6\uff1a1) LLM\u8bc6\u522b\u6cd5\u5f8b\u7279\u6743\u6587\u6863\u7684\u6709\u6548\u6027\uff1b2) \u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5bf9\u5206\u7c7b\u8f93\u51fa\u7684\u5f71\u54cd\uff1b3) \u968f\u673a\u6027\u5bf9\u6574\u4f53\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\uff1b4) \u5229\u7528\u968f\u673a\u6027\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u65b9\u6cd5\u5b66\u3002\u7814\u7a76\u9488\u5bf9\u5f8b\u5e08-\u5ba2\u6237\u7279\u6743\u6587\u6863\u68c0\u6d4b\u4efb\u52a1\u5c55\u5f00\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1) LLM\u80fd\u6709\u6548\u8bc6\u522b\u7279\u6743\u6587\u6863\uff1b2) \u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5bf9\u5206\u7c7b\u6027\u80fd\u5f71\u54cd\u5f88\u5c0f\uff1b3) \u63d0\u51fa\u7684\u5229\u7528\u968f\u673a\u6027\u7684\u65b9\u6cd5\u5b66\u80fd\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\uff1b4) \u8be5\u65b9\u6cd5\u8fd8\u80fd\u589e\u5f3a\u4f01\u4e1a\u5728\u5236\u88c1\u5408\u89c4\u6d41\u7a0b\u4e2d\u5bf9LLM\u8f93\u51fa\u7684\u4fe1\u5fc3\u3002", "conclusion": "\u968f\u7740\u7ec4\u7ec7\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56LLM\u589e\u5f3a\u5408\u89c4\u5de5\u4f5c\u6d41\u7a0b\uff0c\u51cf\u5c11\u8f93\u51fa\u53d8\u5f02\u6027\u6709\u52a9\u4e8e\u5efa\u7acb\u5185\u90e8\u548c\u76d1\u7ba1\u673a\u6784\u5bf9LLM\u884d\u751f\u5236\u88c1\u7b5b\u67e5\u51b3\u7b56\u7684\u4fe1\u5fc3\u3002\u5229\u7528\u968f\u673a\u6027\u7684\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u8fd8\u80fd\u589e\u5f3a\u4f01\u4e1a\u5bf9LLM\u8f93\u51fa\u7684\u4fe1\u4efb\u5ea6\uff0c\u7279\u522b\u662f\u5728\u6cd5\u5f8b\u5408\u89c4\u7b49\u5173\u952e\u5e94\u7528\u4e2d\u3002"}}
{"id": "2512.08480", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08480", "abs": "https://arxiv.org/abs/2512.08480", "authors": ["Ju-Young Kim", "Ji-Hong Park", "Se-Yeon Lee", "Sujin Park", "Gun-Woo Kim"], "title": "Soft Inductive Bias Approach via Explicit Reasoning Perspectives in Inappropriate Utterance Detection Using Large Language Models", "comment": "in Chinese language, Published in the Proceedings of the 37th Annual Conference on Human and Language Technology, 2025, pp. 714-719. (English translation assisted by GPT)", "summary": "Recent incidents in certain online games and communities, where anonymity is guaranteed, show that unchecked inappropriate remarks frequently escalate into verbal abuse and even criminal behavior, raising significant social concerns. Consequently, there is a growing need for research on techniques that can detect inappropriate utterances within conversational texts to help build a safer communication environment. Although large-scale language models trained on Korean corpora and chain-of-thought reasoning have recently gained attention, research applying these approaches to inappropriate utterance detection remains limited. In this study, we propose a soft inductive bias approach that explicitly defines reasoning perspectives to guide the inference process, thereby promoting rational decision-making and preventing errors that may arise during reasoning. We fine-tune a Korean large language model using the proposed method and conduct both quantitative performance comparisons and qualitative evaluations across different training strategies. Experimental results show that the Kanana-1.5 model achieves an average accuracy of 87.0046, improving by approximately 3.89 percent over standard supervised learning. These findings indicate that the proposed method goes beyond simple knowledge imitation by large language models and enables more precise and consistent judgments through constrained reasoning perspectives, demonstrating its effectiveness for inappropriate utterance detection.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8f6f\u5f52\u7eb3\u504f\u7f6e\u65b9\u6cd5\uff0c\u901a\u8fc7\u660e\u786e\u5b9a\u4e49\u63a8\u7406\u89c6\u89d2\u6765\u6307\u5bfc\u97e9\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e0d\u5f53\u8a00\u8bba\u68c0\u6d4b\uff0c\u76f8\u6bd4\u6807\u51c6\u76d1\u7763\u5b66\u4e60\u63d0\u5347\u4e86\u7ea63.89%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5728\u7ebf\u6e38\u620f\u548c\u793e\u533a\u4e2d\u533f\u540d\u73af\u5883\u4e0b\u7684\u4e0d\u5f53\u8a00\u8bba\u7ecf\u5e38\u5347\u7ea7\u4e3a\u8a00\u8bed\u66b4\u529b\u548c\u72af\u7f6a\u884c\u4e3a\uff0c\u9700\u8981\u6784\u5efa\u66f4\u5b89\u5168\u7684\u4ea4\u6d41\u73af\u5883\u3002\u867d\u7136\u97e9\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5728\u4e0d\u5f53\u8a00\u8bba\u68c0\u6d4b\u65b9\u9762\u7684\u5e94\u7528\u7814\u7a76\u4ecd\u7136\u6709\u9650\u3002", "method": "\u63d0\u51fa\u8f6f\u5f52\u7eb3\u504f\u7f6e\u65b9\u6cd5\uff0c\u660e\u786e\u5b9a\u4e49\u63a8\u7406\u89c6\u89d2\u6765\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\uff0c\u4fc3\u8fdb\u7406\u6027\u51b3\u7b56\u5e76\u9632\u6b62\u63a8\u7406\u9519\u8bef\u3002\u4f7f\u7528\u8be5\u65b9\u6cd5\u5bf9\u97e9\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u8bad\u7ec3\u7b56\u7565\u3002", "result": "Kanana-1.5\u6a21\u578b\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523087.0046\uff0c\u76f8\u6bd4\u6807\u51c6\u76d1\u7763\u5b66\u4e60\u63d0\u5347\u4e86\u7ea63.89%\u3002\u8be5\u65b9\u6cd5\u8d85\u8d8a\u4e86\u7b80\u5355\u7684\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u6a21\u4eff\uff0c\u901a\u8fc7\u7ea6\u675f\u63a8\u7406\u89c6\u89d2\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u548c\u4e00\u81f4\u7684\u5224\u65ad\u3002", "conclusion": "\u63d0\u51fa\u7684\u8f6f\u5f52\u7eb3\u504f\u7f6e\u65b9\u6cd5\u901a\u8fc7\u7ea6\u675f\u63a8\u7406\u89c6\u89d2\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u66f4\u7cbe\u786e\u548c\u4e00\u81f4\u7684\u4e0d\u5f53\u8a00\u8bba\u68c0\u6d4b\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u6784\u5efa\u5b89\u5168\u4ea4\u6d41\u73af\u5883\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.08398", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08398", "abs": "https://arxiv.org/abs/2512.08398", "authors": ["Jiin Park", "Hyuna Jeon", "Yoonseo Lee", "Jisu Hong", "Misuk Kim"], "title": "Ontology-Based Knowledge Graph Framework for Industrial Standard Documents via Hierarchical and Propositional Structuring", "comment": null, "summary": "Ontology-based knowledge graph (KG) construction is a core technology that enables multidimensional understanding and advanced reasoning over domain knowledge. Industrial standards, in particular, contain extensive technical information and complex rules presented in highly structured formats that combine tables, scopes of application, constraints, exceptions, and numerical calculations, making KG construction especially challenging. In this study, we propose a method that organizes such documents into a hierarchical semantic structure, decomposes sentences and tables into atomic propositions derived from conditional and numerical rules, and integrates them into an ontology-knowledge graph through LLM-based triple extraction. Our approach captures both the hierarchical and logical structures of documents, effectively representing domain-specific semantics that conventional methods fail to reflect. To verify its effectiveness, we constructed rule, table, and multi-hop QA datasets, as well as a toxic clause detection dataset, from industrial standards, and implemented an ontology-aware KG-RAG framework for comparative evaluation. Experimental results show that our method achieves significant performance improvements across all QA types compared to existing KG-RAG approaches. This study demonstrates that reliable and scalable knowledge representation is feasible even for industrial documents with intertwined conditions, constraints, and scopes, contributing to future domain-specific RAG development and intelligent document management.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u4e09\u5143\u7ec4\u62bd\u53d6\u65b9\u6cd5\uff0c\u5c06\u5de5\u4e1a\u6807\u51c6\u6587\u6863\u7ec4\u7ec7\u6210\u5c42\u6b21\u8bed\u4e49\u7ed3\u6784\uff0c\u5206\u89e3\u53e5\u5b50\u548c\u8868\u683c\u4e3a\u539f\u5b50\u547d\u9898\uff0c\u6784\u5efa\u672c\u4f53\u77e5\u8bc6\u56fe\u8c31\uff0c\u663e\u8457\u63d0\u5347KG-RAG\u6027\u80fd\u3002", "motivation": "\u5de5\u4e1a\u6807\u51c6\u6587\u6863\u5305\u542b\u5927\u91cf\u6280\u672f\u4fe1\u606f\u548c\u590d\u6742\u89c4\u5219\uff0c\u4ee5\u9ad8\u5ea6\u7ed3\u6784\u5316\u683c\u5f0f\u5448\u73b0\uff08\u8868\u683c\u3001\u9002\u7528\u8303\u56f4\u3001\u7ea6\u675f\u3001\u4f8b\u5916\u3001\u6570\u503c\u8ba1\u7b97\uff09\uff0c\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u79cd\u590d\u6742\u7ed3\u6784\u3002", "method": "1) \u5c06\u6587\u6863\u7ec4\u7ec7\u6210\u5c42\u6b21\u8bed\u4e49\u7ed3\u6784\uff1b2) \u5c06\u53e5\u5b50\u548c\u8868\u683c\u5206\u89e3\u4e3a\u57fa\u4e8e\u6761\u4ef6\u548c\u6570\u503c\u89c4\u5219\u7684\u539f\u5b50\u547d\u9898\uff1b3) \u901a\u8fc7LLM\u8fdb\u884c\u4e09\u5143\u7ec4\u62bd\u53d6\uff1b4) \u5c06\u62bd\u53d6\u7ed3\u679c\u96c6\u6210\u5230\u672c\u4f53\u77e5\u8bc6\u56fe\u8c31\u4e2d\u3002", "result": "\u6784\u5efa\u4e86\u89c4\u5219\u3001\u8868\u683c\u3001\u591a\u8df3\u95ee\u7b54\u548c\u6709\u6bd2\u6761\u6b3e\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u672c\u4f53\u611f\u77e5\u7684KG-RAG\u6846\u67b6\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u73b0\u6709KG-RAG\u65b9\u6cd5\uff0c\u5728\u6240\u6709\u95ee\u7b54\u7c7b\u578b\u4e0a\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u5373\u4f7f\u5bf9\u4e8e\u6761\u4ef6\u3001\u7ea6\u675f\u548c\u9002\u7528\u8303\u56f4\u4ea4\u7ec7\u7684\u5de5\u4e1a\u6587\u6863\uff0c\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u8868\u793a\u4e5f\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u672a\u6765\u9886\u57df\u7279\u5b9aRAG\u5f00\u53d1\u548c\u667a\u80fd\u6587\u6863\u7ba1\u7406\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2512.08545", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.08545", "abs": "https://arxiv.org/abs/2512.08545", "authors": ["Indrajit Kar", "Kalathur Chenchu Kishore Kumar"], "title": "Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks", "comment": "22 pages, 2 tables, 9 figures", "summary": "Large Language Models and multi-agent systems have shown promise in decomposing complex tasks, yet they struggle with long-horizon reasoning tasks and escalating computation cost. This work introduces a hierarchical multi-agent architecture that distributes reasoning across a 64*64 grid of lightweight agents, supported by a selective oracle. A spatial curriculum progressively expands the operational region of the grid, ensuring that agents master easier central tasks before tackling harder peripheral ones. To improve reliability, the system integrates Negative Log-Likelihood as a measure of confidence, allowing the curriculum to prioritize regions where agents are both accurate and well calibrated. A Thompson Sampling curriculum manager adaptively chooses training zones based on competence and NLL-driven reward signals. We evaluate the approach on a spatially grounded Tower of Hanoi benchmark, which mirrors the long-horizon structure of many robotic manipulation and planning tasks. Results demonstrate improved stability, reduced oracle usage, and stronger long-range reasoning from distributed agent cooperation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u572864*64\u7f51\u683c\u4e0a\u5206\u5e03\u8f7b\u91cf\u7ea7\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7a7a\u95f4\u8bfe\u7a0b\u5b66\u4e60\u548c\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u63d0\u5347\u957f\u65f6\u7a0b\u63a8\u7406\u80fd\u529b", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u5206\u89e3\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u957f\u65f6\u7a0b\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u6602", "method": "\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5c06\u63a8\u7406\u5206\u5e03\u572864*64\u7f51\u683c\u7684\u8f7b\u91cf\u7ea7\u667a\u80fd\u4f53\u4e0a\uff0c\u4f7f\u7528\u9009\u62e9\u6027oracle\u652f\u6301\uff1b\u901a\u8fc7\u7a7a\u95f4\u8bfe\u7a0b\u5b66\u4e60\u9010\u6b65\u6269\u5c55\u64cd\u4f5c\u533a\u57df\uff1b\u96c6\u6210\u8d1f\u5bf9\u6570\u4f3c\u7136\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u5ea6\u91cf\uff1b\u4f7f\u7528Thompson Sampling\u8bfe\u7a0b\u7ba1\u7406\u5668\u81ea\u9002\u5e94\u9009\u62e9\u8bad\u7ec3\u533a\u57df", "result": "\u5728\u7a7a\u95f4\u63a5\u5730\u7684\u6c49\u8bfa\u5854\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7cfb\u7edf\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u7a33\u5b9a\u6027\u3001\u51cf\u5c11\u7684oracle\u4f7f\u7528\u7387\u4ee5\u53ca\u5206\u5e03\u5f0f\u667a\u80fd\u4f53\u5408\u4f5c\u5e26\u6765\u7684\u66f4\u5f3a\u957f\u7a0b\u63a8\u7406\u80fd\u529b", "conclusion": "\u8be5\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\u901a\u8fc7\u5206\u5e03\u5f0f\u63a8\u7406\u3001\u7a7a\u95f4\u8bfe\u7a0b\u5b66\u4e60\u548c\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u65f6\u7a0b\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6311\u6218\uff0c\u4e3a\u673a\u5668\u4eba\u64cd\u4f5c\u548c\u89c4\u5212\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.08702", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08702", "abs": "https://arxiv.org/abs/2512.08702", "authors": ["Jinfeng Xu", "Zheyu Chen", "Shuo Yang", "Jinze Li", "Zitong Wan", "Hewei Wang", "Weijie Liu", "Yijie Li", "Edith C. H. Ngai"], "title": "VI-MMRec: Similarity-Aware Training Cost-free Virtual User-Item Interactions for Multimodal Recommendation", "comment": "Accepted by KDD 2026", "summary": "Although existing multimodal recommendation models have shown promising performance, their effectiveness continues to be limited by the pervasive data sparsity problem. This problem arises because users typically interact with only a small subset of available items, leading existing models to arbitrarily treat unobserved items as negative samples. To this end, we propose VI-MMRec, a model-agnostic and training cost-free framework that enriches sparse user-item interactions via similarity-aware virtual user-item interactions. These virtual interactions are constructed based on modality-specific feature similarities of user-interacted items. Specifically, VI-MMRec introduces two different strategies: (1) Overlay, which independently aggregates modality-specific similarities to preserve modality-specific user preferences, and (2) Synergistic, which holistically fuses cross-modal similarities to capture complementary user preferences. To ensure high-quality augmentation, we design a statistically informed weight allocation mechanism that adaptively assigns weights to virtual user-item interactions based on dataset-specific modality relevance. As a plug-and-play framework, VI-MMRec seamlessly integrates with existing models to enhance their performance without modifying their core architecture. Its flexibility allows it to be easily incorporated into various existing models, maximizing performance with minimal implementation effort. Moreover, VI-MMRec introduces no additional overhead during training, making it significantly advantageous for practical deployment. Comprehensive experiments conducted on six real-world datasets using seven state-of-the-art multimodal recommendation models validate the effectiveness of our VI-MMRec.", "AI": {"tldr": "VI-MMRec\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u3001\u65e0\u9700\u8bad\u7ec3\u6210\u672c\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u6a21\u6001\u7279\u5f81\u76f8\u4f3c\u6027\u7684\u865a\u62df\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u6765\u7f13\u89e3\u591a\u6a21\u6001\u63a8\u8350\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u867d\u7136\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u53d7\u9650\u4e8e\u666e\u904d\u5b58\u5728\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898\u3002\u7528\u6237\u901a\u5e38\u53ea\u4e0e\u5c11\u91cf\u7269\u54c1\u4ea4\u4e92\uff0c\u5bfc\u81f4\u6a21\u578b\u5c06\u672a\u89c2\u6d4b\u5230\u7684\u7269\u54c1\u4efb\u610f\u89c6\u4e3a\u8d1f\u6837\u672c\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6548\u679c\u3002", "method": "\u63d0\u51faVI-MMRec\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u6a21\u6001\u7279\u5f81\u76f8\u4f3c\u6027\u7684\u865a\u62df\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u6765\u4e30\u5bcc\u7a00\u758f\u4ea4\u4e92\u3002\u91c7\u7528\u4e24\u79cd\u7b56\u7565\uff1a1) Overlay\u7b56\u7565\u72ec\u7acb\u805a\u5408\u6a21\u6001\u7279\u5b9a\u76f8\u4f3c\u6027\u4ee5\u4fdd\u7559\u6a21\u6001\u7279\u5b9a\u7528\u6237\u504f\u597d\uff1b2) Synergistic\u7b56\u7565\u6574\u4f53\u878d\u5408\u8de8\u6a21\u6001\u76f8\u4f3c\u6027\u4ee5\u6355\u6349\u4e92\u8865\u7528\u6237\u504f\u597d\u3002\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u7edf\u8ba1\u4fe1\u606f\u7684\u6743\u91cd\u5206\u914d\u673a\u5236\uff0c\u6839\u636e\u6570\u636e\u96c6\u7279\u5b9a\u6a21\u6001\u76f8\u5173\u6027\u81ea\u9002\u5e94\u5206\u914d\u6743\u91cd\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u4e03\u4e2a\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u8fdb\u884c\u7684\u7efc\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u4e86VI-MMRec\u7684\u6709\u6548\u6027\u3002\u8be5\u6846\u67b6\u80fd\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u6a21\u578b\u4e2d\uff0c\u65e0\u9700\u4fee\u6539\u6838\u5fc3\u67b6\u6784\uff0c\u4e14\u8bad\u7ec3\u65f6\u65e0\u989d\u5916\u5f00\u9500\u3002", "conclusion": "VI-MMRec\u662f\u4e00\u4e2a\u7075\u6d3b\u3001\u5373\u63d2\u5373\u7528\u7684\u6846\u67b6\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u591a\u6a21\u6001\u63a8\u8350\u4e2d\u7684\u6570\u636e\u7a00\u758f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u73b0\u6709\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u6613\u4e8e\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2512.08617", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08617", "abs": "https://arxiv.org/abs/2512.08617", "authors": ["Lifeng Han", "Paul Rayson", "Suzan Verberne", "Andrew Moore", "Goran Nenadic"], "title": "HealthcareNLP: where are we and what is next?", "comment": "Accepted Tutorial by LREC 2026 https://lrec2026.info/", "summary": "This proposed tutorial focuses on Healthcare Domain Applications of NLP, what we have achieved around HealthcareNLP, and the challenges that lie ahead for the future. Existing reviews in this domain either overlook some important tasks, such as synthetic data generation for addressing privacy concerns, or explainable clinical NLP for improved integration and implementation, or fail to mention important methodologies, including retrieval augmented generation and the neural symbolic integration of LLMs and KGs. In light of this, the goal of this tutorial is to provide an introductory overview of the most important sub-areas of a patient- and resource-oriented HealthcareNLP, with three layers of hierarchy: data/resource layer: annotation guidelines, ethical approvals, governance, synthetic data; NLP-Eval layer: NLP tasks such as NER, RE, sentiment analysis, and linking/coding with categorised methods, leading to explainable HealthAI; patients layer: Patient Public Involvement and Engagement (PPIE), health literacy, translation, simplification, and summarisation (also NLP tasks), and shared decision-making support. A hands-on session will be included in the tutorial for the audience to use HealthcareNLP applications. The target audience includes NLP practitioners in the healthcare application domain, NLP researchers who are interested in domain applications, healthcare researchers, and students from NLP fields. The type of tutorial is \"Introductory to CL/NLP topics (HealthcareNLP)\" and the audience does not need prior knowledge to attend this. Tutorial materials: https://github.com/4dpicture/HealthNLP", "AI": {"tldr": "\u8fd9\u662f\u4e00\u4e2a\u5173\u4e8e\u533b\u7597\u9886\u57dfNLP\u5e94\u7528\u7684\u5165\u95e8\u6559\u7a0b\uff0c\u6db5\u76d6\u6570\u636e\u5c42\u3001NLP\u8bc4\u4f30\u5c42\u548c\u60a3\u8005\u5c42\u4e09\u4e2a\u5c42\u6b21\uff0c\u5305\u62ec\u5b9e\u8df5\u73af\u8282\uff0c\u9762\u5411\u533b\u7597NLP\u4ece\u4e1a\u8005\u548c\u7814\u7a76\u4eba\u5458\u3002", "motivation": "\u73b0\u6709\u533b\u7597NLP\u7efc\u8ff0\u8981\u4e48\u5ffd\u7565\u91cd\u8981\u4efb\u52a1\uff08\u5982\u9690\u79c1\u4fdd\u62a4\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u3001\u53ef\u89e3\u91ca\u6027\u4e34\u5e8aNLP\uff09\uff0c\u8981\u4e48\u9057\u6f0f\u91cd\u8981\u65b9\u6cd5\uff08\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001LLM\u4e0eKG\u7684\u795e\u7ecf\u7b26\u53f7\u96c6\u6210\uff09\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u4f9b\u5168\u9762\u7684\u5165\u95e8\u6982\u8ff0\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u5c42\u6b21\u7ed3\u6784\uff1a1) \u6570\u636e/\u8d44\u6e90\u5c42\uff08\u6807\u6ce8\u6307\u5357\u3001\u4f26\u7406\u5ba1\u6279\u3001\u6cbb\u7406\u3001\u5408\u6210\u6570\u636e\uff09\uff1b2) NLP\u8bc4\u4f30\u5c42\uff08NER\u3001\u5173\u7cfb\u62bd\u53d6\u3001\u60c5\u611f\u5206\u6790\u7b49\u4efb\u52a1\u53ca\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff09\uff1b3) \u60a3\u8005\u5c42\uff08\u60a3\u8005\u53c2\u4e0e\u3001\u5065\u5eb7\u7d20\u517b\u3001\u7ffb\u8bd1\u7b80\u5316\u7b49\u4efb\u52a1\uff09\u3002\u5305\u542b\u5b9e\u8df5\u73af\u8282\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u533b\u7597NLP\u6559\u7a0b\u6846\u67b6\uff0c\u6db5\u76d6\u4ece\u6570\u636e\u51c6\u5907\u5230\u60a3\u8005\u5e94\u7528\u7684\u5168\u6d41\u7a0b\uff0c\u5e2e\u52a9\u53c2\u4e0e\u8005\u7406\u89e3\u533b\u7597NLP\u7684\u5173\u952e\u5b50\u9886\u57df\u548c\u6311\u6218\u3002", "conclusion": "\u8be5\u6559\u7a0b\u4e3a\u533b\u7597NLP\u9886\u57df\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5165\u95e8\u6307\u5bfc\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7efc\u8ff0\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\u548c\u5b9e\u8df5\u73af\u8282\u5e2e\u52a9\u4e0d\u540c\u80cc\u666f\u7684\u53c2\u4e0e\u8005\u638c\u63e1\u533b\u7597NLP\u7684\u6838\u5fc3\u6982\u5ff5\u548c\u5e94\u7528\u3002"}}
{"id": "2512.08646", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.08646", "abs": "https://arxiv.org/abs/2512.08646", "authors": ["Maximilian Kreutner", "Jens Rupprecht", "Georg Ahnert", "Ahmed Salem", "Markus Strohmaier"], "title": "QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language Models", "comment": "The Python package is available at https://github.com/dess-mannheim/QSTN/", "summary": "We introduce QSTN, an open-source Python framework for systematically generating responses from questionnaire-style prompts to support in-silico surveys and annotation tasks with large language models (LLMs). QSTN enables robust evaluation of questionnaire presentation, prompt perturbations, and response generation methods. Our extensive evaluation ($>40 $ million survey responses) shows that question structure and response generation methods have a significant impact on the alignment of generated survey responses with human answers, and can be obtained for a fraction of the compute cost. In addition, we offer a no-code user interface that allows researchers to set up robust experiments with LLMs without coding knowledge. We hope that QSTN will support the reproducibility and reliability of LLM-based research in the future.", "AI": {"tldr": "QSTN\u662f\u4e00\u4e2a\u5f00\u6e90\u7684Python\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u95ee\u5377\u5f0f\u63d0\u793a\u7cfb\u7edf\u751f\u6210LLM\u54cd\u5e94\uff0c\u652f\u6301\u8ba1\u7b97\u673a\u6a21\u62df\u8c03\u67e5\u548c\u6807\u6ce8\u4efb\u52a1\uff0c\u63d0\u4f9b\u65e0\u4ee3\u7801\u754c\u9762\u5e76\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u9700\u8981\u7cfb\u7edf\u5316\u751f\u6210\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u95ee\u5377\u5f0f\u63d0\u793a\u7684\u54cd\u5e94\uff0c\u4ee5\u652f\u6301\u8ba1\u7b97\u673a\u6a21\u62df\u8c03\u67e5\u548c\u6807\u6ce8\u4efb\u52a1\uff0c\u540c\u65f6\u8bc4\u4f30\u95ee\u5377\u5448\u73b0\u3001\u63d0\u793a\u6270\u52a8\u548c\u54cd\u5e94\u751f\u6210\u65b9\u6cd5\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86QSTN\u5f00\u6e90Python\u6846\u67b6\uff0c\u5305\u542b\u95ee\u5377\u5448\u73b0\u3001\u63d0\u793a\u6270\u52a8\u548c\u54cd\u5e94\u751f\u6210\u65b9\u6cd5\u7684\u8bc4\u4f30\u7cfb\u7edf\uff0c\u63d0\u4f9b\u65e0\u4ee3\u7801\u7528\u6237\u754c\u9762\uff0c\u5e76\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u8bc4\u4f30\uff08\u8d85\u8fc74000\u4e07\u6b21\u8c03\u67e5\u54cd\u5e94\uff09\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u95ee\u9898\u7ed3\u6784\u548c\u54cd\u5e94\u751f\u6210\u65b9\u6cd5\u5bf9\u751f\u6210\u8c03\u67e5\u54cd\u5e94\u4e0e\u4eba\u7c7b\u7b54\u6848\u7684\u4e00\u81f4\u6027\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u53ef\u4ee5\u4ee5\u6781\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u83b7\u5f97\u7ed3\u679c\u3002\u6846\u67b6\u652f\u6301\u65e0\u4ee3\u7801\u5b9e\u9a8c\u8bbe\u7f6e\u3002", "conclusion": "QSTN\u6846\u67b6\u6709\u671b\u652f\u6301\u672a\u6765\u57fa\u4e8eLLM\u7684\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b9e\u9a8c\u5de5\u5177\u3002"}}
{"id": "2512.08659", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08659", "abs": "https://arxiv.org/abs/2512.08659", "authors": ["Bohao Yang", "Rui Yang", "Joshua M. Biro", "Haoyuan Wang", "Jessica L. Handley", "Brianna Richardson", "Sophia Bessias", "Nicoleta Economou-Zavlanos", "Armando D. Bedoya", "Monica Agrawal", "Michael M. Zavlanos", "Anand Chowdhury", "Raj M. Ratwani", "Kai Sun", "Kathryn I. Pollak", "Michael J. Pencina", "Chuan Hong"], "title": "An Agentic AI System for Multi-Framework Communication Coding", "comment": null, "summary": "Clinical communication is central to patient outcomes, yet large-scale human annotation of patient-provider conversation remains labor-intensive, inconsistent, and difficult to scale. Existing approaches based on large language models typically rely on single-task models that lack adaptability, interpretability, and reliability, especially when applied across various communication frameworks and clinical domains. In this study, we developed a Multi-framework Structured Agentic AI system for Clinical Communication (MOSAIC), built on a LangGraph-based architecture that orchestrates four core agents, including a Plan Agent for codebook selection and workflow planning, an Update Agent for maintaining up-to-date retrieval databases, a set of Annotation Agents that applies codebook-guided retrieval-augmented generation (RAG) with dynamic few-shot prompting, and a Verification Agent that provides consistency checks and feedback. To evaluate performance, we compared MOSAIC outputs against gold-standard annotations created by trained human coders. We developed and evaluated MOSAIC using 26 gold standard annotated transcripts for training and 50 transcripts for testing, spanning rheumatology and OB/GYN domains. On the test set, MOSAIC achieved an overall F1 score of 0.928. Performance was highest in the Rheumatology subset (F1 = 0.962) and strongest for Patient Behavior (e.g., patients asking questions, expressing preferences, or showing assertiveness). Ablations revealed that MOSAIC outperforms baseline benchmarking.", "AI": {"tldr": "MOSAIC\u662f\u4e00\u4e2a\u57fa\u4e8eLangGraph\u7684\u591a\u6846\u67b6\u7ed3\u6784\u5316AI\u7cfb\u7edf\uff0c\u7528\u4e8e\u4e34\u5e8a\u6c9f\u901a\u5206\u6790\uff0c\u901a\u8fc7\u56db\u4e2a\u6838\u5fc3\u4ee3\u7406\u5b9e\u73b0\u4ee3\u7801\u672c\u9009\u62e9\u3001\u6570\u636e\u66f4\u65b0\u3001\u6ce8\u91ca\u751f\u6210\u548c\u9a8c\u8bc1\uff0c\u5728\u98ce\u6e7f\u75c5\u5b66\u548c\u5987\u4ea7\u79d1\u9886\u57df\u8fbe\u52300.928\u7684F1\u5206\u6570\u3002", "motivation": "\u4e34\u5e8a\u6c9f\u901a\u5bf9\u60a3\u8005\u7ed3\u679c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5927\u89c4\u6a21\u4eba\u5de5\u6807\u6ce8\u60a3\u8005-\u63d0\u4f9b\u8005\u5bf9\u8bdd\u52b3\u52a8\u5bc6\u96c6\u3001\u4e0d\u4e00\u81f4\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u7f3a\u4e4f\u9002\u5e94\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u7684\u5355\u4efb\u52a1\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u8de8\u4e0d\u540c\u6c9f\u901a\u6846\u67b6\u548c\u4e34\u5e8a\u9886\u57df\u65f6\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8eLangGraph\u67b6\u6784\u7684\u591a\u6846\u67b6\u7ed3\u6784\u5316AI\u7cfb\u7edf(MOSAIC)\uff0c\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u4ee3\u7406\uff1a\u8ba1\u5212\u4ee3\u7406\uff08\u4ee3\u7801\u672c\u9009\u62e9\u548c\u6d41\u7a0b\u89c4\u5212\uff09\u3001\u66f4\u65b0\u4ee3\u7406\uff08\u7ef4\u62a4\u6700\u65b0\u68c0\u7d22\u6570\u636e\u5e93\uff09\u3001\u6ce8\u91ca\u4ee3\u7406\uff08\u5e94\u7528\u4ee3\u7801\u672c\u5f15\u5bfc\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u52a8\u6001\u5c11\u6837\u672c\u63d0\u793a\uff09\u3001\u9a8c\u8bc1\u4ee3\u7406\uff08\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u53cd\u9988\uff09\u3002\u4f7f\u752826\u4e2a\u9ec4\u91d1\u6807\u51c6\u6807\u6ce8\u8f6c\u5f55\u672c\u8fdb\u884c\u8bad\u7ec3\uff0c50\u4e2a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5728\u6d4b\u8bd5\u96c6\u4e0a\uff0cMOSAIC\u8fbe\u5230\u603b\u4f53F1\u5206\u65700.928\u3002\u98ce\u6e7f\u75c5\u5b66\u5b50\u96c6\u8868\u73b0\u6700\u4f73\uff08F1=0.962\uff09\uff0c\u60a3\u8005\u884c\u4e3a\u7c7b\u522b\uff08\u5982\u60a3\u8005\u63d0\u95ee\u3001\u8868\u8fbe\u504f\u597d\u6216\u8868\u73b0\u81ea\u4fe1\uff09\u8868\u73b0\u6700\u5f3a\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793aMOSAIC\u4f18\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "MOSAIC\u7cfb\u7edf\u901a\u8fc7\u591a\u4ee3\u7406\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u4e34\u5e8a\u6c9f\u901a\u6807\u6ce8\u7684\u6269\u5c55\u6027\u548c\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5728\u4e0d\u540c\u4e34\u5e8a\u9886\u57df\u548c\u6c9f\u901a\u6846\u67b6\u4e2d\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u4e34\u5e8a\u6c9f\u901a\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.08713", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08713", "abs": "https://arxiv.org/abs/2512.08713", "authors": ["Ekhi Azurmendi", "Xabier Arregi", "Oier Lopez de Lacalle"], "title": "Automatic Essay Scoring and Feedback Generation in Basque Language Learning", "comment": "Submitted to LREC 2026", "summary": "This paper introduces the first publicly available dataset for Automatic Essay Scoring (AES) and feedback generation in Basque, targeting the CEFR C1 proficiency level. The dataset comprises 3,200 essays from HABE, each annotated by expert evaluators with criterion specific scores covering correctness, richness, coherence, cohesion, and task alignment enriched with detailed feedback and error examples. We fine-tune open-source models, including RoBERTa-EusCrawl and Latxa 8B/70B, for both scoring and explanation generation. Our experiments show that encoder models remain highly reliable for AES, while supervised fine-tuning (SFT) of Latxa significantly enhances performance, surpassing state-of-the-art (SoTA) closed-source systems such as GPT-5 and Claude Sonnet 4.5 in scoring consistency and feedback quality. We also propose a novel evaluation methodology for assessing feedback generation, combining automatic consistency metrics with expert-based validation of extracted learner errors. Results demonstrate that the fine-tuned Latxa model produces criterion-aligned, pedagogically meaningful feedback and identifies a wider range of error types than proprietary models. This resource and benchmark establish a foundation for transparent, reproducible, and educationally grounded NLP research in low-resource languages such as Basque.", "AI": {"tldr": "\u9996\u4e2a\u5df4\u65af\u514b\u8bed\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u4e0e\u53cd\u9988\u751f\u6210\u516c\u5f00\u6570\u636e\u96c6\uff0c\u5305\u542b3200\u7bc7C1\u6c34\u5e73\u4f5c\u6587\uff0c\u4e13\u5bb6\u6807\u6ce8\u8bc4\u5206\u4e0e\u8be6\u7ec6\u53cd\u9988\uff0c\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u5728\u8bc4\u5206\u4e00\u81f4\u6027\u548c\u53cd\u9988\u8d28\u91cf\u4e0a\u8d85\u8d8aGPT-5\u7b49\u95ed\u6e90\u7cfb\u7edf\u3002", "motivation": "\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5df4\u65af\u514b\u8bed\uff09\u5efa\u7acb\u900f\u660e\u3001\u53ef\u590d\u73b0\u4e14\u6559\u80b2\u57fa\u7840\u624e\u5b9e\u7684NLP\u7814\u7a76\u57fa\u7840\uff0c\u586b\u8865\u5df4\u65af\u514b\u8bed\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u4e0e\u53cd\u9988\u751f\u6210\u9886\u57df\u516c\u5f00\u6570\u636e\u96c6\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5305\u542b3200\u7bc7C1\u6c34\u5e73\u4f5c\u6587\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u7bc7\u7531\u4e13\u5bb6\u6807\u6ce8\u4e94\u4e2a\u7ef4\u5ea6\u7684\u8bc4\u5206\u548c\u8be6\u7ec6\u53cd\u9988\uff1b\u5fae\u8c03RoBERTa-EusCrawl\u548cLatxa 8B/70B\u7b49\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u8bc4\u5206\u548c\u89e3\u91ca\u751f\u6210\uff1b\u63d0\u51fa\u7ed3\u5408\u81ea\u52a8\u4e00\u81f4\u6027\u6307\u6807\u548c\u4e13\u5bb6\u9a8c\u8bc1\u7684\u65b0\u578b\u53cd\u9988\u751f\u6210\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u7f16\u7801\u5668\u6a21\u578b\u5728\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u4e0a\u4fdd\u6301\u9ad8\u53ef\u9760\u6027\uff1b\u76d1\u7763\u5fae\u8c03\u7684Latxa\u6a21\u578b\u5728\u8bc4\u5206\u4e00\u81f4\u6027\u548c\u53cd\u9988\u8d28\u91cf\u4e0a\u8d85\u8d8aGPT-5\u548cClaude Sonnet 4.5\u7b49\u6700\u5148\u8fdb\u7684\u95ed\u6e90\u7cfb\u7edf\uff1b\u5fae\u8c03\u540e\u7684Latxa\u6a21\u578b\u80fd\u751f\u6210\u4e0e\u8bc4\u5206\u6807\u51c6\u5bf9\u9f50\u3001\u5177\u6709\u6559\u5b66\u610f\u4e49\u7684\u53cd\u9988\uff0c\u5e76\u80fd\u8bc6\u522b\u6bd4\u4e13\u6709\u6a21\u578b\u66f4\u5e7f\u6cdb\u7684\u9519\u8bef\u7c7b\u578b\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u548c\u57fa\u51c6\u4e3a\u5df4\u65af\u514b\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u900f\u660e\u3001\u53ef\u590d\u73b0\u4e14\u6559\u80b2\u57fa\u7840\u624e\u5b9e\u7684NLP\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u5f00\u6e90\u6a21\u578b\u5728\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u548c\u53cd\u9988\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.08777", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08777", "abs": "https://arxiv.org/abs/2512.08777", "authors": ["David Samuel", "Lilja \u00d8vrelid", "Erik Velldal", "Andrey Kutuzov"], "title": "Fluent Alignment with Disfluent Judges: Post-training for Lower-resource Languages", "comment": null, "summary": "We propose a post-training method for lower-resource languages that preserves fluency of language models even when aligned by disfluent reward models. Preference-optimization is now a well-researched topic, but previous work has mostly addressed models for English and Chinese. Lower-resource languages lack both datasets written by native speakers and language models capable of generating fluent synthetic data. Thus, in this work, we focus on developing a fluent preference-aligned language model without any instruction-tuning data in the target language. Our approach uses an on-policy training method, which we compare with two common approaches: supervised finetuning on machine-translated data and multilingual finetuning. We conduct a case study on Norwegian Bokm\u00e5l and evaluate fluency through native-speaker assessments. The results show that the on-policy aspect is crucial and outperforms the alternatives without relying on any hard-to-obtain data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5373\u4f7f\u4f7f\u7528\u4e0d\u6d41\u7545\u7684\u5956\u52b1\u6a21\u578b\u8fdb\u884c\u5bf9\u9f50\uff0c\u4e5f\u80fd\u4fdd\u6301\u8bed\u8a00\u6a21\u578b\u7684\u6d41\u7545\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u504f\u597d\u4f18\u5316\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u82f1\u8bed\u548c\u4e2d\u6587\u4e0a\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u65e2\u7f3a\u4e4f\u6bcd\u8bed\u8005\u7f16\u5199\u7684\u6570\u636e\u96c6\uff0c\u4e5f\u7f3a\u4e4f\u80fd\u591f\u751f\u6210\u6d41\u7545\u5408\u6210\u6570\u636e\u7684\u8bed\u8a00\u6a21\u578b\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u76ee\u6807\u8bed\u8a00\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u7684\u6d41\u7545\u504f\u597d\u5bf9\u9f50\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7b56\u7565\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u4e0e\u4e24\u79cd\u5e38\u89c1\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff1a\u5728\u673a\u5668\u7ffb\u8bd1\u6570\u636e\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u4ee5\u53ca\u591a\u8bed\u8a00\u5fae\u8c03\u3002\u4ee5\u632a\u5a01\u535a\u514b\u9a6c\u5c14\u8bed\u4e3a\u6848\u4f8b\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u57fa\u4e8e\u7b56\u7565\u7684\u8bad\u7ec3\u65b9\u6cd5\u5728\u4fdd\u6301\u6d41\u7545\u6027\u65b9\u9762\u8868\u73b0\u5173\u952e\uff0c\u4f18\u4e8e\u5176\u4ed6\u66ff\u4ee3\u65b9\u6cd5\uff0c\u4e14\u65e0\u9700\u4f9d\u8d56\u96be\u4ee5\u83b7\u53d6\u7684\u6570\u636e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u504f\u597d\u5bf9\u9f50\u89e3\u51b3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u7b56\u7565\u8bad\u7ec3\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u7c7b\u4f3c\u8bed\u8a00\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2512.08786", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08786", "abs": "https://arxiv.org/abs/2512.08786", "authors": ["Mahmoud Srewa", "Tianyu Zhao", "Salma Elmalaki"], "title": "A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs", "comment": null, "summary": "This paper addresses the challenge of aligning large language models (LLMs) with diverse human preferences within federated learning (FL) environments, where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group's historical alignment performance. Our experiments on question-answering (Q/A) tasks using a PPO-based RLHF pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating LLM behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u4e0e\u591a\u6837\u5316\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u7684\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u805a\u5408\u7b56\u7565\u6765\u5e73\u8861\u5bf9\u9f50\u8d28\u91cf\u4e0e\u516c\u5e73\u6027\u3002", "motivation": "\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u6807\u51c6\u65b9\u6cd5\u5f80\u5f80\u65e0\u6cd5\u5145\u5206\u4ee3\u8868\u591a\u6837\u5316\u7684\u4eba\u7c7b\u504f\u597d\u89c2\u70b9\uff0c\u5bfc\u81f4LLM\u5bf9\u9f50\u5b58\u5728\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u8ba9\u5404\u7ec4\u672c\u5730\u8bc4\u4f30\u751f\u6210\u7ed3\u679c\u5e76\u4ea7\u751f\u5956\u52b1\u4fe1\u53f7\uff0c\u670d\u52a1\u5668\u805a\u5408\u7ec4\u7ea7\u5956\u52b1\u800c\u4e0d\u8bbf\u95ee\u539f\u59cb\u6570\u636e\u3002\u8bc4\u4f30\u4e86\u6807\u51c6\u805a\u5408\u6280\u672f\uff08\u6700\u5c0f\u503c\u3001\u6700\u5927\u503c\u3001\u5e73\u5747\u503c\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5386\u53f2\u5bf9\u9f50\u6027\u80fd\u52a8\u6001\u8c03\u6574\u504f\u597d\u6743\u91cd\u7684\u81ea\u9002\u5e94\u65b9\u6848\u3002", "result": "\u5728\u95ee\u7b54\u4efb\u52a1\u4e0a\u4f7f\u7528PPO-based RLHF\u7ba1\u9053\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u81ea\u9002\u5e94\u65b9\u6cd5\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u5bf9\u9f50\u5206\u6570\u7684\u540c\u65f6\uff0c\u59cb\u7ec8\u5b9e\u73b0\u66f4\u4f18\u7684\u516c\u5e73\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u8bc4\u4f30LLM\u5728\u591a\u6837\u5316\u4eba\u7fa4\u4e2d\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u7a33\u5065\u65b9\u6cd5\uff0c\u5e76\u4e3a\u5f00\u53d1\u771f\u6b63\u591a\u5143\u5316\u548c\u516c\u5e73\u5bf9\u9f50\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.08814", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08814", "abs": "https://arxiv.org/abs/2512.08814", "authors": ["Yifan Lyu", "Liang Zhang"], "title": "Ask, Answer, and Detect: Role-Playing LLMs for Personality Detection with Question-Conditioned Mixture-of-Experts", "comment": null, "summary": "Understanding human personality is crucial for web applications such as personalized recommendation and mental health assessment. Existing studies on personality detection predominantly adopt a \"posts -> user vector -> labels\" modeling paradigm, which encodes social media posts into user representations for predicting personality labels (e.g., MBTI labels). While recent advances in large language models (LLMs) have improved text encoding capacities, these approaches remain constrained by limited supervision signals due to label scarcity, and under-specified semantic mappings between user language and abstract psychological constructs. We address these challenges by proposing ROME, a novel framework that explicitly injects psychological knowledge into personality detection. Inspired by standardized self-assessment tests, ROME leverages LLMs' role-play capability to simulate user responses to validated psychometric questionnaires. These generated question-level answers transform free-form user posts into interpretable, questionnaire-grounded evidence linking linguistic cues to personality labels, thereby providing rich intermediate supervision to mitigate label scarcity while offering a semantic reasoning chain that guides and simplifies the text-to-personality mapping learning. A question-conditioned Mixture-of-Experts module then jointly routes over post and question representations, learning to answer questionnaire items under explicit supervision. The predicted answers are summarized into an interpretable answer vector and fused with the user representation for final prediction within a multi-task learning framework, where question answering serves as a powerful auxiliary task for personality detection. Extensive experiments on two real-world datasets demonstrate that ROME consistently outperforms state-of-the-art baselines, achieving improvements (15.41% on Kaggle dataset).", "AI": {"tldr": "ROME\u662f\u4e00\u4e2a\u5c06\u5fc3\u7406\u5b66\u77e5\u8bc6\u6ce8\u5165\u4eba\u683c\u68c0\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7LLMs\u6a21\u62df\u7528\u6237\u56de\u7b54\u5fc3\u7406\u6d4b\u91cf\u95ee\u5377\uff0c\u5c06\u81ea\u7531\u6587\u672c\u8f6c\u6362\u4e3a\u53ef\u89e3\u91ca\u7684\u95ee\u5377\u8bc1\u636e\uff0c\u663e\u8457\u63d0\u5347\u4eba\u683c\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u683c\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u91c7\u7528\"\u5e16\u5b50->\u7528\u6237\u5411\u91cf->\u6807\u7b7e\"\u8303\u5f0f\uff0c\u867d\u7136LLMs\u63d0\u5347\u4e86\u6587\u672c\u7f16\u7801\u80fd\u529b\uff0c\u4f46\u4ecd\u53d7\u9650\u4e8e\u6807\u7b7e\u7a00\u7f3a\u6027\u4e0d\u8db3\u4ee5\u53ca\u7528\u6237\u8bed\u8a00\u4e0e\u62bd\u8c61\u5fc3\u7406\u6784\u5ff5\u4e4b\u95f4\u7684\u8bed\u4e49\u6620\u5c04\u4e0d\u660e\u786e\u3002", "method": "ROME\u5229\u7528LLMs\u7684\u89d2\u8272\u626e\u6f14\u80fd\u529b\u6a21\u62df\u7528\u6237\u56de\u7b54\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5fc3\u7406\u6d4b\u91cf\u95ee\u5377\uff0c\u5c06\u7528\u6237\u5e16\u5b50\u8f6c\u6362\u4e3a\u53ef\u89e3\u91ca\u7684\u95ee\u5377\u7ea7\u7b54\u6848\u3002\u91c7\u7528\u95ee\u9898\u6761\u4ef6\u5316\u7684Mixture-of-Experts\u6a21\u5757\u8054\u5408\u8def\u7531\u5e16\u5b50\u548c\u95ee\u9898\u8868\u793a\uff0c\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u5c06\u9884\u6d4b\u7b54\u6848\u6c47\u603b\u4e3a\u53ef\u89e3\u91ca\u7684\u7b54\u6848\u5411\u91cf\u5e76\u4e0e\u7528\u6237\u8868\u793a\u878d\u5408\u8fdb\u884c\u6700\u7ec8\u9884\u6d4b\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cROME\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728Kaggle\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8615.41%\u7684\u6539\u8fdb\u3002", "conclusion": "ROME\u901a\u8fc7\u5c06\u5fc3\u7406\u5b66\u77e5\u8bc6\u6ce8\u5165\u4eba\u683c\u68c0\u6d4b\uff0c\u5229\u7528LLMs\u6a21\u62df\u95ee\u5377\u56de\u7b54\uff0c\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u4e2d\u95f4\u76d1\u7763\u548c\u8bed\u4e49\u63a8\u7406\u94fe\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u6807\u7b7e\u7a00\u7f3a\u95ee\u9898\u5e76\u7b80\u5316\u4e86\u6587\u672c\u5230\u4eba\u683c\u7684\u6620\u5c04\u5b66\u4e60\u3002"}}
{"id": "2512.08819", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08819", "abs": "https://arxiv.org/abs/2512.08819", "authors": ["Ferdinand Kapl", "Emmanouil Angelis", "Tobias H\u00f6ppe", "Kaitlin Maile", "Johannes von Oswald", "Nino Scherrer", "Stefan Bauer"], "title": "Do Depth-Grown Models Overcome the Curse of Depth? An In-Depth Analysis", "comment": null, "summary": "Gradually growing the depth of Transformers during training can not only reduce training cost but also lead to improved reasoning performance, as shown by MIDAS (Saunshi et al., 2024). Thus far, however, a mechanistic understanding of these gains has been missing. In this work, we establish a connection to recent work showing that layers in the second half of non-grown, pre-layernorm Transformers contribute much less to the final output distribution than those in the first half - also known as the Curse of Depth (Sun et al., 2025, Csord\u00e1s et al., 2025). Using depth-wise analyses, we demonstrate that growth via gradual middle stacking yields more effective utilization of model depth, alters the residual stream structure, and facilitates the formation of permutable computational blocks. In addition, we propose a lightweight modification of MIDAS that yields further improvements in downstream reasoning benchmarks. Overall, this work highlights how the gradual growth of model depth can lead to the formation of distinct computational circuits and overcome the limited depth utilization seen in standard non-grown models.", "AI": {"tldr": "\u6df1\u5ea6\u9010\u6e10\u589e\u957f\u7684Transformer\u8bad\u7ec3\u4e0d\u4ec5\u80fd\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\uff0c\u8fd8\u80fd\u63d0\u5347\u63a8\u7406\u6027\u80fd\uff0c\u672c\u6587\u901a\u8fc7\u673a\u5236\u5206\u6790\u63ed\u793a\u4e86\u8fd9\u79cd\u6539\u8fdb\u6e90\u4e8e\u66f4\u597d\u7684\u6df1\u5ea6\u5229\u7528\u548c\u8ba1\u7b97\u7ed3\u6784\u4f18\u5316\u3002", "motivation": "MIDAS\u65b9\u6cd5\u663e\u793a\u9010\u6e10\u589e\u52a0Transformer\u6df1\u5ea6\u80fd\u63d0\u5347\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u7f3a\u4e4f\u673a\u5236\u7406\u89e3\u3002\u540c\u65f6\uff0c\u5df2\u6709\u7814\u7a76\u8868\u660e\u6807\u51c6Transformer\u5b58\u5728\"\u6df1\u5ea6\u8bc5\u5492\"\u73b0\u8c61\u2014\u2014\u540e\u534a\u90e8\u5206\u5c42\u5bf9\u8f93\u51fa\u7684\u8d21\u732e\u8fdc\u5c0f\u4e8e\u524d\u534a\u90e8\u5206\u3002", "method": "\u901a\u8fc7\u6df1\u5ea6\u5206\u6790\u6280\u672f\uff0c\u7814\u7a76\u9010\u6b65\u4e2d\u95f4\u5806\u53e0\u589e\u957f\u65b9\u5f0f\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u3002\u63d0\u51faMIDAS\u7684\u8f7b\u91cf\u7ea7\u6539\u8fdb\uff0c\u5e76\u5728\u4e0b\u6e38\u63a8\u7406\u57fa\u51c6\u4e0a\u6d4b\u8bd5\u3002", "result": "\u9010\u6b65\u589e\u957f\u6df1\u5ea6\u80fd\u66f4\u6709\u6548\u5730\u5229\u7528\u6a21\u578b\u6df1\u5ea6\uff0c\u6539\u53d8\u6b8b\u5dee\u6d41\u7ed3\u6784\uff0c\u4fc3\u8fdb\u53ef\u7f6e\u6362\u8ba1\u7b97\u5757\u7684\u5f62\u6210\u3002\u6539\u8fdb\u7684MIDAS\u5728\u63a8\u7406\u57fa\u51c6\u4e0a\u83b7\u5f97\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "conclusion": "\u6df1\u5ea6\u9010\u6b65\u589e\u957f\u80fd\u5f62\u6210\u72ec\u7279\u7684\u8ba1\u7b97\u7535\u8def\uff0c\u514b\u670d\u6807\u51c6\u6a21\u578b\u4e2d\u6df1\u5ea6\u5229\u7528\u6709\u9650\u7684\u95ee\u9898\uff0c\u4e3a\u9ad8\u6548\u8bad\u7ec3\u548c\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u673a\u5236\u89e3\u91ca\u3002"}}
{"id": "2512.08892", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08892", "abs": "https://arxiv.org/abs/2512.08892", "authors": ["Guangzhi Xiong", "Zhenghao He", "Bohan Liu", "Sanchit Sinha", "Aidong Zhang"], "title": "Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.", "AI": {"tldr": "RAGLens\uff1a\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u81ea\u7f16\u7801\u5668\u548cLLM\u5185\u90e8\u8868\u5f81\u7684\u8f7b\u91cf\u7ea7RAG\u5e7b\u89c9\u68c0\u6d4b\u5668\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u8bad\u7ec3\u6216\u5916\u90e8LLM\u67e5\u8be2\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709RAG\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e24\u5927\u95ee\u9898\uff1a1\uff09\u9700\u8981\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u68c0\u6d4b\u5668\u8bad\u7ec3\uff1b2\uff09\u4f9d\u8d56\u5916\u90e8LLM\u6cd5\u5b98\u5bfc\u81f4\u9ad8\u63a8\u7406\u6210\u672c\u3002\u867d\u7136\u6709\u4e9b\u65b9\u6cd5\u5c1d\u8bd5\u5229\u7528LLM\u5185\u90e8\u8868\u5f81\uff0c\u4f46\u51c6\u786e\u7387\u6709\u9650\u3002", "method": "\u5229\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u89e3\u8026LLM\u5185\u90e8\u6fc0\u6d3b\uff0c\u8bc6\u522bRAG\u5e7b\u89c9\u89e6\u53d1\u7279\u5f81\u3002\u57fa\u4e8e\u4fe1\u606f\u7279\u5f81\u9009\u62e9\u548c\u52a0\u6027\u7279\u5f81\u5efa\u6a21\u7684\u7cfb\u7edf\u5316\u6d41\u7a0b\uff0c\u6784\u5efa\u8f7b\u91cf\u7ea7\u5e7b\u89c9\u68c0\u6d4b\u5668RAGLens\u3002", "result": "RAGLens\u5728\u68c0\u6d4b\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u4f9d\u636e\uff0c\u5e76\u80fd\u6709\u6548\u8fdb\u884c\u540e\u5904\u7406\u7f13\u89e3\u4e0d\u5fe0\u5b9e\u7684RAG\u8f93\u51fa\u3002\u540c\u65f6\u63ed\u793a\u4e86LLM\u4e2d\u5e7b\u89c9\u76f8\u5173\u4fe1\u53f7\u7684\u5206\u5e03\u65b0\u89c1\u89e3\u3002", "conclusion": "RAGLens\u901a\u8fc7\u5229\u7528LLM\u5185\u90e8\u8868\u5f81\u548c\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u8f7b\u91cf\u4e14\u53ef\u89e3\u91ca\u7684RAG\u5e7b\u89c9\u68c0\u6d4b\uff0c\u4e3aRAG\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
