<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 27]
- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search](https://arxiv.org/abs/2511.19648)
*Manil Shrestha,Edward Kim*

Main category: cs.CL

TL;DR: 提出了两种混合算法来解决知识图谱多跳问答的效率与可验证性问题：LLM引导规划使用单次LLM调用预测关系序列，嵌入引导神经搜索完全消除LLM调用，通过轻量级边评分器实现100倍加速。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多跳问答方法存在计算成本高和答案缺乏可验证性的问题，限制了实际部署。

Method: 1) LLM引导规划：单次LLM调用预测关系序列，通过广度优先搜索执行；2) 嵌入引导神经搜索：融合文本和图嵌入的轻量级边评分器，完全避免LLM调用。

Result: 在MetaQA上评估显示，LLM引导规划达到接近完美准确率（micro-F1 > 0.90），嵌入引导神经搜索实现100倍加速且保持竞争力准确率。通过知识蒸馏将规划能力压缩到4B参数模型中。

Conclusion: 可验证的多跳推理不需要大规模模型，而是需要结合符号结构与学习表示的适当架构归纳偏置。

Abstract: Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.

</details>


### [2] [Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case Study on Emotion Detection in Persian](https://arxiv.org/abs/2511.19719)
*Mobina Mehrazar,Mohammad Amin Yousefi,Parisa Abolfath Beygi,Behnam Bahrak*

Main category: cs.CL

TL;DR: 评估LLM在波斯语情感分类中生成解释的忠实度，发现模型解释与人类判断存在显著差异，尽管分类性能良好。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地生成自解释，特别是在低资源语言中，这些解释的忠实性令人担忧。本研究旨在评估波斯语情感分类中LLM生成解释的忠实度。

Method: 通过比较模型识别的影响词与人类标注者的识别结果，使用基于token级对数概率的置信度评分来评估忠实度。测试了两种提示策略：预测后解释和解释后预测。

Result: LLM在分类性能上表现强劲，但生成的解释往往偏离忠实推理，模型间的解释一致性高于与人类判断的一致性。

Conclusion: 当前解释方法和指标存在局限性，需要更稳健的方法来确保LLM在多语言和低资源环境中的可靠性。

Abstract: Large language models (LLMs) are increasingly used to generate self-explanations alongside their predictions, a practice that raises concerns about the faithfulness of these explanations, especially in low-resource languages. This study evaluates the faithfulness of LLM-generated explanations in the context of emotion classification in Persian, a low-resource language, by comparing the influential words identified by the model against those identified by human annotators. We assess faithfulness using confidence scores derived from token-level log-probabilities. Two prompting strategies, differing in the order of explanation and prediction (Predict-then-Explain and Explain-then-Predict), are tested for their impact on explanation faithfulness. Our results reveal that while LLMs achieve strong classification performance, their generated explanations often diverge from faithful reasoning, showing greater agreement with each other than with human judgments. These results highlight the limitations of current explanation methods and metrics, emphasizing the need for more robust approaches to ensure LLM reliability in multilingual and low-resource contexts.

</details>


### [3] [Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation](https://arxiv.org/abs/2511.19739)
*Richard J. Young,Alice M. Matthews*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535 cardiology text pairs derived from authoritative medical textbooks. Results demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve superior domain-specific performance (separation score: 0.510) compared to larger decoder-based models, while requiring significantly fewer computational resources. The findings challenge the assumption that larger language models necessarily produce better domain-specific embeddings and provide practical guidance for clinical NLP system development. All models, training code, and evaluation datasets are publicly available to support reproducible research in medical informatics.

</details>


### [4] [What does it mean to understand language?](https://arxiv.org/abs/2511.19757)
*Colton Casto,Anna Ivanova,Evelina Fedorenko,Nancy Kanwisher*

Main category: cs.CL

TL;DR: 该论文提出语言理解需要将信息从语言系统导出到其他大脑区域，以构建丰富的心理模型，并讨论了测试这一假设的神经科学方法。


<details>
  <summary>Details</summary>
Motivation: 语言理解不仅仅是提取语言输入的表层意义，还需要构建所描述情境的丰富心理模型。由于大脑核心语言系统的处理能力有限，深度理解语言需要将信息导出到其他大脑区域。

Method: 回顾现有证据支持这一假设，并利用认知神经科学的最新进展，包括概念基础和方法，来直接测试这一假设。

Result: 提出了一个新的策略，通过神经科学方法揭示语言理解的认知和神经机制。

Conclusion: 深度语言理解需要将信息从语言系统导出到其他大脑区域，这一假设可以通过现代神经科学方法进行测试，从而更好地理解语言理解的本质。

Abstract: Language understanding entails not just extracting the surface-level meaning of the linguistic input, but constructing rich mental models of the situation it describes. Here we propose that because processing within the brain's core language system is fundamentally limited, deeply understanding language requires exporting information from the language system to other brain regions that compute perceptual and motor representations, construct mental models, and store our world knowledge and autobiographical memories. We review the existing evidence for this hypothesis, and argue that recent progress in cognitive neuroscience provides both the conceptual foundation and the methods to directly test it, thus opening up a new strategy to reveal what it means, cognitively and neurally, to understand language.

</details>


### [5] [Gender Bias in Emotion Recognition by Large Language Models](https://arxiv.org/abs/2511.19785)
*Maureen Herbert,Katie Sun,Angelica Lim,Yasaman Etesam*

Main category: cs.CL

TL;DR: 本研究评估了大语言模型在情感心智理论中的性别偏见，并测试了多种去偏策略，发现基于训练的方法比提示工程更有效。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在日常生活中日益普及，评估和确保其公平性变得尤为重要，特别是在情感心智理论领域是否存在性别偏见。

Method: 通过向模型描述一个人及其环境，询问"这个人感觉如何？"来评估性别偏见，并提出了多种去偏策略进行测试。

Result: 研究发现大语言模型确实存在性别偏见，且基于训练的去偏干预比推理时的提示工程方法更能有效减少偏见。

Conclusion: 实现有意义的偏见减少需要基于训练的方法，而不能仅仅依赖推理时的提示工程方法。

Abstract: The rapid advancement of large language models (LLMs) and their growing integration into daily life underscore the importance of evaluating and ensuring their fairness. In this work, we examine fairness within the domain of emotional theory of mind, investigating whether LLMs exhibit gender biases when presented with a description of a person and their environment and asked, "How does this person feel?". Furthermore, we propose and evaluate several debiasing strategies, demonstrating that achieving meaningful reductions in bias requires training based interventions rather than relying solely on inference-time prompt-based approaches such as prompt engineering.

</details>


### [6] [Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions](https://arxiv.org/abs/2511.19816)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 本文提出了NRC VAD Lexicon v2，这是一个包含10,000个英语多词表达(MWEs)及其组成词的效价、唤醒度和支配度人工评分的词典，扩展了2018年发布的v1版本，新增了25,000个单词，总共覆盖10k MWEs和25k单词。


<details>
  <summary>Details</summary>
Motivation: 现有词典如2018年发布的NRC VAD Lexicon只包含单词的VAD关联评分，缺乏对多词表达(MWEs)的情感分析覆盖，且需要更新自2018年以来变得更加常见的单词。

Method: 通过人工评分收集10,000个英语多词表达及其组成词的效价、唤醒度和支配度评分，并扩展单词语料库覆盖范围。

Result: 新词典包含10k MWEs和25k单词的VAD评分，数据显示这些关联具有高度可靠性。研究发现MWEs（习语、名词复合词和动词粒子结构）表现出强烈的情感性，并分析了MWEs的情感组合性程度。

Conclusion: NRC VAD Lexicon v2为NLP、心理学、公共卫生、数字人文和社会科学等多个领域的研究提供了重要资源，可免费获取。

Abstract: Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we present a complement to it, which has human ratings of valence, arousal, and dominance for 10k English Multiword Expressions (MWEs) and their constituent words. We also increase the coverage of unigrams, especially words that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now has entries for 10k MWEs and 25k words, in addition to the entries in v1. We show that the associations are highly reliable. We use the lexicon to examine emotional characteristics of MWEs, including: 1. The degree to which MWEs (idioms, noun compounds, and verb particle constructions) exhibit strong emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon enables a wide variety of research in NLP, Psychology, Public Health, Digital Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html

</details>


### [7] [Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana](https://arxiv.org/abs/2511.19818)
*Koena Ronny Mabokela,Tim Schlippe,Mpho Raborife,Turgay Celik*

Main category: cs.CL

TL;DR: 提出了一种利用表情符号和情感词汇的自动语言无关情感标注方法，在英语、Sepedi和Setswana三种语言的情感分析中取得较好效果，平均只需修正34%的自动标注结果。


<details>
  <summary>Details</summary>
Motivation: 非洲语言作为低资源语言缺乏标注数据，手动标注耗时昂贵，需要自动高效的标注方法。

Method: 利用表情符号和情感词汇信息开发语言无关的自动情感标注方法。

Result: 英语推文标注准确率66%，Sepedi推文69%，Setswana推文63%，平均只需修正34%的自动标注结果。

Conclusion: 该方法能够有效减少手动标注工作量，为低资源语言的情感分析提供了可行的自动标注方案。

Abstract: Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.

</details>


### [8] [$\text{R}^2\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers](https://arxiv.org/abs/2511.19987)
*Xinyu Wang,Hanwei Wu,Qingchen Hu,Zhenghan Tai,Jingrui Tian,Lei Ding,Jijun Chi,Hailin He,Tung Sum Thomas Kwok,Yufei Cui,Sicheng Lyu,Muzhi Li,Mingze Li,Xinyue Yu,Ling Zhou,Peng Lu*

Main category: cs.CL

TL;DR: R2R是一个领域感知的重排序框架，通过动态专家路由和两阶段训练策略解决领域专业化问题，在金融、法律等高风险领域超越通用模型和单领域微调基线。


<details>
  <summary>Details</summary>
Motivation: 通用重排序模型在高风险领域（如金融、法律）中无法捕捉领域特定细微差别，而简单的微调会导致表面形式过拟合和灾难性遗忘。

Method: R2R框架结合动态专家路由和两阶段训练策略（EAG），通过掩盖最具预测性的表面线索来学习领域不变的相关性模式，并使用轻量级潜在语义路由器选择最优LoRA专家。

Result: 在多个重排序骨干模型和不同领域（法律、医疗、金融）上的广泛实验表明，R2R始终优于通用模型和单领域微调基线。

Conclusion: R2R是一种模型无关且模块化的领域专业化方法，具有强大的跨领域鲁棒性。

Abstract: Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.

</details>


### [9] [Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression in LLMs](https://arxiv.org/abs/2511.19852)
*Shi-Wei Dai,Yan-Wei Shie,Tsung-Huan Yang,Lun-Wei Ku,Yung-Hui Li*

Main category: cs.CL

TL;DR: PersonaPulse框架通过迭代优化角色扮演提示词，利用LLMs对人格特质的固有知识，结合情境响应基准作为评分工具，显著提升了LLMs中人格表达的真实性和效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然探索了使用提示词来激发LLMs的特定人格特质，但未能优化这些提示词以最大化人格表达效果。

Method: 提出PersonaPulse框架，利用LLMs对人格特质的固有知识迭代增强角色扮演提示词，同时整合情境响应基准作为评分工具，确保更真实和情境化的评估来指导优化过程。

Result: 定量评估显示PersonaPulse生成的提示词优于基于心理学研究人格描述设计的先前工作；探索了模型大小与人格建模的关系；发现某些人格特质的激发程度可以通过暂停优化过程来部分控制。

Conclusion: 提示词优化在塑造LLMs中人格表达方面至关重要，为未来自适应AI交互研究提供了宝贵见解。

Abstract: Personalized Large Language Models (LLMs) have been shown to be an effective way to create more engaging and enjoyable user-AI interactions. While previous studies have explored using prompts to elicit specific personality traits in LLMs, they have not optimized these prompts to maximize personality expression. To address this limitation, we propose PersonaPulse: Dynamic Profile Optimization for Realistic Personality Expression in LLMs, a framework that leverages LLMs' inherent knowledge of personality traits to iteratively enhance role-play prompts while integrating a situational response benchmark as a scoring tool, ensuring a more realistic and contextually grounded evaluation to guide the optimization process. Quantitative evaluations demonstrate that the prompts generated by PersonaPulse outperform those of prior work, which were designed based on personality descriptions from psychological studies. Additionally, we explore the relationship between model size and personality modeling through extensive experiments. Finally, we find that, for certain personality traits, the extent of personality evocation can be partially controlled by pausing the optimization process. These findings underscore the importance of prompt optimization in shaping personality expression within LLMs, offering valuable insights for future research on adaptive AI interactions.

</details>


### [10] [SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models](https://arxiv.org/abs/2511.20143)
*Wen-Fang Su,Hsiao-Wei Chou,Wen-Yang Lin*

Main category: cs.CL

TL;DR: 提出了一种结合图像数据增强技术的网格标记方法，用于改进不连续命名实体识别，在多个数据集上显著提升了不连续实体的识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统命名实体识别方法在处理跨句子的不连续实体时存在分割错误和遗漏问题，严重影响识别准确率。

Method: 将图像数据增强技术（裁剪、缩放、填充）集成到基于网格的模型中，增强模型识别不连续实体和处理分割挑战的能力。

Result: 在CADEC、ShARe13和ShARe14数据集上，整体F1分数提升1-2.5%，不连续实体识别F1分数提升3.7-8.4%。

Conclusion: 结合图像数据增强的网格模型能有效解决不连续实体识别中的分割和遗漏问题，显著提升识别性能。

Abstract: Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.

</details>


### [11] [A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction](https://arxiv.org/abs/2511.19858)
*Farzad Ahmed,Joniel Augustine Jerome,Meliha Yetisgen,Özlem Uzuner*

Main category: cs.CL

TL;DR: 评估不同提示策略（零样本提示、静态随机示例提示、检索增强动态提示）在医疗错误处理任务中的表现，发现检索增强动态提示在多个LLM中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 临床文档中存在可能影响患者安全的事实性、诊断性和管理性错误，需要探索LLM在不同提示策略下检测和纠正这些错误的能力。

Method: 使用MEDEC数据集评估9个指令调优的LLM，采用零样本提示、静态随机示例提示和检索增强动态提示三种策略，测量准确性、召回率、假阳性率等指标。

Result: 检索增强动态提示在所有9个LLM中表现最佳，将假阳性率降低约15%，在错误句子检测中召回率提高5-10%，并生成更准确的修正。

Conclusion: 检索增强动态提示优于零样本和静态随机示例提示，使用检索示例能提高检测准确性、降低假阳性率并增强医疗错误纠正的可靠性。

Abstract: Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.
  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.
  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.
  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.

</details>


### [12] [AppSelectBench: Application-Level Tool Selection Benchmark](https://arxiv.org/abs/2511.19957)
*Tianyi Chen,Michael Solodko,Sen Wang,Jongwoo Ko,Junheng Hao,Colby Banbury,Sara Abdali,Saeed Amizadeh,Qing Xiao,Yinheng Li,Tianyu Ding,Kamran Ghasedi Dizaji,Suzhen Zheng,Hao Fan,Justin Wagle,Pashmina Cameron,Kazuhito Koishida*

Main category: cs.CL

TL;DR: AppSelectBench是一个用于评估计算机使用代理（CUAs）应用选择能力的基准测试，包含10万个真实用户任务和100个桌面应用，揭示了现有模型在跨应用推理方面的系统性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估细粒度API选择，无法衡量模型在不同应用间进行推理和选择的能力，而应用选择是CUAs有效运行的基本能力。

Method: 开发了新颖的用户任务生成流程，大规模生成真实、多样且语义基础的用户意图，并建立了统一的评估协议，包括随机、启发式、零样本、少样本和检索增强设置。

Result: 对闭源和开源大语言模型的广泛实验显示，即使最强大的模型在跨应用推理方面仍存在系统性弱点，难以做出一致的应用选择。

Conclusion: AppSelectBench为研究和推进应用级推理能力奠定了基础，这是智能CUAs关键但尚未充分探索的能力。

Abstract: Computer Using Agents (CUAs) are increasingly equipped with external tools, enabling them to perform complex and realistic tasks. For CUAs to operate effectively, application selection, which refers to deciding which application to use before invoking fine-grained tools such as APIs, is a fundamental capability. It determines whether the agent initializes the correct environment, avoids orchestration confusion, and efficiently focuses on relevant context. However, existing benchmarks primarily assess fine-grained API selection, offering limited insight into whether models can reason across and choose between different applications. To fill this gap, we introduce AppSelectBench, a comprehensive benchmark for evaluating application selection in CUAs. AppSelectBench contains a novel user task generation pipeline that produces realistic, diverse, and semantically grounded user intents at scale, together with unified evaluation protocols covering random, heuristic, zero-shot, few-shot, and retrieval-augmented-settings. AppSelectBench covers one hundred widely used desktop applications and includes more than one hundred thousand realistic, diverse, and semantically grounded user tasks. Extensive experiments across both closed-source and open-source large language models reveal systematic strengths and weaknesses in inter-application reasoning, showing that even the most capable models still struggle to make consistent application choices. Together, these results establish AppSelectBench as a foundation for studying and advancing application level reasoning, an essential yet underexplored capability of intelligent CUAs. The source is available at https://github.com/microsoft/appselectbench.

</details>


### [13] [Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test](https://arxiv.org/abs/2511.19997)
*Mihir Sahasrabudhe*

Main category: cs.CL

TL;DR: Transformers理论上具有反转不变性，但在实际应用中存在方向性学习差异。通过合成基准测试发现，即使在没有语言偏见的干净环境中，GPT-2模型仍表现出明显的方向性优化差距，这表明因果Transformer训练本身存在内在的方向性摩擦。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型在实际应用中表现出的方向性学习差异问题，明确这种差异是源于语言统计特性还是架构本身。通过构建完全合成的基准测试来隔离语言先验的影响。

Method: 使用随机字符串映射构建合成基准测试，通过可调分支因子K创建前向任务（零条件熵）和逆向任务（有确定熵下限）。训练GPT-2模型并比较其与MLP在相同数据上的表现差异。

Result: 即使从头训练的GPT-2模型也表现出强烈的方向性优化差距（如K=5时1.16 nats），远大于在相同数据上训练的MLP。预训练初始化改变了优化行为但未消除差距，LoRA在高熵逆向映射中遇到容量瓶颈。

Conclusion: 研究揭示了因果Transformer训练中固有的方向性摩擦，这种差异在去除语言先验、词频和语料级时间不对称性后仍然存在，为研究现代序列模型的方向性偏差提供了受控工具。

Abstract: Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a "reversal curse," and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.

</details>


### [14] [A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media](https://arxiv.org/abs/2511.20001)
*Edward Ajayi,Martha Kachweka,Mawuli Deku,Emily Aiken*

Main category: cs.CL

TL;DR: 提出了一个统一的多类别分类框架，用于从社交媒体数据中检测10种心理健康和网络欺凌类别，采用领域适应的MentalBERT模型取得了最佳性能，并开发了结合模型预测和解释的实用工作流程。


<details>
  <summary>Details</summary>
Motivation: 数字空间中心理健康挑战和网络欺凌日益普遍，需要可扩展且可解释的检测系统。

Method: 从Twitter和Reddit收集数据集，实施严格的"分割再平衡"流程，在平衡数据上训练但在真实的不平衡测试集上评估。比较了传统词汇模型、混合方法和多种端到端微调transformer模型。

Result: 端到端微调对性能至关重要，领域适应的MentalBERT成为最佳模型，准确率达到0.92，宏F1分数为0.76，超越了通用对应模型和零样本LLM基线。

Conclusion: 该系统被定位为人工参与循环的筛查辅助工具而非诊断工具，提出了混合SHAPLLM可解释性框架和原型仪表板，为在线安全和计算心理健康的交叉领域提供了稳健基准。

Abstract: Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous "split-then-balance" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard ("Social Media Screener") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.

</details>


### [15] [Online-PVLM: Advancing Personalized VLMs with Online Concept Learning](https://arxiv.org/abs/2511.20056)
*Huiyu Bai,Runze Wang,Zhuoyun Du,Yiyang Zhao,Fengji Zhang,Haoyu Chen,Xiaoyong Zhu,Bo Zheng,Xuejiao Zhao*

Main category: cs.CL

TL;DR: Online-PVLM是一个用于个性化视觉语言模型在线概念学习的框架，利用双曲表示实现无需训练的概念嵌入生成，支持测试时的实时适应，解决了现有方法无法在测试时进行实时适应和大规模场景下效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化视觉语言模型方法通常需要为每个新概念学习单独的嵌入，这无法支持测试时的实时适应，在大规模场景下无法高效检索概念嵌入。

Method: 提出Online-PVLM框架，利用双曲表示实现无需训练的概念嵌入生成，在测试时创建概念嵌入，使个性化视觉语言模型的使用既可扩展又高效。

Result: 在包含1,292个概念和超过30K高质量实例的OP-Eval基准测试中进行了广泛实验，证明了所提框架的最先进性能。

Conclusion: Online-PVLM通过双曲表示实现了在线概念学习，解决了现有方法的实时适应和可扩展性问题，为个性化视觉语言模型的实际应用提供了有效的解决方案。

Abstract: Personalized Visual Language Models (VLMs) are gaining increasing attention for their formidable ability in user-specific concepts aligned interactions (e.g., identifying a user's bike). Existing methods typically require the learning of separate embeddings for each new concept, which fails to support real-time adaptation during testing. This limitation becomes particularly pronounced in large-scale scenarios, where efficient retrieval of concept embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a framework for online concept learning by leveraging hyperbolic representations. Our approach makes a train-free paradigm for concept embeddings generation at test time, making the use of personalized VLMs both scalable and efficient. In addition, we develop OP-Eval, a comprehensive and large-scale benchmark comprising 1,292 concepts and over 30K high-quality instances with diverse question types, designed to rigorously assess online concept learning in realistic scenarios. Extensive experiments demonstrate the state-of-the-art performance of our proposed framework. Our source code and dataset will be made available.

</details>


### [16] [MTA: A Merge-then-Adapt Framework for Personalized Large Language Model](https://arxiv.org/abs/2511.20072)
*Xiaopeng Li,Yuanjin Zheng,Wanyu Wang,wenlin zhang,Pengyue Jia,Yiqi Wang,Maolin Wang,Xuetao Wei,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 提出了MTA框架，通过合并-适应方法解决个性化大语言模型的可扩展性和稀疏数据问题，包含元LoRA库构建、自适应LoRA融合和少样本个性化LoRA堆叠三个阶段。


<details>
  <summary>Details</summary>
Motivation: 现有个性化大语言模型方法存在两大限制：存储成本随用户数量线性增长导致不可扩展，以及从头微调静态模型对稀疏数据用户性能不佳。

Method: MTA框架包含三个阶段：1）构建共享元LoRA库，预训练元个性化特征；2）自适应LoRA融合，动态合并相关锚点元LoRA合成用户特定模块；3）少样本个性化LoRA堆叠，在合并LoRA上应用超低秩轻量级LoRA模块进行微调。

Result: 在LaMP基准测试上的广泛实验表明，该方法在多个任务上优于现有最先进方法。

Conclusion: MTA框架有效解决了PLLMs的可扩展性和稀疏数据个性化问题，通过动态融合和轻量级适应实现了高效的个人化建模。

Abstract: Personalized Large Language Models (PLLMs) aim to align model outputs with individual user preferences, a crucial capability for user-centric applications. However, the prevalent approach of fine-tuning a separate module for each user faces two major limitations: (1) storage costs scale linearly with the number of users, rendering the method unscalable; and (2) fine-tuning a static model from scratch often yields suboptimal performance for users with sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt framework for PLLMs. MTA comprises three key stages. First, we construct a shared Meta-LoRA Bank by selecting anchor users and pre-training meta-personalization traits within meta-LoRA modules. Second, to ensure scalability and enable dynamic personalization combination beyond static models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and dynamically merges the most relevant anchor meta-LoRAs to synthesize a user-specific one, thereby eliminating the need for user-specific storage and supporting more flexible personalization. Third, we propose a LoRA Stacking for Few-Shot Personalization stage, which applies an additional ultra-low-rank, lightweight LoRA module on top of the merged LoRA. Fine-tuning this module enables effective personalization under few-shot settings. Extensive experiments on the LaMP benchmark demonstrate that our approach outperforms existing SOTA methods across multiple tasks.

</details>


### [17] [More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering](https://arxiv.org/abs/2511.20086)
*Duc Anh Vu,Thong Nguyen,Cong-Duy Nguyen,Viet Anh Nguyen,Anh Tuan Luu*

Main category: cs.CL

TL;DR: BiasPrompting是一个新颖的推理框架，通过引导LLMs为所有可能的答案选项生成并批判性评估推理，然后综合这些推理来选择最合理的答案，显著提升了多项选择题任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多项选择题任务中存在关键限制：答案选项通常没有上下文基础或解释，导致无法充分探索所有可能的答案，从而降低了模型的推理能力。

Method: BiasPrompting包含两个组件：1) 推理生成阶段，模型被提示为每个答案选项生成支持性推理；2) 推理引导的一致性阶段，综合生成的推理来选择最合理的答案。

Result: 在五个广泛使用的多项选择题回答基准测试中，BiasPrompting显示出显著改进。实验表明该方法增强了LLMs的推理能力，并为处理复杂和具有挑战性的问题提供了坚实基础。

Conclusion: BiasPrompting通过引导LLMs全面探索所有答案选项并综合推理，有效提升了多项选择题任务的性能，特别是在现有方法表现不佳的场景中表现出色。

Abstract: With the advancement of large language models (LLMs), their performance on multiple-choice question (MCQ) tasks has improved significantly. However, existing approaches face key limitations: answer choices are typically presented to LLMs without contextual grounding or explanation. This absence of context can lead to incomplete exploration of all possible answers, ultimately degrading the models' reasoning capabilities. To address these challenges, we introduce BiasPrompting, a novel inference framework that guides LLMs to generate and critically evaluate reasoning across all plausible answer options before reaching a final prediction. It consists of two components: first, a reasoning generation stage, where the model is prompted to produce supportive reasonings for each answer option, and then, a reasoning-guided agreement stage, where the generated reasonings are synthesized to select the most plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates significant improvements in five widely used multiple-choice question answering benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning capabilities of LLMs and provides a strong foundation for tackling complex and challenging questions, particularly in settings where existing methods underperform.

</details>


### [18] [SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space](https://arxiv.org/abs/2511.20102)
*Zhenyi Shen,Junru Lu,Lin Gui,Jiazheng Li,Yulan He,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: SSA是一种统一的训练框架，通过同时考虑稀疏和全注意力机制，在每层强制执行双向对齐，解决了现有稀疏注意力方法中梯度更新不足的问题，实现了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法存在一个关键悖论：虽然旨在近似全注意力，但产生的注意力稀疏度却低于全注意力模型，这限制了其有效性。作者将此归因于梯度更新不足的问题。

Method: 提出SSA（稀疏稀疏注意力）训练框架，同时考虑稀疏和全注意力，在每层强制执行双向对齐。这种设计保留了所有token的梯度流，同时明确鼓励稀疏注意力输出与其全注意力对应物对齐，从而促进更强的稀疏性。

Result: SSA在多个常识基准测试中，在稀疏和全注意力推理下都实现了最先进的性能。此外，SSA使模型能够平滑适应不同的稀疏度预算，性能随着允许关注的token数量增加而持续改善。SSA还表现出最强的长上下文外推能力。

Conclusion: SSA通过解决梯度更新不足的问题，实现了高效的稀疏注意力训练，在保持性能的同时支持灵活的计算-性能权衡，并显著提升了长上下文外推能力。

Abstract: The quadratic complexity of full attention limits efficient long-context processing in large language models (LLMs). Sparse attention mitigates this cost by restricting each query to attend to a subset of previous tokens; however, training-free approaches often lead to severe performance degradation. Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet exhibit a critical paradox: they produce lower attention sparsity than full-attention models, despite aiming to approximate full attention, which may constrain their effectiveness. We attribute this paradox to gradient update deficiency: low-ranked key-value pairs excluded during sparse training receive neither forward contribution nor backward gradients, and thus never learn proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse Attention), a unified training framework that considers both sparse and full attention and enforces bidirectional alignment at every layer. This design preserves gradient flow to all tokens while explicitly encouraging sparse-attention outputs to align with their full-attention counterparts, thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art performance under both sparse and full attention inference across multiple commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to varying sparsity budgets; performance improves consistently as more tokens are allowed to attend, supporting flexible compute-performance trade-offs at inference time. Finally, we show that native sparse-attention training surprisingly improves long-context extrapolation by mitigating the over-allocation of attention values in sink areas, with SSA demonstrating the strongest extrapolation capability.

</details>


### [19] [EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning](https://arxiv.org/abs/2511.20106)
*Xingfeng Li,Xiaohan Shi,Junjie Li,Yongwei Li,Masashi Unoki,Tomoki Toda,Masato Akagi*

Main category: cs.CL

TL;DR: EM2LDL是一个新颖的多语言语音语料库，通过标签分布学习推进混合情感识别，包含英语、普通话和粤语表达，捕捉多语言地区的语码转换现象。


<details>
  <summary>Details</summary>
Motivation: 解决现有语料库主要为单语言和单标签情感标注的限制，这些限制阻碍了语言多样性、无法建模混合情感且缺乏生态效度。

Method: 整合来自在线平台的自发情感表达，使用32个类别的细粒度情感分布进行标注，采用自监督学习模型建立实验基线。

Result: 在说话人无关的性别、年龄和人格评估中表现出稳健性能，HuBERT-large-EN模型取得最佳结果。

Conclusion: EM2LDL通过融入语言多样性和生态效度，为多语言环境中复杂情感动态的探索提供了平台，为情感计算应用开发适应性强的共情系统提供了多功能测试平台。

Abstract: This study introduces EM2LDL, a novel multilingual speech corpus designed to advance mixed emotion recognition through label distribution learning. Addressing the limitations of predominantly monolingual and single-label emotion corpora \textcolor{black}{that restrict linguistic diversity, are unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises expressive utterances in English, Mandarin, and Cantonese, capturing the intra-utterance code-switching prevalent in multilingual regions like Hong Kong and Macao. The corpus integrates spontaneous emotional expressions from online platforms, annotated with fine-grained emotion distributions across 32 categories. Experimental baselines using self-supervised learning models demonstrate robust performance in speaker-independent gender-, age-, and personality-based evaluations, with HuBERT-large-EN achieving optimal results. By incorporating linguistic diversity and ecological validity, EM2LDL enables the exploration of complex emotional dynamics in multilingual settings. This work provides a versatile testbed for developing adaptive, empathetic systems for applications in affective computing, including mental health monitoring and cross-cultural communication. The dataset, annotations, and baseline codes are publicly available at https://github.com/xingfengli/EM2LDL.

</details>


### [20] [Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach](https://arxiv.org/abs/2511.20107)
*Huu Tuong Tu,Ha Viet Khanh,Tran Tien Dat,Vu Huan,Thien Van Luong,Nguyen Tien Cuong,Nguyen Thi Thu Trang*

Main category: cs.CL

TL;DR: 提出了一种无需训练的发音错误检测与诊断框架，利用预训练ASR模型和检索技术，避免了传统方法需要评分模型或音素级模型训练的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统的发音错误检测与诊断方法需要训练评分模型或音素级模型，过程复杂且需要大量标注数据，因此希望开发一种无需训练的方法。

Method: 利用预训练的自动语音识别模型和检索技术，无需进行音素特定建模或额外的任务特定训练。

Result: 在L2-ARCTIC数据集上的实验表明，该方法取得了69.60%的F1分数，优于传统方法。

Conclusion: 该方法提供了一种简单有效的发音错误检测与诊断解决方案，避免了模型训练的复杂性，同时保持了良好的性能。

Abstract: Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.

</details>


### [21] ["When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error Correction in Low-Resource Settings](https://arxiv.org/abs/2511.20120)
*Somsubhra De,Harsh Kumar,Arun Prakash A*

Main category: cs.CL

TL;DR: 使用大型语言模型（GPT-4.1、Gemini-2.5、LLaMA-4）结合少量样本提示策略，在资源匮乏的印度语言中实现语法错误校正，显著优于传统微调模型。


<details>
  <summary>Details</summary>
Motivation: 印度语言的语法错误校正面临资源有限、语言多样性和复杂形态学的挑战，现有方法性能不足。

Method: 采用基于提示的方法，包括零样本和少量样本策略，结合精心设计的提示和轻量级适配。

Result: 在共享任务中取得领先成绩：泰米尔语第1名（GLEU: 91.57）、印地语第1名（GLEU: 85.69）、泰卢固语第2名（GLEU: 85.22）、孟加拉语第4名（GLEU: 92.86）、马拉雅拉姆语第5名（GLEU: 92.97）。

Conclusion: 提示驱动的NLP技术有效，大规模LLM有潜力弥合多语言GEC中的资源差距。

Abstract: Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.

</details>


### [22] [KyrgyzBERT: A Compact, Efficient Language Model for Kyrgyz NLP](https://arxiv.org/abs/2511.20182)
*Adilet Metinov,Gulida M. Kudakeeva,Gulnara D. Kabaeva*

Main category: cs.CL

TL;DR: 介绍了首个公开的吉尔吉斯语单语BERT模型KyrgyzBERT，该模型有3590万参数，使用针对吉尔吉斯语形态结构设计的自定义分词器。通过创建kyrgyz-sst2情感分析基准进行评估，KyrgyzBERT在该数据集上微调后达到0.8280的F1分数，与比其大五倍的mBERT模型性能相当。


<details>
  <summary>Details</summary>
Motivation: 吉尔吉斯语是一种低资源语言，缺乏基础NLP工具。为了填补这一空白，需要开发专门针对吉尔吉斯语的语言模型。

Method: 开发了KyrgyzBERT模型，使用自定义分词器适应吉尔吉斯语的形态结构。通过翻译斯坦福情感树库并手动标注完整测试集，创建了kyrgyz-sst2情感分析基准数据集。

Result: KyrgyzBERT在kyrgyz-sst2数据集上微调后获得0.8280的F1分数，与比其大五倍的多语言BERT模型性能竞争。

Conclusion: KyrgyzBERT是首个公开的吉尔吉斯语单语BERT模型，为吉尔吉斯语NLP研究提供了重要工具，所有模型、数据和代码都已发布以支持未来研究。

Abstract: Kyrgyz remains a low-resource language with limited foundational NLP tools. To address this gap, we introduce KyrgyzBERT, the first publicly available monolingual BERT-based language model for Kyrgyz. The model has 35.9M parameters and uses a custom tokenizer designed for the language's morphological structure. To evaluate performance, we create kyrgyz-sst2, a sentiment analysis benchmark built by translating the Stanford Sentiment Treebank and manually annotating the full test set. KyrgyzBERT fine-tuned on this dataset achieves an F1-score of 0.8280, competitive with a fine-tuned mBERT model five times larger. All models, data, and code are released to support future research in Kyrgyz NLP.

</details>


### [23] [REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance](https://arxiv.org/abs/2511.20233)
*Chuyi Kong,Gao Wei,Jing Ma,Hongzhan Lin,Zhiyuan Fan*

Main category: cs.CL

TL;DR: REFLEX是一种无需外部知识的自动化事实核查方法，通过角色扮演对话和对比激活对构建转向向量，在仅465个训练样本下实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的事实核查方法过度依赖外部知识源，导致延迟和幻觉问题，影响可靠性、可解释性和实时性。

Method: 将事实核查重构为角色扮演对话，联合训练判决预测和解释生成，通过对比激活对构建转向向量来分离真相的风格和实质。

Result: 在真实数据集上，REFLEX优于单真相方向引导的方法，仅用465个自精炼训练样本就达到最先进性能，解释信号能提升事实推理能力达7.57%。

Conclusion: REFLEX证明了利用模型内部知识进行事实核查的可行性，内部解释信号在解释和增强事实推理中发挥双重作用，为实时事实核查提供了高效解决方案。

Abstract: The prevalence of misinformation on social media threatens public trust, demanding automated fact-checking systems that provide accurate verdicts with interpretable explanations. However, existing large language model-based (LLM-based) approaches often rely heavily on external knowledge sources, introducing substantial latency and even hallucinations that undermine reliability, interpretability, and responsiveness, which is crucial for real-time use. To address these challenges, we propose REason-guided Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play, self-refining paradigm that leverages the internal knowledge in backbone model to improve both verdict accuracy and explanation quality. REFLEX reformulates fact-checking as a role-play dialogue and jointly trains verdict prediction and explanation generation. It adaptively extracts contrastive activation pairs between the backbone model and its fine-tuned variant to construct steering vectors that disentangle truth into style and substance naturally. These activation-level signals guide inference and suppress noisy explanations, enabling more faithful and efficient reasoning. Experiments on real-world datasets show that REFLEX outperforms previous methods that steer toward a single truth direction and underscores the challenge traditional approaches face when handling the subtle, human-unknown truth in fact-checking tasks. Remarkably, with only 465 self-refined training samples, RELFEX achieves state-of-the-art performance. Furthermore, models trained with explanatory objectives can effectively guide those without them, yielding up to a 7.57% improvement, highlighting that internal explanation signals play a dual role in both interpreting and enhancing factual reasoning.

</details>


### [24] [Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in Large-Batch Scenarios](https://arxiv.org/abs/2511.20340)
*Luohe Shi,Zuchao Li,Lefei Zhang,Baoyuan Qi,Guoming Liu,Hai Zhao*

Main category: cs.CL

TL;DR: SpecFormer是一种新颖的架构，结合了单向和双向注意力机制，通过并行生成草稿序列实现LLM推理加速，无需依赖大型前缀树，在低验证资源和低调度成本下实现一致加速。


<details>
  <summary>Details</summary>
Motivation: 现有的推测解码方法假设有大量可用计算能力，但在批处理等主流推理系统中，可用空闲计算能力被压缩，因此需要在低验证资源和低调度成本下进行推测解码。

Method: 提出SpecFormer架构，集成单向和双向注意力机制，结合自回归模型从整个输入序列提取信息的能力和非自回归模型的并行生成优势，消除对大型前缀树的依赖。

Result: 通过在不同规模模型上的无损推测解码实验，证明SpecFormer为LLM推理扩展设定了新标准，具有更低的训练需求和计算成本。

Conclusion: SpecFormer通过创新的架构设计，在保持无损解码的同时实现了LLM推理的持续加速，特别适用于大批量场景，为高效推理提供了新解决方案。

Abstract: Speculative decoding accelerates LLM inference by utilizing otherwise idle computational resources during memory-to-chip data transfer. Current speculative decoding methods typically assume a considerable amount of available computing power, then generate a complex and massive draft tree using a small autoregressive language model to improve overall prediction accuracy. However, methods like batching have been widely applied in mainstream model inference systems as a superior alternative to speculative decoding, as they compress the available idle computing power. Therefore, performing speculative decoding with low verification resources and low scheduling costs has become an important research problem. We believe that more capable models that allow for parallel generation on draft sequences are what we truly need. Recognizing the fundamental nature of draft models to only generate sequences of limited length, we propose SpecFormer, a novel architecture that integrates unidirectional and bidirectional attention mechanisms. SpecFormer combines the autoregressive model's ability to extract information from the entire input sequence with the parallel generation benefits of non-autoregressive models. This design eliminates the reliance on large prefix trees and achieves consistent acceleration, even in large-batch scenarios. Through lossless speculative decoding experiments across models of various scales, we demonstrate that SpecFormer sets a new standard for scaling LLM inference with lower training demands and reduced computational costs.

</details>


### [25] [The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models](https://arxiv.org/abs/2511.20344)
*Taewhoo Lee,Minju Song,Chanwoong Yoon,Jungwoo Park,Jaewoo Kang*

Main category: cs.CL

TL;DR: LLMs can encode high-level relational concepts for analogical reasoning but struggle to apply them to new entities, requiring strategic patching of hidden representations for improvement.


<details>
  <summary>Details</summary>
Motivation: To explore whether LLMs can encode high-level relational concepts and apply them to novel situations through structured comparisons, given that analogical reasoning is fundamental to human cognition.

Method: Using proportional and story analogies to analyze how LLMs encode relationships between analogous entities, examining information propagation through network layers, and testing strategic patching of hidden representations.

Result: LLMs effectively encode underlying relationships in correct cases but struggle with missing relational information and applying it to new entities; strategic patching can facilitate information transfer; successful reasoning requires strong structural alignment.

Conclusion: LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, showing both parallels and gaps with human analogical reasoning.

Abstract: Analogical reasoning is at the core of human cognition, serving as an important foundation for a variety of intellectual activities. While prior work has shown that LLMs can represent task patterns and surface-level concepts, it remains unclear whether these models can encode high-level relational concepts and apply them to novel situations through structured comparisons. In this work, we explore this fundamental aspect using proportional and story analogies, and identify three key findings. First, LLMs effectively encode the underlying relationships between analogous entities; both attributive and relational information propagate through mid-upper layers in correct cases, whereas reasoning failures reflect missing relational information within these layers. Second, unlike humans, LLMs often struggle not only when relational information is missing, but also when attempting to apply it to new entities. In such cases, strategically patching hidden representations at critical token positions can facilitate information transfer to a certain extent. Lastly, successful analogical reasoning in LLMs is marked by strong structural alignment between analogous situations, whereas failures often reflect degraded or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, highlighting both parallels and gaps with human cognition.

</details>


### [26] [BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali](https://arxiv.org/abs/2511.20399)
*Abdullah Al Sefat*

Main category: cs.CL

TL;DR: BengaliFig是一个针对孟加拉语的比喻和文化推理挑战集，包含435个来自孟加拉口头和文学传统的谜语，用于评估LLM在低资源文化背景下的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在广泛的多语言基准测试中表现出色，但在比喻和文化基础推理方面，特别是在低资源语境中，评估仍然不足。孟加拉语作为广泛使用但资源匮乏的语言，存在这一评估空白。

Method: 构建包含435个独特谜语的BengaliFig数据集，每个项目沿五个正交维度进行注释，并通过约束感知、AI辅助的流水线自动转换为多项选择格式。评估八个前沿LLM在零样本和少样本思维链提示下的表现。

Result: 评估揭示了LLM在隐喻和文化特定推理方面存在一致的弱点，表明它们在低资源文化背景下的推理能力有限。

Conclusion: BengaliFig既为评估LLM在低资源文化背景下的鲁棒性提供了诊断工具，也朝着包容性和传统意识NLP评估迈出了一步。

Abstract: Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.

</details>


### [27] [A Task-Oriented Evaluation Framework for Text Normalization in Modern NLP Pipelines](https://arxiv.org/abs/2511.20409)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 提出了一种新颖的任务导向词干提取评估框架，包含词干提取有效性评分(SES)、模型性能差异(MPD)和平均归一化编辑距离(ANLD)三个维度，用于全面评估词干提取方法。


<details>
  <summary>Details</summary>
Motivation: 当前词干提取评估方法有限，无法捕捉过度词干提取带来的潜在危害，因此需要开发新的评估方法。

Method: 提出包含三个方面的评估框架：SES衡量词干提取效用，MPD评估对下游任务的影响，ANLD衡量词干词与原词的语义相似度。

Result: 应用该框架比较孟加拉语(BNLTK)和英语(Snowball)词干提取器，发现孟加拉语词干提取器SES最高(1.67)但ANLD较差(0.26)，表明存在有害的过度词干提取；英语词干提取器SES适中(1.31)且ANLD安全(0.14)，能积极贡献下游任务性能。

Conclusion: 该研究提供了一个有价值的工具，能够区分潜在效率增益(高SES)和语义保留(低ANLD)，有助于选择更可靠的词干提取器。

Abstract: Text normalization is an essential preprocessing step in many natural language processing (NLP) tasks, and stemming is one such normalization technique that reduces words to their base or root form. However, evaluating stemming methods is challenging because current evaluation approaches are limited and do not capture the potential harm caused by excessive stemming; therefore, it is essential to develop new approaches to evaluate stemming methods. To address this issue, this study propose a novel, task-oriented approach to evaluate stemming methods, which considers three aspects: (1) the utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of stemming on downstream tasks using Model Performance Delta (MPD), and (3) the semantic similarity between stemmed and original words using Average Normalized Levenshtein Distance (ANLD), thus providing a comprehensive evaluation framework. We apply our evaluation framework to compare two stemmers for Bangla (BNLTK) and English (Snowball), and our results reveal a significant issue, prompting us to analyze their performance in detail. While the Bangla stemmer achieves the highest SES (1.67) due to effective word reduction (CR = 1.90), SES alone is insufficient because our proposed safety measure, ANLD, reveals that this high SES is due to harmful over-stemming (ANLD = 0.26), which correlates with the observed decrease in downstream performance.In contrast, the English stemmer achieves a moderate SES (1.31) with a safe meaning distance (ANLD = 0.14), allowing its word reduction to contribute positively to downstream performance; therefore, it is a more reliable stemmer. Our study provides a valuable tool for distinguishing between potential efficiency gains (high SES) and meaning preservation (low ANLD).

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [28] [SCoTER: Structured Chain-of-Thought Transfer for Enhanced Recommendation](https://arxiv.org/abs/2511.19514)
*Yang Wu,Qian Li,Yuling Xiong,Hongbo Tang,Xun Liu,Jun Zhang,Huan Yu,Jie Jiang,Hailong Shi*

Main category: cs.IR

TL;DR: SCoTER是一个统一框架，通过自动模式发现和结构保持集成，将结构化LLM推理转移到推荐系统，在消除在线LLM推理成本的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法缺乏自动发现有效推理模式的机制，依赖脆弱的手动模板或不稳定的零样本提示；同时采用结构破坏的集成方式，要么产生高昂的在线推理成本，要么将推理链压缩为单个向量丢失逐步逻辑。

Method: SCoTER包含两个协同组件：GVM管道用于自动模式发现，以及结构保持集成架构将逐步逻辑转移到高效模型。通过信息论证明结构保持转移比结构无关替代方案具有更紧的性能界限。

Result: 在四个基准测试中相比强基线TIGER提升3.75%-11.59%；在腾讯广告平台生产部署中，GMV提升2.14%同时消除在线LLM推理成本。

Conclusion: SCoTER为将结构化LLM推理转移到大规模推荐系统提供了一个原则性且经过生产验证的蓝图。

Abstract: Harnessing the reasoning power of Large Language Models (LLMs) for recommender systems is hindered by two fundamental challenges. First, current approaches lack a mechanism for automated, data-driven discovery of effective reasoning patterns, relying instead on brittle manual templates or unstable zero-shot prompting. Second, they employ structure-collapsing integration: direct prompting incurs prohibitive online inference costs, while feature extraction collapses reasoning chains into single vectors, discarding stepwise logic. To address these challenges, we propose SCoTER (Structured Chain-of-Thought Transfer for Enhanced Recommendation), a unified framework that treats pattern discovery and structure-aware transfer as a jointly optimized problem. Specifically, SCoTER operationalizes this through two synergistic components: a GVM pipeline for automated pattern discovery and a structure-preserving integration architecture that transfers stepwise logic to efficient models. Formally, we provide information-theoretic justification proving that structure-preserving transfer achieves tighter performance bounds than structure-agnostic alternatives. Empirically, experiments on four benchmarks demonstrate improvements of 3.75\%-11.59\% over a strong TIGER backbone. Moreover, in production deployment on the Tencent Advertising Platform, SCoTER achieved a 2.14\% lift in Gross Merchandise Value (GMV) while eliminating online LLM inference costs. Overall, SCoTER establishes a principled and production-validated blueprint for transferring structured LLM reasoning to large-scale recommender systems.

</details>


### [29] [LLM-EDT: Large Language Model Enhanced Cross-domain Sequential Recommendation with Dual-phase Training](https://arxiv.org/abs/2511.19931)
*Ziwei Liu,Qidong Liu,Wanyu Wang,Yejing Wang,Tong Xu,Wei Huang,Chong Chen,Peng Chuan,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 提出LLM-EDT方法解决跨域序列推荐中的不平衡问题和转移问题，通过可转移项目增强器、双阶段训练策略和域感知配置模块来提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 当前跨域序列推荐存在不平衡问题和转移问题，前者导致一个域的行为主导整个交互，难以捕捉其他域的特征；后者难以在混合交互序列中捕捉用户的跨域偏好。现有LLM方法未能识别无关噪声和粗略配置问题。

Method: 提出LLM-EDT方法，包含三个核心组件：1）可转移项目增强器自适应生成可能的跨域行为；2）双阶段训练策略赋予域特定线程域共享背景；3）域感知配置模块总结用户在每个域的偏好并自适应聚合生成全面用户配置。

Result: 在三个公共数据集上的实验验证了LLM-EDT的有效性。

Conclusion: LLM-EDT成功解决了跨域序列推荐中的不平衡问题和转移问题，通过引入可转移项目增强器、双阶段训练策略和域感知配置模块，显著提升了推荐性能。

Abstract: Cross-domain Sequential Recommendation (CDSR) has been proposed to enrich user-item interactions by incorporating information from various domains. Despite current progress, the imbalance issue and transition issue hinder further development of CDSR. The former one presents a phenomenon that the interactions in one domain dominate the entire behavior, leading to difficulty in capturing the domain-specific features in the other domain. The latter points to the difficulty in capturing users' cross-domain preferences within the mixed interaction sequence, resulting in poor next-item prediction performance for specific domains. With world knowledge and powerful reasoning ability, Large Language Models (LLMs) partially alleviate the above issues by performing as a generator and an encoder. However, current LLMs-enhanced CDSR methods are still under exploration, which fail to recognize the irrelevant noise and rough profiling problems. Thus, to make peace with the aforementioned challenges, we proposed an LLMs Enhanced Cross-domain Sequential Recommendation with Dual-phase Training ({LLM-EDT}). To address the imbalance issue while introducing less irrelevant noise, we first propose the transferable item augmenter to adaptively generate possible cross-domain behaviors for users. Then, to alleviate the transition issue, we introduce a dual-phase training strategy to empower the domain-specific thread with a domain-shared background. As for the rough profiling problem, we devise a domain-aware profiling module to summarize the user's preference in each domain and adaptively aggregate them to generate comprehensive user profiles. The experiments on three public datasets validate the effectiveness of our proposed LLM-EDT. To ease reproducibility, we have released the detailed code online at {https://anonymous.4open.science/r/LLM-EDT-583F}.

</details>


### [30] [The 2nd Workshop on Human-Centered Recommender Systems](https://arxiv.org/abs/2511.19979)
*Kaike Zhang,Jiakai Tang,Du Su,Shuchang Liu,Julian McAuley,Lina Yao,Qi Cao,Yue Feng,Fei Sun*

Main category: cs.IR

TL;DR: 该研讨会呼吁推荐系统从优化参与度转向真正理解、涉及和造福人类的设计，重点关注人类理解、人类参与和人类影响三个主题轴。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统指标（如准确性、点击率和参与度）已无法捕捉对人类真正重要的价值，需要将人类价值观（如信任、安全、公平、透明度和福祉）整合到推荐过程中。

Method: 通过汇集推荐系统、人机交互、AI安全和社交计算领域的研究人员，举办主题演讲、小组讨论和论文展示，涵盖从基于LLM的交互式推荐器到社会福利优化等主题。

Result: 建立了以三个主题轴为中心的研讨会框架，促进跨学科合作，旨在塑造未来十年负责任且与人类对齐的推荐研究。

Conclusion: HCRS研讨会通过促进跨学科合作，旨在推动推荐系统研究向更负责任、更符合人类价值观的方向发展，为未来十年的推荐系统研究奠定基础。

Abstract: Recommender systems shape how people discover information, form opinions, and connect with society. Yet, as their influence grows, traditional metrics, e.g., accuracy, clicks, and engagement, no longer capture what truly matters to humans. The workshop on Human-Centered Recommender Systems (HCRS) calls for a paradigm shift from optimizing engagement toward designing systems that truly understand, involve, and benefit people. It brings together researchers in recommender systems, human-computer interaction, AI safety, and social computing to explore how human values, e.g., trust, safety, fairness, transparency, and well-being, can be integrated into recommendation processes. Centered around three thematic axes-Human Understanding, Human Involvement, and Human Impact-HCRS features keynotes, panels, and papers covering topics from LLM-based interactive recommenders to societal welfare optimization. By fostering interdisciplinary collaboration, HCRS aims to shape the next decade of responsible and human-aligned recommendation research.

</details>


### [31] [Popularity Bias Alignment Estimates](https://arxiv.org/abs/2511.19999)
*Anton Lyubinin*

Main category: cs.IR

TL;DR: 本文扩展了流行度偏差记忆化定理，将其推广到任意度分布，并证明了与top-k奇异超空间对齐的上下界估计。


<details>
  <summary>Details</summary>
Motivation: 扩展arXiv:2404.12008中的流行度偏差记忆化定理，使其适用于更一般的度分布情况，并提供更精确的对齐估计。

Method: 通过数学定理扩展和证明，将原有定理从特定度分布推广到任意度分布，并建立与top-k奇异超空间对齐的上下界。

Result: 成功扩展了流行度偏差记忆化定理，获得了适用于任意度分布的新定理，并给出了与top-k奇异超空间对齐的精确上下界估计。

Conclusion: 该研究显著扩展了流行度偏差记忆化理论的应用范围，为理解推荐系统中流行度偏差的影响提供了更一般的数学框架和精确的量化工具。

Abstract: We are extending Popularity Bias Memorization theorem from arXiv:archive/2404.12008 in several directions. We extend it to arbitrary degree distributions and also prove both upper and lower estimates for the alignment with top-k singular hyperspace.

</details>


### [32] [Adaptive Knowledge Transfer for Cross-Disciplinary Cold-Start Knowledge Tracing](https://arxiv.org/abs/2511.20009)
*Yulong Deng,Zheng Guan,Min He,Xue Wang,Jie Liu,Zheng Li*

Main category: cs.IR

TL;DR: 提出了一种基于专家混合和对抗生成网络的跨学科冷启动知识追踪框架，通过聚类学生知识状态、专家混合网络和对抗判别器来解决跨学科数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 跨学科冷启动知识追踪面临目标学科学生交互数据不足的问题，现有方法依赖学科间重叠实体进行知识迁移，但在实际场景中重叠实体稀缺且简单映射无法充分捕捉跨学科知识复杂性。

Method: 1) 预训练源学科模型并将学生知识状态聚类为K类；2) 使用聚类属性通过门控机制指导专家混合网络作为跨域映射桥梁；3) 通过对抗判别器拉近相同属性学生特征、推开不同属性特征，缓解小样本限制。

Result: 在20个极端跨学科冷启动场景中验证了方法的有效性。

Conclusion: 提出的框架能够有效解决跨学科冷启动知识追踪中的数据稀缺和知识迁移问题，在极端场景下表现良好。

Abstract: Cross-Disciplinary Cold-start Knowledge Tracing (CDCKT) faces a critical challenge: insufficient student interaction data in the target discipline prevents effective knowledge state modeling and performance prediction. Existing cross-disciplinary methods rely on overlapping entities between disciplines for knowledge transfer through simple mapping functions, but suffer from two key limitations: (1) overlapping entities are scarce in real-world scenarios, and (2) simple mappings inadequately capture cross-disciplinary knowledge complexity. To overcome these challenges, we propose Mixed of Experts and Adversarial Generative Network-based Cross-disciplinary Cold-start Knowledge Tracing Framework. Our approach consists of three key components: First, we pre-train a source discipline model and cluster student knowledge states into K categories. Second, these cluster attributes guide a mixture-of-experts network through a gating mechanism, serving as a cross-domain mapping bridge. Third, an adversarial discriminator enforces feature separation by pulling same-attribute student features closer while pushing different-attribute features apart, effectively mitigating small-sample limitations. We validate our method's effectiveness across 20 extreme cross-disciplinary cold-start scenarios.

</details>


### [33] [Towards A Tri-View Diffusion Framework for Recommendation](https://arxiv.org/abs/2511.20122)
*Ximing Chen,Pui Ieng Lei,Yijun Sheng,Yanyan Liu,Zhiguo Gong*

Main category: cs.IR

TL;DR: 提出了一个基于热力学视角的简约扩散推荐框架，通过最大化亥姆霍兹自由能结合能量最大化和熵减少，使用各向异性保持的降噪器和接受-拒绝Gumbel采样过程来提高推荐准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的推荐系统缺乏严谨的理论分析，作者从热力学角度发现扩散模型通过最大化能量工作，而经典推荐模型通过减少熵工作，需要结合这两种机制。

Method: 1. 基于亥姆霍兹自由能最大化的简约扩散框架；2. 使用保持固有各向异性的降噪器；3. 采用接受-拒绝Gumbel采样过程（AR-GSP）来处理大量未观察交互。

Result: 理论分析和广泛实验表明，所提出的框架在准确性和效率方面明显优于基线方法。

Conclusion: 该工作为扩散模型在推荐系统中的理论基础提供了新的视角，提出的框架在性能和效率上都有显著提升，为推荐系统研究开辟了新方向。

Abstract: Diffusion models (DMs) have recently gained significant interest for their exceptional potential in recommendation tasks. This stems primarily from their prominent capability in distilling, modeling, and generating comprehensive user preferences. However, previous work fails to examine DMs in recommendation tasks through a rigorous lens. In this paper, we first experimentally investigate the completeness of recommender models from a thermodynamic view. We reveal that existing DM-based recommender models operate by maximizing the energy, while classic recommender models operate by reducing the entropy. Based on this finding, we propose a minimalistic diffusion framework that incorporates both factors via the maximization of Helmholtz free energy. Meanwhile, to foster the optimization, our reverse process is armed with a well-designed denoiser to maintain the inherent anisotropy, which measures the user-item cross-correlation in the context of bipartite graphs. Finally, we adopt an Acceptance-Rejection Gumbel Sampling Process (AR-GSP) to prioritize the far-outnumbered unobserved interactions for model robustness. AR-GSP integrates an acceptance-rejection sampling to ensure high-quality hard negative samples for general recommendation tasks, and a timestep-dependent Gumbel Softmax to handle an adaptive sampling strategy for diffusion models. Theoretical analyses and extensive experiments demonstrate that our proposed framework has distinct superiority over baselines in terms of accuracy and efficiency.

</details>


### [34] [Enhancing Sequential Recommendation with World Knowledge from Large Language Models](https://arxiv.org/abs/2511.20177)
*Tianjie Dai,Xu Chen,Yunmeng Shu,Jinsong Lan,Xiaoyong Zhu,Jiangchao Yao,Bo Zheng*

Main category: cs.IR

TL;DR: GRASP是一个结合生成增强检索和整体注意力增强的序列推荐框架，通过利用LLM的世界知识并缓解其幻觉噪声，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统协同过滤序列推荐模型因协作信号有限导致性能不佳，而现有LLM方法虽然引入世界知识但容易受到幻觉噪声影响。

Method: 提出GRASP框架，包含生成增强检索（描述性合成和相似性检索）和整体注意力增强（多级注意力机制），利用检索到的相似用户/物品作为辅助上下文信息。

Result: 在两个公共基准数据集和一个工业数据集上的综合评估表明，GRASP与不同骨干网络结合时始终达到最先进性能。

Conclusion: GRASP通过生成增强检索和整体注意力增强，有效利用LLM的世界知识并缓解幻觉噪声，为序列推荐系统提供了灵活且高性能的解决方案。

Abstract: Sequential Recommendation System~(SRS) has become pivotal in modern society, which predicts subsequent actions based on the user's historical behavior. However, traditional collaborative filtering-based sequential recommendation models often lead to suboptimal performance due to the limited information of their collaborative signals. With the rapid development of LLMs, an increasing number of works have incorporated LLMs' world knowledge into sequential recommendation. Although they achieve considerable gains, these approaches typically assume the correctness of LLM-generated results and remain susceptible to noise induced by LLM hallucinations. To overcome these limitations, we propose GRASP (Generation Augmented Retrieval with Holistic Attention for Sequential Prediction), a flexible framework that integrates generation augmented retrieval for descriptive synthesis and similarity retrieval, and holistic attention enhancement which employs multi-level attention to effectively employ LLM's world knowledge even with hallucinations and better capture users' dynamic interests. The retrieved similar users/items serve as auxiliary contextual information for the later holistic attention enhancement module, effectively mitigating the noisy guidance of supervision-based methods. Comprehensive evaluations on two public benchmarks and one industrial dataset reveal that GRASP consistently achieves state-of-the-art performance when integrated with diverse backbones. The code is available at: https://anonymous.4open.science/r/GRASP-SRS.

</details>


### [35] [HKRAG: Holistic Knowledge Retrieval-Augmented Generation Over Visually-Rich Documents](https://arxiv.org/abs/2511.20227)
*Anyang Tong,Xiang Niu,ZhiPing Liu,Chang Tian,Yanyan Wei,Zenglin Shi,Meng Wang*

Main category: cs.IR

TL;DR: HKRAG是一个新的多模态检索增强生成框架，专门针对视觉丰富文档设计，通过混合掩码检索器和不确定性引导生成器，同时捕获显著知识和细粒度知识，显著提升视觉问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态RAG方法在处理视觉丰富文档时存在偏见，主要关注显著知识（如突出文本和视觉元素），而忽略了关键的细粒度知识（如小文本、上下文细节），导致检索不完整和答案不准确。

Method: 提出HKRAG框架，包含两个关键组件：1）混合掩码全息检索器，使用显式掩码策略分别建模显著和细粒度知识；2）不确定性引导代理生成器，动态评估初始答案的不确定性并主动决定如何整合两种知识流。

Result: 在开放域视觉问答基准测试上的广泛实验表明，HKRAG在零样本和监督设置下都持续优于现有方法。

Conclusion: HKRAG证明了全息知识检索对于视觉丰富文档理解的关键重要性，通过同时捕获显著和细粒度知识，显著提升了多模态RAG系统的性能。

Abstract: Existing multimodal Retrieval-Augmented Generation (RAG) methods for visually rich documents (VRD) are often biased towards retrieving salient knowledge(e.g., prominent text and visual elements), while largely neglecting the critical fine-print knowledge(e.g., small text, contextual details). This limitation leads to incomplete retrieval and compromises the generator's ability to produce accurate and comprehensive answers. To bridge this gap, we propose HKRAG, a new holistic RAG framework designed to explicitly capture and integrate both knowledge types. Our framework features two key components: (1) a Hybrid Masking-based Holistic Retriever that employs explicit masking strategies to separately model salient and fine-print knowledge, ensuring a query-relevant holistic information retrieval; and (2) an Uncertainty-guided Agentic Generator that dynamically assesses the uncertainty of initial answers and actively decides how to integrate the two distinct knowledge streams for optimal response generation. Extensive experiments on open-domain visual question answering benchmarks show that HKRAG consistently outperforms existing methods in both zero-shot and supervised settings, demonstrating the critical importance of holistic knowledge retrieval for VRD understanding.

</details>


### [36] [HHFT: Hierarchical Heterogeneous Feature Transformer for Recommendation Systems](https://arxiv.org/abs/2511.20235)
*Liren Yu,Wenming Zhang,Silu Zhou,Zhixuan Zhang,Dan Ou*

Main category: cs.IR

TL;DR: HHFT是一个基于Transformer的工业CTR预测架构，通过语义特征分区、异构Transformer编码器和Hiformer层设计，在淘宝生产平台上实现了CTR AUC提升0.4%和GMV增长0.6%的显著效果。


<details>
  <summary>Details</summary>
Motivation: 解决DNN在工业CTR预测中的局限性，特别是处理异构特征（用户画像、商品信息、行为序列）时语义混淆的问题。

Method: 采用三个关键设计：1）语义特征分区，将异构特征按语义分组；2）异构Transformer编码器，使用块特定的QKV投影和FFN避免语义混淆；3）Hiformer层，捕捉特征间的高阶交互。

Result: Transformer显著超越DNN基线，在规模上实现CTR AUC提升0.4%，在淘宝生产平台部署后观察到关键业务指标显著提升，包括GMV增长0.6%。

Conclusion: HHFT架构通过针对异构特征的专门设计，有效解决了语义混淆问题，在工业CTR预测场景中取得了显著的业务效果提升。

Abstract: We propose HHFT (Hierarchical Heterogeneous Feature Transformer), a Transformer-based architecture tailored for industrial CTR prediction. HHFT addresses the limitations of DNN through three key designs: (1) Semantic Feature Partitioning: Grouping heterogeneous features (e.g. user profile, item information, behaviour sequennce) into semantically coherent blocks to preserve domain-specific information; (2) Heterogeneous Transformer Encoder: Adopting block-specific QKV projections and FFNs to avoid semantic confusion between distinct feature types; (3) Hiformer Layer: Capturing high-order interactions across features. Our findings reveal that Transformers significantly outperform DNN baselines, achieving a +0.4% improvement in CTR AUC at scale. We have successfully deployed the model on Taobao's production platform, observing a significant uplift in key business metrics, including a +0.6% increase in Gross Merchandise Value (GMV).

</details>
