<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 46]
- [cs.IR](#cs.IR) [Total: 16]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Language Family Matters: Evaluating LLM-Based ASR Across Linguistic Boundaries](https://arxiv.org/abs/2601.18899)
*Yuchen Zhang,Ravi Shekhar,Haralambos Mouratidis*

Main category: cs.CL

TL;DR: 提出基于语言家族的连接器共享策略，实现多语言ASR参数高效部署


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的ASR系统为每种语言训练独立连接器，忽视了语言之间的亲缘关系，导致参数效率低下

Method: 提出基于语言家族成员关系的连接器共享策略，同一语言家族内的语言共享一个连接器，大幅减少参数数量

Result: 在两个多语言LLM和两个真实世界语料库上的实验表明，家族式连接器在减少参数的同时，提升了跨领域的泛化能力

Conclusion: 基于语言家族的连接器共享策略为多语言ASR部署提供了实用且可扩展的方案

Abstract: Large Language Model (LLM)-powered Automatic Speech Recognition (ASR) systems achieve strong performance with limited resources by linking a frozen speech encoder to a pretrained LLM via a lightweight connector. Prior work trains a separate connector per language, overlooking linguistic relatedness. We propose an efficient and novel connector-sharing strategy based on linguistic family membership, enabling one connector per family, and empirically validate its effectiveness across two multilingual LLMs and two real-world corpora spanning curated and crowd-sourced speech. Our results show that family-based connectors reduce parameter count while improving generalization across domains, offering a practical and scalable strategy for multilingual ASR deployment.

</details>


### [2] [Self-Aware Knowledge Probing: Evaluating Language Models' Relational Knowledge through Confidence Calibration](https://arxiv.org/abs/2601.18901)
*Christopher Kissling,Elena Merdjanovska,Alan Akbik*

Main category: cs.CL

TL;DR: 提出一个用于关系知识评估的校准探测框架，涵盖内在置信度、结构一致性和语义基础三种置信度模态，发现大多数语言模型（尤其是掩码语言模型）存在过度自信问题。


<details>
  <summary>Details</summary>
Motivation: 现有知识探测方法仅通过预测准确率等指标评估模型能力，未能考虑模型置信度校准所反映的可靠性问题，需要更全面的置信度评估框架。

Method: 提出校准探测框架，包含三种置信度模态：1) 内在置信度；2) 结构一致性；3) 语义基础。对10个因果语言模型和6个掩码语言模型进行广泛分析。

Result: 大多数模型（特别是基于掩码目标预训练的模型）存在过度自信问题；考虑陈述重述不一致性的置信度估计校准最佳；即使最大的预训练模型也无法准确编码语言置信度表达的语义。

Conclusion: 需要超越传统准确率指标来评估语言模型的知识可靠性，置信度校准是评估模型关系知识的重要维度，当前模型在语义理解和置信度校准方面仍有不足。

Abstract: Knowledge probing quantifies how much relational knowledge a language model (LM) has acquired during pre-training. Existing knowledge probes evaluate model capabilities through metrics like prediction accuracy and precision. Such evaluations fail to account for the model's reliability, reflected in the calibration of its confidence scores. In this paper, we propose a novel calibration probing framework for relational knowledge, covering three modalities of model confidence: (1) intrinsic confidence, (2) structural consistency and (3) semantic grounding. Our extensive analysis of ten causal and six masked language models reveals that most models, especially those pre-trained with the masking objective, are overconfident. The best-calibrated scores come from confidence estimates that account for inconsistencies due to statement rephrasing. Moreover, even the largest pre-trained models fail to encode the semantics of linguistic confidence expressions accurately.

</details>


### [3] [Flatter Tokens are More Valuable for Speculative Draft Model Training](https://arxiv.org/abs/2601.18902)
*Jiaming Fan,Daming Cao,Xiangzhong Luo,Jiale Fu,Chonghan Liu,Xu Yang*

Main category: cs.CL

TL;DR: 提出SFDD方法，通过基于平坦度的数据蒸馏，用50%数据实现2倍训练加速，推理速度仅比全数据集基线低4%


<details>
  <summary>Details</summary>
Motivation: 现有的推测解码技术通常需要在大数据集上训练草稿模型，但并非所有训练样本对接受率都有同等贡献。研究发现，那些能诱导目标模型产生更平坦预测分布的token比产生尖锐分布的token更有价值。

Method: 提出了平坦度这一新指标来量化token的价值属性，并开发了基于样本级平坦度的数据集蒸馏方法SFDD，通过筛选训练数据只保留最有价值的样本。

Result: 在EAGLE框架上的实验表明，SFDD仅使用50%的数据就能实现超过2倍的训练加速，同时最终模型的推理加速仅比全数据集基线低4%。

Conclusion: 这项工作介绍了一种有效的数据中心化方法，显著提高了推测解码的训练效率，为LLM推理加速提供了更高效的训练方案。

Abstract: Speculative Decoding (SD) is a key technique for accelerating Large Language Model (LLM) inference, but it typically requires training a draft model on a large dataset. We approach this problem from a data-centric perspective, finding that not all training samples contribute equally to the SD acceptance rate. Specifically, our theoretical analysis and empirical validation reveals that tokens inducing flatter predictive distributions from the target model are more valuable than those yielding sharply peaked distributions. Based on this insight, we propose flatness, a new metric to quantify this property, and develop the Sample-level-flatness-based Dataset Distillation (SFDD) approach, which filters the training data to retain only the most valuable samples. Experiments on the EAGLE framework demonstrate that SFDD can achieve over 2$\times$ training speedup using only 50% of the data, while keeping the final model's inference speedup within 4% of the full-dataset baseline. This work introduces an effective, data-centric approach that substantially improves the training efficiency for Speculative Decoding. Our code is available at https://anonymous.4open.science/r/Flatness.

</details>


### [4] [BabyReasoningBench: Generating Developmentally-Inspired Reasoning Tasks for Evaluating Baby Language Models](https://arxiv.org/abs/2601.18933)
*Kaustubh D. Dhole*

Main category: cs.CL

TL;DR: 开发了BabyReasoningBench基准测试，用于评估在儿童发展数据上训练的"婴儿语言模型"的推理能力，发现这些模型在因果推理方面有所提升，但在心理理论和语用任务上仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估基准主要针对成人，假设了广泛的世界知识、复杂指令理解和成熟的语用能力，这与在儿童发展数据上训练的"婴儿语言模型"不匹配，无法准确评估这类模型在受限输入条件下的推理能力。

Method: 引入BabyReasoningBench基准，包含19个基于发展心理学经典范式的推理任务，涵盖心理理论、类比推理、关系推理、因果推理和干预选择等核心推理能力，使用GPT-5.2生成。在两个基于GPT-2架构、分别在1000万和1亿儿童导向文本上预训练的婴儿语言模型上进行评估。

Result: 婴儿语言模型整体表现较低但存在差异：模型规模扩大改善了因果推理和物理推理任务的表现，但信念归因和语用敏感任务仍然具有挑战性。不同任务家族之间存在分离现象。

Conclusion: BabyReasoningBench为分析儿童式训练分布支持的推理能力提供了发展心理学基础，可用于测试这些能力如何出现的机制假设，揭示了在受限输入条件下语言模型推理能力的特定模式。

Abstract: Traditional evaluations of reasoning capabilities of language models are dominated by adult-centric benchmarks that presuppose broad world knowledge, complex instruction following, and mature pragmatic competence. These assumptions are mismatched to baby language models trained on developmentally plausible input such as child-directed speech and early-childhood narratives, and they obscure which reasoning abilities (if any) emerge under such constraints. We introduce BabyReasoningBench, a GPT-5.2 generated benchmark of 19 reasoning tasks grounded in classic paradigms from developmental psychology, spanning theory of mind, analogical and relational reasoning, causal inference and intervention selection, and core reasoning primitives that are known to be confounded by memory and pragmatics. We find that two GPT-2 based baby language models (pretrained on 10M and 100M of child-directed speech text) show overall low but uneven performance, with dissociations across task families: scaling improves several causal and physical reasoning tasks, while belief attribution and pragmatics-sensitive tasks remain challenging. BabyReasoningBench provides a developmentally grounded lens for analyzing what kinds of reasoning are supported by child-like training distributions, and for testing mechanistic hypotheses about how such abilities emerge.

</details>


### [5] [LLMs versus the Halting Problem: Revisiting Program Termination Prediction](https://arxiv.org/abs/2601.18987)
*Oren Sultan,Jordi Armengol-Estape,Pascal Kesseli,Julien Vanegue,Dafna Shahaf,Yossi Adi,Peter O'Hearn*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在程序终止性预测任务上表现出色，在SV-Comp 2025终止类C程序测试中，GPT-5和Claude Sonnet-4.5性能接近最优工具，但无法提供有效证明，且性能随程序长度增加而下降。


<details>
  <summary>Details</summary>
Motivation: 程序终止性判定是计算机科学核心问题，但图灵停机问题证明其为不可判定问题。现有验证工具依赖特定架构和抽象，且通常绑定特定编程语言。近年来大型语言模型（LLMs）的成功引发研究问题：LLMs能否可靠预测程序终止？

Method: 评估LLMs在SV-Comp 2025终止类C程序上的表现，使用多样化的C程序集进行测试，比较LLMs与现有验证工具的性能。

Result: LLMs在程序终止性预测方面表现优异：GPT-5和Claude Sonnet-4.5性能接近排名第一的工具（使用测试时缩放），Code World Model（CWM）性能接近排名第二的工具。但LLMs通常无法提供有效的证明作为验证，且性能随程序长度增加而下降。

Conclusion: LLMs在预测程序终止方面表现良好，但在提供有效证明方面存在局限，且受程序长度影响。这些发现为研究LLMs在不可判定问题推理方面的潜力提供了新的视角。

Abstract: Determining whether a program terminates is a central problem in computer science. Turing's foundational result established the Halting Problem as undecidable, showing that no algorithm can universally determine termination for all programs and inputs. Consequently, automatic verification tools approximate termination, sometimes failing to prove or disprove; these tools rely on problem-specific architectures and abstractions, and are usually tied to particular programming languages. Recent success and progress in large language models (LLMs) raises the following question: can LLMs reliably predict program termination? In this work, we evaluate LLMs on a diverse set of C programs from the Termination category of the International Competition on Software Verification (SV-Comp) 2025. Our results suggest that LLMs perform remarkably well at predicting program termination, where GPT-5 and Claude Sonnet-4.5 would rank just behind the top-ranked tool (using test-time-scaling), and Code World Model (CWM) would place just behind the second-ranked tool. While LLMs are effective at predicting program termination, they often fail to provide a valid witness as a proof. Moreover, LLMs performance drops as program length increases. We hope these insights motivate further research into program termination and the broader potential of LLMs for reasoning about undecidable problems.

</details>


### [6] [Malicious Repurposing of Open Science Artefacts by Using Large Language Models](https://arxiv.org/abs/2601.18998)
*Zahra Hashemi,Zhiqiang Zhong,Jun Pang,Wei Zhao*

Main category: cs.CL

TL;DR: 研究展示大语言模型可以被用于生成有害研究提案，通过绕过安全防护并重新利用开放科学资源，但不同LLM评估结果存在显著差异，表明它们尚不能作为恶意评估的可靠裁判。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注LLMs在促进科学发现方面的潜力，但忽视了它们可能被恶意利用来生成有害研究的风险。需要填补这一空白，研究如何通过重新利用开放科学资源来产生有害研究提案。

Method: 提出端到端管道：1) 通过说服式越狱绕过LLM安全防护；2) 重新解读NLP论文，识别并重新利用其资源（数据集、方法和工具）；3) 使用三维评估框架（危害性、误用可行性、技术合理性）评估这些提案的安全性。

Result: LLMs确实能够通过重新利用伦理设计的开放资源生成有害提案。然而，不同LLM作为评估者时对评估结果存在严重分歧：GPT-4.1评分较高（表明潜在危害更大、技术合理性和误用可行性更高），Gemini-2.5-pro明显更严格，Grok-3介于两者之间。

Conclusion: LLMs尚不能作为恶意评估设置中的可靠裁判，其评估结果存在显著不一致性，这使得人类评估对于可信的双重用途风险评估至关重要。

Abstract: The rapid evolution of large language models (LLMs) has fuelled enthusiasm about their role in advancing scientific discovery, with studies exploring LLMs that autonomously generate and evaluate novel research ideas. However, little attention has been given to the possibility that such models could be exploited to produce harmful research by repurposing open science artefacts for malicious ends. We fill the gap by introducing an end-to-end pipeline that first bypasses LLM safeguards through persuasion-based jailbreaking, then reinterprets NLP papers to identify and repurpose their artefacts (datasets, methods, and tools) by exploiting their vulnerabilities, and finally assesses the safety of these proposals using our evaluation framework across three dimensions: harmfulness, feasibility of misuse, and soundness of technicality. Overall, our findings demonstrate that LLMs can generate harmful proposals by repurposing ethically designed open artefacts; however, we find that LLMs acting as evaluators strongly disagree with one another on evaluation outcomes: GPT-4.1 assigns higher scores (indicating greater potential harms, higher soundness and feasibility of misuse), Gemini-2.5-pro is markedly stricter, and Grok-3 falls between these extremes. This indicates that LLMs cannot yet serve as reliable judges in a malicious evaluation setup, making human evaluation essential for credible dual-use risk assessment.

</details>


### [7] [FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning](https://arxiv.org/abs/2601.19001)
*Haozheng Luo,Zhuolin Jiang,Md Zahid Hasan,Yan Chen,Soumalya Sarkar*

Main category: cs.CL

TL;DR: FROST是一种基于注意力感知的高效推理方法，通过注意力权重剪除不重要的推理路径，显著减少token使用并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 传统推理方法存在效率低下和不可靠推理路径的问题，需要一种能够识别并去除不关键推理路径的方法来提高推理效率和可靠性。

Method: 提出"推理异常值"概念，设计基于注意力的机制来识别和移除这些异常值，在句子级别消除异常值的同时保持和增强模型的推理能力。

Result: 在四个基准测试中，使用Phi-4-Reasoning和GPT-OSS-20B模型，FROST优于TALE和ThinkLess等最先进方法，平均减少69.68%的token使用，提高26.70%的准确率，并显著降低注意力异常值指标。

Conclusion: FROST通过注意力感知的路径剪枝有效提高了推理效率和质量，在减少计算开销的同时提升了推理可靠性，为高效推理提供了新方法。

Abstract: We propose FROST, an attention-aware method for efficient reasoning. Unlike traditional approaches, FROST leverages attention weights to prune uncritical reasoning paths, yielding shorter and more reliable reasoning trajectories. Methodologically, we introduce the concept of reasoning outliers and design an attention-based mechanism to remove them. Theoretically, FROST preserves and enhances the model's reasoning capacity while eliminating outliers at the sentence level. Empirically, we validate FROST on four benchmarks using two strong reasoning models (Phi-4-Reasoning and GPT-OSS-20B), outperforming state-of-the-art methods such as TALE and ThinkLess. Notably, FROST achieves an average 69.68% reduction in token usage and a 26.70% improvement in accuracy over the base model. Furthermore, in evaluations of attention outlier metrics, FROST reduces the maximum infinity norm by 15.97% and the average kurtosis by 91.09% compared to the base model. Code is available at https://github.com/robinzixuan/FROST

</details>


### [8] [Optimizing Conversational Quality in Spoken Dialogue Systems with Reinforcement Learning from AI Feedback](https://arxiv.org/abs/2601.19063)
*Siddhant Arora,Jinchuan Tian,Jiatong Shi,Hayato Futami,Yosuke Kashiwagi,Emiru Tsunoo,Shinji Watanabe*

Main category: cs.CL

TL;DR: 首个面向语音对话系统的多奖励RLAIF框架，结合语义、音频质量和情感一致性奖励，解决现有单奖励方法忽视对话质量多维度的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF/RLAIF方法在语音对话系统中主要限于单语义奖励且应用于话语级别，忽视了对话质量的多维性和多模态特性（语义连贯性、音频自然度、说话人一致性、情感对齐和话轮转换行为），且与双工语音对话系统的增量生成特性不匹配。

Method: 提出首个多奖励RLAIF框架，结合语义、音频质量和情感一致性奖励。采用话轮级别偏好采样，并在单个DPO目标中聚合每块对数概率，以对齐话语级别偏好与双工模型的增量块解码。

Result: 实验表明单奖励RLAIF选择性改进其目标指标，而联合多奖励训练在语义质量和音频自然度上均获得一致提升。多奖励方法在多轮思维链和块级双工模型中均有效。

Conclusion: 研究强调了多维度奖励对齐对于实用对话语音系统的重要性，并发布了多奖励DPO数据集以支持可重复研究。

Abstract: Reinforcement learning from human or AI feedback (RLHF/RLAIF) for speech-in/speech-out dialogue systems (SDS) remains underexplored, with prior work largely limited to single semantic rewards applied at the utterance level. Such setups overlook the multi-dimensional and multi-modal nature of conversational quality, which encompasses semantic coherence, audio naturalness, speaker consistency, emotion alignment, and turn-taking behavior. Moreover, they are fundamentally mismatched with duplex spoken dialogue systems that generate responses incrementally, where agents must make decisions based on partial utterances. We address these limitations with the first multi-reward RLAIF framework for SDS, combining semantic, audio-quality, and emotion-consistency rewards. To align utterance-level preferences with incremental, blockwise decoding in duplex models, we apply turn-level preference sampling and aggregate per-block log-probabilities within a single DPO objective. We present the first systematic study of preference learning for improving SDS quality in both multi-turn Chain-of-Thought and blockwise duplex models, and release a multi-reward DPO dataset to support reproducible research. Experiments show that single-reward RLAIF selectively improves its targeted metric, while joint multi-reward training yields consistent gains across semantic quality and audio naturalness. These results highlight the importance of holistic, multi-reward alignment for practical conversational SDS.

</details>


### [9] [PsyProbe: Proactive and Interpretable Dialogue through User State Modeling for Exploratory Counseling](https://arxiv.org/abs/2601.19096)
*Sohhyung Park,Hyunji Kang,Sungzoon Cho,Dongil Kim*

Main category: cs.CL

TL;DR: PsyProbe 是一个用于心理咨询探索阶段的对话系统，通过系统化的用户心理状态建模和主动提问，在韩国真实咨询场景中表现出优于基线的性能。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康对话系统大多是反应式的，缺乏系统化的用户状态建模来进行主动的治疗探索，限制了心理咨询的效果。

Method: PsyProbe 采用 PPPPPI 框架（呈现、易感性、诱发、持续、保护、影响）结合认知错误检测来跟踪用户心理状态。系统包含状态构建器、记忆构建、策略规划器（基于动机访谈行为编码）、响应生成器（含问题构思和批评/修订模块）。

Result: 在27名参与者的真实韩国咨询场景评估中：1）自动评估显示完整 PsyProbe 模型优于基线和消融模式；2）用户评估显示参与意愿显著增加，自然度改善；3）专家评估显示核心问题理解大幅改善，提问率接近专业咨询师水平。

Conclusion: 系统化的状态建模和主动提问对治疗探索阶段有效，PsyProbe 在自动、用户和专家评估中均表现出色，验证了该方法在心理健康对话系统中的可行性。

Abstract: Recent advances in large language models have enabled mental health dialogue systems, yet existing approaches remain predominantly reactive, lacking systematic user state modeling for proactive therapeutic exploration. We introduce PsyProbe, a dialogue system designed for the exploration phase of counseling that systematically tracks user psychological states through the PPPPPI framework (Presenting, Predisposing, Precipitating, Perpetuating, Protective, Impact) augmented with cognitive error detection. PsyProbe combines State Builder for extracting structured psychological profiles, Memory Construction for tracking information gaps, Strategy Planner for Motivational Interviewing behavioral codes, and Response Generator with Question Ideation and Critic/Revision modules to generate contextually appropriate, proactive questions. We evaluate PsyProbe with 27 participants in real-world Korean counseling scenarios, including automatic evaluation across ablation modes, user evaluation, and expert evaluation by a certified counselor. The full PsyProbe model consistently outperforms baseline and ablation modes in automatic evaluation. User evaluation demonstrates significantly increased engagement intention and improved naturalness compared to baseline. Expert evaluation shows that PsyProbe substantially improves core issue understanding and achieves question rates comparable to professional counselors, validating the effectiveness of systematic state modeling and proactive questioning for therapeutic exploration.

</details>


### [10] [Leveraging Sentence-oriented Augmentation and Transformer-Based Architecture for Vietnamese-Bahnaric Translation](https://arxiv.org/abs/2601.19124)
*Tan Sang Nguyen,Quoc Nguyen Pham,Tho Quan*

Main category: cs.CL

TL;DR: 本文提出使用神经机器翻译技术，结合两种数据增强策略，解决越南语-巴拿语翻译中资源有限的问题，以促进巴拿语的保护和复兴。


<details>
  <summary>Details</summary>
Motivation: 巴拿语作为越南少数民族语言具有重要文化历史价值，政府重视其保护与推广。虽然神经机器翻译技术能提升翻译质量从而促进语言复兴，但越南语-巴拿语翻译面临资源有限的挑战。

Method: 采用先进的神经机器翻译技术，结合两种数据增强策略，专注于领域特定的越南语-巴拿语翻译任务。这些方法灵活且无需复杂数据预处理、额外系统训练或获取额外平行语料。

Result: 论文未明确报告具体实验结果，但指出所提方法能有效应对资源限制问题，为巴拿语翻译提供可行解决方案。

Conclusion: 通过神经机器翻译与数据增强策略的结合，能够有效解决越南语-巴拿语翻译中的资源限制问题，为巴拿语的保护、推广和复兴提供技术支持。

Abstract: The Bahnar people, an ethnic minority in Vietnam with a rich ancestral heritage, possess a language of immense cultural and historical significance. The government places a strong emphasis on preserving and promoting the Bahnaric language by making it accessible online and encouraging communication across generations. Recent advancements in artificial intelligence, such as Neural Machine Translation (NMT), have brought about a transformation in translation by improving accuracy and fluency. This, in turn, contributes to the revival of the language through educational efforts, communication, and documentation. Specifically, NMT is pivotal in enhancing accessibility for Bahnaric speakers, making information and content more readily available. Nevertheless, the translation of Vietnamese into Bahnaric faces practical challenges due to resource constraints, especially given the limited resources available for the Bahnaric language. To address this, we employ state-of-the-art techniques in NMT along with two augmentation strategies for domain-specific Vietnamese-Bahnaric translation task. Importantly, both approaches are flexible and can be used with various neural machine translation models. Additionally, they do not require complex data preprocessing steps, the training of additional systems, or the acquisition of extra data beyond the existing training parallel corpora.

</details>


### [11] [Transparency-First Medical Language Models: Datasheets, Model Cards, and End-to-End Data Provenance for Clinical NLP](https://arxiv.org/abs/2601.19191)
*Olaf Yunus Laitinen Imanov,Taner Yilmaz,Ayse Tuba Tugrul,Melike Nesrin Zaman,Ozkan Gunalp,Duygu Erisken,Sila Burde Dulger,Rana Irem Turhan,Izzet Ozdemir,Derya Umut Kulali,Ozan Akbulut,Harun Demircioglu,Hasan Basri Kara,Berfin Tavan*

Main category: cs.CL

TL;DR: TeMLM是一个临床语言模型的透明度优先发布框架，包含标准化文档和轻量级审计清单，并在大型合成临床数据集Technetium-I上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 当前临床语言模型缺乏统一的透明度标准，难以确保数据来源、模型构建和治理过程的可靠性与可追溯性。

Method: 设计TeMLM框架，包含TeMLM-Card、TeMLM-Datasheet、TeMLM-Provenance三个核心文档和轻量级一致性检查清单；在Technetium-I合成数据集（49.8万份病历、774万个PHI实体标注、ICD-9-CM诊断标签）上实例化该框架，并用ProtactiniumBERT模型（约1亿参数）验证PHI去识别化和ICD-9代码提取任务。

Result: 成功建立了机器可检查的发布框架，在合成数据集上获得了PHI去识别化（token分类）和前50位ICD-9代码提取（多标签分类）的参考结果；同时指出合成基准对工具和流程验证有价值，但模型部署前仍需在真实临床数据上验证。

Conclusion: TeMLM为临床语言模型提供了统一的透明度框架，通过标准化文档和审计清单提高了模型发布的可信度，但强调合成数据验证需与真实临床数据验证相结合。

Abstract: We introduce TeMLM, a set of transparency-first release artifacts for clinical language models. TeMLM unifies provenance, data transparency, modeling transparency, and governance into a single, machine-checkable release bundle. We define an artifact suite (TeMLM-Card, TeMLM-Datasheet, TeMLM-Provenance) and a lightweight conformance checklist for repeatable auditing. We instantiate the artifacts on Technetium-I, a large-scale synthetic clinical NLP dataset with 498,000 notes, 7.74M PHI entity annotations across 10 types, and ICD-9-CM diagnosis labels, and report reference results for ProtactiniumBERT (about 100 million parameters) on PHI de-identification (token classification) and top-50 ICD-9 code extraction (multi-label classification). We emphasize that synthetic benchmarks are valuable for tooling and process validation, but models should be validated on real clinical data prior to deployment.

</details>


### [12] [Do Images Speak Louder than Words? Investigating the Effect of Textual Misinformation in VLMs](https://arxiv.org/abs/2601.19202)
*Chi Zhang,Wenxuan Ding,Jiale Liu,Mingrui Wu,Qingyun Wu,Ray Mooney*

Main category: cs.CL

TL;DR: 论文提出CONTEXT-VQA数据集，发现当前视觉语言模型容易受到与视觉证据相矛盾的误导性文本提示影响，性能平均下降48.2%。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在多模态推理上表现良好，但其对文本错误信息的鲁棒性尚未充分研究。现有研究主要关注纯文本领域的错误信息，而模型如何处理不同模态间的矛盾信息尚不清楚。

Method: 1. 提出CONTEXT-VQA数据集，包含图像-问题对及系统生成的与视觉证据矛盾的误导性提示；2. 设计评估框架，测试不同模型对矛盾多模态输入的敏感性；3. 对11个先进视觉语言模型进行全面实验。

Result: 实验显示当前视觉语言模型容易受到误导性文本提示影响，常常忽视清晰的视觉证据而偏向矛盾文本，仅经过一轮说服性对话后平均性能下降超过48.2%。

Conclusion: 当前视觉语言模型存在对文本操纵的鲁棒性不足的严重局限，需要改进模型以更好地处理多模态矛盾信息。

Abstract: Vision-Language Models (VLMs) have shown strong multimodal reasoning capabilities on Visual-Question-Answering (VQA) benchmarks. However, their robustness against textual misinformation remains under-explored. While existing research has studied the effect of misinformation in text-only domains, it is not clear how VLMs arbitrate between contradictory information from different modalities. To bridge the gap, we first propose the CONTEXT-VQA (i.e., Conflicting Text) dataset, consisting of image-question pairs together with systematically generated persuasive prompts that deliberately conflict with visual evidence. Then, a thorough evaluation framework is designed and executed to benchmark the susceptibility of various models to these conflicting multimodal inputs. Comprehensive experiments over 11 state-of-the-art VLMs reveal that these models are indeed vulnerable to misleading textual prompts, often overriding clear visual evidence in favor of the conflicting text, and show an average performance drop of over 48.2% after only one round of persuasive conversation. Our findings highlight a critical limitation in current VLMs and underscore the need for improved robustness against textual manipulation.

</details>


### [13] [How Do Transformers Learn to Associate Tokens: Gradient Leading Terms Bring Mechanistic Interpretability](https://arxiv.org/abs/2601.19208)
*Shawn Im,Changdae Oh,Zhen Fang,Sharon Li*

Main category: cs.CL

TL;DR: 该论文通过训练动态分析注意力语言模型如何从自然语言数据中学习语义关联，并推导出权重闭式表达式


<details>
  <summary>Details</summary>
Motivation: 理解语义关联（如"鸟"和"飞"之间的联系）如何在语言模型中被学习和表示，这对于连接深度学习与语言学理论、建立大语言模型的机制基础至关重要

Method: 利用梯度主导项近似，推导出训练早期阶段的权重闭式表达式，揭示transformer权重可表示为三种基函数（二元组、令牌可互换性和上下文映射）的简单组合

Result: 理论权重特征与实际LLM学习到的权重高度匹配，定性分析显示该理论能解释transformer如何通过学习这些组合来捕获语义关联

Conclusion: 通过训练动态分析揭示了transformer学习语义关联的机制基础，为解释语言模型内部表示提供了理论框架

Abstract: Semantic associations such as the link between "bird" and "flew" are foundational for language modeling as they enable models to go beyond memorization and instead generalize and generate coherent text. Understanding how these associations are learned and represented in language models is essential for connecting deep learning with linguistic theory and developing a mechanistic foundation for large language models. In this work, we analyze how these associations emerge from natural language data in attention-based language models through the lens of training dynamics. By leveraging a leading-term approximation of the gradients, we develop closed-form expressions for the weights at early stages of training that explain how semantic associations first take shape. Through our analysis, we reveal that each set of weights of the transformer has closed-form expressions as simple compositions of three basis functions (bigram, token-interchangeability, and context mappings), reflecting the statistics of the text corpus and uncovering how each component of the transformer captures semantic associations based on these compositions. Experiments on real-world LLMs demonstrate that our theoretical weight characterizations closely match the learned weights, and qualitative analyses further show how our theorem shines light on interpreting the learned associations in transformers.

</details>


### [14] [SynCABEL: Synthetic Contextualized Augmentation for Biomedical Entity Linking](https://arxiv.org/abs/2601.19667)
*Adam Remaki,Christel Gérardin,Eulàlia Farré-Maduell,Martin Krallinger,Xavier Tannier*

Main category: cs.CL

TL;DR: SynCABEL：利用大语言模型生成生物医学实体链接的上下文增强合成训练数据，减少对专家标注的依赖，在多语言基准测试中取得SOTA结果


<details>
  <summary>Details</summary>
Motivation: 解决生物医学实体链接（BEL）中专家标注训练数据稀缺的核心瓶颈问题。现有的监督学习方法严重依赖成本高昂、劳动密集型的专家标注，限制了模型的可扩展性和性能。

Method: 提出SynCABEL框架，利用大语言模型为目标知识库中的所有候选概念生成上下文丰富的合成训练示例。该方法提供广泛的监督而不需要手动标注。结合仅解码器模型和引导推理，并在标准评估基础上引入LLM-as-a-judge协议来评估临床有效性。

Result: 在三个多语言基准测试中（英语MedMentions、法语QUAERO、西班牙语SPACCC）达到新的最先进水平。数据效率方面，使用比完整人工监督少60%的标注数据即可达到相同性能。LLM-as-a-judge分析显示SynCABEL显著提高了临床有效预测的比例。

Conclusion: SynCABEL有效解决了生物医学实体链接的数据稀缺问题，通过合成数据生成大幅减少对专家标注的依赖，同时提高模型性能和临床有效性。该框架具有重要的实际应用价值，已开源数据集、模型和代码以支持可复现性和未来研究。

Abstract: We present SynCABEL (Synthetic Contextualized Augmentation for Biomedical Entity Linking), a framework that addresses a central bottleneck in supervised biomedical entity linking (BEL): the scarcity of expert-annotated training data. SynCABEL leverages large language models to generate context-rich synthetic training examples for all candidate concepts in a target knowledge base, providing broad supervision without manual annotation. We demonstrate that SynCABEL, when combined with decoder-only models and guided inference establish new state-of-the-art results across three widely used multilingual benchmarks: MedMentions for English, QUAERO for French, and SPACCC for Spanish. Evaluating data efficiency, we show that SynCABEL reaches the performance of full human supervision using up to 60% less annotated data, substantially reducing reliance on labor-intensive and costly expert labeling. Finally, acknowledging that standard evaluation based on exact code matching often underestimates clinically valid predictions due to ontology redundancy, we introduce an LLM-as-a-judge protocol. This analysis reveals that SynCABEL significantly improves the rate of clinically valid predictions. Our synthetic datasets, models, and code are released to support reproducibility and future research.

</details>


### [15] [A Hybrid Supervised-LLM Pipeline for Actionable Suggestion Mining in Unstructured Customer Reviews](https://arxiv.org/abs/2601.19214)
*Aakash Trivedi,Aniket Upadhyay,Pratik Narang,Dhruv Kumar,Praveen Kumar*

Main category: cs.CL

TL;DR: 结合RoBERTa分类器和指令调优LLM的混合架构，从客户评论中提取可操作建议，在准确性和聚类一致性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 客户评论中常包含对业务改进有价值的具体建议，但这些建议往往混杂在无结构的混合意图文本中。现有方法要么分类建议性句子，要么生成高级摘要，很少能精确提取企业所需的改进指令。

Method: 采用混合管道：1) 使用高召回率的RoBERTa分类器（采用精确率-召回率替代损失训练以减少不可恢复的假阴性）；2) 指令调优的LLM用于建议提取、分类、聚类和摘要生成。

Result: 在真实世界的酒店和餐饮数据集上，混合系统在提取准确性和聚类一致性上优于仅提示、基于规则和仅分类器的基线方法。人工评估确认生成的建议和摘要清晰、忠实且可解释。

Conclusion: 混合推理架构在细粒度可操作建议挖掘方面取得显著改进，同时凸显了领域适应性和高效本地部署方面的挑战。

Abstract: Extracting actionable suggestions from customer reviews is essential for operational decision-making, yet these directives are often embedded within mixed-intent, unstructured text. Existing approaches either classify suggestion-bearing sentences or generate high-level summaries, but rarely isolate the precise improvement instructions businesses need. We evaluate a hybrid pipeline combining a high-recall RoBERTa classifier trained with a precision-recall surrogate to reduce unrecoverable false negatives with a controlled, instruction-tuned LLM for suggestion extraction, categorization, clustering, and summarization. Across real-world hospitality and food datasets, the hybrid system outperforms prompt-only, rule-based, and classifier-only baselines in extraction accuracy and cluster coherence. Human evaluations further confirm that the resulting suggestions and summaries are clear, faithful, and interpretable. Overall, our results show that hybrid reasoning architectures achieve meaningful improvements fine-grained actionable suggestion mining while highlighting challenges in domain adaptation and efficient local deployment.

</details>


### [16] [When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering](https://arxiv.org/abs/2601.19827)
*Mahdi Astaraki,Mohammad Arshi Saloot,Ali Shiraee Kasmaee,Hamidreza Mahyar,Soheila Samiee*

Main category: cs.CL

TL;DR: 本文首次通过机制级诊断研究证明，在科学多跳推理任务中，迭代式检索增强生成（Iterative RAG）能够超越理想静态检索（Gold Context）的上限表现，提升达25.6个百分点，尤其对非推理微调模型效果显著。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统虽能扩展LLM的非参数知识，但迭代检索-推理循环在科学领域（多跳推理、稀疏领域知识、异构证据）是否真正优于静态RAG尚不明确，缺乏机制层面的诊断研究。

Method: 采用化学领域ChemKGMultiHopQA数据集，设计三种实验范式：无上下文（测参数记忆）、黄金上下文（一次性提供所有证据）、迭代RAG（无训练控制器交替进行检索、假设精炼和证据感知停止）。对11个SOTA LLM进行基准测试，分析检索覆盖缺口、锚点传递丢失、查询质量、组合保真度和控制校准等诊断指标。

Result: 迭代RAG在所有模型中均一致优于黄金上下文，最高提升25.6个百分点，对非推理微调模型提升尤其显著。分阶段检索减少了后期跳失败、缓解了上下文过载、能动态纠正早期假设漂移，但仍有检索覆盖不全、干扰轨迹锁定、早期停止校准不准、即使完美检索下组合失败率高等问题。

Conclusion: 分阶段检索往往比单纯提供理想证据更重要；研究为专业科学场景中部署和诊断RAG系统提供了实用指导，并为构建更可靠、可控的迭代检索-推理框架奠定了基础。

Abstract: Retrieval-Augmented Generation (RAG) extends large language models (LLMs) beyond parametric knowledge, yet it is unclear when iterative retrieval-reasoning loops meaningfully outperform static RAG, particularly in scientific domains with multi-hop reasoning, sparse domain knowledge, and heterogeneous evidence. We provide the first controlled, mechanism-level diagnostic study of whether synchronized iterative retrieval and reasoning can surpass an idealized static upper bound (Gold Context) RAG. We benchmark eleven state-of-the-art LLMs under three regimes: (i) No Context, measuring reliance on parametric memory; (ii) Gold Context, where all oracle evidence is supplied at once; and (iii) Iterative RAG, a training-free controller that alternates retrieval, hypothesis refinement, and evidence-aware stopping. Using the chemistry-focused ChemKGMultiHopQA dataset, we isolate questions requiring genuine retrieval and analyze behavior with diagnostics spanning retrieval coverage gaps, anchor-carry drop, query quality, composition fidelity, and control calibration. Across models, Iterative RAG consistently outperforms Gold Context, with gains up to 25.6 percentage points, especially for non-reasoning fine-tuned models. Staged retrieval reduces late-hop failures, mitigates context overload, and enables dynamic correction of early hypothesis drift, but remaining failure modes include incomplete hop coverage, distractor latch trajectories, early stopping miscalibration, and high composition failure rates even with perfect retrieval. Overall, staged retrieval is often more influential than the mere presence of ideal evidence; we provide practical guidance for deploying and diagnosing RAG systems in specialized scientific settings and a foundation for more reliable, controllable iterative retrieval-reasoning frameworks.

</details>


### [17] [DREAMSTATE: Diffusing States and Parameters for Recurrent Large Language Models](https://arxiv.org/abs/2601.19221)
*Liu Xiao*

Main category: cs.CL

TL;DR: 提出DREAMSTATE框架，利用条件扩散变换器建模RWKV状态的概率流形，实现状态生成与编辑；并设计结合RNN局部优势与全局上下文适应性的混合架构。


<details>
  <summary>Details</summary>
Motivation: 现代RNN（如RWKV）具有强大的短程建模能力和高效固定大小状态，但缺乏对其内部状态作为可编辑知识表示的研究。

Method: 1) 提出DREAMSTATE框架，使用条件扩散变换器直接建模状态的概率流形；2) 提出混合架构，结合RNN局部优势与全局上下文适应性，通过并行DiT处理变长全局上下文来动态生成和调整核心循环模块的WKV参数。

Result: 通过t-SNE可视化和受控生成实验验证了状态表示的结构性；混合模型可通过多目标损失稳定训练，验证了设计可行性。

Conclusion: 该工作不仅为RNN状态表示开辟了新研究方向，还为未来模型设计提供了具体的架构参考。

Abstract: Modern Recurrent Neural Networks (RNNs), such as RWKV, are distinguished by their powerful short-range modeling capabilities and efficient fixed-size states, which constitute a core advantage over standard Transformers. However, there is a significant lack of research into their internal state as an editable knowledge representation. To fill this gap, we first explore the representational properties of the RWKV state by proposing the DREAMSTATE framework. This framework utilizes a conditional Diffusion Transformer (DiT) to directly model the probability manifold of the state, enabling its generation and editing. The structural nature of this representation is validated through t-SNE visualizations and controlled generation experiments. After successfully uncovering and modeling the state's representational potential, we further propose a novel hybrid architecture that combines the local advantages of RNNs with global context adaptability. This architecture features a parallel DiT that processes a variable-length global context to dynamically generate and adjust the core recurrent module's WKV parameters, transforming the fixed recurrence mechanism into a context-aware dynamic function. Experiments demonstrate that this hybrid model can be trained stably via a multi-objective loss, validating its design feasibility. Our work not only opens a new research direction for RNN state representation but also provides a concrete architectural reference for future model design. The code is publicly available at: https://huggingface.co/2dgx41s/DreamState.

</details>


### [18] [RPO-RAG: Aligning Small LLMs with Relation-aware Preference Optimization for Knowledge Graph Question Answering](https://arxiv.org/abs/2601.19225)
*Kaehyun Um,KyuHwan Yeom,Haerim Yang,Minyoung Choi,Hyeongjun Yang,Kyong-Ho Lee*

Main category: cs.CL

TL;DR: RPO-RAG：首个专门为小型LLMs设计的基于知识图谱的检索增强生成框架，通过语义采样、关系感知优化和答案中心提示设计，显著提升小型LLMs在KGQA任务上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的RAG方法存在三个主要问题：1）依赖语义不敏感的路径采样，与KG推理目标对齐较弱；2）检索到的路径直接输入推理器，缺乏组织，阻碍小型LLMs利用知识；3）先前工作主要依赖大型LLMs或7B以上参数模型，对7B以下小型模型探索不足。

Method: RPO-RAG提出三个关键创新：1）查询-路径语义采样策略，提供信息丰富的监督信号；2）关系感知偏好优化，将训练与KG推理中间信号（如关系）对齐；3）答案中心的提示设计，以可解释格式组织实体和推理路径。

Result: 在WebQSP和CWQ两个KGQA基准数据集上的实验表明：在WebQSP上F1提升最高达8.8%；在CWQ上，在8B参数以下模型中达到新的SOTA结果（Hit和F1）。即使在3B参数以下的小型LLMs上，RPO-RAG也显著提升了推理能力。

Conclusion: RPO-RAG有效缩小了小型与大型语言模型之间的性能差距，展示了小型LLMs在资源高效、实用的设备端KGQA应用中的潜力。

Abstract: Large Language Models (LLMs) have recently demonstrated remarkable reasoning abilities, yet hallucinate on knowledge-intensive tasks. Retrieval-augmented generation (RAG) mitigates this issue by grounding answers in external sources, e.g., knowledge graphs (KGs). However, existing KG-based RAG approaches rely on semantics-unaware path sampling and are weakly aligned with KG reasoning objectives, which limits further accuracy gains. They also feed retrieved paths directly into the reasoner without organizing them into answer-centered reasoning paths, hindering small LLMs' ability to leverage the retrieved knowledge. Furthermore, prior works predominantly rely on large LLMs (e.g., ChatGPT/GPT-4) or assume backbones above 7B parameters, leaving sub-7B models underexplored. We address this gap with RPO-RAG, the first KG-based RAG framework specifically designed for small LLMs, to the best of our knowledge. RPO-RAG introduces three key innovations: (1) a query-path semantic sampling strategy that provides informative supervisory signals; (2) a relation-aware preference optimization that aligns training with intermediate KG reasoning signals (e.g., relation); and (3) an answer-centered prompt design that organizes entities and reasoning paths in an interpretable format. Extensive experiments on two benchmark Knowledge Graph Question Answering (KGQA) datasets, WebQSP and CWQ, demonstrate that RPO-RAG effectively bridges the performance gap between small and large language models. On WebQSP, it improves F1 by up to 8.8%, reflecting enhanced answer precision, while on CWQ it achieves new state-of-the-art results among models under 8B parameters in both Hit and F1. Overall, RPO-RAG substantially improves the reasoning capability of small LLMs, even under 3B parameters-highlighting their potential for resource-efficient and practical on-device KGQA applications.

</details>


### [19] [DiaDem: Advancing Dialogue Descriptions in Audiovisual Video Captioning for Multimodal Large Language Models](https://arxiv.org/abs/2601.19267)
*Xinlong Chen,Weihong Lin,Jingyun Hua,Linli Yao,Yue Ding,Bozhou Li,Bohan Zeng,Yang Shi,Qiang Liu,Yuanxing Zhang,Pengfei Wan,Liang Wang,Tieniu Tan*

Main category: cs.CL

TL;DR: DiaDem是一个能够生成更精确对话描述的视听视频字幕模型，通过合成高质量SFT数据集和两阶段GRPO策略优化，在对话描述准确性上超越了Gemini系列模型。


<details>
  <summary>Details</summary>
Motivation: 现有视听视频字幕模型在生成忠实对话描述方面存在困难，而准确的对话描述对于下游理解和生成任务至关重要。

Method: 1. 合成高质量SFT数据集；2. 采用难度分区的两阶段GRPO策略来增强对话描述能力；3. 提出DiaDemBench基准来系统评估对话描述能力。

Result: DiaDem在对话描述准确性上超越了Gemini系列模型，同时在通用视听字幕基准上保持了竞争力，DiaDemBench评估显示即使是商业模型在对话感知字幕方面仍有很大改进空间。

Conclusion: DiaDem在生成精确对话描述的视听字幕方面表现出色，提出的DiaDemBench为系统评估对话描述能力提供了有效工具，推动了该领域的发展。

Abstract: Accurate dialogue description in audiovisual video captioning is crucial for downstream understanding and generation tasks. However, existing models generally struggle to produce faithful dialogue descriptions within audiovisual captions. To mitigate this limitation, we propose DiaDem, a powerful audiovisual video captioning model capable of generating captions with more precise dialogue descriptions while maintaining strong overall performance. We first synthesize a high-quality dataset for SFT, then employ a difficulty-partitioned two-stage GRPO strategy to further enhance dialogue descriptions. To enable systematic evaluation of dialogue description capabilities, we introduce DiaDemBench, a comprehensive benchmark designed to evaluate models across diverse dialogue scenarios, emphasizing both speaker attribution accuracy and utterance transcription fidelity in audiovisual captions. Extensive experiments on DiaDemBench reveal even commercial models still exhibit substantial room for improvement in dialogue-aware captioning. Notably, DiaDem not only outperforms the Gemini series in dialogue description accuracy but also achieves competitive performance on general audiovisual captioning benchmarks, demonstrating its overall effectiveness.

</details>


### [20] [Riddle Quest : The Enigma of Words](https://arxiv.org/abs/2601.19273)
*Niharika Sri Parasa,Chaitali Diwan,Srinath Srinivasa*

Main category: cs.CL

TL;DR: 研究者提出了一個簡單的流程來創建和評估基於類比的謎語，並用該系統測試大型語言模型是否能完整識別謎語的所有可能答案。


<details>
  <summary>Details</summary>
Motivation: 謎語是一種需要解釋提示、識別模式並進行推論才能找到答案的創造性表達形式。研究者希望利用謎語作為輕量級工具來檢驗語言模型的推理覆蓋率和模糊性處理能力。

Method: 系統包含四個主要組件：三元組創建器（構建概念結構化事實）、語義映射器（選擇適合類比的屬性）、風格化生成器（將屬性轉化為謎語線索）、驗證器（收集謎語所有可能答案）。研究者使用這個驗證器來研究大型語言模型是否能完整恢復不同謎語類型的答案集合。

Result: 案例研究顯示，雖然語言模型通常能猜出主要預期答案，但經常錯過其他有效的解釋。這突顯了謎語作為檢驗語言模型推理覆蓋率和模糊性處理能力的價值。

Conclusion: 謎語可以作為一個輕量級工具，有效評估語言模型在處理模糊性和覆蓋多種解釋方面的能力。研究結果表明當前語言模型在完整理解謎語所有可能答案方面仍有不足。

Abstract: Riddles are concise linguistic puzzles that describe an object or idea through indirect, figurative, or playful clues. They are a longstanding form of creative expression, requiring the solver to interpret hints, recognize patterns, and draw inferences to identify the answers. In this work, we introduce a simple pipeline for creating and evaluating analogy-based riddles. The system includes a triples creator that builds structured facts about a concept, a semantic mapper that selects attributes useful for analogy, a stylized generator that turns them into riddle clues, and a validator that collects all possible answers the riddle could point to. We use this validator to study whether large language models can recover the full answer set for different riddle types. Our case study shows that while models often guess the main intended answer, they frequently miss other valid interpretations. This highlights the value of riddles as a lightweight tool for examining reasoning coverage and ambiguity handling in language models.

</details>


### [21] [DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference](https://arxiv.org/abs/2601.19278)
*Fuliang Liu,Xue Li,Ketai Zhao,Yinxi Gao,Ziyan Zhou,Zhonghui Zhang,Zhibin Wang,Wanchun Dou,Sheng Zhong,Chen Tian*

Main category: cs.CL

TL;DR: DART提出一种基于扩散式语言模型的并行生成推测解码方法，通过单次前向传播预测多个未来位置的logits，减少草稿阶段的延迟，同时保持轻量级设计和高精度。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法（如EAGLE3）虽然提高了精度，但采用多步自回归推理导致草稿阶段延迟高，成为性能瓶颈。需要一种既能保持高精度又能显著降低草稿延迟的方法。

Method: 1. 基于扩散式语言模型（dLLMs）的并行生成：利用目标模型的隐藏状态，在单次前向传播中并行预测多个未来掩码位置的logits，避免自回归展开；2. 高效的树剪枝算法：基于并行logit预测构建高质量草稿标记树，强制N-gram语义连续性；3. 轻量级设计，保持低开销。

Result: DART在多个数据集上实现了2.03x-3.44x的端到端解码速度提升，平均比EAGLE3快30%，显著减少了草稿阶段开销，同时保持高精度。

Conclusion: DART通过并行生成和高效树剪枝算法，在保持高精度的同时显著降低了推测解码的草稿阶段延迟，提供了一种实用的推测解码框架，有效解决了现有方法的性能瓶颈问题。

Abstract: Speculative decoding is an effective and lossless approach for accelerating LLM inference. However, existing widely adopted model-based draft designs, such as EAGLE3, improve accuracy at the cost of multi-step autoregressive inference, resulting in high drafting latency and ultimately rendering the drafting stage itself a performance bottleneck. Inspired by diffusion-based large language models (dLLMs), we propose DART, which leverages parallel generation to reduce drafting latency. DART predicts logits for multiple future masked positions in parallel within a single forward pass based on hidden states of the target model, thereby eliminating autoregressive rollouts in the draft model while preserving a lightweight design. Based on these parallel logit predictions, we further introduce an efficient tree pruning algorithm that constructs high-quality draft token trees with N-gram-enforced semantic continuity. DART substantially reduces draft-stage overhead while preserving high draft accuracy, leading to significantly improved end-to-end decoding speed. Experimental results demonstrate that DART achieves a 2.03x--3.44x wall-clock time speedup across multiple datasets, surpassing EAGLE3 by 30% on average and offering a practical speculative decoding framework. Code is released at https://github.com/fvliang/DART.

</details>


### [22] [ReToP: Learning to Rewrite Electronic Health Records for Clinical Prediction](https://arxiv.org/abs/2601.19286)
*Jesus Lovon-Melgarejo,Jose G. Moreno,Christine Damase-Michel,Lynda Tamine*

Main category: cs.CL

TL;DR: 提出ReToP框架，通过端到端训练EHR重写器和临床预测器，利用LLM生成临床相关重写以提升预测性能


<details>
  <summary>Details</summary>
Motivation: 现有方法大多任务无关，将LLM用作EHR编码器或补全模块，未能充分利用预测任务信号，限制了任务性能

Method: 提出Rewrite-To-Predict框架，包含EHR重写器和临床预测器；使用临床驱动特征选择生成合成伪标签来训练重写器；引入Classifier Supervised Contribution评分使重写器生成临床相关重写

Result: 在MIMIC-IV的三个临床任务上超越强基线模型；能够泛化到未见数据集和任务，保持忠实重写并强调任务相关预测特征

Conclusion: ReToP框架通过任务感知的EHR重写有效提升了临床预测性能，具有良好的泛化能力和临床相关性

Abstract: Electronic Health Records (EHRs) provide crucial information for clinical decision-making. However, their high-dimensionality, heterogeneity, and sparsity make clinical prediction challenging. Large Language Models (LLMs) allowed progress towards addressing this challenge by leveraging parametric medical knowledge to enhance EHR data for clinical prediction tasks. Despite the significant achievements made so far, most of the existing approaches are fundamentally task-agnostic in the sense that they deploy LLMs as EHR encoders or EHR completion modules without fully integrating signals from the prediction tasks. This naturally hinders task performance accuracy. In this work, we propose Rewrite-To-Predict (ReToP), an LLM-based framework that addresses this limitation through an end-to-end training of an EHR rewriter and a clinical predictor. To cope with the lack of EHR rewrite training data, we generate synthetic pseudo-labels using clinical-driven feature selection strategies to create diverse patient rewrites for fine-tuning the EHR rewriter. ReToP aligns the rewriter with prediction objectives using a novel Classifier Supervised Contribution (CSC) score that enables the EHR rewriter to generate clinically relevant rewrites that directly enhance prediction. Our ReToP framework surpasses strong baseline models across three clinical tasks on MIMIC-IV. Moreover, the analysis of ReToP shows its generalizability to unseen datasets and tasks with minimal fine-tuning while preserving faithful rewrites and emphasizing task-relevant predictive features.

</details>


### [23] [MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning](https://arxiv.org/abs/2601.19290)
*Yimeng Wang,Jiaxing Zhao,Hongbin Xie,Hexing Ma,Yuzhen Lei,Shuangxue Liu,Xuan Song,Zichen Zhang,Haoran Zhang*

Main category: cs.CL

TL;DR: MetaGen是一个无需训练的多智能体框架，通过动态调整角色空间和协作拓扑来提升复杂任务处理能力


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统依赖固定的角色库和静态交互拓扑，这种刚性设计导致任务不匹配、无法及时适应推理过程中的新证据，并且增加了推理成本

Method: MetaGen在推理时动态生成和重写查询条件角色规范，维护可控的动态角色池，实例化基于最小骨干的约束执行图，迭代更新角色提示并利用轻量级反馈信号调整结构决策

Result: 在代码生成和多步推理基准测试中，MetaGen相比强大的多智能体基线方法，在准确性和成本权衡方面有所改进

Conclusion: MetaGen通过动态调整角色空间和协作拓扑，无需更新基础模型权重，能够有效解决现有多智能体系统的局限性，在保持成本效益的同时提升任务性能

Abstract: Large language models are increasingly deployed as multi-agent systems, where specialized roles communicate and collaborate through structured interactions to solve complex tasks that often exceed the capacity of a single agent. However, most existing systems still rely on a fixed role library and an execution-frozen interaction topology, a rigid design choice that frequently leads to task mismatch, prevents timely adaptation when new evidence emerges during reasoning, and further inflates inference cost. We introduce MetaGen, a training-free framework that adapts both the role space and the collaboration topology at inference time, without updating base model weights. MetaGen generates and rewrites query-conditioned role specifications to maintain a controllable dynamic role pool, then instantiates a constrained execution graph around a minimal backbone. During execution, it iteratively updates role prompts and adjusts structural decisions using lightweight feedback signals. Experiments on code generation and multi-step reasoning benchmarks show that MetaGen improves the accuracy and cost tradeoff over strong multi-agent baselines.

</details>


### [24] [Formula-One Prompting: Adaptive Reasoning Through Equations For Applied Mathematics](https://arxiv.org/abs/2601.19302)
*Natapong Nitarach,Pittawat Taveekitworachai,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: Formula-One Prompting (F-1) 是一种两阶段提示方法，首先从问题描述中提取控制方程，然后根据方程自适应选择解决策略（CoT、PoT或直接计算），在单个LLM调用中完成，显著提升应用数学问题的解决效果。


<details>
  <summary>Details</summary>
Motivation: 现有提示技术（如CoT和PoT）在数学推理中通过自然语言或代码构建中间步骤，但在金融、物理、密码学等应用数学领域，问题通常需要回忆或推导控制方程，这是当前方法未能充分利用的关键步骤。

Method: F-1采用两阶段方法：1) 从问题描述中提取或推导出控制方程作为中间表示；2) 根据生成的方程自适应选择解决策略（CoT、PoT或直接计算），整个过程在单个LLM调用中完成。

Result: 在5个模型和4个基准测试中，F-1平均比CoT提升5.76%，比PoT提升8.42%。在应用领域提升尤其显著：在FinanceMath上比CoT提升13.30%；在OlympiadBench中，物理问题提升2.55%，而纯数学问题仅提升0.44%。

Conclusion: F-1通过显式利用数学方程作为中间表示，在应用数学问题上比CoT更有效，证明了方程优先的方法在复杂数学推理中的价值。

Abstract: Prompting techniques such as Chain-of-Thought (CoT) and Program-of-Thought (PoT) improve LLM mathematical reasoning by structuring intermediate steps in natural language or code. However, applied mathematics problems in domains like finance, physics, and cryptography often require recalling or deriving governing equations, a step that current approaches do not explicitly leverage. We propose Formula-One Prompting (F-1), a two-phase approach that uses mathematical equations as an intermediate representation before adaptive solving. F-1 first formulates governing equations from problem descriptions, then selects a solving strategy among CoT, PoT, or direct computation based on the generated equations, all within a single LLM call. Results across five models and four benchmarks show F-1 outperforms CoT by +5.76% and PoT by +8.42% on average. Crucially, gains are largest in applied domains: +13.30% on FinanceMath over CoT, and within OlympiadBench, larger gains on physics (+2.55%) than pure math (+0.44%). This demonstrates that F-1 is more effective than CoT in applied mathematics problems.

</details>


### [25] [When Benchmarks Leak: Inference-Time Decontamination for LLMs](https://arxiv.org/abs/2601.19334)
*Jianzhe Chai,Yu Zhe,Jun Sakuma*

Main category: cs.CL

TL;DR: DeconIEP：一种通过在输入嵌入空间施加有界扰动来减少测试集污染的评估框架，能在保持基准完整性的同时有效抑制记忆驱动的捷径行为。


<details>
  <summary>Details</summary>
Motivation: 基准评估是LLM比较的标准方法，但其可靠性受到测试集污染的威胁——测试样本或其变体泄露到训练数据中，人为提高了报告的性能。现有缓解方法存在局限性：要么需要修改评估集本身，要么在评估时干预会干扰正常推理并导致干净输入上的性能下降。

Method: DeconIEP在评估过程中完全操作，通过在输入嵌入空间应用小的有界扰动。该方法以相对较少污染的参考模型为指导，学习一个实例自适应的扰动生成器，引导被评估模型远离记忆驱动的捷径路径。

Result: 在多个开源LLM和基准测试上的广泛实证结果显示，DeconIEP实现了强大的去污染效果，同时在良性效用上仅产生最小的性能下降。

Conclusion: DeconIEP提供了一种有效的评估时去污染框架，能够在保持基准完整性的同时，可靠地减轻测试集污染对LLM性能评估的影响。

Abstract: Benchmark-based evaluation is the de facto standard for comparing large language models (LLMs). However, its reliability is increasingly threatened by test set contamination, where test samples or their close variants leak into training data and artificially inflate reported performance. To address this issue, prior work has explored two main lines of mitigation. One line attempts to identify and remove contaminated benchmark items before evaluation, but this inevitably alters the evaluation set itself and becomes unreliable when contamination is moderate or severe. The other line preserves the benchmark and instead suppresses contaminated behavior at evaluation time; however, such interventions often interfere with normal inference and lead to noticeable performance degradation on clean inputs. We propose DeconIEP, a decontamination framework that operates entirely during evaluation by applying small, bounded perturbations in the input embedding space. Guided by a relatively less-contaminated reference model, DeconIEP learns an instance-adaptive perturbation generator that steers the evaluated model away from memorization-driven shortcut pathways. Across multiple open-weight LLMs and benchmarks, extensive empirical results show that DeconIEP achieves strong decontamination effectiveness while incurring only minimal degradation in benign utility.

</details>


### [26] [Cross-Examination Framework: A Task-Agnostic Diagnostic for Information Fidelity in Text-to-Text Generation](https://arxiv.org/abs/2601.19350)
*Tathagata Raha,Clement Christophe,Nada Saadi,Hamza A Javed,Marco AF Pimentel,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.CL

TL;DR: CEF是一个无需参考文本的多维度评估框架，通过将源文本和生成文本视为独立知识库进行交叉验证，生成可验证问题来计算覆盖度、一致性和连贯性分数。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标如BLEU和BERTScore无法捕捉生成文本任务的语义保真度，特别是在无参考文本的情况下评估生成质量存在困难。

Method: 将源文本和候选文本视为独立知识库，从每个文本生成可验证的问题，通过交叉验证计算三个可解释分数：覆盖度（Coverage）、一致性（Conformity）和连贯性（Consistency）。

Result: 在翻译、摘要和临床笔记生成任务上验证，CEF能够识别标准指标遗漏的关键错误（如内容遗漏和事实矛盾）。无参考模式与有参考模式强相关，验证了无需黄金参考的可靠性。人类专家验证显示CEF不匹配问题与语义错误高度相关。

Conclusion: CEF提供了一个可靠、无需参考的多维度评估框架，能够有效识别生成文本中的语义错误，特别是在实体和关系扭曲方面表现出色。

Abstract: Traditional metrics like BLEU and BERTScore fail to capture semantic fidelity in generative text-to-text tasks. We adapt the Cross-Examination Framework (CEF) for a reference-free, multi-dimensional evaluation by treating the source and candidate as independent knowledge bases. CEF generates verifiable questions from each text and performs a cross-examination to derive three interpretable scores: Coverage, Conformity, and Consistency. Validated across translation, summarization and clinical note-generation, our framework identifies critical errors, such as content omissions and factual contradictions, missed by standard metrics. A key contribution is a systematic robustness analysis to select a stable judge model. Crucially, the strong correlation between our reference-free and with-reference modes validates CEF's reliability without gold references. Furthermore, human expert validation demonstrates that CEF mismatching questions align with meaning-altering semantic errors higher than with non-semantic errors, particularly excelling at identifying entity-based and relational distortions.

</details>


### [27] [Binary Token-Level Classification with DeBERTa for All-Type MWE Identification: A Lightweight Approach with Linguistic Enhancement](https://arxiv.org/abs/2601.19360)
*Diego Rossini,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 本文提出了一种结合二元token级分类、语言学特征集成和数据增强的多词表达识别方法，在CoAM数据集上取得69.8% F1分数，显著优于大型语言模型，且参数数量减少165倍。


<details>
  <summary>Details</summary>
Motivation: 多词表达识别是自然语言处理中的重要任务，现有方法特别是大型语言模型在结构化NLP任务上表现不佳且计算资源消耗大。本文旨在证明通过精心设计的小型模型可以在资源受限环境下显著超越大型模型。

Method: 1) 将检测重构为二元token级START/END/INSIDE分类而非基于跨度的预测；2) 集成NP分块和依存特征以帮助识别不连续和名词型多词表达；3) 应用过采样技术解决训练数据中的严重类别不平衡问题。

Result: DeBERTa-v3-large模型在CoAM数据集上达到69.8% F1分数，比该数据集最佳结果（Qwen-72B，57.8% F1）提升12个百分点，参数数量减少165倍。在STREUSLE数据集上验证泛化能力，达到78.9% F1分数。

Conclusion: 精心设计的小型模型在结构化NLP任务上可以显著超越大型语言模型，这对资源受限部署具有重要意义，证明了特定任务优化方法相对于通用大规模模型的有效性。

Abstract: We present a comprehensive approach for multiword expression (MWE) identification that combines binary token-level classification, linguistic feature integration, and data augmentation. Our DeBERTa-v3-large model achieves 69.8% F1 on the CoAM dataset, surpassing the best results (Qwen-72B, 57.8% F1) on this dataset by 12 points while using 165x fewer parameters. We achieve this performance by (1) reformulating detection as binary token-level START/END/INSIDE classification rather than span-based prediction, (2) incorporating NP chunking and dependency features that help discontinuous and NOUN-type MWEs identification, and (3) applying oversampling that addresses severe class imbalance in the training data. We confirm the generalization of our method on the STREUSLE dataset, achieving 78.9% F1. These results demonstrate that carefully designed smaller models can substantially outperform LLMs on structured NLP tasks, with important implications for resource-constrained deployments.

</details>


### [28] [Do LLMs Truly Benefit from Longer Context in Automatic Post-Editing?](https://arxiv.org/abs/2601.19410)
*Ahrii Kim,Seong-heum Kim*

Main category: cs.CL

TL;DR: 大型语言模型在文档级自动后编辑中表现出色，但存在成本高、难以有效利用上下文等限制。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在翻译方面表现出色，但它们在文档级自动后编辑中的有效性尚未得到充分理解，特别是在利用上下文纠正错误方面。

Method: 对专有和开源大型语言模型进行系统比较，采用简单的文档级提示设置，分析APE质量、上下文行为、鲁棒性和效率。

Result: 专有LLMs即使使用简单的一次提示也能达到接近人类水平的APE质量，但对数据中毒攻击的鲁棒性较高，却难以有效利用文档级上下文进行错误纠正；标准自动评估指标无法可靠反映质量改进。

Conclusion: 专有LLMs在APE方面表现出色但成本过高，难以实际部署；当前LLM在文档级上下文利用方面存在局限，需要更高效的长上下文建模方法。

Abstract: Automatic post-editing (APE) aims to refine machine translations by correcting residual errors. Although recent large language models (LLMs) demonstrate strong translation capabilities, their effectiveness for APE--especially under document-level context--remains insufficiently understood. We present a systematic comparison of proprietary and open-weight LLMs under a naive document-level prompting setup, analyzing APE quality, contextual behavior, robustness, and efficiency.
  Our results show that proprietary LLMs achieve near human-level APE quality even with simple one-shot prompting, regardless of whether document context is provided. While these models exhibit higher robustness to data poisoning attacks than open-weight counterparts, this robustness also reveals a limitation: they largely fail to exploit document-level context for contextual error correction. Furthermore, standard automatic metrics do not reliably reflect these qualitative improvements, highlighting the continued necessity of human evaluation. Despite their strong performance, the substantial cost and latency overheads of proprietary LLMs render them impractical for real-world APE deployment. Overall, our findings elucidate both the promise and current limitations of LLM-based document-aware APE, and point toward the need for more efficient long-context modeling approaches for translation refinement.

</details>


### [29] [KG-CRAFT: Knowledge Graph-based Contrastive Reasoning with LLMs for Enhancing Automated Fact-checking](https://arxiv.org/abs/2601.19447)
*Vítor N. Lourenço,Aline Paes,Tillman Weyde,Audrey Depeige,Mohnish Dubey*

Main category: cs.CL

TL;DR: KG-CRAFT利用知识图谱构建对比问题，增强大语言模型在声明验证任务中的事实核查能力，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自动声明验证系统在处理复杂声明时面临证据利用不充分、推理能力有限的挑战，需要更有效地整合结构化知识来提升事实核查的准确性。

Method: KG-CRAFT首先从声明和相关报告中构建知识图谱，然后基于图谱结构生成上下文相关的对比问题，这些问题指导证据报告的提炼，最终生成简洁摘要供LLM进行真实性评估。

Result: 在LIAR-RAW和RAWFC两个真实世界数据集上的广泛评估表明，该方法在预测性能上达到了新的最先进水平，知识图谱对比推理方法有效提升了LLM的事实核查能力。

Conclusion: KG-CRAFT通过知识图谱驱动的对比问题增强LLM的证据推理能力，为自动事实核查提供了一种有效方法，在多个基准测试中显著优于现有方法。

Abstract: Claim verification is a core component of automated fact-checking systems, aimed at determining the truthfulness of a statement by assessing it against reliable evidence sources such as documents or knowledge bases. This work presents KG-CRAFT, a method that improves automatic claim verification by leveraging large language models (LLMs) augmented with contrastive questions grounded in a knowledge graph. KG-CRAFT first constructs a knowledge graph from claims and associated reports, then formulates contextually relevant contrastive questions based on the knowledge graph structure. These questions guide the distillation of evidence-based reports, which are synthesised into a concise summary that is used for veracity assessment by LLMs. Extensive evaluations on two real-world datasets (LIAR-RAW and RAWFC) demonstrate that our method achieves a new state-of-the-art in predictive performance. Comprehensive analyses validate in detail the effectiveness of our knowledge graph-based contrastive reasoning approach in improving LLMs' fact-checking capabilities.

</details>


### [30] [Dynamic Multi-Expert Projectors with Stabilized Routing for Multilingual Speech Recognition](https://arxiv.org/abs/2601.19451)
*Isha Pandey,Ashish Mittal,Vartul Bahuguna,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 提出SMEAR-MoE，一种稳定的专家混合投影器，用于多语言ASR，防止专家崩溃并实现跨语言共享，在四种印度语言上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based ASR方法在单语设置中有效，但单个投影器难以捕捉多语言ASR所需的多样化声学到语义映射。

Method: 提出SMEAR-MoE（稳定专家混合投影器），确保所有专家的密集梯度流，防止专家崩溃同时支持跨语言共享。系统比较了单体、静态多投影器和动态MoE设计。

Result: 在四种印度语言（印地语、马拉地语、泰米尔语、泰卢固语）上，SMEAR-MoE相比单投影器基线实现最高7.6%的相对WER降低，同时保持可比的运行时效率。专家路由分析显示语言学上有意义的专业化，相关语言共享专家。

Conclusion: 稳定的多专家投影器是实现可扩展和鲁棒多语言ASR的关键。

Abstract: Recent advances in LLM-based ASR connect frozen speech encoders with Large Language Models (LLMs) via lightweight projectors. While effective in monolingual settings, a single projector struggles to capture the diverse acoustic-to-semantic mappings required for multilingual ASR. To address this, we propose SMEAR-MoE, a stabilized Mixture-of-Experts projector that ensures dense gradient flow to all experts, preventing expert collapse while enabling cross-lingual sharing. We systematically compare monolithic, static multi-projector, and dynamic MoE designs across four Indic languages (Hindi, Marathi, Tamil, Telugu). Our SMEAR-MoE achieves strong performance, delivering upto a 7.6% relative WER reduction over the single-projector baseline, while maintaining comparable runtime efficiency. Analysis of expert routing further shows linguistically meaningful specialization, with related languages sharing experts. These results demonstrate that stable multi-expert projectors are key to scalable and robust multilingual ASR.

</details>


### [31] [ClaimPT: A Portuguese Dataset of Annotated Claims in News Articles](https://arxiv.org/abs/2601.19490)
*Ricardo Campos,Raquel Sequeira,Sara Nerea,Inês Cantante,Diogo Folques,Luís Filipe Cunha,João Canavilhas,António Branco,Alípio Jorge,Sérgio Nunes,Nuno Guimarães,Purificação Silvano*

Main category: cs.CL

TL;DR: ClaimPT：针对欧洲葡萄牙语新闻文章的事实主张标注数据集，包含1,308篇文章和6,875个标注，为低资源语言的事实核查研究提供基础。


<details>
  <summary>Details</summary>
Motivation: 手动事实核查难以应对在线错误信息的快速传播，而自动化事实核查在非英语语言中因缺乏标注数据而进展缓慢。葡萄牙语尤其缺乏可访问的许可数据集，限制了NLP研究和应用发展。

Method: 与葡萄牙新闻社LUSA合作收集新闻文章，采用新提出的标注方案，由两名训练有素的标注员对每篇文章进行标注，并由管理员验证所有标注。最终创建包含1,308篇文章和6,875个标注的ClaimPT数据集。

Result: 发布了ClaimPT数据集，这是首个专注于欧洲葡萄牙语新闻文章的事实主张标注数据集。提供了基准模型用于主张检测，建立了初步基准，并为未来NLP和信息检索应用奠定了基础。

Conclusion: ClaimPT数据集填补了葡萄牙语事实核查资源的空白，通过专注于新闻内容而非社交媒体或议会记录，为低资源语言的事实核查研究提供了重要工具，有助于推动对新闻媒体中错误信息的理解。

Abstract: Fact-checking remains a demanding and time-consuming task, still largely dependent on manual verification and unable to match the rapid spread of misinformation online. This is particularly important because debunking false information typically takes longer to reach consumers than the misinformation itself; accelerating corrections through automation can therefore help counter it more effectively. Although many organizations perform manual fact-checking, this approach is difficult to scale given the growing volume of digital content. These limitations have motivated interest in automating fact-checking, where identifying claims is a crucial first step. However, progress has been uneven across languages, with English dominating due to abundant annotated data. Portuguese, like other languages, still lacks accessible, licensed datasets, limiting research, NLP developments and applications. In this paper, we introduce ClaimPT, a dataset of European Portuguese news articles annotated for factual claims, comprising 1,308 articles and 6,875 individual annotations. Unlike most existing resources based on social media or parliamentary transcripts, ClaimPT focuses on journalistic content, collected through a partnership with LUSA, the Portuguese News Agency. To ensure annotation quality, two trained annotators labeled each article, with a curator validating all annotations according to a newly proposed scheme. We also provide baseline models for claim detection, establishing initial benchmarks and enabling future NLP and IR applications. By releasing ClaimPT, we aim to advance research on low-resource fact-checking and enhance understanding of misinformation in news media.

</details>


### [32] [GradPruner: Gradient-Guided Layer Pruning Enabling Efficient Fine-Tuning and Inference for LLMs](https://arxiv.org/abs/2601.19503)
*Wei Huang,Anda Cheng,Yinggui Wang*

Main category: cs.CL

TL;DR: GradPruner：利用梯度信息在微调早期对LLM进行层剪枝，提升训练和推理效率


<details>
  <summary>Details</summary>
Motivation: 当前LLM微调需要大量时间和计算资源，传统结构化剪枝方法虽然能提升推理效率，但需要额外训练、知识蒸馏或结构搜索，难以实现高效的微调过程。

Method: 在微调初期计算参数梯度累积矩阵（IGIA-Matrix）评估层重要性，进行剪枝后将剪除层稀疏化并与保留层合并，仅合并符号相同的元素以减少符号变化干扰。

Result: 在两个LLM和八个下游数据集（包括医疗、金融和通用基准任务）上的实验表明，GradPruner能减少40%参数，仅带来0.99%的准确率下降。

Conclusion: GradPruner能够同时提升LLM下游任务微调的训练和推理效率，通过梯度引导的早期剪枝实现参数大幅减少而性能损失极小。

Abstract: Fine-tuning Large Language Models (LLMs) with downstream data is often considered time-consuming and expensive. Structured pruning methods are primarily employed to improve the inference efficiency of pre-trained models. Meanwhile, they often require additional time and memory for training, knowledge distillation, structure search, and other strategies, making efficient model fine-tuning challenging to achieve. To simultaneously enhance the training and inference efficiency of downstream task fine-tuning, we introduce GradPruner, which can prune layers of LLMs guided by gradients in the early stages of fine-tuning. GradPruner uses the cumulative gradients of each parameter during the initial phase of fine-tuning to compute the Initial Gradient Information Accumulation Matrix (IGIA-Matrix) to assess the importance of layers and perform pruning. We sparsify the pruned layers based on the IGIA-Matrix and merge them with the remaining layers. Only elements with the same sign are merged to reduce interference from sign variations. We conducted extensive experiments on two LLMs across eight downstream datasets. Including medical, financial, and general benchmark tasks. The results demonstrate that GradPruner has achieved a parameter reduction of 40% with only a 0.99% decrease in accuracy. Our code is publicly available.

</details>


### [33] [Automated Safety Benchmarking: A Multi-agent Pipeline for LVLMs](https://arxiv.org/abs/2601.19507)
*Xiangyang Zhu,Yuan Tian,Zicheng Zhang,Qi Jia,Chunyi Li,Renrui Zhang,Heng Li,Zongrui Wang,Wei Sun*

Main category: cs.CL

TL;DR: VLSafetyBencher是首个自动化的大视觉语言模型安全基准测试系统，通过四个协作代理自动构建高质量安全测试样本，在一周内以最小成本完成基准构建，能有效区分模型安全性差异。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在跨模态任务中表现出色，但面临严重的安全挑战，影响其在实际应用中的可靠性。现有安全评估基准存在人工构建过程繁琐、复杂度静态、区分能力有限等问题，无法跟上快速发展的模型和新兴风险。

Method: 提出VLSafetyBencher系统，包含四个协作代理：数据预处理代理、生成代理、增强代理和选择代理，共同构建和筛选高质量的安全测试样本。

Result: 实验验证VLSafetyBencher能在一周内以最小成本构建高质量安全基准。生成的基准能有效区分模型安全性，最安全与最不安全模型之间的安全率差异达70%。

Conclusion: VLSafetyBencher解决了现有安全基准的局限性，为大型视觉语言模型的安全评估提供了自动化、高效且区分力强的解决方案。

Abstract: Large vision-language models (LVLMs) exhibit remarkable capabilities in cross-modal tasks but face significant safety challenges, which undermine their reliability in real-world applications. Efforts have been made to build LVLM safety evaluation benchmarks to uncover their vulnerability. However, existing benchmarks are hindered by their labor-intensive construction process, static complexity, and limited discriminative power. Thus, they may fail to keep pace with rapidly evolving models and emerging risks. To address these limitations, we propose VLSafetyBencher, the first automated system for LVLM safety benchmarking. VLSafetyBencher introduces four collaborative agents: Data Preprocessing, Generation, Augmentation, and Selection agents to construct and select high-quality samples. Experiments validates that VLSafetyBencher can construct high-quality safety benchmarks within one week at a minimal cost. The generated benchmark effectively distinguish safety, with a safety rate disparity of 70% between the most and least safe models.

</details>


### [34] [Yunque DeepResearch Technical Report](https://arxiv.org/abs/2601.19578)
*Yuxuan Cai,Xinyi Lai,Peng Yuan,Weiting Liu,Huajian Li,Mingda Li,Xinghua Wang,Shengxie Zheng,Yanchao Hao,Yuyang Yin,Zheng Wei*

Main category: cs.CL

TL;DR: Yunque DeepResearch是一个分层、模块化、鲁棒的深度研究框架，通过多智能体编排、动态上下文管理和主动监督模块解决现有深度研究中的上下文噪声、脆弱性和扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的深度研究能力存在关键限制：长时程任务中上下文噪声不断升级、脆弱性导致级联错误、缺乏模块化可扩展性，这些阻碍了深度研究充分发挥潜力。

Method: 提出三个关键组件：1) 集中式多智能体编排系统，将子任务路由到原子能力池的工具和专用子智能体；2) 动态上下文管理机制，将完成的子目标结构化成语义摘要以缓解信息过载；3) 主动监督模块，通过主动异常检测和上下文修剪确保鲁棒性。

Result: 在多个智能体深度研究基准测试（包括GAIA、BrowseComp、BrowseComp-ZH和Humanity's Last Exam）上实现了最先进的性能。

Conclusion: Yunque DeepResearch是一个有效的深度研究框架，解决了现有方法的局限性，通过开源框架、可复现实现和应用案例赋能社区。

Abstract: Deep research has emerged as a transformative capability for autonomous agents, empowering Large Language Models to navigate complex, open-ended tasks. However, realizing its full potential is hindered by critical limitations, including escalating contextual noise in long-horizon tasks, fragility leading to cascading errors, and a lack of modular extensibility. To address these challenges, we introduce Yunque DeepResearch, a hierarchical, modular, and robust framework. The architecture is characterized by three key components: (1) a centralized Multi-Agent Orchestration System that routes subtasks to an Atomic Capability Pool of tools and specialized sub-agents; (2) a Dynamic Context Management mechanism that structures completed sub-goals into semantic summaries to mitigate information overload; and (3) a proactive Supervisor Module that ensures resilience through active anomaly detection and context pruning. Yunque DeepResearch achieves state-of-the-art performance across a range of agentic deep research benchmarks, including GAIA, BrowseComp, BrowseComp-ZH, and Humanity's Last Exam. We open-source the framework, reproducible implementations, and application cases to empower the community.

</details>


### [35] [Decompose-and-Formalise: Recursively Verifiable Natural Language Inference](https://arxiv.org/abs/2601.19605)
*Xin Quan,Marco Valentino,Louise A. Dennis,André Freitas*

Main category: cs.CL

TL;DR: 提出分解与形式化框架，通过将前提-假设对分解为原子步骤的蕴含树，自底向上验证并定位失败节点，结合局部诊断引导的细化，提升自然语言推理的解释验证效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将大型语言模型与定理证明器结合时，面临自然语言推理中的挑战：长而语法复杂的输入和多步深层论证会放大自动形式化错误，且当前方法难以定位错误源，只能通过代价高昂的全局重新生成来处理失败。

Method: 提出分解与形式化框架：1) 将前提-假设对分解为原子步骤的蕴含树；2) 自底向上验证树结构以将失败隔离到特定节点；3) 执行局部诊断引导的细化而非重新生成整个解释。此外，引入基于事件的逻辑形式中的θ-替换，以加强一致的角色绑定，提升自动形式化的忠实度。

Result: 在五个LLM骨干上的多种推理任务中，该方法实现了最高的解释验证率，相比现有最佳方法分别提升了26.2%、21.7%、21.6%和48.9%，同时减少了细化迭代次数和运行时间，并保持了强大的NLI准确性。

Conclusion: 分解与形式化框架通过结构化分解、精确故障定位和局部细化，有效解决了神经符号管道在自然语言推理中的可扩展性和可靠性问题，显著提升了自动形式化和解释验证的性能。

Abstract: Recent work has shown that integrating large language models (LLMs) with theorem provers (TPs) in neuro-symbolic pipelines helps with entailment verification and proof-guided refinement of explanations for natural language inference (NLI). However, scaling such refinement to naturalistic NLI remains difficult: long, syntactically rich inputs and deep multi-step arguments amplify autoformalisation errors, where a single local mismatch can invalidate the proof. Moreover, current methods often handle failures via costly global regeneration due to the difficulty of localising the responsible span or step from prover diagnostics. Aiming to address these problems, we propose a decompose-and-formalise framework that (i) decomposes premise-hypothesis pairs into an entailment tree of atomic steps, (ii) verifies the tree bottom-up to isolate failures to specific nodes, and (iii) performs local diagnostic-guided refinement instead of regenerating the whole explanation. Moreover, to improve faithfulness of autoformalisation, we introduce $θ$-substitution in an event-based logical form to enforce consistent argument-role bindings. Across a range of reasoning tasks using five LLM backbones, our method achieves the highest explanation verification rates, improving over the state-of-the-art by 26.2%, 21.7%, 21.6% and 48.9%, while reducing refinement iterations and runtime and preserving strong NLI accuracy.

</details>


### [36] [Up to 36x Speedup: Mask-based Parallel Inference Paradigm for Key Information Extraction in MLLMs](https://arxiv.org/abs/2601.19613)
*Xinzhong Wang,Ya Guo,Jing Li,Huan Chen,Yi Tu,Yijie Hong,Gongshen Liu,Huijia Zhu*

Main category: cs.CL

TL;DR: PIP提出并行推理范式，使用掩码标记同时生成所有目标值，相比自回归模型实现5-36倍推理加速，性能损失可忽略


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM/MLLM的视觉文档关键信息提取方法依赖自回归推理，需要顺序生成输出，在处理多字段提取时存在显著效率瓶颈

Method: 提出PIP并行推理范式：1) 使用"[mask]"标记作为所有目标值的占位符；2) 设计专门的掩码预训练策略；3) 构建大规模监督数据集；4) 在单次前向传播中同时生成所有目标值

Result: PIP模型相比传统自回归基础模型实现5-36倍推理加速，性能损失可忽略不计

Conclusion: PIP通过并行推理范式显著提升KIE任务效率同时保持高精度，为可扩展的实用KIE解决方案铺平道路

Abstract: Key Information Extraction (KIE) from visually-rich documents (VrDs) is a critical task, for which recent Large Language Models (LLMs) and Multi-Modal Large Language Models (MLLMs) have demonstrated strong potential. However, their reliance on autoregressive inference, which generates outputs sequentially, creates a significant efficiency bottleneck, especially as KIE tasks often involve extracting multiple, semantically independent fields. To overcome this limitation, we introduce PIP: a Parallel Inference Paradigm for KIE. Our approach reformulates the problem by using "[mask]" tokens as placeholders for all target values, enabling their simultaneous generation in a single forward pass. To facilitate this paradigm, we develop a tailored mask pre-training strategy and construct large-scale supervised datasets. Experimental results show that our PIP-models achieve a 5-36x inference speedup with negligible performance degradation compared to traditional autoregressive base models. By substantially improving efficiency while maintaining high accuracy, PIP paves the way for scalable and practical real-world KIE solutions.

</details>


### [37] [RATE: Reviewer Profiling and Annotation-free Training for Expertise Ranking in Peer Review Systems](https://arxiv.org/abs/2601.19637)
*Weicong Liu,Zixuan Yang,Yibo Zhao,Xiang Li*

Main category: cs.CL

TL;DR: 提出LR-bench基准和RATE框架，解决LLM时代审稿人分配难题，在2024-2025数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 在LLM时代，审稿人分配面临两个主要挑战：1）预2023基准测试已过时，无法跟上快速变化的主题；2）代理信号（如发表记录）不能准确反映审稿人真正的熟悉程度。

Method: 1）构建LR-bench基准：收集2024-2025年AI/NLP手稿，通过大规模邮件调查获取五级自我评估熟悉度评分，得到1055个专家标注的论文-审稿人-分数三元组；2）提出RATE框架：将审稿人近期发表记录提炼为紧凑的关键词配置文件，使用启发式检索信号构建弱偏好监督来微调嵌入模型，实现手稿与审稿人配置文件的直接匹配。

Result: 在LR-bench和CMU黄金标准数据集上，RATE方法持续达到最先进的性能，明显优于强嵌入基线方法。

Conclusion: 该研究通过创建最新的高质量基准和创新的审稿人中心排名框架，有效解决了LLM时代审稿人分配的评估瓶颈问题，并开源了数据集和代码库。

Abstract: Reviewer assignment is increasingly critical yet challenging in the LLM era, where rapid topic shifts render many pre-2023 benchmarks outdated and where proxy signals poorly reflect true reviewer familiarity. We address this evaluation bottleneck by introducing LR-bench, a high-fidelity, up-to-date benchmark curated from 2024-2025 AI/NLP manuscripts with five-level self-assessed familiarity ratings collected via a large-scale email survey, yielding 1055 expert-annotated paper-reviewer-score annotations. We further propose RATE, a reviewer-centric ranking framework that distills each reviewer's recent publications into compact keyword-based profiles and fine-tunes an embedding model with weak preference supervision constructed from heuristic retrieval signals, enabling matching each manuscript against a reviewer profile directly. Across LR-bench and the CMU gold-standard dataset, our approach consistently achieves state-of-the-art performance, outperforming strong embedding baselines by a clear margin. We release LR-bench at https://huggingface.co/datasets/Gnociew/LR-bench, and a GitHub repository at https://github.com/Gnociew/RATE-Reviewer-Assign.

</details>


### [38] [One Token Is Enough: Improving Diffusion Language Models with a Sink Token](https://arxiv.org/abs/2601.19657)
*Zihou Zhang,Zheyong Xie,Li Zhong,Haifeng Liu,Shaosheng Cao*

Main category: cs.CL

TL;DR: 论文提出了一种简单有效的方法来解决扩散语言模型中的移动汇点现象：通过引入一个额外的汇点令牌来稳定注意力机制，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型存在移动汇点现象，这是一种不稳定性问题。汇点令牌在Transformer值空间中具有低范数表示，移动汇点现象是DLMs防止信息过度混合的保护机制，但其在扩散步骤中的不可预测位置会损害推理的鲁棒性。

Method: 提出通过修改注意力掩码实现一个简单但有效的额外汇点令牌。具体引入一个特殊令牌，该令牌只能关注自身，但对所有其他令牌全局可见。

Result: 实验结果表明，引入单个额外令牌能够稳定注意力汇点，显著提高模型性能。进一步分析证实该令牌的有效性与其位置无关，且语义内容可忽略，验证了其作为鲁棒专用结构汇点的作用。

Conclusion: 额外汇点令牌是解决扩散语言模型中移动汇点现象的有效方法，能够稳定注意力机制并提升模型性能，且该令牌的功能具有结构性和鲁棒性。

Abstract: Diffusion Language Models (DLMs) have emerged as a compelling alternative to autoregressive approaches, enabling parallel text generation with competitive performance. Despite these advantages, there is a critical instability in DLMs: the moving sink phenomenon. Our analysis indicates that sink tokens exhibit low-norm representations in the Transformer's value space, and that the moving sink phenomenon serves as a protective mechanism in DLMs to prevent excessive information mixing. However, their unpredictable positions across diffusion steps undermine inference robustness. To resolve this, we propose a simple but effective extra sink token implemented via a modified attention mask. Specifically, we introduce a special token constrained to attend solely to itself, while remaining globally visible to all other tokens. Experimental results demonstrate that introducing a single extra token stabilizes attention sinks, substantially improving model performance. Crucially, further analysis confirms that the effectiveness of this token is independent of its position and characterized by negligible semantic content, validating its role as a robust and dedicated structural sink.

</details>


### [39] [Component-Level Lesioning of Language Models Reveals Clinically Aligned Aphasia Phenotypes](https://arxiv.org/abs/2601.19723)
*Yifan Wang,Jichen Zheng,Jingyuan Sun,Yunhao Zhang,Chunyu Ye,Jixing Li,Chengqing Zong,Shaonan Wang*

Main category: cs.CL

TL;DR: LLMs可作为语言认知计算模拟器，通过选择性扰动功能组件来模拟失语症语言障碍，在模块化MoE模型中实现更局部化、可解释的表型-组件映射。


<details>
  <summary>Details</summary>
Motivation: LLMs展现出类人语言行为和内部表征，可作为语言认知计算模拟器。研究者希望探索LLMs是否能系统性地模拟脑损伤后失语症的语言障碍特征，为康复假设测试提供可扩展代理，并为语言功能组织研究提供受控框架。

Method: 提出基于临床的组件级框架，通过选择性扰动LLMs中的功能组件来模拟失语症。采用统一干预接口应用于模块化Mixture-of-Experts模型和密集Transformer模型。管道包括：(1)识别Broca和Wernicke失语亚型相关组件；(2)通过语言探测任务解释这些组件；(3)通过渐进扰动top-k亚型相关组件诱导分级损伤，使用西方失语症成套测验(WAB)子测试和失语商(AQ)评估结果。

Result: 跨架构和损伤策略，亚型靶向扰动比大小匹配的随机扰动产生更系统、更类似失语症的回归。MoE模块化支持更局部化和可解释的表型-组件映射。模块化LLMs与临床信息组件扰动相结合，为模拟失语症语言生产和研究不同语言功能在靶向干扰下的退化提供了有前景的平台。

Conclusion: 模块化LLMs结合临床信息组件扰动，为模拟失语症语言生产和研究靶向干扰下不同语言功能退化提供了有前景的计算平台。该方法支持更系统、更类似失语症的回归，模块化架构提供更局部化、可解释的表型-组件映射。

Abstract: Large language models (LLMs) increasingly exhibit human-like linguistic behaviors and internal representations that they could serve as computational simulators of language cognition. We ask whether LLMs can be systematically manipulated to reproduce language-production impairments characteristic of aphasia following focal brain lesions. Such models could provide scalable proxies for testing rehabilitation hypotheses, and offer a controlled framework for probing the functional organization of language. We introduce a clinically grounded, component-level framework that simulates aphasia by selectively perturbing functional components in LLMs, and apply it to both modular Mixture-of-Experts models and dense Transformers using a unified intervention interface. Our pipeline (i) identifies subtype-linked components for Broca's and Wernicke's aphasia, (ii) interprets these components with linguistic probing tasks, and (iii) induces graded impairments by progressively perturbing the top-k subtype-linked components, evaluating outcomes with Western Aphasia Battery (WAB) subtests summarized by Aphasia Quotient (AQ). Across architectures and lesioning strategies, subtype-targeted perturbations yield more systematic, aphasia-like regressions than size-matched random perturbations, and MoE modularity supports more localized and interpretable phenotype-to-component mappings. These findings suggest that modular LLMs, combined with clinically informed component perturbations, provide a promising platform for simulating aphasic language production and studying how distinct language functions degrade under targeted disruptions.

</details>


### [40] [TokenSeek: Memory Efficient Fine Tuning via Instance-Aware Token Ditching](https://arxiv.org/abs/2601.19739)
*Runjia Zeng,Qifan Wang,Qiang Guan,Ruixiang Tang,Lifu Huang,Zhenting Wang,Xueling Zhang,Cheng Han,Dongfang Liu*

Main category: cs.CL

TL;DR: TokenSeek是一个用于Transformer模型的通用插件，通过实例感知的token选择与丢弃机制，显著降低大语言模型微调时的内存消耗，同时保持甚至提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型微调方法存在高内存消耗问题，尤其是激活值占用了大部分内存。虽然已有各种激活优化策略，但它们的数据无关特性导致微调效果不佳且不稳定。

Method: 提出TokenSeek方法，这是一个通用插件解决方案，通过实例感知的token寻找和丢弃机制来优化Transformer模型的微调过程。该方法能够智能选择重要的token并丢弃不重要的token。

Result: TokenSeek实现了显著的微调内存节省（例如在Llama3.2 1B模型上仅需14.8%的内存），同时性能相当甚至更好。可解释的token寻找过程揭示了其有效性的底层原因。

Conclusion: TokenSeek为基于Transformer的模型提供了一种高效的内存优化微调方案，其可解释性为未来的token效率研究提供了有价值的见解。

Abstract: Fine tuning has been regarded as a de facto approach for adapting large language models (LLMs) to downstream tasks, but the high training memory consumption inherited from LLMs makes this process inefficient. Among existing memory efficient approaches, activation-related optimization has proven particularly effective, as activations consistently dominate overall memory consumption. Although prior arts offer various activation optimization strategies, their data-agnostic nature ultimately results in ineffective and unstable fine tuning. In this paper, we propose TokenSeek, a universal plugin solution for various transformer-based models through instance-aware token seeking and ditching, achieving significant fine-tuning memory savings (e.g., requiring only 14.8% of the memory on Llama3.2 1B) with on-par or even better performance. Furthermore, our interpretable token seeking process reveals the underlying reasons for its effectiveness, offering valuable insights for future research on token efficiency. Homepage: https://runjia.tech/iclr_tokenseek/

</details>


### [41] [Strong Reasoning Isn't Enough: Evaluating Evidence Elicitation in Interactive Diagnosis](https://arxiv.org/abs/2601.19773)
*Zhuohan Long,Zhijie Bao,Zhongyu Wei*

Main category: cs.CL

TL;DR: 本文提出了一个交互式医疗咨询评估框架，通过模拟患者和报告器来量化智能体在不确定性下收集临床证据的完整性，发现诊断推理能力不等于有效信息收集，并提出了REFINE策略来指导智能体主动解决不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗咨询评估大多是静态或结果导向的，忽视了证据收集过程。交互式医疗咨询需要智能体在不确定性下主动收集缺失的临床证据，但目前缺乏对这一过程的系统性评估框架。

Method: 1) 提出了基于原子证据的交互式评估框架，使用模拟患者和模拟报告器来建模咨询过程；2) 引入信息覆盖率(ICR)来量化智能体在交互中揭示必要证据的完整性；3) 构建了EviMed基准，涵盖从常见症状到罕见疾病的多样化条件；4) 提出了REFINE策略，利用诊断验证来指导智能体主动解决不确定性。

Result: 评估了10个具有不同推理能力的模型，发现强大的诊断推理能力并不能保证有效的信息收集，这种不足成为限制交互式场景性能的主要瓶颈。REFINE策略在多样化数据集上始终优于基线方法，并促进了有效的模型协作，使较小的智能体在强推理监督下能够获得更好的性能。

Conclusion: 本文提出了一个系统性的交互式医疗咨询评估框架，揭示了诊断推理与信息收集能力之间的脱节，并通过REFINE策略有效解决了这一瓶颈，为提升医疗AI在不确定性下的主动信息收集能力提供了新方向。

Abstract: Interactive medical consultation requires an agent to proactively elicit missing clinical evidence under uncertainty. Yet existing evaluations largely remain static or outcome-centric, neglecting the evidence-gathering process. In this work, we propose an interactive evaluation framework that explicitly models the consultation process using a simulated patient and a \rev{simulated reporter} grounded in atomic evidences. Based on this representation, we introduce Information Coverage Rate (ICR) to quantify how completely an agent uncovers necessary evidence during interaction. To support systematic study, we build EviMed, an evidence-based benchmark spanning diverse conditions from common complaints to rare diseases, and evaluate 10 models with varying reasoning abilities. We find that strong diagnostic reasoning does not guarantee effective information collection, and this insufficiency acts as a primary bottleneck limiting performance in interactive settings. To address this, we propose REFINE, a strategy that leverages diagnostic verification to guide the agent in proactively resolving uncertainties. Extensive experiments demonstrate that REFINE consistently outperforms baselines across diverse datasets and facilitates effective model collaboration, enabling smaller agents to achieve superior performance under strong reasoning supervision. Our code can be found at https://github.com/NanshineLoong/EID-Benchmark .

</details>


### [42] [LVLMs and Humans Ground Differently in Referential Communication](https://arxiv.org/abs/2601.19792)
*Peter Zeng,Weiling Li,Amie Paige,Zhengxiang Wang,Panagiotis Kaliosis,Dimitris Samaras,Gregory Zelinsky,Susan Brennan,Owen Rambow*

Main category: cs.CL

TL;DR: 该研究通过参照沟通实验揭示了大型视觉语言模型在交互式解决指代表达方面的局限性，特别是在建模共同基础方面存在缺陷。


<details>
  <summary>Details</summary>
Motivation: 生成式AI代理要有效与人类用户合作，准确预测人类意图至关重要。但目前这种协作能力受到一个关键缺陷的限制：无法建模共同基础。

Method: 设计了包含四种配对组合（人-人、人-AI、AI-人、AI-AI）的参照沟通实验，参与者通过多轮互动匹配没有明显词汇标签的物体图片。收集了356个对话语料库，并开发了准确度、效率和词汇重叠度的分析工具。

Result: 揭示了大型视觉语言模型在交互式解决指代表达方面的局限性，这是人类语言使用的基础关键技能。实验结果表明AI在建模共同基础方面存在明显不足。

Conclusion: 该研究不仅暴露了LVLMs在交互式参照解决方面的缺陷，还提供了数据收集管道、分析工具和对话语料库，为未来改进AI协作能力提供了基础。

Abstract: For generative AI agents to partner effectively with human users, the ability to accurately predict human intent is critical. But this ability to collaborate remains limited by a critical deficit: an inability to model common ground. Here, we present a referential communication experiment with a factorial design involving director-matcher pairs (human-human, human-AI, AI-human, and AI-AI) that interact with multiple turns in repeated rounds to match pictures of objects not associated with any obvious lexicalized labels. We release the online pipeline for data collection, the tools and analyses for accuracy, efficiency, and lexical overlap, and a corpus of 356 dialogues (89 pairs over 4 rounds each) that unmasks LVLMs' limitations in interactively resolving referring expressions, a crucial skill that underlies human language use.

</details>


### [43] [Zero-Shot Stance Detection in the Wild: Dynamic Target Generation and Multi-Target Adaptation](https://arxiv.org/abs/2601.19802)
*Aohua Li,Yuanshuo Zhang,Ge Gao,Bo Chen,Xiaobing Zhao*

Main category: cs.CL

TL;DR: 该论文提出了一种新颖的零样本立场检测任务DGTA，能够在没有先验目标知识的情况下从文本中自动识别多个目标-立场对，并在中文社交媒体数据集上验证了微调大语言模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 现实社交媒体场景中，立场检测的目标既不是预定义的也不是静态的，而是复杂且动态变化的。当前研究通常基于给定目标和文本进行立场预测，无法应对这种动态场景。

Method: 提出DGTA框架，包含动态目标生成和多目标适应。构建中文社交媒体立场检测数据集，设计多维评估指标。探索了集成和两阶段微调策略，并在多种基线模型上进行评估。

Result: 实验结果表明微调LLM在该任务上表现优异：两阶段微调的Qwen2.5-7B获得最高的综合目标识别分数66.99%，集成微调的DeepSeek-R1-Distill-Qwen-7B获得立场检测F1分数79.26%。

Conclusion: DGTA框架能够有效解决现实社交媒体中动态目标的立场检测问题，微调的大语言模型在该任务上展现出优越性能，为零样本立场检测提供了新思路。

Abstract: Current stance detection research typically relies on predicting stance based on given targets and text. However, in real-world social media scenarios, targets are neither predefined nor static but rather complex and dynamic. To address this challenge, we propose a novel task: zero-shot stance detection in the wild with Dynamic Target Generation and Multi-Target Adaptation (DGTA), which aims to automatically identify multiple target-stance pairs from text without prior target knowledge. We construct a Chinese social media stance detection dataset and design multi-dimensional evaluation metrics. We explore both integrated and two-stage fine-tuning strategies for large language models (LLMs) and evaluate various baseline models. Experimental results demonstrate that fine-tuned LLMs achieve superior performance on this task: the two-stage fine-tuned Qwen2.5-7B attains the highest comprehensive target recognition score of 66.99%, while the integrated fine-tuned DeepSeek-R1-Distill-Qwen-7B achieves a stance detection F1 score of 79.26%.

</details>


### [44] [Identifying and Transferring Reasoning-Critical Neurons: Improving LLM Inference Reliability via Activation Steering](https://arxiv.org/abs/2601.19847)
*Fangan Dong,Zuming Yan,Xuri Ge,Zhiwei Xu,Mengqi Zhang,Xuanang Chen,Ben He,Xin Xin,Zhumin Chen,Ying Zhou*

Main category: cs.CL

TL;DR: AdaRAS是一种轻量级推理时框架，通过选择性干预神经元激活来提升LLM的推理可靠性，无需额外训练或采样成本。


<details>
  <summary>Details</summary>
Motivation: 尽管当前大型语言模型具备强大推理能力，但在复杂任务上实现可靠性能通常需要后训练或计算昂贵的采样策略，限制了实际效率。

Method: 基于发现LLM中少数神经元与推理正确性存在强预测相关性，提出AdaRAS框架：1) 通过极性感知均值差异准则识别推理关键神经元(RCNs)；2) 在推理时自适应引导这些神经元的激活，增强错误推理轨迹同时避免对正确案例的负面影响。

Result: 在10个数学和编程基准测试中取得一致改进，包括在AIME-24和AIME-25上超过13%的提升。方法具有跨数据集的强可迁移性，并能扩展到更强模型，性能优于后训练方法且无需额外训练或采样成本。

Conclusion: AdaRAS通过选择性神经元干预有效提升了LLM的推理可靠性，为高效推理增强提供了一种轻量级解决方案。

Abstract: Despite the strong reasoning capabilities of recent large language models (LLMs), achieving reliable performance on challenging tasks often requires post-training or computationally expensive sampling strategies, limiting their practical efficiency. In this work, we first show that a small subset of neurons in LLMs exhibits strong predictive correlations with reasoning correctness. Based on this observation, we propose AdaRAS (Adaptive Reasoning Activation Steering), a lightweight test-time framework that improves reasoning reliability by selectively intervening on neuron activations. AdaRAS identifies Reasoning-Critical Neurons (RCNs) via a polarity-aware mean-difference criterion and adaptively steers their activations during inference, enhancing incorrect reasoning traces while avoiding degradation on already-correct cases. Experiments on 10 mathematics and coding benchmarks demonstrate consistent improvements, including over 13% gains on AIME-24 and AIME-25. Moreover, AdaRAS exhibits strong transferability across datasets and scalability to stronger models, outperforming post-training methods without additional training or sampling cost.

</details>


### [45] [Reflective Translation: Improving Low-Resource Machine Translation via Structured Self-Reflection](https://arxiv.org/abs/2601.19871)
*Nicholas Cheng*

Main category: cs.CL

TL;DR: 提出Reflective Translation框架，通过模型自我批判和修订来提升低资源语言翻译质量


<details>
  <summary>Details</summary>
Motivation: isiZulu和isiXhosa等低资源语言由于平行数据有限，在机器翻译中面临持续挑战，需要有效方法提升翻译质量

Method: 引入Reflective Translation框架：模型首先生成初始翻译，然后进行结构化自我批判，最后利用反思生成精炼翻译

Result: 在英语-isiZulu和英语-isiXhosa翻译中，BLEU和COMET分数均有提升，平均增益分别达+0.22 BLEU和+0.18 COMET

Conclusion: 结构化自我反思是提升低资源语言翻译质量的有效机制，该方法无需微调且模型无关，并为未来研究提供了反思增强数据集

Abstract: Low-resource languages such as isiZulu and isiXhosa face persistent challenges in machine translation due to limited parallel data and linguistic resources. Recent advances in large language models suggest that self-reflection, prompting a model to critique and revise its own outputs, can improve reasoning quality and factual consistency. Building on this idea, this paper introduces Reflective Translation, a prompt-based framework in which a model generates an initial translation, produces a structured self-critique, and then uses this reflection to generate a refined translation. The approach is evaluated on English-isiZulu and English-isiXhosa translation using OPUS-100 and NTREX-African, across multiple prompting strategies and confidence thresholds. Results show consistent improvements in both BLEU and COMET scores between first- and second-pass translations, with average gains of up to +0.22 BLEU and +0.18 COMET. Statistical significance testing using paired nonparametric tests confirms that these improvements are robust. The proposed method is model-agnostic, requires no fine-tuning, and introduces a reflection-augmented dataset that can support future supervised or analysis-driven work. These findings demonstrate that structured self-reflection is a practical and effective mechanism for improving translation quality in low-resource settings.

</details>


### [46] [Evaluation of Oncotimia: An LLM based system for supporting tumour boards](https://arxiv.org/abs/2601.19899)
*Luis Lorenzo,Marcos Montana-Mendez,Sergio Figueiras,Miguel Boubeta,Cristobal Bernardo-Castineira*

Main category: cs.CL

TL;DR: ONCOTIMIA是一个基于生成式AI的临床工具，通过LLMs自动完成肺癌多学科肿瘤委员会表单，减少文档负担，保持数据质量。


<details>
  <summary>Details</summary>
Motivation: 多学科肿瘤委员会在肿瘤学决策中至关重要，但需要手动处理大量异构临床信息，导致沉重的文档负担。需要自动化工具来提高效率。

Method: 开发ONCOTIMIA模块化安全临床工具，结合多层数据湖、混合关系/向量存储、检索增强生成和规则驱动自适应表单模型，将非结构化临床文档转化为结构化标准化肿瘤委员会记录。评估6个通过AWS Bedrock部署的LLMs在10个肺癌案例中的表现。

Result: 最佳配置实现了80%的正确字段完成率，大多数LLMs具有临床可接受的响应时间。更大更新的模型表现出最佳准确性且不会导致过高的延迟。

Conclusion: LLM辅助的自动表单完成在多学科肺癌工作流程中技术上可行且操作上可行，有潜力显著减少文档负担同时保持数据质量。

Abstract: Multidisciplinary tumour boards (MDTBs) play a central role in oncology decision-making but require manual processes and structuring large volumes of heterogeneous clinical information, resulting in a substantial documentation burden. In this work, we present ONCOTIMIA, a modular and secure clinical tool designed to integrate generative artificial intelligence (GenAI) into oncology workflows and evaluate its application to the automatic completion of lung cancer tumour board forms using large language models (LLMs). The system combines a multi-layer data lake, hybrid relational and vector storage, retrieval-augmented generation (RAG) and a rule-driven adaptive form model to transform unstructured clinical documentation into structured and standardised tumour board records. We assess the performance of six LLMs deployed through AWS Bedrock on ten lung cancer cases, measuring both completion form accuracy and end-to-end latency. The results demonstrate high performance across models, with the best performing configuration achieving an 80% of correct field completion and clinically acceptable response time for most LLMs. Larger and more recent models exhibit best accuracies without incurring prohibitive latency. These findings provide empirical evidence that LLM- assisted autocompletion form is technically feasible and operationally viable in multidisciplinary lung cancer workflows and support its potential to significantly reduce documentation burden while preserving data quality.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [47] [XProvence: Zero-Cost Multilingual Context Pruning for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.18886)
*Youssef Mohamed,Mohamed Elhoseiny,Thibault Formal,Nadezhda Chirkova*

Main category: cs.IR

TL;DR: XProvence是一个多语言零成本上下文剪枝模型，用于检索增强生成，支持100多种语言，在16种语言上训练，能有效剪枝RAG上下文且性能损失极小。


<details>
  <summary>Details</summary>
Motivation: 随着RAG系统在多种语言中的广泛应用，需要将原本仅支持英语的Provence框架扩展到多语言场景，以支持更广泛的跨语言应用需求。

Method: 扩展Provence框架，将高效的零成本上下文剪枝直接集成到重排序模型中，通过跨语言迁移策略，在16种语言上进行训练，支持100多种语言。

Result: 在四个多语言问答基准测试中，XProvence能够有效剪枝RAG上下文，性能下降极小甚至没有下降，且优于多个强基线模型。

Conclusion: XProvence成功实现了多语言零成本上下文剪枝，为多语言RAG系统提供了高效的解决方案，模型已在HuggingFace上开源。

Abstract: This paper introduces XProvence, a multilingual zero-cost context pruning model for retrieval-augmented generation (RAG), trained on 16 languages and supporting 100+ languages through effective cross-lingual transfer. Motivated by the growing use of RAG systems across diverse languages, we explore several strategies to generalize the Provence framework-which first integrated efficient zero-cost context pruning directly into the re-ranking model-beyond English. Across four multilingual question answering benchmarks, we show how XProvence can prune RAG contexts with minimal-to-no performance degradation and outperforms strong baselines. Our model is available at https://huggingface.co/naver/xprovence-reranker-bgem3-v2.

</details>


### [48] [Recommending Composite Items Using Multi-Level Preference Information: A Joint Interaction Modeling Approach](https://arxiv.org/abs/2601.19005)
*Xuan Bi,Yaqiong Wang,Gediminas Adomavicius,Shawn Curley*

Main category: cs.IR

TL;DR: JIMA是一个联合交互建模方法，使用单一模型整合不同粒度层次的数据，学习原子项目和复合项目用户偏好以及领域专业知识之间的复杂关系。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习技术发展，推荐系统应用场景日益复杂多样，需要更复杂的推荐技术。特别是在复合项目（如时尚搭配）推荐中，多个层次的用户偏好信息可能同时存在且相关。

Method: 提出JIMA方法，采用联合交互建模方法，使用单一模型利用不同粒度的所有数据，并整合交互来学习低阶（原子项目）和高阶（复合项目）用户偏好以及领域专业知识（如风格适配）之间的复杂关系。

Result: 通过多个模拟研究以及在离线与在线环境中的真实数据，与先进基线方法进行全面比较，结果一致表明所提方法具有优越性能。

Conclusion: JIMA方法能够有效处理复合项目推荐中的多层次用户偏好问题，在复杂推荐场景中表现出色。

Abstract: With the advancement of machine learning and artificial intelligence technologies, recommender systems have been increasingly used across a vast variety of platforms to efficiently and effectively match users with items. As application contexts become more diverse and complex, there is a growing need for more sophisticated recommendation techniques. One example is the composite item (for example, fashion outfit) recommendation where multiple levels of user preference information might be available and relevant. In this study, we propose JIMA, a joint interaction modeling approach that uses a single model to take advantage of all data from different levels of granularity and incorporate interactions to learn the complex relationships among lower-order (atomic item) and higher-order (composite item) user preferences as well as domain expertise (e.g., on the stylistic fit). We comprehensively evaluate the proposed method and compare it with advanced baselines through multiple simulation studies as well as with real data in both offline and online settings. The results consistently demonstrate the superior performance of the proposed approach.

</details>


### [49] [RobustExplain: Evaluating Robustness of LLM-Based Explanation Agents for Recommendation](https://arxiv.org/abs/2601.19120)
*Guilin Zhang,Kai Zhao,Jeffrey Friedman,Xu Chu*

Main category: cs.IR

TL;DR: 本文提出了RobustExplain框架，首次系统评估LLM生成推荐解释的鲁棒性，发现在真实用户行为噪声下当前模型仅具有中等鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实网络平台中用户行为历史存在固有噪声（如误点击、时间不一致、缺失值、偏好变化），而现有研究主要关注固定输入下的解释流畅性和相关性，对LLM生成解释在噪声下的鲁棒性缺乏系统评估。

Method: 提出RobustExplain框架，包含五种现实用户行为扰动（在不同严重级别下评估）和多维鲁棒性指标（语义、关键词、结构和长度一致性）。在四个代表性LLM（7B-70B）上进行实验。

Result: 当前模型仅表现出中等鲁棒性，更大模型可实现高达8%的稳定性提升。建立了首个解释代理的鲁棒性基准。

Conclusion: 鲁棒性是可信、代理驱动的推荐系统在Web规模下的关键维度，RobustExplain为评估LLM生成解释的鲁棒性提供了原则性框架和基准。

Abstract: Large Language Models (LLMs) are increasingly used to generate natural-language explanations in recommender systems, acting as explanation agents that reason over user behavior histories. While prior work has focused on explanation fluency and relevance under fixed inputs, the robustness of LLM-generated explanations to realistic user behavior noise remains largely unexplored. In real-world web platforms, interaction histories are inherently noisy due to accidental clicks, temporal inconsistencies, missing values, and evolving preferences, raising concerns about explanation stability and user trust. We present RobustExplain, the first systematic evaluation framework for measuring the robustness of LLM-generated recommendation explanations. RobustExplain introduces five realistic user behavior perturbations evaluated across multiple severity levels and a multi-dimensional robustness metric capturing semantic, keyword, structural, and length consistency. Our goal is to establish a principled, task-level evaluation framework and initial robustness baselines, rather than to provide a comprehensive leaderboard across all available LLMs. Experiments on four representative LLMs (7B--70B) show that current models exhibit only moderate robustness, with larger models achieving up to 8% higher stability. Our results establish the first robustness benchmarks for explanation agents and highlight robustness as a critical dimension for trustworthy, agent-driven recommender systems at web scale.

</details>


### [50] [LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems](https://arxiv.org/abs/2601.19121)
*Guilin Zhang,Kai Zhao,Jeffrey Friedman,Xu Chu*

Main category: cs.IR

TL;DR: DualAgent-Rec：基于LLM协调的双智能体框架，用于电商推荐中的约束多目标优化，实现100%约束满足和4-6%帕累托超体积提升。


<details>
  <summary>Details</summary>
Motivation: 现实推荐系统需要同时优化多个目标（如准确性和多样性）并满足硬业务约束（如公平性和覆盖率）。现有方法将约束视为软惩罚或只关注项目评分，导致实际部署中频繁违反约束。如何利用LLM协调约束优化在推荐系统中尚未充分探索。

Method: 提出DualAgent-Rec框架：1) 开发智能体在硬约束下优先考虑准确性；2) 探索智能体通过无约束帕累托搜索促进多样性；3) LLM协调器根据优化进度和约束满足情况自适应分配资源；4) 自适应epsilon松弛机制保证最终解的可行性。

Result: 在Amazon Reviews 2023数据集上的实验表明：1) 实现100%约束满足；2) 帕累托超体积比强基线提升4-6%；3) 保持竞争力的准确性-多样性权衡。

Conclusion: LLM可以作为有效的编排智能体，构建可部署且符合约束的推荐系统。该框架展示了LLM在协调复杂多目标优化问题中的潜力。

Abstract: Recommendation systems must optimize multiple objectives while satisfying hard business constraints such as fairness and coverage. For example, an e-commerce platform may require every recommendation list to include items from multiple sellers and at least one newly listed product; violating such constraints--even once--is unacceptable in production. Prior work on multi-objective recommendation and recent LLM-based recommender agents largely treat constraints as soft penalties or focus on item scoring and interaction, leading to frequent violations in real-world deployments. How to leverage LLMs for coordinating constrained optimization in recommendation systems remains underexplored. We propose DualAgent-Rec, an LLM-coordinated dual-agent framework for constrained multi-objective e-commerce recommendation. The framework separates optimization into an Exploitation Agent that prioritizes accuracy under hard constraints and an Exploration Agent that promotes diversity through unconstrained Pareto search. An LLM-based coordinator adaptively allocates resources between agents based on optimization progress and constraint satisfaction, while an adaptive epsilon-relaxation mechanism guarantees feasibility of final solutions. Experiments on the Amazon Reviews 2023 dataset demonstrate that DualAgent-Rec achieves 100% constraint satisfaction and improves Pareto hypervolume by 4-6% over strong baselines, while maintaining competitive accuracy-diversity trade-offs. These results indicate that LLMs can act as effective orchestration agents for deployable and constraint-compliant recommendation systems.

</details>


### [51] [Accelerating Generative Recommendation via Simple Categorical User Sequence Compression](https://arxiv.org/abs/2601.19158)
*Qijiong Liu,Lu Fan,Zhongzhou Liu,Xiaoyu Dong,Yuankai Luo,Guoyuan An,Nuo Chen,Wei Guo,Yong Liu,Xiao-Ming Wu*

Main category: cs.IR

TL;DR: 提出基于物品类别的长历史压缩方法，在降低计算成本的同时提升推荐准确性


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统在长序列下性能提升但计算成本过高，阻碍实时部署，需要有效压缩用户历史的方法

Method: 利用物品的类别特征压缩长序列用户历史，保留用户兴趣的同时提高效率

Result: 在两个大规模数据集上，相比HSTU模型，计算成本降低6倍，在相似序列长度下准确率提升39%

Conclusion: 提出的基于物品类别的压缩方法能有效平衡生成式推荐系统的计算效率和性能，实现实时部署

Abstract: Although generative recommenders demonstrate improved performance with longer sequences, their real-time deployment is hindered by substantial computational costs. To address this challenge, we propose a simple yet effective method for compressing long-term user histories by leveraging inherent item categorical features, thereby preserving user interests while enhancing efficiency. Experiments on two large-scale datasets demonstrate that, compared to the influential HSTU model, our approach achieves up to a 6x reduction in computational cost and up to 39% higher accuracy at comparable cost (i.e., similar sequence length).

</details>


### [52] [HELM: A Human-Centered Evaluation Framework for LLM-Powered Recommender Systems](https://arxiv.org/abs/2601.19197)
*Sushant Mehta*

Main category: cs.IR

TL;DR: 本文提出了HELM框架，用于评估LLM驱动的推荐系统在五个以人为中心的维度上的表现，弥补了传统准确性指标无法捕捉用户体验多维度的不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要关注传统准确性指标，无法全面衡量LLM推荐系统在真实用户体验中的多维质量，如解释质量、交互自然性等。

Method: 提出了HELM框架，通过三个最先进的LLM推荐系统（GPT-4、LLaMA-3.1、P5）在三个领域（电影、书籍、餐厅）的实验，由12位领域专家对847个推荐场景进行系统评估。

Result: 实验显示GPT-4在解释质量（4.21/5.0）和交互自然性（4.35/5.0）方面表现优异，但存在显著流行度偏差（基尼系数0.73），高于传统协同过滤（0.58）。HELM框架揭示了传统指标无法捕捉的关键质量维度。

Conclusion: HELM框架为推荐系统社区提供了开源工具包，推动了以人为中心的评估实践，能够更全面地评估LLM推荐系统的真实用户体验质量。

Abstract: The integration of Large Language Models (LLMs) into recommendation systems has introduced unprecedented capabilities for natural language understanding, explanation generation, and conversational interactions. However, existing evaluation methodologies focus predominantly on traditional accuracy metrics, failing to capture the multifaceted human-centered qualities that determine the real-world user experience. We introduce \framework{} (\textbf{H}uman-centered \textbf{E}valuation for \textbf{L}LM-powered reco\textbf{M}menders), a comprehensive evaluation framework that systematically assesses LLM-powered recommender systems across five human-centered dimensions: \textit{Intent Alignment}, \textit{Explanation Quality}, \textit{Interaction Naturalness}, \textit{Trust \& Transparency}, and \textit{Fairness \& Diversity}. Through extensive experiments involving three state-of-the-art LLM-based recommenders (GPT-4, LLaMA-3.1, and P5) across three domains (movies, books, and restaurants), and rigorous evaluation by 12 domain experts using 847 recommendation scenarios, we demonstrate that \framework{} reveals critical quality dimensions invisible to traditional metrics. Our results show that while GPT-4 achieves superior explanation quality (4.21/5.0) and interaction naturalness (4.35/5.0), it exhibits a significant popularity bias (Gini coefficient 0.73) compared to traditional collaborative filtering (0.58). We release \framework{} as an open-source toolkit to advance human-centered evaluation practices in the recommender systems community.

</details>


### [53] [Propagating Similarity, Mitigating Uncertainty: Similarity Propagation-enhanced Uncertainty for Multimodal Recommendation](https://arxiv.org/abs/2601.19198)
*Xinzhuo Wu,Hongbo Wang,Yuan Lin,Kan Xu,Liang Yang,Hongfei Lin*

Main category: cs.IR

TL;DR: SPUMR是一个新颖的多模态推荐框架，通过相似性传播增强的不确定性建模来改进多模态推荐，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态推荐系统常受模态特征固有噪声和不确定性的影响（如模糊图像、多样化视觉外观或模糊文本），现有方法常忽略这种模态特异性不确定性，导致特征融合效果不佳，且未能充分利用用户和物品之间的丰富相似性模式来优化表示和不确定性估计。

Method: SPUMR框架首先构建模态相似性图和协同相似性图，从内容和行为角度细化表示；然后通过不确定性感知的偏好聚合模块自适应融合细化的多模态特征，为更可靠的模态分配更大权重。

Result: 在三个基准数据集上的广泛实验表明，SPUMR相比现有领先方法取得了显著改进。

Conclusion: SPUMR通过显式建模和缓解不确定性，并利用相似性传播机制，有效提升了多模态推荐系统的性能。

Abstract: Multimodal Recommendation (MMR) systems are crucial for modern platforms but are often hampered by inherent noise and uncertainty in modal features, such as blurry images, diverse visual appearances, or ambiguous text. Existing methods often overlook this modality-specific uncertainty, leading to ineffective feature fusion. Furthermore, they fail to leverage rich similarity patterns among users and items to refine representations and their corresponding uncertainty estimates. To address these challenges, we propose a novel framework, Similarity Propagation-enhanced Uncertainty for Multimodal Recommendation (SPUMR). SPUMR explicitly models and mitigates uncertainty by first constructing the Modality Similarity Graph and the Collaborative Similarity Graph to refine representations from both content and behavioral perspectives. The Uncertainty-aware Preference Aggregation module then adaptively fuses the refined multimodal features, assigning greater weight to more reliable modalities. Extensive experiments on three benchmark datasets demonstrate that SPUMR achieves significant improvements over existing leading methods.

</details>


### [54] [Physics-Informed Neuro-Symbolic Recommender System: A Dual-Physics Approach for Personalized Nutrition](https://arxiv.org/abs/2601.19244)
*Chayan Banerjee*

Main category: cs.IR

TL;DR: 提出了一种融合营养科学的物理信息神经符号推荐系统，通过双层次架构确保食品推荐满足用户的能量消耗和宏量营养素需求


<details>
  <summary>Details</summary>
Motivation: 传统电商推荐系统主要优化用户参与度和购买可能性，忽视了人类健康所需的严格生理约束。标准的协同过滤算法在结构上无法处理这些硬性限制，经常推荐不符合每日总能量消耗和宏量营养素平衡需求的食品组合。

Method: 1. 使用句子级编码器构建语义知识图谱，将商业产品与权威营养数据严格对齐
2. 训练阶段：应用隐式物理正则化器，使用可微热力学损失函数，确保学习的潜在嵌入反映营养合理性而非简单流行度
3. 推理阶段：使用显式物理优化器，采用模拟退火和弹性数量优化，生成严格符合用户蛋白质和热量目标的离散食品组合

Result: 提出了一个物理信息神经符号推荐系统框架，能够生成符合用户营养需求的食品推荐，解决了传统推荐系统忽视健康约束的问题。

Conclusion: 通过将营养科学直接整合到推荐流程中，该研究提供了一种能够满足严格生理约束的推荐系统方法，为健康导向的电商推荐开辟了新途径。

Abstract: Traditional e-commerce recommender systems primarily optimize for user engagement and purchase likelihood, often neglecting the rigid physiological constraints required for human health. Standard collaborative filtering algorithms are structurally blind to these hard limits, frequently suggesting bundles that fail to meet specific total daily energy expenditure and macronutrient balance requirements. To address this disconnect, this paper introduces a Physics-Informed Neuro-Symbolic Recommender System that integrates nutritional science directly into the recommendation pipeline via a dual-layer architecture. The framework begins by constructing a semantic knowledge graph using sentence-level encoders to strictly align commercial products with authoritative nutritional data. During the training phase, an implicit physics regularizer applies a differentiable thermodynamic loss function, ensuring that learned latent embeddings reflect nutritional plausibility rather than simple popularity. Subsequently, during the inference phase, an explicit physics optimizer employs simulated annealing and elastic quantity optimization to generate discrete grocery bundles that strictly adhere to the user's protein and caloric targets.

</details>


### [55] [Talos: Optimizing Top-$K$ Accuracy in Recommender Systems](https://arxiv.org/abs/2601.19276)
*Shengjia Zhang,Weiqin Yang,Jiawei Chen,Peng Wu,Yuegang Sun,Gang Wang,Qihao Shi,Can Wang*

Main category: cs.IR

TL;DR: Talos是一个专门优化Top-K推荐准确性的损失函数，通过分位数技术和阈值学习替代复杂的排序依赖操作，提高效率并增强对分布偏移的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 推荐系统主要关注Top-K结果质量，但评估Top-K准确性需要确定物品的排序位置，这带来了巨大的计算开销和优化挑战。此外，推荐系统经常面临用户偏好演变或数据偏差导致的分布偏移问题。

Method: 提出Talos损失函数，利用分位数技术将复杂的排序依赖操作简化为预测分数与学习阈值之间的比较；开发基于采样的回归算法进行高效准确的阈值估计；引入约束项防止分数膨胀以保持优化稳定性；并设计定制化的替代函数处理不连续性和增强对分布偏移的鲁棒性。

Result: 通过全面的理论分析和实证实验，证明了Talos在有效性、效率、收敛性和分布鲁棒性方面的优越性能。

Conclusion: Talos提供了一种高效且鲁棒的方法来优化Top-K推荐准确性，解决了传统方法中的计算复杂性和分布偏移问题，在推荐系统领域具有重要应用价值。

Abstract: Recommender systems (RS) aim to retrieve a small set of items that best match individual user preferences. Naturally, RS place primary emphasis on the quality of the Top-$K$ results rather than performance across the entire item set. However, estimating Top-$K$ accuracy (e.g., Precision@$K$, Recall@$K$) requires determining the ranking positions of items, which imposes substantial computational overhead and poses significant challenges for optimization. In addition, RS often suffer from distribution shifts due to evolving user preferences or data biases, further complicating the task.
  To address these issues, we propose Talos, a loss function that is specifically designed to optimize the Talos recommendation accuracy. Talos leverages a quantile technique that replaces the complex ranking-dependent operations into simpler comparisons between predicted scores and learned score thresholds. We further develop a sampling-based regression algorithm for efficient and accurate threshold estimation, and introduce a constraint term to maintain optimization stability by preventing score inflation. Additionally, we incorporate a tailored surrogate function to address discontinuity and enhance robustness against distribution shifts. Comprehensive theoretical analyzes and empirical experiments are conducted to demonstrate the effectiveness, efficiency, convergence, and distributional robustness of Talos. The code is available at https://github.com/cynthia-shengjia/WWW-2026-Talos.

</details>


### [56] [UniRec: Unified Multimodal Encoding for LLM-Based Recommendations](https://arxiv.org/abs/2601.19423)
*Zijie Lei,Tao Feng,Zhigang Hua,Yan Xie,Guanyu Lin,Shuang Yang,Ge Liu,Jiaxuan You*

Main category: cs.IR

TL;DR: UniRec提出了一种统一的多模态编码器，用于解决LLM在推荐系统中处理异质多模态数据（文本、图像、分类特征、数值属性）时面临的跨模态和模态内语义差异挑战，以及用户交互的嵌套结构问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界推荐信号远不止文本和图像，还包括分类特征和数值属性等模态。这些异质多模态数据给LLM带来独特挑战：不仅跨模态存在差异，同一模态内（如价格、评分、时间等数值属性）也具有不同语义含义。此外，推荐信号具有嵌套结构，用户历史是包含多个属性的项目序列。

Method: 提出UniRec统一多模态编码器：1）使用模态特定编码器为异质信号生成一致嵌入；2）采用三元组表示（属性名、类型、值）分离模式与原始输入并保持语义区分；3）使用分层Q-Former建模用户交互的嵌套结构同时保持其分层组织。

Result: 在多个真实世界基准测试中，UniRec比最先进的多模态和LLM推荐系统性能提升高达15%。广泛的消融研究进一步验证了每个组件的贡献。

Conclusion: UniRec通过统一编码框架有效解决了LLM在推荐系统中处理异质多模态数据的挑战，显著提升了推荐性能，为LLM在多模态推荐领域的应用提供了重要进展。

Abstract: Large language models have recently shown promise for multimodal recommendation, particularly with text and image inputs. Yet real-world recommendation signals extend far beyond these modalities. To reflect this, we formalize recommendation features into four modalities: text, images, categorical features, and numerical attributes, and highlight the unique challenges this heterogeneity poses for LLMs in understanding multimodal information. In particular, these challenges arise not only across modalities but also within them, as attributes such as price, rating, and time may all be numeric yet carry distinct semantic meanings. Beyond this intra-modality ambiguity, another major challenge is the nested structure of recommendation signals, where user histories are sequences of items, each associated with multiple attributes. To address these challenges, we propose UniRec, a unified multimodal encoder for LLM-based recommendation. UniRec first employs modality-specific encoders to produce consistent embeddings across heterogeneous signals. It then adopts a triplet representation, comprising attribute name, type, and value, to separate schema from raw inputs and preserve semantic distinctions. Finally, a hierarchical Q-Former models the nested structure of user interactions while maintaining their layered organization. Across multiple real-world benchmarks, UniRec outperforms state-of-the-art multimodal and LLM-based recommenders by up to 15%, and extensive ablation studies further validate the contributions of each component.

</details>


### [57] [Masked Diffusion Generative Recommendation](https://arxiv.org/abs/2601.19501)
*Lingyu Mu,Hao Deng,Haibo Xing,Jinxin Hu,Yu Zhang,Xiaoyi Zeng,Jing Zhang*

Main category: cs.IR

TL;DR: 提出MDGR框架，使用掩码扩散生成推荐，通过并行codebook、自适应掩码训练和两阶段并行解码，解决自回归解码的三个局限性，提升推荐性能和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐采用自回归解码存在三个关键限制：1)难以捕捉SID多维特征的全局依赖；2)固定解码路径假设所有用户以相同顺序关注商品属性；3)推理效率低难以满足实时需求。

Method: 提出MDGR框架：1)采用并行codebook为扩散式GR提供结构基础；2)训练时沿时间和样本维度自适应构建掩码监督信号；3)推理时使用基于预热的两阶段并行解码策略高效生成SID。

Result: 在多个公开和工业规模数据集上，MDGR超越10个SOTA基线达10.78%；在大型在线广告平台部署实现收入增长1.20%，证明其实用价值。

Conclusion: MDGR通过重塑生成式推荐流程，有效解决了自回归解码的局限性，在推荐性能和推理效率上均取得显著提升，具有实际应用价值。

Abstract: Generative recommendation (GR) typically first quantizes continuous item embeddings into multi-level semantic IDs (SIDs), and then generates the next item via autoregressive decoding. Although existing methods are already competitive in terms of recommendation performance, directly inheriting the autoregressive decoding paradigm from language models still suffers from three key limitations: (1) autoregressive decoding struggles to jointly capture global dependencies among the multi-dimensional features associated with different positions of SID; (2) using a unified, fixed decoding path for the same item implicitly assumes that all users attend to item attributes in the same order; (3) autoregressive decoding is inefficient at inference time and struggles to meet real-time requirements. To tackle these challenges, we propose MDGR, a Masked Diffusion Generative Recommendation framework that reshapes the GR pipeline from three perspectives: codebook, training, and inference. (1) We adopt a parallel codebook to provide a structural foundation for diffusion-based GR. (2) During training, we adaptively construct masking supervision signals along both the temporal and sample dimensions. (3) During inference, we develop a warm-up-based two-stage parallel decoding strategy for efficient generation of SIDs. Extensive experiments on multiple public and industrial-scale datasets show that MDGR outperforms ten state-of-the-art baselines by up to 10.78%. Furthermore, by deploying MDGR on a large-scale online advertising platform, we achieve a 1.20% increase in revenue, demonstrating its practical value. The code will be released upon acceptance.

</details>


### [58] [Enhancing Academic Paper Recommendations Using Fine-Grained Knowledge Entities and Multifaceted Document Embeddings](https://arxiv.org/abs/2601.19513)
*Haixu Xi,Heng Zhang,Chengzhi Zhang*

Main category: cs.IR

TL;DR: 本文提出了一种基于细粒度知识实体的学术论文推荐方法，通过整合多维度信息来满足研究过程中的具体文献需求。


<details>
  <summary>Details</summary>
Motivation: 当前学术论文推荐系统主要基于宽泛的主题或领域相似性进行推荐，无法满足学者在研究过程中更具体、细粒度的需求，如寻找使用特定研究方法或解决特定任务的论文。

Method: 提出一种新颖的学术论文推荐方法，通过整合细粒度知识实体、文档标题和摘要、引用数据等多维度信息来嵌入论文，然后计算组合论文向量之间的相似度来生成推荐。

Result: 在STM-KG数据集上的实验结果表明，该方法优于基线模型，在前50个推荐中平均准确率达到27.3%，比现有方法提高了6.7%。

Conclusion: 该方法能够有效满足学者在研究过程中的多样化和具体化文献需求，通过细粒度知识实体整合提升了推荐系统的精准度和实用性。

Abstract: In the era of explosive growth in academic literature, the burden of literature review on scholars are increasing. Proactively recommending academic papers that align with scholars' literature needs in the research process has become one of the crucial pathways to enhance research efficiency and stimulate innovative thinking. Current academic paper recommendation systems primarily focus on broad and coarse-grained suggestions based on general topic or field similarities. While these systems effectively identify related literature, they fall short in addressing scholars' more specific and fine-grained needs, such as locating papers that utilize particular research methods, or tackle distinct research tasks within the same topic. To meet the diverse and specific literature needs of scholars in the research process, this paper proposes a novel academic paper recommendation method. This approach embeds multidimensional information by integrating new types of fine-grained knowledge entities, title and abstract of document, and citation data. Recommendations are then generated by calculating the similarity between combined paper vectors. The proposed recommendation method was evaluated using the STM-KG dataset, a knowledge graph that incorporates scientific concepts derived from papers across ten distinct domains. The experimental results indicate that our method outperforms baseline models, achieving an average precision of 27.3% among the top 50 recommendations. This represents an improvement of 6.7% over existing approaches.

</details>


### [59] [LURE-RAG: Lightweight Utility-driven Reranking for Efficient RAG](https://arxiv.org/abs/2601.19535)
*Manish Chandra,Debasis Ganguly,Iadh Ounis*

Main category: cs.IR

TL;DR: LURE-RAG是一个轻量级效用驱动重排序框架，通过LambdaMART重排序器优化RAG中的文档排序，达到接近SOTA性能但更高效。


<details>
  <summary>Details</summary>
Motivation: 传统RAG管道依赖相关性检索，但相关性常与效用（即检索到的段落是否能真正提升下游任务生成质量）不一致。现有效用驱动检索方法存在两个局限：1) 资源密集，通常需要查询编码；2) 训练时不使用列表排序损失，而文档相对顺序直接影响RAG生成质量。

Method: 提出LURE-RAG框架，为任何黑盒检索器添加基于LambdaMART的高效重排序器。与先前方法不同，LURE-RAG使用由LLM效用指导的列表排序损失训练重排序器，直接优化检索文档的排序。还包括其密集变体UR-RAG。

Result: 在两个标准数据集上的实验表明，LURE-RAG达到竞争性性能，达到最先进密集神经基线的97-98%，同时在训练和推理中都保持高效。其密集变体UR-RAG显著优于现有最佳基线达3%。

Conclusion: LURE-RAG通过轻量级效用驱动重排序有效解决了RAG中检索与生成效用对齐问题，在保持高效的同时达到接近SOTA的性能，其密集变体UR-RAG表现更优。

Abstract: Most conventional Retrieval-Augmented Generation (RAG) pipelines rely on relevance-based retrieval, which often misaligns with utility -- that is, whether the retrieved passages actually improve the quality of the generated text specific to a downstream task such as question answering or query-based summarization. The limitations of existing utility-driven retrieval approaches for RAG are that, firstly, they are resource-intensive typically requiring query encoding, and that secondly, they do not involve listwise ranking loss during training. The latter limitation is particularly critical, as the relative order between documents directly affects generation in RAG. To address this gap, we propose Lightweight Utility-driven Reranking for Efficient RAG (LURE-RAG), a framework that augments any black-box retriever with an efficient LambdaMART-based reranker. Unlike prior methods, LURE-RAG trains the reranker with a listwise ranking loss guided by LLM utility, thereby directly optimizing the ordering of retrieved documents. Experiments on two standard datasets demonstrate that LURE-RAG achieves competitive performance, reaching 97-98% of the state-of-the-art dense neural baseline, while remaining efficient in both training and inference. Moreover, its dense variant, UR-RAG, significantly outperforms the best existing baseline by up to 3%.

</details>


### [60] [Comparing how Large Language Models perform against keyword-based searches for social science research data discovery](https://arxiv.org/abs/2601.19559)
*Mark Green,Maura Halstead,Caroline Jay,Richard Kingston,Alex Singleton,David Topping*

Main category: cs.IR

TL;DR: 本文比较了基于大语言模型的语义搜索与传统关键词搜索在数据发现中的性能，发现语义搜索在结果数量、处理复杂查询和容错性方面表现更优，能有效补充但不会完全取代关键词搜索。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型驱动的语义搜索工具相对于传统关键词搜索在数据发现任务中的实际性能表现，为数据服务平台提供改进搜索功能的实证依据。

Method: 使用从CDRC搜索日志中提取的131个最常用搜索词，对比自定义语义搜索系统与CDRC关键词搜索的输出。通过描述性统计、定性检查和定量相似度测量（精确数据集重叠、Jaccard相似度、BERT嵌入的余弦相似度）分析结果数量、重叠度、排名和相关性的差异。

Result: 语义搜索返回的结果数量更多，在处理基于地点、拼写错误、模糊或复杂查询时表现尤其出色。虽然语义搜索未能捕获所有关键词搜索结果，但返回的数据集在语义上高度相似，余弦相似度得分高而精确重叠度较低。两种工具的搜索结果排名差异显著，反映了不同的优先级策略。案例研究表明，LLM工具对拼写错误具有鲁棒性，能有效解释地理和上下文相关性，并能处理自然语言查询。

Conclusion: LLM驱动的语义搜索为数据发现提供了实质性改进，能够有效补充而非完全取代传统关键词搜索方法，特别是在处理复杂查询和自然语言交互方面表现出优势。

Abstract: This paper evaluates the performance of a large language model (LLM) based semantic search tool relative to a traditional keyword-based search for data discovery. Using real-world search behaviour, we compare outputs from a bespoke semantic search system applied to UKRI data services with the Consumer Data Research Centre (CDRC) keyword search. Analysis is based on 131 of the most frequently used search terms extracted from CDRC search logs between December 2023 and October 2024. We assess differences in the volume, overlap, ranking, and relevance of returned datasets using descriptive statistics, qualitative inspection, and quantitative similarity measures, including exact dataset overlap, Jaccard similarity, and cosine similarity derived from BERT embeddings. Results show that the semantic search consistently returns a larger number of results than the keyword search and performs particularly well for place based, misspelled, obscure, or complex queries. While the semantic search does not capture all keyword based results, the datasets returned are overwhelmingly semantically similar, with high cosine similarity scores despite lower exact overlap. Rankings of the most relevant results differ substantially between tools, reflecting contrasting prioritisation strategies. Case studies demonstrate that the LLM based tool is robust to spelling errors, interprets geographic and contextual relevance effectively, and supports natural-language queries that keyword search fails to resolve. Overall, the findings suggest that LLM driven semantic search offers a substantial improvement for data discovery, complementing rather than fully replacing traditional keyword-based approaches.

</details>


### [61] [LLM-Enhanced Reinforcement Learning for Long-Term User Satisfaction in Interactive Recommendation](https://arxiv.org/abs/2601.19585)
*Chongjun Xia,Yanchun Peng,Xianzhi Wang*

Main category: cs.IR

TL;DR: LERL是一个结合LLM语义规划和RL细粒度适应性的分层推荐框架，通过高层LLM选择多样内容类别，底层RL推荐个性化项目，显著提升长期用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有交互式推荐系统存在内容同质化和过滤气泡问题，过度拟合短期用户偏好。虽然已有改进多样性的方法，但主要关注静态或一次性设置，忽视了用户兴趣的长期演化。强化学习虽能优化长期满意度，但受限于稀疏的用户-项目交互和有限的语义规划能力。

Method: 提出LLM增强的强化学习（LERL）分层框架：1）高层LLM规划器选择语义多样的内容类别；2）底层RL策略在选定语义空间内推荐个性化项目。这种分层设计缩小了动作空间，提高了规划效率，减少了冗余内容的过度曝光。

Result: 在真实世界数据集上的广泛实验表明，LERL相比最先进的基线方法显著提高了长期用户满意度。

Conclusion: LERL通过整合LLM的语义规划能力和RL的细粒度适应性，有效解决了交互式推荐系统中的内容同质化和长期兴趣演化问题，为优化长期用户满意度提供了有效方案。

Abstract: Interactive recommender systems can dynamically adapt to user feedback, but often suffer from content homogeneity and filter bubble effects due to overfitting short-term user preferences. While recent efforts aim to improve content diversity, they predominantly operate in static or one-shot settings, neglecting the long-term evolution of user interests. Reinforcement learning provides a principled framework for optimizing long-term user satisfaction by modeling sequential decision-making processes. However, its application in recommendation is hindered by sparse, long-tailed user-item interactions and limited semantic planning capabilities. In this work, we propose LLM-Enhanced Reinforcement Learning (LERL), a novel hierarchical recommendation framework that integrates the semantic planning power of LLM with the fine-grained adaptability of RL. LERL consists of a high-level LLM-based planner that selects semantically diverse content categories, and a low-level RL policy that recommends personalized items within the selected semantic space. This hierarchical design narrows the action space, enhances planning efficiency, and mitigates overexposure to redundant content. Extensive experiments on real-world datasets demonstrate that LERL significantly improves long-term user satisfaction when compared with state-of-the-art baselines. The implementation of LERL is available at https://anonymous.4open.science/r/code3-18D3/.

</details>


### [62] [Differentiable Semantic ID for Generative Recommendation](https://arxiv.org/abs/2601.19711)
*Junchen Fu,Xuri Ge,Alexandros Karatzoglou,Ioannis Arapakis,Suzan Verberne,Joemon M. Jose,Zhaochun Ren*

Main category: cs.IR

TL;DR: DIGER通过引入Gumbel噪声和不确定性衰减策略，实现了可微分的语义ID学习，解决了生成式推荐中索引与推荐目标不匹配的问题，有效缓解了码书塌陷。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐系统中，语义ID通常只为内容重建优化，而非推荐准确性优化，导致索引损失和推荐损失之间存在目标不匹配。由于分词器独立训练，推荐损失无法更新语义ID学习过程。

Method: 提出DIGER方法，引入Gumbel噪声在早期阶段显式鼓励码本探索，缓解码书塌陷。设计两种不确定性衰减策略逐步减少噪声，实现从探索到利用的平滑过渡。

Result: 在多个公开数据集上的实验表明，可微分语义ID带来了一致的性能提升，验证了通过可微分语义ID对齐索引和推荐目标的有效性。

Conclusion: 可微分语义索引是有前景的研究方向，DIGER通过可微分学习机制有效缓解码书塌陷问题，提高了生成式推荐系统的性能。

Abstract: Generative recommendation provides a novel paradigm in which each item is represented by a discrete semantic ID (SID) learned from rich content. Most existing methods treat SIDs as predefined and train recommenders under static indexing. In practice, SIDs are typically optimized only for content reconstruction rather than recommendation accuracy. This leads to an objective mismatch: the system optimizes an indexing loss to learn the SID and a recommendation loss for interaction prediction, but because the tokenizer is trained independently, the recommendation loss cannot update it. A natural approach is to make semantic indexing differentiable so that recommendation gradients can directly influence SID learning, but this often causes codebook collapse, where only a few codes are used. We attribute this issue to early deterministic assignments that limit codebook exploration, resulting in imbalance and unstable optimization.
  In this paper, we propose DIGER (Differentiable Semantic ID for Generative Recommendation), a first step toward effective differentiable semantic IDs for generative recommendation. DIGER introduces Gumbel noise to explicitly encourage early-stage exploration over codes, mitigating codebook collapse and improving code utilization. To balance exploration and convergence, we further design two uncertainty decay strategies that gradually reduce the Gumbel noise, enabling a smooth transition from early exploration to exploitation of learned SIDs. Extensive experiments on multiple public datasets demonstrate consistent improvements from differentiable semantic IDs. These results confirm the effectiveness of aligning indexing and recommendation objectives through differentiable SIDs and highlight differentiable semantic indexing as a promising research direction.

</details>
